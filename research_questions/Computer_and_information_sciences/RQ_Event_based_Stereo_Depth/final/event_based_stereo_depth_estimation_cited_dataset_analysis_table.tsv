Name (extracted)	Citing Article	Citied Article	Features
MVSEC	https://doi.org/10.1609/aaai.v35i2.16171 (2021), https://doi.org/10.1109/LRA.2023.3269950 (2022), https://doi.org/10.1109/LRA.2023.3311374 (2023) (+3)	https://doi.org/10.1109/LRA.2018.2800793 (2018)	The MVSEC dataset is primarily used for evaluating event-based stereo depth estimation methods, leveraging event cameras and stereo setups. It provides rich sensor data, including event streams, intensity images, and Lidar measurements, enabling researchers to compare performance metrics between event-based and frame-based methods. The dataset supports 3D perception tasks, particularly in indoor environments, and facilitates the development and evaluation of pipelines for event-based stereo depth estimation.
DSEC	https://doi.org/10.1109/TCSVT.2022.3189480 (2022), https://doi.org/10.1109/LRA.2023.3269950 (2022), https://doi.org/10.1109/LRA.2022.3186770 (2022)	https://doi.org/10.1109/LRA.2021.3068942 (2021)	The DSEC dataset is primarily used to evaluate and compare event-based stereo depth estimation methods in driving scenarios. It focuses on challenges such as forward motion, sparse event generation, dynamic conditions, and varying illumination. Researchers use it to validate the performance of event-based algorithms against intensity frame-based methods, emphasizing accuracy and robustness in diverse and challenging environments. The dataset supports the development and testing of stereo event camera algorithms without the need for LiDAR or IMU data.
VECtor	https://doi.org/10.1109/TIV.2024.3412595 (2023), https://doi.org/10.1109/LRA.2023.3269950 (2022)	https://doi.org/10.1109/LRA.2022.3186770 (2022)	The VECtor dataset is primarily used to evaluate and compare algorithms in multi-sensor SLAM and event-based stereo depth estimation. It leverages high-quality ground truth and sensor calibration to assess performance, robustness, and accuracy, particularly in dynamic environments. The dataset supports offline optimization processes and facilitates comparisons between RGB and event-based methods, highlighting its utility in defining method limitations and enhancing system reliability.
Multivehicle Stereo Event Camera Dataset	https://doi.org/10.1007/978-3-030-01246-5_15 (2018)	https://doi.org/10.1109/LRA.2018.2800793 (2018)	The Multivehicle Stereo Event Camera Dataset is used to evaluate and develop methods for 3D perception and stereo depth estimation using event-based cameras. Researchers employ the dataset to create and test stereo observations from real-world sequences, particularly those captured by drones. This enables the assessment of stereo depth estimation techniques in dynamic environments, focusing on improving 3D perception accuracy and robustness.
Multi Vehicle Stereo Event Camera (MVSEC)	https://doi.org/10.1609/aaai.v35i2.16171 (2021), https://doi.org/10.1109/LRA.2023.3311374 (2023), https://doi.org/10.1109/ACCESS.2022.3226484 (2021)	https://doi.org/10.15607/RSS.2018.XIV.062 (2018)	The Multi Vehicle Stereo Event Camera (MVSEC) dataset is primarily used for evaluating and training deep learning networks focused on event-based stereo depth estimation. It provides real-world scenarios to assess the accuracy, smoothness, and performance of trajectory estimates in 3D perception tasks, often compared against state-of-the-art methods. The dataset's event-based camera data enable researchers to enhance and validate algorithms for robust stereo depth estimation.
event-camera dataset	https://doi.org/10.1007/978-3-030-01246-5_15 (2018)	https://doi.org/10.1177/0278364917691115 (2016)	The event-camera dataset is used to evaluate stereo depth estimation methods, particularly through synthetic sequences generated by a simulator. It is also employed to assess event-based stereo depth estimation techniques, focusing on pose estimation, visual odometry, and SLAM. This dataset enables researchers to test and refine algorithms in these specific areas, leveraging its synthetic data to provide controlled evaluation environments.
TUM-VIE sequences	https://doi.org/10.1109/TIV.2024.3412595 (2023)	https://doi.org/10.1109/TRO.2021.3075644 (2020)	The TUM-VIE sequences dataset is mentioned in the citation context but lacks detailed descriptions of its usage in specific research. Therefore, there is no evidence to support claims about its application in event-based stereo depth estimation or any other research areas, methodologies, or specific characteristics.
Indoor Flying dataset	https://doi.org/10.1609/aaai.v35i2.16171 (2021)	https://doi.org/10.1109/ICCV.2019.00161 (2019)	The Indoor Flying dataset is used to train and evaluate event-based stereo depth estimation models, specifically tailored for indoor flying scenarios. This dataset, featuring data from event cameras, enables researchers to focus on the challenges of dynamic indoor environments, enhancing the accuracy and robustness of depth estimation algorithms in such settings.
VECtor sequences	https://doi.org/10.1109/TIV.2024.3412595 (2023)	https://doi.org/10.1109/TRO.2021.3075644 (2020)	The VECtor sequences dataset is used to evaluate multi-sensor SLAM systems, particularly focusing on event-centric data. It enables accurate localization and mapping by providing precise event-based information, which enhances the performance and reliability of SLAM algorithms in dynamic environments.
KITTI	https://doi.org/10.3389/fnins.2017.00535 (2017), https://doi.org/10.1109/LRA.2022.3186770 (2022)	https://doi.org/10.1109/CVPR.2015.7298925 (2015)	The KITTI dataset is primarily used to evaluate stereo vision systems in both real-world driving scenarios and general outdoor and indoor environments. It provides stereo image pairs and ground truth data, enabling researchers to benchmark and compare stereo depth estimation methods. The dataset's comprehensive ground truth data and diverse environmental conditions facilitate robust evaluation and improvement of stereo vision algorithms.
Multi Vehicle Stereo Event Camera Dataset (MVSEC)	https://doi.org/10.1609/aaai.v35i2.16171 (2021), https://doi.org/10.1109/TCSVT.2022.3189480 (2022)	https://doi.org/10.15607/RSS.2018.XIV.062 (2018)	The MVSEC dataset is primarily used for evaluating and training methods in event-based stereo depth estimation. It supports research by providing data to assess performance metrics and robustness in dynamic environments. The dataset is also utilized to develop and validate unsupervised event stereo methods, focusing on enhancing 3D perception tasks. Its characteristics enable researchers to test algorithms under realistic conditions, ensuring practical applicability.
TUM-VIE	https://doi.org/10.1109/TIV.2024.3412595 (2023)	https://doi.org/10.1109/ICCV48922.2021.01249 (2021)	The TUM-VIE dataset is used to evaluate methods in event-based stereo depth estimation, specifically focusing on the accuracy and robustness of these methods. It assesses the ability of proposed techniques to maintain and track features under varying lighting conditions, employing a fusion of events and frames to enhance performance.
Middlebury	https://doi.org/10.1109/CVPR.2018.00786 (2018)	https://doi.org/10.1109/CVPR.2015.7298925 (2015)	The Middlebury dataset is referenced in academic citations but lacks detailed descriptions of its usage. There is no explicit evidence provided regarding its application in event-based stereo depth estimation or any other specific research methodologies, questions, or characteristics. Therefore, based on the given information, the actual usage and research enabled by this dataset cannot be accurately specified.
DDD17	https://doi.org/10.1109/LRA.2018.2800793 (2018)	https://www.semanticscholar.org/paper/e9496ccf44f6ebca4f01c31a012bdab7cac4a65c (2017)	The DDD17 dataset is used to provide a large collection of data from a DAVIS 346B event-based sensor mounted in a car, capturing 12 hours of driving scenarios. It is employed for end-to-end learning of driving-related tasks, leveraging the unique temporal resolution and dynamic range of event-based sensors to enhance the training of machine learning models for real-time driving applications.
ESVO (Stereo Events)	https://doi.org/10.1109/TIV.2024.3412595 (2023)	https://doi.org/10.1109/TRO.2021.3062252 (2020)	The ESVO (Stereo Events) dataset is used to evaluate event-based stereo visual odometry, specifically focusing on the accuracy and robustness of depth estimation in dynamic environments. This dataset enables researchers to test and validate algorithms designed to handle real-time, high-frequency event data, ensuring reliable performance under varying conditions.
DAVISm346b	https://doi.org/10.1109/LRA.2018.2800793 (2018)	https://doi.org/10.1109/ICRA.2014.6906892 (2014)	The DAVISm346b dataset is used to provide event streams from synchronized and calibrated dynamic vision sensors, capturing long indoor and outdoor sequences under varying conditions. It includes depth images and pose data, enabling research in stereo depth estimation. This dataset supports the development and evaluation of algorithms by offering realistic, diverse, and well-calibrated data.
VECDataset	https://doi.org/10.1109/LRA.2023.3269950 (2022)	https://doi.org/10.1109/LRA.2022.3186770 (2022)	The VECDataset is mentioned in the citation context but lacks detailed descriptions of its usage, methodology, research questions, or specific characteristics. Therefore, there is insufficient evidence to provide a comprehensive description of how this dataset is actually used in research.
DAVIS	https://doi.org/10.1177/1729881417752759 (2018)	https://doi.org/10.1109/JSSC.2014.2342715 (2014)	The DAVIS dataset is used for capturing event-based data for stereo depth estimation, specifically focusing on high-resolution and low-latency event streams. It employs a quadruplet representation (time, x, y, polarity) to enable precise and efficient processing of visual events, facilitating research in real-time depth perception and dynamic scene understanding.
MVS	https://doi.org/10.1109/LRA.2023.3269950 (2022)	https://doi.org/10.1109/LRA.2018.2800793 (2018)	The dataset 'MVS' is mentioned in the citation context but lacks detailed descriptions of its usage, methodology, research questions, or specific characteristics. Therefore, there is insufficient evidence to provide a comprehensive description of how this dataset is actually used in research.
DSEC dataset	https://doi.org/10.1109/TCSVT.2022.3189480 (2022)	https://doi.org/10.1109/LRA.2018.2800793 (2018)	The DSEC dataset is mentioned in research citations but lacks detailed descriptions of its usage. There is no explicit information on how it is employed in methodologies, specific research questions, or the characteristics that enable its use. Therefore, based on the provided evidence, no specific research application or methodology can be accurately described for this dataset.
3planes	https://doi.org/10.1007/978-3-030-01246-5_15 (2018)	https://doi.org/10.1177/0278364917691115 (2016)	The '3planes' dataset is used to simulate event-based data for pose estimation, offering a controlled environment to test algorithms under diverse conditions. This enables researchers to evaluate and refine pose estimation techniques systematically, ensuring robust performance across varying scenarios.
Indoor flying1	https://doi.org/10.1007/978-3-030-01246-5_15 (2018)	https://doi.org/10.1177/0278364917691115 (2016)	The 'Indoor flying1' dataset is used to evaluate event-based visual odometry in indoor flying scenarios. It focuses on accurate motion estimation and assessing the robustness of algorithms in dynamic environments. This dataset enables researchers to test and improve the performance of visual odometry techniques specifically tailored for indoor navigation tasks.
Indoor flying3	https://doi.org/10.1007/978-3-030-01246-5_15 (2018)	https://doi.org/10.1177/0278364917691115 (2016)	The 'Indoor flying3' dataset is used to evaluate the performance of event-based SLAM in complex indoor flying environments. It emphasizes real-time processing and accuracy, enabling researchers to test and refine algorithms for robust navigation and mapping in dynamic indoor settings.
Stereo DAVIS sequences	https://doi.org/10.1109/TIV.2024.3412595 (2023)	https://doi.org/10.1007/978-3-030-01246-5_15 (2018)	The Stereo DAVIS sequences dataset is used to evaluate stereo depth estimation with event-based cameras, specifically focusing on alignment and reconstruction accuracy in semi-dense 3D environments. This dataset enables researchers to assess the performance of event-based stereo algorithms, ensuring precise and reliable depth maps in dynamic scenes.
An Event-based Vision Dataset for Visual Navigation Tasks in Agricultural Environments	https://doi.org/10.1109/LRA.2022.3186770 (2022)	https://doi.org/10.1109/ICRA48506.2021.9561741 (2021)	The dataset is used to evaluate event-based stereo depth estimation methods, particularly in agricultural environments. Researchers focus on assessing the performance of depth estimation techniques using event cameras in various agricultural settings. This enables the development and refinement of visual navigation systems tailored for complex, dynamic agricultural scenarios.
