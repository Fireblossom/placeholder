{
  "report_info": {
    "title": "TEXT LINE SEGMENTATION IN HISTORICAL DOCUMENT - CITING PAPERS 论文引用上下文分析报告",
    "query": "text line segmentation in historical document - Citing Papers",
    "generated_at": "2025-09-12 15:33:37",
    "total_papers_queried": 187,
    "papers_with_contexts": 130,
    "papers_without_contexts": 57
  },
  "query_statistics": {
    "total_ids": 187,
    "found_ids": 130,
    "not_found_ids": [
      235844545,
      278408772,
      269393137,
      127518132,
      237458512,
      280665989,
      251431450,
      53291082,
      53214848,
      65203611,
      125859161,
      257519806,
      723272,
      16958669,
      174800931,
      280870692,
      271077920,
      261102307,
      276265187,
      271370811,
      251083372,
      246081075,
      237684384,
      280340334,
      238586016,
      240825722,
      261102085,
      252500460,
      1610874,
      46776463,
      238242471,
      155528821,
      233432159,
      1913486,
      10565704,
      69711838,
      49301635,
      254127000,
      244777991,
      221141556,
      46234524,
      221152889,
      42133220,
      203847886,
      228771619,
      19363314,
      36033438,
      60712058,
      2775421,
      247606794,
      255163345,
      46946833,
      57314701,
      39591642,
      257337051,
      270457626,
      155837360
    ],
    "total_results": 1039,
    "query_time_seconds": 2.417555570602417
  },
  "papers_data": {
    "211026904": {
      "citing_paper_info": {
        "title": "Text Line Segmentation in Historical Document Images Using an Adaptive U-Net Architecture",
        "abstract": "On most document image transcription, indexing and retrieval systems, text line segmentation remains one of the most important preliminary task. Hence, the research community working in document image analysis is particularly interested in providing reliable text line segmentation methods. Recently, an increasing interest in using deep learning-based methods has been noted for solving various sub-fields and tasks related to the issues surrounding document image analysis. Thanks to the computer hardware and software evolution, several methods based on using deep architectures continue to outperform the pattern recognition issues and particularly those related to historical document image analysis. Thus, in this paper we present a novel deep learning-based method for text line segmentation of historical documents. The proposed method is based on using an adaptive U-Net architecture. Qualitative and numerical experiments are given using a large number of historical document images collected from the Tunisian national archives and different recent benchmarking datasets provided in the context of ICDAR and ICFHR competitions. Moreover, the results achieved are compared with those obtained using the state-of-the-art methods.",
        "year": 2019,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "51133427",
            "name": "Olfa Mechi"
          },
          {
            "authorId": "2131158",
            "name": "Maroua Mehri"
          },
          {
            "authorId": "1680326",
            "name": "R. Ingold"
          },
          {
            "authorId": "2536574",
            "name": "N. Amara"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 12,
        "unique_cited_count": 12,
        "influential_count": 4,
        "detailed_records_count": 12
      },
      "cited_papers": [
        "56598011",
        "619938",
        "4761833",
        "53362938",
        "1779661",
        "56597938",
        "1610874",
        "53564381",
        "3496842",
        "14196680",
        "15257932",
        "3719281"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "[14]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1610874,
          "isinfluential": true,
          "contexts": [
            "The ad-hoc methods have been categorized into three classes [3].",
            "• Enclosing polygon: Corresponds to a geometric representation which encloses the total connected text pixels [3].",
            "Nevertheless, two main categories can be distinguished [3].",
            "Several deep learningbased contributions achieved on different sub-fields and tasks of document image analysis have been recently reported in the literature and particularly for text line segmentation [3].",
            "• X-height: Corresponds to the area covering the text core, without considering its ascenders and descenders [3].",
            "• Set of pixels: Corresponds to the pixels defined in the textual components [3].",
            "recognition task based on pre-segmented text lines [3]."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['background']",
            "['background']",
            "['background']",
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Dense prediction for text line segmentation in handwritten document images",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Information Photonics",
            "authors": [
              {
                "authorId": "12581289",
                "name": "Q. Vo"
              },
              {
                "authorId": "144096223",
                "name": "Gueesang Lee"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1779661,
          "isinfluential": false,
          "contexts": [
            "• Deep learning-based methods: are based on using a large number of parameters and layers in neural networks [21]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Deep Learning",
            "abstract": "",
            "year": 2016,
            "venue": "International Journal of Semantic Computing",
            "authors": [
              {
                "authorId": "2343609447",
                "name": "Xingbang Hao"
              },
              {
                "authorId": "8273966",
                "name": "Guigang Zhang"
              },
              {
                "authorId": "2118869556",
                "name": "Shang Ma"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3496842,
          "isinfluential": false,
          "contexts": [
            "Nevertheless, the publicly available datasets of historical document images can be mostly provided for scientific use in the context of ICFHR and ICDAR competitions [12], [11], [13].",
            "2) Experiments have been conducted on a large number of historical document images collected from the ANT4 and different current benchmarking datasets provided in the context of ICDAR [11], ICFHR competitions [12], [13] (READ1, cBAD2 and DIVA-HisDB3)."
          ],
          "intents": [
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "DIVA-HisDB: A Precisely Annotated Large Dataset of Challenging Medieval Manuscripts",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2860677",
                "name": "Fotini Simistira"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "2065610080",
                "name": "Nicole Eichenberger"
              },
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3719281,
          "isinfluential": true,
          "contexts": [
            "[10] focused on increasing the output resolution of the network architecture.",
            "Unlike the original U-Net architecture which is based on using 64 filters at the first block, and then 64, 128, 256, 512 and 1024 filters at each block in the contracting path [10], we propose to use 32 filters at the first block, and then 32, 64, 128, 256 and 512 filters at each block in the contracting path.",
            "The U-Net architecture was previously used for medical image segmentation [10].",
            "[10] used the upsampling by means of the “Upsampling2D” operation for the decoder phase.",
            "[10] for segmentation in medical imaging."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
            "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .",
            "year": 2015,
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "authors": [
              {
                "authorId": "1737326",
                "name": "O. Ronneberger"
              },
              {
                "authorId": "152702479",
                "name": "P. Fischer"
              },
              {
                "authorId": "1710872",
                "name": "T. Brox"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4761833,
          "isinfluential": true,
          "contexts": [
            "evaluation criteria as in the cBAD competition: precision (P), recall (R) and F-measure (F) [11].",
            "In the past few years, there has been increasing interest in using deep learning-based methods for solving various sub-\n2https://scriptnet.iit.demokritos.gr/competitions/5/ 3https://diuf.unifr.ch/main/hisdoc/diva-hisdb 4http://www.archives.nat.tn/\n369\n2379-2140/19/$31.00 ©2019 IEEE DOI 10.1109/ICDAR.2019.00066\nfields and tasks related to the issues surrounding computer vision and pattern recognition and particularly document image analysis [6].",
            "Thus, to analyze the performance of the proposed method, a set of experiments has\nbeen conducted with qualitative and numerical observations obtained firstly from historical document images collected from both three public benchmarking datasets provided in the context of ICDAR and ICFHR competitions (READ1, cBAD2 and DIVA-HisDB3), and then from the ANT4.",
            "2) Experiments have been conducted on a large number of historical document images collected from the ANT4 and different current benchmarking datasets provided in the context of ICDAR [11], ICFHR competitions [12], [13] (READ1, cBAD2 and DIVA-HisDB3).",
            "Nevertheless, the publicly available datasets of historical document images can be mostly provided for scientific use in the context of ICFHR and ICDAR competitions [12], [11], [13].",
            "2) The second dataset, which is called cBAD2, was released in the context of the ICDAR competition on baseline detection [11].",
            "• Baseline: Corresponds to a virtual line which encloses the most characters whereas descender remains below [11]."
          ],
          "intents": [
            "['background']",
            "--",
            "--",
            "--",
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "cBAD: ICDAR2017 Competition on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              },
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14196680,
          "isinfluential": false,
          "contexts": [
            "[20] proposed to first extract the CCs, and then to apply the Hough transform in order to detect the text lines, and finally to carry out a post processing step in order to correct the false alarms."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line and word segmentation of handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15257932,
          "isinfluential": false,
          "contexts": [
            "[15] proposed to apply the steerable directional filters to locate the text lines and to use heuristic post-processing task in order to isolate the connected lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition A Steerable Directional Local Profile Technique for Extraction of Handwritten Arabic Text Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 53362938,
          "isinfluential": false,
          "contexts": [
            "Indeed, the large digitization programs conducted by the ANT over the last three decades result in the need for a robust and accurate text recognition system [4]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Comparative Study of Filtering Approaches Applied to Color Archival Document Images",
            "abstract": "Current systems used by the Tunisian national archives for the automatic transcription of archival documents are hindered by many issues related to the performance of the optical character recognition (OCR) tools. Indeed, using a classical OCR system to transcribe and index ancient Arabic documents is not a straightforward task due to the idiosyncrasies of this category of documents, such as noise and degradation. Thus, applying an enhancement method or a denoising technique remains an essential prerequisite step to ease the archival document image analysis task. The state-of-the-art methods addressing the use of degraded document image enhancement and denoising are mainly based on applying filters. The most common filtering techniques applied to color images in the literature may be categorized into four approaches: scalar, marginal, vector and hybrid. To provide a set of comprehensive guidelines on the strengths and weaknesses of these filtering approaches, a thorough comparative study is proposed in this article. Numerical experiments are carried out in this study on color archival document images to show and quantify the performance of each assessed filtering approach.",
            "year": 2019,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "9736202",
                "name": "Walid Elhedda"
              },
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1707715",
                "name": "M. Mahjoub"
              }
            ]
          }
        },
        {
          "citedcorpusid": 53564381,
          "isinfluential": false,
          "contexts": [
            "analysis [6]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Shall deep learning be the mandatory future of document analysis problems?",
            "abstract": "",
            "year": 2019,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "145645182",
                "name": "N. Vincent"
              },
              {
                "authorId": "1695766",
                "name": "J. Ogier"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56597938,
          "isinfluential": false,
          "contexts": [
            "Figure 1(a)) [12].",
            "Nevertheless, the publicly available datasets of historical document images can be mostly provided for scientific use in the context of ICFHR and ICDAR competitions [12], [11], [13].",
            "2) Experiments have been conducted on a large number of historical document images collected from the ANT4 and different current benchmarking datasets provided in the context of ICDAR [11], ICFHR competitions [12], [13] (READ1, cBAD2 and DIVA-HisDB3)."
          ],
          "intents": [
            "--",
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "ICFHR2018 Competition on Automated Text Recognition on a READ Dataset",
            "abstract": "We summarize the results of a competition on Automated Text Recognition targeting the effective adaptation of recognition engines to essentially new data. The task consists in achieving a minimum character error rate on a previously unknown text corpus from which only a few pages are available for adjusting an already pre-trained recognition engine. This issue addresses a frequent application scenario where only a small amount of task-specific training data is available, because producing this data usually requires much effort. We present the results of five submission. They show that the task is a challenging issue but for certain documents 16 pages of transcription are sufficient to adapt a pre-trained recognition system.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "40508719",
                "name": "Tobias Strauß"
              },
              {
                "authorId": "1680083",
                "name": "Gundram Leifert"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              },
              {
                "authorId": "1380013206",
                "name": "Tobias Hodel"
              },
              {
                "authorId": "32708042",
                "name": "Günter Mühlberger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56598011,
          "isinfluential": true,
          "contexts": [
            "Kiumarsi and Alaei [19] stated that their method achieved a comparable performance to the state-ofthe-art methods with a low computation, but it failed to detect correctly the text lines in the case of small inter-line gaps.",
            "For example, Kiumarsi and Alaei [19] proposed a hybrid method which first identified the CCs chains in order to determine the separator lines, and then computed an adaptive projection profile for text line extraction in handwritten document images.",
            "Alaei et al. [16] proposed to split a document image into vertical strips based on firstly determining the inter-line gap, and then on applying a piece wise filtering on each strip, and finally on using a thinning algorithm for handwritten text line segmentation.",
            "Kiumarsi and Alaei [19] stated that their"
          ],
          "intents": [
            "--",
            "['methodology']",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "A Hybrid Method for Text Line Extraction in Handwritten Document Images",
            "abstract": "Text line segmentation in handwritten document image, as one of the preliminarily steps for document image recognition, is a challenging problem. In this paper, a hybrid method for text line extraction in handwritten document images is presented. Initially, a connected component (CC) labelling method following by a CC filtering is employed to extract a set of CCs from the input document image. A new distance measure is introduced to compute normal distances between the extracted CCs. By traversing the normal distance matrix from both the right and left directions, half-chains of CCs are constructed. The CCs half-chains are merged to obtain CCs full-chains. From the extracted full-chains separator lines are obtained. A gradient metric is proposed to detect and remove touching text lines. Using remaining separator lines the adaptive projection profile of the image is computed. Based on the projection profile, coarse text line extraction is performed. Finally, a fine text lines extraction is performed by applying a postprocessing step. To evaluate the method, two benchmarks named ICDAR2013 handwriting segmentation contest, and Kannada datasets composed of handwritten document images in English, Greek, Bengali, and Kannada languages were considered for experimentation. Experimental results indicate a promising performance was obtained compared to some of the state-of-the-art methods.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "52424260",
                "name": "Ehsan Kiumarsi"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              }
            ]
          }
        }
      ]
    },
    "254100190": {
      "citing_paper_info": {
        "title": "An effective method for text line segmentation in historical document images",
        "abstract": "In this paper, we present a text-line segmentation method for historical documents. Historical documents are challenging given their characteristics of highly degradation, writing style variation and diacritics. From these observations, we proposed an effective approach for text line segmentation by analysing the properties of document layouts. We combine the idea of seam carving method with the novel cost functions to accurately split text lines. Experiments were conducted on two challenging datasets of historical documents, namely the DIVA-HisDB dataset and our ChamDoc dataset. Our methods provided good results on the DIVA-HisDB dataset with 99.36% of Line IU and 98.86% of Pixel IU. On the ChamDoc dataset, the proposed method outperformed the two baseline approaches i.e. seam carving-based and A* path planning by a large margin.",
        "year": 2022,
        "venue": "International Conference on Pattern Recognition",
        "authors": [
          {
            "authorId": "123232762",
            "name": "Tien-Nam Nguyen"
          },
          {
            "authorId": "1690398",
            "name": "J. Burie"
          },
          {
            "authorId": "10128454",
            "name": "Thi-Lan Le"
          },
          {
            "authorId": "103858632",
            "name": "Anne-Valérie Schweyer"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 11,
        "unique_cited_count": 11,
        "influential_count": 2,
        "detailed_records_count": 11
      },
      "cited_papers": [
        "56597514",
        "52953483",
        "1913486",
        "221130277",
        "17844687",
        "4765236",
        "33748389",
        "35471180",
        "12814562",
        "195750543",
        "41601768"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1913486,
          "isinfluential": false,
          "contexts": [
            "In the bottom-up approaches [13], [14], [15], topological features are used such as connected components.",
            "done through different methods such as image blurring [13], steerable directional filters [14] or isotropic Gaussian filters in multi-scale space [15]."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 4765236,
          "isinfluential": true,
          "contexts": [
            "1) DIVA-HisBD dataset: DIVA-HisDB dataset [5] contains 150 pages of three different medieval manuscripts (CB55, CSG863, CSG18) dating from 11th to the 14th century and\ndigitized with a resolution of 600 dpi camera.",
            "setup of evaluation tools provided in the competition [5].",
            "We use the DIVA-HisDB dataset [5] to compare our approach with other state-of-the-art methods.",
            "In section IV, we present the experimental results on two datasets: DIVA-HisDB dataset [5] and our own ChamDoc dataset.",
            "We found that with the DIVA-HisDB dataset, the weight related to the balance cost function has a minor impact.",
            "1) DIVA-HisBD dataset: DIVA-HisDB dataset [5] contains 150 pages of three different medieval manuscripts (CB55, CSG863, CSG18) dating from 11th to the 14th century and",
            "datasets: the DIVA-HisDB [5] and our own ChamDoc dataset.",
            "For the second set of metrics used with the Diva-HisBD dataset, we have adopted the metrics Line IU and Pixel IU [5] used in different papers of the literature.",
            "Experiments on our ChamDoc dataset and DIVA-HisDB dataset prove the relevance of our method.",
            "In this section, we conducted the experiments on two datasets: the DIVA-HisDB [5] and our own ChamDoc dataset.",
            "We set the value to 1e − 6\non ChamDoc dataset and 5e− 4 on the DIVA-HisDB.",
            "1) DIVA-HisDB dataset: Table I shows the comparison results of our method with different approaches on DIVA-HisDB dataset.",
            "For this experiment, we use the private test set with 30 pages (875 lines) of the ICDAR 2017 competition [5]."
          ],
          "intents": [
            "--",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "--",
            "['background']",
            "['methodology']",
            "['methodology']",
            "--",
            "--",
            "--",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ICDAR2017 Competition on Layout Analysis for Challenging Medieval Manuscripts",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2860677",
                "name": "Fotini Simistira"
              },
              {
                "authorId": "2489964",
                "name": "Manuel Bouillon"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "3424460",
                "name": "Marcel Würsch"
              },
              {
                "authorId": "38890619",
                "name": "Michele Alberti"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12814562,
          "isinfluential": false,
          "contexts": [
            "Another approach belonging to top-down category is seam carving-based [10], [7], [11], [3].",
            "We can note that, in comparison with seam carving based method [11], our approach improved both Line IU and Pixel IU scores."
          ],
          "intents": [
            "['background']",
            "['result']"
          ],
          "cited_paper_info": {
            "title": "Robust Heartbeat-based Line Segmentation Methods for Regular Texts and Paratextual Elements",
            "abstract": "",
            "year": 2017,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "31977716",
                "name": "D. Ezra"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17844687,
          "isinfluential": false,
          "contexts": [
            "The first one from [22] includes Detection Rate (DR), Recognition Accuracy (RA), F-measure (FM) is used with the ChamDoc dataset."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition ICDAR2009 Handwriting Segmentation Contest",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 33748389,
          "isinfluential": false,
          "contexts": [
            "Recently, deep learning-based methods for text line segmentation have been emerged [16], [17], [18], [19].",
            "In [18] the authors first used a deep convolution network to assign each pixel to the corresponding class (baseline, separator, other), then they calculated super-pixels from the output of the previous step before estimating and assigning them to the text line."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A two-stage method for text line detection in historical documents",
            "abstract": "This work presents a two-stage text line detection method for historical documents. Each detected text line is represented by its baseline. In a first stage, a deep neural network called ARU-Net labels pixels to belong to one of the three classes: baseline, separator and other. The separator class marks beginning and end of each text line. The ARU-Net is trainable from scratch with manageably few manually annotated example images (<50\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$<\\,50$$\\end{document}). This is achieved by utilizing data augmentation strategies. The network predictions are used as input for the second stage which performs a bottom-up clustering to build baselines. The developed method is capable of handling complex layouts as well as curved and arbitrarily oriented text lines. It substantially outperforms current state-of-the-art approaches. For example, for the complex track of the cBAD: ICDAR2017 Competition on Baseline Detection the F value is increased from 0.859 to 0.922. The framework to train and run the ARU-Net is open source.",
            "year": 2018,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "1680083",
                "name": "Gundram Leifert"
              },
              {
                "authorId": "40508719",
                "name": "Tobias Strauß"
              },
              {
                "authorId": "88739357",
                "name": "Johannes Michael"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              }
            ]
          }
        },
        {
          "citedcorpusid": 35471180,
          "isinfluential": false,
          "contexts": [
            "In the bottom-up approaches [13], [14], [15], topological features are used such as connected components.",
            "done through different methods such as image blurring [13], steerable directional filters [14] or isotropic Gaussian filters in multi-scale space [15]."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Using Scale-Space Anisotropic Smoothing for Text Line Extraction in Historical Documents",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Image Analysis and Recognition",
            "authors": [
              {
                "authorId": "51037361",
                "name": "Rafi Cohen"
              },
              {
                "authorId": "1686153",
                "name": "I. Dinstein"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              }
            ]
          }
        },
        {
          "citedcorpusid": 41601768,
          "isinfluential": false,
          "contexts": [
            "Several methods can be used to compute the energy map including Gray-level Distance Transform (GDT) [20], gradient map (GM) [7], or a combination of background energy and text energy map (LCG) in [3]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Grey-Weighted Skeleton",
            "abstract": "",
            "year": 1970,
            "venue": "Information and Control",
            "authors": [
              {
                "authorId": "143760024",
                "name": "G. Levi"
              },
              {
                "authorId": "1690890",
                "name": "U. Montanari"
              }
            ]
          }
        },
        {
          "citedcorpusid": 52953483,
          "isinfluential": false,
          "contexts": [
            "Although, some recent recognition methods can work at paragraph level [1], [2], their applications are still very limited and dependent on the layout of documents."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Start, Follow, Read: End-to-End Full-Page Handwriting Recognition",
            "abstract": "",
            "year": 2018,
            "venue": "European Conference on Computer Vision",
            "authors": [
              {
                "authorId": "26360698",
                "name": "Curtis Wigington"
              },
              {
                "authorId": "67319819",
                "name": "Chris Tensmeyer"
              },
              {
                "authorId": "145566717",
                "name": "Brian L. Davis"
              },
              {
                "authorId": "144055367",
                "name": "W. Barrett"
              },
              {
                "authorId": "31844147",
                "name": "Brian L. Price"
              },
              {
                "authorId": "2116876915",
                "name": "Scott Cohen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56597514,
          "isinfluential": false,
          "contexts": [
            "Recently, deep learning-based methods for text line segmentation have been emerged [16], [17], [18], [19]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation for Challenging Handwritten Document Images using Fully Convolutional Network",
            "abstract": "This paper presents a method for text line segmentation of challenging historical manuscript images. These manuscript images contain narrow interline spaces with touching components, interpenetrating vowel signs and inconsistent font types and sizes. In addition, they contain curved, multi-skewed and multi-directed side note lines within a complex page layout. Therefore, bounding polygon labeling would be very difficult and time consuming. Instead we rely on line masks that connect the components on the same text line. Then these line masks are predicted using a Fully Convolutional Network (FCN). In the literature, FCN has been successfully used for text line segmentation of regular handwritten document images. The present paper shows that FCN is useful with challenging manuscript images as well. Using a new evaluation metric that is sensitive to over segmentation as well as under segmentation, testing results on a publicly available challenging handwritten dataset are comparable with the results of a previous work on the same dataset.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "39240022",
                "name": "M. Kassis"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 195750543,
          "isinfluential": true,
          "contexts": [
            "Figure 3 visualizes the energy map with LCG method and candidate lines position.",
            "In this paper, we employ the method in [3] as the baseline method and adapt it for Cham documents.",
            "Several methods can be used to compute the energy map including Gray-level Distance Transform (GDT) [20], gradient map (GM) [7], or a combination of background energy and text energy map (LCG) in [3].",
            "Figure 4 illustrates some results obtained by the method in [3].",
            "3: Heat maps of energy map computed with LCG [3].",
            "Moreover, in [3], the authors have shown that a good binarization of documents can lead to good segmentation results without requiring the training of complex deep learning models.",
            "The proposed method is based on seam carving method which used the energy map proposed in [3].",
            "Secondly, in our method, seams are generated at every pixel in the constrained regions while in the LCG method, one seam is created at every 100 pixels.",
            "Another approach belonging to top-down category is seam carvingbased [10], [7], [11], [3].",
            "In [3] the Labeling, Cutting, Grouping (LCG) method is proposed.",
            "The proposed approach is closed to the work of LCG [3] but it is different in two points.",
            "Why do we need an additional cost function ? We run a simple experiment with the seam carving method [3] on our Cham documents.",
            "4: Separation lines (yellow lines) with the simple seam carving method when using only energy map [3]",
            "In the second experiment, we compared the results of the proposed method with three baseline approaches that are seam-carvingbased [7] and A* path planning [12] and LCG [3]."
          ],
          "intents": [
            "--",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['background']",
            "['methodology']",
            "--",
            "['background']",
            "--",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Labeling, Cutting, Grouping: An Efficient Text Line Segmentation Method for Medieval Manuscripts",
            "abstract": "This paper introduces a new way for text-line extraction by integrating deep-learning based pre-classification and state-of-the-art segmentation methods. Text-line extraction in complex handwritten documents poses a significant challenge, even to the most modern computer vision algorithms. Historical manuscripts are a particularly hard class of documents as they present several forms of noise, such as degradation, bleed-through, interlinear glosses, and elaborated scripts. In this work, we propose a novel method which uses semantic segmentation at pixel level as intermediate task, followed by a text-line extraction step. We measured the performance of our method on a recent dataset of challenging medieval manuscripts and surpassed state-of-the-art results by reducing the error by 80.7%. Furthermore, we demonstrate the effectiveness of our approach on various other datasets written in different scripts. Hence, our contribution is two-fold. First, we demonstrate that semantic pixel segmentation can be used as strong denoising pre-processing step before performing text line extraction. Second, we introduce a novel, simple and robust algorithm that leverages the high-quality semantic segmentation to achieve a text-line extraction performance of 99.42% line IU on a challenging dataset.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "38890619",
                "name": "Michele Alberti"
              },
              {
                "authorId": "147382507",
                "name": "Lars Vögtlin"
              },
              {
                "authorId": "8811132",
                "name": "Vinaychandran Pondenkandath"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 221130277,
          "isinfluential": false,
          "contexts": [
            "The comparison with deep learning approach [23], [17], shows that our method obtains competitive results for Line IU score and the highest result for the Pixel IU score."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line extraction using fully convolutional network and energy minimization",
            "abstract": "Text lines are important parts of handwritten document images and easier to analyze by further applications. Despite recent progress in text line detection, text line extraction from a handwritten document remains an unsolved task. This paper proposes to use a fully convolutional network for text line detection and energy minimization for text line extraction. Detected text lines are represented by blob lines that strike through the text lines. These blob lines assist an energy function for text line extraction. The detection stage can locate arbitrarily oriented text lines. Furthermore, the extraction stage is capable of finding out the pixels of text lines with various heights and interline proximity independent of their orientations. Besides, it can finely split the touching and overlapping text lines without an orientation assumption. We evaluate the proposed method on VML-AHTE, VML-MOC, and Diva-HisDB datasets. The VML-AHTE dataset contains overlapping, touching and close text lines with rich diacritics. The VML-MOC dataset is very challenging by its multiply oriented and skewed text lines. The Diva-HisDB dataset exhibits distinct text line heights and touching text lines. The results demonstrate the effectiveness of the method despite various types of challenges, yet using the same parameters in all the experiments.",
            "year": 2021,
            "venue": "ICPR Workshops",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "1414748211",
                "name": "Reem Alaasam"
              },
              {
                "authorId": "1573588308",
                "name": "Boraq Madi"
              },
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        }
      ]
    },
    "268208245": {
      "citing_paper_info": {
        "title": "Experimental Application of Semantic Segmentation Models Fine-Tuned with Synthesized Document Images to Text Line Segmentation in a Handwritten Japanese Historical Document",
        "abstract": ": Because it is difficult even for Japanese to read handwritten Japanese historical documents, computer-assisted transcription of such documents is helpful. We plan to apply semantic segmentation to text line segmentation for handwritten Japanese historical documents. We use both synthesized document images resembling a Japanese historical document and annotations for them because it is time-consuming to manually annotate a large set of document images for training data. The purpose of this research is to evaluate the effect of fine-tuning semantic segmentation models with synthesized Japanese historical document images in text line segmentation. The experimental results show that the segmentation results produced by our method are generally satisfactory for test data consisting of synthesized document images and are also satisfactory for Japanese historical document images with straightforward formats.",
        "year": 2024,
        "venue": "International Conference on Pattern Recognition Applications and Methods",
        "authors": [
          {
            "authorId": "2289663855",
            "name": "Sayaka Mori"
          },
          {
            "authorId": "2289794779",
            "name": "Tetsuya Suzuki"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 3,
        "unique_cited_count": 3,
        "influential_count": 0,
        "detailed_records_count": 3
      },
      "cited_papers": [
        "245291064",
        "56597514",
        "204800700"
      ],
      "citation_details": [
        {
          "citedcorpusid": 56597514,
          "isinfluential": false,
          "contexts": [
            "Convolutional Network and post-processing Barakat et al. proposed a method for extracting text lines from handwritten Arabic documents where some characters touch each other and the orientations of the text lines are not regular (Barakat et al., 2018)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation for Challenging Handwritten Document Images using Fully Convolutional Network",
            "abstract": "This paper presents a method for text line segmentation of challenging historical manuscript images. These manuscript images contain narrow interline spaces with touching components, interpenetrating vowel signs and inconsistent font types and sizes. In addition, they contain curved, multi-skewed and multi-directed side note lines within a complex page layout. Therefore, bounding polygon labeling would be very difficult and time consuming. Instead we rely on line masks that connect the components on the same text line. Then these line masks are predicted using a Fully Convolutional Network (FCN). In the literature, FCN has been successfully used for text line segmentation of regular handwritten document images. The present paper shows that FCN is useful with challenging manuscript images as well. Using a new evaluation metric that is sensitive to over segmentation as well as under segmentation, testing results on a publicly available challenging handwritten dataset are comparable with the results of a previous work on the same dataset.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "39240022",
                "name": "M. Kassis"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 204800700,
          "isinfluential": false,
          "contexts": [
            "KuroNet (CLANUWAT et al., 2019) is a deep neural network that detects the locations of characters and recognizes the characters in a given image of a historical Japanese document."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "KuroNet: Pre-Modern Japanese Kuzushiji Character Recognition with Deep Learning",
            "abstract": "Kuzushiji, a cursive writing style, had been used in Japan for over a thousand years starting from the 8th century. Over 3 millions books on a diverse array of topics, such as literature, science, mathematics and even cooking are preserved. However, following a change to the Japanese writing system in 1900, Kuzushiji has not been included in regular school curricula. Therefore, most Japanese natives nowadays cannot read books written or printed just 150 years ago. Museums and libraries have invested a great deal of effort into creating digital copies of these historical documents as a safeguard against fires, earthquakes and tsunamis. The result has been datasets with hundreds of millions of photographs of historical documents which can only be read by a small number of specially trained experts. Thus there has been a great deal of interest in using Machine Learning to automatically recognize these historical texts and transcribe them into modern Japanese characters. Nevertheless, several challenges in Kuzushiji recognition have made the performance of existing systems extremely poor. To tackle these challenges, we propose KuroNet, a new end-to-end model which jointly recognizes an entire page of text by using a residual U-Net architecture which predicts the location and identity of all characters given a page of text (without any pre-processing). This allows the model to handle long range context, large vocabularies, and non-standardized character layouts. We demonstrate that our system is able to successfully recognize a large fraction of pre-modern Japanese documents, but also explore areas where our system is limited and suggest directions for future work.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "52214414",
                "name": "Tarin Clanuwat"
              },
              {
                "authorId": "49071560",
                "name": "Alex Lamb"
              },
              {
                "authorId": "1730368",
                "name": "A. Kitamoto"
              }
            ]
          }
        },
        {
          "citedcorpusid": 245291064,
          "isinfluential": false,
          "contexts": [
            "We used the following semantic segmentation models and the encoder provided by the Web site ”Segmenta-tion models pytorch” (Iakubovskii, 2019)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Segmentation Models",
            "abstract": "",
            "year": 2016,
            "venue": "Brand Management Strategies",
            "authors": []
          }
        }
      ]
    },
    "236298361": {
      "citing_paper_info": {
        "title": "A two-step framework for text line segmentation in historical Arabic and Latin document images",
        "abstract": "",
        "year": 2021,
        "venue": "International Journal on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "51133427",
            "name": "Olfa Mechi"
          },
          {
            "authorId": "2131158",
            "name": "Maroua Mehri"
          },
          {
            "authorId": "1680326",
            "name": "R. Ingold"
          },
          {
            "authorId": "134509992",
            "name": "Najoua Essoukri Ben Amara"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 18,
        "unique_cited_count": 18,
        "influential_count": 4,
        "detailed_records_count": 18
      },
      "cited_papers": [
        "15398231",
        "13749026",
        "56595852",
        "9811883",
        "5252785",
        "1889158",
        "15401169",
        "27494128",
        "232234980",
        "43477852",
        "211026904",
        "4761833",
        "56597514",
        "19363314",
        "54462156",
        "123885967",
        "1610874",
        "1629541"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1610874,
          "isinfluential": false,
          "contexts": [
            "Some systems have been proposed to deal with document images which require a preliminary text line segmentation [6–10], while others have been focused on word recognition based on pre-segmented text lines [11,12].",
            "More particularly, the use of deep architectures for text line segmentation has been shown to be efﬁcient with pages having complex layouts (e.g., variations in spacing between characters, words, lines, paragraphs and margins) [10].",
            "…of a polygon enclosing the connected pixels representing textual content; – Baseline corresponds to a virtual line enclosing the most characters whereas descender remains below; – X-height corresponds to the area covering the text core without considering its ascenders and descenders [10,23, 24]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Dense prediction for text line segmentation in handwritten document images",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Information Photonics",
            "authors": [
              {
                "authorId": "12581289",
                "name": "Q. Vo"
              },
              {
                "authorId": "144096223",
                "name": "Gueesang Lee"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1629541,
          "isinfluential": true,
          "contexts": [
            "Hence, FCN could have a reduced numerical complexity (i.e., a reduced number of trainable parameters) when the dense layers are excluded in the case of the classiﬁcation task [16,23].",
            "Thedeepmodels have shown outstanding performance in semantic segmentation [16].",
            "…in the literature that the FCN architectures are efﬁcient for semantic segmentation of document images and particularly for text line segmentation, we focus our work on investigating and comparing different FCN variants in order to propose an efﬁcient framework for text line segmentation [16].",
            "Besides, their effectiveness is proved for image classiﬁcation [17], segmentation [16] and detection [18] tasks, etc."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Fully convolutional networks for semantic segmentation",
            "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.",
            "year": 2014,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "1782282",
                "name": "Evan Shelhamer"
              },
              {
                "authorId": "2117314646",
                "name": "Jonathan Long"
              },
              {
                "authorId": "1753210",
                "name": "Trevor Darrell"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1889158,
          "isinfluential": false,
          "contexts": [
            "…literature, many researchers working on text line segmentation focused on proposing end-to-end deep-based methods without introducing a post-processing step [25], while others proposed text line segmentation methods based on combining deep architectures and other image processing techniques [21]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Paragraph text segmentation into lines with Recurrent Neural Networks",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "144899680",
                "name": "Christian Wolf"
              },
              {
                "authorId": "2373952",
                "name": "J. Louradour"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4761833,
          "isinfluential": true,
          "contexts": [
            "Our experiments have been conducted using a large number of ancient document images collected from the ANT and different benchmark datasets provided in the context of recent open competitions at ICDAR and ICFHR conferences [24,26,27].",
            "Furthermore, three of the ﬁve participating methods in the ICDAR2017 competition on baseline detection ( cBAD2017 ) 2 are based on deep architectures [24].",
            "…of a polygon enclosing the connected pixels representing textual content; – Baseline corresponds to a virtual line enclosing the most characters whereas descender remains below; – X-height corresponds to the area covering the text core without considering its ascenders and descenders [10,23, 24].",
            "However, the cBAD (Track B) dataset is composed of more challenging document images (degraded document images that have rotated text lines, multi-column text, marginal notes, tables, etc.) [24]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "cBAD: ICDAR2017 Competition on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              },
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5252785,
          "isinfluential": false,
          "contexts": [
            "Kundu et al. [8] used the generative adversarial networks (GAN) for text line extraction."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Binarization-Free Text Line Segmentation for Historical Documents Based on Interest Point Clustering",
            "abstract": "",
            "year": 2012,
            "venue": "2012 10th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1706090",
                "name": "Robert Sablatnig"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9811883,
          "isinfluential": false,
          "contexts": [
            "Hence, we have deﬁned the ground truths at X-heightlevelaccordingtothe PAGE formatusing Aletheia , a document image annotation tool [48]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The PAGE (Page Analysis and Ground-Truth Elements) Format Framework",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "1980669",
                "name": "Stefan Pletschacher"
              },
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13749026,
          "isinfluential": false,
          "contexts": [
            "[35] had not shown the generalization of dhSegment since the same experimental corpus was used for both the prediction and training phases.",
            "[35] for addressing different HDIA tasks such as layout analysis, baseline extraction and page extraction."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "dhSegment: A Generic Deep-Learning Approach for Document Segmentation",
            "abstract": "In recent years there have been multiple successful attempts tackling document processing problems separately by designing task specific hand-tuned strategies. We argue that the diversity of historical document processing tasks prohibits to solve them one at a time and shows a need for designing generic approaches in order to handle the variability of historical series. In this paper, we address multiple tasks simultaneously such as page extraction, baseline extraction, layout analysis or multiple typologies of illustrations and photograph extraction. We propose an open-source implementation of a CNN-based pixel-wise predictor coupled with task dependent post-processing blocks. We show that a single CNN-architecture can be used across tasks with competitive results. Moreover most of the task-specific post-precessing steps can be decomposed in a small number of simple and standard reusable operations, adding to the flexibility of our approach.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2066810458",
                "name": "S. Oliveira"
              },
              {
                "authorId": "2060245962",
                "name": "Benoit Seguin"
              },
              {
                "authorId": "143791091",
                "name": "F. Kaplan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15398231,
          "isinfluential": false,
          "contexts": [
            "Recently, fueled by the recent increase in computer hardware power, a new field of machine learning research called representation learning also known as deep learning has gained great attention of many researchers working on many sub-fields and tasks related to the issues surrounding computer vision and pattern recognition [14,15]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Age and gender classification using convolutional neural networks",
            "abstract": "",
            "year": 2015,
            "venue": "2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
            "authors": [
              {
                "authorId": "36813724",
                "name": "Gil Levi"
              },
              {
                "authorId": "1756099",
                "name": "Tal Hassner"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15401169,
          "isinfluential": false,
          "contexts": [
            "Hence, ﬁve performance evaluation metrics (“Match”, “Merge”, “Miss”, “Split”, and “False alarm”), which were introduced by Gal-ibert et al. [49], have been computed to assess quantitatively the performance of the proposed post-processing method."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The zonemap metric for page segmentation and area classification in scanned documents",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Information Photonics",
            "authors": [
              {
                "authorId": "1701385",
                "name": "Olivier Galibert"
              },
              {
                "authorId": "35798452",
                "name": "Juliette Kahn"
              },
              {
                "authorId": "3135839",
                "name": "I. Oparin"
              }
            ]
          }
        },
        {
          "citedcorpusid": 19363314,
          "isinfluential": false,
          "contexts": [
            ", layout, content anddigitization resolution) on the other hand [13]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "ICDAR 2015 competition on text line detection in historical documents",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40474413",
                "name": "Michael Murdock"
              },
              {
                "authorId": "27437299",
                "name": "S. Reid"
              },
              {
                "authorId": "2067534881",
                "name": "Blaine Hamilton"
              },
              {
                "authorId": "48163297",
                "name": "J. Reese"
              }
            ]
          }
        },
        {
          "citedcorpusid": 27494128,
          "isinfluential": true,
          "contexts": [
            "For instance, Renton et al. [23] proposed for hand-written text line segmentation in document images a deep methods based on fully convolutional networks (FCN) that clearly outperformed steerable ﬁlters.",
            "…of a polygon enclosing the connected pixels representing textual content; – Baseline corresponds to a virtual line enclosing the most characters whereas descender remains below; – X-height corresponds to the area covering the text core without considering its ascenders and descenders [10,23, 24].",
            "Figures 9 and 10 illustrate the resulting images obtained when using the classical U-Net [21], dilated FCN [23], RU-Net [22], and adaptive U-Net [37] architectures on a test image of the RASM and DIVA-HisDB datasets, respectively.",
            "Renton et al. [23] stated that the dilated FCN had numerous advantages.",
            "Afterreferringtothemostrecent and widely used FCN architectures for text line segmentation in the literature, we propose a comparative study of the four following FCN variants: classical U-Net [21], dilated FCN [23], RU-Net [22] and adaptive U-Net [37].",
            "Hence, FCN could have a reduced numerical complexity (i.e., a reduced number of trainable parameters) when the dense layers are excluded in the case of the classiﬁcation task [16,23].",
            "Then, it deals with overlapping line issues (particularly in the case of handwritten documents written in Arabic) [23].",
            "Renton et al. [23], Neche et al. [22], and Mechi et al. [37] claimed that it is more efﬁcient to propose a two-step solution to extract text lines in historical documents.",
            "Renton et al. [23], Neche et al. [22] and Mechi et al. [37] used the X-height as a text line representation for evaluating their FCN-based text line segmentation method.",
            "The dilated FCN is described in more detail in [23]."
          ],
          "intents": [
            "--",
            "['background']",
            "['methodology']",
            "['background']",
            "['methodology']",
            "['background']",
            "['background']",
            "['background']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Handwritten Text Line Segmentation Using Fully Convolutional Network",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "47689382",
                "name": "G. Renton"
              },
              {
                "authorId": "1712446",
                "name": "Clément Chatelain"
              },
              {
                "authorId": "143680806",
                "name": "Sébastien Adam"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 43477852,
          "isinfluential": false,
          "contexts": [
            "Then, the RLSA is applied to fill the space between the extractedCCby linking the neighboring black areas [46]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Extraction of Homogeneous Regions in Historical Document Images",
            "abstract": "To reach the objective of ensuring the indexing and retrieval of digitized resources and offering a structured access to large sets of cultural heritage documents, a raising interest to historical document image segmentation has been generated. In fact, there is a real need for automatic algorithms ensuring the identification of homogeneous regions or similar groups of pixels sharing some visual characteristics from historical documents (i.e. distinguishing graphic types, segmenting graphical regions from textual ones, and discriminating text in a variety of situations of different fonts and scales). Indeed, determining graphic regions can help to segment and analyze the graphical part in historical heritage, while finding text zones can be used as a pre-processing stage for character recognition, text line extraction, handwriting recognition, etc. Thus, we propose in this article an automatic segmentation method for historical document images based on extraction of homogeneous or similar content regions. The proposed algorithm is based on using simple linear iterative clustering (SLIC) su-perpixels, Gabor filters, multi-scale analysis, majority voting technique, connected component analysis, color layer separation, and an adaptive run-length smoothing algorithm (ARLSA). It has been evaluated on 1000 pages of historical documents and achieved interesting results.",
            "year": 2015,
            "venue": "International Conference on Computer Vision Theory and Applications",
            "authors": [
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1826457",
                "name": "P. Héroux"
              },
              {
                "authorId": "1405425047",
                "name": "Nabil Sliti"
              },
              {
                "authorId": "1399368454",
                "name": "Petra Gomez-Krämer"
              },
              {
                "authorId": "2536574",
                "name": "N. Amara"
              },
              {
                "authorId": "1682986",
                "name": "R. Mullot"
              }
            ]
          }
        },
        {
          "citedcorpusid": 54462156,
          "isinfluential": false,
          "contexts": [
            "Some systems have been proposed to deal with document images which require a preliminary text line segmentation [6–10], while others have been focused on word recognition based on pre-segmented text lines [11,12]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Towards Spotting and Recognition of Handwritten Words in Indic Scripts",
            "abstract": "Handwriting recognition (HWR) in Indic scripts is a challenging problem due to the inherent subtleties in the scripts, cursive nature of the handwriting and similar shape of the characters. Lack of publicly available handwriting datasets in Indic scripts has affected the development of handwritten word recognizers, and made direct comparisons across different methods an impossible task in the field. In this paper, we propose a framework for annotating large scale of handwritten word images with ease and speed. We also release a new handwritten word dataset for Telugu, which is collected and annotated using the proposed framework. We also benchmark major Indic scripts such as Devanagari, Bangla and Telugu for the tasks of word spotting and handwriting recognition using state of the art deep neural architectures. Finally, we evaluate the proposed pipeline on RoyDB, a public dataset, and achieve significant reduction in error rates.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "17311720",
                "name": "Kartik Dutta"
              },
              {
                "authorId": "144195890",
                "name": "Praveen Krishnan"
              },
              {
                "authorId": "34317896",
                "name": "Minesh Mathew"
              },
              {
                "authorId": "1694502",
                "name": "C. V. Jawahar"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56595852,
          "isinfluential": false,
          "contexts": [
            "Some systems have been proposed to deal with document images which require a preliminary text line segmentation [6–10], while others have been focused on word recognition based on presegmented text lines [11,12]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "DNN-HMM Based Large Vocabulary Online Handwritten Assamese Word Recognition System",
            "abstract": "In this work, we consider recognizing online handwritten Assamese word (an Indic script) using the hybrid deep neural network - hidden Markov model (DNN-HMM) framework. The recognition task is generally challenging since Assamese handwriting is mixed with the discrete and cursive writing style, and further complicated due to the placing of vowel/consonant modifier above and/or below already written character in delayed order. Also, as it contains large character set, there is lack of common definition of the basic unit (BU) for automatic recognition. As a step in this direction, first, we select 173 BU capable of characterizing 20K most frequent Assamese words. The HMMs are created for these selected BUs. Next, we create a lexicon for word recognition where each word is represented by all probable \"sequence of BUs\" that constitute the word. The system is developed using the state-of-the-art Kaldi Automatic speech recognition toolkit, under large vocabulary word recognition framework and is evaluated on the lexicon of sizes 1K, 5k, 10K and 20K words. To the best of our knowledge, this paper is the first of its kind that considers online handwritten Assamese word instead of isolated characters. The experiments are conducted on locally collected Assamese word database, and a promising recognition performance is obtained, noting that the DNN-HMM framework outperforms the GMM-HMM system significantly",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "48172708",
                "name": "S. Mandal"
              },
              {
                "authorId": "40528369",
                "name": "Himakshi Choudhury"
              },
              {
                "authorId": "2269513833",
                "name": "S. Prasanna"
              },
              {
                "authorId": "2000307852",
                "name": "S. Sundaram"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56597514,
          "isinfluential": false,
          "contexts": [
            "Barakat et al. [36] presented a FCN model for Arabic handwritten text line detection."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation for Challenging Handwritten Document Images using Fully Convolutional Network",
            "abstract": "This paper presents a method for text line segmentation of challenging historical manuscript images. These manuscript images contain narrow interline spaces with touching components, interpenetrating vowel signs and inconsistent font types and sizes. In addition, they contain curved, multi-skewed and multi-directed side note lines within a complex page layout. Therefore, bounding polygon labeling would be very difficult and time consuming. Instead we rely on line masks that connect the components on the same text line. Then these line masks are predicted using a Fully Convolutional Network (FCN). In the literature, FCN has been successfully used for text line segmentation of regular handwritten document images. The present paper shows that FCN is useful with challenging manuscript images as well. Using a new evaluation metric that is sensitive to over segmentation as well as under segmentation, testing results on a publicly available challenging handwritten dataset are comparable with the results of a previous work on the same dataset.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "39240022",
                "name": "M. Kassis"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 123885967,
          "isinfluential": false,
          "contexts": [
            "For this purpose, a binarization step is firstly carried by applying the Otsu’s algorithm on the analyzed document [44]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ATlreshold Selection Method fromGray-Level Histograms",
            "abstract": "",
            "year": 1979,
            "venue": "",
            "authors": [
              {
                "authorId": "1809629",
                "name": "N. Otsu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211026904,
          "isinfluential": true,
          "contexts": [
            "Figures 9 and 10 illustrate the resulting images obtained when using the classical U-Net [21], dilated FCN [23], RU-Net [22], and adaptive U-Net [37] architectures on a test image of the RASM and DIVA-HisDB datasets, respectively.",
            "The adaptive U-Net is described in more detail in [37].",
            "Afterreferringtothemostrecent and widely used FCN architectures for text line segmentation in the literature, we propose a comparative study of the four following FCN variants: classical U-Net [21], dilated FCN [23], RU-Net [22] and adaptive U-Net [37].",
            "The adaptive U-Net architecture is a variant of the classical U-Net, which was introduced by Mechi et al. [37] for text line segmentation in historical Arabic and Latin document images.",
            "Mechi et al. [37]’ method achieved competitive results for images having simple and complex layouts.",
            "Mechi et al. [37] proposed an adaptive U-Net architecture for text line segmentation in Arabic and Latin handwritten documents.",
            "Renton et al. [23], Neche et al. [22], and Mechi et al. [37] claimed that it is more efﬁcient to propose a two-step solution to extract text lines in historical documents.",
            "Renton et al. [23], Neche et al. [22] and Mechi et al. [37] used the X-height as a text line representation for evaluating their FCN-based text line segmentation method."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['methodology']",
            "['background']",
            "['background']",
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation in Historical Document Images Using an Adaptive U-Net Architecture",
            "abstract": "On most document image transcription, indexing and retrieval systems, text line segmentation remains one of the most important preliminary task. Hence, the research community working in document image analysis is particularly interested in providing reliable text line segmentation methods. Recently, an increasing interest in using deep learning-based methods has been noted for solving various sub-fields and tasks related to the issues surrounding document image analysis. Thanks to the computer hardware and software evolution, several methods based on using deep architectures continue to outperform the pattern recognition issues and particularly those related to historical document image analysis. Thus, in this paper we present a novel deep learning-based method for text line segmentation of historical documents. The proposed method is based on using an adaptive U-Net architecture. Qualitative and numerical experiments are given using a large number of historical document images collected from the Tunisian national archives and different recent benchmarking datasets provided in the context of ICDAR and ICFHR competitions. Moreover, the results achieved are compared with those obtained using the state-of-the-art methods.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "51133427",
                "name": "Olfa Mechi"
              },
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "2536574",
                "name": "N. Amara"
              }
            ]
          }
        },
        {
          "citedcorpusid": 232234980,
          "isinfluential": false,
          "contexts": [
            "Furthermore, providing robust and accurate text recognition systems has been pointed out by the ANT as a primary necessity [1,2]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Text Line Extraction Method for Archival Document Transcription",
            "abstract": "In order to reinforce the enrichment and exploitation of archival collections, a growing need for computer-aided tools able to assist researchers, historians and archivists in historical document image transcription has been recently highlighted. However, to ensure an efficient text transcription from archival handwritten and printed document images, a robust text line segmentation task is required. Thus, in this paper we propose a method able to extract whole text lines from archival document images. The proposed method is firstly based on our previous work reported at ICDAR 2019, which focused on extracting only the main area covering the text core. A post-processing step is introduced in this paper to extract whole text lines (including the ascender and descender components). The post-processing step is based on topological structural analysis of binary images. To illustrate the effectiveness of the proposed method, we have conducted experiments on archival document images collected from the Tunisian national archives. Qualitative and quantitative results are reported and discussed.",
            "year": 2020,
            "venue": "International Multi-Conference on Systems, Signals & Devices",
            "authors": [
              {
                "authorId": "51133427",
                "name": "Olfa Mechi"
              },
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "2536574",
                "name": "N. Amara"
              }
            ]
          }
        }
      ]
    },
    "270702879": {
      "citing_paper_info": {
        "title": "SegHist: A General Segmentation-based Framework for Chinese Historical Document Text Line Detection",
        "abstract": "Text line detection is a key task in historical document analysis facing many challenges of arbitrary-shaped text lines, dense texts, and text lines with high aspect ratios, etc. In this paper, we propose a general framework for historical document text detection (SegHist), enabling existing segmentation-based text detection methods to effectively address the challenges, especially text lines with high aspect ratios. Integrating the SegHist framework with the commonly used method DB++, we develop DB-SegHist. This approach achieves SOTA on the CHDAC, MTHv2, and competitive results on HDRC datasets, with a significant improvement of 1.19% on the most challenging CHDAC dataset which features more text lines with high aspect ratios. Moreover, our method attains SOTA on rotated MTHv2 and rotated HDRC, demonstrating its rotational robustness. The code is available at https://github.com/LumionHXJ/SegHist.",
        "year": 2024,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "2308364937",
            "name": "Xingjian Hu"
          },
          {
            "authorId": "1471376530",
            "name": "Baole Wei"
          },
          {
            "authorId": "2308033589",
            "name": "Liangcai Gao"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 14,
        "unique_cited_count": 13,
        "influential_count": 0,
        "detailed_records_count": 14
      },
      "cited_papers": [
        "234343711",
        "2843566",
        "49570059",
        "46966180",
        "10328909",
        "225039882",
        "261102355",
        "251431450",
        "214612334",
        "8890220",
        "2141740",
        "211258587",
        "72940925"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2141740,
          "isinfluential": false,
          "contexts": [
            "Textboxes [17] applies the SSD [21] framework to text detection by designing anchor boxes with various aspect ratios and incorporating asymmetric convolutional kernels."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "SSD: Single Shot MultiBox Detector",
            "abstract": "We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets confirm that SSD has comparable accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. Compared to other single stage methods, SSD has much better accuracy, even with a smaller input image size. For $300\\times 300$ input, SSD achieves 72.1% mAP on VOC2007 test at 58 FPS on a Nvidia Titan X and for $500\\times 500$ input, SSD achieves 75.1% mAP, outperforming a comparable state of the art Faster R-CNN model. Code is available at this https URL .",
            "year": 2015,
            "venue": "European Conference on Computer Vision",
            "authors": [
              {
                "authorId": "46641573",
                "name": "W. Liu"
              },
              {
                "authorId": "1838674",
                "name": "Dragomir Anguelov"
              },
              {
                "authorId": "1761978",
                "name": "D. Erhan"
              },
              {
                "authorId": "2574060",
                "name": "Christian Szegedy"
              },
              {
                "authorId": "144828948",
                "name": "Scott E. Reed"
              },
              {
                "authorId": "2084646762",
                "name": "Cheng-Yang Fu"
              },
              {
                "authorId": "39668247",
                "name": "A. Berg"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2843566,
          "isinfluential": false,
          "contexts": [
            "During training, we used OHEM [37] to balance positive and negative samples."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Training Region-Based Object Detectors with Online Hard Example Mining",
            "abstract": "The field of object detection has made significant advances riding on the wave of region-based ConvNets, but their training procedure still includes many heuristics and hyperparameters that are costly to tune. We present a simple yet surprisingly effective online hard example mining (OHEM) algorithm for training region-based ConvNet detectors. Our motivation is the same as it has always been - detection datasets contain an overwhelming number of easy examples and a small number of hard examples. Automatic selection of these hard examples can make training more effective and efficient. OHEM is a simple and intuitive algorithm that eliminates several heuristics and hyperparameters in common use. But more importantly, it yields consistent and significant boosts in detection performance on benchmarks like PASCAL VOC 2007 and 2012. Its effectiveness increases as datasets become larger and more difficult, as demonstrated by the results on the MS COCO dataset. Moreover, combined with complementary advances in the field, OHEM leads to state-of-the-art results of 78.9% and 76.3% mAP on PASCAL VOC 2007 and 2012 respectively.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "1781242",
                "name": "Abhinav Shrivastava"
              },
              {
                "authorId": "1726095131",
                "name": "A. Gupta"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8890220,
          "isinfluential": false,
          "contexts": [
            "Before the era of deep learning, MSER [32] and SWT [9] were mainstream text detection methods that analyzed images by finding correlations in pixel values."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Detecting text in natural scenes with stroke width transform",
            "abstract": "",
            "year": 2010,
            "venue": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "3126798",
                "name": "B. Epshtein"
              },
              {
                "authorId": "20592981",
                "name": "E. Ofek"
              },
              {
                "authorId": "1743988",
                "name": "Y. Wexler"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10328909,
          "isinfluential": false,
          "contexts": [
            "Inthetask of text line detection in Chinese historical documents, Ma et al. [31] enhanced the Faster R-CNN framework [35] by adding a character prediction branch, achieving commendable results on the MTHv2 dataset."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
            "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available",
            "year": 2015,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              },
              {
                "authorId": "2032184078",
                "name": "Jian Sun"
              }
            ]
          }
        },
        {
          "citedcorpusid": 46966180,
          "isinfluential": false,
          "contexts": [
            "…inference to recover text regions; otherwise, maintain the original post-processing method (such as progressive scale expansion method of PSENet [42] which uses multiple text kernel maps with different shrinkage distances) to fully utilize the additional prediction targets of M to achieve…",
            "On the CHDAC dataset, we integrated the SegHist framework to PSENet [42] and PAN [43], resulting in PSE-SegHist and PAN-SegHist, respectively.",
            "PSENet [42] utilizes multiple shrinkage levels in prediction and expands text regions during post-processing."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Shape Robust Text Detection With Progressive Scale Expansion Network",
            "abstract": "Scene text detection has witnessed rapid progress especially with the recent development of convolutional neural networks. However, there still exists two challenges which prevent the algorithm into industry applications. On the one hand, most of the state-of-art algorithms require quadrangle bounding box which is in-accurate to locate the texts with arbitrary shape. On the other hand, two text instances which are close to each other may lead to a false detection which covers both instances. Traditionally, the segmentation-based approach can relieve the first problem but usually fail to solve the second challenge. To address these two challenges, in this paper, we propose a novel Progressive Scale Expansion Network (PSENet), which can precisely detect text instances with arbitrary shapes. More specifically, PSENet generates the different scale of kernels for each text instance, and gradually expands the minimal scale kernel to the text instance with the complete shape. Due to the fact that there are large geometrical margins among the minimal scale kernels, our method is effective to split the close text instances, making it easier to use segmentation-based methods to detect arbitrary-shaped text instances. Extensive experiments on CTW1500, Total-Text, ICDAR 2015 and ICDAR 2017 MLT validate the effectiveness of PSENet. Notably, on CTW1500, a dataset full of long curve texts, PSENet achieves a F-measure of 74.3% at 27 FPS, and our best F-measure (82.2%) outperforms state-of-art algorithms by 6.6%. The code will be released in the future.",
            "year": 2018,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2144439048",
                "name": "Xiang Li"
              },
              {
                "authorId": "71074736",
                "name": "Wenhai Wang"
              },
              {
                "authorId": "2061634523",
                "name": "Wenbo Hou"
              },
              {
                "authorId": "7247659",
                "name": "Ruo-Ze Liu"
              },
              {
                "authorId": "144720255",
                "name": "Tong Lu"
              },
              {
                "authorId": "2146236917",
                "name": "Jian Yang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 49570059,
          "isinfluential": false,
          "contexts": [
            "TextSnake [28] describes text by using a series of discs along the text center line."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "TextSnake: A Flexible Representation for Detecting Text of Arbitrary Shapes",
            "abstract": "Driven by deep neural networks and large scale datasets, scene text detection methods have progressed substantially over the past years, continuously refreshing the performance records on various standard benchmarks. However, limited by the representations (axis-aligned rectangles, rotated rectangles or quadrangles) adopted to describe text, existing methods may fall short when dealing with much more free-form text instances, such as curved text, which are actually very common in real-world scenarios. To tackle this problem, we propose a more flexible representation for scene text, termed as TextSnake, which is able to effectively represent text instances in horizontal, oriented and curved forms. In TextSnake, a text instance is described as a sequence of ordered, overlapping disks centered at symmetric axes, each of which is associated with potentially variable radius and orientation. Such geometry attributes are estimated via a Fully Convolutional Network (FCN) model. In experiments, the text detector based on TextSnake achieves state-of-the-art or comparable performance on Total-Text and SCUT-CTW1500, the two newly published benchmarks with special emphasis on curved text in natural images, as well as the widely-used datasets ICDAR 2015 and MSRA-TD500. Specifically, TextSnake outperforms the baseline on Total-Text by more than 40% in F-measure.",
            "year": 2018,
            "venue": "European Conference on Computer Vision",
            "authors": [
              {
                "authorId": "51126615",
                "name": "Shangbang Long"
              },
              {
                "authorId": "51125377",
                "name": "Jiaqiang Ruan"
              },
              {
                "authorId": "19262604",
                "name": "W. Zhang"
              },
              {
                "authorId": "2116553662",
                "name": "Xin He"
              },
              {
                "authorId": null,
                "name": "Wenhao Wu"
              },
              {
                "authorId": "2146721",
                "name": "C. Yao"
              }
            ]
          }
        },
        {
          "citedcorpusid": 72940925,
          "isinfluential": false,
          "contexts": [
            "HDRC HDRC [36] is a collection of Chinese family records images.",
            "Historical documents analysis [5, 31, 36, 38, 44] is pivotal for preserving and disseminating historical documentary materials."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "ICDAR 2019 Historical Document Reading Challenge on Large Structured Chinese Family Records",
            "abstract": "In this paper, we present a large historical database of Chinese family records with the aim to develop robust systems for historical document analysis. In this direction, we propose a Historical Document Reading Challenge on Large Chinese Structured Family Records (ICDAR 2019 HDRCCHINESE). The objective of the competition is to recognize and analyze the layout, and finally detect and recognize the textlines and characters of the large historical document image dataset containing more than 100000 pages. Cascade R-CNN, CRNN, and U-Net based architectures were trained to evaluate the performances in these tasks. Error rate of 0.01 has been recorded for textline recognition (Task1) whereas a Jaccard Index of 99:54% has been recorded for layout analysis (Task2). The graph edit distance based total error ratio of 1:5% has been recorded for complete integrated textline detection and recognition (Task3).",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "80342407",
                "name": "F. Liwicki"
              },
              {
                "authorId": "3415124",
                "name": "Rajkumar Saini"
              },
              {
                "authorId": "145710896",
                "name": "Derek Dobson"
              },
              {
                "authorId": "52362408",
                "name": "Jon Morrey"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211258587,
          "isinfluential": false,
          "contexts": [
            "To address the challenge of curved text, ABCNet [22, 24] represents text regions by Bezier curves."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ABCNet: Real-Time Scene Text Spotting With Adaptive Bezier-Curve Network",
            "abstract": "Scene text detection and recognition has received increasing research attention. Existing methods can be roughly categorized into two groups: character-based and segmentation-based. These methods either are costly for character annotation or need to maintain a complex pipeline, which is often not suitable for real-time applications. Here we address the problem by proposing the Adaptive Bezier-Curve Network (\\BeCan). Our contributions are three-fold: 1) For the first time, we adaptively fit oriented or curved text by a parameterized Bezier curve. 2) We design a novel BezierAlign layer for extracting accurate convolution features of a text instance with arbitrary shapes, significantly improving the precision compared with previous methods. 3) Compared with standard bounding box detection, our Bezier curve detection introduces negligible computation overhead, resulting in superiority of our method in both efficiency and accuracy. Experiments on oriented or curved benchmark datasets, namely Total-Text and CTW1500, demonstrate that \\BeCan achieves state-of-the-art accuracy, meanwhile significantly improving the speed. In particular, on Total-Text, our real-time version is over 10 times faster than recent state-of-the-art methods with a competitive recognition accuracy. Code is available at \\url{https://git.io/AdelaiDet}.",
            "year": 2020,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2108353180",
                "name": "Yuliang Liu"
              },
              {
                "authorId": "2029503517",
                "name": "Hao Chen"
              },
              {
                "authorId": "12459603",
                "name": "Chunhua Shen"
              },
              {
                "authorId": "2118328320",
                "name": "Tong He"
              },
              {
                "authorId": "144838978",
                "name": "Lianwen Jin"
              },
              {
                "authorId": "2144691690",
                "name": "Liangwei Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 214612334,
          "isinfluential": false,
          "contexts": [
            "After each convolution operation, we apply the spatially-aware DY-ReLU [4], the parameters θ i for pixel i are obtained as follows: , where the deep feature map F in , the spatial and temporal computational costs are not significant."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Dynamic ReLU",
            "abstract": "Rectified linear units (ReLU) are commonly used in deep neural networks. So far ReLU and its generalizations (non-parametric or parametric) are static, performing identically for all input samples. In this paper, we propose dynamic ReLU (DY-ReLU), a dynamic rectifier of which parameters are generated by a hyper function over all in-put elements. The key insight is that DY-ReLU encodes the global context into the hyper function, and adapts the piecewise linear activation function accordingly. Compared to its static counterpart, DY-ReLU has negligible extra computational cost, but significantly more representation capability, especially for light-weight neural networks. By simply using DY-ReLU for MobileNetV2, the top-1 accuracy on ImageNet classification is boosted from 72.0% to 76.2% with only 5% additional FLOPs.",
            "year": 2020,
            "venue": "European Conference on Computer Vision",
            "authors": [
              {
                "authorId": "2109306087",
                "name": "Yinpeng Chen"
              },
              {
                "authorId": "3386593",
                "name": "Xiyang Dai"
              },
              {
                "authorId": "2152968847",
                "name": "Mengchen Liu"
              },
              {
                "authorId": "49025801",
                "name": "Dongdong Chen"
              },
              {
                "authorId": "145347147",
                "name": "Lu Yuan"
              },
              {
                "authorId": "2145253136",
                "name": "Zicheng Liu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 225039882,
          "isinfluential": false,
          "contexts": [
            "SeamFormer [39] uses ViT [7] to process historical palm leaf manuscripts in two stages to fit text line polygons."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
            "abstract": "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.",
            "year": 2020,
            "venue": "International Conference on Learning Representations",
            "authors": [
              {
                "authorId": "2841331",
                "name": "Alexey Dosovitskiy"
              },
              {
                "authorId": "39611591",
                "name": "Lucas Beyer"
              },
              {
                "authorId": "144629422",
                "name": "Alexander Kolesnikov"
              },
              {
                "authorId": "3319373",
                "name": "Dirk Weissenborn"
              },
              {
                "authorId": "2743563",
                "name": "Xiaohua Zhai"
              },
              {
                "authorId": "2465270",
                "name": "Thomas Unterthiner"
              },
              {
                "authorId": "2274215058",
                "name": "Mostafa Dehghani"
              },
              {
                "authorId": "46352821",
                "name": "Matthias Minderer"
              },
              {
                "authorId": "2280399",
                "name": "G. Heigold"
              },
              {
                "authorId": "1802148",
                "name": "S. Gelly"
              },
              {
                "authorId": "39328010",
                "name": "Jakob Uszkoreit"
              },
              {
                "authorId": "2815290",
                "name": "N. Houlsby"
              }
            ]
          }
        },
        {
          "citedcorpusid": 234343711,
          "isinfluential": false,
          "contexts": [
            "To address the challenge of curved text, ABCNet [22, 24] represents text regions by Bezier curves."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ABCNet v2: Adaptive Bezier-Curve Network for Real-Time End-to-End Text Spotting",
            "abstract": "End-to-end text-spotting, which aims to integrate detection and recognition in a unified framework, has attracted increasing attention due to its simplicity of the two complimentary tasks. It remains an open problem especially when processing arbitrarily-shaped text instances. Previous methods can be roughly categorized into two groups: character-based and segmentation-based, which often require character-level annotations and/or complex post-processing due to the unstructured output. Here, we tackle end-to-end text spotting by presenting Adaptive Bezier Curve Network v2 (ABCNet v2). Our main contributions are four-fold: 1) For the first time, we adaptively fit arbitrarily-shaped text by a parameterized Bezier curve, which, compared with segmentation-based methods, can not only provide structured output but also controllable representation. 2) We design a novel BezierAlign layer for extracting accurate convolution features of a text instance of arbitrary shapes, significantly improving the precision of recognition over previous methods. 3) Different from previous methods, which often suffer from complex post-processing and sensitive hyper-parameters, our ABCNet v2 maintains a simple pipeline with the only post-processing non-maximum suppression (NMS). 4) As the performance of text recognition closely depends on feature alignment, ABCNet v2 further adopts a simple yet effective coordinate convolution to encode the position of the convolutional filters, which leads to a considerable improvement with negligible computation overhead. Comprehensive experiments conducted on various bilingual (English and Chinese) benchmark datasets demonstrate that ABCNet v2 can achieve state-of-the-art performance while maintaining very high efficiency. More importantly, as there is little work on quantization of text spotting models, we quantize our models to improve the inference time of the proposed ABCNet v2. This can be valuable for real-time applications. Code and model are available at: https://git.io/AdelaiDet.",
            "year": 2021,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2108353180",
                "name": "Yuliang Liu"
              },
              {
                "authorId": "12459603",
                "name": "Chunhua Shen"
              },
              {
                "authorId": "144838978",
                "name": "Lianwen Jin"
              },
              {
                "authorId": "2118328320",
                "name": "Tong He"
              },
              {
                "authorId": "150258229",
                "name": "Peng Chen"
              },
              {
                "authorId": "9401586",
                "name": "Chongyu Liu"
              },
              {
                "authorId": "2029503517",
                "name": "Hao Chen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 251431450,
          "isinfluential": false,
          "contexts": [
            "Droby et al. [8] demonstrated good adaptability in Arabic historical manuscripts containing various diacritical marks using Mask R-CNN [10]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Extraction in Historical Documents Using Mask R-CNN",
            "abstract": "Text line extraction is an essential preprocessing step in many handwritten document image analysis tasks. It includes detecting text lines in a document image and segmenting the regions of each detected line. Deep learning-based methods are frequently used for text line detection. However, only a limited number of methods tackle the problems of detection and segmentation together. This paper proposes a holistic method that applies Mask R-CNN for text line extraction. A Mask R-CNN model is trained to extract text lines fractions from document patches, which are further merged to form the text lines of an entire page. The presented method was evaluated on the two well-known datasets of historical documents, DIVA-HisDB and ICDAR 2015-HTR, and achieved state-of-the-art results. In addition, we introduce a new challenging dataset of Arabic historical manuscripts, VML-AHTE, where numerous diacritics are present. We show that the presented Mask R-CNN-based method can successfully segment text lines, even in such a challenging scenario.",
            "year": 2022,
            "venue": "Signals",
            "authors": [
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "2126299723",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "1414748211",
                "name": "Reem Alaasam"
              },
              {
                "authorId": "1573588308",
                "name": "Boraq Madi"
              },
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 261102355,
          "isinfluential": false,
          "contexts": [
            "Rahal et al. [34] proposed a lightweight network, L-U-Net, based on FCN [27] for historical document analysis."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Layout Analysis of Historical Document Images Using a Light Fully Convolutional Network",
            "abstract": "",
            "year": 2023,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "35215669",
                "name": "Najoua Rahal"
              },
              {
                "authorId": "147382507",
                "name": "Lars Vögtlin"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "HisDoc R-CNN [12] applies Mask R-CNN approach [10], employing iterative methods inspired by Cascade R-CNN [1] to refine predictions and accurately detect distorted text lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "232106220": {
      "citing_paper_info": {
        "title": "Experimental Application of a Japanese Historical Document Image Synthesis Method to Text Line Segmentation",
        "abstract": "We plan to use a text line segmentation method based on machine learning in our transcription support system for handwritten Japanese historical document in Kana, and are searching for a data synthesis method of annotated document images because it is time consuming to manually annotate a large set of document images for training data for machine learning. In this paper, we report our synthesis method of annotated document images designed for a Japanese historical document. To compare manually annotated Japanese historical document images and annotated document images synthesized by the method as training data for an object detection algorithm YOLOv3, we conducted text line segmentation experiments using the object detection algorithm. The experimental results show that a model trained by the synthetic annotated document images are competitive with that trained by the manually annotated document images from the view point of a metric intersection-over-union.",
        "year": 2021,
        "venue": "International Conference on Pattern Recognition Applications and Methods",
        "authors": [
          {
            "authorId": "2051871833",
            "name": "Naoto Inuzuka"
          },
          {
            "authorId": "2108444413",
            "name": "Tetsuya Suzuki"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 5,
        "influential_count": 0,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "5628593",
        "54458639",
        "52897574",
        "207958590",
        "15326934"
      ],
      "citation_details": [
        {
          "citedcorpusid": 5628593,
          "isinfluential": false,
          "contexts": [
            "proposed a historical document image generation tool (Capobianco and Marinai, 2017).",
            "Capobianco et al. proposed a historical document image generation tool (Capobianco and Marinai, 2017)."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "DocEmul: A Toolkit to Generate Structured Historical Documents",
            "abstract": "We propose a toolkit to generate structured synthetic documents emulating the actual document production process. Synthetic documents can be used to train systems to perform document analysis tasks. In our case we address the record counting task on handwritten structured collections containing a limited number of examples. Using the DocEmul toolkit we can generate a larger dataset to train a deep architecture to predict the number of records for each page. The toolkit is able to generate synthetic collections and also perform data augmentation to create a larger trainable dataset. It includes one method to extract the page background from real pages which can be used as a substrate where records can be written on the basis of variable structures and using cursive fonts. Moreover, it is possible to extend the synthetic collection by adding random noise, page rotations, and other visual variations. We performed some experiments on two different handwritten collections using the toolkit to generate synthetic data to train a Convolutional Neural Network able to count the number of records in the real collections.",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2285356",
                "name": "Samuele Capobianco"
              },
              {
                "authorId": "3285734",
                "name": "S. Marinai"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15326934,
          "isinfluential": false,
          "contexts": [
            "They were binarized by Otsu’s\nmethod (Otsu, 1979) and resized to 512-pixel width and 512-pixel height.",
            "They were binarized by Otsu’s method (Otsu, 1979) and resized to 512-pixel width and 512-pixel height."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Threshold Selection Method from Gray-Level Histograms",
            "abstract": "",
            "year": 1979,
            "venue": "IEEE Transactions on Systems, Man and Cybernetics",
            "authors": [
              {
                "authorId": "1809629",
                "name": "N. Otsu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 52897574,
          "isinfluential": false,
          "contexts": [
            "We briefly explain our transcription support system for handwritten Japanese historical document in Kana (Sando et al., 2018; Yamazaki et al., 2018) .",
            "The fonts command extracts at most n fonts for each Japanese Kana from Kuzushiji-49(Clanuwat et al., 2018) which is a data set of deformed Kana with white on black.",
            "The command puts a randomly selected character in Kana with a randomly selected font of it in the font data file according to a format specified by the format file.",
            "Kana is a kind of Japanese characters, and it is difficult to read handwritten Kana used in historical documents because of the following reasons.",
            "• At most 100 fonts were randomly selected for each character in Kana.",
            "We plan to use a text line segmentation method based on machine learning in a transcription support system for handwritten Japanese historical document in Kana which we are developing."
          ],
          "intents": [
            "['methodology']",
            "--",
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "A Handwritten Japanese Historical Kana Reprint Support System: Development of a Graphical User Interface",
            "abstract": "Reprint of Japanese historical manuscripts is time-consuming and requires training because they are hand-written, and may contain characters different from those currently used. We proposed a framework for assisting the human process for reading Japanese historical manuscripts and implemented a part of a system based on the framework as a Web service. In this paper, we present a graphical user interface (GUI) for the system and reprint process through the GUI. We conducted a user test to evaluate the system with the GUI by a questionnaire. From the results of the experiment, we confirmed that the GUI can be used intuitively but we also found points to be improved in the GUI.",
            "year": 2018,
            "venue": "ACM Symposium on Document Engineering",
            "authors": [
              {
                "authorId": "2064040759",
                "name": "Atsushi Yamazaki"
              },
              {
                "authorId": "47708836",
                "name": "Kazuki Sando"
              },
              {
                "authorId": "2108444413",
                "name": "Tetsuya Suzuki"
              },
              {
                "authorId": "1750047",
                "name": "A. Aiba"
              }
            ]
          }
        },
        {
          "citedcorpusid": 54458639,
          "isinfluential": false,
          "contexts": [
            "The fonts command extracts at most n fonts for each Japanese Kana from Kuzushiji-49(Clanuwat et al., 2018) which is a data set of deformed Kana with white on black."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Deep Learning for Classical Japanese Literature",
            "abstract": "Much of machine learning research focuses on producing models which perform well on benchmark tasks, in turn improving our understanding of the challenges associated with those tasks. From the perspective of ML researchers, the content of the task itself is largely irrelevant, and thus there have increasingly been calls for benchmark tasks to more heavily focus on problems which are of social or cultural relevance. In this work, we introduce Kuzushiji-MNIST, a dataset which focuses on Kuzushiji (cursive Japanese), as well as two larger, more challenging datasets, Kuzushiji-49 and Kuzushiji-Kanji. Through these datasets, we wish to engage the machine learning community into the world of classical Japanese literature. Dataset available at this https URL",
            "year": 2018,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "52214414",
                "name": "Tarin Clanuwat"
              },
              {
                "authorId": "1387990552",
                "name": "Mikel Bober-Irizar"
              },
              {
                "authorId": "1730368",
                "name": "A. Kitamoto"
              },
              {
                "authorId": "49071560",
                "name": "Alex Lamb"
              },
              {
                "authorId": "50032855",
                "name": "Kazuaki Yamamoto"
              },
              {
                "authorId": "1389041357",
                "name": "David Ha"
              }
            ]
          }
        },
        {
          "citedcorpusid": 207958590,
          "isinfluential": false,
          "contexts": [
            "Pondenkandath et al. proposed a synthesis method of historical document images using a deep neural network (Pondenkandath et al., 2019).",
            "proposed a synthesis method of historical document images using a deep neural network (Pondenkandath et al., 2019)."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Historical Document Synthesis with Generative Adversarial Networks",
            "abstract": "This work tackles a particular image-to-image translation problem, where the goal is to transform an image from a source domain (modern printed electronic document) to a target domain (historical handwritten document). The main motivation of this task is to generate massive synthetic datasets of \"historic\" documents which can be used for the training of document analysis systems. By completing this task, it becomes possible to consider the generation of a tremendous amount of synthetic training data using only one single deep learning algorithm. Existing approaches for synthetic document generation rely on heuristics, or 2D and 3D geometric transformation-functions and are typically targeted at degrading the document. We tackle the problem of document synthesis and propose to train a particular form of Generative Adversarial Neural Networks, to learn a mapping function from an input image to an output image. With several experiments, we show that our algorithm generates an artificial historical document image that looks like a real historical document – for expert and non-expert eyes – by transferring the \"historical style\" to the classical electronic document.",
            "year": 2019,
            "venue": "2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)",
            "authors": [
              {
                "authorId": "8811132",
                "name": "Vinaychandran Pondenkandath"
              },
              {
                "authorId": "38890619",
                "name": "Michele Alberti"
              },
              {
                "authorId": "1404344553",
                "name": "Michaël Diatta"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "constructed a layout data set of documents usable for machine learning and made it public (Aoike et al., 2019).",
            "Aoike et al. constructed a layout data set of documents usable for machine learning and made it public (Aoike et al., 2019)."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "9673364": {
      "citing_paper_info": {
        "title": "Text line segmentation for gray scale historical document images",
        "abstract": "",
        "year": 2011,
        "venue": "The Hip",
        "authors": [
          {
            "authorId": "145766704",
            "name": "Abedelkadir Asi"
          },
          {
            "authorId": "1741845",
            "name": "Raid Saabni"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 4,
        "unique_cited_count": 3,
        "influential_count": 1,
        "detailed_records_count": 4
      },
      "cited_papers": [
        "9187881",
        "41601768",
        "15554170"
      ],
      "citation_details": [
        {
          "citedcorpusid": 9187881,
          "isinfluential": false,
          "contexts": [
            "Level-set techniques are applied to extract text lines and handle multiple orientations, touching, and overlapping characters [5, 30].",
            "Document image segmentation into text lines is a major prerequisite procedure for various document image analysis tasks, such as word spotting, key-word searching, and text alignment [1, 2, 3, 4, 5, 6]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15554170,
          "isinfluential": false,
          "contexts": [
            "Document image segmentation into text lines is a major prerequisite procedure for various document image analysis tasks, such as word spotting, key-word searching, and text alignment [1, 2, 3, 4, 5, 6]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Word image matching using dynamic time warping",
            "abstract": "",
            "year": 2003,
            "venue": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "2352980",
                "name": "T. Rath"
              },
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              }
            ]
          }
        },
        {
          "citedcorpusid": 41601768,
          "isinfluential": true,
          "contexts": [
            "To determine a seam that passes along the medial axis of a text line and crosses its components, we use an energy map based on a gray-level distance transform, introduced by Levi and Montanari [33].",
            "To determine a seam that passes along the medial axis of a text line and crosses its \ncomponents, we use an energy map based on a gray-level distance transform, introduced by Levi and Montanari \n[33].",
            "Available: http://portal.acm.org/citation.cfm?id=1304595.1304766 [33] G. Levi and U. Montanari., \nA grey-weighted skeleton."
          ],
          "intents": [
            "['methodology']",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "A Grey-Weighted Skeleton",
            "abstract": "",
            "year": 1970,
            "venue": "Information and Control",
            "authors": [
              {
                "authorId": "143760024",
                "name": "G. Levi"
              },
              {
                "authorId": "1690890",
                "name": "U. Montanari"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Projection profiles along a predetermined direction is used in top-down approaches to estimate the paths separating consecutive text lines [12, 13, 14, 11, 15, 16]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "228102342": {
      "citing_paper_info": {
        "title": "Learning-Free Text Line Segmentation for Historical Handwritten Documents",
        "abstract": "We present a learning-free method for text line segmentation of historical handwritten document images. This method relies on automatic scale selection together with second derivative of anisotropic Gaussian filters to detect the blob lines that strike through the text lines. Detected blob lines guide an energy minimization procedure to extract the text lines. Historical handwritten documents contain noise, heterogeneous text line heights, skews and touching characters among text lines. Automatic scale selection allows for automatic adaption to the heterogeneous nature of handwritten text lines in case the character height range is correctly estimated. In the extraction phase, the method can accurately split the touching characters among the text lines. We provide results investigating various settings and compare the model with recent learning-free and learning-based methods on the cBAD competition dataset.",
        "year": 2020,
        "venue": "Applied Sciences",
        "authors": [
          {
            "authorId": "2126299723",
            "name": "Berat Kurar Barakat"
          },
          {
            "authorId": "51037361",
            "name": "Rafi Cohen"
          },
          {
            "authorId": "27005271",
            "name": "Ahmad Droby"
          },
          {
            "authorId": "2578300",
            "name": "Irina Rabaev"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 14,
        "unique_cited_count": 14,
        "influential_count": 1,
        "detailed_records_count": 14
      },
      "cited_papers": [
        "16958669",
        "16503365",
        "46955576",
        "6962281",
        "5490524",
        "5252785",
        "20611223",
        "17575742",
        "16432038",
        "14635907",
        "15793605",
        "9763623",
        "9656136",
        "4761833"
      ],
      "citation_details": [
        {
          "citedcorpusid": 4761833,
          "isinfluential": true,
          "contexts": [
            "Using the extracted baselines, the performance is measured by means of Precision (P), Recall (R), and F-measure (FM), as described in [9].",
            "Henceforth, the recent competition datasets [9] (Figure 1) are more challenging than the prior ones [10–13].",
            "cBAD dataset [9] contains 539 document images from 7 different archives.",
            "The precision and recall values indicate that the IRISA method splits baselines more precisely but also misses more baselines compared to our method.",
            "70 is for a learning-based method, DMRZ [9] Two learning-free methods, our method and IRISA [9], achieve close F-measure values.",
            "The best performance with an F-measure value of 97.70 is for a learning-based method, DMRZ [9] Two learning-free methods, our method and IRISA [9], achieve close F-measure values.",
            "However, we observe only limited attempts where learning-free algorithms have been used for text line detection of challenging historical documents [9]."
          ],
          "intents": [
            "['methodology']",
            "['result']",
            "['background']",
            "--",
            "['methodology']",
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "cBAD: ICDAR2017 Competition on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              },
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5252785,
          "isinfluential": false,
          "contexts": [
            "They can be applied both to the binarized document images [13,29] as well as to the gray scale document images [30,31]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Binarization-Free Text Line Segmentation for Historical Documents Based on Interest Point Clustering",
            "abstract": "",
            "year": 2012,
            "venue": "2012 10th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1706090",
                "name": "Robert Sablatnig"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5490524,
          "isinfluential": false,
          "contexts": [
            "They can be applied both to the binarized document images [13,29] as well as to the gray scale document images [30,31]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Binarization-Free Clustering Approach to Segment Curved Text Lines in Historical Manuscripts",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6962281,
          "isinfluential": false,
          "contexts": [
            "Character height range σ x is computed automatically using either way: (1) Component Evolution Map (CEM) [44] estimates character height range by analyzing the height distribution of connected components for each possible grayscale threshold; (2) Mean height of components estimates character height…"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Evolution maps and applications",
            "abstract": "Common tasks in document analysis, such as binarization, line extraction etc., are still considered diffi cult for highly degraded text documents. Having reliable fundamental information regarding the characters of the document, such as the distribution of character dimensions and stroke width, can significantly improve the performance of these tasks. We introduce a novel perspective of the image data which maps the evolution of connected components along the change in gray scale threshold. The maps reveal significant information about the sets of elements in the document, such as characters, noise, stains, and words. The information is further employed to improve state of the art binarization algorithm, and achieve automatically character size estimation, line extraction, stroke width estimation, and feature distribution analysis, all of which are hard tasks for highly degraded documents.",
            "year": 2016,
            "venue": "PeerJ Computer Science",
            "authors": [
              {
                "authorId": "2339207",
                "name": "Ofer Biller"
              },
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1686153",
                "name": "I. Dinstein"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9656136,
          "isinfluential": false,
          "contexts": [
            "Early methods used nonconvolutional classifiers with hand crafted features [12,32,33]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Pixel Labeling Approach for Historical Digitized Books",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1826457",
                "name": "P. Héroux"
              },
              {
                "authorId": "1399368454",
                "name": "Petra Gomez-Krämer"
              },
              {
                "authorId": "143858619",
                "name": "A. Boucher"
              },
              {
                "authorId": "1682986",
                "name": "R. Mullot"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9763623,
          "isinfluential": false,
          "contexts": [
            "[39] globally estimates coarse text lines and locally reassigns misclassified elements to split the touching text lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Handwritten Textlines in Presence of Touching Components",
            "abstract": "",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2069634816",
                "name": "J. Kumar"
              },
              {
                "authorId": "145714522",
                "name": "Le Kang"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "1404588675",
                "name": "W. Abd-Almageed"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14635907,
          "isinfluential": false,
          "contexts": [
            "Advancement in text line segmentation performance will boost the performance of other tasks, such as word segmentation [1,2] and word recognition [3,4]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Novel Connectionist System for Unconstrained Handwriting Recognition",
            "abstract": "",
            "year": 2009,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1753223",
                "name": "Alex Graves"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "143913738",
                "name": "Santiago Fernández"
              },
              {
                "authorId": "2168488",
                "name": "Roman Bertolami"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              },
              {
                "authorId": "145341374",
                "name": "J. Schmidhuber"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15793605,
          "isinfluential": false,
          "contexts": [
            "Projection profile is commonly used for simple document images [18] but can also be adapted for gray scale images [19] and slightly skewed lines [20]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Document image analysis for World War II personal records",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              },
              {
                "authorId": "1694974",
                "name": "Dimosthenis Karatzas"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16432038,
          "isinfluential": false,
          "contexts": [
            "Projection proﬁle is commonly used for simple document images [18] but can also be adapted for gray scale images [19] and slightly skewed lines [20]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A general approach for multi-oriented text line extraction of handwritten documents",
            "abstract": "",
            "year": 2011,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2892336",
                "name": "Nazih Ouwayed"
              },
              {
                "authorId": "2257903477",
                "name": "Abdel Belaïd"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16503365,
          "isinfluential": false,
          "contexts": [
            "Later on, Alaei et al. [25] adapted smearing to skewed lines by applying it in a strip-wise fashion."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A new scheme for unconstrained handwritten text-line segmentation",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16958669,
          "isinfluential": false,
          "contexts": [
            "Hough transform can also be applied to the centroids of connected components and directly align them as text lines [22]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Historical Handwritten Documents into Text Zones and Text Lines",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17575742,
          "isinfluential": false,
          "contexts": [
            "Component tree [43] binarizes the grayscale blob lines image by ﬁtting k knots linear splines of least squares to each of the candidate blob lines.",
            "Component tree [43] organizes the connected components of level sets in a tree structure."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A document binarization method based on connected operators",
            "abstract": "",
            "year": 2010,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "1781065",
                "name": "B. Naegel"
              },
              {
                "authorId": "145440322",
                "name": "L. Wendling"
              }
            ]
          }
        },
        {
          "citedcorpusid": 20611223,
          "isinfluential": false,
          "contexts": [
            "Advancement in text line segmentation performance will boost the performance of other tasks, such as word segmentation [1,2] and word recognition [3,4]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Scale Space Technique for Word Segmentation in Handwritten Documents",
            "abstract": "",
            "year": 1999,
            "venue": "Scale-Space",
            "authors": [
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              },
              {
                "authorId": "103948542",
                "name": "N. Srimal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 46955576,
          "isinfluential": false,
          "contexts": [
            "Learning-based methods [5–8] can inherently handle the problems arising from complex layout of text lines and heterogeneity of documents.",
            "As a remedy, dense prediction has been successfully used for text line segmentation of handwritten documents [5,8]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Fully convolutional network with dilated convolutions for handwritten text line segmentation",
            "abstract": "",
            "year": 2018,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "47689382",
                "name": "G. Renton"
              },
              {
                "authorId": "2652359",
                "name": "Yann Soullard"
              },
              {
                "authorId": "1712446",
                "name": "Clément Chatelain"
              },
              {
                "authorId": "143680806",
                "name": "Sébastien Adam"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        }
      ]
    },
    "277071728": {
      "citing_paper_info": {
        "title": "Exploring Few-Shot Text Line Segmentation Approaches in Challenging Ancient Manuscripts",
        "abstract": "Text line segmentation is a critical component of document layout analysis, particularly for ancient handwritten manuscripts. Its primary goal is to accurately extract individual text lines, a step that significantly influences subsequent tasks such as optical character recognition, text transcription, and information extraction. However, segmenting text lines in historical manuscripts is particularly challenging due to irregular handwriting, faded ink, and complex layouts with overlapping lines and non-linear text flows. Additionally, the limited availability of large annotated datasets makes fully supervised learning approaches impractical for these documents. In this paper, we explore the applicability of three prominent semantic segmentation models when applied in a few-shot learning setting, using only a small number of labeled examples per manuscript. Our results demonstrate the challenges of addressing text line segmentation in the context of scarce labeled data. This provides a promising avenue for future research in document analysis for historical manuscripts.",
        "year": 2025,
        "venue": "Italian Research Conference on Digital Library Management Systems",
        "authors": [
          {
            "authorId": "2188989649",
            "name": "Silvia Zottin"
          },
          {
            "authorId": "2140259458",
            "name": "Axel De Nardin"
          },
          {
            "authorId": "2350578495",
            "name": "Giuseppe Branca"
          },
          {
            "authorId": "93798001",
            "name": "E. Colombi"
          },
          {
            "authorId": "1709627",
            "name": "C. Piciarelli"
          },
          {
            "authorId": "2318013572",
            "name": "Hafsa Shujat"
          },
          {
            "authorId": "2270471565",
            "name": "G. Foresti"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 9,
        "unique_cited_count": 9,
        "influential_count": 3,
        "detailed_records_count": 9
      },
      "cited_papers": [
        "3638670",
        "56598571",
        "267658933",
        "162169040",
        "268246760",
        "28347739",
        "5299559",
        "272072950",
        "1629541"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1629541,
          "isinfluential": true,
          "contexts": [
            "Specifically, we focus on three of the most popular models in the literature characterized by different architectural choices: FCN [1], PSPNet [2], and DeepLabv3+ [3].",
            "Specifically, we investigate the performance of three well-known, effective, semantic segmentation models, FCN [1], PSPNet [2], and DeepLabv3+ [3], in the context of few-shot learning.",
            "Fully Convolutional Network (FCN) [1] is a pioneering architecture designed for semantic segmentation tasks.",
            "Table 1 summarizes the performance evaluation of the three semantic segmentation models, FCN [1], PSPNet [2], and DeepLabv3+ [3], on the text line segmentation task."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Fully convolutional networks for semantic segmentation",
            "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.",
            "year": 2014,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "1782282",
                "name": "Evan Shelhamer"
              },
              {
                "authorId": "2117314646",
                "name": "Jonathan Long"
              },
              {
                "authorId": "1753210",
                "name": "Trevor Darrell"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3638670,
          "isinfluential": true,
          "contexts": [
            "Specifically, we focus on three of the most popular models in the literature characterized by different architectural choices: FCN [1], PSPNet [2], and DeepLabv3+ [3].",
            "Specifically, we investigate the performance of three well-known, effective, semantic segmentation models, FCN [1], PSPNet [2], and DeepLabv3+ [3], in the context of few-shot learning.",
            "Table 1 summarizes the performance evaluation of the three semantic segmentation models, FCN [1], PSPNet [2], and DeepLabv3+ [3], on the text line segmentation task.",
            "DeepLabv3+ [3] is a state-of-the-art model for semantic segmentation, designed to achieve high accuracy by effectively capturing contextual information and refining spatial details."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation",
            "abstract": "Spatial pyramid pooling module or encode-decoder structure are used in deep neural networks for semantic segmentation task. The former networks are able to encode multi-scale contextual information by probing the incoming features with filters or pooling operations at multiple rates and multiple effective fields-of-view, while the latter networks can capture sharper object boundaries by gradually recovering the spatial information. In this work, we propose to combine the advantages from both methods. Specifically, our proposed model, DeepLabv3+, extends DeepLabv3 by adding a simple yet effective decoder module to refine the segmentation results especially along object boundaries. We further explore the Xception model and apply the depthwise separable convolution to both Atrous Spatial Pyramid Pooling and decoder modules, resulting in a faster and stronger encoder-decoder network. We demonstrate the effectiveness of the proposed model on PASCAL VOC 2012 and Cityscapes datasets, achieving the test set performance of 89.0\\% and 82.1\\% without any post-processing. Our paper is accompanied with a publicly available reference implementation of the proposed models in Tensorflow at \\url{this https URL}.",
            "year": 2018,
            "venue": "European Conference on Computer Vision",
            "authors": [
              {
                "authorId": "34192119",
                "name": "Liang-Chieh Chen"
              },
              {
                "authorId": "1844940337",
                "name": "Yukun Zhu"
              },
              {
                "authorId": "2776496",
                "name": "G. Papandreou"
              },
              {
                "authorId": "3302320",
                "name": "Florian Schroff"
              },
              {
                "authorId": "2595180",
                "name": "Hartwig Adam"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5299559,
          "isinfluential": true,
          "contexts": [
            "Specifically, we focus on three of the most popular models in the literature characterized by different architectural choices: FCN [1], PSPNet [2], and DeepLabv3+ [3].",
            "Pyramid Scene Parsing Network (PSPNet) [2] is a powerful model for semantic segmentation, known for its ability to capture both local and global contextual information.",
            "Specifically, we investigate the performance of three well-known, effective, semantic segmentation models, FCN [1], PSPNet [2], and DeepLabv3+ [3], in the context of few-shot learning.",
            "Table 1 summarizes the performance evaluation of the three semantic segmentation models, FCN [1], PSPNet [2], and DeepLabv3+ [3], on the text line segmentation task."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Pyramid Scene Parsing Network",
            "abstract": "Scene parsing is challenging for unrestricted open vocabulary and diverse scenes. In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network (PSPNet). Our global prior representation is effective to produce good quality results on the scene parsing task, while PSPNet provides a superior framework for pixel-level prediction. The proposed approach achieves state-of-the-art performance on various datasets. It came first in ImageNet scene parsing challenge 2016, PASCAL VOC 2012 benchmark and Cityscapes benchmark. A single PSPNet yields the new record of mIoU accuracy 85.4% on PASCAL VOC 2012 and accuracy 80.2% on Cityscapes.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "3459894",
                "name": "Hengshuang Zhao"
              },
              {
                "authorId": "1788070",
                "name": "Jianping Shi"
              },
              {
                "authorId": "50844674",
                "name": "Xiaojuan Qi"
              },
              {
                "authorId": "31843833",
                "name": "Xiaogang Wang"
              },
              {
                "authorId": "1729056",
                "name": "Jiaya Jia"
              }
            ]
          }
        },
        {
          "citedcorpusid": 28347739,
          "isinfluential": false,
          "contexts": [
            "PSPNet builds upon a backbone network, typically ResNet [15], which serves as the feature extractor."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Focusing Attention: Towards Accurate Text Recognition in Natural Images",
            "abstract": "Scene text recognition has been a hot research topic in computer vision due to its various applications. The state of the art is the attention-based encoder-decoder framework that learns the mapping between input images and output sequences in a purely data-driven way. However, we observe that existing attention-based methods perform poorly on complicated and/or low-quality images. One major reason is that existing methods cannot get accurate alignments between feature areas and targets for such images. We call this phenomenon “attention drift”. To tackle this problem, in this paper we propose the FAN (the abbreviation of Focusing Attention Network) method that employs a focusing attention mechanism to automatically draw back the drifted attention. FAN consists of two major components: an attention network (AN) that is responsible for recognizing character targets as in the existing methods, and a focusing network (FN) that is responsible for adjusting attention by evaluating whether AN pays attention properly on the target areas in the images. Furthermore, different from the existing methods, we adopt a ResNet-based network to enrich deep representations of scene text images. Extensive experiments on various benchmarks, including the IIIT5k, SVT and ICDAR datasets, show that the FAN method substantially outperforms the existing methods.",
            "year": 2017,
            "venue": "IEEE International Conference on Computer Vision",
            "authors": [
              {
                "authorId": "2398015",
                "name": "Zhanzhan Cheng"
              },
              {
                "authorId": "2057969271",
                "name": "Fan Bai"
              },
              {
                "authorId": "47103450",
                "name": "Yunlu Xu"
              },
              {
                "authorId": "2070795686",
                "name": "Gang Zheng"
              },
              {
                "authorId": "3290437",
                "name": "Shiliang Pu"
              },
              {
                "authorId": "50730331",
                "name": "Shuigeng Zhou"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56598571,
          "isinfluential": false,
          "contexts": [
            "Evaluation involves calculating key text line semantic segmentation metrics commonly adopted in the literature [18, 19], including Pixel Intersection over Union (Pixel IU), Line Intersection over Union (Line IU), Detection Rate (DR), Recognition Accuracy (RA), and F-measure (FM)."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "ICFHR 2018 Competition On Document Image Analysis Tasks for Southeast Asian Palm Leaf Manuscripts",
            "abstract": "This paper presents the results of the Competition on Document Image Analysis Tasks for Southeast Asian Palm Leaf Manuscripts that was organized in the context of the 16th International Conference on Frontiers in Handwriting Recognition (ICFHR-2018). For this competition, three different corpus of palm leaf manuscripts written in three different scripts and languages (Balinese, Sundanese and Khmer) are used. Four Document Image Analysis (DIA) tasks are proposed as the challenges in this competition: binarization, text line segmentation, solated character/glyph recognition, and word transliteration. The results of this competition will be very useful in benchmarking analysis for the collection of palm leaf manuscripts, accelerating, evaluating and improving the performance of existing DIA system for a new type of document collection. This paper describes the competition details including the dataset, the evaluation measures used, a short description of each participant as well as the performance of the all submitted methods",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2154407",
                "name": "M. W. A. Kesiman"
              },
              {
                "authorId": "8700325",
                "name": "Dona Valy"
              },
              {
                "authorId": "1690398",
                "name": "J. Burie"
              },
              {
                "authorId": "39662991",
                "name": "E. Paulus"
              },
              {
                "authorId": "9165810",
                "name": "M. Suryani"
              },
              {
                "authorId": "8714538",
                "name": "S. Hadi"
              },
              {
                "authorId": "1782629",
                "name": "M. Verleysen"
              },
              {
                "authorId": "153584768",
                "name": "Sophea Chhun"
              },
              {
                "authorId": "1695766",
                "name": "J. Ogier"
              }
            ]
          }
        },
        {
          "citedcorpusid": 162169040,
          "isinfluential": false,
          "contexts": [
            "In addition, the study in [8] investigates the performance of models pre-trained on ImageNet and fine-tuned on an ancient document dataset."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "A Comprehensive Study of ImageNet Pre-Training for Historical Document Image Analysis",
            "abstract": "Automatic analysis of scanned historical documents comprises a wide range of image analysis tasks, which are often challenging for machine learning due to a lack of human-annotated learning samples. With the advent of deep neural networks, a promising way to cope with the lack of training data is to pre-train models on images from a different domain and then fine-tune them on historical documents. In the current research, a typical example of such cross-domain transfer learning is the use of neural networks that have been pre-trained on the ImageNet database for object recognition. It remains a mostly open question whether or not this pre-training helps to analyse historical documents, which have fundamentally different image properties when compared with ImageNet. In this paper, we present a comprehensive empirical survey on the effect of ImageNet pre-training for diverse historical document analysis tasks, including character recognition, style classification, manuscript dating, semantic segmentation, and content-based retrieval. While we obtain mixed results for semantic segmentation at pixel-level, we observe a clear trend across different network architectures that ImageNet pre-training has a positive effect on classification as well as content-based retrieval.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "144026657",
                "name": "Linda Studer"
              },
              {
                "authorId": "38890619",
                "name": "Michele Alberti"
              },
              {
                "authorId": "8811132",
                "name": "Vinaychandran Pondenkandath"
              },
              {
                "authorId": "121362498",
                "name": "Pinar Goktepe"
              },
              {
                "authorId": "22399511",
                "name": "Thomas Kolonko"
              },
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 267658933,
          "isinfluential": false,
          "contexts": [
            "Research in [6, 7] demonstrates that pre-training on document-related datasets consistently enhances segmentation results and accelerates convergence compared to using general-purpose datasets."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Is ImageNet Always the Best Option? An Overview on Transfer Learning Strategies for Document Layout Analysis",
            "abstract": "",
            "year": 2023,
            "venue": "ICIAP Workshops",
            "authors": [
              {
                "authorId": "2140259458",
                "name": "Axel De Nardin"
              },
              {
                "authorId": "2188989649",
                "name": "Silvia Zottin"
              },
              {
                "authorId": "93798001",
                "name": "E. Colombi"
              },
              {
                "authorId": "1709627",
                "name": "C. Piciarelli"
              },
              {
                "authorId": "2270471565",
                "name": "G. Foresti"
              }
            ]
          }
        },
        {
          "citedcorpusid": 268246760,
          "isinfluential": false,
          "contexts": [
            "A more recent one-shot learning framework is introduced in [13], targeting layout segmentation of ancient Arabic documents."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "A One-Shot Learning Approach to Document Layout Segmentation of Ancient Arabic Manuscripts",
            "abstract": "Document layout segmentation is a challenging task due to the variability and complexity of document layouts. Ancient manuscripts in particular are often damaged by age, have very irregular layouts, and are characterized by progressive editing from different authors over a large time window. All these factors make the semantic segmentation process of specific areas, such as main text and side text, very difficult. However, the study of these manuscripts turns out to be fundamental for historians and humanists, so much so that in recent years the demand for machine learning approaches aimed at simplifying the extraction of information from these documents has consistently increased, leading document layout analysis to become an increasingly important research area. In order for machine learning techniques to be applied effectively to this task, however, a large amount of correctly and precisely labeled images is required for their training. This is obviously a limitation for this field of research as ground truth must be precisely and manually crafted by expert humanists, making it a very time-consuming process. In this paper, with the aim of overcoming this limitation, we present an efficient document layout segmentation framework, which while being trained on only one labeled page per manuscript still achieves state-of-the-art performance compared to other popular approaches trained on all the available data when tested on a challenging dataset of ancient Arabic manuscripts.",
            "year": 2024,
            "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
            "authors": [
              {
                "authorId": "2140259458",
                "name": "Axel De Nardin"
              },
              {
                "authorId": "2188989649",
                "name": "Silvia Zottin"
              },
              {
                "authorId": "1709627",
                "name": "C. Piciarelli"
              },
              {
                "authorId": "93798001",
                "name": "E. Colombi"
              },
              {
                "authorId": "2270471565",
                "name": "G. Foresti"
              }
            ]
          }
        },
        {
          "citedcorpusid": 272072950,
          "isinfluential": false,
          "contexts": [
            "Research in [6, 7] demonstrates that pre-training on document-related datasets consistently enhances segmentation results and accelerates convergence compared to using general-purpose datasets."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "In-domain versus out-of-domain transfer learning for document layout analysis",
            "abstract": "Data availability is a big concern in the field of document analysis, especially when working on tasks that require a high degree of precision when it comes to the definition of the ground truths on which to train deep learning models. A notable example is represented by the task of document layout analysis in handwritten documents, which requires pixel-precise segmentation maps to highlight the different layout components of each document page. These segmentation maps are typically very time-consuming and require a high degree of domain knowledge to be defined, as they are intrinsically characterized by the content of the text. For this reason in the present work, we explore the effects of different initialization strategies for deep learning models employed for this type of task by relying on both in-domain and cross-domain datasets for their pre-training. To test the employed models we use two publicly available datasets with heterogeneous characteristics both regarding their structure as well as the languages of the contained documents. We show how a combination of cross-domain and in-domain transfer learning approaches leads to the best overall performance of the models, as well as speeding up their convergence process.\n",
            "year": 2024,
            "venue": "Int. J. Document Anal. Recognit.",
            "authors": [
              {
                "authorId": "2140259458",
                "name": "Axel De Nardin"
              },
              {
                "authorId": "2188989649",
                "name": "Silvia Zottin"
              },
              {
                "authorId": "1709627",
                "name": "C. Piciarelli"
              },
              {
                "authorId": "2270471565",
                "name": "G. Foresti"
              },
              {
                "authorId": "93798001",
                "name": "E. Colombi"
              }
            ]
          }
        }
      ]
    },
    "229036427": {
      "citing_paper_info": {
        "title": "Text line segmentation based on local baselines and connected component centroids for Tibetan historical documents",
        "abstract": "Text line segmentation is one of the key contents in document image analysis and recognition. Due to the complex situation of text images in Tibetan historical document, such as the coexistence of slanting and distortion of text lines, especially the adhesion between lines, text line segmentation has become a challenging task. In this paper, a new method of text segmentation for Tibetan historical document is proposed. This method first obtains the local baseline information of the text line, and then performs the detection and segmentation of the adhesion area. Finally, according to the barycentre coordinates of the connected component and the local baseline information, each connected component is assigned to the corresponding text line. The method avoids the effect of text line distortion on the segmentation of the stuck text line and greatly reduces the error rate of the adhesion text line segmentation and can effectively deal with the segmentation of slanted and distorted Tibetan sticky text lines.",
        "year": 2020,
        "venue": "Journal of Physics: Conference Series",
        "authors": [
          {
            "authorId": "2067770685",
            "name": "Pengfei Hu"
          },
          {
            "authorId": "2144355950",
            "name": "Yang Chen"
          },
          {
            "authorId": "1574182682",
            "name": "Yusheng Hao"
          },
          {
            "authorId": "2108941572",
            "name": "Yiqun Wang"
          },
          {
            "authorId": "2254980",
            "name": "Weilan Wang"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 7,
        "influential_count": 7,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "8086719",
        "33393978",
        "46955576",
        "44084528",
        "5490524",
        "211026904",
        "28662025"
      ],
      "citation_details": [
        {
          "citedcorpusid": 5490524,
          "isinfluential": true,
          "contexts": [
            "For text line segmentation of historical documents, there are mainly the following methods: projection-based methods[1-3], clustering approach[4-6], neural network[7-9], based on the center of gravity of connected components[10-11], based on baseline detection method[12] and based on connected components analysis[13]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Binarization-Free Clustering Approach to Segment Curved Text Lines in Historical Manuscripts",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8086719,
          "isinfluential": true,
          "contexts": [
            "For text line segmentation of historical documents, there are mainly the following methods: projection-based methods[1-3], clustering approach[4-6], neural network[7-9], based on the center of gravity of connected components[10-11], based on baseline detection method[12] and based on connected components analysis[13]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line and Ligature Segmentation of Urdu Nastaleeq Text",
            "abstract": "The recognition accuracy of ligature-based Urdu language optical character recognition (OCR) systems highly depends on the accuracy of segmentation that converts Urdu text into lines and ligatures. In general, lines and ligatures-based Urdu language OCRs are more successful as compared to characters-based. This paper presents the techniques for segmenting Urdu Nastaleeq text images into lines and subsequently to ligatures. Classical horizontal projection-based segmentation method is augmented with a curved-line-split algorithm for successfully overcoming the problems, such as text line split position, overlapping, merged ligatures, and ligatures crossing line split positions. Ligature segmentation algorithm extracts connected components from text lines, categorizes them into primary and secondary classes, and allocates secondary components to the primary class by examining width, height, coordinates, overlapping, centroids, and baseline information. The proposed line segmentation algorithm is tested on 47 pages with 99.17% accuracy. The proposed ligature segmentation algorithm is mainly tested on a large Urdu-printed text images data set. The proposed algorithm segmented Urdu-printed text images data set to 189 000 ligatures from 10 063 text lines having 332 000 connected components. A total of about 142 000 secondary components have been successfully allocated to more than 189 000 primary ligatures with accuracy rate of 99.80%. Thus, both of the proposed segmentation algorithms outperform the existing algorithms employed for Urdu Nastaleeq text segmentation. Moreover, the proposed line segmentation algorithm is also tested on Arabic, for which it also extracted lines correctly.",
            "year": 2017,
            "venue": "IEEE Access",
            "authors": [
              {
                "authorId": "2074278846",
                "name": "Ibrar Ahmad"
              },
              {
                "authorId": "38542466",
                "name": "Xiaojie Wang"
              },
              {
                "authorId": "2462591",
                "name": "Ruifan Li"
              },
              {
                "authorId": "2115227826",
                "name": "Manzoor Ahmed"
              },
              {
                "authorId": "49706554",
                "name": "R. Ullah"
              }
            ]
          }
        },
        {
          "citedcorpusid": 28662025,
          "isinfluential": true,
          "contexts": [
            "For text line segmentation of historical documents, there are mainly the following methods: projection-based methods[1-3], clustering approach[4-6], neural network[7-9], based on the center of gravity of connected components[10-11], based on baseline detection method[12] and based on connected…"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Projection–Based Text Line Segmentation with a Variable Threshold",
            "abstract": "Abstract Document image segmentation into text lines is one of the stages in unconstrained handwritten document recognition. This paper presents a new algorithm for text line separation in handwriting. The developed algorithm is based on a method using the projection profile. It employs thresholding, but the threshold value is variable. This permits determination of low or overlapping peaks of the graph. The proposed technique is shown to improve the recognition rate relative to traditional methods. The algorithm is robust in text line detection with respect to different text line lengths.",
            "year": 2017,
            "venue": "International Journal of Applied Mathematics and Computer Sciences",
            "authors": [
              {
                "authorId": "31739585",
                "name": "R. Ptak"
              },
              {
                "authorId": "10009081",
                "name": "Bartosz Zygadlo"
              },
              {
                "authorId": "1682586",
                "name": "O. Unold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33393978,
          "isinfluential": true,
          "contexts": [
            "For text line segmentation of historical documents, there are mainly the following methods: projection-based methods[1-3], clustering approach[4-6], neural network[7-9], based on the center of gravity of connected components[10-11], based on baseline detection method[12] and based on connected components analysis[13]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Text-Line Segmentation Method for Historical Tibetan Documents Based on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "Chinese Conference on Computer Vision",
            "authors": [
              {
                "authorId": "2110489669",
                "name": "Yanxing Li"
              },
              {
                "authorId": "2072987",
                "name": "Long-Long Ma"
              },
              {
                "authorId": "7667827",
                "name": "Lijuan Duan"
              },
              {
                "authorId": "46177912",
                "name": "Jian Wu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 44084528,
          "isinfluential": true,
          "contexts": [
            "For text line segmentation of historical documents, there are mainly the following methods: projection-based methods[1-3], clustering approach[4-6], neural network[7-9], based on the center of gravity of connected components[10-11], based on baseline detection method[12] and based on connected components analysis[13]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Unsupervised multi-language handwritten text line segmentation",
            "abstract": "",
            "year": 2018,
            "venue": "Journal of Intelligent & Fuzzy Systems",
            "authors": [
              {
                "authorId": "3442225",
                "name": "Miguel Ángel García Calderón"
              },
              {
                "authorId": "1398808779",
                "name": "René Arnulfo García-Hernández"
              },
              {
                "authorId": "2331280",
                "name": "Yulia Ledeneva"
              }
            ]
          }
        },
        {
          "citedcorpusid": 46955576,
          "isinfluential": true,
          "contexts": [
            "For text line segmentation of historical documents, there are mainly the following methods: projection-based methods[1-3], clustering approach[4-6], neural network[7-9], based on the center of gravity of connected components[10-11], based on baseline detection method[12] and based on connected components analysis[13]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Fully convolutional network with dilated convolutions for handwritten text line segmentation",
            "abstract": "",
            "year": 2018,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "47689382",
                "name": "G. Renton"
              },
              {
                "authorId": "2652359",
                "name": "Yann Soullard"
              },
              {
                "authorId": "1712446",
                "name": "Clément Chatelain"
              },
              {
                "authorId": "143680806",
                "name": "Sébastien Adam"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211026904,
          "isinfluential": true,
          "contexts": [
            "…of historical documents, there are mainly the following methods: projection-based methods[1-3], clustering approach[4-6], neural network[7-9], based on the center of gravity of connected components[10-11], based on baseline detection method[12] and based on connected components…"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation in Historical Document Images Using an Adaptive U-Net Architecture",
            "abstract": "On most document image transcription, indexing and retrieval systems, text line segmentation remains one of the most important preliminary task. Hence, the research community working in document image analysis is particularly interested in providing reliable text line segmentation methods. Recently, an increasing interest in using deep learning-based methods has been noted for solving various sub-fields and tasks related to the issues surrounding document image analysis. Thanks to the computer hardware and software evolution, several methods based on using deep architectures continue to outperform the pattern recognition issues and particularly those related to historical document image analysis. Thus, in this paper we present a novel deep learning-based method for text line segmentation of historical documents. The proposed method is based on using an adaptive U-Net architecture. Qualitative and numerical experiments are given using a large number of historical document images collected from the Tunisian national archives and different recent benchmarking datasets provided in the context of ICDAR and ICFHR competitions. Moreover, the results achieved are compared with those obtained using the state-of-the-art methods.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "51133427",
                "name": "Olfa Mechi"
              },
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "2536574",
                "name": "N. Amara"
              }
            ]
          }
        }
      ]
    },
    "56597514": {
      "citing_paper_info": {
        "title": "Text Line Segmentation for Challenging Handwritten Document Images using Fully Convolutional Network",
        "abstract": "This paper presents a method for text line segmentation of challenging historical manuscript images. These manuscript images contain narrow interline spaces with touching components, interpenetrating vowel signs and inconsistent font types and sizes. In addition, they contain curved, multi-skewed and multi-directed side note lines within a complex page layout. Therefore, bounding polygon labeling would be very difficult and time consuming. Instead we rely on line masks that connect the components on the same text line. Then these line masks are predicted using a Fully Convolutional Network (FCN). In the literature, FCN has been successfully used for text line segmentation of regular handwritten document images. The present paper shows that FCN is useful with challenging manuscript images as well. Using a new evaluation metric that is sensitive to over segmentation as well as under segmentation, testing results on a publicly available challenging handwritten dataset are comparable with the results of a previous work on the same dataset.",
        "year": 2018,
        "venue": "International Conference on Frontiers in Handwriting Recognition",
        "authors": [
          {
            "authorId": "51036690",
            "name": "Berat Kurar Barakat"
          },
          {
            "authorId": "27005271",
            "name": "Ahmad Droby"
          },
          {
            "authorId": "39240022",
            "name": "M. Kassis"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 12,
        "unique_cited_count": 12,
        "influential_count": 0,
        "detailed_records_count": 12
      },
      "cited_papers": [
        "16503365",
        "14124313",
        "13986799",
        "4761833",
        "20611223",
        "15921038",
        "52927386",
        "35471180",
        "1610874",
        "2908640",
        "27494128",
        "2123198"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1610874,
          "isinfluential": false,
          "contexts": [
            "On the other hand, dense prediction does not suffer from redundant computation and has been successfully used for text line segmentation of handwritten documents [12], [13]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Dense prediction for text line segmentation in handwritten document images",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Information Photonics",
            "authors": [
              {
                "authorId": "12581289",
                "name": "Q. Vo"
              },
              {
                "authorId": "144096223",
                "name": "Gueesang Lee"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2123198,
          "isinfluential": false,
          "contexts": [
            "Their approach achieved outstanding results on ICDAR2009 [20] and ICDAR2013 [21] datasets.",
            "Although several benchmark datasets [20]–[22] of handwritten document images are available, a challenging document dataset is absent."
          ],
          "intents": [
            "['result']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "144429596",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "2265885161",
                "name": "Umapada Pal"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2908640,
          "isinfluential": false,
          "contexts": [
            "Pixel classification can be done in a sliding window manner [10], [11] which is not desirable due to redundant and expensive computation of overlapping areas in the sliding windows."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Complete System for Text Line Extraction Using Convolutional Neural Networks and Watershed Transform",
            "abstract": "",
            "year": 2016,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1403927620",
                "name": "Joan Pastor-Pellicer"
              },
              {
                "authorId": "145181206",
                "name": "Muhammad Zeshan Afzal"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "145816817",
                "name": "María José Castro Bleda"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4761833,
          "isinfluential": false,
          "contexts": [
            "Although several benchmark datasets [20]–[22] of handwritten document images are available, a challenging document dataset is absent."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "cBAD: ICDAR2017 Competition on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              },
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13986799,
          "isinfluential": false,
          "contexts": [
            "Ellipse fitting was done using the algorithm described in [19]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Buyer's Guide to Conic Fitting",
            "abstract": "In this paper we evaluate several methods of fitting data to conic sections. Conic fitting is a commonly required task in machine vision, but many algorithms perform badly on incomplete or noisy data. We evaluate several algorithms under various noise and degeneracy conditions, identify the key parameters which affect sensitivity, and present the results of comparative experiments which emphasize the algorithms' behaviours under common examples of degenerate data. In addition, complexity analyses in terms of flop counts are provided in order to further inform the choice of algorithm for a specific application.",
            "year": 1995,
            "venue": "British Machine Vision Conference",
            "authors": [
              {
                "authorId": "47139824",
                "name": "A. Fitzgibbon"
              },
              {
                "authorId": "1843592",
                "name": "Robert B. Fisher"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14124313,
          "isinfluential": false,
          "contexts": [
            "First five blocks, encoder part, follow the design of VGG 16-layer network [16] except the discarded final layer."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
            "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.",
            "year": 2014,
            "venue": "International Conference on Learning Representations",
            "authors": [
              {
                "authorId": "34838386",
                "name": "K. Simonyan"
              },
              {
                "authorId": "1688869",
                "name": "Andrew Zisserman"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15921038,
          "isinfluential": false,
          "contexts": [
            "Smearing method [6] which fills the space between consecutive foreground pixels can be used on skewed documents [7] as well."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document Analysis System",
            "abstract": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included.",
            "year": 1982,
            "venue": "IBM Journal of Research and Development",
            "authors": [
              {
                "authorId": "145470231",
                "name": "Kwan Y. Wong"
              },
              {
                "authorId": "34896449",
                "name": "R. Casey"
              },
              {
                "authorId": "1880661",
                "name": "F. Wahl"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16503365,
          "isinfluential": false,
          "contexts": [
            "Smearing method [6] which fills the space between consecutive foreground pixels can be used on skewed documents [7] as well."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A new scheme for unconstrained handwritten text-line segmentation",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 20611223,
          "isinfluential": false,
          "contexts": [
            "Projection method was initially used for printed documents [1], [2] then modified for skewed [3], [4] and multi-skewed documents [5]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Scale Space Technique for Word Segmentation in Handwritten Documents",
            "abstract": "",
            "year": 1999,
            "venue": "Scale-Space",
            "authors": [
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              },
              {
                "authorId": "103948542",
                "name": "N. Srimal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 27494128,
          "isinfluential": false,
          "contexts": [
            "On the other hand, dense prediction does not suffer from redundant computation and has been successfully used for text line segmentation of handwritten documents [12], [13]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Text Line Segmentation Using Fully Convolutional Network",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "47689382",
                "name": "G. Renton"
              },
              {
                "authorId": "1712446",
                "name": "Clément Chatelain"
              },
              {
                "authorId": "143680806",
                "name": "Sébastien Adam"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 35471180,
          "isinfluential": false,
          "contexts": [
            "Grouping method aggregates pixels or connected components in a bottom up strategy and is superior in case of skewed and curved text lines [8], [9]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Using Scale-Space Anisotropic Smoothing for Text Line Extraction in Historical Documents",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Image Analysis and Recognition",
            "authors": [
              {
                "authorId": "51037361",
                "name": "Rafi Cohen"
              },
              {
                "authorId": "1686153",
                "name": "I. Dinstein"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              }
            ]
          }
        },
        {
          "citedcorpusid": 52927386,
          "isinfluential": false,
          "contexts": [
            "However, particularly FCN8 architecture was selected because it has been successful in page layout analysis of a similar dataset [17]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Binarization Free Layout Analysis for Arabic Historical Documents Using Fully Convolutional Networks",
            "abstract": "",
            "year": 2018,
            "venue": "International Workshop on Arabic Script Analysis and Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        }
      ]
    },
    "247618781": {
      "citing_paper_info": {
        "title": "Robust text line detection in historical documents: learning and evaluation methods",
        "abstract": "Text line segmentation is one of the key steps in historical document understanding. It is challenging due to the variety of fonts, contents, writing styles and the quality of documents that have degraded through the years. In this paper, we address the limitations that currently prevent people from building line segmentation models with a high generalization capacity. We present a study conducted using three state-of-the-art systems Doc-UFCN, dhSegment and ARU-Net and show that it is possible to build generic models trained on a wide variety of historical document datasets that can correctly segment diverse unseen pages. This paper also highlights the importance of the annotations used during training: Each existing dataset is annotated differently. We present a unification of the annotations and show its positive impact on the final text recognition results. In this end, we present a complete evaluation strategy using standard pixel-level metrics, object-level ones and introducing goal-oriented metrics.",
        "year": 2022,
        "venue": "International Journal on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "1380222130",
            "name": "Mélodie Boillet"
          },
          {
            "authorId": "2156685",
            "name": "Christopher Kermorvant"
          },
          {
            "authorId": "1690399",
            "name": "T. Paquet"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 17,
        "unique_cited_count": 17,
        "influential_count": 10,
        "detailed_records_count": 17
      },
      "cited_papers": [
        "221543615",
        "2272015",
        "211266862",
        "1919557",
        "10328909",
        "6069782",
        "15780310",
        "57246310",
        "221141556",
        "33748389",
        "225319541",
        "211026904",
        "211027032",
        "219687205",
        "206594692",
        "234641195",
        "786357"
      ],
      "citation_details": [
        {
          "citedcorpusid": 786357,
          "isinfluential": false,
          "contexts": [
            "Deep TextSpotter [11] uses a mod-iﬁed version of YOLOv2 [12] for the detection and a CNN for the recognition of natural scene text images.",
            "Similar methods [12] [19] have emerged following this idea, however very few were ap-",
            "Deep TextSpotter [11] uses a modified version of YOLOv2 [12] for the detection and a CNN for the recognition of natural scene text images."
          ],
          "intents": [
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "YOLO9000: Better, Faster, Stronger",
            "abstract": "We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. Using a novel, multi-scale training method the same YOLOv2 model can run at varying sizes, offering an easy tradeoff between speed and accuracy. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that dont have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. YOLO9000 predicts detections for more than 9000 different object categories, all in real-time.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "40497777",
                "name": "Joseph Redmon"
              },
              {
                "authorId": "143787583",
                "name": "Ali Farhadi"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1919557,
          "isinfluential": true,
          "contexts": [
            "Even if this metric has shown to be complementary to the IoU metric on Maurdor evaluation [21], it is at present not really used due to the complexity of its computations and its hard applicabil-",
            "The second strategy has shown a real improvement for the box detection task on Maurdor [21] documents.",
            "Even if this metric has shown to be complementary to the IoU metric on Maurdor evaluation [21], it is at present not really used due to the complexity of its computations and its hard applicability to images with multiple objects."
          ],
          "intents": [
            "['background']",
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "First maurdor 2013 evaluation campaign in scanned document image processing",
            "abstract": "",
            "year": 2014,
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "authors": [
              {
                "authorId": "3135839",
                "name": "I. Oparin"
              },
              {
                "authorId": "35798452",
                "name": "Juliette Kahn"
              },
              {
                "authorId": "1701385",
                "name": "Olivier Galibert"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2272015,
          "isinfluential": true,
          "contexts": [
            "[27] also presented a model for multiple classes segmentation.",
            "Yang et al. [27] also presented a model for multiple classes segmentation.",
            "Lastly, in one of our previous works we presented Doc-UFCN [6], a FCN inspired by the previously cited systems and by the multi-modal model presented by Yang et al. [27].",
            "Object-level IoU P/R F1 P/R R@.85/.95 mAP@.65 mAP Barakat [23] Mechi [24] Renton [25] Doc-UFCN [6] dhSegment [7] Yang [27] Tarride [2] Soullard [30] Melnikov [31] To tackle this problem, metrics originally designed in the Information Retrieval community [34] have been adapted to images and used during the PASCAL VOC Challenge 2012 to compute the Precision at object-level.",
            "Barakat [23] 3 3 Mechi [24] 3 3 3 Renton [25] 3 3 Doc-UFCN [6] 3 3 3 dhSegment [7] 3 3 3 3 Yang [27] 3 3 Tarride [2] 3 3 3 3 Soullard [30] 3 Melnikov [31] 3 3"
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Learning to Extract Semantic Structure from Documents Using Multimodal Fully Convolutional Neural Networks",
            "abstract": "We present an end-to-end, multimodal, fully convolutional network for extracting semantic structures from document images. We consider document semantic structure extraction as a pixel-wise segmentation task, and propose a unified model that classifies pixels based not only on their visual appearance, as in the traditional page segmentation task, but also on the content of underlying text. Moreover, we propose an efficient synthetic document generation process that we use to generate pretraining data for our network. Once the network is trained on a large set of synthetic documents, we fine-tune the network on unlabeled real documents using a semi-supervised approach. We systematically study the optimum network architecture and show that both our multimodal approach and the synthetic data pretraining significantly boost the performance.",
            "year": 2017,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2112096491",
                "name": "Xiao Yang"
              },
              {
                "authorId": "8020964",
                "name": "Ersin Yumer"
              },
              {
                "authorId": "2934421",
                "name": "P. Asente"
              },
              {
                "authorId": "1389971134",
                "name": "Mike Kraley"
              },
              {
                "authorId": "1852261",
                "name": "Daniel Kifer"
              },
              {
                "authorId": "145157784",
                "name": "C. Lee Giles"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6069782,
          "isinfluential": true,
          "contexts": [
            "Some other pioneer contributions have also investigated line segmentation-free approaches that try to directly recognize the text from paragraphs or pages [3] [4]; however, these systems still face important limitations and struggle to be eﬀective on complex documents.",
            "Our evaluation library will be made publicly available 4 .",
            "For example, Bluche [4] proposed a segmentation-free handwriting recognition system based on MDLSTM layers."
          ],
          "intents": [
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Joint Line Segmentation and Transcription for End-to-End Handwritten Paragraph Recognition",
            "abstract": "Offline handwriting recognition systems require cropped text line images for both training and recognition. On the one hand, the annotation of position and transcript at line level is costly to obtain. On the other hand, automatic line segmentation algorithms are prone to errors, compromising the subsequent recognition. In this paper, we propose a modification of the popular and efficient multi-dimensional long short-term memory recurrent neural networks (MDLSTM-RNNs) to enable end-to-end processing of handwritten paragraphs. More particularly, we replace the collapse layer transforming the two-dimensional representation into a sequence of predictions by a recurrent version which can recognize one line at a time. In the proposed model, a neural network performs a kind of implicit line segmentation by computing attention weights on the image representation. The experiments on paragraphs of Rimes and IAM database yield results that are competitive with those of networks trained at line level, and constitute a significant step towards end-to-end transcription of full documents.",
            "year": 2016,
            "venue": "Neural Information Processing Systems",
            "authors": [
              {
                "authorId": "3387810",
                "name": "Théodore Bluche"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10328909,
          "isinfluential": false,
          "contexts": [
            "Despite the significant improvement in the field and the development of more advanced systems (Fast R-CNN [15], Faster-RCNN [16,17]), thismethod did not break through the document images community.",
            "Despite the signiﬁcant improvement in the ﬁeld and the development of more advanced systems (Fast R-CNN [15], Faster-RCNN [16] and [17]), this method did not break through the document images community."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
            "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available",
            "year": 2015,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              },
              {
                "authorId": "2032184078",
                "name": "Jian Sun"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15780310,
          "isinfluential": true,
          "contexts": [
            "Furthermore, as handwritten line detection is the first step of the whole recognition process, it should be more realistic to evaluate its true impact on the final recognition results (Character and Word Error Rates), by conducting a goal-directed evaluation [5].",
            "Lastly, Trier and Jain [5] have shown the importance of a goal-oriented evaluation for binarization methods since",
            "Lastly, Trier and Jain [5] have shown the importance of a goal-oriented evaluation for binarization methods since\nan evaluation from a human expert really depends on his visual criteria."
          ],
          "intents": [
            "['background']",
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Goal-Directed Evaluation of Binarization Methods",
            "abstract": "This paper presents a methodology for evaluation of low-level image analysis methods, using binarization (two-level thresholding) as an example. Binarization of scanned gray scale images is the first step in most document image analysis systems. Selection of an appropriate binarization method for an input image domain is a difficult problem. Typically, a human expert evaluates the binarized images according to his/her visual criteria. However, to conduct an objective evaluation, one needs to investigate how well the subsequent image analysis steps will perform on the binarized image. We call this approach goal-directed evaluation, and it can be used to evaluate other low-level image processing methods as well. Our evaluation of binarization methods is in the context of digit recognition, so we define the performance of the character recognition module as the objective measure. Eleven different locally adaptive binarization methods were evaluated, and Niblack's method gave the best performance.",
            "year": 1995,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2258400",
                "name": "Ø. Trier"
              },
              {
                "authorId": "145295484",
                "name": "Anil K. Jain"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33748389,
          "isinfluential": true,
          "contexts": [
            "[8] proposed ARU-Net, an extended version of the U-Net architecture using spatial attention to deal with various font sizes and residual blocks to reach higher results.",
            "All the datasets cited above have been used to train generic text line detection models using Doc-UFCN [6], dhSegment [7] and ARU-Net [8].",
            "For our experiments, we chose to study three state-of-the-art systems: Doc-UFCN [6], dhSegment [7] and ARU-Net [8].",
            "In this paper, we provide a fair and extensive evaluation of three state-of-the-art approaches for text line segmentation, Doc-UFCN [6], dhSegment [7] and ARU-Net [8] on a wide collection of historical datasets and using multiple metrics including a goal-directed one."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A two-stage method for text line detection in historical documents",
            "abstract": "This work presents a two-stage text line detection method for historical documents. Each detected text line is represented by its baseline. In a first stage, a deep neural network called ARU-Net labels pixels to belong to one of the three classes: baseline, separator and other. The separator class marks beginning and end of each text line. The ARU-Net is trainable from scratch with manageably few manually annotated example images (<50\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$<\\,50$$\\end{document}). This is achieved by utilizing data augmentation strategies. The network predictions are used as input for the second stage which performs a bottom-up clustering to build baselines. The developed method is capable of handling complex layouts as well as curved and arbitrarily oriented text lines. It substantially outperforms current state-of-the-art approaches. For example, for the complex track of the cBAD: ICDAR2017 Competition on Baseline Detection the F value is increased from 0.859 to 0.922. The framework to train and run the ARU-Net is open source.",
            "year": 2018,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "1680083",
                "name": "Gundram Leifert"
              },
              {
                "authorId": "40508719",
                "name": "Tobias Strauß"
              },
              {
                "authorId": "88739357",
                "name": "Johannes Michael"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              }
            ]
          }
        },
        {
          "citedcorpusid": 57246310,
          "isinfluential": false,
          "contexts": [
            "The encoder is composed of convolution and pooling layers (up to 2048 feature maps) and has been pre-trained on natural scene images [29].",
            "Their model follows an encoder-decoder architecture where the encoder is a ResNet-50 [28] pre-trained on natural scene images such as ImageNet [29].",
            "Their model follows an encoder–decoder architecture where the encoder is a ResNet-50 [28] pre-trained on natural scene images such as ImageNet [29]."
          ],
          "intents": [
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "ImageNet: A large-scale hierarchical image database",
            "abstract": "",
            "year": 2009,
            "venue": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "153302678",
                "name": "Jia Deng"
              },
              {
                "authorId": "144847596",
                "name": "Wei Dong"
              },
              {
                "authorId": "2166511",
                "name": "R. Socher"
              },
              {
                "authorId": "2040091191",
                "name": "Li-Jia Li"
              },
              {
                "authorId": "94451829",
                "name": "K. Li"
              },
              {
                "authorId": "48004138",
                "name": "Li Fei-Fei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206594692,
          "isinfluential": false,
          "contexts": [
            "Their model follows an encoder-decoder architecture where the encoder is a ResNet-50 [28] pre-trained on natural scene images such as ImageNet [29].",
            "Their model follows an encoder–decoder architecture where the encoder is a ResNet-50 [28] pre-trained on natural scene images such as ImageNet [29]."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Deep Residual Learning for Image Recognition",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
            "year": 2015,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "1771551",
                "name": "X. Zhang"
              },
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": null,
                "name": "Jian Sun"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211026904,
          "isinfluential": true,
          "contexts": [
            "Object-level IoU P/R F1 P/R R@.85/.95 mAP@.65 mAP Barakat [23] Mechi [24] Renton [25] Doc-UFCN [6] dhSegment [7] Yang [27] Tarride [2] Soullard [30] Melnikov [31] To tackle this problem, metrics originally designed in the Information Retrieval community [34] have been adapted to images and used during the PASCAL VOC Challenge 2012 to compute the Precision at object-level.",
            "Barakat [23] 3 3 Mechi [24] 3 3 3 Renton [25] 3 3 Doc-UFCN [6] 3 3 3 dhSegment [7] 3 3 3 3 Yang [27] 3 3 Tarride [2] 3 3 3 3 Soullard [30] 3 Melnikov [31] 3 3",
            "Following the same idea, Mechi [24] proposed an adaptive U-Net architecture, quite similar to the ﬁrst one, with convolutions in the encoder and transposed convolutions in the decoder.",
            "Following the same idea, Mechi [24] proposed an adaptive U-Net architecture,"
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation in Historical Document Images Using an Adaptive U-Net Architecture",
            "abstract": "On most document image transcription, indexing and retrieval systems, text line segmentation remains one of the most important preliminary task. Hence, the research community working in document image analysis is particularly interested in providing reliable text line segmentation methods. Recently, an increasing interest in using deep learning-based methods has been noted for solving various sub-fields and tasks related to the issues surrounding document image analysis. Thanks to the computer hardware and software evolution, several methods based on using deep architectures continue to outperform the pattern recognition issues and particularly those related to historical document image analysis. Thus, in this paper we present a novel deep learning-based method for text line segmentation of historical documents. The proposed method is based on using an adaptive U-Net architecture. Qualitative and numerical experiments are given using a large number of historical document images collected from the Tunisian national archives and different recent benchmarking datasets provided in the context of ICDAR and ICFHR competitions. Moreover, the results achieved are compared with those obtained using the state-of-the-art methods.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "51133427",
                "name": "Olfa Mechi"
              },
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "2536574",
                "name": "N. Amara"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211027032,
          "isinfluential": false,
          "contexts": [
            "cBAD2019 [39] 7 755 755 1511 49630 46724 209714 × N/A 2980×2569",
            "cBAD2019: The cBAD dataset [39] consists of 3021 annotated document images collected from seven European archives."
          ],
          "intents": [
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "cBAD: ICDAR2019 Competition on Baseline Detection",
            "abstract": "Baseline detection is a simplified text-line extraction that typically serves as pre-processing for Automated Text Recognition. The cBAD competition benchmarks state-of-the-art baseline detection algorithms. It is the successor of cBAD 2017 with a larger dataset that contains more diverse document pages. The images together with the manually annotated groundtruth are made publicly available which allows other teams to benchmark and compare their methods. We could also evaluate the winning method of cBAD 2017 on the newly introduced dataset which now serves as baseline. This competition shows that the performance of automated baseline detection increased substantially since 2017.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1706090",
                "name": "Robert Sablatnig"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211266862,
          "isinfluential": true,
          "contexts": [
            "[30] used this mean mAP for evaluating their historical newspaper segmentation model.",
            "Object-level IoU P/R F1 P/R R@.85/.95 mAP@.65 mAP Barakat [23] Mechi [24] Renton [25] Doc-UFCN [6] dhSegment [7] Yang [27] Tarride [2] Soullard [30] Melnikov [31] To tackle this problem, metrics originally designed in the Information Retrieval community [34] have been adapted to images and used during the PASCAL VOC Challenge 2012 to compute the Precision at object-level.",
            "Barakat [23] 3 3 Mechi [24] 3 3 3 Renton [25] 3 3 Doc-UFCN [6] 3 3 3 dhSegment [7] 3 3 3 3 Yang [27] 3 3 Tarride [2] 3 3 3 3 Soullard [30] 3 Melnikov [31] 3 3",
            "Soullard et al. [30] used this mean mAP for evaluating their historical newspaper segmentation model."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Multi-scale Gated Fully Convolutional DenseNets for semantic labeling of historical newspaper images",
            "abstract": "",
            "year": 2020,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "2652359",
                "name": "Yann Soullard"
              },
              {
                "authorId": "2928766",
                "name": "Pierrick Tranouez"
              },
              {
                "authorId": "145593192",
                "name": "C. Chatelain"
              },
              {
                "authorId": "97014121",
                "name": "Stéphane Nicolas"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 219687205,
          "isinfluential": false,
          "contexts": [
            "[3] recently proposed OrigamiNet, a segmentation-free recognition",
            "Some other pioneer contributions have also investigated line segmentation-free approaches that try to directly recognize the text from paragraphs or pages [3] [4], however these systems still face important limitations and struggle to be effective on complex documents."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "OrigamiNet: Weakly-Supervised, Segmentation-Free, One-Step, Full Page Text Recognition by learning to unfold",
            "abstract": "Text recognition is a major computer vision task with a big set of associated challenges. One of those traditional challenges is the coupled nature of text recognition and segmentation. This problem has been progressively solved over the past decades, going from segmentation based recognition to segmentation free approaches, which proved more accurate and much cheaper to annotate data for. We take a step from segmentation-free single line recognition towards segmentation-free multi-line / full page recognition. We propose a novel and simple neural network module, termed OrigamiNet, that can augment any CTC-trained, fully convolutional single line text recognizer, to convert it into a multi-line version by providing the model with enough spatial capacity to be able to properly collapse a 2D input signal into 1D without losing information. Such modified networks can be trained using exactly their same simple original procedure, and using only unsegmented image and text pairs. We carry out a set of interpretability experiments that show that our trained models learn an accurate implicit line segmentation. We achieve state-of-the-art character error rate on both IAM & ICDAR 2017 HTR benchmarks for handwriting recognition, surpassing all other methods in the literature. On IAM we even surpass single line methods that use accurate localization information during training. Our code is available online at https://github.com/IntuitionMachines/OrigamiNet .",
            "year": 2020,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "144993063",
                "name": "Mohamed Yousef"
              },
              {
                "authorId": "1823550",
                "name": "Tom E. Bishop"
              }
            ]
          }
        },
        {
          "citedcorpusid": 221141556,
          "isinfluential": true,
          "contexts": [
            "Object-level IoU P/R F1 P/R R@.85/.95 mAP@.65 mAP Barakat [23] Mechi [24] Renton [25] Doc-UFCN [6] dhSegment [7] Yang [27] Tarride [2] Soullard [30] Melnikov [31] To tackle this problem, metrics originally designed in the Information Retrieval community [34] have been adapted to images and used during the PASCAL VOC Challenge 2012 to compute the Precision at object-level.",
            "For example, when confronted to touching bounding boxes, Melnikov and Zagaynov [31] suggested removing the ascenders and descenders by reducing the height of the annotated boxes by 30% at the top and the bottom.",
            "ing boxes, Melnikov and Zagaynov [31] suggested to remove the ascenders and descenders by reducing the height of the annotated boxes by 30% at the top and the bottom.",
            "Barakat [23] 3 3 Mechi [24] 3 3 3 Renton [25] 3 3 Doc-UFCN [6] 3 3 3 dhSegment [7] 3 3 3 3 Yang [27] 3 3 Tarride [2] 3 3 3 3 Soullard [30] 3 Melnikov [31] 3 3"
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Fast and Lightweight Text Line Detection on Historical Documents",
            "abstract": "",
            "year": 2020,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "70067928",
                "name": "A. Melnikov"
              },
              {
                "authorId": "137791477",
                "name": "Ivan Zagaynov"
              }
            ]
          }
        },
        {
          "citedcorpusid": 221543615,
          "isinfluential": false,
          "contexts": [
            "[32] have proposed various annotationmasks for detecting and classifying geometric shapes from grayscale images."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Detection of Dense, Overlapping, Geometric Objects",
            "abstract": "Using a unique data collection, we are able to study the detection of dense geometric objects in image data where object density, clarity, and size vary. The data is a large set of black and white images of scatterplots, taken from journals reporting thermophysical property data of metal systems, whose plot points are represented primarily by circles, triangles, and squares. We built a highly accurate single class U-Net convolutional neural network model to identify 97 % of image objects in a defined set of test images, locating the centers of the objects to within a few pixels of the correct locations. We found an optimal way in which to mark our training data masks to achieve this level of accuracy. The optimal markings for object classification, however, required more information in the masks to identify particular types of geometries. We show a range of different patterns used to mark the training data masks, and how they help or hurt our dual goals of location and classification. Altering the annotations in the segmentation masks can increase both the accuracy of object classification and localization on the plots, more than other factors such as adding loss terms to the network calculations. However, localization of the plot points and classification of the geometric objects require different optimal training data.",
            "year": 2020,
            "venue": "International Journal of Artificial Intelligence & Applications",
            "authors": [
              {
                "authorId": "1762734",
                "name": "A. Peskin"
              }
            ]
          }
        },
        {
          "citedcorpusid": 225319541,
          "isinfluential": true,
          "contexts": [
            "To conduct this goal-oriented evaluation, we used a Handwritten Text Recognizer [41] based on the KALDI library [48].",
            "AN-Index 7 N/A 19 3 12 433 62 171 7 N/A 2078×1433 Balsac [37] 7 74 730 92 91 36807 4577 4301 3 26 3882×2418 BNPP 7 5 7 2 3 705 218 358 3 34 3723×5040 Bozen [38] 3 N/A 350 50 50 8367 1043 1140 3 20 3511×2394 cBAD2019 [39] 3 7 755 755 1511 49630 46724 209714 7 N/A 2980×2569 DIVA-HisDB [40] 3 3 60 30 30 6037 2999 2897 7 N/A 4992×3328 HOME-NACR [41] 3 43 000 398 49 49 7004 900 840 3 138 4635×6593 Horae [42] 3 500 522 20 30 12568 270 958 3 28 4096×5236 READ-Complex [43] 3 9 216 27 27 17768 2160 1758 7 N/A 4096×2733 READ-Simple [43] 3 172 22 22 5117 539 723 7 N/A 3947×2721",
            "To conduct this goal-oriented evaluation we used a Handwritten Text Recognizer [41] based on the KALDI library [48].",
            "HOME : The HOME dataset [41] consists in 420 annotated medieval charters selected amongst 43,000 digitized charters from the archives of the Bohemian Crown and the archives of monasteries."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "A comparison of sequential and combined approaches for named entity recognition in a corpus of handwritten medieval charters",
            "abstract": "This paper introduces a new corpus of multilingual medieval handwritten charter images, annotated with full transcription and named entities. The corpus is used to compare two approaches for named entity recognition in historical document images in several languages: on the one hand, a sequential approach, more commonly used, that sequentially applies handwritten text recognition (HTR) and named entity recognition (NER), on the other hand, a combined approach that simultaneously transcribes the image text line and extracts the entities. Experiments conducted on the charter corpus in Latin, early new high German and old Czech for name, date and location recognition demonstrate a superior performance of the combined approach.",
            "year": 2020,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "35101485",
                "name": "Emanuela Boros"
              },
              {
                "authorId": "144340605",
                "name": "Verónica Romero"
              },
              {
                "authorId": "1724401528",
                "name": "Martin Maarand"
              },
              {
                "authorId": "2001793563",
                "name": "Kateřina Zenklová"
              },
              {
                "authorId": "121410548",
                "name": "Jitka Křečková"
              },
              {
                "authorId": "143783065",
                "name": "E. Vidal"
              },
              {
                "authorId": "2064656632",
                "name": "Dominique Stutzmann"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              }
            ]
          }
        },
        {
          "citedcorpusid": 234641195,
          "isinfluential": true,
          "contexts": [
            "Unsurprisingly, according to Table 5 almost all the values are better when using the model trained on the uni-ﬁed labels, sometimes by a considerable margin (+ 33 percentage points for Balsac and + 37 for Bozen).",
            "Balsac : This second dataset [37] consists in 913 images of birth, marriage and death records extracted from 74 Québécois registers.",
            "According to Table 4, training with the normalized ground-truth improves the performances at pixel-level by up to +16 percentage points of IoU on Balsac.",
            "When being less permissive with a IoU of 75 %, this trend continues for Balsac and starts to reverse for Horae.",
            "In most datasets (AN-Index, Balsac, Bozen, BNPP, HOME and Horae), the images are annotated us-ing simple polygons including line ascenders and de-scenders; –",
            "The uniﬁcation process did not improve the results on Balsac and BNPP because the original annotations were already thin and a correct input for the HTR system.",
            "AN-Index 7 N/A 19 3 12 433 62 171 7 N/A 2078×1433 Balsac [37] 7 74 730 92 91 36807 4577 4301 3 26 3882×2418 BNPP 7 5 7 2 3 705 218 358 3 34 3723×5040 Bozen [38] 3 N/A 350 50 50 8367 1043 1140 3 20 3511×2394 cBAD2019 [39] 3 7 755 755 1511 49630 46724 209714 7 N/A 2980×2569 DIVA-HisDB [40] 3 3 60 30 30 6037 2999 2897 7 N/A 4992×3328 HOME-NACR [41] 3 43 000 398 49 49 7004 900 840 3 138 4635×6593 Horae [42] 3 500 522 20 30 12568 270 958 3 28 4096×5236 READ-Complex [43] 3 9 216 27 27 17768 2160 1758 7 N/A 4096×2733 READ-Simple [43] 3 172 22 22 5117 539 723 7 N/A 3947×2721",
            "Indeed, all the ARU-Net results are much lower compared to those of the two other systems, except for the Balsac dataset where the text line polygons are really spaced in the annotations."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "An Overview of the BALSAC Population Database. Past Developments, Current State and Future Prospects",
            "abstract": "The BALSAC database, developed since 1971, contains data on the Quebec population from the beginnings of European settlement in the 17th century to the contemporary period. Today, BALSAC is a major research infrastructure used by researchers from Quebec and elsewhere, both in the social sciences and in the biomedical sciences. This paper presents the evolution and current state of the database and offers a perspective on forthcoming developments. BALSAC contains marriage certificates until 1965. Coverage is complete for Catholic records (80 to 100% of the population depending on the region and the period) and partial for the other denominations. Birth and death certificates from all Catholic parishes have been integrated for the period 1800–1849 and work in underway for 1850–1916. All the records entered in BALSAC are subject to a linkage process which, ultimately, allows the automatic reconstitution of genealogical links and family relationships. The basic principle has remained the same since the beginning, namely to match individuals based on the nominative information contained in the sources. The changes made in recent years and the resulting gains are mostly related to IT advances which now offer more flexibility and increased performance. Future perspectives rest on the diversification of the sources of population data entered or connected to the database and, as a corollary, by continuous optimization of data processing and linkage procedures. In the era of 'big data', BALSAC is gradually moving from a historical population database to a multifaceted infrastructure for interdisciplinary research on the Quebec population.",
            "year": 2020,
            "venue": "",
            "authors": [
              {
                "authorId": "3115011",
                "name": "H. Vézina"
              },
              {
                "authorId": "117993253",
                "name": "Jean-Sébastien Bournival"
              }
            ]
          }
        }
      ]
    },
    "195750543": {
      "citing_paper_info": {
        "title": "Labeling, Cutting, Grouping: An Efficient Text Line Segmentation Method for Medieval Manuscripts",
        "abstract": "This paper introduces a new way for text-line extraction by integrating deep-learning based pre-classification and state-of-the-art segmentation methods. Text-line extraction in complex handwritten documents poses a significant challenge, even to the most modern computer vision algorithms. Historical manuscripts are a particularly hard class of documents as they present several forms of noise, such as degradation, bleed-through, interlinear glosses, and elaborated scripts. In this work, we propose a novel method which uses semantic segmentation at pixel level as intermediate task, followed by a text-line extraction step. We measured the performance of our method on a recent dataset of challenging medieval manuscripts and surpassed state-of-the-art results by reducing the error by 80.7%. Furthermore, we demonstrate the effectiveness of our approach on various other datasets written in different scripts. Hence, our contribution is two-fold. First, we demonstrate that semantic pixel segmentation can be used as strong denoising pre-processing step before performing text line extraction. Second, we introduce a novel, simple and robust algorithm that leverages the high-quality semantic segmentation to achieve a text-line extraction performance of 99.42% line IU on a challenging dataset.",
        "year": 2019,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "38890619",
            "name": "Michele Alberti"
          },
          {
            "authorId": "147382507",
            "name": "Lars Vögtlin"
          },
          {
            "authorId": "8811132",
            "name": "Vinaychandran Pondenkandath"
          },
          {
            "authorId": "2700495",
            "name": "Mathias Seuret"
          },
          {
            "authorId": "1680326",
            "name": "R. Ingold"
          },
          {
            "authorId": "1743758",
            "name": "M. Liwicki"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 10,
        "unique_cited_count": 10,
        "influential_count": 1,
        "detailed_records_count": 10
      },
      "cited_papers": [
        "2908640",
        "58712706",
        "12811834",
        "4765236",
        "15921038",
        "4761833",
        "5683245",
        "15742927",
        "7130275",
        "2123198"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2123198,
          "isinfluential": false,
          "contexts": [
            "s of our algorithm generalise to other scenarios, we ran it on other datasets. Speciﬁcally, we choose the ICDAR 2019 HDRC-Chinese dataset [26], the ICDAR 2013 Handwriting Segmentation Contest dataset [27], the challenging handwritten dataset from the WAHAD Database [28] and the well known George Washingtion dataset [29]. Preliminary results visualised in Figure 6 suggest our proposed method is perform"
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "144429596",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "2265885161",
                "name": "Umapada Pal"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2908640,
          "isinfluential": false,
          "contexts": [
            "ural network. This offers the advantage to focus on the text, and therefore ignores degradations or drawings. The closest work related to our method are multi-step methods, presented by Pastor et al. [14] and Gruüning et al. [15]. The former employs a multi-stage deep learning approach to detect text regions followed by watershed-transform as post-processing step. The latter, performs an unsupervised "
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Complete System for Text Line Extraction Using Convolutional Neural Networks and Watershed Transform",
            "abstract": "",
            "year": 2016,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1403927620",
                "name": "Joan Pastor-Pellicer"
              },
              {
                "authorId": "145181206",
                "name": "Muhammad Zeshan Afzal"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "145816817",
                "name": "María José Castro Bleda"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4761833,
          "isinfluential": false,
          "contexts": [
            "Text-line segmentation is a crucial part of document image processing and remains mainly unsolved, especially in documents with complex layouts [1], [2], [3]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "cBAD: ICDAR2017 Competition on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              },
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4765236,
          "isinfluential": true,
          "contexts": [
            "[3] have used a preliminary version of our proposed method for demonstrating the possibility of classification as proxy task, however, this paper presents a more elaborated and robust method.",
            "polygons enclosing the text-lines in the document (Figure 1c); as proposed for Task-3 at the ICDAR2017 Competition on Layout Analysis for Challenging Medieval Manuscripts [3].",
            "is a collection of three medieval manuscripts that have been selected for the high complexity of their layout [3].",
            "Text-line segmentation is a crucial part of document image processing and remains mainly unsolved, especially in documents with complex layouts [1], [2], [3].",
            "which delivers near state-of-the-art results [24], [3].",
            "The task considered in this work is text-line segmentation i.e. given an RGB image (Figure 1a), produce a list of polygons enclosing the text-lines in the document (Figure 1c); as proposed for Task-3 at the ICDAR2017 Competition on Layout Analysis for Challenging Medieval Manuscripts [3]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['background']",
            "['background']",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "ICDAR2017 Competition on Layout Analysis for Challenging Medieval Manuscripts",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2860677",
                "name": "Fotini Simistira"
              },
              {
                "authorId": "2489964",
                "name": "Manuel Bouillon"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "3424460",
                "name": "Marcel Würsch"
              },
              {
                "authorId": "38890619",
                "name": "Michele Alberti"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5683245,
          "isinfluential": false,
          "contexts": [
            "In the last years the Document Image Analysis (DIA) field has witnessed significant improvements in terms of layout analysis performance [16], [17], [18]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Historical Document Image Segmentation with LDA-Initialized Deep Neural Networks",
            "abstract": "In this paper, we present a novel approach to perform deep neural networks layer-wise weight initialization using Linear Discriminant Analysis (LDA). Typically, the weights of a deep neural network are initialized with: random values, greedy layer-wise pre-training (usually as Deep Belief Network or as auto-encoder) or by re-using the layers from another network (transfer learning). Hence, many training epochs are needed before meaningful weights are learned, or a rather similar dataset is required for seeding a fine-tuning of transfer learning. In this paper, we describe how to turn an LDA into either a neural layer or a classification layer. We analyze the initialization technique on historical documents. First, we show that an LDA-based initialization is quick and leads to a very stable initialization. Furthermore, for the task of layout analysis at pixel level, we investigate the effectiveness of LDA-based initialization and show that it outperforms state-of-the-art random weight initialization methods.",
            "year": 2017,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "38890619",
                "name": "Michele Alberti"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "8811132",
                "name": "Vinaychandran Pondenkandath"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7130275,
          "isinfluential": false,
          "contexts": [
            "Specifically, we choose the ICDAR 2019 HDRC-Chinese dataset [26], the ICDAR 2013 Handwriting Segmentation Contest dataset [27], the challenging handwritten dataset from the WAHAD Database [28] and the well known George Washingtion dataset [29]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ICFHR 2010 Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12811834,
          "isinfluential": false,
          "contexts": [
            "Specifically, we choose the ICDAR 2019 HDRC-Chinese dataset [26], the ICDAR 2013 Handwriting Segmentation Contest dataset [27], the challenging handwritten dataset from the WAHAD Database [28] and the well known George Washingtion dataset [29]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Lexicon-free handwritten word spotting using character HMMs",
            "abstract": "",
            "year": 2012,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "2052881224",
                "name": "Andreas Keller"
              },
              {
                "authorId": "1688695",
                "name": "Volkmar Frinken"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15742927,
          "isinfluential": false,
          "contexts": [
            "[13] extended this method by aggregating with combinatorial algorithms interest points, such as upper and lower text baselines, computed by a deep neural network."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Combining Learned Script Points and Combinatorial Optimization for Text Line Extraction",
            "abstract": "",
            "year": 2015,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "1403927620",
                "name": "Joan Pastor-Pellicer"
              },
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "145816817",
                "name": "María José Castro Bleda"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15921038,
          "isinfluential": false,
          "contexts": [
            "[5] is based on image smearing, which consists of binarizing a document image, and expanding the foreground horizontally and/or vertically to make the connected components merge."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Document Analysis System",
            "abstract": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included.",
            "year": 1982,
            "venue": "IBM Journal of Research and Development",
            "authors": [
              {
                "authorId": "145470231",
                "name": "Kwan Y. Wong"
              },
              {
                "authorId": "34896449",
                "name": "R. Casey"
              },
              {
                "authorId": "1880661",
                "name": "F. Wahl"
              }
            ]
          }
        },
        {
          "citedcorpusid": 58712706,
          "isinfluential": false,
          "contexts": [
            "In the last years the Document Image Analysis (DIA) field has witnessed significant improvements in terms of layout analysis performance [16], [17], [18]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Document Structure and Layout Analysis",
            "abstract": "",
            "year": 2007,
            "venue": "",
            "authors": [
              {
                "authorId": "3185334",
                "name": "A. Namboodiri"
              },
              {
                "authorId": "145295484",
                "name": "Anil K. Jain"
              }
            ]
          }
        }
      ]
    },
    "619938": {
      "citing_paper_info": {
        "title": "Text line segmentation of historical documents: a survey",
        "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
        "year": 2007,
        "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
        "authors": [
          {
            "authorId": "1398902377",
            "name": "Laurence Likforman-Sulem"
          },
          {
            "authorId": "2320185",
            "name": "Abderrazak Zahour"
          },
          {
            "authorId": "2080593310",
            "name": "B. Taconet"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 20,
        "unique_cited_count": 19,
        "influential_count": 2,
        "detailed_records_count": 20
      },
      "cited_papers": [
        "12734250",
        "35215159",
        "22995244",
        "41524799",
        "10143316",
        "130013763",
        "1413694",
        "8696977",
        "40667133",
        "15793605",
        "36363181",
        "12542023",
        "9712378",
        "12262114",
        "3004586",
        "27220892",
        "34005863",
        "8124667",
        "14677442"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1413694,
          "isinfluential": false,
          "contexts": [
            "[40], copyright (1999) with permission from Elsevier)",
            "[40] Repulsive– Baselines Arabic and Pixels (gray Fluctuating Ancient Ottoman attractive Latin levels) lines (same documents network handwriting size) Pal and Datta [41] Piecewise Piecewise Bangla Segmentation Overlapping/ Indian projections linear paths handwriting points touching lines handwritten documents Pu and Shi [45] Hough Clusters Latin Minima Fluctuating Handwritten transform handwriting points lines documents (moving window) Shapiro et al."
          ],
          "intents": [
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Repulsive attractive network for baseline extraction on document images",
            "abstract": "",
            "year": 1997,
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "authors": [
              {
                "authorId": "8222607",
                "name": "Erhan Öztop"
              },
              {
                "authorId": "3049928",
                "name": "Adem Yasar Mülayim"
              },
              {
                "authorId": "1737543",
                "name": "V. Atalay"
              },
              {
                "authorId": "1398326708",
                "name": "F. Yarman-Vural"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3004586,
          "isinfluential": false,
          "contexts": [
            "Large loops are present in the inter-line space and ancient Arabic documents include diacritical points [1]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Off-line Arabic character recognition: the state of the art",
            "abstract": "",
            "year": 1998,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "144434788",
                "name": "A. Amin"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8124667,
          "isinfluential": false,
          "contexts": [
            "ing text from figures (text segmentation) can also be performed on texture grounds [20,36] or by morphological filters [16,37]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Morphological Segmentation of Text and Figures in Renaissance Books (XVI Century)",
            "abstract": "",
            "year": 2000,
            "venue": "International Symposium on Mathematical Morphology and Its Application to Signal and Image Processing",
            "authors": [
              {
                "authorId": "2694815",
                "name": "M. Mengucci"
              },
              {
                "authorId": "3124773",
                "name": "I. Granado"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8696977,
          "isinfluential": false,
          "contexts": [
            "To make such queries possible for handwritten sources of literary works, several projects have been carried out under EU and National Programs: for instance the so-called ‘philological workstation’ Bambi [6,8] and within the Philectre reading and editing environment [47]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Image and text coupling for creating electronic books from manuscripts",
            "abstract": "",
            "year": 1997,
            "venue": "Proceedings of the Fourth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2056080193",
                "name": "Laurent Robert"
              },
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "1794025",
                "name": "É. Lecolinet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9712378,
          "isinfluential": false,
          "contexts": [
            "Antonacopoulos Projection Linear paths Latin Pixels Separated Memorial/personal and Karatzas [3] profiles printed lines records (World War II) Calabretto and Projection Linear paths Cursive Pixels Separated Bambi/Italian Bozzi [8] profiles (grayhandwriting lines manuscripts level image) (16th century) Feldbach and Grouping Baselines Cursive Minima Fluctuating Church registers Tönnies [13] method handwriting points lines (18th, 19th centuries) He and Downton Projections Linear paths Latin Pixels Separated Viadocs/Natural [18] (RXY cuts) printed and lines History Cards handwriting Lebourgeois et al.",
            "In the work of Feldbach and Tönnies [12][13], body baselines are searched in Church Registers images.",
            "In the work of Feldbach and Tönnies [12,13], body baselines are searched in Church Registers images."
          ],
          "intents": [
            "['background']",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line detection and segmentation in historical church registers",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2834467",
                "name": "Markus Feldbach"
              },
              {
                "authorId": "145967589",
                "name": "Klaus D. Tönnies"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10143316,
          "isinfluential": false,
          "contexts": [
            "The segmentation of handwritten documents has also been addressed with the segmentation of address blocks on envelopes and mail pieces [9,10,15,48] and for authentication or recognition purposes [53,60]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "External word segmentation of off-line handwritten text lines",
            "abstract": "",
            "year": 1994,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1928756",
                "name": "G. Seni"
              },
              {
                "authorId": "2064653407",
                "name": "Edward Cohen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12262114,
          "isinfluential": false,
          "contexts": [
            "It generally consists in dating documents, localizing the place where the document was produced, identifying the writer by using characteristics and features extracted from blank spaces, line orientations and fluctuations, word or character shapes [4,27,44]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Classification of Hebrew calligraphic handwriting styles: preliminary results",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "2407309",
                "name": "Itay Bar Yosef"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1686153",
                "name": "I. Dinstein"
              },
              {
                "authorId": "1409114607",
                "name": "Malachi Beit-Arie"
              },
              {
                "authorId": "122675677",
                "name": "Edna Engel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12542023,
          "isinfluential": false,
          "contexts": [
            "[27] are written in Hebrew, in a so-called squared writing as most characters are made of horizontal and vertical strokes.",
            "It generally consists in dating documents, localizing the place where the document was produced, identifying the writer by using characteristics and features extracted from blank spaces, line orientations and fluctuations, word or character shapes [4,27,44]."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An expert vision system for analysis of Hebrew characters and authentication of manuscripts",
            "abstract": "",
            "year": 1991,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "145208646",
                "name": "H. Maître"
              },
              {
                "authorId": "133797874",
                "name": "C. Sirat"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12734250,
          "isinfluential": false,
          "contexts": [
            "More recently, the development of handwritten text databases (IAM database [34]) provides new material for handwritten page segmentation."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A full English sentence database for off-line handwriting recognition",
            "abstract": "",
            "year": 1999,
            "venue": "Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)",
            "authors": [
              {
                "authorId": "37526757",
                "name": "Urs-Viktor Marti"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14677442,
          "isinfluential": false,
          "contexts": [
            "Word spotting techniques [22,46,55] can retrieve similar words in the image document through an image query.",
            "A direct correspondence can then be established between the document image and its content by text/image alignment techniques [55]."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Transcript mapping for historic handwritten document images",
            "abstract": "",
            "year": 2002,
            "venue": "Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2603631",
                "name": "C. Tomai"
              },
              {
                "authorId": "2119453473",
                "name": "Bin Zhang"
              },
              {
                "authorId": "117208225",
                "name": "Venu Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15793605,
          "isinfluential": false,
          "contexts": [
            "Several projects also concern printed material: Debora [5] and Memorial [3].",
            "In the work of Antonacopoulos and Karatzas [3], each minimum of the profile curve is a potential segmentation point."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document image analysis for World War II personal records",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              },
              {
                "authorId": "1694974",
                "name": "Dimosthenis Karatzas"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22995244,
          "isinfluential": false,
          "contexts": [
            "Many techniques have been developed for page segmentation of printed documents (newspapers, scientific journals, magazines, business letters) produced with modern editing tools [2,14,38,39,57]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "The Document Spectrum for Page Layout Analysis",
            "abstract": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >",
            "year": 1993,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1398550688",
                "name": "L. O'Gorman"
              }
            ]
          }
        },
        {
          "citedcorpusid": 27220892,
          "isinfluential": false,
          "contexts": [
            "In Bangla and Telugu text, touching and overlapping occur frequently [23]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "An optical character recognition system for printed Telugu text",
            "abstract": "",
            "year": 2004,
            "venue": "Pattern Analysis and Applications",
            "authors": [
              {
                "authorId": "144407470",
                "name": "C. Lakshmi"
              },
              {
                "authorId": "34612909",
                "name": "C. Patvardhan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 34005863,
          "isinfluential": false,
          "contexts": [
            "The segmentation of handwritten documents has also been addressed with the segmentation of address blocks on envelopes and mail pieces [9,10,15,48] and for authentication or recognition purposes [53,60]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Preprocessing and presorting of envelope images for automatic sorting using OCR",
            "abstract": "",
            "year": 1990,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1798094",
                "name": "A. Downton"
              },
              {
                "authorId": "1711390",
                "name": "G. Leedham"
              }
            ]
          }
        },
        {
          "citedcorpusid": 35215159,
          "isinfluential": false,
          "contexts": [
            "[58,59], the document page is first cut into eight equal columns.",
            "In case of skew or moderate fluctuations of the text lines, the image may be divided into vertical strips and profiles sought inside each strip [58]."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Arabic hand-written text-line extraction",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              },
              {
                "authorId": "144484822",
                "name": "P. Mercy"
              },
              {
                "authorId": "2102325551",
                "name": "Said Ramdane"
              }
            ]
          }
        },
        {
          "citedcorpusid": 36363181,
          "isinfluential": false,
          "contexts": [
            "[49] Projection Linear paths Latin Pixels Skewed Handwritten profiles handwriting separated documents lines Shi and Smearing Cluster Latin Pixels Straight Newton, Galileo Govindaraju [50] (fuzzy run handwriting touching lines manuscripts length) Tseng and Lee [56] Stochastic Non-linear Chinese Pixels Overlapping Handwritten (probabilistic paths handwriting lines documents Viterbi algorithm) Zahour et al.",
            "[49], the global orientation (skew angle) of a handwritten page is first searched by"
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwritten document image segmentation and analysis",
            "abstract": "",
            "year": 1993,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "145852526",
                "name": "V. Shapiro"
              },
              {
                "authorId": "2329505",
                "name": "G. Gluhchev"
              },
              {
                "authorId": "144088894",
                "name": "V. Sgurev"
              }
            ]
          }
        },
        {
          "citedcorpusid": 40667133,
          "isinfluential": false,
          "contexts": [
            "To make such queries possible for handwritten sources of literary works, several projects have been carried out under EU and National Programs: for instance the so-called ‘philological workstation’ Bambi [6,8] and within the Philectre reading and editing environment [47].",
            "To make such queries possible for handwritten sources of literary works, several projects have been carried out under EU and National Programs: for instance the so-called ‘philological workstation’ Bambi [6][8] and within the Philectre reading and editing environment [47].",
            "Antonacopoulos Projection Linear paths Latin Pixels Separated Memorial/personal and Karatzas [3] profiles printed lines records (World War II) Calabretto and Projection Linear paths Cursive Pixels Separated Bambi/Italian Bozzi [8] profiles (grayhandwriting lines manuscripts level image) (16th century) Feldbach and Grouping Baselines Cursive Minima Fluctuating Church registers Tönnies [13] method handwriting points lines (18th, 19th centuries) He and Downton Projections Linear paths Latin Pixels Separated Viadocs/Natural [18] (RXY cuts) printed and lines History Cards handwriting Lebourgeois et al."
          ],
          "intents": [
            "['background']",
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "The Philological Workstation BAMBI (Better Access to Manuscripts and Browsing of Images)",
            "abstract": "This paper presents the results of the European project LIB-3114 for Digital Libraries called BAMBI (Better Access to Manuscripts and Browsing of Images). The project has produced a hypermedia system allowing historians, and more particularly codicologists and philologists, to read manuscripts, transcribe manuscripts, write annotations, and navigate between the words of the transcription and the matching piece of image in the numerized picture of the manuscript. After an introduction on the objectives of the project and the related works, the second part is devoted to the description of the functions and the design of the Philological Workstation. The third part describes how the international standard HyTime (Hypermedia/Time-based Structured Language) has been used as a modelling language to describe works on manuscripts (description, transcription, annotations, links, ...). Finally, the architecture of the BAMBI workstation is presented.",
            "year": 2006,
            "venue": "Journal of Digital Information",
            "authors": [
              {
                "authorId": "1682119",
                "name": "S. Calabretto"
              },
              {
                "authorId": "47510837",
                "name": "A. Bozzi"
              }
            ]
          }
        },
        {
          "citedcorpusid": 41524799,
          "isinfluential": true,
          "contexts": [
            "Variants for obtaining a profile curve may consist in projecting black/white transitions such as in Marti and Bunke [35] or the number of connected components, rather than pixels.",
            "In simple cases of handwritten pages [35], the center of gravity of the connected component is used either to associate the component to the current line or to the following line, or to cut the component into two parts.",
            "In simple cases of handwritten pages (Marti and Bunke [35]), the center of gravity of the connected component is used either to associate the component to the current line or to the following line, or to cut the component into two parts."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "On the influence of vocabulary size and language models in unconstrained handwritten text recognition",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "37526757",
                "name": "Urs-Viktor Marti"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 130013763,
          "isinfluential": false,
          "contexts": [
            "4 detects an ambiguous component during the grouping process when a conflict occurs between two alignments [28,29]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "02 - Une méthode de résolution des conflits d'alignements pour la segmentation des documents manuscrits",
            "abstract": "Text line segmentation is necessary before performing character recognition . \nWe present here an iterative method for extracting text lines in unconstrained \nhandwritten documents which uses clues from laws of perceptual organisation . \nAlignments are build from anchor points, linking components under criteria such \nas proximity, similarity and direction continuity. Conflicts may appear due to \noverlapping or interwoven lines . A local procedure guided by a direction continuity \ncriteria, first seeks to solve the conflict. It may be followed by a global procedure \nwhich is based on the configuration of the alignments and their perceptual quality.",
            "year": 1995,
            "venue": "",
            "authors": [
              {
                "authorId": "2065789074",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2262868173",
                "name": "C. Faure"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": true,
          "contexts": [
            "Likforman-Sulem and Faure have developed in [28] an iterative method based on perceptual grouping for forming alignments, which has been applied to handwritten pages, author drafts and historical documents [29][47].",
            "Smearing Clusters Latin Pixels Separated Debora/books [26] (accumulated printed lines (16th century) gradients) Likforman-Sulem Grouping Strings Latin Connected Fluctuating Philectre/ and Faure [28] handwriting components lines authorial manuscripts Likforman-Sulem Hough Strings Latin Connected Different Philectre/ et al.",
            "4 detects an ambiguous component during the grouping process when a conflict occurs between two alignments [28,29].",
            "Likforman-Sulem and Faure [28] have developed an iterative method based on perceptual grouping for forming alignments, which has been applied to handwritten pages, author drafts and historical documents Fig."
          ],
          "intents": [
            "--",
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "2543004": {
      "citing_paper_info": {
        "title": "Influence of text line segmentation in Handwritten Text Recognition",
        "abstract": "Text line segmentation is the process by which text lines in a document image are localized and extracted. It is an important step in off-line Handwritten Text Recognition (HTR) given that the input of these systems is the line image of the text to be transcribed. A myriad of solutions to the text line segmentation problem have been proposed in the literature. Although these solutions may differ greatly on what is actually applied to perform the segmentation, they can be classified by the level of precision and detail in the final extracted lines. In this paper we study the influence and real needs of different levels of precision and detail in the segmentation solutions in a real HTR task. We test three technics of text line segmentation whose output range from a simple rectangle for each line to a perfect fitted polygon surrounding the detected lines. Experiments have been carried out with a historical collection and results show that good HTR accuracy can be obtained with simple extraction algorithms.",
        "year": 2015,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "144340605",
            "name": "Verónica Romero"
          },
          {
            "authorId": "1928123",
            "name": "Joan Andreu Sánchez"
          },
          {
            "authorId": "3277118",
            "name": "Vicente Bosch"
          },
          {
            "authorId": "11514804",
            "name": "K. Depuydt"
          },
          {
            "authorId": "3302102",
            "name": "J. Does"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 6,
        "influential_count": 2,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "17844687",
        "18718198",
        "19106607",
        "10821687",
        "619938",
        "14196680"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": true,
          "contexts": [
            "transformation [1], [5], [6], dynamic progranuning to search for optimal paths between overlapping text lines [7], making use of HTR training information [8] and natural language inspired proposals [3], [9].",
            "However, this problem can be very difficult when handwritten documents are considered, specially historical documents due to the lack of layout rules and degradation problems [1].",
            "It is an important stage for many tasks in Document Image Analysis of textual documents [1]-[3], such as off-line Handwritten Text Recognition (HTR) [4].",
            "Text line segmentation in printed documents can be easily resolved, even when the documents present warping or some type of degradation [1]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10821687,
          "isinfluential": false,
          "contexts": [
            "Then, as our HTR system is based on HMMs, each preprocessed line image is represented as a sequence of feature vectors [16]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Moment-Based Image Normalization for Handwritten Text Recognition",
            "abstract": "",
            "year": 2012,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2250860",
                "name": "M. Kozielski"
              },
              {
                "authorId": "145817218",
                "name": "Jens Forster"
              },
              {
                "authorId": "145322333",
                "name": "H. Ney"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14196680,
          "isinfluential": true,
          "contexts": [
            "transformation [1], [5], [6], dynamic progranuning to search for optimal paths between overlapping text lines [7], making use of HTR training information [8] and natural language inspired proposals [3], [9].",
            "At the other extreme of the spectrum methods that try to provide a perfectly fitted polygon surrounding the lines can be found [5], [6], [10].",
            "In this paper we generated automatically the polygons using the method presented in [5].",
            "In the literature there are different segmentation techniques that obtain this kind of information [5], [6], [10]­ [12]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line and word segmentation of handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17844687,
          "isinfluential": false,
          "contexts": [
            "In order to evaluate the segmentation methods, we used the ICDAR20 13 Handwritten Segmentation Contest metrics [19] (at line level).",
            "F 2 DR RA DR+RA As contest in [19] shows, none of the current proposed methods were perfect and, in order to use the segmented lines in an HTR system, it is required some form of human super­ vision."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition ICDAR2009 Handwriting Segmentation Contest",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 18718198,
          "isinfluential": false,
          "contexts": [
            "transformation [1], [5], [6], dynamic progranuning to search for optimal paths between overlapping text lines [7], making use of HTR training information [8] and natural language inspired proposals [3], [9].",
            "Lastly, the simplest approach to the text line segmentation problem consists in obtaining a simple rectangle around each line [2], [8].",
            "The simplest method to describe the lines is to obtain a simple rectangle for each localized line [2], [3], [8]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Automatic Line Segmentation and Ground-Truth Alignment of Handwritten Documents",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "3387810",
                "name": "Théodore Bluche"
              },
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              }
            ]
          }
        },
        {
          "citedcorpusid": 19106607,
          "isinfluential": false,
          "contexts": [
            "transformation [1], [5], [6], dynamic progranuning to search for optimal paths between overlapping text lines [7], making use of HTR training information [8] and natural language inspired proposals [3], [9]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Line Detection via an EM Algorithm",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "144858239",
                "name": "Francisco Cruz"
              },
              {
                "authorId": "3045937",
                "name": "O. R. Terrades"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "For a more detailed description of this HTR system, including text line processing, model training and decoding, refers to [4].",
            "The HTR system used in this paper follows the clas­ sical architecture composed of three main modules: docu­ ment image preprocessing, line image feature extraction and Hidden Markov Model (HMM) and language model train­ ing/decoding [4].",
            "It is an important stage for many tasks in Document Image Analysis of textual documents [1]-[3], such as off-line Handwritten Text Recognition (HTR) [4]."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "17135581": {
      "citing_paper_info": {
        "title": "Text Line Segmentation in Images of Handwritten Historical Documents",
        "abstract": "",
        "year": 2008,
        "venue": "2008 First Workshops on Image Processing Theory, Tools and Applications",
        "authors": [
          {
            "authorId": "144837322",
            "name": "A. Sanchez"
          },
          {
            "authorId": "144889138",
            "name": "P. D. Suárez"
          },
          {
            "authorId": "1846903",
            "name": "C. Mello"
          },
          {
            "authorId": "2216183040",
            "name": "A.L.I. Oliveira"
          },
          {
            "authorId": "143755164",
            "name": "V. Alves"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 0,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "15745943",
        "14210437",
        "12751642",
        "14677442",
        "11964016"
      ],
      "citation_details": [
        {
          "citedcorpusid": 11964016,
          "isinfluential": false,
          "contexts": [
            "A recent paper by Wu et al [14] uses a proposed morphology-based text line extraction method to detect text regions in images."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Morphology-based text line extraction",
            "abstract": "",
            "year": 2008,
            "venue": "Machine Vision and Applications",
            "authors": [
              {
                "authorId": "2866936",
                "name": "Jui-Chen Wu"
              },
              {
                "authorId": "144717607",
                "name": "J. Hsieh"
              },
              {
                "authorId": "9407097",
                "name": "Yung-Sheng Chen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12751642,
          "isinfluential": false,
          "contexts": [
            "In general, for the case of historical manuscripts, the document structure extraction is more complex since they have a “free-form” layout [2]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Separating lines of text in free-form handwritten historical documents",
            "abstract": "",
            "year": 2006,
            "venue": "Document Image Analysis for Libraries",
            "authors": [
              {
                "authorId": "2051579",
                "name": "Douglas J. Kennard"
              },
              {
                "authorId": "144055367",
                "name": "W. Barrett"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14210437,
          "isinfluential": false,
          "contexts": [
            "Another approach uses a block-based Hough transform for unconstrained line detection and extraction [ 10 ]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Block-Based Hough Transform Mapping for Text Line Detection in Handwritten Documents",
            "abstract": "In this paper, we present a new text line detection method for unconstrained handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes preprocessing for image enhancement, connected component extraction and average character height estimation. In the second step, a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible false alarms. The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "70602633",
                "name": "K. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14677442,
          "isinfluential": false,
          "contexts": [
            "Second, many authors also presented (in the same paper) some methods for further word extraction in each of the segmented lines [8][15]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Transcript mapping for historic handwritten document images",
            "abstract": "",
            "year": 2002,
            "venue": "Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2603631",
                "name": "C. Tomai"
              },
              {
                "authorId": "2119453473",
                "name": "Bin Zhang"
              },
              {
                "authorId": "117208225",
                "name": "Venu Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15745943,
          "isinfluential": false,
          "contexts": [
            "This simple method counts the number of black pixels in each line of the image."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "PROHIST : An Environment for Image Processing of Historical Documents",
            "abstract": "There is an increasing interest in historical documents nowadays. Due to the fragility of the paper as main media of storing information through the ages, it is necessary to develop means to retrieve this information in a more robust way. At the same time, it must be possible to make this information available to everyone world around. Digital media comes as the more effective way to achieve both these objectives. They are more appropriate for preservation purposes and digital information is easily accessible through the Internet. This paper describes the advances in creating algorithms for image processing of historical documents achieved in the ProHist project. These advances come from thresholding, text segmentation and automatic indexing of the documents. Each one of these steps works together as part of a complete environment for publishing historical documents in a digital library.",
            "year": 2007,
            "venue": "",
            "authors": [
              {
                "authorId": "1846903",
                "name": "C. Mello"
              },
              {
                "authorId": "40057895",
                "name": "Adriano Oliveira"
              }
            ]
          }
        }
      ]
    },
    "56596173": {
      "citing_paper_info": {
        "title": "Neural Text Line Segmentation of Multilingual Print and Handwriting with Recognition-Based Evaluation",
        "abstract": "We present a novel method for detecting text lines in historical handwritten and printed document images. Our hybrid technique begins by leveraging deep neural networks to perform multi-class pixel-wise prediction. The predictor not only discovers text and graphics pixels in the document, but it is also designed to automatically adhere contiguous regions from the same text line while also predicting buffers that prevent disassociated text lines from merging. The system breaks neural \"ties\" through dynamic programming. To the best of our knowledge, our system is the first neural system to predict the entire perimeters of full text lines. Also, to aid in scaling and full-scope awareness, the network during training is initially given small regions of the image to study and then expands its scope to full images as training continues. Our goal for line segmentation is to enable automatic transcription on huge heterogenous collections of historical images, so we use transcription accuracy as our metric. We document and leverage our state-of-the-art transcription system as an evaluation harness for scoring our segmenter along with various other competitor segmenters. We then show the effectiveness of our system as it relates to other systems by comparing it to both known data sets (IAM) and to three 50K-word \"in the wild\" test sets consisting of (a) US handwritten wills and deeds, (b) US historical newsprint images, and (c) Spanish Church and Government records.",
        "year": 2018,
        "venue": "International Conference on Frontiers in Handwriting Recognition",
        "authors": [
          {
            "authorId": "1686074",
            "name": "Patrick Schone"
          },
          {
            "authorId": "52605921",
            "name": "Christian Hargraves"
          },
          {
            "authorId": "52362408",
            "name": "Jon Morrey"
          },
          {
            "authorId": "144712237",
            "name": "Rachael Day"
          },
          {
            "authorId": "52502044",
            "name": "Mindy Jacox"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 4,
        "unique_cited_count": 4,
        "influential_count": 0,
        "detailed_records_count": 4
      },
      "cited_papers": [
        "27942783",
        "16636683",
        "12888813",
        "7153187"
      ],
      "citation_details": [
        {
          "citedcorpusid": 7153187,
          "isinfluential": false,
          "contexts": [
            "[17], [18]) where one can exploit color and shadowing."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Instance-Sensitive Fully Convolutional Networks",
            "abstract": "Fully convolutional networks (FCNs) have been proven very successful for semantic segmentation, but the FCN outputs are unaware of object instances. In this paper, we develop FCNs that are capable of proposing instance-level segment candidates. In contrast to the previous FCN that generates one score map, our FCN is designed to compute a small set of instance-sensitive score maps, each of which is the outcome of a pixel-wise classifier of a relative position to instances. On top of these instance-sensitive score maps, a simple assembling module is able to output instance candidate at each position. In contrast to the recent DeepMask method for segmenting instances, our method does not have any high-dimensional layer related to the mask resolution, but instead exploits image local coherence for estimating instances. We present competitive results of instance segment proposal on both PASCAL VOC and MS COCO.",
            "year": 2016,
            "venue": "European Conference on Computer Vision",
            "authors": [
              {
                "authorId": "3304536",
                "name": "Jifeng Dai"
              },
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2153682629",
                "name": "Yi Li"
              },
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": null,
                "name": "Jian Sun"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12888813,
          "isinfluential": false,
          "contexts": [
            "These ideas have also been applied to tasks like gland detection [19] which has much in common with text line segmentation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Gland Instance Segmentation Using Deep Multichannel Neural Networks",
            "abstract": "Objective: A new image instance segmentation method is proposed to segment individual glands (instances) in colon histology images. This process is challenging since the glands not only need to be segmented from a complex background, they must also be individually identified. Methods: We leverage the idea of image-to-image prediction in recent deep learning by designing an algorithm that automatically exploits and fuses complex multichannel information—regional, location, and boundary cues—in gland histology images. Our proposed algorithm, a deep multichannel framework, alleviates heavy feature design due to the use of convolutional neural networks and is able to meet multifarious requirements by altering channels. Results: Compared with methods reported in the 2015 MICCAI Gland Segmentation Challenge and other currently prevalent instance segmentation methods, we observe state-of-the-art results based on the evaluation metrics. Conclusion: The proposed deep multichannel algorithm is an effective method for gland instance segmentation. Significance:  The generalization ability of our model not only enable the algorithm to solve gland instance segmentation problems, but the channel is also alternative that can be replaced for a specific task.",
            "year": 2016,
            "venue": "IEEE Transactions on Biomedical Engineering",
            "authors": [
              {
                "authorId": "48615144",
                "name": "Yan Xu"
              },
              {
                "authorId": "50024187",
                "name": "Yang Li"
              },
              {
                "authorId": "2125060481",
                "name": "Yipei Wang"
              },
              {
                "authorId": "2142436397",
                "name": "Mingyuan Liu"
              },
              {
                "authorId": "2118166235",
                "name": "Yubo Fan"
              },
              {
                "authorId": "145400644",
                "name": "M. Lai"
              },
              {
                "authorId": "13178880",
                "name": "E. Chang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16636683,
          "isinfluential": false,
          "contexts": [
            "Also, in the interior of the network, as identified in [24], we use an 8x8 convolution."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Network In Network",
            "abstract": "We propose a novel deep network structure called \"Network In Network\" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.",
            "year": 2013,
            "venue": "International Conference on Learning Representations",
            "authors": [
              {
                "authorId": "2115913164",
                "name": "Min Lin"
              },
              {
                "authorId": "35370244",
                "name": "Qiang Chen"
              },
              {
                "authorId": "143653681",
                "name": "Shuicheng Yan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 27942783,
          "isinfluential": false,
          "contexts": [
            "Stewart and Barrett [22] leveraged a comparable network to semantically segment images into print, handwriting, pictures, etc.",
            "We learned from [22] that this situation can be remedied by making the network predict separate layers or planes of information that represent each label type and by ensuring that each batch contains representative samples of each label type, and through the use of squared error as a loss function."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Document Image Page Segmentation and Character Recognition as Semantic Segmentation",
            "abstract": "",
            "year": 2017,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "38924250",
                "name": "S. Stewart"
              },
              {
                "authorId": "144055367",
                "name": "W. Barrett"
              }
            ]
          }
        }
      ]
    },
    "5252785": {
      "citing_paper_info": {
        "title": "Binarization-Free Text Line Segmentation for Historical Documents Based on Interest Point Clustering",
        "abstract": "",
        "year": 2012,
        "venue": "2012 10th IAPR International Workshop on Document Analysis Systems",
        "authors": [
          {
            "authorId": "1697354",
            "name": "A. Garz"
          },
          {
            "authorId": "153745355",
            "name": "Andreas Fischer"
          },
          {
            "authorId": "1706090",
            "name": "Robert Sablatnig"
          },
          {
            "authorId": "1720945",
            "name": "H. Bunke"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 11,
        "unique_cited_count": 11,
        "influential_count": 0,
        "detailed_records_count": 11
      },
      "cited_papers": [
        "619938",
        "12637182",
        "15793605",
        "3345452",
        "14651494",
        "18324118",
        "9187881",
        "35215159",
        "1913486",
        "6717725",
        "17376493"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "…INTRODUCTION\nAutomatic segmentation of historical document page images is an open research field; algorithms are required to be robust with respect to background artifacts such as clutter, stains and noise, as well as artifacts due to aging, and touching or interfering lines [1]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1913486,
          "isinfluential": false,
          "contexts": [
            "Various authors [8], [9] adapted the global PP such that skewed text blocks, converging or merging text lines are segmented correctly."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 3345452,
          "isinfluential": false,
          "contexts": [
            "First identifying the word clusters which need to be split, we efficiently apply the seam carving approach only in a local area, thus further improving the efficiency of the method."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Optimal matching problem in detection and recognition performance evaluation",
            "abstract": "",
            "year": 2002,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "2146562400",
                "name": "Gang Liu"
              },
              {
                "authorId": "1710238",
                "name": "R. Haralick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6717725,
          "isinfluential": false,
          "contexts": [
            "Various authors [8], [9] adapted the global PP such that skewed text blocks, converging or merging text lines are segmented correctly.",
            "Most importantly, the threshold on the scale and sensitivity of the DOG interest points that determines the parts-of-character interest points needs to be optimized (see Section II-A)."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Seam Carving for Content-Aware Image Resizing",
            "abstract": "Effective resizing of images should not only use geometric constraints, but consider the image content as well. We present a simple image operator called seam carving that supports content-aware image resizing for both reduction and expansion. A seam is an optimal 8-connected path of pixels on a single image from top to bottom, or left to right, where optimality is defined by an image energy function. By repeatedly carving out or inserting seams in one direction we can change the aspect ratio of an image. By applying these operators in both directions we can retarget the image to a new size. The selection and order of seams protect the content of the image, as defined by the energy function. Seam carving can also be used for image content enhancement and object removal. We support various visual saliency measures for defining the energy of an image, and can also include user input to guide the process. By storing the order of seams in an image we create multi-size images, that are able to continuously change in real time to fit a given size.",
            "year": 2007,
            "venue": "ACM Transactions on Graphics",
            "authors": [
              {
                "authorId": "1815078",
                "name": "S. Avidan"
              },
              {
                "authorId": "2947946",
                "name": "Ariel Shamir"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": false,
          "contexts": [
            "First identifying the word clusters which need to be split, we efficiently apply the seam carving approach only in a local area, thus further improving the efficiency of the method."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12637182,
          "isinfluential": false,
          "contexts": [
            "Another commonly used approach is\nThis work has been supported by Austrian Science Fund (Grant P23133) and Swiss National Science Foundation (Project CRSI22 125220).\nbased on Projection Profiles (PP) [2], [8]–[11] for both binary and gray-scale images.",
            "Handwritten documents do not have strict layout rules and thus line segmentation methods need to be invariant to layout inconsistencies, irregularities in script and writing style, skew, and fluctuating text lines [1]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Layout Analysis of Handwritten Historical Documents for Searching the Archive of the Cabinet of the Dutch Queen",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1806816",
                "name": "M. Bulacu"
              },
              {
                "authorId": "84540883",
                "name": "Rutger van Koert"
              },
              {
                "authorId": "1799278",
                "name": "Lambert Schomaker"
              },
              {
                "authorId": "3296970",
                "name": "T. V. D. Zant"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14651494,
          "isinfluential": false,
          "contexts": [
            "Nicolaou and Gatos [14] use so-called local minima tracers which follow the line spacing in order to shred the document page in lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "On-Line Handwritten Text Line Detection Using Dynamic Programming",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1693905",
                "name": "Emanuel Indermühle"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15793605,
          "isinfluential": false,
          "contexts": [
            "Another commonly used approach is\nThis work has been supported by Austrian Science Fund (Grant P23133) and Swiss National Science Foundation (Project CRSI22 125220).\nbased on Projection Profiles (PP) [2], [8]–[11] for both binary and gray-scale images."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document image analysis for World War II personal records",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              },
              {
                "authorId": "1694974",
                "name": "Dimosthenis Karatzas"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17376493,
          "isinfluential": false,
          "contexts": [
            "Another commonly used approach is\nThis work has been supported by Austrian Science Fund (Grant P23133) and Swiss National Science Foundation (Project CRSI22 125220).\nbased on Projection Profiles (PP) [2], [8]–[11] for both binary and gray-scale images."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Line segmentation for degraded handwritten historical documents",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 18324118,
          "isinfluential": false,
          "contexts": [
            "Various authors [8], [9] adapted the global PP such that skewed text blocks, converging or merging text lines are segmented correctly."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Combining Alignment Results for Historical Handwritten Document Analysis",
            "abstract": "",
            "year": 2009,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1693905",
                "name": "Emanuel Indermühle"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 35215159,
          "isinfluential": false,
          "contexts": [
            "Another commonly used approach is\nThis work has been supported by Austrian Science Fund (Grant P23133) and Swiss National Science Foundation (Project CRSI22 125220).\nbased on Projection Profiles (PP) [2], [8]–[11] for both binary and gray-scale images."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Arabic hand-written text-line extraction",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              },
              {
                "authorId": "144484822",
                "name": "P. Mercy"
              },
              {
                "authorId": "2102325551",
                "name": "Said Ramdane"
              }
            ]
          }
        }
      ]
    },
    "229678052": {
      "citing_paper_info": {
        "title": "Multiple Document Datasets Pre-training Improves Text Line Detection With Deep Neural Networks",
        "abstract": "In this paper, we introduce a fully convolutional network for the document layout analysis task. While state-of-the-art methods are using models pre-trained on natural scene images, our method Doc-UFCN relies on a U-shaped model trained from scratch for detecting objects from historical documents. We consider the line segmentation task and more generally the layout analysis problem as a pixel-wise classification task then our model outputs a pixel-labeling of the input images. We show that Doc-UFCN outperforms state-of-the-art methods on various datasets and also demonstrate that the pre-trained parts on natural scene images are not required to reach good results. In addition, we show that pre-training on multiple document datasets can improve the performances. We evaluate the models using various metrics to have a fair and complete comparison between the methods.",
        "year": 2020,
        "venue": "International Conference on Pattern Recognition",
        "authors": [
          {
            "authorId": "1380222130",
            "name": "Mélodie Boillet"
          },
          {
            "authorId": "2156685",
            "name": "Christopher Kermorvant"
          },
          {
            "authorId": "1690399",
            "name": "T. Paquet"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 6,
        "influential_count": 2,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "56597514",
        "211026904",
        "206594692",
        "3496842",
        "3719281",
        "33748389"
      ],
      "citation_details": [
        {
          "citedcorpusid": 3496842,
          "isinfluential": false,
          "contexts": [
            "4) DIVA-HisDB: This last dataset [18] contains 120 annotated pages extracted from 3 different manuscripts."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "DIVA-HisDB: A Precisely Annotated Large Dataset of Challenging Medieval Manuscripts",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2860677",
                "name": "Fotini Simistira"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "2065610080",
                "name": "Nicole Eichenberger"
              },
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3719281,
          "isinfluential": true,
          "contexts": [
            "In addition, they added residual blocks to the U-Net architecture.",
            "First a hierarchical neural network (ARU-Net) is applied to detect the text lines.",
            "Mechi et al. [10] presented an adaptive U-Net architecture for text line segmentation.",
            "This ARU-Net is an extended version of the U-Net [12] architecture."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
            "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .",
            "year": 2015,
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "authors": [
              {
                "authorId": "1737326",
                "name": "O. Ronneberger"
              },
              {
                "authorId": "152702479",
                "name": "P. Fischer"
              },
              {
                "authorId": "1710872",
                "name": "T. Brox"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33748389,
          "isinfluential": false,
          "contexts": [
            "[11] proposed a more complicated architecture composed of two stages to detect baselines in historical documents."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A two-stage method for text line detection in historical documents",
            "abstract": "This work presents a two-stage text line detection method for historical documents. Each detected text line is represented by its baseline. In a first stage, a deep neural network called ARU-Net labels pixels to belong to one of the three classes: baseline, separator and other. The separator class marks beginning and end of each text line. The ARU-Net is trainable from scratch with manageably few manually annotated example images (<50\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$<\\,50$$\\end{document}). This is achieved by utilizing data augmentation strategies. The network predictions are used as input for the second stage which performs a bottom-up clustering to build baselines. The developed method is capable of handling complex layouts as well as curved and arbitrarily oriented text lines. It substantially outperforms current state-of-the-art approaches. For example, for the complex track of the cBAD: ICDAR2017 Competition on Baseline Detection the F value is increased from 0.859 to 0.922. The framework to train and run the ARU-Net is open source.",
            "year": 2018,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "1680083",
                "name": "Gundram Leifert"
              },
              {
                "authorId": "40508719",
                "name": "Tobias Strauß"
              },
              {
                "authorId": "88739357",
                "name": "Johannes Michael"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56597514,
          "isinfluential": false,
          "contexts": [
            "[9] proposed a fully convolutional network for text line detection."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation for Challenging Handwritten Document Images using Fully Convolutional Network",
            "abstract": "This paper presents a method for text line segmentation of challenging historical manuscript images. These manuscript images contain narrow interline spaces with touching components, interpenetrating vowel signs and inconsistent font types and sizes. In addition, they contain curved, multi-skewed and multi-directed side note lines within a complex page layout. Therefore, bounding polygon labeling would be very difficult and time consuming. Instead we rely on line masks that connect the components on the same text line. Then these line masks are predicted using a Fully Convolutional Network (FCN). In the literature, FCN has been successfully used for text line segmentation of regular handwritten document images. The present paper shows that FCN is useful with challenging manuscript images as well. Using a new evaluation metric that is sensitive to over segmentation as well as under segmentation, testing results on a publicly available challenging handwritten dataset are comparable with the results of a previous work on the same dataset.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "39240022",
                "name": "M. Kassis"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206594692,
          "isinfluential": true,
          "contexts": [
            "We also tested blocks with 5 convolutions with different rates ([1, 1, 1, 1, 1] and [1, 2, 4, 8, 16]).",
            "The initial learning rate is 5e-5 and we chose to use a ResNet50 [8] as pre-trained encoder.",
            "The encoding path corresponds to a modified version of the ResNet-50 [8] architecture.",
            "This model differs from DocUFCN since its encoder follows the ResNet-50 [8] achitecture and is pre-trained on natural scene images."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Deep Residual Learning for Image Recognition",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
            "year": 2015,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "1771551",
                "name": "X. Zhang"
              },
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": null,
                "name": "Jian Sun"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211026904,
          "isinfluential": false,
          "contexts": [
            "[10] presented an adaptive U-Net architecture for text line segmentation.",
            "[10], we decided to replace the unpooling layers of Yang’s model by transposed convolutions in order to keep the same resolution on both the input and output."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation in Historical Document Images Using an Adaptive U-Net Architecture",
            "abstract": "On most document image transcription, indexing and retrieval systems, text line segmentation remains one of the most important preliminary task. Hence, the research community working in document image analysis is particularly interested in providing reliable text line segmentation methods. Recently, an increasing interest in using deep learning-based methods has been noted for solving various sub-fields and tasks related to the issues surrounding document image analysis. Thanks to the computer hardware and software evolution, several methods based on using deep architectures continue to outperform the pattern recognition issues and particularly those related to historical document image analysis. Thus, in this paper we present a novel deep learning-based method for text line segmentation of historical documents. The proposed method is based on using an adaptive U-Net architecture. Qualitative and numerical experiments are given using a large number of historical document images collected from the Tunisian national archives and different recent benchmarking datasets provided in the context of ICDAR and ICFHR competitions. Moreover, the results achieved are compared with those obtained using the state-of-the-art methods.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "51133427",
                "name": "Olfa Mechi"
              },
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "2536574",
                "name": "N. Amara"
              }
            ]
          }
        }
      ]
    },
    "232234980": {
      "citing_paper_info": {
        "title": "A Text Line Extraction Method for Archival Document Transcription",
        "abstract": "In order to reinforce the enrichment and exploitation of archival collections, a growing need for computer-aided tools able to assist researchers, historians and archivists in historical document image transcription has been recently highlighted. However, to ensure an efficient text transcription from archival handwritten and printed document images, a robust text line segmentation task is required. Thus, in this paper we propose a method able to extract whole text lines from archival document images. The proposed method is firstly based on our previous work reported at ICDAR 2019, which focused on extracting only the main area covering the text core. A post-processing step is introduced in this paper to extract whole text lines (including the ascender and descender components). The post-processing step is based on topological structural analysis of binary images. To illustrate the effectiveness of the proposed method, we have conducted experiments on archival document images collected from the Tunisian national archives. Qualitative and quantitative results are reported and discussed.",
        "year": 2020,
        "venue": "International Multi-Conference on Systems, Signals & Devices",
        "authors": [
          {
            "authorId": "51133427",
            "name": "Olfa Mechi"
          },
          {
            "authorId": "2131158",
            "name": "Maroua Mehri"
          },
          {
            "authorId": "1680326",
            "name": "R. Ingold"
          },
          {
            "authorId": "2536574",
            "name": "N. Amara"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 9,
        "unique_cited_count": 8,
        "influential_count": 1,
        "detailed_records_count": 9
      },
      "cited_papers": [
        "6253771",
        "16993962",
        "9976076",
        "211026904",
        "5987534",
        "2292615",
        "60062262",
        "19363314"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2292615,
          "isinfluential": false,
          "contexts": [
            "Recently, deep methods have gained a great attention by many researchers since they have achieved highly satisfactory results for solving many applications and various sub-ﬁelds of computer vision and pattern recognition (e.g., object detection [14], biomedical image [15])."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "SMC faster R-CNN: Toward a scene-specialized multi-object detector",
            "abstract": "",
            "year": 2017,
            "venue": "Computer Vision and Image Understanding",
            "authors": [
              {
                "authorId": "2191195",
                "name": "A. Mhalla"
              },
              {
                "authorId": "144032408",
                "name": "T. Chateau"
              },
              {
                "authorId": "3433367",
                "name": "H. Maâmatou"
              },
              {
                "authorId": "3342453",
                "name": "S. Gazzah"
              },
              {
                "authorId": "2536574",
                "name": "N. Amara"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5987534,
          "isinfluential": false,
          "contexts": [
            "Chen et al. [19] proposed a CNN architecture for segmenting text into lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Convolutional Neural Networks for Page Segmentation of Historical Document Images",
            "abstract": "This paper presents a page segmentation method for handwritten historical document images based on a Convolutional Neural Network (CNN). We consider page segmentation as a pixel labeling problem, i.e., each pixel is classified as one of the predefined classes. Traditional methods in this area rely on hand-crafted features carefully tuned considering prior knowledge. In contrast, we propose to learn features from raw image pixels using a CNN. While many researchers focus on developing deep CNN architectures to solve different problems, we train a simple CNN with only one convolution layer. We show that the simple architecture achieves competitive results against other deep architectures on different public datasets. Experiments also demonstrate the effectiveness and superiority of the proposed method compared to previous methods.",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "153819461",
                "name": "Kai Chen"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6253771,
          "isinfluential": false,
          "contexts": [
            "Ryu et al. [11] applied the superpixel technique to extract the connected components.",
            "Ryu et al. [11]’ method is only well-suited for documents written in Latin and Chinese."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Language-Independent Text-Line Extraction Algorithm for Handwritten Documents",
            "abstract": "",
            "year": 2014,
            "venue": "IEEE Signal Processing Letters",
            "authors": [
              {
                "authorId": "2189947",
                "name": "Jewoong Ryu"
              },
              {
                "authorId": "2463454",
                "name": "H. Koo"
              },
              {
                "authorId": "2287480732",
                "name": "Nam Ik Cho"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9976076,
          "isinfluential": false,
          "contexts": [
            "It has been demonstrated that by using a global thresholding approach such as the Otsu’s method, an adequate and fast foreground/background separation in historical document images is ensured [24]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A texture-based pixel labeling approach for historical books",
            "abstract": "",
            "year": 2015,
            "venue": "Pattern Analysis and Applications",
            "authors": [
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1399368454",
                "name": "Petra Gomez-Krämer"
              },
              {
                "authorId": "1826457",
                "name": "P. Héroux"
              },
              {
                "authorId": "143858619",
                "name": "A. Boucher"
              },
              {
                "authorId": "1682986",
                "name": "R. Mullot"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16993962,
          "isinfluential": false,
          "contexts": [
            "Bruzzone et al. [8] and Shi et al. [9] used the projection proﬁle technique for text line segmentation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line separation for complex document images using fuzzy runlength",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 19363314,
          "isinfluential": false,
          "contexts": [
            "…slanted and skewed), irregular spacing between text lines, signiﬁcant degradation (e.g., scanning noise, smear, aging effects, uneven background or foreground and uneven illumination), various types of noise (e.g., ink stains, stamp, signature, handwritten notes and back-to-front interference) [4]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "ICDAR 2015 competition on text line detection in historical documents",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40474413",
                "name": "Michael Murdock"
              },
              {
                "authorId": "27437299",
                "name": "S. Reid"
              },
              {
                "authorId": "2067534881",
                "name": "Blaine Hamilton"
              },
              {
                "authorId": "48163297",
                "name": "J. Reese"
              }
            ]
          }
        },
        {
          "citedcorpusid": 60062262,
          "isinfluential": false,
          "contexts": [
            "Minima points and gravity centers of connected components are often used in the Hough-based methods [7]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A natural learning algorithm based on Hough transform for text lines extraction in handwritten documents",
            "abstract": "",
            "year": 1999,
            "venue": "",
            "authors": [
              {
                "authorId": "2139654987",
                "name": "Yao Pu"
              },
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211026904,
          "isinfluential": true,
          "contexts": [
            "The proposed method is ﬁrstly based on our previous work [5], which focused on extracting only the main area covering the text core, called the X-height.",
            "Figure 2 illustrates the results obtained by using the adaptive U-Net architecture for segmenting text lines at X-height level [5].",
            "We proposed in [5] an adaptive U-Net architecture to segment both Arabic and Latin handwritten historical document images.",
            "Thus, an extension of our previous work [5] is required to reﬁne and improve the text line segmentation results and subsequently to provide sufﬁcient information for end-to-end text recognition framework.",
            "In our previous work [5], we proposed a deep neural network for text line segmentation of historical documents.",
            "Afterward, based on the obtained X-height contours by using the adaptive U-Net architecture below [5], we propose to extract whole text lines (including the ascender and de-scender components) based on topological structural analysis of binary images achieved by the Otsu’s method.",
            "Figure 4 depicts the results obtained by applying both the proposed method in this paper and our previous work [5] on a document image of the ANT dataset.",
            "Thus, an extension of our previous work [5] is required to reﬁne and improve the text line segmentation results and subsequently to provide sufﬁcient information for text recognition task."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['background']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation in Historical Document Images Using an Adaptive U-Net Architecture",
            "abstract": "On most document image transcription, indexing and retrieval systems, text line segmentation remains one of the most important preliminary task. Hence, the research community working in document image analysis is particularly interested in providing reliable text line segmentation methods. Recently, an increasing interest in using deep learning-based methods has been noted for solving various sub-fields and tasks related to the issues surrounding document image analysis. Thanks to the computer hardware and software evolution, several methods based on using deep architectures continue to outperform the pattern recognition issues and particularly those related to historical document image analysis. Thus, in this paper we present a novel deep learning-based method for text line segmentation of historical documents. The proposed method is based on using an adaptive U-Net architecture. Qualitative and numerical experiments are given using a large number of historical document images collected from the Tunisian national archives and different recent benchmarking datasets provided in the context of ICDAR and ICFHR competitions. Moreover, the results achieved are compared with those obtained using the state-of-the-art methods.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "51133427",
                "name": "Olfa Mechi"
              },
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "2536574",
                "name": "N. Amara"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Renton et al. [17] applied the fully convolutional networks to extract text base-lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "5107590": {
      "citing_paper_info": {
        "title": "Text Line for Historical Document Images",
        "abstract": "In this paper we present a new approach for text line segmentation that works directly on gray-scale document images. Our algorithm constructs distance transform directly on the gray-scale images, which is used to compute two types of seams: medial seams and separating seams. A medial seam is a chain of pixels that crosses the text area of a text line and a separating seam is a path that passes between two consecutive rows. The medial seam determines a text line and the separating seams define the upper and lower boundaries of the text line. The medial and separating seams propagate according to energy maps, which are defined based on the constructed distance transform. We have performed various experimental results on different datasets and received encouraging results.",
        "year": 2011,
        "venue": "",
        "authors": [
          {
            "authorId": "1741845",
            "name": "Raid Saabni"
          },
          {
            "authorId": "145766704",
            "name": "Abedelkadir Asi"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          },
          {
            "authorId": "1399102470",
            "name": "Ben-Gurion"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 16,
        "unique_cited_count": 13,
        "influential_count": 3,
        "detailed_records_count": 16
      },
      "cited_papers": [
        "2123198",
        "14935721",
        "15554170",
        "7695150",
        "59896225",
        "41601768",
        "16503365",
        "74439549",
        "17376493",
        "6717725",
        "14210437",
        "12534822",
        "1913486"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1913486,
          "isinfluential": true,
          "contexts": [
            "Nicolaou and Gatos [25] used local minima tracers, to follow the white-most and black-most paths from one side to other in order to shred the image into text line areas.",
            "The first system was presented by Nicolaou and Gatos [25], shreds an image to lines using tracers to follow the white-most and blackmost paths.",
            "Table 1: Results achieved by our system (the third column) compared to the system presented in [25](the first Column) and the system presented in [32](the second Column).",
            "[22] G. Louloudis, B. Gatos, I. Pratikakis, and K. Halatsis.",
            "[9] B. Gatos, A. Antonacopoulos, and N. Stamatopoulos.",
            "[21] G Louloudis, B Gatos, I Pratikakis, and C Halatsis.",
            "[25] Anguelos Nicolaou and Basilis Gatos."
          ],
          "intents": [
            "--",
            "['methodology']",
            "['result']",
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 2123198,
          "isinfluential": true,
          "contexts": [
            "We have evaluated our system using 40 Arabic pages from Juma’a Al-Majid Center (Dubai), 10 pages in Chinese, and 50 pages taken from ICDAR2007 Handwriting Segmentation Contest dataset [9] including English, French, German, and Greek.",
            "The 40 Arabic pages include 853 lines and 24, 876 word-parts, the 50 pages from the ICDAR2007 contest have 967 lines.",
            "The first row compares results of the three systems on a subset of the ICDAR2007 [9] test set and the second row uses our private collection, which is based on documents from Juma’a Almajed Center, Dubai.",
            "We have received similar results with the other 50 pages from the ICDAR2007 contest."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "144429596",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "2265885161",
                "name": "Umapada Pal"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6717725,
          "isinfluential": true,
          "contexts": [
            "Our novel approach to separating text blocks into lines was inspired and built upon the seam carving work [6], which resizes images in a content-aware fashion.",
            "[6] Shai Avidan and Ariel Shamir.",
            "Avidan and Shamir [6] discussed several operators for calculating the energy function to determine pixels with minimum energy for content-aware resizing."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Seam Carving for Content-Aware Image Resizing",
            "abstract": "Effective resizing of images should not only use geometric constraints, but consider the image content as well. We present a simple image operator called seam carving that supports content-aware image resizing for both reduction and expansion. A seam is an optimal 8-connected path of pixels on a single image from top to bottom, or left to right, where optimality is defined by an image energy function. By repeatedly carving out or inserting seams in one direction we can change the aspect ratio of an image. By applying these operators in both directions we can retarget the image to a new size. The selection and order of seams protect the content of the image, as defined by the energy function. Seam carving can also be used for image content enhancement and object removal. We support various visual saliency measures for defining the energy of an image, and can also include user input to guide the process. By storing the order of seams in an image we create multi-size images, that are able to continuously change in real time to fit a given size.",
            "year": 2007,
            "venue": "ACM Transactions on Graphics",
            "authors": [
              {
                "authorId": "1815078",
                "name": "S. Avidan"
              },
              {
                "authorId": "2947946",
                "name": "Ariel Shamir"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7695150,
          "isinfluential": false,
          "contexts": [
            "Toivanen [34] developed the distance transform on curved space (DTOCS) and the weighted distance transform on curved space, where the distance metric is defined as difference between the gray values of the pixels along the minimal path; i."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "New geodesic distance transforms for grayscale images",
            "abstract": "In this paper, two new geodesic distance transforms for gray-scale images are presented. The first transform, the Distance Transform on Curved Space (DTOCS), performs the calculation with integer numbers. The second transform, the Weighted Distance Transform on Curved Space (WDTOCS), gives a weighted distance map with real numbers for an arbitrary gray-value image. Both transforms give a distance map in which the distance value of a single point corresponds to the length of the shortest discrete 8-path to the nearest background point. Both differ from the previously presented gray-level distance transforms by not weighting the distance values directly by the gray-values, but by gray-value differences.",
            "year": 2002,
            "venue": "",
            "authors": [
              {
                "authorId": "1822700",
                "name": "P. Toivanen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12534822,
          "isinfluential": false,
          "contexts": [
            "Extracting unconstrained handwritten text lines from document images is a basic procedure for various document processing applications and it has received enormous attention over the last several decades."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A scale space approach for automatically segmenting words from historical handwritten documents",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              },
              {
                "authorId": "1845217",
                "name": "Jamie L. Rothfeder"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14210437,
          "isinfluential": false,
          "contexts": [
            "The Hough transform methodology was exploited for text line segmentation [18, 22, 21]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Block-Based Hough Transform Mapping for Text Line Detection in Handwritten Documents",
            "abstract": "In this paper, we present a new text line detection method for unconstrained handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes preprocessing for image enhancement, connected component extraction and average character height estimation. In the second step, a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible false alarms. The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "70602633",
                "name": "K. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14935721,
          "isinfluential": false,
          "contexts": [
            "Using a set of line filters [29] to emphasize text line patterns may remove dots and storkes from documets sometimes and this would lead to erroneous segmentation and hence recognition of text lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text-Line Extraction Using a Convolution of Isotropic Gaussian Filter with a Set of Line Filters",
            "abstract": "",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "145461897",
                "name": "S. S. Bukhari"
              },
              {
                "authorId": "1688013",
                "name": "F. Shafait"
              },
              {
                "authorId": "1733858",
                "name": "T. Breuel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15554170,
          "isinfluential": false,
          "contexts": [
            "Keywords Seam Carving, Line Extraction, Multilingual, Signed Distance Transform, Dynamic programming, Handwriting"
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Word image matching using dynamic time warping",
            "abstract": "",
            "year": 2003,
            "venue": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "2352980",
                "name": "T. Rath"
              },
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16503365,
          "isinfluential": false,
          "contexts": [
            "Hybrid schemes combine techniques from top-down and bottom-up classes to yield better results."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A new scheme for unconstrained handwritten text-line segmentation",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17376493,
          "isinfluential": false,
          "contexts": [
            "Bottom-up approaches group basic elements, such as pixels or connected components, to form text line patterns."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Line segmentation for degraded handwritten historical documents",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 41601768,
          "isinfluential": false,
          "contexts": [
            "To determine a seam that passes along the medial axis of a text line and crosses its components, we use an energy map based on a gray-level distance transform, introduced by Levi and Montanari [16].",
            "[16] G. Levi and U. Montanari."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "A Grey-Weighted Skeleton",
            "abstract": "",
            "year": 1970,
            "venue": "Information and Control",
            "authors": [
              {
                "authorId": "143760024",
                "name": "G. Levi"
              },
              {
                "authorId": "1690890",
                "name": "U. Montanari"
              }
            ]
          }
        },
        {
          "citedcorpusid": 59896225,
          "isinfluential": false,
          "contexts": [
            "Projection profile, which was initially used to determine text-lines in printed image documents, was modified and adapted to work on sub-blocks and stripes [35, 24, 36, 12] (see Section ??)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "DOCUMENT ANALYSIS WITH AN EXPERT SYSTEM",
            "abstract": "",
            "year": 1986,
            "venue": "",
            "authors": [
              {
                "authorId": "145916951",
                "name": "G. Nagy"
              },
              {
                "authorId": "145062511",
                "name": "S. Seth"
              },
              {
                "authorId": "3700278",
                "name": "Spotswood D. Stoddard"
              }
            ]
          }
        },
        {
          "citedcorpusid": 74439549,
          "isinfluential": false,
          "contexts": [
            "Extracting lines from slices with adaptive orientation could save the recalculation of the signed distance map and improve the runtime performance of the algorithm."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Master Thesis in Pharmacy",
            "abstract": "",
            "year": 2008,
            "venue": "",
            "authors": [
              {
                "authorId": "33634172",
                "name": "A. Wilhelmson"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Keywords Seam Carving, Line Extraction, Multilingual, Signed Distance Transform, Dynamic programming, Handwriting"
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Various approaches rely on grouping techniques to determine text line in document images, while applying heuristic rules [8], learning algorithms [39], nearest neighbor [10], and searching trees [26].",
            "Gorman [10] presented a typical grouping method, which rules are based on the geometric relationship among k-nearest neighbors."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Extracting unconstrained handwritten text lines from document images is a basic procedure for various document processing applications and it has received enormous attention over the last several decades."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "239009676": {
      "citing_paper_info": {
        "title": "Accurate Fine-Grained Layout Analysis for the Historical Tibetan Document Based on the Instance Segmentation",
        "abstract": "Accurate layout analysis without subsequent text-line segmentation remains an ongoing challenge, especially when facing the Kangyur, a kind of historical Tibetan document featuring considerable touching components and mottled background. Aiming at identifying different regions in document images, layout analysis is indispensable for subsequent procedures such as character recognition. However, there was only a little research being carried out to perform line-level layout analysis which failed to deal with the Kangyur. To obtain the optimal results, a fine-grained sub-line level layout analysis approach is presented. Firstly, we introduced an accelerated method to build the dataset which is dynamic and reliable. Secondly, enhancement had been made to the SOLOv2 according to the characteristics of the Kangyur. Then, we fed the enhanced SOLOv2 with the prepared annotation file during the training phase. Once the network is trained, instances of the text line, sentence, and titles can be segmented and identified during the inference stage. The experimental results show that the proposed method delivers a decent 72.7% average precision on our dataset. In general, this preliminary research provides insights into the fine-grained sub-line level layout analysis and testifies the SOLOv2-based approaches. We also believe that the proposed methods can be adopted on other language documents with various layouts.",
        "year": 2021,
        "venue": "IEEE Access",
        "authors": [
          {
            "authorId": "2284827556",
            "name": "Penghai Zhao"
          },
          {
            "authorId": "2254980",
            "name": "Weilan Wang"
          },
          {
            "authorId": "2113441483",
            "name": "Zhengqi Cai"
          },
          {
            "authorId": "2116628830",
            "name": "Guowei Zhang"
          },
          {
            "authorId": "2140043273",
            "name": "Yuqi Lu"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 13,
        "unique_cited_count": 13,
        "influential_count": 4,
        "detailed_records_count": 13
      },
      "cited_papers": [
        "67856179",
        "23806350",
        "49651094",
        "3429309",
        "206594692",
        "104291983",
        "53214848",
        "211228089",
        "3496842",
        "5987534",
        "24139",
        "10716717",
        "201124789"
      ],
      "citation_details": [
        {
          "citedcorpusid": 24139,
          "isinfluential": true,
          "contexts": [
            "8), and set the pixel value of ith text line to 20 × i, i ∈ [1, 8].",
            "recognition algorithms [1], [2] converting them into the encoded text.",
            "Ten classes are considered based on the object type and location which are linei, i ∈ [1, 8], ‘ltitle’, and ‘rtitle’."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "An End-to-End Trainable Neural Network for Image-Based Sequence Recognition and Its Application to Scene Text Recognition",
            "abstract": "Image-based sequence recognition has been a long-standing research topic in computer vision. In this paper, we investigate the problem of scene text recognition, which is among the most important and challenging tasks in image-based sequence recognition. A novel neural network architecture, which integrates feature extraction, sequence modeling and transcription into a unified framework, is proposed. Compared with previous systems for scene text recognition, the proposed architecture possesses four distinctive properties: (1) It is end-to-end trainable, in contrast to most of the existing algorithms whose components are separately trained and tuned. (2) It naturally handles sequences in arbitrary lengths, involving no character segmentation or horizontal scale normalization. (3) It is not confined to any predefined lexicon and achieves remarkable performances in both lexicon-free and lexicon-based scene text recognition tasks. (4) It generates an effective yet much smaller model, which is more practical for real-world application scenarios. The experiments on standard benchmarks, including the IIIT-5K, Street View Text and ICDAR datasets, demonstrate the superiority of the proposed algorithm over the prior arts. Moreover, the proposed algorithm performs well in the task of image-based music score recognition, which evidently verifies the generality of it.",
            "year": 2015,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2276155",
                "name": "Baoguang Shi"
              },
              {
                "authorId": "145905113",
                "name": "X. Bai"
              },
              {
                "authorId": "2146721",
                "name": "C. Yao"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3429309,
          "isinfluential": false,
          "contexts": [
            "Most document layout analysis approaches utilized semantic segmentation neural networks [3]–[5] to divide document images into various zones."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs",
            "abstract": "In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or ‘atrous convolution’, as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed “DeepLab” system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7 percent mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.",
            "year": 2016,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "34192119",
                "name": "Liang-Chieh Chen"
              },
              {
                "authorId": "2776496",
                "name": "G. Papandreou"
              },
              {
                "authorId": "2010660",
                "name": "Iasonas Kokkinos"
              },
              {
                "authorId": "1702318",
                "name": "K. Murphy"
              },
              {
                "authorId": "145081362",
                "name": "A. Yuille"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3496842,
          "isinfluential": false,
          "contexts": [
            "Over the past ten years, only a few layout analysis datasets were released including the widely used PubLayNet [21] and DIVA-hisDB [22].",
            "The annotation of the DIVA-hisDB was generated by adopting the approach mentioned in [23]."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "DIVA-HisDB: A Precisely Annotated Large Dataset of Challenging Medieval Manuscripts",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2860677",
                "name": "Fotini Simistira"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "2065610080",
                "name": "Nicole Eichenberger"
              },
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5987534,
          "isinfluential": false,
          "contexts": [
            "datasets had demonstrated the effectiveness of the proposed method [11]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Convolutional Neural Networks for Page Segmentation of Historical Document Images",
            "abstract": "This paper presents a page segmentation method for handwritten historical document images based on a Convolutional Neural Network (CNN). We consider page segmentation as a pixel labeling problem, i.e., each pixel is classified as one of the predefined classes. Traditional methods in this area rely on hand-crafted features carefully tuned considering prior knowledge. In contrast, we propose to learn features from raw image pixels using a CNN. While many researchers focus on developing deep CNN architectures to solve different problems, we train a simple CNN with only one convolution layer. We show that the simple architecture achieves competitive results against other deep architectures on different public datasets. Experiments also demonstrate the effectiveness and superiority of the proposed method compared to previous methods.",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "153819461",
                "name": "Kai Chen"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10716717,
          "isinfluential": true,
          "contexts": [
            "We feed the topdown pathway of HRFPN with the concatenation of feature maps from C2 to C5.",
            "Res-101-FPN denotes the backbone consisting of ResNet101 and FPN whereas the X-101-FPN represents using ResNeXt and HRFPN as the backbone.",
            "The input scale experiment is designed to ﬁnd the optimal size of the input image which adopts SOLOv2 with a ResNet-50 and FPN backbone (Res-50-FPN) and the ‘10-8’ contour type.",
            "Thus, FPN is effective for extracting features of both large and small objects, which are entire text lines and short sentences in the historical Tibetan document images.",
            "The adopted backbone of SOLOv2 is composed of the FPN [26] which has two pathways.",
            "The proposed method whose backbone consists of ResNeXt101 and HRFPN delivers the best performance across several metrics.",
            "Similar structure of the high-resolution feature pyramid network (HRFPN) [28] was designed to augment the high-resolution representation of the backbone.",
            "Table 3 compares the performance of different types of contours when the SOLOv2(Res-50-FPN) is utilized, and the size of the input image is 1024 times 1024.",
            "Mask kernel branch is designed to learn the dynamic convolution kernel where the input feature F with the size of h × w × E and the output space is S × S × E ( h and w are height and width of output at each stage of FPN, E correspond to input channels)."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "['background']",
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Feature Pyramid Networks for Object Detection",
            "abstract": "Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But pyramid representations have been avoided in recent object detectors that are based on deep convolutional networks, partially because they are slow to compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "33493200",
                "name": "Tsung-Yi Lin"
              },
              {
                "authorId": "3127283",
                "name": "Piotr Dollár"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              },
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "1790580",
                "name": "Bharath Hariharan"
              },
              {
                "authorId": "50172592",
                "name": "Serge J. Belongie"
              }
            ]
          }
        },
        {
          "citedcorpusid": 23806350,
          "isinfluential": false,
          "contexts": [
            "The annotation of the DIVA-hisDB was generated by adopting the approach mentioned in [23]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Creating Ground Truth for Historical Manuscripts with Document Graphs and Scribbling Interaction",
            "abstract": "",
            "year": 2016,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "2860677",
                "name": "Fotini Simistira"
              },
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 49651094,
          "isinfluential": false,
          "contexts": [
            "For text and sub-line regions, there will be subsequent recognition algorithms [1, 2] converting them into the encoded text."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Mask TextSpotter: An End-to-End Trainable Neural Network for Spotting Text with Arbitrary Shapes",
            "abstract": "Unifying text detection and text recognition in an end-to-end training fashion has become a new trend for reading text in the wild, as these two tasks are highly relevant and complementary. In this paper, we investigate the problem of scene text spotting, which aims at simultaneous text detection and recognition in natural images. An end-to-end trainable neural network named as Mask TextSpotter is presented. Different from the previous text spotters that follow the pipeline consisting of a proposal generation network and a sequence-to-sequence recognition network, Mask TextSpotter enjoys a simple and smooth end-to-end learning procedure, in which both detection and recognition can be achieved directly from two-dimensional space via semantic segmentation. Further, a spatial attention module is proposed to enhance the performance and universality. Benefiting from the proposed two-dimensional representation on both detection and recognition, it easily handles text instances of irregular shapes, for instance, curved text. We evaluate it on four English datasets and one multi-language dataset, achieving consistently superior performance over state-of-the-art methods in both detection and end-to-end text recognition tasks. Moreover, we further investigate the recognition module of our method separately, which significantly outperforms state-of-the-art methods on both regular and irregular text datasets for scene text recognition.",
            "year": 2018,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "10344582",
                "name": "Pengyuan Lyu"
              },
              {
                "authorId": "8155680",
                "name": "Minghui Liao"
              },
              {
                "authorId": "2146721",
                "name": "C. Yao"
              },
              {
                "authorId": null,
                "name": "Wenhao Wu"
              },
              {
                "authorId": "145905113",
                "name": "X. Bai"
              }
            ]
          }
        },
        {
          "citedcorpusid": 53214848,
          "isinfluential": false,
          "contexts": [
            "and thus achieved finer performance [16].",
            "Here, we borrowed the ideas from the previously proposed research [16], [17] to decompose the image into several text lines."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Research on Text Line Segmentation of Historical Tibetan Documents Based on the Connected Component Analysis",
            "abstract": "",
            "year": 2018,
            "venue": "Chinese Conference on Pattern Recognition and Computer Vision",
            "authors": [
              {
                "authorId": "2108941572",
                "name": "Yiqun Wang"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              },
              {
                "authorId": "49970018",
                "name": "Zhenjiang Li"
              },
              {
                "authorId": "51481292",
                "name": "Yuehui Han"
              },
              {
                "authorId": "2115451526",
                "name": "Xiaojuan Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 67856179,
          "isinfluential": true,
          "contexts": [
            "However, the improved Mask R-CNN training with the roughly annotated data failed to produce acceptable results, probably due to adjacent or overlapped text lines.",
            "Abdullah Almutairi conducted a region-level layout analysis by employing the instance segmentation network Mask R-CNN which is language-agnostic and can deconstruct newspaper images into various parts [19].",
            "From Table 4 we can see that these networks with the restricted size of the head, such as Mask R-CNN and YOLACT, achieve lower performance than the SOLOv2 which has no restriction on the mask head.",
            "Compared with Mask R-CNN, these networks remove the restriction on the mask head and may generate higher-quality masks.",
            "In his major study, Prusty demonstrated the effectiveness of the Mask R-CNN which reached 64.76% of AP50 on the Indiscapes dataset [20].",
            "Neither vanilla nor improved Mask R-CNN obtained satisfactory results (see right column of Fig.3 (b) (c)).",
            "Abhishek Prusty et al . adopted Mask R-CNN for automatic, instance-level spatial layout parsing of historical Indic manuscripts images.",
            "Mask R-CNN was adopted to parse the layout of historical Tibetan images in response to the views of Prusty A’s studies [20].",
            "3 (a), we used the Labelme tool [24] to roughly annotate ten images and trained the network to try to fully exploit the potential of Mask R-CNN (even overﬁtting could happen).",
            "The quantitative comparison experiments were conducted to compare our methods with other previous state-of-the-art approaches including Mask R-CNN and our improved version (Mask R-CNN*), Mask Scoring R-CNN [39], YOLACT [40], SOLO [25], and SOLOv2 [7].",
            "The quantitative comparison experiments were conducted to compare our methods with other previous state-of-theart approaches including Mask R-CNN and our improved version (Mask R-CNN), Mask Scoring R-CNN [40],",
            "Mask R-CNN is capable of extracting individual text lines from the image and is proved to be effective on certain datasets.",
            "However, Mask R-CNN cannot be applied to the historical document images directly because of the frequent occurrence of segmentation mistakes.",
            "A few existing line-level layout analysis research treated layout analysis as an instance segmentation task and employed the instance segmentation network to identify different text lines, such as Mask R-CNN [6]."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "['methodology']",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Mask Scoring R-CNN",
            "abstract": "Letting a deep network be aware of the quality of its own predictions is an interesting yet important problem. In the task of instance segmentation, the confidence of instance classification is used as mask quality score in most instance segmentation frameworks. However, the mask quality, quantified as the IoU between the instance mask and its ground truth, is usually not well correlated with classification score. In this paper, we study this problem and propose Mask Scoring R-CNN which contains a network block to learn the quality of the predicted instance masks. The proposed network block takes the instance feature and the corresponding predicted mask together to regress the mask IoU. The mask scoring strategy calibrates the misalignment between mask quality and mask score, and improves instance segmentation performance by prioritizing more accurate mask predictions during COCO AP evaluation. By extensive evaluations on the COCO dataset, Mask Scoring R-CNN brings consistent and noticeable gain with different models and outperforms the state-of-the-art Mask R-CNN. We hope our simple and effective approach will provide a new direction for improving instance segmentation. The source code of our method is available at \\url{https://github.com/zjhuang22/maskscoring_rcnn}.",
            "year": 2019,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2109606861",
                "name": "Zhaojin Huang"
              },
              {
                "authorId": "47033130",
                "name": "Lichao Huang"
              },
              {
                "authorId": "2183266",
                "name": "Yongchao Gong"
              },
              {
                "authorId": "48908475",
                "name": "Chang Huang"
              },
              {
                "authorId": "2443233",
                "name": "Xinggang Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 104291983,
          "isinfluential": false,
          "contexts": [
            "Similar structure of the high-resolution feature pyramid network (HRFPN) introduced in [28] was designed to augment the high-resolution representation of the backbone."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "High-Resolution Representations for Labeling Pixels and Regions",
            "abstract": "High-resolution representation learning plays an essential role in many vision problems, e.g., pose estimation and semantic segmentation. The high-resolution network (HRNet)~\\cite{SunXLW19}, recently developed for human pose estimation, maintains high-resolution representations through the whole process by connecting high-to-low resolution convolutions in \\emph{parallel} and produces strong high-resolution representations by repeatedly conducting fusions across parallel convolutions. \nIn this paper, we conduct a further study on high-resolution representations by introducing a simple yet effective modification and apply it to a wide range of vision tasks. We augment the high-resolution representation by aggregating the (upsampled) representations from all the parallel convolutions rather than only the representation from the high-resolution convolution as done in~\\cite{SunXLW19}. This simple modification leads to stronger representations, evidenced by superior results. We show top results in semantic segmentation on Cityscapes, LIP, and PASCAL Context, and facial landmark detection on AFLW, COFW, $300$W, and WFLW. In addition, we build a multi-level representation from the high-resolution representation and apply it to the Faster R-CNN object detection framework and the extended frameworks. The proposed approach achieves superior results to existing single-model networks on COCO object detection. The code and models have been publicly available at \\url{this https URL}.",
            "year": 2019,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "143819050",
                "name": "Ke Sun"
              },
              {
                "authorId": "145940718",
                "name": "Yang Zhao"
              },
              {
                "authorId": "51151760",
                "name": "Borui Jiang"
              },
              {
                "authorId": "46806979",
                "name": "Tianheng Cheng"
              },
              {
                "authorId": "144025674",
                "name": "Bin Xiao"
              },
              {
                "authorId": "1718355",
                "name": "Dong Liu"
              },
              {
                "authorId": "145353089",
                "name": "Yadong Mu"
              },
              {
                "authorId": "2443233",
                "name": "Xinggang Wang"
              },
              {
                "authorId": "2109194747",
                "name": "Wenyu Liu"
              },
              {
                "authorId": "1688516",
                "name": "Jingdong Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 201124789,
          "isinfluential": false,
          "contexts": [
            "Over the past ten years, only a few layout analysis datasets were released including the widely used PubLayNet [21] and DIVA-hisDB [22].",
            "Its annotated region’s edge shows much more precision compared to the PubLayNet, but likewise failed to establish the distinction of individual text lines.",
            "With a total number of more than 360 thousand document images at the polygon-level, the PubLayNet dataset was generated by automatically matching the XML representations and the content of PDF from PubMed CentralTM."
          ],
          "intents": [
            "['methodology']",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "PubLayNet: Largest Dataset Ever for Document Layout Analysis",
            "abstract": "Recognizing the layout of unstructured digital documents is an important step when parsing the documents into structured machine-readable format for downstream applications. Deep neural networks that are developed for computer vision have been proven to be an effective method to analyze layout of document images. However, document layout datasets that are currently publicly available are several magnitudes smaller than established computing vision datasets. Models have to be trained by transfer learning from a base model that is pre-trained on a traditional computer vision dataset. In this paper, we develop the PubLayNet dataset for document layout analysis by automatically matching the XML representations and the content of over 1 million PDF articles that are publicly available on PubMed Central. The size of the dataset is comparable to established computer vision datasets, containing over 360 thousand document images, where typical document layout elements are annotated. The experiments demonstrate that deep neural networks trained on PubLayNet accurately recognize the layout of scientific articles. The pre-trained models are also a more effective base mode for transfer learning on a different document domain. We release the dataset (https://github.com/ibm-aur-nlp/PubLayNet) to support development and evaluation of more advanced models for document layout analysis.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2113309578",
                "name": "Xu Zhong"
              },
              {
                "authorId": "2328282",
                "name": "Jianbin Tang"
              },
              {
                "authorId": "1399097376",
                "name": "Antonio Jimeno-Yepes"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206594692,
          "isinfluential": true,
          "contexts": [
            "The bottom-up pathway uses ResNet [27] to extract features at different levels.",
            "Res-101-FPN denotes the backbone consisting of ResNet101 and FPN whereas the X-101-FPN represents using ResNeXt and HRFPN as the backbone.",
            "The input scale experiment is designed to ﬁnd the optimal size of the input image which adopts SOLOv2 with a ResNet-50 and FPN backbone (Res-50-FPN) and the ‘10-8’ contour type.",
            "In addition, we replace the ResNet in the bottom-up pathway with ResNeXt [29] which is supposed to demonstrate a stronger performance than the original one.",
            "bottom-up pathway uses ResNet [27] to extract features at different levels."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Deep Residual Learning for Image Recognition",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
            "year": 2015,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "1771551",
                "name": "X. Zhang"
              },
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": null,
                "name": "Jian Sun"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211228089,
          "isinfluential": false,
          "contexts": [
            "Abdullah Almutairi conducted a region-level layout analysis by employing the instance segmentation network Mask R-CNN which is language-agnostic and can deconstruct newspaper images into various parts [19]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Instance Segmentation of Newspaper Elements Using Mask R-CNN",
            "abstract": "Newspaper digitization has gained wide interest around the world. Archives of digitized newspapers contain a wealth of information that spans decades. To extract this abundance of information, optical character recognition (OCR) techniques are used. However, as a first step, the newspaper pages should be logically deconstructed into articles to gain meaningful knowledge. This is difficult due to the complex layout of newspapers and the various styles, shapes, and languages of newspaper articles. Newspaper pages also contain other elements besides articles, such as advertisements that come in multiple shapes and forms, and top headers that contain information about the newspaper's issue and page. Therefore, it is important to detect these elements before information extraction begins. In this paper, we present a deep learning solution for the problem of newspaper page semantic segmentation of the main newspaper elements (articles, advertisements, and page headers). We employed the instance segmentation method mask R-CNN mask_rcnn to create a language-agnostic model that logically deconstructs a newspaper page raw image into its main elements based only on its visual features. We show the results of experiments that display the accuracy and robustness of our model.",
            "year": 2019,
            "venue": "International Conference on Machine Learning and Applications",
            "authors": [
              {
                "authorId": "2337306810",
                "name": "Abdullah Almutairi"
              },
              {
                "authorId": "51061517",
                "name": "Meshal Alfarhood"
              }
            ]
          }
        }
      ]
    },
    "220903282": {
      "citing_paper_info": {
        "title": "docExtractor: An off-the-shelf historical document element extraction",
        "abstract": "We present docExtractor, a generic approach for extracting visual elements such as text lines or illustrations from historical documents without requiring any real data annotation. We demonstrate it provides high-quality performances as an off-the-shelf system across a wide variety of datasets and leads to results on par with state-of-the-art when fine-tuned. We argue that the performance obtained without fine-tuning on a specific dataset is critical for applications, in particular in digital humanities, and that the line-level page segmentation we address is the most relevant for a general purpose element extraction engine. We rely on a fast generator of rich synthetic documents and design a fully convolutional network, which we show to generalize better than a detection-based approach. Furthermore, we introduce a new public dataset dubbed IlluHisDoc dedicated to the fine evaluation of illustration segmentation in historical documents.",
        "year": 2020,
        "venue": "International Conference on Frontiers in Handwriting Recognition",
        "authors": [
          {
            "authorId": "1643955575",
            "name": "Tom Monnier"
          },
          {
            "authorId": "48582897",
            "name": "Mathieu Aubry"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 10,
        "unique_cited_count": 10,
        "influential_count": 2,
        "detailed_records_count": 10
      },
      "cited_papers": [
        "173188066",
        "3719281",
        "33748389",
        "16516553",
        "2272015",
        "27494128",
        "5575601",
        "49417857",
        "206594692",
        "33693201"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2272015,
          "isinfluential": false,
          "contexts": [
            "[7] and Zhong et al."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Learning to Extract Semantic Structure from Documents Using Multimodal Fully Convolutional Neural Networks",
            "abstract": "We present an end-to-end, multimodal, fully convolutional network for extracting semantic structures from document images. We consider document semantic structure extraction as a pixel-wise segmentation task, and propose a unified model that classifies pixels based not only on their visual appearance, as in the traditional page segmentation task, but also on the content of underlying text. Moreover, we propose an efficient synthetic document generation process that we use to generate pretraining data for our network. Once the network is trained on a large set of synthetic documents, we fine-tune the network on unlabeled real documents using a semi-supervised approach. We systematically study the optimum network architecture and show that both our multimodal approach and the synthetic data pretraining significantly boost the performance.",
            "year": 2017,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2112096491",
                "name": "Xiao Yang"
              },
              {
                "authorId": "8020964",
                "name": "Ersin Yumer"
              },
              {
                "authorId": "2934421",
                "name": "P. Asente"
              },
              {
                "authorId": "1389971134",
                "name": "Mike Kraley"
              },
              {
                "authorId": "1852261",
                "name": "Daniel Kifer"
              },
              {
                "authorId": "145157784",
                "name": "C. Lee Giles"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3719281,
          "isinfluential": false,
          "contexts": [
            "1) Network architecture: Similar to [16], we use a simple encoder-decoder architecture combining the descriptive power of ResNet [15] with the localization recovering capacity of U-Net [14].",
            "The ICDAR2017 competition on BAseline Detection (cBAD2017) [9] was won by the approach proposed by Fink et al. [13], a sliding-window dense prediction using a U-Net architecture [14].",
            "[13], a sliding-window dense prediction using a U-Net architecture [14]."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
            "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .",
            "year": 2015,
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "authors": [
              {
                "authorId": "1737326",
                "name": "O. Ronneberger"
              },
              {
                "authorId": "152702479",
                "name": "P. Fischer"
              },
              {
                "authorId": "1710872",
                "name": "T. Brox"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5575601,
          "isinfluential": false,
          "contexts": [
            "the encoder, which significantly speeds up the training, and Xavier initialization [25] for the other convolutional layers."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Understanding the difficulty of training deep feedforward neural networks",
            "abstract": "Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert & Weston, 2008; Mnih & Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a “better” basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact).",
            "year": 2010,
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "authors": [
              {
                "authorId": "3119801",
                "name": "Xavier Glorot"
              },
              {
                "authorId": "1751762",
                "name": "Yoshua Bengio"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16516553,
          "isinfluential": true,
          "contexts": [
            "For memory reasons, we process one sample per batch and use Instance Normalization [23] with a momentum of 0.",
            "For memory reasons, we process one sample per batch and use Instance Normalization [23] with a momentum of 0.1 instead of batch normalization."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Instance Normalization: The Missing Ingredient for Fast Stylization",
            "abstract": "It this paper we revisit the fast stylization method introduced in Ulyanov et. al. (2016). We show how a small change in the stylization architecture results in a significant qualitative improvement in the generated images. The change is limited to swapping batch normalization with instance normalization, and to apply the latter both at training and testing times. The resulting method can be used to train high-performance architectures for real-time image generation. The code will is made available on github at this https URL. Full paper can be found at arXiv:1701.02096.",
            "year": 2016,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "145276680",
                "name": "Dmitry Ulyanov"
              },
              {
                "authorId": "1687524",
                "name": "A. Vedaldi"
              },
              {
                "authorId": "1740145",
                "name": "V. Lempitsky"
              }
            ]
          }
        },
        {
          "citedcorpusid": 27494128,
          "isinfluential": false,
          "contexts": [
            "We use instead the xheight representation [12] which not only enables to infer the baseline but also we believe to be more robust, easier to generalize and more directly useful for downstream text"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Text Line Segmentation Using Fully Convolutional Network",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "47689382",
                "name": "G. Renton"
              },
              {
                "authorId": "1712446",
                "name": "Clément Chatelain"
              },
              {
                "authorId": "143680806",
                "name": "Sébastien Adam"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33693201,
          "isinfluential": false,
          "contexts": [
            "[19] proposed toolkits to expand an existing annotated document dataset by generating similar semi-synthetic documents with the help of advanced data augmentation strategies."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "DocCreator: A New Software for Creating Synthetic Ground-Truthed Document Images",
            "abstract": "Most digital libraries that provide user-friendly interfaces, enabling quick and intuitive access to their resources, are based on Document Image Analysis and Recognition (DIAR) methods. Such DIAR methods need ground-truthed document images to be evaluated/compared and, in some cases, trained. Especially with the advent of deep learning-based approaches, the required size of annotated document datasets seems to be ever-growing. Manually annotating real documents has many drawbacks, which often leads to small reliably annotated datasets. In order to circumvent those drawbacks and enable the generation of massive ground-truthed data with high variability, we present DocCreator, a multi-platform and open-source software able to create many synthetic image documents with controlled ground truth. DocCreator has been used in various experiments, showing the interest of using such synthetic images to enrich the training stage of DIAR tools.",
            "year": 2017,
            "venue": "Journal of Imaging",
            "authors": [
              {
                "authorId": "1748667",
                "name": "N. Journet"
              },
              {
                "authorId": "1698969",
                "name": "M. Visani"
              },
              {
                "authorId": "2236496",
                "name": "Boris Mansencal"
              },
              {
                "authorId": "1853118",
                "name": "V. C. Kieu"
              },
              {
                "authorId": "50382409",
                "name": "Antoine Billy"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33748389,
          "isinfluential": false,
          "contexts": [
            "[17] which added an attention mechanism and developed a sophisticated post-processing step",
            "Our performance could likely be further improved, for example using the superpixel-based post-processing of [17] which they demonstrate to provide a remarkable boost."
          ],
          "intents": [
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "A two-stage method for text line detection in historical documents",
            "abstract": "This work presents a two-stage text line detection method for historical documents. Each detected text line is represented by its baseline. In a first stage, a deep neural network called ARU-Net labels pixels to belong to one of the three classes: baseline, separator and other. The separator class marks beginning and end of each text line. The ARU-Net is trainable from scratch with manageably few manually annotated example images (<50\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$<\\,50$$\\end{document}). This is achieved by utilizing data augmentation strategies. The network predictions are used as input for the second stage which performs a bottom-up clustering to build baselines. The developed method is capable of handling complex layouts as well as curved and arbitrarily oriented text lines. It substantially outperforms current state-of-the-art approaches. For example, for the complex track of the cBAD: ICDAR2017 Competition on Baseline Detection the F value is increased from 0.859 to 0.922. The framework to train and run the ARU-Net is open source.",
            "year": 2018,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "1680083",
                "name": "Gundram Leifert"
              },
              {
                "authorId": "40508719",
                "name": "Tobias Strauß"
              },
              {
                "authorId": "88739357",
                "name": "Johannes Michael"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              }
            ]
          }
        },
        {
          "citedcorpusid": 49417857,
          "isinfluential": false,
          "contexts": [
            "[13], a sliding-window dense prediction using a U-Net architecture [14]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Baseline Detection in Historical Documents Using Convolutional U-Nets",
            "abstract": "Baseline detection is still a challenging task for heterogeneous collections of historical documents. We present a novel approach to baseline extraction in such settings, turning out the winning entry to the ICDAR 2017 Competition on Baseline detection (cBAD). It utilizes deep convolutional nets (CNNs) for both, the actual extraction of baselines, as well as for a simple form of layout analysis in a pre-processing step. To the best of our knowledge it is the first CNN-based system for baseline extraction applying a U-net architecture and sliding window detection, profiting from a high local accuracy of the candidate lines extracted. Final baseline post-processing complements our approach, compensating for inaccuracies mainly due to missing context information during sliding window detection. We experimentally evaluate the components of our system individually on the cBAD dataset. Moreover, we investigate how it generalizes to different data by means of the dataset used for the baseline extraction task of the ICDAR 2017 Competition on Layout Analysis for Challenging Medieval Manuscripts (HisDoc). A comparison with the results reported for HisDoc shows that it also outperforms the contestants of the latter.",
            "year": 2018,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "2105534484",
                "name": "Michael Fink"
              },
              {
                "authorId": "47837360",
                "name": "T. Layer"
              },
              {
                "authorId": "51011459",
                "name": "Georg Mackenbrock"
              },
              {
                "authorId": "50877255",
                "name": "M. Sprinzl"
              }
            ]
          }
        },
        {
          "citedcorpusid": 173188066,
          "isinfluential": false,
          "contexts": [
            "Annotations were performed at pixel-level using VGG Image Annotator [27]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The VIA Annotation Software for Images, Audio and Video",
            "abstract": "In this paper, we introduce a simple and standalone manual annotation tool for images, audio and video: the VGG Image Annotator (VIA). This is a light weight, standalone and offline software package that does not require any installation or setup and runs solely in a web browser. The VIA software allows human annotators to define and describe spatial regions in images or video frames, and temporal segments in audio or video. These manual annotations can be exported to plain text data formats such as JSON and CSV and therefore are amenable to further processing by other software tools. VIA also supports collaborative annotation of a large dataset by a group of human annotators. The BSD open source license of this software allows it to be used in any academic project or commercial application.",
            "year": 2019,
            "venue": "ACM Multimedia",
            "authors": [
              {
                "authorId": "2080123400",
                "name": "Abhishek Dutta"
              },
              {
                "authorId": "1688869",
                "name": "Andrew Zisserman"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206594692,
          "isinfluential": true,
          "contexts": [
            "3) Network architecture: We now validate the benefits of the architecture changes we made compared to dhSegment [16]: a simple ResNet-18 backbone, the replacement of\nthe max-pooling by a strided convolution and the deconvolutional upscaling.",
            "1) Network architecture: Similar to [16], we use a simple encoder-decoder architecture combining the descriptive power of ResNet [15] with the localization recovering capacity of U-Net [14].",
            "We replaced the max-pooling operation in ResNet conv2 block by a 2-strided 3x3 convolutional layer, as max-pooling has been shown [21] to lead to gridding artifacts.",
            "Later, the winning entry was successively surpassed by the ResNet [15] adaptation of Ares Oliveira et al. [16] and by the model proposed by Grüning et al. [17] which added an attention mechanism and developed a sophisticated post-processing step\nbased on superpixels.",
            "Later, the winning entry was successively surpassed by the ResNet [15]",
            "Compared to [16], we use a smaller ResNet-18 as backbone encoder since detecting text lines requires keeping document images as large as possible, which constraints memory, and we perform small modifications in the architecture resulting in better performances."
          ],
          "intents": [
            "--",
            "['methodology']",
            "--",
            "--",
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Deep Residual Learning for Image Recognition",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
            "year": 2015,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "1771551",
                "name": "X. Zhang"
              },
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": null,
                "name": "Jian Sun"
              }
            ]
          }
        }
      ]
    },
    "44853906": {
      "citing_paper_info": {
        "title": "Impact of Smearing Techniques on Text Line Localization of Kannada Historical Scripts",
        "abstract": "Text line localization and segmentation is an important preprocessing stage in the context of document image analysis. Text lines must be localized first and then segmented in the logical order. The final recognition results are highly dependent on the results of text line segmentation. Historical documents have free form handwritten text and pose a great challenge for text line segmentation. The presence of connected and overlapping characters make the segmentation task more challenging. Smearing techniques have been conventionally used for the purpose of text line localization. In this paper, performance analysis of various smearing techniques is carried out on the text line localization of Kannada historical scripts.",
        "year": 2015,
        "venue": "",
        "authors": [
          {
            "authorId": "101203025",
            "name": "S. VishwasH"
          },
          {
            "authorId": "46793272",
            "name": "B. A. Thomas"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 1,
        "unique_cited_count": 1,
        "influential_count": 0,
        "detailed_records_count": 1
      },
      "cited_papers": [
        "12751642"
      ],
      "citation_details": [
        {
          "citedcorpusid": 12751642,
          "isinfluential": false,
          "contexts": [
            "Cross counting technique has been employed in [8] [9] for getting a map of the original image."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Separating lines of text in free-form handwritten historical documents",
            "abstract": "",
            "year": 2006,
            "venue": "Document Image Analysis for Libraries",
            "authors": [
              {
                "authorId": "2051579",
                "name": "Douglas J. Kennard"
              },
              {
                "authorId": "144055367",
                "name": "W. Barrett"
              }
            ]
          }
        }
      ]
    },
    "43477852": {
      "citing_paper_info": {
        "title": "Extraction of Homogeneous Regions in Historical Document Images",
        "abstract": "To reach the objective of ensuring the indexing and retrieval of digitized resources and offering a structured access to large sets of cultural heritage documents, a raising interest to historical document image segmentation has been generated. In fact, there is a real need for automatic algorithms ensuring the identification of homogeneous regions or similar groups of pixels sharing some visual characteristics from historical documents (i.e. distinguishing graphic types, segmenting graphical regions from textual ones, and discriminating text in a variety of situations of different fonts and scales). Indeed, determining graphic regions can help to segment and analyze the graphical part in historical heritage, while finding text zones can be used as a pre-processing stage for character recognition, text line extraction, handwriting recognition, etc. Thus, we propose in this article an automatic segmentation method for historical document images based on extraction of homogeneous or similar content regions. The proposed algorithm is based on using simple linear iterative clustering (SLIC) su-perpixels, Gabor filters, multi-scale analysis, majority voting technique, connected component analysis, color layer separation, and an adaptive run-length smoothing algorithm (ARLSA). It has been evaluated on 1000 pages of historical documents and achieved interesting results.",
        "year": 2015,
        "venue": "International Conference on Computer Vision Theory and Applications",
        "authors": [
          {
            "authorId": "2131158",
            "name": "Maroua Mehri"
          },
          {
            "authorId": "1826457",
            "name": "P. Héroux"
          },
          {
            "authorId": "1405425047",
            "name": "Nabil Sliti"
          },
          {
            "authorId": "1399368454",
            "name": "Petra Gomez-Krämer"
          },
          {
            "authorId": "2536574",
            "name": "N. Amara"
          },
          {
            "authorId": "1682986",
            "name": "R. Mullot"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 7,
        "influential_count": 2,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "7391071",
        "123885967",
        "41585742",
        "62618327",
        "6278891",
        "39171119",
        "8204609"
      ],
      "citation_details": [
        {
          "citedcorpusid": 6278891,
          "isinfluential": false,
          "contexts": [
            ", 2011), Gabor filters (Gabor, 1946), k-means clustering (MacQueen, 1967), multi-scale analysis (Li et al.",
            "…is based on using simple linear iterative clustering (SLIC) superpixels (Liu et al., 2011), Gabor filters (Gabor, 1946), k-means clustering (MacQueen, 1967), multi-scale analysis (Li et al., 2000), majority voting technique (Lam and Suen, 1997), connected component (CC) analysis (Rosenfeld…"
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Some methods for classification and analysis of multivariate observations",
            "abstract": "The main purpose of this paper is to describe a process for partitioning an N-dimensional population into k sets on the basis of a sample. The process, which is called 'k-means,' appears to give partitions which are reasonably efficient in the sense of within-class variance. That is, if p is the probability mass function for the population, S = {S1, S2, * *, Sk} is a partition of EN, and ui, i = 1, 2, * , k, is the conditional mean of p over the set Si, then W2(S) = ff=ISi f z u42 dp(z) tends to be low for the partitions S generated by the method. We say 'tends to be low,' primarily because of intuitive considerations, corroborated to some extent by mathematical analysis and practical computational experience. Also, the k-means procedure is easily programmed and is computationally economical, so that it is feasible to process very large samples on a digital computer. Possible applications include methods for similarity grouping, nonlinear prediction, approximating multivariate distributions, and nonparametric tests for independence among several variables. In addition to suggesting practical classification methods, the study of k-means has proved to be theoretically interesting. The k-means concept represents a generalization of the ordinary sample mean, and one is naturally led to study the pertinent asymptotic behavior, the object being to establish some sort of law of large numbers for the k-means. This problem is sufficiently interesting, in fact, for us to devote a good portion of this paper to it. The k-means are defined in section 2.1, and the main results which have been obtained on the asymptotic behavior are given there. The rest of section 2 is devoted to the proofs of these results. Section 3 describes several specific possible applications, and reports some preliminary results from computer experiments conducted to explore the possibilities inherent in the k-means idea. The extension to general metric spaces is indicated briefly in section 4. The original point of departure for the work described here was a series of problems in optimal classification (MacQueen [9]) which represented special",
            "year": 1967,
            "venue": "",
            "authors": [
              {
                "authorId": "104537710",
                "name": "J. MacQueen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7391071,
          "isinfluential": false,
          "contexts": [
            "…(MacQueen, 1967), multi-scale analysis (Li et al., 2000), majority voting technique (Lam and Suen, 1997), connected component (CC) analysis (Rosenfeld and Pfaltz, 1966), color layer separation, and adaptive run-length smoothing algorithm (ARLSA), for extraction of homogeneous or similar…",
            ", 2000), majority voting technique (Lam and Suen, 1997), connected component (CC) analysis (Rosenfeld and Pfaltz, 1966), color layer separation, and adaptive run-length smoothing algorithm (ARLSA), for extraction of homogeneous or similar content regions in HDIs."
          ],
          "intents": [
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Sequential Operations in Digital Picture Processing",
            "abstract": "",
            "year": 1966,
            "venue": "JACM",
            "authors": [
              {
                "authorId": "143766793",
                "name": "A. Rosenfeld"
              },
              {
                "authorId": "2585707",
                "name": "J. Pfaltz"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8204609,
          "isinfluential": false,
          "contexts": [
            ", 2011), Gabor filters (Gabor, 1946), k-means clustering (MacQueen, 1967), multi-scale analysis (Li et al., 2000), majority voting technique (Lam and Suen, 1997), connected component (CC) analysis (Rosenfeld and Pfaltz, 1966), color layer separation, and adaptive run-length smoothing algorithm (ARLSA), for extraction of homogeneous or similar content regions in HDIs.",
            "…iterative clustering (SLIC) superpixels (Liu et al., 2011), Gabor filters (Gabor, 1946), k-means clustering (MacQueen, 1967), multi-scale analysis (Li et al., 2000), majority voting technique (Lam and Suen, 1997), connected component (CC) analysis (Rosenfeld and Pfaltz, 1966), color layer…"
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Classification of textured and non-textured images using region segmentation",
            "abstract": "",
            "year": 2000,
            "venue": "Proceedings 2000 International Conference on Image Processing (Cat. No.00CH37101)",
            "authors": [
              {
                "authorId": "40116905",
                "name": "Jia Li"
              },
              {
                "authorId": "48094094",
                "name": "James Ze Wang"
              },
              {
                "authorId": "1683556",
                "name": "G. Wiederhold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 39171119,
          "isinfluential": false,
          "contexts": [
            "Then, three accuracy metrics are computed: the precision (PAR), recall (RAR), and Jaccard index (JAR) for evaluating the extracted homogeneous regions (Brunessaux et al., 2014)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The Maurdor Project: Improving Automatic Processing of Digital Documents",
            "abstract": "",
            "year": 2014,
            "venue": "2014 11th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1990445",
                "name": "S. Brunessaux"
              },
              {
                "authorId": "2102383646",
                "name": "Patrick Giroux"
              },
              {
                "authorId": "1809808",
                "name": "B. Grilhères"
              },
              {
                "authorId": "49586578",
                "name": "M. Manta"
              },
              {
                "authorId": "28476916",
                "name": "Maylis Bodin"
              },
              {
                "authorId": "1678451",
                "name": "K. Choukri"
              },
              {
                "authorId": "1701385",
                "name": "Olivier Galibert"
              },
              {
                "authorId": "35798452",
                "name": "Juliette Kahn"
              }
            ]
          }
        },
        {
          "citedcorpusid": 41585742,
          "isinfluential": true,
          "contexts": [
            "Finally, a second post-processing task “Post-processing 2” is added based on using the multi-scale analysis, majority voting technique, CC analysis, color layer separation, and ARLSA to identify the homogeneous or similar content regions that are characterized by similar properties.",
            "Once the horizontal and vertical run-length smoothing values are estimated automatically according to the analyzed HDI content (i.e. and particularly the distributions of the widths and heights of the extracted CCs of the binarized enhanced document image), the proposed ARLSA is applied on each resulting image of the color layer separation task after performing a binarizing step by using the Otsu’s algorithm.",
            "The proposed algorithm is based on using simple linear iterative clustering (SLIC) superpixels (Liu et al., 2011), Gabor filters (Gabor, 1946), k-means clustering (MacQueen, 1967), multi-scale analysis (Li et al., 2000), majority voting technique (Lam and Suen, 1997), connected component (CC) analysis (Rosenfeld and Pfaltz, 1966), color layer separation, and adaptive run-length smoothing algorithm (ARLSA), for extraction of homogeneous or similar content regions in HDIs.",
            "After applying the ARLSA on each resulting image of the color layer separation task, the logical NOT is performed on each resulting image to merge the different resulting images of the ARLSA task (cf. Figures 3(l) and 3(p)) with the logical OR.",
            "The proposed ARLSA determines automatically the horizontal and vertical thresholds, which correspond to to the run-length smoothing values, respectively.",
            "The RLSA studies the spaces between black pixels in order to link neighboring black areas by applying the run-length smearing both horizontally and vertically.",
            "So an adaptive RLSA is proposed in this work, which is a modified version of the state-of-the-art RLSA (Wahl et al., 1982)."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Block segmentation and text extraction in mixed text/image documents",
            "abstract": "",
            "year": 1982,
            "venue": "Computer Graphics and Image Processing",
            "authors": [
              {
                "authorId": "1880661",
                "name": "F. Wahl"
              },
              {
                "authorId": "145470231",
                "name": "Kwan Y. Wong"
              },
              {
                "authorId": "34896449",
                "name": "R. Casey"
              }
            ]
          }
        },
        {
          "citedcorpusid": 62618327,
          "isinfluential": false,
          "contexts": [
            ", 2011), Gabor filters (Gabor, 1946), k-means clustering (MacQueen, 1967), multi-scale analysis (Li et al.",
            "The proposed algorithm is based on using simple linear iterative clustering (SLIC) superpixels (Liu et al., 2011), Gabor filters (Gabor, 1946), k-means clustering (MacQueen, 1967), multi-scale analysis (Li et al., 2000), majority voting technique (Lam and Suen, 1997), connected component (CC)…"
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Theory of communication. Part 1: The analysis of information",
            "abstract": "Hitherto communication theory was based on two alternative methods of signal analysis. One is the description of the signal as a function of time; the other is Fourier analysis. Both are idealizations, as the first method operates with sharply defined instants of time, the second with infinite wave-trains of rigorously defined frequencies. But our everyday experiences?especially our auditory sensations?insist on a description in terms of both time and frequency. In the present paper this point of view is developed in quantitative language. Signals are represented in two dimensions, with time and frequency as co-ordinates. Such two-dimensional representations can be called ?information diagrams,? as areas in them are proportional to the number of independent data which they can convey. This is a consequence of the fact that the frequency of a signal which is not of infinite duration can be defined only with a certain inaccuracy, which is inversely proportional to the duration, and vice versa. This ?uncertainty relation? suggests a new method of description, intermediate between the two extremes of time analysis and spectral analysis. There are certain ?elementary signals? which occupy the smallest possible area in the information diagram. They are harmonic oscillations modulated by a ?probability pulse.? Each elementary signal can be considered as conveying exactly one datum, or one ?quantum of information.? Any signal can be expanded in terms of these by a process which includes time analysis and Fourier analysis as extreme cases. These new methods of analysis, which involve some of the mathematical apparatus of quantum theory, are illustrated by application to some problems of transmission theory, such as direct generation of single sidebands, signals transmitted in minimum time through limited frequency channels, frequency modulation and time-division multiplex telephony.",
            "year": 1946,
            "venue": "",
            "authors": [
              {
                "authorId": "16298171",
                "name": "D. Gabor"
              }
            ]
          }
        },
        {
          "citedcorpusid": 123885967,
          "isinfluential": true,
          "contexts": [
            "Figure 3(e)) and subsequently to retrieve the CCs (Otsu, 1979).",
            "First, a binarization step is performed using a standard parameter-free binarization method, the Otsu’s method, on the enhanced document image (cf. Section 2.2, Figure 3(d)) to obtain a binarized enhanced document image (cf. Figure 3(e)) and subsequently to retrieve the CCs (Otsu, 1979)."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ATlreshold Selection Method fromGray-Level Histograms",
            "abstract": "",
            "year": 1979,
            "venue": "",
            "authors": [
              {
                "authorId": "1809629",
                "name": "N. Otsu"
              }
            ]
          }
        }
      ]
    },
    "166512795": {
      "citing_paper_info": {
        "title": "Tibetan historical document recognition of uchen script using baseline information",
        "abstract": "A method is proposed for recognition of uchen script Tibetan historical document using baseline information. The baseline is a significant feature of uchen script Tibetan characters, and the result of Tibetan document recognition can be improved effectively by using baseline information. Firstly, the baseline is detected accurately by the upper edge of character strokes in the document. Secondly, the baseline is used for segmentation of text line and character, and the text line adhesion can be handled also. Finally, the character part above baseline and that below baseline are recognized individually, and the final results are synthesized. The experiment shows that the proposed method is effective for the recognition of Tibetan historical document, and the recognition accuracy is better than that of the whole character recognition.",
        "year": 2019,
        "venue": "International Conference on Graphic and Image Processing",
        "authors": [
          {
            "authorId": "49970018",
            "name": "Zhenjiang Li"
          },
          {
            "authorId": "2254980",
            "name": "Weilan Wang"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 2,
        "unique_cited_count": 1,
        "influential_count": 0,
        "detailed_records_count": 2
      },
      "cited_papers": [
        "17204582"
      ],
      "citation_details": [
        {
          "citedcorpusid": 17204582,
          "isinfluential": false,
          "contexts": [
            "Wang Weilan, Qian Jianjun and Wang Daohui extracted the 2DPCA feature [7] and stroke direction feature [8] of the online character firstly, and then reduced the dimension of feature by IMLDA method, and finally a classifier of MQDF was used to recognize the online character."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2DPCA and IMLDA method of feature extraction for online handwritten Tibetan recognition",
            "abstract": "",
            "year": 2010,
            "venue": "2010 International Conference on Networking and Digital Society",
            "authors": [
              {
                "authorId": "9091654",
                "name": "Daohui Wang"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              },
              {
                "authorId": "40074541",
                "name": "J. Qian"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Huang Heming developed an off-line Tibetan handwritten recognition database THCDB [14], extracted features by wavelet transform and gradient direction [15], and implemented recognition based on sparse transformation [16]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "5490524": {
      "citing_paper_info": {
        "title": "A Binarization-Free Clustering Approach to Segment Curved Text Lines in Historical Manuscripts",
        "abstract": "",
        "year": 2013,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "1697354",
            "name": "A. Garz"
          },
          {
            "authorId": "153745355",
            "name": "Andreas Fischer"
          },
          {
            "authorId": "1720945",
            "name": "H. Bunke"
          },
          {
            "authorId": "1680326",
            "name": "R. Ingold"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 6,
        "influential_count": 2,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "1913486",
        "18324118",
        "130535382",
        "8461025",
        "9187881",
        "9673364"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1913486,
          "isinfluential": false,
          "contexts": [
            "Nicolaou and Gatos [13] use so-called local minima tracers which follow the line spacing to shred the document page in lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 8461025,
          "isinfluential": false,
          "contexts": [
            "[11] report an approach which combines outputs of a set of line segmentation algorithms using graph clustering.",
            "Although text line segmentation in printed documents is considered a solved problem [1], and has been widely addressed in literature [2]–[11] for handwritten documents, it is still an open research topic due to bad quality, variability and complexity of historical handwritten documents."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Graph Clustering-Based Ensemble Method for Handwritten Text Line Segmentation",
            "abstract": "",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "144249397",
                "name": "V. Manohar"
              },
              {
                "authorId": "3306372",
                "name": "S. Vitaladevuni"
              },
              {
                "authorId": "39784761",
                "name": "Huaigu Cao"
              },
              {
                "authorId": "36073757",
                "name": "R. Prasad"
              },
              {
                "authorId": "145603129",
                "name": "P. Natarajan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": true,
          "contexts": [
            "The final text line, however, is represented by contours accounting for the fact that handwritten text lines cannot be represented accurately enough by piece-wise approximations [6] generated by the line-finding algorithm.",
            "[6] propose a method based on character density estimation and the level set method for text line segmentation.",
            "Missing parts of text lines, noise or additionally added parts of other text lines are penalized [6].",
            "The best assignment between a line detected by the system and a line in the ground truth is found based on corresponding pixels by means of the Hungarian algorithm [6]."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9673364,
          "isinfluential": false,
          "contexts": [
            "[15] apply their approach directly on gray-scale images, where a distance transform is computed from a Gaussian-blurred image, and separating paths are established using DP.",
            "Several recent approaches [12]–[15] introduce Dynamic Programming (DP) for text line segmentation in binarized and gray scale images."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation for gray scale historical document images",
            "abstract": "",
            "year": 2011,
            "venue": "The Hip",
            "authors": [
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "1741845",
                "name": "Raid Saabni"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18324118,
          "isinfluential": false,
          "contexts": [
            "Several recent approaches [12]–[15] introduce Dynamic Programming (DP) for text line segmentation in binarized and gray scale images."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Combining Alignment Results for Historical Handwritten Document Analysis",
            "abstract": "",
            "year": 2009,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1693905",
                "name": "Emanuel Indermühle"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 130535382,
          "isinfluential": true,
          "contexts": [
            "In order to calculate the cost function for DP, we use a smoothed DOG image previously generated for the extraction of interest points [19].",
            "We use interest points extracted by means of Difference of Gaussian (DOG) [19], where interest points describe positions and scales of local extremes with respect to both space and scale.",
            "For more details on DOG interest point extraction and DBSCAN word clustering, we refer to [16].",
            "Most importantly, the thresholds on scale and sensitivity of the DOG detector need to be optimized, as well as the neighborhood radius for DBSCAN to obtain word clusters."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Distinctive Image Features from Scale-Invariant Keypoints Abstract by Matthijs Dorst Based on the paper by",
            "abstract": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images. These features can then be used to reliably match objects in diering images. The algorithm was rst proposed by Lowe [12] and further developed to increase performance resulting in the classic paper [13] that served as foundation for SIFT which has played an important role in robotic and machine vision in the past decade.",
            "year": 2011,
            "venue": "",
            "authors": [
              {
                "authorId": "2059876008",
                "name": "Matthijs C. Dorst"
              }
            ]
          }
        }
      ]
    },
    "49414646": {
      "citing_paper_info": {
        "title": "Handwriting Recognition of Historical Documents with Few Labeled Data",
        "abstract": "Historical documents present many challenges for offline handwriting recognition systems, among them, the segmentation and labeling steps. Carefully annotated text lines are needed to train an HTR system. In some scenarios, transcripts are only available at the paragraph level with no text-line information. In this work, we demonstrate how to train an HTR system with few labeled data. Specifically, we train a deep convolutional recurrent neural network (CRNN) system on only 10% of manually labeled text-line data from a dataset and propose an incremental training procedure that covers the rest of the data. Performance is further increased by augmenting the training set with specially crafted multi scale data. We also propose a model-based normalization scheme which considers the variability in the writing scale at the recognition phase. We apply this approach to the publicly available READ dataset. Our system achieved the second best result during the ICDAR2017 competition [1].",
        "year": 2018,
        "venue": "International Workshop on Document Analysis Systems",
        "authors": [
          {
            "authorId": "3221676",
            "name": "Edgard Chammas"
          },
          {
            "authorId": "1699564",
            "name": "C. Mokbel"
          },
          {
            "authorId": "1398902377",
            "name": "Laurence Likforman-Sulem"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 7,
        "influential_count": 0,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "215842252",
        "215850874",
        "350512",
        "11057710",
        "5808102",
        "28742063",
        "60827152"
      ],
      "citation_details": [
        {
          "citedcorpusid": 350512,
          "isinfluential": false,
          "contexts": [
            "Recent work on text detection and localization [2] at the document level, and joint line segmentation and recognition at the paragraph level [3] showed promising results."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Recognition : Learning Where to Start and When to Stop",
            "abstract": "Text line detection and localization is a crucial step for full page document analysis, but still suffers from heterogeneity of real life documents. In this paper, we present a new approach for full page text recognition. Localization of the text lines is based on regressions with Fully Convolutional Neural Networks and Multidimensional Long Short-Term Memory as contextual layers. In order to increase the efficiency of this localization method, only the position of the left side of the text lines are predicted. The text recognizer is then in charge of predicting the end of the text to recognize. This method has shown good results for full page text recognition on the highly heterogeneous Maurdor dataset.",
            "year": 2017,
            "venue": "",
            "authors": [
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "144899680",
                "name": "Christian Wolf"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5808102,
          "isinfluential": false,
          "contexts": [
            "Batch normalization as described in [14], was added after each convolutional layer in order to accelerate the training process."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
            "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.",
            "year": 2015,
            "venue": "International Conference on Machine Learning",
            "authors": [
              {
                "authorId": "2054165706",
                "name": "Sergey Ioffe"
              },
              {
                "authorId": "2574060",
                "name": "Christian Szegedy"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11057710,
          "isinfluential": false,
          "contexts": [
            "Therefore, more advanced segmentation algorithms are needed to improve the selection/training process, like the ones based on Seam Carving technique [18] and dynamic programming, which would have resulted in fewer segmentation errors and therefore more labeled training data."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Seam Carving for Text Line Extraction on Color and Grayscale Historical Manuscripts",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2965236",
                "name": "Nikolaos Arvanitopoulos"
              },
              {
                "authorId": "1735035",
                "name": "S. Süsstrunk"
              }
            ]
          }
        },
        {
          "citedcorpusid": 28742063,
          "isinfluential": false,
          "contexts": [
            "A token passing algorithm was used for decoding [15]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting Recognition for Historical Documents",
            "abstract": "OCR of printed text is a well-developed technology that has steadily improved in accuracy and flexibility. Initially limited to interpretation of numerals printed with special fonts, current day OCR software can deal with a multitude of fonts, character sets, languages, and page attributes. For extremely clean and wellscanned documents, the resulting text may be good enough to use for direct display purposes. More commonly, the OCR is somewhat \"dirty\" (i.e., contains errors) but is still accurate enough to form the basis of a quite usable machine-searchable index. Accuracy rates of 99.5% and higher (at the character level) are achievable for good quality source documents.",
            "year": 2014,
            "venue": "",
            "authors": [
              {
                "authorId": "3119900",
                "name": "Richard Entlich"
              }
            ]
          }
        },
        {
          "citedcorpusid": 60827152,
          "isinfluential": false,
          "contexts": [
            "The recognized lines were mapped to lines in the ground-truth data for each page, based on the Levenshtein distance [17] between the text lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Binary codes capable of correcting deletions, insertions, and reversals",
            "abstract": "",
            "year": 1965,
            "venue": "",
            "authors": [
              {
                "authorId": "2154179",
                "name": "V. Levenshtein"
              }
            ]
          }
        },
        {
          "citedcorpusid": 215842252,
          "isinfluential": false,
          "contexts": [
            "It integrates a bigram language model with modified Kneser-Ney discounting [16], built from the available training data."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An Empirical Study of Smoothing Techniques for Language Modeling",
            "abstract": "We present an extensive empirical comparison of several smoothing techniques in the domain of language modeling, including those described by Jelinek and Mercer (1980), Katz (1987), and Church and Gale (1991). We investigate for the first time how factors such as training data size, corpus (e.g., Brown versus Wall Street Journal), and n-gram order (bigram versus trigram) affect the relative performance of these methods, which we measure through the cross-entropy of test data. In addition, we introduce two novel smoothing techniques, one a variation of Jelinek-Mercer smoothing and one a very simple linear interpolation technique, both of which outperform existing methods.",
            "year": 1996,
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "authors": [
              {
                "authorId": "2110909951",
                "name": "Stanley F. Chen"
              },
              {
                "authorId": "50126864",
                "name": "Joshua Goodman"
              }
            ]
          }
        },
        {
          "citedcorpusid": 215850874,
          "isinfluential": false,
          "contexts": [
            "Based on a vertical scale score [19], the training lines were first classified into 3 classes (Large, Medium and Small) via Jenks natural breaks optimization algorithm [20]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The Data Model Concept in Statistical Mapping",
            "abstract": "",
            "year": 1967,
            "venue": "",
            "authors": [
              {
                "authorId": "17051696",
                "name": "G. Jenks"
              }
            ]
          }
        }
      ]
    },
    "51606465": {
      "citing_paper_info": {
        "title": "Multi-task Layout Analysis for Historical Handwritten Documents Using Fully Convolutional Networks",
        "abstract": "Layout analysis is a fundamental process in document image analysis and understanding. It consists of several sub-processes such as page segmentation, text line segmentation, baseline detection and so on. In this work, we propose a multi-task layout analysis method that use a single FCN model to solve the above three problems simultaneously. The FCN is trained to segment the document image into different regions and detect the center line of each text line by classifying pixels into different categories. By supervised learning on document images with pixel-wise labels, the FCN can extract discriminative features and perform pixel-wise classification accurately. After pixel-wise classification, post-processing steps are taken to reduce noises, correct wrong segmentations and find out overlapping regions. Experimental results on the public dataset DIVA-HisDB containing challenging medieval manuscripts demonstrate the effectiveness and superiority of the proposed method.",
        "year": 2018,
        "venue": "International Joint Conference on Artificial Intelligence",
        "authors": [
          {
            "authorId": "2143570879",
            "name": "Yue Xu"
          },
          {
            "authorId": "145820427",
            "name": "Fei Yin"
          },
          {
            "authorId": "145274329",
            "name": "Zhaoxiang Zhang"
          },
          {
            "authorId": "1689269",
            "name": "Cheng-Lin Liu"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 7,
        "influential_count": 0,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "1799558",
        "32492059",
        "9187881",
        "11770604",
        "35114695",
        "20278237",
        "16104745"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1799558,
          "isinfluential": false,
          "contexts": [
            "The whole experiments are conducted on Caffe [ Jia et al. , 2014 ] and run on a workstation with 2.9GHz, 12-core CPU, 256G RAM GTX Titan X and Ubuntu 64-bit OS."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Caffe: Convolutional Architecture for Fast Feature Embedding",
            "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.",
            "year": 2014,
            "venue": "ACM Multimedia",
            "authors": [
              {
                "authorId": "39978391",
                "name": "Yangqing Jia"
              },
              {
                "authorId": "1782282",
                "name": "Evan Shelhamer"
              },
              {
                "authorId": "7408951",
                "name": "Jeff Donahue"
              },
              {
                "authorId": "3049736",
                "name": "Sergey Karayev"
              },
              {
                "authorId": "2117314646",
                "name": "Jonathan Long"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              },
              {
                "authorId": "1687120",
                "name": "S. Guadarrama"
              },
              {
                "authorId": "1753210",
                "name": "Trevor Darrell"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": false,
          "contexts": [
            "[Li et al. , 2008] segments text lines based on density estimation."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11770604,
          "isinfluential": false,
          "contexts": [
            "Top-down approaches [Nagy et al. , 1992],[Uttama et al. , 2005],[Ouwayed and Bela¨ıd, 2008] start from the whole page and cut it into small areas."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Top-down segmentation of ancient graphical drop caps : lettrines",
            "abstract": "The restauration and preservation of ancient documents is becoming an interesting application in document image analysis. This paper introduces a top-down approach aimed at segmenting the graphical part in historical heritage called lettrine. The research principle was established on the concept of human visual perception and invariant texture analysis (co-occurrence and run-length matrices, autocorrelation function and wold decomposition). The preliminary results concerning segmentation stages were presented by highligthing difficulties related to the nature of strokes and textures in lettrines. Textured background was extracted although there existed some ambiguities. Nonetheless, the segmented areas of interest are informative enough to serve in an indexing method. The prospective bottom-up approach are mentioned and will be added to gain more precise segmentation.",
            "year": 2005,
            "venue": "",
            "authors": [
              {
                "authorId": "2847710",
                "name": "Surapong Uttama"
              },
              {
                "authorId": "1695766",
                "name": "J. Ogier"
              },
              {
                "authorId": "2467477",
                "name": "P. Loonis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16104745,
          "isinfluential": false,
          "contexts": [
            "[ Mehri et al. , 2015] proposed a bottom-up method based on learning texture features for historical document image enhancement and segmentation.",
            "Bottom-up approaches [Bukhari et al. , 2012], [Mehri et al. , 2015] usually take the pixels or connected components as the basic elements."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Learning Texture Features for Enhancement and Segmentation of Historical Document Images",
            "abstract": "",
            "year": 2015,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "2170742",
                "name": "Nibal Nayef"
              },
              {
                "authorId": "1826457",
                "name": "P. Héroux"
              },
              {
                "authorId": "1399368454",
                "name": "Petra Gomez-Krämer"
              },
              {
                "authorId": "1682986",
                "name": "R. Mullot"
              }
            ]
          }
        },
        {
          "citedcorpusid": 20278237,
          "isinfluential": false,
          "contexts": [
            "The evaluation of the baseline extraction is based on a new performance measure [Gruning et al. , 2017] that ﬁnds the start and end points of the he baseline of each textline."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "READ-BAD: A New Dataset and Evaluation Scheme for Baseline Detection in Archival Documents",
            "abstract": "Text line detection is crucial for any application associated with Automatic Text Recognition or Keyword Spotting. Modern algorithms perform good on well-established datasets since they either comprise clean data or simple/homogeneous page layouts. We have collected and annotated 2036 archival document images from different locations and time periods. The dataset contains varying page layouts and degradations that challenge text line segmentation methods. Well established text line segmentation evaluation schemes such as the Detection Rate or Recognition Accuracy demand for binarized data that is annotated on a pixel level. Producing ground truth by these means is laborious and not needed to determine a method's quality. In this paper we propose a new evaluation scheme that is based on baselines. The proposed scheme has no need for binarization and it can handle skewed as well as rotated text lines. The ICDAR 2017 Competition on Baseline Detection and the ICDAR 2017 Competition on Layout Analysis for Challenging Medieval Manuscripts used this evaluation scheme. Finally, we present results achieved by a recently published text line detection algorithm.",
            "year": 2017,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              },
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 32492059,
          "isinfluential": false,
          "contexts": [
            "…have been proposed, for example, the histogram projection based methods [ Al-Badr and Mahmoud, 1995 ] , the Hough transform based methods [ Razak et al. , 2008 ] , the word skeleton based methods [ Pechwitz and Margner, 2002 ] , the word contour based methods [ Faisal et al. , 2005 ] , and so on."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Baseline estimation for Arabic handwritten words",
            "abstract": "",
            "year": 2002,
            "venue": "Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "1683324",
                "name": "M. Pechwitz"
              },
              {
                "authorId": "1774130",
                "name": "V. Märgner"
              }
            ]
          }
        },
        {
          "citedcorpusid": 35114695,
          "isinfluential": false,
          "contexts": [
            "Top-down approaches [Nagy et al. , 1992],[Uttama et al. , 2005],[Ouwayed and Bela¨ıd, 2008] start from the whole page and cut it into small areas."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Multi-oriented Text Line Extraction from Handwritten Arabic Documents",
            "abstract": "In this paper, we present a novel approach for the multi-oriented text line extraction from handwritten Arabic documents. After image pre-processing, the local orientations are determined in small windows obtained by image paving. The orientation of the text within each window is estimated using the projection profile technique considering several projection angles. Then, the windows which close angles are gathered into largest zones. We use the Wigner-Ville Distribution (WVD) to estimate the global orientation of each zone. The WVD is more precise than the classical projection profile technique. Afterwards, the text lines are extracted in each zone basing on the follow-up of the baselines and the proximity of connected components. The experimental results prove the efficiency of the proposed scheme. It has been evaluated on 50 documents reaching an accuracy of about 97.6%.",
            "year": 2008,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "2892336",
                "name": "Nazih Ouwayed"
              },
              {
                "authorId": "2257903477",
                "name": "Abdel Belaïd"
              }
            ]
          }
        }
      ]
    },
    "153312645": {
      "citing_paper_info": {
        "title": "A Human-Inspired Recognition System for Pre-Modern Japanese Historical Documents",
        "abstract": "Recognition of historical documents is a challenging problem due to the noised, damaged characters, and background. However, in Japanese historical documents, not only contains the mentioned problems, pre-modern Japanese characters were written in cursive and are connected. Therefore, character segmentation-based methods do not work well. This leads to the idea of creating a new recognition system. In this paper, we propose a human-inspired document reading system to recognize multiple lines of pre-modern Japanese historical documents. During the reading, people employ eyes movement to determine the start of a text line. Then, they move the eyes from the current character/word to the next character/word. They can also determine the end of a line or skip a figure to move to the next line. The eyes movement integrates with visual processing to operate the reading process in the brain. We employ attention-based encoder–decoder to implement this recognition system. First, the recognition system detects were to start a text line. Second, the system scans and recognize character by character until the text line is completed. Then, the system continues to detect the start of the next text line. This process is repeated until reading the whole document. As results, the system is successful to recognize multiple lines, connected and cursive characters without performing character/line segmentation. Besides, we also employ a coverage model which stores the history of eyes movement to predict the next movement more precisely. We tested our human-inspired recognition system on the pre-modern Japanese historical document provided by the PRMU Kuzushiji competition. The results of the experiments demonstrate the superiority and effectiveness of our proposed system by achieving Sequence Error Rate of 9.87% and 53.81% on level 2 and level 3 of the dataset, respectively. These results outperform to any other systems participated in the PRMU Kuzushiji competition.",
        "year": 2019,
        "venue": "IEEE Access",
        "authors": [
          {
            "authorId": "2697883",
            "name": "A. D. Le"
          },
          {
            "authorId": "52214414",
            "name": "Tarin Clanuwat"
          },
          {
            "authorId": "1730368",
            "name": "A. Kitamoto"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 21,
        "unique_cited_count": 17,
        "influential_count": 3,
        "detailed_records_count": 21
      },
      "cited_papers": [
        "22890055",
        "5652781",
        "16475655",
        "16070956",
        "13273599",
        "206741496",
        "195444460",
        "4717203",
        "11212020",
        "6549978",
        "19004349",
        "5756363",
        "14986843",
        "1055111",
        "38351807",
        "350512",
        "51606465"
      ],
      "citation_details": [
        {
          "citedcorpusid": 350512,
          "isinfluential": false,
          "contexts": [
            "Moysset proposed a recognition system which contains Fully Convolutional Network based text localization network and Multidimensional Long Short-Term Memory based text recognition [15]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Recognition : Learning Where to Start and When to Stop",
            "abstract": "Text line detection and localization is a crucial step for full page document analysis, but still suffers from heterogeneity of real life documents. In this paper, we present a new approach for full page text recognition. Localization of the text lines is based on regressions with Fully Convolutional Neural Networks and Multidimensional Long Short-Term Memory as contextual layers. In order to increase the efficiency of this localization method, only the position of the left side of the text lines are predicted. The text recognizer is then in charge of predicting the end of the text to recognize. This method has shown good results for full page text recognition on the highly heterogeneous Maurdor dataset.",
            "year": 2017,
            "venue": "",
            "authors": [
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "144899680",
                "name": "Christian Wolf"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1055111,
          "isinfluential": false,
          "contexts": [
            "Recently, an attention-based encoder-decoder model has been successful in many domains such as machine translation [17], image caption generation [18], and handwriting recognition [19], [20]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",
            "abstract": "Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr9k, Flickr30k and MS COCO.",
            "year": 2015,
            "venue": "International Conference on Machine Learning",
            "authors": [
              {
                "authorId": "2117101253",
                "name": "Ke Xu"
              },
              {
                "authorId": "2503659",
                "name": "Jimmy Ba"
              },
              {
                "authorId": "3450996",
                "name": "Ryan Kiros"
              },
              {
                "authorId": "1979489",
                "name": "Kyunghyun Cho"
              },
              {
                "authorId": "1760871",
                "name": "Aaron C. Courville"
              },
              {
                "authorId": "145124475",
                "name": "R. Salakhutdinov"
              },
              {
                "authorId": "1804104",
                "name": "R. Zemel"
              },
              {
                "authorId": "1751762",
                "name": "Yoshua Bengio"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4717203,
          "isinfluential": true,
          "contexts": [
            "For text line recognition, Segmentation based methods, which attempt to split text line into characters at their true boundaries and label the split characters by using Hidden MarkovModel [8] or CNN [9, 10].",
            "For text line recognition, Segmentation based methods, which attempt to split text line into characters at their true boundaries and label the split characters by using Hidden Markov Model [8] or CNN [9, 10].",
            "The relatedworks on image classification [9] and handwritten math recognition [13] have been verified DenseNets outperforms the VGG and ResNets by proposing direct connections from any preceding layers to succeeding layers.",
            "Deep Convolutional Recurrent Network (DCRN) is a combined architecture of CNN, BLSTM, and CTC. VGG_2DBLSTM is a combined architecture of VGG feature extraction and 2-dimensional BLSTM. Faster R-CNN is an object detection to detect and recognize characters in an input image.",
            "C. Wiginton proposed a page handwritten recognition composing Region Proposal Network to find the start position of text lines, line follower network to normalize text lines and CNN-LSTM network to do text recognition [16]."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Building efficient CNN architecture for offline handwritten Chinese character recognition",
            "abstract": "Deep convolutional neural networks-based methods have brought great breakthrough in image classification, which provides an end-to-end solution for handwritten Chinese character recognition (HCCR) problem through learning discriminative features automatically. Nevertheless, state-of-the-art CNNs appear to incur huge computational cost and require the storage of a large number of parameters especially in fully connected layers, which is difficult to deploy such networks into alternative hardware devices with limited computation capacity. To solve the storage problem, we propose a novel technique called weighted average pooling for reducing the parameters in fully connected layer without loss in accuracy. Besides, we implement a cascaded model in single CNN by adding mid output to complete recognition as early as possible, which reduces average inference time significantly. Experiments are performed on the ICDAR-2013 offline HCCR dataset. It is found that our proposed approach only needs 6.9 ms for classifying a character image on average and achieves the state-of-the-art accuracy of 97.1% while requires only 3.3 MB for storage.",
            "year": 2018,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2144281181",
                "name": "Zhiyuan Li"
              },
              {
                "authorId": "41015848",
                "name": "Nanjun Teng"
              },
              {
                "authorId": "2072905563",
                "name": "Min Jin"
              },
              {
                "authorId": "2115782178",
                "name": "Huaxiang Lu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5652781,
          "isinfluential": false,
          "contexts": [
            "proposed a real-time recognition to recognize Chinese handwritten pages [14]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "An approach for real-time recognition of online Chinese handwritten sentences",
            "abstract": "",
            "year": 2012,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1807704",
                "name": "Da-Han Wang"
              },
              {
                "authorId": "1689269",
                "name": "Cheng-Lin Liu"
              },
              {
                "authorId": "2116447343",
                "name": "Xiang-Dong Zhou"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5756363,
          "isinfluential": false,
          "contexts": [
            "Level 1: recognition of single segmented characters, level 2: recognition of three vertically Kana characters and level 3: recognition of unrestricted sets of three or more than three characters possibly in multiple lines [11].",
            "Segmentation free method show their advantages in the problems of the sequence to sequence such as handwritten recognition [11], speech recognition [12].",
            "Since the structure of feature extraction affects the performance of the end-to-end system [8-11], we tried four settings of the hyperparameters to train the recognition system on the training and validation sets of level 3."
          ],
          "intents": [
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Unconstrained Online Handwriting Recognition with Recurrent Neural Networks",
            "abstract": "In online handwriting recognition the trajectory of the pen is recorded during writing. Although the trajectory provides a compact and complete representation of the written output, it is hard to transcribe directly, because each letter is spread over many pen locations. Most recognition systems therefore employ sophisticated preprocessing techniques to put the inputs into a more localised form. However these techniques require considerable human effort, and are specific to particular languages and alphabets. This paper describes a system capable of directly transcribing raw online handwriting data. The system consists of an advanced recurrent neural network with an output layer designed for sequence labelling, combined with a probabilistic language model. In experiments on an unconstrained online database, we record excellent results using either raw or preprocessed data, well outperforming a state-of-the-art HMM based system in both cases.",
            "year": 2007,
            "venue": "",
            "authors": [
              {
                "authorId": "1753223",
                "name": "Alex Graves"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6549978,
          "isinfluential": false,
          "contexts": [
            "Recently, an attention-based encoder-decoder model has been successful in many domains such as machine translation [17], image caption generation [18], and handwriting recognition [19], [20]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Multi-Scale Attention with Dense Encoder for Handwritten Mathematical Expression Recognition",
            "abstract": "Handwritten mathematical expression recognition is a challenging problem due to the complicated two-dimensional structures, ambiguous handwriting input and variant scales of handwritten math symbols. To settle this problem, recently we propose the attention based encoder-decoder model that recognizes mathematical expression images from two-dimensional layouts to one-dimensional LaTeX strings. In this study, we improve the encoder by employing densely connected convolutional networks as they can strengthen feature extraction and facilitate gradient propagation especially on a small training set. We also present a novel multi-scale attention model which is employed to deal with the recognition of math symbols in different scales and restore the fine-grained details dropped by pooling operations. Validated on the CROHME competition task, the proposed method significantly outperforms the state-of-the-art methods with an expression recognition accuracy of 52.8% on CROHME 2014 and 50.1% on CROHME 2016, by only using the official training dataset.",
            "year": 2018,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "39557762",
                "name": "Jianshu Zhang"
              },
              {
                "authorId": "145419855",
                "name": "Jun Du"
              },
              {
                "authorId": "1860774",
                "name": "Lirong Dai"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11212020,
          "isinfluential": false,
          "contexts": [
            "Recently, an attention-based encoder-decoder model has been successful in many domains such as machine translation [17], image caption generation [18], and handwriting recognition [19], [20]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
            "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
            "year": 2014,
            "venue": "International Conference on Learning Representations",
            "authors": [
              {
                "authorId": "3335364",
                "name": "Dzmitry Bahdanau"
              },
              {
                "authorId": "1979489",
                "name": "Kyunghyun Cho"
              },
              {
                "authorId": "1751762",
                "name": "Yoshua Bengio"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13273599,
          "isinfluential": false,
          "contexts": [
            "They showed the effectiveness of the proposed method on a diverse set of historical documents in the IMPACTproject [6]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "A robust hybrid approach for text line segmentation in historical documents",
            "abstract": "",
            "year": 2012,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "2764871",
                "name": "C. Clausner"
              },
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              },
              {
                "authorId": "1980669",
                "name": "Stefan Pletschacher"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14986843,
          "isinfluential": false,
          "contexts": [
            "Level 1: recognition of single segmented characters, level 2: recognition of three vertically Kana characters and level 3: recognition of unrestricted sets of three or more than three characters possibly in multiple lines [11].",
            "Segmentation free method show their advantages in the problems of the sequence to sequence, such as handwritten recognition [11], speech recognition [12].",
            "Since the structure of feature extraction affects the performance of the end-to-end system [8]–[11], we tried four settings of the hyperparameters to train the recognition system on the training and validation sets of level 3."
          ],
          "intents": [
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Unconstrained On-line Handwriting Recognition with Recurrent Neural Networks",
            "abstract": "In online handwriting recognition the trajectory of the pen is recorded during writing. Although the trajectory provides a compact and complete representation of the written output, it is hard to transcribe directly, because each letter is spread over many pen locations. Most recognition systems therefore employ sophisticated preprocessing techniques to put the inputs into a more localised form. However these techniques require considerable human effort, and are specific to particular languages and alphabets. This paper describes a system capable of directly transcribing raw online handwriting data. The system consists of an advanced recurrent neural network with an output layer designed for sequence labelling, combined with a probabilistic language model. In experiments on an unconstrained online database, we record excellent results using either raw or preprocessed data, well outperforming a state-of-the-art HMM based system in both cases.",
            "year": 2007,
            "venue": "Neural Information Processing Systems",
            "authors": [
              {
                "authorId": "1753223",
                "name": "Alex Graves"
              },
              {
                "authorId": "143913738",
                "name": "Santiago Fernández"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              },
              {
                "authorId": "145341374",
                "name": "J. Schmidhuber"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16070956,
          "isinfluential": false,
          "contexts": [
            "For recognizing Kuzushiji characters, Horiuchi and Kato [3] employed modular neural networks which consist of a rough-classifier and a set of fine-classifiers to recognize Kuzushiji."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "A Study on Japanese Historical Character Recognition Using Modular Neural Networks",
            "abstract": "",
            "year": 2009,
            "venue": "International Conference on Innovative Computing, Information and Control",
            "authors": [
              {
                "authorId": "2933273",
                "name": "T. Horiuchi"
              },
              {
                "authorId": "46846450",
                "name": "S. Kato"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16475655,
          "isinfluential": false,
          "contexts": [
            "The relatedworks on image classification [9] and handwritten math recognition [13] have been verified DenseNets outperforms the VGG and ResNets by proposing direct connections from any preceding layers to succeeding layers.",
            "employed two state-of-the-art recognizers for modern scripts (HMM and LSTM) to recognize medieval documents [13]."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Automatic Transcription of Handwritten Medieval Documents",
            "abstract": "",
            "year": 2009,
            "venue": "International Conference on Virtual Systems and MultiMedia",
            "authors": [
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "30836304",
                "name": "Markus Wuthrich"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1688695",
                "name": "Volkmar Frinken"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              },
              {
                "authorId": "2264628420",
                "name": "Gabriel Viehhauser"
              },
              {
                "authorId": "49561025",
                "name": "Michael Stolz"
              }
            ]
          }
        },
        {
          "citedcorpusid": 19004349,
          "isinfluential": false,
          "contexts": [
            "For text line recognition, Segmentation based methods, which attempt to split text line into characters at their true boundaries and label the split characters by using Hidden MarkovModel [8] or CNN [9, 10].",
            "Since the structure of feature extraction affects the performance of the end-to-end system [8]–[11], we tried four settings of the hyperparameters to train the recognition system on the training and validation sets of level 3."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "HMM-Based On-Line Recognition of Handwritten Whiteboard Notes",
            "abstract": "In this paper we present an on-line recognition system for handwritten texts acquired from a whiteboard. This input modality has received relatively little attention in the handwriting recognition community in the past. The system proposed in this paper uses state-of-the-art normalization and feature extraction strategies to transform a handwritten text line into a sequence of feature vectors. Additional preprocessing techniques are introduced, which significantly increase the word recognition rate. For classification, Hidden Markov Models are used together with a statistical language model. In writer independent experiments we achieved word recognition rates of 67.3% on the test set when no language model is used, and 70.8% by including a language model.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22890055,
          "isinfluential": false,
          "contexts": [
            "They developed three recognition systems based on convolutional neural network (CNN) and Bidirectional Long Short-Term Memory (BLSTM) for three tasks [5].",
            "dataset into training, validation, and testing set as the winning team of the competition [5]."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Attempts to recognize anomalously deformed Kana in Japanese historical documents",
            "abstract": "",
            "year": 2017,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "144647137",
                "name": "Hung Tuan Nguyen"
              },
              {
                "authorId": "40325274",
                "name": "N. Ly"
              },
              {
                "authorId": "29367641",
                "name": "K. Nguyen"
              },
              {
                "authorId": "2342621",
                "name": "Cuong Tuan Nguyen"
              },
              {
                "authorId": "145887653",
                "name": "M. Nakagawa"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22890055,
          "isinfluential": false,
          "contexts": [
            "They developed three recognition systems based on convolutional neural network (CNN) and Bidirectional Long Short-Term Memory (BLSTM) for three tasks [5].",
            "Since the testing set in the PRMU competition has not released yet, we separated the dataset into training, validation, and testing set as the winning team of the competition [5]."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Attempts to recognize anomalously deformed Kana in Japanese historical documents",
            "abstract": "",
            "year": 2017,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "144647137",
                "name": "Hung Tuan Nguyen"
              },
              {
                "authorId": "40325274",
                "name": "N. Ly"
              },
              {
                "authorId": "29367641",
                "name": "K. Nguyen"
              },
              {
                "authorId": "2342621",
                "name": "Cuong Tuan Nguyen"
              },
              {
                "authorId": "145887653",
                "name": "M. Nakagawa"
              }
            ]
          }
        },
        {
          "citedcorpusid": 38351807,
          "isinfluential": true,
          "contexts": [
            "For recognizing isolated Kuzushiji characters, they employed CNN and 2DBLSTM based methods.",
            "Deep Convolutional Recurrent Network (DCRN) is a combined architecture of CNN, BLSTM, and CTC. VGG_2DBLSTM is a combined architecture of VGG feature extraction and 2- dimensional BLSTM. Faster R-CNN is an object detection to detect and recognize characters in an input image.",
            "For text line recognition, Segmentation based methods, which attempt to split text line into characters at their true boundaries and label the split characters by using Hidden Markov Model [8] or CNN [9, 10].",
            "For recognizing single line and multiple lines of Kuzushiji characters, they combined architecture of CNN and BLSTM.\nTraditional character recognition systems are divided into two main steps: text line detection and text line recognition.",
            "They developed three recognition systems based on convolutional neural network (CNN) and Bidirectional Long Short-Term Memory (BLSTM) for three tasks [5].",
            "C. Wiginton proposed a page handwritten recognition composing Region Proposal Network to find the start position of text lines, line follower network to normalize text lines and CNN-LSTM network to do text recognition [16].",
            "Since the structure of feature extraction affects the performance of the end-to-end system [8-11], we tried four settings of the hyperparameters to train the recognition system on the training and validation sets of level 3."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Recognition of Online Handwritten Math Symbols Using Deep Neural Networks",
            "abstract": "This paper presents deep learning to recognize online handwritten mathematical symbols. Recently various deep learning architectures such as Convolution neural networks (CNNs), Deep neural networks (DNNs), Recurrent neural networks (RNNs) and Long short-term memory (LSTM) RNNs have been applied to fields such as computer vision, speech recognition and natural language processing where they have shown superior performance to state-of-the-art methods on various tasks. In this paper, max-out-based CNNs and Bidirectional LSTM (BLSTM) networks are applied to image patterns created from online patterns and to the original online patterns, respectively and then combined. They are compared with traditional recognition methods which are MRFs and MQDFs by recognition experiments on the CROHME database along with analysis and explanation. key words: CNN, BLSTM, gradient features, dropout, maxout",
            "year": 2016,
            "venue": "IEICE Trans. Inf. Syst.",
            "authors": [
              {
                "authorId": "40632698",
                "name": "Hai Dai Nguyen"
              },
              {
                "authorId": "2697883",
                "name": "A. D. Le"
              },
              {
                "authorId": "145887653",
                "name": "M. Nakagawa"
              }
            ]
          }
        },
        {
          "citedcorpusid": 38351807,
          "isinfluential": true,
          "contexts": [
            "C. Wiginton proposed a page handwritten recognition composing Region Proposal Network to find the start position of text lines, line follower network to normalize text lines and CNN-LSTM network to do text recognition [16].",
            "For text line recognition, Segmentation based methods, which attempt to split text line into characters at their true boundaries and label the split characters by using Hidden MarkovModel [8] or CNN [9, 10].",
            "Deep Convolutional Recurrent Network (DCRN) is a combined architecture of CNN, BLSTM, and CTC. VGG_2DBLSTM is a combined architecture of VGG feature extraction and 2-dimensional BLSTM. Faster R-CNN is an object detection to detect and recognize characters in an input image.",
            "For text line recognition, Segmentation based methods, which attempt to split text line into characters at their true boundaries and label the split characters by using Hidden Markov Model [8] or CNN [9, 10]."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Recognition of Online Handwritten Math Symbols Using Deep Neural Networks",
            "abstract": "This paper presents deep learning to recognize online handwritten mathematical symbols. Recently various deep learning architectures such as Convolution neural networks (CNNs), Deep neural networks (DNNs), Recurrent neural networks (RNNs) and Long short-term memory (LSTM) RNNs have been applied to fields such as computer vision, speech recognition and natural language processing where they have shown superior performance to state-of-the-art methods on various tasks. In this paper, max-out-based CNNs and Bidirectional LSTM (BLSTM) networks are applied to image patterns created from online patterns and to the original online patterns, respectively and then combined. They are compared with traditional recognition methods which are MRFs and MQDFs by recognition experiments on the CROHME database along with analysis and explanation. key words: CNN, BLSTM, gradient features, dropout, maxout",
            "year": 2016,
            "venue": "IEICE Trans. Inf. Syst.",
            "authors": [
              {
                "authorId": "40632698",
                "name": "Hai Dai Nguyen"
              },
              {
                "authorId": "2697883",
                "name": "A. D. Le"
              },
              {
                "authorId": "145887653",
                "name": "M. Nakagawa"
              }
            ]
          }
        },
        {
          "citedcorpusid": 51606465,
          "isinfluential": false,
          "contexts": [
            "proposed a multi-task layout analysis method that uses a single Fully Convolutional Network to perform page segmentation, text line segmentation, and baseline detection on medieval manuscripts, simultaneously [7]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Multi-task Layout Analysis for Historical Handwritten Documents Using Fully Convolutional Networks",
            "abstract": "Layout analysis is a fundamental process in document image analysis and understanding. It consists of several sub-processes such as page segmentation, text line segmentation, baseline detection and so on. In this work, we propose a multi-task layout analysis method that use a single FCN model to solve the above three problems simultaneously. The FCN is trained to segment the document image into different regions and detect the center line of each text line by classifying pixels into different categories. By supervised learning on document images with pixel-wise labels, the FCN can extract discriminative features and perform pixel-wise classification accurately. After pixel-wise classification, post-processing steps are taken to reduce noises, correct wrong segmentations and find out overlapping regions. Experimental results on the public dataset DIVA-HisDB containing challenging medieval manuscripts demonstrate the effectiveness and superiority of the proposed method.",
            "year": 2018,
            "venue": "International Joint Conference on Artificial Intelligence",
            "authors": [
              {
                "authorId": "2143570879",
                "name": "Yue Xu"
              },
              {
                "authorId": "145820427",
                "name": "Fei Yin"
              },
              {
                "authorId": "145274329",
                "name": "Zhaoxiang Zhang"
              },
              {
                "authorId": "1689269",
                "name": "Cheng-Lin Liu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 195444460,
          "isinfluential": false,
          "contexts": [
            "Wiginton proposed a page handwritten recognition composing Region Proposal Network to find the start position of text lines, line follower network to normalize text lines, and CNN-LSTM network to do text recognition [16]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "End-to-End Full-Page Handwriting Recognition",
            "abstract": "End-to-End Full-Page Handwriting Recognition Curtis Michael Wigington Department of Computer Science, BYU Master of Science Despite decades of research, offline handwriting recognition (HWR) of historical documents remains a challenging problem, which if solved could greatly improve the searchability of online cultural heritage archives. Historical documents are plagued with noise, degradation, ink bleed-through, overlapping strokes, variation in slope and slant of the writing, and inconsistent layouts. Often the documents in a collection have been written by thousands of authors, all of whom have significantly different writing styles. In order to better capture the variations in writing styles we introduce a novel data augmentation technique. This methods achieves state-of-the-art results on modern datasets written in English and French and a historical dataset written in German. HWR models are often limited by the accuracy of the preceding steps of text detection and segmentation. Motivated by this, we present a deep learning model that jointly learns text detection, segmentation, and recognition using mostly images without detection or segmentation annotations. Our Start, Follow, Read (SFR) model is composed of a Region Proposal Network to find the start position of handwriting lines, a novel line follower network that incrementally follows and preprocesses lines of (perhaps curved) handwriting into dewarped images, and a CNN-LSTM network to read the characters. SFR exceeds the performance of the winner of the ICDAR2017 handwriting recognition competition, even when not using the provided competition region annotations.",
            "year": 2018,
            "venue": "",
            "authors": [
              {
                "authorId": "26360698",
                "name": "Curtis Wigington"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206741496,
          "isinfluential": false,
          "contexts": [
            "Segmentation free method show their advantages in the problems of the sequence to sequence, such as handwritten recognition [11], speech recognition [12]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Speech recognition with deep recurrent neural networks",
            "abstract": "Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.",
            "year": 2013,
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "authors": [
              {
                "authorId": "1753223",
                "name": "Alex Graves"
              },
              {
                "authorId": "40360972",
                "name": "Abdel-rahman Mohamed"
              },
              {
                "authorId": "1695689",
                "name": "Geoffrey E. Hinton"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206741496,
          "isinfluential": false,
          "contexts": [
            "VOLUME XX, 2017 9 method show their advantages in the problems of the sequence to sequence such as handwritten recognition [11], speech recognition [12]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Speech recognition with deep recurrent neural networks",
            "abstract": "Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.",
            "year": 2013,
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "authors": [
              {
                "authorId": "1753223",
                "name": "Alex Graves"
              },
              {
                "authorId": "40360972",
                "name": "Abdel-rahman Mohamed"
              },
              {
                "authorId": "1695689",
                "name": "Geoffrey E. Hinton"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "C. Wiginton proposed a page handwritten recognition composing Region Proposal Network to find the start position of text lines, line follower network to normalize text lines and CNN-LSTM network to do text recognition [16]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "4785929": {
      "citing_paper_info": {
        "title": "High Performance Layout Analysis of Medieval European Document Images",
        "abstract": "Layout analysis, mainly including binarization and page segmentation, is one of the most important performance determining steps of an OCR system for complex medieval document images, which contain noise, distortions and irregular layouts. In this paper, we present high performance page segmentation techniques for medieval European document images which include a novel main-body and side-notes segregation and an improved version of OCRopus (OCRopus, ) based text line extraction. In order to complete the high performance layout analysis pipeline, we have also presented the application of the percentile based binarization (Afzal et al., 2014) and the multiresolution morphology based text and non-text segmentation (Bukhari et al., 2011) methods over historical document images. presented layout analysis techniques are applied to a collection of the 15th century Latin document images, which achieved more than 90% accuracy for each of the segmentation techniques.",
        "year": 2018,
        "venue": "International Conference on Pattern Recognition Applications and Methods",
        "authors": [
          {
            "authorId": "145461897",
            "name": "S. S. Bukhari"
          },
          {
            "authorId": "2118590635",
            "name": "Ashutosh Gupta"
          },
          {
            "authorId": "1707654",
            "name": "A. Tiwari"
          },
          {
            "authorId": "145279674",
            "name": "A. Dengel"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 1,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "10505962",
        "1411363",
        "23399574",
        "62269638",
        "15921038"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1411363,
          "isinfluential": false,
          "contexts": [
            "…of six algorithms for page segmentation on Nastaliq script: the x-y cut (Nagy et al., 1992), the smearing (Wong et al., 1982), whitespace analysis (Baird, 1994), the constrained text-line finding (Baird, 2002), Docstrum (OGorman, 1993), and the Voronoi-diagram based approach (Kise et al., 1998).",
            ", 1982), whitespace analysis (Baird, 1994), the constrained text-line finding (Baird, 2002), Docstrum (OGorman, 1993), and the Voronoi-diagram based approach (Kise et al."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Two Geometric Algorithms for Layout Analysis",
            "abstract": "",
            "year": 2002,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1733858",
                "name": "T. Breuel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10505962,
          "isinfluential": false,
          "contexts": [
            "The performance of classification based on text and non-text segmentation approaches (Bukhari et al., 2010) heavily depends on training samples, and they can not be directly applied to different scripts."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Document image segmentation using discriminative learning over connected components",
            "abstract": "",
            "year": 2010,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "145461897",
                "name": "S. S. Bukhari"
              },
              {
                "authorId": "3290619",
                "name": "M. A. Azawi"
              },
              {
                "authorId": "1688013",
                "name": "F. Shafait"
              },
              {
                "authorId": "1733858",
                "name": "T. Breuel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15921038,
          "isinfluential": true,
          "contexts": [
            "On the other hand, smearing (Wong et al., 1982) and multiresolution morphology (Bloomberg, 1991), (Bukhari et al.",
            "…al., 2007) have evaluated the performance of six algorithms for page segmentation on Nastaliq script: the x-y cut (Nagy et al., 1992), the smearing (Wong et al., 1982), whitespace analysis (Baird, 1994), the constrained text-line finding (Baird, 2002), Docstrum (OGorman, 1993), and the…",
            "On the other hand, smearing (Wong et al., 1982) and multiresolution morphology (Bloomberg, 1991), (Bukhari et al., 2011) based approaches work on an assumption that non-text el-\n324 Bukhari, S., Gupta, A., Tiwari, A. and Dengel, A. High Performance Layout Analysis of Medieval European Document…",
            ", 1992), the smearing (Wong et al., 1982), whitespace analysis (Baird, 1994), the constrained text-line finding (Baird, 2002), Docstrum (OGorman, 1993), and the Voronoi-diagram based approach (Kise et al."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document Analysis System",
            "abstract": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included.",
            "year": 1982,
            "venue": "IBM Journal of Research and Development",
            "authors": [
              {
                "authorId": "145470231",
                "name": "Kwan Y. Wong"
              },
              {
                "authorId": "34896449",
                "name": "R. Casey"
              },
              {
                "authorId": "1880661",
                "name": "F. Wahl"
              }
            ]
          }
        },
        {
          "citedcorpusid": 23399574,
          "isinfluential": false,
          "contexts": [
            ", 1982), whitespace analysis (Baird, 1994), the constrained text-line finding (Baird, 2002), Docstrum (OGorman, 1993), and the Voronoi-diagram based approach (Kise et al., 1998).",
            "…of six algorithms for page segmentation on Nastaliq script: the x-y cut (Nagy et al., 1992), the smearing (Wong et al., 1982), whitespace analysis (Baird, 1994), the constrained text-line finding (Baird, 2002), Docstrum (OGorman, 1993), and the Voronoi-diagram based approach (Kise et al., 1998)."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Page Images Using the Area Voronoi Diagram",
            "abstract": "This paper presents a method of page segmentation based on the approximated area Voronoi diagram. The characteristics of the proposed method are as follows: (1) The Voronoi diagram enables us to obtain the candidates of boundaries of document components from page images with non-Manhattan layout and a skew. (2) The candidates are utilized to estimate the intercharacter and interline gaps without the use of domain-specific parameters to select the boundaries. From the experimental results for 128 images with non-Manhattan layout and the skew of 0°~45° as well as 98 images with Manhattan layout, we have confirmed that the method is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis.",
            "year": 1998,
            "venue": "Computer Vision and Image Understanding",
            "authors": [
              {
                "authorId": "3277321",
                "name": "K. Kise"
              },
              {
                "authorId": "2064863306",
                "name": "A. Sato"
              },
              {
                "authorId": "40411993",
                "name": "M. Iwata"
              }
            ]
          }
        },
        {
          "citedcorpusid": 62269638,
          "isinfluential": false,
          "contexts": [
            ", 1982) and multiresolution morphology (Bloomberg, 1991), (Bukhari et al.",
            "On the other hand, smearing (Wong et al., 1982) and multiresolution morphology (Bloomberg, 1991), (Bukhari et al., 2011) based approaches work on an assumption that non-text el-\n324 Bukhari, S., Gupta, A., Tiwari, A. and Dengel, A. High Performance Layout Analysis of Medieval European Document…",
            "Bloomberg (Bloomberg, 1991) presented a multiresolution morphology based text and non-text segmentation method."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Multiresolution Morphological Approach to Document Image Analysis",
            "abstract": "An image-based approach to document image analysis is presented. The methods are motivated by a merged view of shape and textural image properties at multiple scales. The principal binary image operations are morphological and multiresolution. The generalized opening is introduced for extraction of both shape and texture from an image. Threshold reduction operations are introduced for performing efficient and controllable shape and texture transformations between resolution levels. Some problems, such as halftone or dark area segmentation, can be in large part solved by a sequence of threshold reductions. Aspects of the approach are illustrated by the problem of identifying italic and bold words in text, using word-level extraction at lowered resolution. The computational costs of the basic operations are given, so that algorithm efficienc y can be estimated, and the importance of operating at the lowest feasable resolution is demonstrated. For example, word segmentation and halftone extraction proceed in excess of 1.5x10 image pixels/second on a Sun Sparcstation2 .",
            "year": 1991,
            "venue": "",
            "authors": [
              {
                "authorId": "3308281",
                "name": "D. Bloomberg"
              }
            ]
          }
        }
      ]
    },
    "204837345": {
      "citing_paper_info": {
        "title": "Layout Analysis of Tibetan Historical Documents Based on Deep Learning",
        "abstract": "Tibetan historical document are vast, second in quantity only to Chinese historical document in China, and they are considered a treasure of Chinese culture. The digital protection and utilization of Tibetan literature resources is a hot topic in the field of literature digitization. Layout analysis is an important basic step in the digitization of historical document. Tibetan historical document have a complex layout, a variety of graphic and text forms, and diverse backgrounds, all of which have an impact on the layout analysis. We design a method combining deep learning text line detection with rule-based layout analysis to realize layout analysis of Tibetan historical document. This method first conducts text detection through deep learning, then constructs text lines, and finally segments horizontal text regions and vertical text regions by rule analysis to realize the segmentation of the layout. Our self-built datasets with rich sample types show that the proposed method can achieve detection of a variety of layouts with high accuracy and provide reliable text regions for subsequent text recognition, thus offering strong application value.",
        "year": 2019,
        "venue": "Proceedings of the 2019 the International Conference on Pattern Recognition and Artificial Intelligence  - PRAI '19",
        "authors": [
          {
            "authorId": "15840116",
            "name": "Yong Cuo"
          },
          {
            "authorId": "4577369",
            "name": "N. Tashi"
          },
          {
            "authorId": "1390625008",
            "name": "Zhengzhen Liu"
          },
          {
            "authorId": "48477403",
            "name": "Qiuhua Wei"
          },
          {
            "authorId": "1380208434",
            "name": "Luosang Gadeng"
          },
          {
            "authorId": "1380208429",
            "name": "Gama Trashi"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 0,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "11341313",
        "1565945",
        "706860",
        "14728290",
        "2214682"
      ],
      "citation_details": [
        {
          "citedcorpusid": 706860,
          "isinfluential": false,
          "contexts": [
            "Training samples need to be labeled at the pixel level, as in [10,16,22,24,25]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "EAST: An Efficient and Accurate Scene Text Detector",
            "abstract": "Previous approaches for scene text detection have already achieved promising performances across various benchmarks. However, they usually fall short when dealing with challenging scenarios, even when equipped with deep neural network models, because the overall performance is determined by the interplay of multiple stages and components in the pipelines. In this work, we propose a simple yet powerful pipeline that yields fast and accurate text detection in natural scenes. The pipeline directly predicts words or text lines of arbitrary orientations and quadrilateral shapes in full images, eliminating unnecessary intermediate steps (e.g., candidate aggregation and word partitioning), with a single neural network. The simplicity of our pipeline allows concentrating efforts on designing loss functions and neural network architecture. Experiments on standard datasets including ICDAR 2015, COCO-Text and MSRA-TD500 demonstrate that the proposed algorithm significantly outperforms state-of-the-art methods in terms of both accuracy and efficiency. On the ICDAR 2015 dataset, the proposed algorithm achieves an F-score of 0.7820 at 13.2fps at 720p resolution.",
            "year": 2017,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2148927556",
                "name": "Xinyu Zhou"
              },
              {
                "authorId": "2146721",
                "name": "C. Yao"
              },
              {
                "authorId": "2075348632",
                "name": "He Wen"
              },
              {
                "authorId": "47905836",
                "name": "Yuzhi Wang"
              },
              {
                "authorId": "35132667",
                "name": "Shuchang Zhou"
              },
              {
                "authorId": "2416953",
                "name": "Weiran He"
              },
              {
                "authorId": "1387852255",
                "name": "Jiajun Liang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1565945,
          "isinfluential": false,
          "contexts": [
            "In the mid-1990s, several researchers, as in [4-5], took the lead in the development of natural scene text detection."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Recognizing Characters in Scene Images",
            "abstract": "An effective algorithm for character recognition in scene images is studied. Scene images are segmented into regions by an image segmentation method based on adaptive thresholding. Character candidate regions are detected by observing gray-level differences between adjacent regions. To ensure extraction of multisegment characters as well as single-segment characters, character pattern candidates are obtained by associating the detected regions according to their positions and gray levels. A character recognition process selects patterns with high similarities by calculating the similarities between character pattern candidates and the standard patterns in a dictionary and then comparing the similarities to the thresholds. A relaxational approach to determine character patterns updates the similarities by evaluating the interactions between categories of patterns, and finally character patterns and their recognition results are obtained. Highly promising experimental results have been obtained using the method on 100 images involving characters of different sizes and formats under uncontrolled lighting. >",
            "year": 1994,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1708785",
                "name": "J. Ohya"
              },
              {
                "authorId": "2019875",
                "name": "A. Shio"
              },
              {
                "authorId": "49052113",
                "name": "S. Akamatsu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2214682,
          "isinfluential": false,
          "contexts": [
            "Training samples need to be labeled at the pixel level, as in [10,16,22,24,25]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Multi-oriented Text Detection with Fully Convolutional Networks",
            "abstract": "In this paper, we propose a novel approach for text detection in natural images. Both local and global cues are taken into account for localizing text lines in a coarse-to-fine procedure. First, a Fully Convolutional Network (FCN) model is trained to predict the salient map of text regions in a holistic manner. Then, text line hypotheses are estimated by combining the salient map and character components. Finally, another FCN classifier is used to predict the centroid of each character, in order to remove the false hypotheses. The framework is general for handling text in multiple orientations, languages and fonts. The proposed method consistently achieves the state-of-the-art performance on three text detection benchmarks: MSRA-TD500, ICDAR2015 and ICDAR2013.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "38448016",
                "name": "Zheng Zhang"
              },
              {
                "authorId": "1979323",
                "name": "Chengquan Zhang"
              },
              {
                "authorId": "41187410",
                "name": "Wei Shen"
              },
              {
                "authorId": "2146721",
                "name": "C. Yao"
              },
              {
                "authorId": null,
                "name": "Wenyu Liu"
              },
              {
                "authorId": "145905113",
                "name": "X. Bai"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11341313,
          "isinfluential": false,
          "contexts": [
            "…on the results of character detection, while character detection usually distinguishes between candidate text and background based on low-level features, such as stroke width transform (SWT)[8], maximally stable extremal regions (MSER) [17], and histogram of oriented gradient (HOG)[18-20]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Strokelets: A Learned Multi-scale Representation for Scene Text Recognition",
            "abstract": "",
            "year": 2014,
            "venue": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2146721",
                "name": "C. Yao"
              },
              {
                "authorId": "145905113",
                "name": "X. Bai"
              },
              {
                "authorId": "2276155",
                "name": "Baoguang Shi"
              },
              {
                "authorId": null,
                "name": "Wenyu Liu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14728290,
          "isinfluential": false,
          "contexts": [
            "Inspired by reference [9], we propose a layout analysis method for Tibetan historical document based on a connectionist text proposal network (CTPN).",
            "The CTPN algorithm, as in [9], shows good detection results in natural scenes and higher accuracy compared to Faster R-CNN and SSD.",
            "A large number of natural scene text detection methods based on deep learning have emerged, as in [1,3,6,7,9-15]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Detecting Text in Natural Image with Connectionist Text Proposal Network",
            "abstract": "We propose a novel Connectionist Text Proposal Network (CTPN) that accurately localizes text lines in natural image. The CTPN detects a text line in a sequence of fine-scale text proposals directly in convolutional feature maps. We develop a vertical anchor mechanism that jointly predicts location and text/non-text score of each fixed-width proposal, considerably improving localization accuracy. The sequential proposals are naturally connected by a recurrent neural network, which is seamlessly incorporated into the convolutional network, resulting in an end-to-end trainable model. This allows the CTPN to explore rich context information of image, making it powerful to detect extremely ambiguous text. The CTPN works reliably on multi-scale and multi-language text without further post-processing, departing from previous bottom-up methods requiring multi-step post filtering. It achieves 0.88 and 0.61 F-measure on the ICDAR 2013 and 2015 benchmarks, surpassing recent results [8, 35] by a large margin. The CTPN is computationally efficient with 0.14 s/image, by using the very deep VGG16 model [27]. Online demo is available: http://textdet.com/.",
            "year": 2016,
            "venue": "European Conference on Computer Vision",
            "authors": [
              {
                "authorId": "40219976",
                "name": "Zhi Tian"
              },
              {
                "authorId": "49015548",
                "name": "Weilin Huang"
              },
              {
                "authorId": "2118328320",
                "name": "Tong He"
              },
              {
                "authorId": "50462511",
                "name": "Pan He"
              },
              {
                "authorId": "143970608",
                "name": "Y. Qiao"
              }
            ]
          }
        }
      ]
    },
    "255875328": {
      "citing_paper_info": {
        "title": "End-to-End Transcript Alignment of 17th Century Manuscripts: The Case of Moccia Code",
        "abstract": "The growth of digital libraries has yielded a large number of handwritten historical documents in the form of images, often accompanied by a digital transcription of the content. The ability to track the position of the words of the digital transcription in the images can be important both for the study of the document by humanities scholars and for further automatic processing. We propose a learning-free method for automatically aligning the transcription to the document image. The method receives as input the digital image of the document and the transcription of its content and aims at linking the transcription to the corresponding images within the page at the word level. The method comprises two main original contributions: a line-level segmentation algorithm capable of detecting text lines with curved baseline, and a text-to-image alignment algorithm capable of dealing with under- and over-segmentation errors at the word level. Experiments on pages from a 17th-century Italian manuscript have demonstrated that the line segmentation method allows one to segment 92% of the text line correctly. They also demonstrated that it achieves a correct alignment accuracy greater than 68%. Moreover, the performance achieved on widely used data sets compare favourably with the state of the art.",
        "year": 2023,
        "venue": "Journal of Imaging",
        "authors": [
          {
            "authorId": "2075778349",
            "name": "Giuseppe De Gregorio"
          },
          {
            "authorId": "2084057935",
            "name": "Giuliana Capriolo"
          },
          {
            "authorId": "2136508708",
            "name": "Angelo Marcelli"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 0,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "12659334",
        "181736636",
        "22709212",
        "15181078",
        "29159089"
      ],
      "citation_details": [
        {
          "citedcorpusid": 12659334,
          "isinfluential": false,
          "contexts": [
            "[13] first perform a word-segmentation and then the segments are matched with the transcriptions.",
            "[13] Handwritten Kabinet van de Koningin (KdK) collection XIX Only images Transcription not available Ink Projection Segmentation 69."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text-image alignment for historical handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "1784334",
                "name": "S. Zinger"
              },
              {
                "authorId": "1806832",
                "name": "J. Nerbonne"
              },
              {
                "authorId": "1799278",
                "name": "Lambert Schomaker"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15181078,
          "isinfluential": false,
          "contexts": [
            "[10] propose to align word segmentation boxes to transcription words using a Dynamic Time Wrapping algorithm.",
            "[10] Handwritten George Washington XVIII Yes Dynamic Time Warping 75."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Text alignment with handwritten documents",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "2711577",
                "name": "E. Kornfield"
              },
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              },
              {
                "authorId": "144890574",
                "name": "James Allan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22709212,
          "isinfluential": false,
          "contexts": [
            "48% [17] Handwritten Queste del Saint Graal IX Yes Segmentation Free 72.",
            "[17] avoid the segmentation and learning phase."
          ],
          "intents": [
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Learning-Free Text-Image Alignment for Medieval Manuscripts",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "3100171",
                "name": "Yann Leydier"
              },
              {
                "authorId": "1721326",
                "name": "V. Eglin"
              },
              {
                "authorId": "1784847",
                "name": "S. Bres"
              },
              {
                "authorId": "2064656632",
                "name": "Dominique Stutzmann"
              }
            ]
          }
        },
        {
          "citedcorpusid": 29159089,
          "isinfluential": false,
          "contexts": [
            "All these issues restrict the possibility of a direct comparison to the methods that have been tested on the Bentham, the George Washington, and the Jefferson Letter data sets because the test sets are publicly available in the repositories.",
            "Moreover, as the implementation of the first method is also publicly available, we have reported the performance achieved by our method and its competitors on the Bentham [37], the George Washington [38] and the Jefferson Letter [9] datasets, as they fall within the same historical period as the Moccia Code, and the Saint Gall [39], although it contains documents produced in the Middle Age, because it is among the most widely used for performance assessment."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Word spotting for historical documents",
            "abstract": "",
            "year": 2006,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "2352980",
                "name": "T. Rath"
              },
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              }
            ]
          }
        },
        {
          "citedcorpusid": 181736636,
          "isinfluential": false,
          "contexts": [
            "remarkable performance in different tasks, such as image quality enhancement, text-line segmentation, keyword spotting and character recognition [6], as well as in handwriting text recognition [7]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A set of benchmarks for Handwritten Text Recognition on historical documents",
            "abstract": "",
            "year": 2019,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1928123",
                "name": "Joan Andreu Sánchez"
              },
              {
                "authorId": "2218294739",
                "name": "Joan-Andreu Sánchez"
              },
              {
                "authorId": "144340605",
                "name": "Verónica Romero"
              },
              {
                "authorId": "52151344",
                "name": "A. Toselli"
              },
              {
                "authorId": "41206897",
                "name": "M. Villegas"
              },
              {
                "authorId": "143783065",
                "name": "E. Vidal"
              }
            ]
          }
        }
      ]
    },
    "256391516": {
      "citing_paper_info": {
        "title": "Text Line Segmentation in Historical Newspapers",
        "abstract": "",
        "year": 2022,
        "venue": "International Conference on Artificial Intelligence and Soft Computing",
        "authors": [
          {
            "authorId": "2628715",
            "name": "Ladislav Lenc"
          },
          {
            "authorId": "40800185",
            "name": "J. Martínek"
          },
          {
            "authorId": "3246597",
            "name": "P. Král"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 9,
        "unique_cited_count": 9,
        "influential_count": 0,
        "detailed_records_count": 9
      },
      "cited_papers": [
        "39049104",
        "3238570",
        "3770261",
        "15401169",
        "5987534",
        "20278237",
        "7244356",
        "9814021",
        "211026625"
      ],
      "citation_details": [
        {
          "citedcorpusid": 3238570,
          "isinfluential": false,
          "contexts": [
            "Another FCN-based model in the biomedical domain was proposed by Novikov et al. [17]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Fully Convolutional Architectures for Multiclass Segmentation in Chest Radiographs",
            "abstract": "The success of deep convolutional neural networks (NNs) on image classification and recognition tasks has led to new applications in very diversified contexts, including the field of medical imaging. In this paper, we investigate and propose NN architectures for automated multiclass segmentation of anatomical organs in chest radiographs (CXRs), namely for lungs, clavicles, and heart. We address several open challenges including model overfitting, reducing number of parameters, and handling of severely imbalanced data in CXR by fusing recent concepts in convolutional networks and adapting them to the segmentation problem task in CXR. We demonstrate that our architecture combining delayed subsampling, exponential linear units, highly restrictive regularization, and a large number of high-resolution low-level abstract features outperforms state-of-the-art methods on all considered organs, as well as the human observer on lungs and heart. The models use a multiclass configuration with three target classes and are trained and tested on the publicly available Japanese Society of Radiological Technology database, consisting of 247 X-ray images the ground-truth masks for which are available in the segmentation in CXR database. Our best performing model, trained with the loss function based on the Dice coefficient, reached mean Jaccard overlap scores of 95% for lungs, 86.8% for clavicles, and 88.2% for heart. This architecture outperformed the human observer results for lungs and heart.",
            "year": 2017,
            "venue": "IEEE Transactions on Medical Imaging",
            "authors": [
              {
                "authorId": "144749230",
                "name": "A. A. Novikov"
              },
              {
                "authorId": "7275181",
                "name": "D. Lenis"
              },
              {
                "authorId": "2064806166",
                "name": "David Major"
              },
              {
                "authorId": "1883027",
                "name": "J. Hladůvka"
              },
              {
                "authorId": "88258871",
                "name": "M. Wimmer"
              },
              {
                "authorId": "1759884",
                "name": "K. Bühler"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3770261,
          "isinfluential": false,
          "contexts": [
            "Text Segmentation We use two pixel-based metrics, namely F1-score [19] and intersection over union (IoU) also known as Jaccard index [20] that are standard metrics in the segmentation task."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation",
            "abstract": "Commonly used evaluation measures including Recall, Precision, F-Factor and Rand Accuracy are biased and should not be used without clear understanding of the biases, and corresponding identification of chance or base case levels of the statistic. Using these measures a system that performs worse in the objective sense of Informedness, can appear to perform better under any of these commonly used measures. We discuss several concepts and measures that reflect the probability that prediction is informed versus chance. Informedness and introduce Markedness as a dual measure for the probability that prediction is marked versus chance. Finally we demonstrate elegant connections between the concepts of Informedness, Markedness, Correlation and Significance as well as their intuitive relationships with Recall and Precision, and outline the extension from the dichotomous case to the general multi-class case. .",
            "year": 2011,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "144871539",
                "name": "D. Powers"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5987534,
          "isinfluential": false,
          "contexts": [
            "An approach aiming at historical documents proposed by Chen et al. [3] is based on super-pixel calculation us-ing simple linear iterative clustering [1]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Convolutional Neural Networks for Page Segmentation of Historical Document Images",
            "abstract": "This paper presents a page segmentation method for handwritten historical document images based on a Convolutional Neural Network (CNN). We consider page segmentation as a pixel labeling problem, i.e., each pixel is classified as one of the predefined classes. Traditional methods in this area rely on hand-crafted features carefully tuned considering prior knowledge. In contrast, we propose to learn features from raw image pixels using a CNN. While many researchers focus on developing deep CNN architectures to solve different problems, we train a simple CNN with only one convolution layer. We show that the simple architecture achieves competitive results against other deep architectures on different public datasets. Experiments also demonstrate the effectiveness and superiority of the proposed method compared to previous methods.",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "153819461",
                "name": "Kai Chen"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7244356,
          "isinfluential": false,
          "contexts": [
            "Current OCR algorithms usually rely on neural networks that recognise whole text lines [24,2,23]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "High-Performance OCR for Printed English and Fraktur Using LSTM Networks",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1733858",
                "name": "T. Breuel"
              },
              {
                "authorId": "1403326950",
                "name": "A. Ul-Hasan"
              },
              {
                "authorId": "3290619",
                "name": "M. A. Azawi"
              },
              {
                "authorId": "1688013",
                "name": "F. Shafait"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9814021,
          "isinfluential": false,
          "contexts": [
            "This method outperformed a previously presented method [4] which solves document segmentation by convolutional auto-encoders."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Page segmentation of historical document images with convolutional autoencoders",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "153819461",
                "name": "Kai Chen"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1722800",
                "name": "J. Hennebert"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15401169,
          "isinfluential": false,
          "contexts": [
            "The authors use intersection over union (IoU) and ZoneMap metric [9] for document region segmentation evaluation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The zonemap metric for page segmentation and area classification in scanned documents",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Information Photonics",
            "authors": [
              {
                "authorId": "1701385",
                "name": "Olivier Galibert"
              },
              {
                "authorId": "35798452",
                "name": "Juliette Kahn"
              },
              {
                "authorId": "3135839",
                "name": "I. Oparin"
              }
            ]
          }
        },
        {
          "citedcorpusid": 20278237,
          "isinfluential": false,
          "contexts": [
            "The R-value indicates how reliably the text is detected – ignoring layout issues while the P-value indicates how reliable the structure of the text lines (layout) is [10].",
            "Comparison of our text-line detection algorithm applied on the whole page (page-level) and results of the presented system (region-level); evaluation metrics are adopted from [10];we report average values for P-value, R-value and F-value"
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "READ-BAD: A New Dataset and Evaluation Scheme for Baseline Detection in Archival Documents",
            "abstract": "Text line detection is crucial for any application associated with Automatic Text Recognition or Keyword Spotting. Modern algorithms perform good on well-established datasets since they either comprise clean data or simple/homogeneous page layouts. We have collected and annotated 2036 archival document images from different locations and time periods. The dataset contains varying page layouts and degradations that challenge text line segmentation methods. Well established text line segmentation evaluation schemes such as the Detection Rate or Recognition Accuracy demand for binarized data that is annotated on a pixel level. Producing ground truth by these means is laborious and not needed to determine a method's quality. In this paper we propose a new evaluation scheme that is based on baselines. The proposed scheme has no need for binarization and it can handle skewed as well as rotated text lines. The ICDAR 2017 Competition on Baseline Detection and the ICDAR 2017 Competition on Layout Analysis for Challenging Medieval Manuscripts used this evaluation scheme. Finally, we present results achieved by a recently published text line detection algorithm.",
            "year": 2017,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              },
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 39049104,
          "isinfluential": false,
          "contexts": [
            "Current OCR algorithms usually rely on neural networks that recognise whole text lines [24,2,23]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Recognition of historical Greek polytonic scripts using LSTM networks",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2860677",
                "name": "Fotini Simistira"
              },
              {
                "authorId": "1403326950",
                "name": "A. Ul-Hasan"
              },
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211026625,
          "isinfluential": false,
          "contexts": [
            "A complex document segmentation and evaluation method was proposed by Li et al. [14]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Instance Aware Document Image Segmentation using Label Pyramid Networks and Deep Watershed Transformation",
            "abstract": "Segmentation of complex document images remains a challenge due to the large variability of layout and image degradation. In this paper, we propose a method to segment complex document images based on Label Pyramid Network (LPN) and Deep Watershed Transform (DWT). The method can segment document images into instance aware regions including text lines, text regions, figures, tables, etc. The backbone of LPN can be any type of Fully Convolutional Networks (FCN), and in training, label map pyramids on training images are provided to exploit the hierarchical boundary information of regions efficiently through multi-task learning. The label map pyramid is transformed from region class label map by distance transformation and multi-level thresholding. In segmentation, the outputs of multiple tasks of LPN are summed into one single probability map, on which watershed transformation is carried out to segment the document image into instance aware regions. In experiments on four public databases, our method is demonstrated effective and superior, yielding state of the art performance for text line segmentation, baseline detection and region segmentation.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "48569353",
                "name": "Xiaohui Li"
              },
              {
                "authorId": "145820427",
                "name": "Fei Yin"
              },
              {
                "authorId": "1708162759",
                "name": "Tao Xue"
              },
              {
                "authorId": "2116179604",
                "name": "Long Liu"
              },
              {
                "authorId": "1695766",
                "name": "J. Ogier"
              },
              {
                "authorId": "1689269",
                "name": "Cheng-Lin Liu"
              }
            ]
          }
        }
      ]
    },
    "268309003": {
      "citing_paper_info": {
        "title": "Historical Text Line Segmentation Using Deep Learning Algorithms: Mask-RCNN against U-Net Networks",
        "abstract": "Text line segmentation is a necessary preliminary step before most text transcription algorithms are applied. The leading deep learning networks used in this context (ARU-Net, dhSegment, and Doc-UFCN) are based on the U-Net architecture. They are efficient, but fall under the same concept, requiring a post-processing step to perform instance (e.g., text line) segmentation. In the present work, we test the advantages of Mask-RCNN, which is designed to perform instance segmentation directly. This work is the first to directly compare Mask-RCNN- and U-Net-based networks on text segmentation of historical documents, showing the superiority of the former over the latter. Three studies were conducted, one comparing these networks on different historical databases, another comparing Mask-RCNN with Doc-UFCN on a private historical database, and a third comparing the handwritten text recognition (HTR) performance of the tested networks. The results showed that Mask-RCNN outperformed ARU-Net, dhSegment, and Doc-UFCN using relevant line segmentation metrics, that performance evaluation should not focus on the raw masks generated by the networks, that a light mask processing is an efficient and simple solution to improve evaluation, and that Mask-RCNN leads to better HTR performance.",
        "year": 2024,
        "venue": "Journal of Imaging",
        "authors": [
          {
            "authorId": "2290574026",
            "name": "Florian Côme Fizaine"
          },
          {
            "authorId": "49456597",
            "name": "Patrick Bard"
          },
          {
            "authorId": "2282439525",
            "name": "Michel Paindavoine"
          },
          {
            "authorId": "2290575488",
            "name": "Cécile Robin"
          },
          {
            "authorId": "2290574056",
            "name": "Edouard Bouyé"
          },
          {
            "authorId": "2290511154",
            "name": "Raphaël Lefèvre"
          },
          {
            "authorId": "2290578031",
            "name": "Annie Vinter"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 17,
        "unique_cited_count": 16,
        "influential_count": 2,
        "detailed_records_count": 17
      },
      "cited_papers": [
        "26232274",
        "245854320",
        "206770307",
        "247618781",
        "4246903",
        "13756489",
        "59336154",
        "251018572",
        "248640027",
        "54465873",
        "10328909",
        "237563224",
        "4761833",
        "29622813",
        "237581568",
        "27494128"
      ],
      "citation_details": [
        {
          "citedcorpusid": 4246903,
          "isinfluential": true,
          "contexts": [
            "In addition to these two metrics, we calculated the averaged precision (AP) from the PASCAL VOC Challenge [34] at different IoU thresholds (0.5, 0.75), and the mean of the AP (AP@[0.5,0.95]) from 0.5 to 0.95."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "International Journal of Computer Vision manuscript No. (will be inserted by the editor) The PASCAL Visual Object Classes (VOC) Challenge",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 4761833,
          "isinfluential": false,
          "contexts": [
            "To complete the DRoSB database and to compare the performance of Mask-RCNN with U-Net networks, we added the cBaD 2017 database provided for the ICDAR 2017 conference competition [4], the DIVA-HisDB, and the HOME-Alcar database for the training of Mask-RCNN.",
            "Among them, a common and competitive approach distinguishes two phases in the process [4].",
            "U-Net and Mask-RCNN networks are then compared in the context of text line segmentation for text transcription using different public databases (cBaD 2017 READ-Complex [4], DIVA-HisDB[18], HOME-Alcar[19]) and a private database (the Deliberation Registers of the States of Burgundy, hereafter DRoSB)."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "cBAD: ICDAR2017 Competition on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              },
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10328909,
          "isinfluential": false,
          "contexts": [
            "Mask-RCNN [14] is built on top of Faster-RCNN [24], an object detection network."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
            "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available",
            "year": 2015,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              },
              {
                "authorId": "2032184078",
                "name": "Jian Sun"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13756489,
          "isinfluential": false,
          "contexts": [
            "In this study, the output of both networks fed a neural network dedicated to transcription, precisely a Transformer network [41]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Attention is All you Need",
            "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
            "year": 2017,
            "venue": "Neural Information Processing Systems",
            "authors": [
              {
                "authorId": "40348417",
                "name": "Ashish Vaswani"
              },
              {
                "authorId": "1846258",
                "name": "Noam M. Shazeer"
              },
              {
                "authorId": "3877127",
                "name": "Niki Parmar"
              },
              {
                "authorId": "39328010",
                "name": "Jakob Uszkoreit"
              },
              {
                "authorId": "145024664",
                "name": "Llion Jones"
              },
              {
                "authorId": "19177000",
                "name": "Aidan N. Gomez"
              },
              {
                "authorId": "40527594",
                "name": "Lukasz Kaiser"
              },
              {
                "authorId": "3443442",
                "name": "I. Polosukhin"
              }
            ]
          }
        },
        {
          "citedcorpusid": 26232274,
          "isinfluential": false,
          "contexts": [
            "However, we are not proposing a new metric with the LMP, as [35] did with the FgPA, but a new mask processing in order to make existing metrics more accurate.",
            "These steps are similar to those described for foreground pixel accuracy (FgPA) in [35]."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Fully Convolutional Neural Networks for Page Segmentation of Historical Document Images",
            "abstract": "We propose a high-performance fully convolutional neural network (FCN) for historical document segmentation that is designed to process a single page in one step. The advantage of this model beside its speed is its ability to directly learn from raw pixels instead of using preprocessing steps e. g. feature computation or superpixel generation. We show that this network yields better results than existing methods on different public data sets. For evaluation of this model we introduce a novel metric that is independent of ambiguous ground truth called Foreground Pixel Accuracy (FgPA). This pixel based measure only counts foreground pixels in the binarized page, any background pixel is omitted. The major advantage of this metric is, that it enables researchers to compare different segmentation methods on their ability to successfully segment text or pictures and not on their ability to learn and possibly overfit the peculiarities of an ambiguous hand-made ground truth segmentation.",
            "year": 2017,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "144603426",
                "name": "C. Wick"
              },
              {
                "authorId": "1707592",
                "name": "F. Puppe"
              }
            ]
          }
        },
        {
          "citedcorpusid": 27494128,
          "isinfluential": false,
          "contexts": [
            "U-Net is a fully convolutional neural network (FCNN) [23] with a U-shape, as shown in Figure 2."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Text Line Segmentation Using Fully Convolutional Network",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "47689382",
                "name": "G. Renton"
              },
              {
                "authorId": "1712446",
                "name": "Clément Chatelain"
              },
              {
                "authorId": "143680806",
                "name": "Sébastien Adam"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 29622813,
          "isinfluential": false,
          "contexts": [
            "Then, the entire model was trained on the IAM dataset [38]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The IAM-database: an English sentence database for offline handwriting recognition",
            "abstract": "",
            "year": 2002,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "37526757",
                "name": "Urs-Viktor Marti"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 54465873,
          "isinfluential": false,
          "contexts": [
            "The main architectures used for this purpose, originally developed for applications in the medical domain, are the U-Net [13] and the Mask-RCNN [14] networks, which are based on different philosophies, as we will see in the next section.",
            "The original paper [14] proposed three scales and three aspect ratios per location, i.e., nine anchors per region.",
            "Mask-RCNN [14] is built on top of Faster-RCNN [24], an object detection network."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Mask R-CNN",
            "abstract": "We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.",
            "year": 2017,
            "venue": "",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2082991",
                "name": "Georgia Gkioxari"
              },
              {
                "authorId": "3127283",
                "name": "Piotr Dollár"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 59336154,
          "isinfluential": false,
          "contexts": [
            "Vuola et al. [25] compared U-Net and Mask-RCNN networks in the medical field for the segmentation of general nuclei instances in microscopy images.",
            "These results are in line with the observations reported in a study in the medical domain [25], in which Mask-RCNN appeared to be optimal for separating close objects, while U-Net was better at detecting objects but tended to merge close objects."
          ],
          "intents": [
            "['background']",
            "['result']"
          ],
          "cited_paper_info": {
            "title": "Mask-RCNN and U-Net Ensembled for Nuclei Segmentation",
            "abstract": "Nuclei segmentation is both an important and in some ways ideal task for modern computer vision methods, e.g. convolutional neural networks. While recent developments in theory and open-source software have made these tools easier to implement, expert knowledge is still required to choose the right model architecture and training setup. We compare two popular segmentation frameworks, U-Net and Mask-RCNN in the nuclei segmentation task and find that they have different strengths and failures. To get the best of both worlds, we develop an ensemble model to combine their predictions that can outperform both models by a significant margin and should be considered when aiming for best nuclei segmentation performance.",
            "year": 2019,
            "venue": "IEEE International Symposium on Biomedical Imaging",
            "authors": [
              {
                "authorId": "89166179",
                "name": "A. Vuola"
              },
              {
                "authorId": "2309959",
                "name": "S. Akram"
              },
              {
                "authorId": "1776374",
                "name": "Juho Kannala"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206770307,
          "isinfluential": false,
          "contexts": [
            "Deep learning algorithms have led to significant improvements in the processing of complex images and especially in object detection, such as the Yolo [9], SSD [10] or Fast-RCNN [11] algorithms."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Fast R-CNN",
            "abstract": "This paper proposes Fast R-CNN, a clean and fast framework for object detection. Compared to traditional R-CNN, and its accelerated version SPPnet, Fast R-CNN trains networks using a multi-task loss in a single training stage. The multi-task loss simplifies learning and improves detection accuracy. Unlike SPPnet, all network layers can be updated during fine-tuning. We show that this difference has practical ramifications for very deep networks, such as VGG16, where mAP suffers when only the fully-connected layers are updated. Compared to\"slow\"R-CNN, Fast R-CNN is 9x faster at training VGG16 for detection, 213x faster at test-time, and achieves a significantly higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn",
            "year": 2015,
            "venue": "",
            "authors": [
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 237563224,
          "isinfluential": false,
          "contexts": [
            "On the basis of the Boillet et al.’s results [17], we selected three state-of-the-art U-Net architecture networks: dhSegment [20], ARU-Net [21], and Doc-UFCN [22], to compare the performance of Mask-RCNN.",
            "Three state-of-the-art networks based on the U-Net architecture [13], namely, dhSeg-ment [20], ARU-Net [21] and Doc-UFCN [22], are compared in [17], showing the efficiency of U-Net-based architectures, their current dominance for text line segmentation, and their limitations."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Including Keyword Position in Image-based Models for Act Segmentation of Historical Registers",
            "abstract": "The segmentation of complex images into semantic regions has seen a growing interest these last years with the advent of Deep Learning. Until recently, most existing methods for Historical Document Analysis focused on the visual appearance of documents, ignoring the rich information that textual content can offer. However, the segmentation of complex documents into semantic regions is sometimes impossible relying only on visual features and recent models embed both visual and textual information. In this paper, we focus on the use of both visual and textual information for segmenting historical registers into structured and meaningful units such as acts. An act is a text recording containing valuable knowledge such as demographic information (baptism, marriage or death) or royal decisions (donation or pardon). We propose a simple pipeline to enrich document images with the position of text lines containing key-phrases and show that running a standard image-based layout analysis system on these images can lead to significant gains. Our experiments show that the detection of acts increases from 38 % of mAP to 74 % when adding textual information, in real use-case conditions where text lines positions and content are extracted with an automatic recognition system.",
            "year": 2021,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "1380222130",
                "name": "Mélodie Boillet"
              },
              {
                "authorId": "1724401528",
                "name": "Martin Maarand"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              }
            ]
          }
        },
        {
          "citedcorpusid": 237581568,
          "isinfluential": false,
          "contexts": [
            "We chose TrOCR [36], because it is widely recognized as one of the best transcription models."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models",
            "abstract": "Text recognition is a long-standing research problem for document digitalization. Existing approaches are usually built based on CNN for image understanding and RNN for char-level text generation. In addition, another language model is usually needed to improve the overall accuracy as a post-processing step. In this paper, we propose an end-to-end text recognition approach with pre-trained image Transformer and text Transformer models, namely TrOCR, which leverages the Transformer architecture for both image understanding and wordpiece-level text generation. The TrOCR model is simple but effective, and can be pre-trained with large-scale synthetic data and fine-tuned with human-labeled datasets. Experiments show that the TrOCR model outperforms the current state-of-the-art models on the printed, handwritten and scene text recognition tasks. The TrOCR models and code are publicly available at https://aka.ms/trocr.",
            "year": 2021,
            "venue": "AAAI Conference on Artificial Intelligence",
            "authors": [
              {
                "authorId": "123545597",
                "name": "Minghao Li"
              },
              {
                "authorId": "1379581011",
                "name": "Tengchao Lv"
              },
              {
                "authorId": "2114843952",
                "name": "Lei Cui"
              },
              {
                "authorId": "38534822",
                "name": "Yijuan Lu"
              },
              {
                "authorId": "1882479",
                "name": "D. Florêncio"
              },
              {
                "authorId": "2109292017",
                "name": "Cha Zhang"
              },
              {
                "authorId": "1707275",
                "name": "Zhoujun Li"
              },
              {
                "authorId": "49807919",
                "name": "Furu Wei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 245854320,
          "isinfluential": false,
          "contexts": [
            "The superiority of Mask-RCNN for object separation was recently confirmed in two other applications [26,27]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Cross-Sectional Reproducibility Study of a Standard Camera Sensor Using Artificial Intelligence to Assess Food Items: The FoodIntech Project",
            "abstract": "Having a system to measure food consumption is important to establish whether individual nutritional needs are being met in order to act quickly and to minimize the risk of undernutrition. Here, we tested a smartphone-based food consumption assessment system named FoodIntech. FoodIntech, which is based on AI using deep neural networks (DNN), automatically recognizes food items and dishes and calculates food leftovers using an image-based approach, i.e., it does not require human intervention to assess food consumption. This method uses one-input and one-output images by means of the detection and synchronization of a QRcode located on the meal tray. The DNN are then used to process the images and implement food detection, segmentation and recognition. Overall, 22,544 situations analyzed from 149 dishes were used to test the reliability of this method. The reliability of the AI results, based on the central intra-class correlation coefficient values, appeared to be excellent for 39% of the dishes (n = 58 dishes) and good for 19% (n = 28). The implementation of this method is an effective way to improve the recognition of dishes and it is possible, with a sufficient number of photos, to extend the capabilities of the tool to new dishes and foods.",
            "year": 2022,
            "venue": "Nutrients",
            "authors": [
              {
                "authorId": "2051874355",
                "name": "V. Van Wymelbeke-Delannoy"
              },
              {
                "authorId": "2149520278",
                "name": "Charles Juhel"
              },
              {
                "authorId": "2149520274",
                "name": "Hugo Bole"
              },
              {
                "authorId": "2149520327",
                "name": "Amadou-Khalilou Sow"
              },
              {
                "authorId": "2149523433",
                "name": "Charline Guyot"
              },
              {
                "authorId": "2149520370",
                "name": "Farah Belbaghdadi"
              },
              {
                "authorId": "2668955",
                "name": "O. Brousse"
              },
              {
                "authorId": "1902716",
                "name": "M. Paindavoine"
              }
            ]
          }
        },
        {
          "citedcorpusid": 247618781,
          "isinfluential": true,
          "contexts": [
            "We will first describe the U-Net and Mask-RCNN networks and introduce the work of [16], which allows us to give the rationale for our choice to select the study of [17] as the source of our performance comparisons.",
            "Finally, to perform the evaluation, in order to use the same algorithm as [17], after the LMP operation, a closing iterative operation with a progressive increase in the kernel size (of 1 pixel) is applied until all the pixels belonging to the mask touch each other.",
            "Boillet et al. [17] also proposed to compute object-level metrics because they showed that the pixel-level metrics are not sufficient to evaluate text line segmentation networks.",
            "Three state-of-the-art networks based on the U-Net architecture [13], namely, dhSeg-ment [20], ARU-Net [21] and Doc-UFCN [22], are compared in [17], showing the efficiency of U-Net-based architectures, their current dominance for text line segmentation, and their limitations.",
            "First, we compared the line segmentation performance of Mask-RCNN with that reported by [17] in their Tables 4 and 5 for three U-Net networks on different historical databases, and also by [33] for the Dilated-FCN network.",
            "These limitations justify our choice to use databases and U-Net networks similar to those of Boillet et al. [17] to evaluate our Mask-RCNN network.",
            "It should be noted that this step was necessary because we decided to use the scripts of [17] in order to apply the same measures as those authors.",
            "Boillet et al. [17] performed an in-depth comparative study of the use of U-Net on a large number of databases.",
            "To evaluate the performance of Mask-RCNN against the U-Net networks, the selected metrics were at both the pixel and object level, as convincingly introduced in [17].",
            "On the basis of the Boillet et al.’s results [17], we selected three state-of-the-art U-Net architecture networks: dhSegment [20], ARU-Net [21], and Doc-UFCN [22], to compare the performance of Mask-RCNN."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['background']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['background']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Robust text line detection in historical documents: learning and evaluation methods",
            "abstract": "Text line segmentation is one of the key steps in historical document understanding. It is challenging due to the variety of fonts, contents, writing styles and the quality of documents that have degraded through the years. In this paper, we address the limitations that currently prevent people from building line segmentation models with a high generalization capacity. We present a study conducted using three state-of-the-art systems Doc-UFCN, dhSegment and ARU-Net and show that it is possible to build generic models trained on a wide variety of historical document datasets that can correctly segment diverse unseen pages. This paper also highlights the importance of the annotations used during training: Each existing dataset is annotated differently. We present a unification of the annotations and show its positive impact on the final text recognition results. In this end, we present a complete evaluation strategy using standard pixel-level metrics, object-level ones and introducing goal-oriented metrics.",
            "year": 2022,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1380222130",
                "name": "Mélodie Boillet"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 248640027,
          "isinfluential": false,
          "contexts": [
            "The superiority of Mask-RCNN for object separation was recently confirmed in two other applications [26,27]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "FC046: Automated Mest-C Classification in IGA Nephropathy using Deep-Learning based Segmentation",
            "abstract": "\n \n \n IgA nephropathy prognosis depends on histological factors. The MEST-C score is used to grade those factors and assess the renal prognosis of this disease. Nevertheless, this manual evaluation is time-consuming, tedious and has a poor reproducibility. An automated analysis would be faster and more objective. This work aimed to use deep-learning techniques on whole kidney biopsies from patients suffering from IgA nephropathy to obtain an automated MEST-C score.\n \n \n \n We used a previously developed convolutional neural network (CNN) to isolate the cortical area. Then, two additional CNNs were independently trained. The first one was used to evaluate the Interstitial Fibrosis/Tubular Atrophy (IF/TA) and segment the glomeruli. The second one was used to segment the relevant glomerular lesions (mesangial hypercellularity, endocapillary hypercellularity, segmental glomerulosclerosis and crescents). A total of 95 kidney biopsies from patients suffering from IgA nephropathy were randomly sorted into either the training set or the validation set. From those samples, regions of interest (ROI) were selected and annotated to develop the two CNNs (358 ROI and 458 ROI, respectively). The main annotation categories for the first CNN were `non-sclerotic glomeruli’, `sclerotic glomeruli’, `normal tubules’, `atrophic tubules’, `veins’ and `arteries’. For the second CNN, the main categories were `mesangial hypercellularity’, `endocapillary hypercellularity’, `segmental glomerulosclerosis’ and `crescents. Then, the three CNNs were sequentially applied to the biopsies of 109 patients suffering from IgA nephropathy. From the data provided by the CNNs, an automated MEST-C was calculated. We assessed its performances to predict the criteria of the gold standard MEST-C (scored by nephropathologists) using Receiver Operator Characteristic (ROC).\n \n \n \n The CNNs detected the renal structures of interest with good precision and recall up to 0.98 and 0.96 respectively for the non-sclerotic glomeruli. Normal and atrophic were also reliably recognized with 0.88 and 0.71 f-scores. Glomerular lesions were harder to recognize with a 0.67 f-score for mesangial hypercellularity, 0.76 f-score for endocapillary hypercellularity, 0.47 f-score for segmental glomerulosclerosis and 0.50 f-score for the crescents. Manual and automated evaluation of IF/TA were well correlated with a 0.76 Spearman coefficient (P < 0.001). In the application cohort, the criteria of the automated adapted MEST-C were compared with the criteria of the visual MEST-C using Receiver Operator Characteristic (ROC), we assessed the performances of the criteria of the automated MEST-C to predict the criteria of the manual MEST-C. Areas under the curve (AUC) were 0.82 for mesangial hypercellularity, 0.79 for endothelial hypercellularity and 0.82 for segmental glomerulosclerosis. Regarding IF/TA (the T criteria), the AUC were 0.86 for T1 and 0.84 for T2. Regarding the evaluation of crescents, the AUC were 0.76 for the C1 criteria and 0.88 for the C2 criteria. Those ROC were used to determine adapted thresholds for each criterion.\n \n \n \n This deep-learning based tool can be used to segment relevant renal cortical structures and provide a reliable assessment of IF/TA. An automated MEST-C score can be provided by our tool. Nevertheless, improvements are needed to consider using this tool in clinical practice and obtain an objective evaluation on large and numerous samples. FIGURE 1:Kidney samples stained with Masson's trichrome before and after the two first consecutive convolutional neural networks predictions (B, C). B: Cortical area (red), capsule (deep blue), C: normal and atrophic tubules (red and orange), non-sclerotic glomeruli (yellow), sclerotic glomeruli (light blue), arteries (purple), vein (deep blue).FIGURE 2:Kidney samples stained with Masson's trichrome before (A) and after the last convolutional neural networks predictions (B). B: hilum (yellow), mesangial hypercellularity (red), endothelial hypercellularity (purple), segmental glomerulosclerosis (green).\n",
            "year": 2022,
            "venue": "Nephrology, Dialysis and Transplantation",
            "authors": [
              {
                "authorId": "2094055531",
                "name": "Elise Maréchal"
              },
              {
                "authorId": "14824995",
                "name": "A. Jaugey"
              },
              {
                "authorId": "1380030701",
                "name": "G. Tarris"
              },
              {
                "authorId": "20906857",
                "name": "Laurent Martin"
              },
              {
                "authorId": "1902716",
                "name": "M. Paindavoine"
              },
              {
                "authorId": "2164647463",
                "name": "Jean Michel Rebibou"
              },
              {
                "authorId": "2006073951",
                "name": "Legendre Mathieu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 251018572,
          "isinfluential": false,
          "contexts": [
            "For example, [12] used the YoloV5 algorithm to demonstrate its ability to distinguish and identify the main body of a text, the text in the margins, and the common headings."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "You Actually Look Twice At it (YALTAi): using an object detection approach instead of region segmentation within the Kraken engine",
            "abstract": "Layout Analysis (the identification of zones and their classification) is the first step along line segmentation in Optical Character Recognition and similar tasks. The ability of identifying main body of text from marginal text or running titles makes the difference between extracting the work full text of a digitized book and noisy outputs. We show that most segmenters focus on pixel classification and that polygonization of this output has not been used as a target for the latest competition on historical document (ICDAR 2017 and onwards), despite being the focus in the early 2010s. We propose to shift, for efficiency, the task from a pixel classification-based polygonization to an object detection using isothetic rectangles. We compare the output of Kraken and YOLOv5 in terms of segmentation and show that the later severely outperforms the first on small datasets (1110 samples and below). We release two datasets for training and evaluation on historical documents as well as a new package, YALTAi, which injects YOLOv5 in the segmentation pipeline of Kraken 4.1.",
            "year": 2022,
            "venue": "Journal of Data Mining and Digital Humanities",
            "authors": [
              {
                "authorId": "2067044926",
                "name": "Thibault Cl'erice"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "U-Net and Mask-RCNN networks are then compared in the context of text line segmentation for text transcription using different public databases (cBaD 2017 READ-Complex [4], DIVA-HisDB[18], HOME-Alcar[19]) and a private database (the Deliberation Registers of the States of Burgundy, hereafter DRoSB)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "13273599": {
      "citing_paper_info": {
        "title": "A robust hybrid approach for text line segmentation in historical documents",
        "abstract": "",
        "year": 2012,
        "venue": "International Conference on Pattern Recognition",
        "authors": [
          {
            "authorId": "2764871",
            "name": "C. Clausner"
          },
          {
            "authorId": "1803149",
            "name": "A. Antonacopoulos"
          },
          {
            "authorId": "1980669",
            "name": "Stefan Pletschacher"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 4,
        "unique_cited_count": 3,
        "influential_count": 0,
        "detailed_records_count": 4
      },
      "cited_papers": [
        "17175452",
        "528469",
        "9811883"
      ],
      "citation_details": [
        {
          "citedcorpusid": 528469,
          "isinfluential": false,
          "contexts": [
            "Resulting text lines are compared against (manually created, [8]) ground truth text lines, identifying five conditions: Merge, split, miss / partial miss and false detection."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Aletheia - An Advanced Document Layout and Text Ground-Truthing System for Production Environments",
            "abstract": "Large-scale digitisation has led to a number of new possibilities with regard to adaptive and learning based methods in the field of Document Image Analysis and OCR. For ground truth production of large corpora, however, there is still a gap in terms of productivity. Ground truth is not only crucial for training and evaluation at the development stage of tools but also for quality assurance in the scope of production workflows for digital libraries. This paper describes Aletheia, an advanced system for accurate and yet cost-effective ground truthing of large amounts of documents. It aids the user with a number of automated and semi-automated tools which were partly developed and improved based on feedback from major libraries across Europe and from their digitisation service providers which are using the tool in a production environment. Novel features are, among others, the support of top-down ground truthing with sophisticated split and shrink tools as well as bottom-up ground truthing supporting the aggregation of lower-level elements to more complex structures. Special features have been developed to support working with the complexities of historical documents. The integrated rules and guidelines validator, in combination with powerful correction tools, enable efficient production of highly accurate ground truth.",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2764871",
                "name": "C. Clausner"
              },
              {
                "authorId": "1980669",
                "name": "Stefan Pletschacher"
              },
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9811883,
          "isinfluential": false,
          "contexts": [
            "Both input and output are represented using the PAGE format [6]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The PAGE (Page Analysis and Ground-Truth Elements) Format Framework",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "1980669",
                "name": "Stefan Pletschacher"
              },
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17175452,
          "isinfluential": false,
          "contexts": [
            "The evaluation method that has been used for the experiments is based on line correspondence analysis [7].",
            "By using an objective performance measure [7] the optimisation step can also be automated."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Scenario Driven In-depth Performance Evaluation of Document Layout Analysis Methods",
            "abstract": "",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2764871",
                "name": "C. Clausner"
              },
              {
                "authorId": "1980669",
                "name": "Stefan Pletschacher"
              },
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "1 This work has been supported in part through the EU 7th Framework Programme grant IMPACT (Ref: 215064)."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "269952725": {
      "citing_paper_info": {
        "title": "Text Line Segmentation on Myanmar Handwritten Documents Using Directional Gaussian Filter",
        "abstract": "Text line segmentation is a crucial step in document processing. Although text line segmentation techniques for handwritten documents in other languages (English, Chinese, Arabic) have developed, there is still room for improving text line segmentation in Myanmar handwritten documents. It is a challenging task to segment text lines in handwritten documents due to variations in handwriting styles, irregular spacing between lines and characters, and touching characters between lines. A method for Myanmar handwritten documents proposes to overcome these problems. The proposed system extracts bounding boxes of characters from text images by applying an anisotropic Gaussian method and connected component analysis (CCA). To extract correcting text lines by touching characters between lines, text lines are extracted by using proposed algorithm based on adaptive blob scale. To evaluate the proposed method, Myanmar handwritten documents dataset is collected from undergraduate students and high school students. According to the experimental results, the proposed technique achieves 97.5% accuracy rate with correct lines.",
        "year": 2024,
        "venue": "International Conferences on Computing Advancements",
        "authors": [
          {
            "authorId": "2302584638",
            "name": "Nilar Phyo Wai"
          },
          {
            "authorId": "19254502",
            "name": "Nu War"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 4,
        "unique_cited_count": 4,
        "influential_count": 0,
        "detailed_records_count": 4
      },
      "cited_papers": [
        "25111851",
        "46776463",
        "14196680",
        "6413416"
      ],
      "citation_details": [
        {
          "citedcorpusid": 6413416,
          "isinfluential": false,
          "contexts": [
            "Object, mark and human in videos and images can be modeled as blob” [12]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Comparative Analysis of Detection Algorithms for Corner and Blob Features in Image Processing",
            "abstract": "Feature detection is very important to image processing area. In this paper we compare and analyze some characteristics of image processing algorithms for corner and blob feature detection. We also analyze the simulation results through image matching process. We show that how these algorithms work and how fast they execute. The simulation results are shown for helping us to select an algorithm or several algorithms extracting corner and blob feature.",
            "year": 2013,
            "venue": "International Journal of Fuzzy Logic and Intelligent Systems",
            "authors": [
              {
                "authorId": "145106119",
                "name": "Xing Xiong"
              },
              {
                "authorId": "2816921",
                "name": "Byung-Jae Choi"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14196680,
          "isinfluential": false,
          "contexts": [
            "In 2009, Louloudis [8] proposed a method that utilizes the Hough transform on handwritten document images."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line and word segmentation of handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 25111851,
          "isinfluential": false,
          "contexts": [
            "The concept of scale performs a crucial role in extracting features and descriptors from image data [11]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Scale Selection",
            "abstract": "",
            "year": 2020,
            "venue": "Computer Vision, A Reference Guide",
            "authors": [
              {
                "authorId": "3205375",
                "name": "Tony Lindeberg"
              }
            ]
          }
        },
        {
          "citedcorpusid": 46776463,
          "isinfluential": false,
          "contexts": [
            "Text line structure prediction with FCN was developed by Quang Nhat et al. [6] in 2017.",
            "In recent years, there has been significant research interest in developing accurate and robust text line segmentation algorithms in other languages (English, Chinese, Japanese, and Arabic) [4, 6, 7] to improve the performance of handwritten text recognition systems."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation using a fully convolutional network in handwritten document images",
            "abstract": "Line detection in handwritten documents is an important problem for processing of scanned documents. While existing approaches mainly use hand-designed features or heuristic rules to estimate the location of text lines, the authors present a novel approach that trains a fully convolutional network (FCN) to predict text line structure in document images. A rough estimation of text line, or a line map, is obtained by using FCN, from which text strings that pass through characters in each text line are constructed. Finally, the touching characters should be separated and assigned to different text lines to complete the segmentation, for which line adjacency graph is used. Experimental results on ICDAR2013 Handwritten Segmentation Contest data set show high performance together with the robustness of the system with different types of languages and multi-skewed text lines.",
            "year": 2017,
            "venue": "IET Image Processing",
            "authors": [
              {
                "authorId": "12581289",
                "name": "Q. Vo"
              },
              {
                "authorId": "2355626",
                "name": "Soohyung Kim"
              },
              {
                "authorId": "97598888",
                "name": "Hyung-Jeong Yang"
              },
              {
                "authorId": "144096223",
                "name": "Gueesang Lee"
              }
            ]
          }
        }
      ]
    },
    "255264473": {
      "citing_paper_info": {
        "title": "Baseline detection based on local connection and evaluation for Tibetan historical document text line",
        "abstract": "The baseline position is an important reference information of the text line in the document written by Uchen Script. In order to overcome the distortion of text line and obtain accurate baseline position, this paper proposes a baseline detection method based on lines connection local and global evaluation. First, the slanted document image is corrected and the number of text lines is determined by projection. Then the discrete lines are connected locally; Finally, the baseline of text lines is obtained by evaluating the combination of baselines. Experimental results show that the proposed method can effectively overcome document skew and text line distortion, and the baseline position detected is accurate.",
        "year": 2022,
        "venue": "Conference on Computer Science and Communication Technology",
        "authors": [
          {
            "authorId": "2108941572",
            "name": "Yiqun Wang"
          },
          {
            "authorId": "2254980",
            "name": "Weilan Wang"
          },
          {
            "authorId": "2113441483",
            "name": "Zhengqi Cai"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 9,
        "unique_cited_count": 8,
        "influential_count": 0,
        "detailed_records_count": 9
      },
      "cited_papers": [
        "127518132",
        "53291082",
        "229036427",
        "33393978",
        "166512795",
        "63096591",
        "213653308",
        "53214848"
      ],
      "citation_details": [
        {
          "citedcorpusid": 33393978,
          "isinfluential": false,
          "contexts": [
            "Li et al. 6 proposed a baseline detection method based on template matching, pruning algorithms and closing operation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Text-Line Segmentation Method for Historical Tibetan Documents Based on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "Chinese Conference on Computer Vision",
            "authors": [
              {
                "authorId": "2110489669",
                "name": "Yanxing Li"
              },
              {
                "authorId": "2072987",
                "name": "Long-Long Ma"
              },
              {
                "authorId": "7667827",
                "name": "Lijuan Duan"
              },
              {
                "authorId": "46177912",
                "name": "Jian Wu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 53214848,
          "isinfluential": false,
          "contexts": [
            "Wang et al. 7 use the projection method to detect the baseline position of text lines, but projection-based method is not suitable for distorted text lines or tilted document."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Research on Text Line Segmentation of Historical Tibetan Documents Based on the Connected Component Analysis",
            "abstract": "",
            "year": 2018,
            "venue": "Chinese Conference on Pattern Recognition and Computer Vision",
            "authors": [
              {
                "authorId": "2108941572",
                "name": "Yiqun Wang"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              },
              {
                "authorId": "49970018",
                "name": "Zhenjiang Li"
              },
              {
                "authorId": "51481292",
                "name": "Yuehui Han"
              },
              {
                "authorId": "2115451526",
                "name": "Xiaojuan Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 53291082,
          "isinfluential": false,
          "contexts": [
            "The other method takes advantage of the feature that characters belonging to the same text line are close to each other, and characters are extracted along the direction of the text line to achieve the purpose of text line extraction 3,4 ."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Novel Text Line Segmentation Method Based on Contour Curve Tracking for Tibetan Historical Documents",
            "abstract": "In this paper, we proposed a novel method for text line segmentation of Tibetan historical document image with uchen script based on contour tracking. Our method is mainly to segment the text lines from the image documents using the contour curve of the text lines, which consists of three parts: First, we calculate the barycentre coordinates of the connected components for the text regions, and then the barycentre of each text line is connected in order, so that the main part of each text line is connected and a new connected component is formed; then the contour curve of the connected component is obtained using the contour tracing algorithm; Second, the contour curve and the barycentre gravity are used to assign key elements (such as the syllable point, the upper vowel, the lower vowel, and the broken strokes and so on) of the text lines, and next the candidate text lines are obtained based on these connected components; Finally, the contour tracking algorithm is used to calculate the contour curve of the candidate text lines and segment the text lines. We evaluated our text line segmentation method on the 200 document image data sets. Experimental results show that the proposed method based on contour curve tracing can accurately segment the text lines of image documents and achieve the encouraging results.",
            "year": 2018,
            "venue": "International journal of pattern recognition and artificial intelligence",
            "authors": [
              {
                "authorId": "2114903352",
                "name": "Fengming Zhou"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              },
              {
                "authorId": "40526686",
                "name": "Qiang Lin"
              }
            ]
          }
        },
        {
          "citedcorpusid": 63096591,
          "isinfluential": false,
          "contexts": [
            "According to these characteristics, text line extraction algorithms can be divided into two categories 1 ."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation of curved document images - A survey",
            "abstract": "",
            "year": 2014,
            "venue": "",
            "authors": [
              {
                "authorId": "30429790",
                "name": "Dhanya M. Dhanalakshmy"
              }
            ]
          }
        },
        {
          "citedcorpusid": 127518132,
          "isinfluential": false,
          "contexts": [
            "Li et al. 10,11 proposed a baseline detection method based on local connection."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A novel method of text line segmentation for historical document image of the uchen Tibetan",
            "abstract": "",
            "year": 2019,
            "venue": "Journal of Visual Communication and Image Representation",
            "authors": [
              {
                "authorId": "49970018",
                "name": "Zhenjiang Li"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              },
              {
                "authorId": "145906066",
                "name": "Yang Chen"
              },
              {
                "authorId": "1574182682",
                "name": "Yusheng Hao"
              }
            ]
          }
        },
        {
          "citedcorpusid": 166512795,
          "isinfluential": false,
          "contexts": [
            "Li et al. 10,11 proposed a baseline detection method based on local connection."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Tibetan historical document recognition of uchen script using baseline information",
            "abstract": "A method is proposed for recognition of uchen script Tibetan historical document using baseline information. The baseline is a significant feature of uchen script Tibetan characters, and the result of Tibetan document recognition can be improved effectively by using baseline information. Firstly, the baseline is detected accurately by the upper edge of character strokes in the document. Secondly, the baseline is used for segmentation of text line and character, and the text line adhesion can be handled also. Finally, the character part above baseline and that below baseline are recognized individually, and the final results are synthesized. The experiment shows that the proposed method is effective for the recognition of Tibetan historical document, and the recognition accuracy is better than that of the whole character recognition.",
            "year": 2019,
            "venue": "International Conference on Graphic and Image Processing",
            "authors": [
              {
                "authorId": "49970018",
                "name": "Zhenjiang Li"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 213653308,
          "isinfluential": false,
          "contexts": [
            "The first category uses the feature of obvious space between adjacent text lines to extract text lines 2 ."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Segmentation and Recognition for Historical Tibetan Document Images",
            "abstract": "As a shining pearl in traditional Tibetan culture, historical Tibetan documents have received extensive attention from historians, linguists and Buddhist scholars. These documents are converted into digital form using Tibetan document segmentation and recognition methods. The document digitization is of great significance for the research, protection and inheritance of Tibetan history. This paper proposes an overall segmentation and recognition framework for historical Tibetan document images. Firstly, the historical Tibetan document image is preprocessed to correct imbalanced illumination, tilt and noises, and is further transformed into the binarized image. Secondly, we propose a layout segmentation method based on block projection to segment Tibetan document images into texts, lines and frames. Thirdly, in order to solve the problems of touching strokes between text-lines and curvilinear text-lines, we present a text-line segmentation method based on graph model for historical Tibetan text-line segmentation. Lastly, we present a touching segmentation method to segment touching Tibetan character string, and then recognize Tibetan characters. Experimental results show our proposed methods on layout segmentation, text-line segmentation and touching character string segmentation, achieve the satisfactory performance. The proposed methods can also be applied to other fonts in Tibetan font family.",
            "year": 2020,
            "venue": "IEEE Access",
            "authors": [
              {
                "authorId": "2072987",
                "name": "Long-Long Ma"
              },
              {
                "authorId": "40356720",
                "name": "Congjun Long"
              },
              {
                "authorId": "7667827",
                "name": "Lijuan Duan"
              },
              {
                "authorId": "2108171941",
                "name": "Xiqun Zhang"
              },
              {
                "authorId": "2110489669",
                "name": "Yanxing Li"
              },
              {
                "authorId": "30770249",
                "name": "Quanchao Zhao"
              }
            ]
          }
        },
        {
          "citedcorpusid": 229036427,
          "isinfluential": false,
          "contexts": [
            "In order to overcome the distortion of text lines and detect the accurate baseline of text lines, Hu et al. 8,9 proposed local projection method to detect the baseline position, which uses multiple straight lines to approach the baseline of distorted text lines to reduce detection errors."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation based on local baselines and connected component centroids for Tibetan historical documents",
            "abstract": "Text line segmentation is one of the key contents in document image analysis and recognition. Due to the complex situation of text images in Tibetan historical document, such as the coexistence of slanting and distortion of text lines, especially the adhesion between lines, text line segmentation has become a challenging task. In this paper, a new method of text segmentation for Tibetan historical document is proposed. This method first obtains the local baseline information of the text line, and then performs the detection and segmentation of the adhesion area. Finally, according to the barycentre coordinates of the connected component and the local baseline information, each connected component is assigned to the corresponding text line. The method avoids the effect of text line distortion on the segmentation of the stuck text line and greatly reduces the error rate of the adhesion text line segmentation and can effectively deal with the segmentation of slanted and distorted Tibetan sticky text lines.",
            "year": 2020,
            "venue": "Journal of Physics: Conference Series",
            "authors": [
              {
                "authorId": "2067770685",
                "name": "Pengfei Hu"
              },
              {
                "authorId": "2144355950",
                "name": "Yang Chen"
              },
              {
                "authorId": "1574182682",
                "name": "Yusheng Hao"
              },
              {
                "authorId": "2108941572",
                "name": "Yiqun Wang"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "The Tibetan script is a kind of spelling language 5 ."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "237793218": {
      "citing_paper_info": {
        "title": "BN-HTRd: A Benchmark Dataset for Document Level Offline Bangla Handwritten Text Recognition (HTR) and Line Segmentation",
        "abstract": "We introduce a new dataset for offline Handwritten Text Recognition (HTR) from images of Bangla scripts comprising words, lines, and document-level annotations. The BN-HTRd dataset is based on the BBC Bangla News corpus, meant to act as ground truth texts. These texts were subsequently used to generate the annotations that were filled out by people with their handwriting. Our dataset includes 788 images of handwritten pages produced by approximately 150 different writers. It can be adopted as a basis for various handwriting classification tasks such as end-to-end document recognition, word-spotting, word or line segmentation, and so on. We also propose a scheme to segment Bangla handwritten document images into corresponding lines in an unsupervised manner. Our line segmentation approach takes care of the variability involved in different writing styles, accurately segmenting complex handwritten text lines of curvilinear nature. Along with a bunch of pre-processing and morphological operations, both Hough line and circle transforms were employed to distinguish different linear components. In order to arrange those components into their corresponding lines, we followed an unsupervised clustering approach. The average success rate of our segmentation technique is 81.57% in terms of FM metrics (similar to F-measure) with a mean Average Precision (mAP) of 0.547.",
        "year": 2022,
        "venue": "arXiv.org",
        "authors": [
          {
            "authorId": "48852630",
            "name": "Md Ataur Rahman"
          },
          {
            "authorId": "1657267650",
            "name": "M. Paul"
          },
          {
            "authorId": "35437967",
            "name": "Nazifa Tabassum"
          },
          {
            "authorId": "2053894612",
            "name": "Riya Pal"
          },
          {
            "authorId": "2147345557",
            "name": "Bipon Das"
          },
          {
            "authorId": "2128393808",
            "name": "Raisa Tasnim"
          },
          {
            "authorId": "83582318",
            "name": "Md Osman Gony"
          },
          {
            "authorId": "116667286",
            "name": "Fatin Noor"
          },
          {
            "authorId": "2128996830",
            "name": "Sheikh Mohammad Jubaer"
          },
          {
            "authorId": "2147310328",
            "name": "Mehanaz Chowdhury"
          },
          {
            "authorId": "49731360",
            "name": "Yeasmin Ara Akter"
          },
          {
            "authorId": "35257922",
            "name": "M. K. Islam"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 4,
        "influential_count": 0,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "14260885",
        "12531971",
        "17287157",
        "16513111"
      ],
      "citation_details": [
        {
          "citedcorpusid": 12531971,
          "isinfluential": false,
          "contexts": [
            "Apart from this, the ISI [7] and CMATERdb [8] datasets are two of the oldest character based handwritten dataset for the Bangla language."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Numeral Databases of Indian Scripts and Multistage Recognition of Mixed Numerals",
            "abstract": "",
            "year": 2009,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2435807",
                "name": "U. Bhattacharya"
              },
              {
                "authorId": "1759420",
                "name": "B. Chaudhuri"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14260885,
          "isinfluential": false,
          "contexts": [
            "A local region-based text-line segmentation algorithm was proposed in [15]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Extracting local reliable text regions to segment complex handwritten textlines",
            "abstract": "",
            "year": 2013,
            "venue": "Iranian Conference on Machine Vision and Image Processing",
            "authors": [
              {
                "authorId": "2394658",
                "name": "M. Ziaratban"
              },
              {
                "authorId": "2083395325",
                "name": "F. Bagheri"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16513111,
          "isinfluential": false,
          "contexts": [
            "Diﬀerent lines were separated by Hough Line transformation, and some form of clustering scheme allowed to distinguish between each component that falls under distinct lines [14]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Word Segmentation Method for Handwritten Documents based on Structured Learning",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE Signal Processing Letters",
            "authors": [
              {
                "authorId": "2189947",
                "name": "Jewoong Ryu"
              },
              {
                "authorId": "2463454",
                "name": "H. Koo"
              },
              {
                "authorId": "1707645",
                "name": "N. Cho"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17287157,
          "isinfluential": false,
          "contexts": [
            "The author of this article [16] used these zones in order to distinguish among diﬀerent words within a line."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Fuzzy Technique for Segmentation of Handwritten Bangla Word Images",
            "abstract": "",
            "year": 2007,
            "venue": "International Conference on Computing: Theory and Applications",
            "authors": [
              {
                "authorId": "145096292",
                "name": "Subhadip Basu"
              },
              {
                "authorId": "35846271",
                "name": "R. Sarkar"
              },
              {
                "authorId": "1723341",
                "name": "N. Das"
              },
              {
                "authorId": "143995288",
                "name": "M. Kundu"
              },
              {
                "authorId": "1729425",
                "name": "M. Nasipuri"
              },
              {
                "authorId": "143701816",
                "name": "D. K. Basu"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "This dataset ( IAM ) was subsequently used to initiate one of the most popular handwriting recognition shared tasks - ICDAR [4]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "The use of convolutional neural networks with a combination of LSTM and other deep learning frameworks to detect and recognise the lines or words in an image became popular after 2017 [18, 19, 20, 21]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "After that, researcher slowly started building sentence-level [2] as well as document-level [3] of-ﬂine handwritten datasets for English."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "245217066": {
      "citing_paper_info": {
        "title": "ENHANCED TEXT LINE SEGMENTATION AND SKEW ESTIMATION FOR HANDWRITTEN KANNADA DOCUMENT",
        "abstract": "Abstract. When Handwritten Kannada document undergoes text line segmentation, the process is referred to as Text line segmentation and skew correction. This is quite essential for the HCRS (Human Character Recognition System). The process of text line segmentation and skew estimation tends to be quiet challenging during document analysis. The proposed system presents improvised text-line segmentation along with skew estimation for which the handwritten Kannada document forms the dataset. Following are the three methods for carrying out preprocessing, namely: (i) filtering (ii) gray scale conversion and (ii) Binarization. The ESLD (Enhanced Supervised Learning Distance) algorithm is being adopted for the assessment of distance amidst text lines and G_Clustering aids in grouping of words or the Connected Components. Also, by computing skew angle with respect to the gap, Skew estimation can be performed. It’s elucidated from the output that the proposed system exhibits higher performance.",
        "year": 2021,
        "venue": "",
        "authors": [
          {
            "authorId": "2122286162",
            "name": "Dr. C S Pillai"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 11,
        "unique_cited_count": 11,
        "influential_count": 0,
        "detailed_records_count": 11
      },
      "cited_papers": [
        "14164216",
        "12534822",
        "14196680",
        "17135581",
        "14975706",
        "4651364",
        "12531971",
        "16167028",
        "23794350",
        "1308491",
        "14542261"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1308491,
          "isinfluential": false,
          "contexts": [
            "Expectation-maximization algorithm has been proposed by [15] to understand mixtures of Gaussians [15]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line extraction from multi-skewed handwritten documents",
            "abstract": "",
            "year": 2008,
            "venue": "Cybersecurity and Cyberforensics Conference",
            "authors": [
              {
                "authorId": "2064966924",
                "name": "Jiang Yong"
              },
              {
                "authorId": "2285625299",
                "name": "Xiaojing Chen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4651364,
          "isinfluential": false,
          "contexts": [
            "Combination of different on-line and off-line MCS (Multiple Classifier System) based systems has been proposed by [20] for handwritten text line recognition."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Chinese text line segmentation by clustering with distance metric learning",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "145820427",
                "name": "Fei Yin"
              },
              {
                "authorId": "1689269",
                "name": "Cheng-Lin Liu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12531971,
          "isinfluential": false,
          "contexts": [
            "[10] Employs the Otsu’s technique for obtaining the binary images of the scanned documents."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Numeral Databases of Indian Scripts and Multistage Recognition of Mixed Numerals",
            "abstract": "",
            "year": 2009,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2435807",
                "name": "U. Bhattacharya"
              },
              {
                "authorId": "1759420",
                "name": "B. Chaudhuri"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12534822,
          "isinfluential": false,
          "contexts": [
            "[1][2] Have suggested a variety of approaches pertaining to text-line segmentation which are classified as following: (i) projection profile techniques, (ii) Hough transform techniques, and (iii) smearing techniques."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A scale space approach for automatically segmenting words from historical handwritten documents",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              },
              {
                "authorId": "1845217",
                "name": "Jamie L. Rothfeder"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14164216,
          "isinfluential": false,
          "contexts": [
            "…works by extracting a group of related features in an ordered manner apt to Markovian modelling thus minimizing the redundancy factor in the word image Pr-processing stage is then followed by feature extraction according to [12] while preserving the discriminative information for recognition."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Offline Arabic handwriting recognition system based on HMM",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Computer Science and Information Technologies",
            "authors": [
              {
                "authorId": "2057622315",
                "name": "Dong Xiang"
              },
              {
                "authorId": "29241220",
                "name": "H. Yan"
              },
              {
                "authorId": "2203899",
                "name": "Xianqiao Chen"
              },
              {
                "authorId": "47585371",
                "name": "Yanfen Cheng"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14196680,
          "isinfluential": false,
          "contexts": [
            "There exists certain praiseworthy work presented by [21][22]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line and word segmentation of handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14542261,
          "isinfluential": false,
          "contexts": [
            "The CENPARMI dataset comprises of 17000 isolated digits fetched from images of nearly 3400 postal ZIP Codes through manual segmentation as indicated by [7]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Gradient-based learning applied to document recognition",
            "abstract": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.",
            "year": 1998,
            "venue": "Proceedings of the IEEE",
            "authors": [
              {
                "authorId": "1688882",
                "name": "Yann LeCun"
              },
              {
                "authorId": "52184096",
                "name": "L. Bottou"
              },
              {
                "authorId": "1751762",
                "name": "Yoshua Bengio"
              },
              {
                "authorId": "1721248",
                "name": "P. Haffner"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14975706,
          "isinfluential": false,
          "contexts": [
            "By the means of Connected Components Labeling algorithm, the unwetted bands can be segregated according to [16], for acquiring the text lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten character segmentation for Kannada scripts",
            "abstract": "",
            "year": 2012,
            "venue": "World Congress on Information and Communication Technologies",
            "authors": [
              {
                "authorId": "144991125",
                "name": "C. Naveena"
              },
              {
                "authorId": "1710382",
                "name": "Manjunath Aradhya"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16167028,
          "isinfluential": false,
          "contexts": [
            "[23] Have introduced text line detection of handwritten documents that relies upon block-based Hough transforms."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line detection in handwritten documents",
            "abstract": "Article history: Received 13 April 2007 Received in revised form 26 March 2008",
            "year": 2008,
            "venue": "",
            "authors": [
              {
                "authorId": "2084353304",
                "name": "G. Louloudisa"
              },
              {
                "authorId": "2080207726",
                "name": "B. Gatosb"
              },
              {
                "authorId": "2085864307",
                "name": "I. Pratikakisb"
              },
              {
                "authorId": "2080987605",
                "name": "C. Halatsisa"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17135581,
          "isinfluential": false,
          "contexts": [
            "Numerous research works are into practice that caters to handwritten documents and various basic datasets are being built that aid the researchers for the result sharing and comparing the classifier’s performance, as put forth by [6]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation in Images of Handwritten Historical Documents",
            "abstract": "",
            "year": 2008,
            "venue": "2008 First Workshops on Image Processing Theory, Tools and Applications",
            "authors": [
              {
                "authorId": "144837322",
                "name": "A. Sanchez"
              },
              {
                "authorId": "144889138",
                "name": "P. D. Suárez"
              },
              {
                "authorId": "1846903",
                "name": "C. Mello"
              },
              {
                "authorId": "2216183040",
                "name": "A.L.I. Oliveira"
              },
              {
                "authorId": "143755164",
                "name": "V. Alves"
              }
            ]
          }
        },
        {
          "citedcorpusid": 23794350,
          "isinfluential": false,
          "contexts": [
            "There exists certain praiseworthy work presented by [21][22]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Combining diverse on-line and off-line systems for handwritten text line recognition",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": []
          }
        }
      ]
    },
    "261321739": {
      "citing_paper_info": {
        "title": "Handwriting-Based Text Line Segmentation from Malayalam Documents",
        "abstract": "Optical character recognition systems for Malayalam handwritten documents have become an open research area. A major hindrance in this research is the unavailability of a benchmark database. Therefore, a new database of 402 Malayalam handwritten document images and ground truth images of 7535 text lines is developed for the implementation of the proposed technique. This paper proposes a technique for the extraction of text lines from handwritten documents in the Malayalam language, specifically based on the handwriting of the writer. Text lines are extracted based on horizontal and vertical projection values, the size of the handwritten characters, the height of the text lines and the curved nature of the Malayalam alphabet. The proposed technique is able to overcome incorrect segmentation due to the presence of characters written with spaces above or below other characters and the overlapping of lines because of ascenders and descenders. The performance of the proposed method for text line extraction is quantitatively evaluated using the MatchScore value metric and is found to be 85.507%. The recognition accuracy, detection rate and F-measure of the proposed method are found to be 99.39%, 85.5% and 91.92%, respectively. It is experimentally verified that the proposed method outperforms some of the existing language-independent text line extraction algorithms.",
        "year": 2023,
        "venue": "Applied Sciences",
        "authors": [
          {
            "authorId": "2230521174",
            "name": "Pearlsy P V"
          },
          {
            "authorId": "40446857",
            "name": "D. Sankar"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 12,
        "unique_cited_count": 12,
        "influential_count": 0,
        "detailed_records_count": 12
      },
      "cited_papers": [
        "14047609",
        "60877474",
        "221663960",
        "3409693",
        "18646784",
        "13750607",
        "19299969",
        "14927324",
        "228102342",
        "16503365",
        "54534452",
        "202777453"
      ],
      "citation_details": [
        {
          "citedcorpusid": 3409693,
          "isinfluential": false,
          "contexts": [
            "English and Chinese is available in handheld devices and personal OCR for languages like English and Chinese is available in handheld devices and personal computers [3,4]. computers [3,4]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Offline Chinese handwriting recognition: an assessment of current technology",
            "abstract": "",
            "year": 2007,
            "venue": "Frontiers of Computer Science in China",
            "authors": [
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              },
              {
                "authorId": "1985392",
                "name": "Xuanshen Yang"
              },
              {
                "authorId": "34366451",
                "name": "G. R. Ball"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13750607,
          "isinfluential": false,
          "contexts": [
            "Text line extraction from handwritten documents in Indian languages such as Oriya, Bangla and Kannada has been performed by applying a projection proﬁle on the document image [14–16]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting segmentation of unconstrained Oriya text",
            "abstract": "",
            "year": 2004,
            "venue": "Ninth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "6504614",
                "name": "N. Tripathy"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14047609,
          "isinfluential": false,
          "contexts": [
            "In [22], the count of the zero-crossings of the wavelet coefﬁcient is used as a feature to classify characters."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Recognition of Unconstrained Handwritten Malayalam Characters Using Zero-crossing of Wavelet Coefficients",
            "abstract": "",
            "year": 2006,
            "venue": "2006 International Conference on Advanced Computing and Communications",
            "authors": [
              {
                "authorId": "1734294",
                "name": "G. Raju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14927324,
          "isinfluential": false,
          "contexts": [
            "A chain code histogram from the chain code representation of the boundary of a skeletonized character image is used as a feature vector for character recognition in [19]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Offline handwritten Malayalam Character Recognition based on chain code histogram",
            "abstract": "",
            "year": 2011,
            "venue": "International Conference on Emerging Trends in Electrical and Computer Technology",
            "authors": [
              {
                "authorId": "9413240",
                "name": "J. John"
              },
              {
                "authorId": "145031280",
                "name": "K. Pramod"
              },
              {
                "authorId": "35507167",
                "name": "K. Balakrishnan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16503365,
          "isinfluential": false,
          "contexts": [
            "The proposed method is compared with language-independent text line extraction algorithms like A* Path Planning [33] and the piecewise painting algorithm [34]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A new scheme for unconstrained handwritten text-line segmentation",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18646784,
          "isinfluential": false,
          "contexts": [
            "In [18], handwritten Malayalam character recognition is performed by determining the position and number of horizontal and vertical lines in the skeletonized character set."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Recognition of handwritten Malayalam characters using vertical & horizontal line positional analyzer algorithm",
            "abstract": "",
            "year": 2011,
            "venue": "International Conference on Electronic Computer Technology",
            "authors": [
              {
                "authorId": "2285654470",
                "name": "Abdul Rahiman"
              },
              {
                "authorId": "1751766",
                "name": "M. Rajasree"
              },
              {
                "authorId": "2285433767",
                "name": "Asst"
              },
              {
                "authorId": "2285428922",
                "name": "Masha N"
              },
              {
                "authorId": "2285579015",
                "name": "Rema M"
              },
              {
                "authorId": "2285559376",
                "name": "Meenakshi R"
              },
              {
                "authorId": "2286618514",
                "name": "Manoj Kumar"
              }
            ]
          }
        },
        {
          "citedcorpusid": 19299969,
          "isinfluential": false,
          "contexts": [
            "[8 presents text line Text lines are extracted by applying a Hough transform to these blocks. extraction from handwritten documents using natural learning techniques based Ref."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Advances in Handwriting Recognition",
            "abstract": "On-line handwriting recognition by discrete HMM with fast learning diacritical processing using efficient accounting procedures in a forward search a handwritten form reader architecture combining different classifiers and levels of knowledge - a first step towards an adaptive recognition system architecture for handwritten text recognition systems search algorithms for the recognition of cursive phrases without world segmentation a method for the determination of features used in human reading of cursive handwriting global methods for stroke segmentation an advanced segmentation technique for cursive word recognition document understanding based on maximum a posteriori probability estimation combining shape matrices and HMMs for hand-drawn pictogram recognition.",
            "year": 1999,
            "venue": "Series in Machine Perception and Artificial Intelligence",
            "authors": [
              {
                "authorId": "50112753",
                "name": "Seong-Whan Lee"
              }
            ]
          }
        },
        {
          "citedcorpusid": 54534452,
          "isinfluential": false,
          "contexts": [
            "Jomy John et al. [17] proposed a method to recognize the individual characters in Malayalam using the gradient and curvature features of hand-written characters."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A System for Offline Recognition of Handwritten Characters in Malayalam Script",
            "abstract": "In this paper, we propose a handwritten character recognition system for Malayalam language. The feature extraction phase consists of gradient and curvature calculation and dimensionality reduction using Principal Component Analysis. Directional information from the arc tangent of gradient is used as gradient feature. Strength of gradient in curvature direction is used as the curvature feature. The proposed system uses a combination of gradient and curvature feature in reduced dimension as the feature vector. For classification, discriminative power of Support Vector Machine (SVM) is evaluated. The results reveal that SVM with Radial Basis Function (RBF) kernel yield the best performance with 96.28% and 97.96% of accuracy in two different datasets. This is the highest accuracy ever reported on these datasets.",
            "year": 2013,
            "venue": "",
            "authors": [
              {
                "authorId": "9413240",
                "name": "J. John"
              },
              {
                "authorId": "35507167",
                "name": "K. Balakrishnan"
              },
              {
                "authorId": "2286070100",
                "name": "K. V. Pramod"
              }
            ]
          }
        },
        {
          "citedcorpusid": 60877474,
          "isinfluential": false,
          "contexts": [
            "Moreover, it is assumed that Text lines are extracted in each vertical stripe separately using the horizontal projection (HP) method described in [28].",
            "C Shanjana et al. [28] proposed a technique for the recognition of characters from unconstrained Malayalam handwritten documents."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Offline Recognition of Malayalam Handwritten Text",
            "abstract": "",
            "year": 2015,
            "venue": "",
            "authors": [
              {
                "authorId": "30671900",
                "name": "C. Shanjana"
              },
              {
                "authorId": "20554024",
                "name": "A. James"
              }
            ]
          }
        },
        {
          "citedcorpusid": 202777453,
          "isinfluential": false,
          "contexts": [
            "Deep learning architectures like convolutional neural networks (CNN) and generative adversarial networks (GAN), trained using annotated images, are used to extract the text lines in [10,11]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text-line extraction from handwritten document images using GAN",
            "abstract": "",
            "year": 2020,
            "venue": "Expert systems with applications",
            "authors": [
              {
                "authorId": "51121093",
                "name": "Soumyadeep Kundu"
              },
              {
                "authorId": "1609356568",
                "name": "Sayantan Paul"
              },
              {
                "authorId": "1442063196",
                "name": "S. Bera"
              },
              {
                "authorId": "145731499",
                "name": "A. Abraham"
              },
              {
                "authorId": "35846271",
                "name": "R. Sarkar"
              }
            ]
          }
        },
        {
          "citedcorpusid": 221663960,
          "isinfluential": false,
          "contexts": [
            "B K Barakat et al. [12] proposed an unsupervised deep learning technique for the extraction of text lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Unsupervised deep learning for text line segmentation",
            "abstract": "We present an unsupervised deep learning method for text line segmentation that is inspired by the relative variance between text lines and spaces among text lines. Handwritten text line segmentation is important for the efficiency of further processing. A common method is to train a deep learning network for embedding the document image into an image of blob lines that are tracing the text lines. Previous methods learned such embedding in a supervised manner, requiring the annotation of many document images. This paper presents an unsupervised embedding of document image patches without a need for annotations. The number of foreground pixels over the text lines is relatively different from the number of foreground pixels over the spaces among text lines. Generating similar and different pairs relying on this principle definitely leads to outliers. However, as the results show, the outliers do not harm the convergence and the network learns to discriminate the text lines from the spaces between text lines. Remarkably, with a challenging Arabic handwritten text line segmentation dataset, VML-AHTE, we achieved superior performance over the supervised methods. Additionally, the proposed method was evaluated on the ICDAR 2017 and ICFHR 2010 handwritten text line segmentation datasets.",
            "year": 2020,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "1414748211",
                "name": "Reem Alaasam"
              },
              {
                "authorId": "1573588308",
                "name": "Boraq Madi"
              },
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "1573588240",
                "name": "Raed Shammes"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 228102342,
          "isinfluential": false,
          "contexts": [
            "[13] presents a learning free algorithm for text line segmentation."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Learning-Free Text Line Segmentation for Historical Handwritten Documents",
            "abstract": "We present a learning-free method for text line segmentation of historical handwritten document images. This method relies on automatic scale selection together with second derivative of anisotropic Gaussian filters to detect the blob lines that strike through the text lines. Detected blob lines guide an energy minimization procedure to extract the text lines. Historical handwritten documents contain noise, heterogeneous text line heights, skews and touching characters among text lines. Automatic scale selection allows for automatic adaption to the heterogeneous nature of handwritten text lines in case the character height range is correctly estimated. In the extraction phase, the method can accurately split the touching characters among the text lines. We provide results investigating various settings and compare the model with recent learning-free and learning-based methods on the cBAD competition dataset.",
            "year": 2020,
            "venue": "Applied Sciences",
            "authors": [
              {
                "authorId": "2126299723",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "51037361",
                "name": "Rafi Cohen"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        }
      ]
    },
    "252272047": {
      "citing_paper_info": {
        "title": "Text line segmentation in indian ancient handwritten documents using faster R-CNN",
        "abstract": "",
        "year": 2022,
        "venue": "Multimedia tools and applications",
        "authors": [
          {
            "authorId": "2184861753",
            "name": "Amar Jindal"
          },
          {
            "authorId": "47937007",
            "name": "Rajib Ghosh"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 13,
        "unique_cited_count": 13,
        "influential_count": 3,
        "detailed_records_count": 13
      },
      "cited_papers": [
        "14196680",
        "21211516",
        "2375110",
        "1610874",
        "182432961",
        "16585008",
        "5252785",
        "2355296",
        "195247398",
        "49414646",
        "10328909",
        "33748389",
        "219492588"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1610874,
          "isinfluential": false,
          "contexts": [
            "[31] obtained the line map using the FCN model and the line adjacency graphs were used to classify the touching text components into textlines.",
            "By exploiting the capability of the faster R-CNN detection network, the textlines of the ancient handwritten historical documents can be detected easily because textline can also be seen as a bounding box [20] or a set of connected text pixels [31]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Dense prediction for text line segmentation in handwritten document images",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Information Photonics",
            "authors": [
              {
                "authorId": "12581289",
                "name": "Q. Vo"
              },
              {
                "authorId": "144096223",
                "name": "Gueesang Lee"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2355296,
          "isinfluential": false,
          "contexts": [
            "Bayesian optimization technique [23] has been used to find the optimal IoU value 0."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "BOA: the Bayesian optimization algorithm",
            "abstract": "In this paper, an algorithm based on the concepts of genetic algorithms that uses an estimation of a probability distribution of promising solutions in order to generate new candidate solutions is proposed. To estimate the distribution, techniques for modeling multivariate data by Bayesian networks are used. The proposed algorithm identifies, reproduces and mixes building blocks up to a specified order. It is independent of the ordering of the variables in the strings representing the solutions. Moreover, prior information about the problem can be incorporated into the algorithm. However, prior information is not essential. Preliminary experiments show that the BOA outperforms the simple genetic algorithm even on decomposable functions with tight building blocks as a problem size grows.",
            "year": 1999,
            "venue": "",
            "authors": [
              {
                "authorId": "145659242",
                "name": "M. Pelikán"
              },
              {
                "authorId": "1715339",
                "name": "D. Goldberg"
              },
              {
                "authorId": "1398050557",
                "name": "E. Cantú-Paz"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2375110,
          "isinfluential": false,
          "contexts": [
            "Apart from Resnet50, five other backbone networks, namely, Resnet32, Resnet101, Resnet152, VGG-19 [16], and XceptionNet [2] have been incorporated in the faster R-CNN architecture to make a comparative performance evaluation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Xception: Deep Learning with Depthwise Separable Convolutions",
            "abstract": "We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "1565641737",
                "name": "François Chollet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5252785,
          "isinfluential": false,
          "contexts": [
            "[3] have used the grouping methodology without performing binarization on the document image samples from the Saint-Gall dataset.",
            "So, several investigations have been reported [3, 10, 13, 15, 17, 19, 21, 22, 24, 29] to segment the textlines in ancient handwritten documents, but most of these investigations have been carried out in Latin, Chinese, Arabic, and Japanese scripts."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Binarization-Free Text Line Segmentation for Historical Documents Based on Interest Point Clustering",
            "abstract": "",
            "year": 2012,
            "venue": "2012 10th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1706090",
                "name": "Robert Sablatnig"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10328909,
          "isinfluential": true,
          "contexts": [
            "Ren et al. [26] proposed the conventional faster R-CNN for object detection.",
            "In the proposed architecture, the total loss is the sum of the classification loss [26] and regression loss [26].",
            "…are present in the document because these methods cannot find any row containing white pixels This article proposes a faster region-convolutional neural network (R-CNN) [26] model based method for TLS in ancient historical handwritten Devanagari document images for the first time in the literature."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
            "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available",
            "year": 2015,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              },
              {
                "authorId": "2032184078",
                "name": "Jian Sun"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14196680,
          "isinfluential": false,
          "contexts": [
            "So, several investigations have been reported [3, 10, 13, 15, 17, 19, 21, 22, 24, 29] to segment the textlines in ancient handwritten documents, but most of these investigations have been carried out in Latin, Chinese, Arabic, and Japanese scripts.",
            "Louloudis et al. [17] have initially calculated the connected components and average height of the character.",
            "These existing studies have mostly relied upon various conventional techniques like projection profile [21, 22], component grouping [13, 15, 24], and hough transform [17] based methods to segment the textlines in various ancient documents."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line and word segmentation of handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16585008,
          "isinfluential": false,
          "contexts": [
            "So, several investigations have been reported [3, 10, 13, 15, 17, 19, 21, 22, 24, 29] to segment the textlines in ancient handwritten documents, but most of these investigations have been carried out in Latin, Chinese, Arabic, and Japanese scripts.",
            "In another study [13], the average height and width of each character in the textline are considered to be equal.",
            "These existing studies have mostly relied upon various conventional techniques like projection profile [21, 22], component grouping [13, 15, 24], and hough transform [17] based methods to segment the textlines in various ancient documents."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Ancient document analysis based on text line extraction",
            "abstract": "",
            "year": 2008,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1706090",
                "name": "Robert Sablatnig"
              },
              {
                "authorId": "39054567",
                "name": "M. Gau"
              },
              {
                "authorId": "1919633",
                "name": "Heinz Miklas"
              }
            ]
          }
        },
        {
          "citedcorpusid": 21211516,
          "isinfluential": false,
          "contexts": [
            "Apart from Resnet50, five other backbone networks, namely, Resnet32, Resnet101, Resnet152, VGG-19 [16], and XceptionNet [2] have been incorporated in the faster R-CNN architecture to make a comparative performance evaluation.",
            "In another study [1], convolutional recurrent neural network (CRNN) based architecture with visual geometry group (VGG)-16 [16] as a backbone network was proposed to segment the textlines in ancient historical documents in Latin script."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Very deep convolutional neural network based image classification using small training sample size",
            "abstract": "",
            "year": 2015,
            "venue": "Asian Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "50152570",
                "name": "Shuying Liu"
              },
              {
                "authorId": "1774956",
                "name": "Weihong Deng"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33748389,
          "isinfluential": false,
          "contexts": [
            "Gr¨uning et al. [6] used this concept and applied the FCN based architecture to classify the pixel label."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A two-stage method for text line detection in historical documents",
            "abstract": "This work presents a two-stage text line detection method for historical documents. Each detected text line is represented by its baseline. In a first stage, a deep neural network called ARU-Net labels pixels to belong to one of the three classes: baseline, separator and other. The separator class marks beginning and end of each text line. The ARU-Net is trainable from scratch with manageably few manually annotated example images (<50\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$<\\,50$$\\end{document}). This is achieved by utilizing data augmentation strategies. The network predictions are used as input for the second stage which performs a bottom-up clustering to build baselines. The developed method is capable of handling complex layouts as well as curved and arbitrarily oriented text lines. It substantially outperforms current state-of-the-art approaches. For example, for the complex track of the cBAD: ICDAR2017 Competition on Baseline Detection the F value is increased from 0.859 to 0.922. The framework to train and run the ARU-Net is open source.",
            "year": 2018,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "1680083",
                "name": "Gundram Leifert"
              },
              {
                "authorId": "40508719",
                "name": "Tobias Strauß"
              },
              {
                "authorId": "88739357",
                "name": "Johannes Michael"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              }
            ]
          }
        },
        {
          "citedcorpusid": 49414646,
          "isinfluential": false,
          "contexts": [
            "In another study [1], convolutional recurrent neural network (CRNN) based architecture with visual geometry group (VGG)-16 [16] as a backbone network was proposed to segment the textlines in ancient historical documents in Latin script."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwriting Recognition of Historical Documents with Few Labeled Data",
            "abstract": "Historical documents present many challenges for offline handwriting recognition systems, among them, the segmentation and labeling steps. Carefully annotated text lines are needed to train an HTR system. In some scenarios, transcripts are only available at the paragraph level with no text-line information. In this work, we demonstrate how to train an HTR system with few labeled data. Specifically, we train a deep convolutional recurrent neural network (CRNN) system on only 10% of manually labeled text-line data from a dataset and propose an incremental training procedure that covers the rest of the data. Performance is further increased by augmenting the training set with specially crafted multi scale data. We also propose a model-based normalization scheme which considers the variability in the writing scale at the recognition phase. We apply this approach to the publicly available READ dataset. Our system achieved the second best result during the ICDAR2017 competition [1].",
            "year": 2018,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "3221676",
                "name": "Edgard Chammas"
              },
              {
                "authorId": "1699564",
                "name": "C. Mokbel"
              },
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              }
            ]
          }
        },
        {
          "citedcorpusid": 182432961,
          "isinfluential": true,
          "contexts": [
            "The text present in the scanned image is recognized by the system later [4, 21, 22].",
            "So, several investigations have been reported [3, 10, 13, 15, 17, 19, 21, 22, 24, 29] to segment the textlines in ancient handwritten documents, but most of these investigations have been carried out in Latin, Chinese, Arabic, and Japanese scripts.",
            "Narang et al. [21] have developed a complete ancient Devanagari handwritten text recognition system on self generated data.",
            "These existing studies have mostly relied upon various conventional techniques like projection profile [21, 22], component grouping [13, 15, 24], and hough transform [17] based methods to segment the textlines in various ancient documents."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Devanagari ancient documents recognition using statistical feature extraction techniques",
            "abstract": "",
            "year": 2019,
            "venue": "Sādhanā",
            "authors": [
              {
                "authorId": "89271782",
                "name": "S. Narang"
              },
              {
                "authorId": "35495324",
                "name": "M. Jindal"
              },
              {
                "authorId": "2109645645",
                "name": "Munish Kumar"
              }
            ]
          }
        },
        {
          "citedcorpusid": 195247398,
          "isinfluential": true,
          "contexts": [
            "The text present in the scanned image is recognized by the system later [4, 21, 22].",
            "These existing studies have mostly relied upon various conventional techniques like projection profile [21, 22], component grouping [13, 15, 24], and hough transform [17] based methods to segment the textlines in various ancient documents.",
            "So, several investigations have been reported [3, 10, 13, 15, 17, 19, 21, 22, 24, 29] to segment the textlines in ancient handwritten documents, but most of these investigations have been carried out in Latin, Chinese, Arabic, and Japanese scripts.",
            "The problem of undersegmentation and over-segmentation has been resolved by computing the average height of the textline for each piece-wise strip and then applying the projection profile method in another study [22] on ancient historical handwritten document in Devanagari script.",
            "The text skewness, varying layouts, variable interline spacing, broken characters, overlapping of textlines as well as characters create other recognition challenges like under-segmentation and over-segmentation of textlines [22]."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Line Segmentation of Devanagari Ancient Manuscripts",
            "abstract": "",
            "year": 2019,
            "venue": "Proceedings of the National Academy of Sciences India Section A Physical Sciences",
            "authors": [
              {
                "authorId": "89271782",
                "name": "S. Narang"
              },
              {
                "authorId": "35495324",
                "name": "M. Jindal"
              },
              {
                "authorId": "2109645645",
                "name": "Munish Kumar"
              }
            ]
          }
        },
        {
          "citedcorpusid": 219492588,
          "isinfluential": false,
          "contexts": [
            "In a recent study [14] towards TLS in historical documents in Latin script, a fully convolutional network (FCN) based architecture has been proposed to detect the baselines.",
            "After the segmentation task, generally the character recognition and word recognition task are performed [7, 14, 18].",
            "In the recent decades, intensive works are going on offline handwritten text recognition (HTR) in ancient historical documents [7, 14, 18]."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "HDPA: historical document processing and analysis framework",
            "abstract": "",
            "year": 2020,
            "venue": "Evolutionary Systematics",
            "authors": [
              {
                "authorId": "2628715",
                "name": "Ladislav Lenc"
              },
              {
                "authorId": "40800185",
                "name": "J. Martínek"
              },
              {
                "authorId": "3246597",
                "name": "P. Král"
              },
              {
                "authorId": "2287377991",
                "name": "Anguelos Nicolao"
              },
              {
                "authorId": "2663226",
                "name": "Vincent Christlein"
              }
            ]
          }
        }
      ]
    },
    "59292245": {
      "citing_paper_info": {
        "title": "Text line Segmentation in Compressed Representation of Handwritten Document using Tunneling Algorithm",
        "abstract": "Operating directly on the compressed document images without decompression would be an additional advantage for storage and transmission. In this research work, we perform text line segmentation directly in compressed representation of an unconstraint handwritten document image using tunneling algorithm. In this relation, we make use of text line terminal point which is the current state-of-the-art that enables text line segmentation. The terminal points spotted along both margins (left and right) of a document image for every text line are considered as source and target respectively. The effort in spotting the terminal positions is performed directly in the compressed domain. The tunneling algorithm uses a single agent to identify the coordinate positions in the compressed representation to perform text-line segmentation of the document. The agent starts at a source point and progressively tunnels a path routing in between two adjacent text lines and reaches the probable target. The agent’s navigation path from source to the target bypassing obstacles, if any, results in segregating the two adjacent text lines. However, the target point would be known only when the agent reaches destination; this is applicable for all source points and henceforth we could analyze the correspondence between source and target nodes. In compressed representation of a document image, the continuous pixel values in a spatial domain are available in the form of batches known as white-runs (background) and black-runs (foreground). These batches are considered as features of a document image represented in a Grid map. Performing text-line segmentation using these features makes the system inexpensive compared to spatial domain processing. Artificial Intelligence in Expert systems with dynamic programming and greedy strategies is employed for every search space for tunneling. An exhaustive experimentation is carried out on various benchmark datasets including ICDAR13 and the performances are reported.",
        "year": 2018,
        "venue": "arXiv.org",
        "authors": [
          {
            "authorId": "2127437020",
            "name": "Amarnath R"
          },
          {
            "authorId": "2265910773",
            "name": "N. P"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 5,
        "influential_count": 0,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "15002127",
        "62119079",
        "11418414",
        "42004427",
        "22357202"
      ],
      "citation_details": [
        {
          "citedcorpusid": 11418414,
          "isinfluential": false,
          "contexts": [
            "uments in the digital format. It is also necessary to preserve these documents in digital image format only, particularly in case of handwritten documents for verification and authentication purposes [1, 2, 3, 4, 5]. Maintaining these document images in the digital form would require huge storage space and network bandwidth. Therefore, an efficient compressed representation would be an effective solution to the "
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Word spotting for historical documents",
            "abstract": "",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "2352980",
                "name": "T. Rath"
              },
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15002127,
          "isinfluential": false,
          "contexts": [
            "The compressed image file formats such as TIFF, JPEG, and PNG, strictly follow CCITT standards [7, 8, 9, 10, 11, 12].",
            "A recent literature [12] on CDP shows the strategies to perform document image analysis in its compressed representation."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A review on document image analysis techniques directly in the compressed domain",
            "abstract": "",
            "year": 2018,
            "venue": "Artificial Intelligence Review",
            "authors": [
              {
                "authorId": "145707155",
                "name": "M. Javed"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              },
              {
                "authorId": "1759420",
                "name": "B. Chaudhuri"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22357202,
          "isinfluential": false,
          "contexts": [
            "It is also necessary to preserve these documents in digital image format only, particularly in case of handwritten documents for verification and authentication purposes [1, 2, 3, 4, 5]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Multilingual word spotting in offline handwritten documents",
            "abstract": "",
            "year": 2012,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "1732789",
                "name": "S. Wshah"
              },
              {
                "authorId": "48387892",
                "name": "Manish Kumar"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 42004427,
          "isinfluential": false,
          "contexts": [
            "The compressed image file formats such as TIFF, JPEG, and PNG, strictly follow CCITT standards [7, 8, 9, 10, 11, 12].",
            "The digital libraries with document images in their compressed formats could imply a solution to a big data problem arising from the document images, particularly about storage and transmission [11]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Compressed image file formats - JPEG, PNG, GIF, XBM, BMP",
            "abstract": "Preface. Acknowledgments. 1. Introduction. The Representation of Images. Vector and Bitmap Graphics. Color Models. True Color versus Palette. Compression. Byte and Bit Ordering. Color Quantization. A Common Image Format. Conclusion. 2. Windows BMP. Data Ordering. File Structure. Compression. Conclusion. 3. XBM. File Format. Reading and Writing XBM Files. Conclusion. 4. Introduction to JPEG. JPEG Compression Modes. What Part of JPEG Will Be Covered in This Book? What are JPEG Files? SPIFF File Format. Byte Ordering. Sampling Frequency. JPEG Operation. Interleaved and Noninterleaved Scans. Conclusion. 5. JPEG File Format. Markers. Compressed Data. Marker Types. JFIF Format. Conclusion. 6. JPEG Human Coding. Usage Frequencies. Huffman Coding Example. Huffman Coding Using Code Lengths. Huffman Coding in JPEG. Limiting Code Lengths. Decoding Huffman Codes. Conclusion. 7. The Discrete Cosine Transform. DCT in One Dimension. DCT in Two Dimensions. Basic Matrix Operations. Using the 2-D Forward DCT. Quantization. Zigzag Ordering. Conclusion. 8. Decoding Sequential-Mode JPEG Images. MCU Dimensions. Decoding Data Units. Decoding Example. Processing DCT Coefficients. Up-Sampling. Restart Marker Processing. Overview of JPEG Decoding. Conclusion. 9. Creating Sequential JPEG Files. Compression Parameters. Output File Structure. Doing the Encoding. Down-Sampling. Interleaving. Data Unit Encoding. Huffman Table Generation. Conclusion. 10. Optimizing the DCT. Factoring the DCT Matrix. Scaled Integer Arithmetic. Merging Quantization and the DCT. Conclusion. 11. Progressive JPEG. Component Division in Progressive JPEG. Processing Progressive JPEG Files. Processing Progressive Scans. MCUs in Progressive Scans. Huffman Tables in Progressive Scans. Data Unit Decoding. Preparing to Create Progressive JPEG Files. Encoding Progressive Scans. Huffman Coding. Data Unit Encoding. Conclusion. 12. GIF. Byte Ordering. File Structure. Interlacing. Compressed Data Format. Animated GIF. Legal Problems. Uncompressed GIF. Conclusion. 13. PNG. History. Byte Ordering. File Format. File Organization. Color Representation in PNG. Device-Independent Color. Gamma. Interlacing. Critical Chunks. Noncritical Chunks. Conclusion. 14. Decompressing PNG Image Data. Decompressing the Image Data. Huffman Coding in Deflate. Compressed Data Format. Compressed Data Blocks. Writing the Decompressed Data to the Image. Conclusion. 15. Creating PNG Files. Overview. Deflate Compression Process. Huffman Table Generation. Filtering. Conclusion. Glossary. Bibliography. Index. 0201604434T04062001",
            "year": 1999,
            "venue": "",
            "authors": [
              {
                "authorId": "32532837",
                "name": "John Miano"
              }
            ]
          }
        },
        {
          "citedcorpusid": 62119079,
          "isinfluential": false,
          "contexts": [
            "on 5. Section 6 summarizes the research work with future avenues. 2. Related Works In the recent past, we could trace few related works on CDP, but restricted to printed document images. A literature [15] on CDP provides a detailed study on document image analysis techniques from the perspectives of image processing, image compression and compressed domain processing. This enabled various operations c",
            "e in its compressed format must undergo the decompression stage. However, performing operations on decompressed documents would unwarrantedly suppress the advantages of both the time and buffer space [6, 13, 14, 15]. If DDA could be achieved in the compressed version of the document image without decompression, then the document image compression could be viewed as an effective solution to the immense data probl"
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Pattern Matching in Compressed Texts and Images",
            "abstract": "Pattern Matching in Compressed Texts and Images surveys and appraises techniques for pattern matching in compressed text and images. Normally compressed data needs to be decompressed before it is processed. If however the compression has been done in the right way, it is often possible to search the data without having to decompress it, or, at least, only partially decompress it. The problem can be divided into lossless and lossy compression methods, and then in each of these cases the pattern matching can be either exact or inexact. Much work has been reported in the literature on techniques for all of these cases. It includes algorithms that are suitable for pattern matching for various compression methods, and compression methods designed specifically for pattern matching. This monograph provides a survey of this work while also identifying the important relationship between pattern matching and compression, and proposing some performance measures for compressed pattern matching algorithms. Pattern Matching in Compressed Texts and Images is an excellent reference text for anyone who has an interest in the problem of searching compressed text and images. It concludes with a particularly insightful section on the ideas and research directions that are likely to occupy researchers in this field in the short and long term.",
            "year": 2013,
            "venue": "Foundations and Trends® in Signal Processing",
            "authors": [
              {
                "authorId": "145358382",
                "name": "D. Adjeroh"
              },
              {
                "authorId": "49014513",
                "name": "T. Bell"
              },
              {
                "authorId": "143887818",
                "name": "A. Mukherjee"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Usage of memoize technique [28] in dynamic programming",
            "In computing, memoization [28] or memorize [28] is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "211210239": {
      "citing_paper_info": {
        "title": "iDocChip - A Configurable Hardware Architecture for Historical Document Image Processing: Text Line Extraction",
        "abstract": "Digitizing historical archives poses a great challenge due to the quality degradation existing in these documents. Hence, even well-established Optical Character Recognition (OCR) systems, such as Abby, OCRopus, Tesseract, etc., fail to give sufficient recognition accuracy for historical archives, since they are optimized for transcribing contemporary documents. In contrast, the open-source anyOCR system is designed specifically for digitizing historical documents with state-of-the-art image processing techniques, to achieve high accuracy. Nowadays, the retrieval of historical document images for further OCR requires special scanning devices that are bulky and stationary. As a result, a portable device that combines scanning and OCR capabilities is beneficial to transcribe documents without the need to remove them from where they are archived. For example, smart goggles equipped with embedded OCR device can be used for instant word spotting. However, the available anyOCR software implementation has long runtime and high power consumption. As a solution, we propose a low power, energy-efficient accelerator with real-time capabilities called iDocChip, which is a hybrid hardware-software programmable System-on-Chip (SoC) for digitizing historical documents. This chip can be easily integrated in a portable device. This paper focuses on one of the most crucial processing steps in anyOCR: Text line extraction. We propose, to the best of our knowledge, the first hybrid hardware-software architecture of the text line extraction technique implemented on an FPGA based programmable SoC. The resulting custom hardware accelerator outperforms the existing anyOCR software implementation by 120x, while achieving 1700x higher energy efficiency without affecting the high accuracy of the system.",
        "year": 2019,
        "venue": "International Conference on Reconfigurable Computing and FPGAs",
        "authors": [
          {
            "authorId": "51163451",
            "name": "M. Tekleyohannes"
          },
          {
            "authorId": "2104261184",
            "name": "Vladimir Rybalkin"
          },
          {
            "authorId": "51123288",
            "name": "M. M. Ghaffar"
          },
          {
            "authorId": "1690688",
            "name": "N. Wehn"
          },
          {
            "authorId": "145279674",
            "name": "A. Dengel"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 11,
        "unique_cited_count": 10,
        "influential_count": 2,
        "detailed_records_count": 11
      },
      "cited_papers": [
        "15926594",
        "17997974",
        "15257932",
        "1889158",
        "14209826",
        "67866192",
        "4768150",
        "12843544",
        "52898990",
        "5934826"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1889158,
          "isinfluential": false,
          "contexts": [
            "Moysset et al. [17] proposes a method based on machine learning."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Paragraph text segmentation into lines with Recurrent Neural Networks",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "144899680",
                "name": "Christian Wolf"
              },
              {
                "authorId": "2373952",
                "name": "J. Louradour"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4768150,
          "isinfluential": true,
          "contexts": [
            "To summarize, the novel contributions of this paper are: • Optimization of the original software algorithm, anyOCR [5], is presented to enable efﬁcient hardware parallelization, without any loss of accuracy.",
            "In the original anyOCR system [5], the scanned image of the historical document is ﬁrst binarized using PBB scheme.",
            "The digitization of historical archives, therefore, brings additional challenges to an already complex OCR techniques. anyOCR [5] is especially designed to digitize historical documents with high accuracy, taking into account the quality deﬁciency existing in these archives."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "anyOCR: An Open-Source OCR System for Historical Archives",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "145461897",
                "name": "S. S. Bukhari"
              },
              {
                "authorId": "35399131",
                "name": "A. Kadi"
              },
              {
                "authorId": "35479963",
                "name": "Mohammad Ayman Jouneh"
              },
              {
                "authorId": "35539072",
                "name": "Fahim Mahmood Mir"
              },
              {
                "authorId": "145279674",
                "name": "A. Dengel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5934826,
          "isinfluential": false,
          "contexts": [
            "Diem et al. [13] proposes a bottom up approach, where the document images are ﬁrst aligned and binarized to locate text elements."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Detection for Heterogeneous Documents",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1706090",
                "name": "Robert Sablatnig"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12843544,
          "isinfluential": false,
          "contexts": [
            "Although there have been some proposals for accelerating the task on a dedicated hardware [22–24] this research area has not yet been well investigated."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "FPGA implementation of a Deep Belief Network architecture for character recognition using stochastic computation",
            "abstract": "",
            "year": 2015,
            "venue": "Annual Conference on Information Sciences and Systems",
            "authors": [
              {
                "authorId": "2066497091",
                "name": "Kayode A. Sanni"
              },
              {
                "authorId": "3185763",
                "name": "Guillaume Garreau"
              },
              {
                "authorId": "48344522",
                "name": "J. Molin"
              },
              {
                "authorId": "2730857",
                "name": "A. Andreou"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14209826,
          "isinfluential": false,
          "contexts": [
            "Saabni et al. [9] computes an energy map of a text image and determines the seams that pass across and between text lines.",
            "Saabini et al. [9] classiﬁes the methods used for this task into three classes: top-down, bottom-up and hybrid.",
            "In [9, 11, 12], authors use dynamic programming principles to calculate cost optimal paths passing the image from left to right, to separate different text lines from each other."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line extraction for historical document images",
            "abstract": "",
            "year": 2014,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "1741845",
                "name": "Raid Saabni"
              },
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15257932,
          "isinfluential": false,
          "contexts": [
            "[10] proposes a top-down approach where steerable directional filter is used to build a generalized adaptive local connectivity map (ALCM)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition A Steerable Directional Local Profile Technique for Extraction of Handwritten Arabic Text Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 15926594,
          "isinfluential": false,
          "contexts": [
            "Bukhari et al. [21] applies a ﬁlter bank to smooth the input text image."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Script-Independent Handwritten Textlines Segmentation using Active Contours",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 17997974,
          "isinfluential": false,
          "contexts": [
            "Although there have been some proposals for accelerating the task on a dedicated hardware [22–24] this research area has not yet been well investigated."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A RMB optical character recognition system using FPGA",
            "abstract": "",
            "year": 2016,
            "venue": "IEEE International Conference on Signal and Image Processing",
            "authors": [
              {
                "authorId": "83725138",
                "name": "Hui Zho"
              },
              {
                "authorId": "2090389757",
                "name": "Guojun Zhu"
              },
              {
                "authorId": "101763553",
                "name": "Yu-Hang Peng"
              }
            ]
          }
        },
        {
          "citedcorpusid": 52898990,
          "isinfluential": true,
          "contexts": [
            "Rybalkin et al. [25] proposed the ﬁrst heterogeneous hardware-software architecture of the Percentile-based Binarization (PBB) algorithm which performs binarization of the any-OCR input image.",
            "TABLE II: Resource utilization of the hardware implementation for binarization (Bin) [25], text-image segmentation (TIS) [26], text line extraction (TLE) (this work) and character recognition (CR) [27] on Zynq 7045 device @ 166MHz.",
            "With respect to iDocChip, FPGA implementations of the different pipeline stages have been presented in [25–27].",
            "Moreover, it substantially outperforms the commercially available OCR engines ABBYY and Tesseract, which have recognition accuracy of 66.47% and 56.83%, respectively, for the given dataset [25]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "iDocChip: A Configurable Hardware Architecture for Historical Document Image Processing: Percentile Based Binarization",
            "abstract": "End-to-end Optical Character Recognition (OCR) systems are heavily used to convert document images into machine-readable text. Commercial and open-source OCR systems (like Abbyy, OCRopus, Tesseract etc.) have traditionally been optimized for contemporary documents like books, letters, memos, and other end-user documents. However, these systems are difficult to use equally well for digitizing historical document images, which contain degradations like non-uniform shading, bleed-through, and irregular layout; such degradations usually do not exist in contemporary document images. The open-source anyOCR is an end-to-end OCR pipeline, which contains state-of-the-art techniques that are required for digitizing degraded historical archives with high accuracy. However, high accuracy comes at a cost of high computational complexity that results in 1) long runtime that limits digitization of big collection of historical archives and 2) high energy consumption that is the most critical limiting factor for portable devices with constrained energy budget. Therefore, we are targeting energy efficient and high throughput acceleration of the anyOCR pipeline. Generalpurpose computing platforms fail to meet these requirements that makes custom hardware design mandatory. In this paper, we are presenting a new concept named iDocChip. It is a portable hybrid hardware-software FPGA-based accelerator that is characterized by low footprint meaning small size, high power efficiency that will allow using it in portable devices, and high throughput that will make it possible to process big collection of historical archives in real time without effecting the accuracy. In this paper, we focus on binarization, which is the second most critical step in the anyOCR pipeline after text-line recognizer that we have already presented in our previous publication [21]. The anyOCR system makes use of a Percentile Based Binarization method that is suitable for overcoming degradations like non-uniform shading and bleed-through. To the best of our knowledge, we propose the first hardware architecture of the PBB technique. Based on the new architecture, we present a hybrid hardware-software FPGA-based accelerator that outperforms the existing anyOCR software implementation running on i7-4790T in terms of runtime by factor of 21, while achieving energy efficiency of 10 Images/J that is higher than that achieved by low power embedded processors with negligible loss of recognition accuracy.",
            "year": 2018,
            "venue": "ACM Symposium on Document Engineering",
            "authors": [
              {
                "authorId": "2104261184",
                "name": "Vladimir Rybalkin"
              },
              {
                "authorId": "145461897",
                "name": "S. S. Bukhari"
              },
              {
                "authorId": "51123288",
                "name": "M. M. Ghaffar"
              },
              {
                "authorId": "80456550",
                "name": "Aqib Ghafoor"
              },
              {
                "authorId": "1690688",
                "name": "N. Wehn"
              },
              {
                "authorId": "145279674",
                "name": "A. Dengel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 67866192,
          "isinfluential": false,
          "contexts": [
            "Although there have been some proposals for accelerating the task on a dedicated hardware [22–24] this research area has not yet been well investigated."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "An FPGA-based Hardware Accelerator for Scene Text Character Recognition",
            "abstract": "Scene text character recognition is a challenging task in Computer Vision since natural scene images usually have cluttered background and the character’s size, font, orientation, texture, brightness, and alignment in the picture are variable and non-predictable. Furthermore, most systems including scene text character recognition are usually embedded in a system on a chip (SoC), which has critical requirements, such as low latency, low area, mobility, and flexibility, at the same time that they require high accuracy. In this context, in this work we propose a heterogeneous system for embedded applications with time, area and power constraints, that combines hardware and software to accelerate a technique for scene text character recognition, based on Histogram of Oriented Gradients (HOG) for feature extraction and a neural network Extreme Learning Machine (ELM) as a classifier. The system was prototyped and experimented in the Terasic embedded platform DE2i-150 and the results showed that the system has accuracy of 65.5% in the Chars74k-15 dataset and is able to process up to 11 frames per second, having a good trade-off between processing time and accuracy in embedded environments. Moreover, it occupies only 11% logic elements of the Altera Cyclone IV FPGA, enabling its use in embedded systems.",
            "year": 2018,
            "venue": "IEEE/IFIP International Conference on Very Large Scale Integration of System-on-Chip",
            "authors": [
              {
                "authorId": "51513854",
                "name": "L. A. D. O. Junior"
              },
              {
                "authorId": "143716584",
                "name": "E. Barros"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Abbyy [1], Omnipage [2], OCRopus [3] and Tesseract [4]) are used to digitize contemporary documents such as books, letters, memos, etc."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "13043546": {
      "citing_paper_info": {
        "title": "Spotting Separator Points at Line Terminals in Compressed Document Images for Text-line Segmentation",
        "abstract": "Line separators are used to segregate text-lines from one another in document image analysis. Finding the separator points at every line terminal in a document image would enable text-line segmentation. In particular, identifying the separators in handwritten text could be a thrilling exercise. Obviously it would be challenging to perform this in the compressed version of a document image and that is the proposed objective in this research. Such an effort would prevent the computational burden of decompressing a document for text-line segmentation. Since document images are generally compressed using run length encoding (RLE) technique as per the CCITT standards, the first column in the RLE will be a white column. The value (depth) in the white column is very low when a particular line is a text line and the depth could be larger at the point of text line separation. A longer consecutive sequence of such larger depth should indicate the gap between the text lines, which provides the separator region. In case of over separation and under separation issues, corrective actions such as deletion and insertion are suggested respectively. An extensive experimentation is conducted on the compressed images of the benchmark datasets of ICDAR13 and Alireza et al [17] to demonstrate the efficacy.",
        "year": 2017,
        "venue": "arXiv.org",
        "authors": [
          {
            "authorId": "145405400",
            "name": "R. Amarnath"
          },
          {
            "authorId": "1750931",
            "name": "P. Nagabhushan"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 3,
        "unique_cited_count": 2,
        "influential_count": 1,
        "detailed_records_count": 3
      },
      "cited_papers": [
        "9401652",
        "55765130"
      ],
      "citation_details": [
        {
          "citedcorpusid": 9401652,
          "isinfluential": false,
          "contexts": [
            "This compression standard facilitates both efficient storage and transmission [12] and therefore it is utilized in real-time applications including fax machines, photocopy machines, digital libraries and communication networks.",
            "Document Retrieval Yue Lu et al [12] Have worked on connected component techniques of CCITT Group 4 standard images."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document retrieval from compressed images",
            "abstract": "",
            "year": 2003,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1409858950",
                "name": "Yue Lu"
              },
              {
                "authorId": "1679749",
                "name": "C. Tan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 55765130,
          "isinfluential": false,
          "contexts": [
            "COMPRESSED IMAGE REPRESENTATION AND TERMINOLOGIES The CCITT Group 3 [2] or Modified Huffman (MH) [15] image format primarily uses line by line coding technique.",
            "The CCITT Group-3 / Group-4 and JBIG protocols are developed based on the run-length encoding (RLE) [15], widely accepted for binary document compression."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ScienceDirect International Conference on Computational Modeling and Security ( CMS 2016 ) Visualizing CCITT Group 3 and Group 4 TIFF Documents and Transforming to Run-Length Compressed Format Enabling Direct Processing in Compressed Domain",
            "abstract": "",
            "year": 2016,
            "venue": "",
            "authors": [
              {
                "authorId": "145707155",
                "name": "M. Javed"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              },
              {
                "authorId": "2349324268",
                "name": "B. B. Chaudhuri"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": true,
          "contexts": [
            "These word objects are matched based on weighted Hausdorff distance\nSegmentation Mohammed Javed\net al [8, 13, 14]\nHave performed Line, Word, and Character Segments directly from run-\nlength compressed data.",
            "In summary, the motivation is the absence of the work on the compressed version of handwritten document, and the hope that can be traced particularly because of [8,13,14].",
            "Segmentation Mohammed Javed et al [8, 13, 14] Have performed Line, Word, and Character Segments directly from runlength compressed data.",
            "The compression standard is adopted as presented in [14]."
          ],
          "intents": [
            "--",
            "['background']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "232240176": {
      "citing_paper_info": {
        "title": "Combining Morphological and Histogram based Text Line Segmentation in the OCR Context",
        "abstract": "Text line segmentation is one of the pre-stages of modern optical character\nrecognition systems. The algorithmic approach proposed by this paper has been\ndesigned for this exact purpose. Its main characteristic is the combination of\ntwo different techniques, morphological image operations and horizontal\nhistogram projections. The method was developed to be applied on a historic\ndata collection that commonly features quality issues, such as degraded paper,\nblurred text, or presence of noise. For that reason, the segmenter in question\ncould be of particular interest for cultural institutions, that want access to\nrobust line bounding boxes for a given historic document. Because of the\npromising segmentation results that are joined by low computational cost, the\nalgorithm was incorporated into the OCR pipeline of the National Library of\nLuxembourg, in the context of the initiative of reprocessing their historic\nnewspaper collection. The general contribution of this paper is to outline the\napproach and to evaluate the gains in terms of accuracy and speed, comparing it\nto the segmentation algorithm bundled with the used open source OCR software.",
        "year": 2021,
        "venue": "Journal of Data Mining and Digital Humanities",
        "authors": [
          {
            "authorId": "46281657",
            "name": "Pit Schneider"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 1,
        "unique_cited_count": 1,
        "influential_count": 0,
        "detailed_records_count": 1
      },
      "cited_papers": [
        "56597514"
      ],
      "citation_details": [
        {
          "citedcorpusid": 56597514,
          "isinfluential": false,
          "contexts": [
            "Common comparison methods typically rely on the measures of recall/precision/F (Barakat et al. [2018]) or on the intersection over union (IoU) metric (Renton et al. [2017])."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation for Challenging Handwritten Document Images using Fully Convolutional Network",
            "abstract": "This paper presents a method for text line segmentation of challenging historical manuscript images. These manuscript images contain narrow interline spaces with touching components, interpenetrating vowel signs and inconsistent font types and sizes. In addition, they contain curved, multi-skewed and multi-directed side note lines within a complex page layout. Therefore, bounding polygon labeling would be very difficult and time consuming. Instead we rely on line masks that connect the components on the same text line. Then these line masks are predicted using a Fully Convolutional Network (FCN). In the literature, FCN has been successfully used for text line segmentation of regular handwritten document images. The present paper shows that FCN is useful with challenging manuscript images as well. Using a new evaluation metric that is sensitive to over segmentation as well as under segmentation, testing results on a publicly available challenging handwritten dataset are comparable with the results of a previous work on the same dataset.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "39240022",
                "name": "M. Kassis"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        }
      ]
    },
    "234790206": {
      "citing_paper_info": {
        "title": "Unsupervised learning of text line segmentation by differentiating coarse patterns",
        "abstract": "Despite recent advances in the field of supervised deep learning for text line segmentation, unsupervised deep learning solutions are beginning to gain popularity. In this paper, we present an unsupervised deep learning method that embeds document image patches to a compact Euclidean space where distances correspond to a coarse text line pattern similarity. Once this space has been produced, text line segmentation can be easily implemented using standard techniques with the embedded feature vectors. To train the model, we extract random pairs of document image patches with the assumption that neighbour patches contain a similar coarse trend of text lines, whereas if one of them is rotated, they contain different coarse trends of text lines. Doing well on this task requires the model to learn to recognize the text lines and their salient parts. The benefit of our approach is zero manual labelling effort. We evaluate the method qualitatively and quantitatively on several variants of text line segmentation datasets to demonstrate its effectivity.",
        "year": 2021,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "51036690",
            "name": "Berat Kurar Barakat"
          },
          {
            "authorId": "27005271",
            "name": "Ahmad Droby"
          },
          {
            "authorId": "1741845",
            "name": "Raid Saabni"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 10,
        "unique_cited_count": 10,
        "influential_count": 4,
        "detailed_records_count": 10
      },
      "cited_papers": [
        "1629541",
        "56597514",
        "4765236",
        "9811883",
        "54465873",
        "33748389",
        "4761833",
        "221130277",
        "528469",
        "195750543"
      ],
      "citation_details": [
        {
          "citedcorpusid": 528469,
          "isinfluential": false,
          "contexts": [
            "Their ground truth is provided in PAGE xml format [19,6]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Aletheia - An Advanced Document Layout and Text Ground-Truthing System for Production Environments",
            "abstract": "Large-scale digitisation has led to a number of new possibilities with regard to adaptive and learning based methods in the field of Document Image Analysis and OCR. For ground truth production of large corpora, however, there is still a gap in terms of productivity. Ground truth is not only crucial for training and evaluation at the development stage of tools but also for quality assurance in the scope of production workflows for digital libraries. This paper describes Aletheia, an advanced system for accurate and yet cost-effective ground truthing of large amounts of documents. It aids the user with a number of automated and semi-automated tools which were partly developed and improved based on feedback from major libraries across Europe and from their digitisation service providers which are using the tool in a production environment. Novel features are, among others, the support of top-down ground truthing with sophisticated split and shrink tools as well as bottom-up ground truthing supporting the aggregation of lower-level elements to more complex structures. Special features have been developed to support working with the complexities of historical documents. The integrated rules and guidelines validator, in combination with powerful correction tools, enable efficient production of highly accurate ground truth.",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2764871",
                "name": "C. Clausner"
              },
              {
                "authorId": "1980669",
                "name": "Stefan Pletschacher"
              },
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1629541,
          "isinfluential": true,
          "contexts": [
            "FCN+EM method [14] is fully supervised by human annotated blob lines.",
            "However, when using FCN, each text line is represented as a single connected component.",
            "We compare our results with those of supervised learning methods, Mask-RCNN [14] and FCN+EM [14], and an unsupervised deep learning method, UTLS [15].",
            "Foreground pixels definitely can not discriminate a text line from the others because FCN output is a semantic segmentation where multiple instances of the same object are not separated.",
            "Given a document image, a Fully Convolutional Network (FCN) [17] is trained to densely predict whether a pixel is a text line pixel or not.",
            "FCNs are very successful at detecting handwritten text lines [7]."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Fully convolutional networks for semantic segmentation",
            "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.",
            "year": 2014,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "1782282",
                "name": "Evan Shelhamer"
              },
              {
                "authorId": "2117314646",
                "name": "Jonathan Long"
              },
              {
                "authorId": "1753210",
                "name": "Trevor Darrell"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4761833,
          "isinfluential": true,
          "contexts": [
            "The recent trend in solving the handwritten text line segmentation problem is to employ deep networks that learn the representation directly from the pixels of the image rather than using engineered features [7].",
            "There are metrics that can evaluate the detected baselines [7,20,18] or blob lines [16].",
            "Text line extraction is evaluated by classical image segmentation metrics [7].",
            "FCNs are very successful at detecting handwritten text lines [7]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "cBAD: ICDAR2017 Competition on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              },
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4765236,
          "isinfluential": true,
          "contexts": [
            "The ICDAR2017 dataset [21] includes three books, CB55, CSG18, and CSG863.",
            "The second evaluation is carried out on the ICDAR2017 dataset [21].",
            "The performance is measured using the text line segmentation evaluation metrics, LIU and PIU, of the ICDAR2017 competition on layout analysis [21]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ICDAR2017 Competition on Layout Analysis for Challenging Medieval Manuscripts",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2860677",
                "name": "Fotini Simistira"
              },
              {
                "authorId": "2489964",
                "name": "Manuel Bouillon"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "3424460",
                "name": "Marcel Würsch"
              },
              {
                "authorId": "38890619",
                "name": "Michele Alberti"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9811883,
          "isinfluential": false,
          "contexts": [
            "Their ground truth is provided in PAGE xml format [19,6]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "The PAGE (Page Analysis and Ground-Truth Elements) Format Framework",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "1980669",
                "name": "Stefan Pletschacher"
              },
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33748389,
          "isinfluential": false,
          "contexts": [
            "This problem has been handled via augmentation [9] or learning-free detection [13].",
            "This component can be either a blob line [22,20,16,18,14] strikes through the main body area of the characters that belong to a text line or a baseline [9] passes through the bottom part of the main body of the characters that belong to a text line."
          ],
          "intents": [
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A two-stage method for text line detection in historical documents",
            "abstract": "This work presents a two-stage text line detection method for historical documents. Each detected text line is represented by its baseline. In a first stage, a deep neural network called ARU-Net labels pixels to belong to one of the three classes: baseline, separator and other. The separator class marks beginning and end of each text line. The ARU-Net is trainable from scratch with manageably few manually annotated example images (<50\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$<\\,50$$\\end{document}). This is achieved by utilizing data augmentation strategies. The network predictions are used as input for the second stage which performs a bottom-up clustering to build baselines. The developed method is capable of handling complex layouts as well as curved and arbitrarily oriented text lines. It substantially outperforms current state-of-the-art approaches. For example, for the complex track of the cBAD: ICDAR2017 Competition on Baseline Detection the F value is increased from 0.859 to 0.922. The framework to train and run the ARU-Net is open source.",
            "year": 2018,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "1680083",
                "name": "Gundram Leifert"
              },
              {
                "authorId": "40508719",
                "name": "Tobias Strauß"
              },
              {
                "authorId": "88739357",
                "name": "Johannes Michael"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              }
            ]
          }
        },
        {
          "citedcorpusid": 54465873,
          "isinfluential": false,
          "contexts": [
            "Mask-RCNN is an instance segmentation algorithm which is fully supervised using the pixel labels of the text lines.",
            "Very recently, text line segmentation has been formulated as an instance segmentation problem using Mask-RCNN [10], and its results are available in [14].",
            "We compare our results with those of supervised learning methods, Mask-RCNN [14] and FCN+EM [14], and an unsupervised deep learning method, UTLS [15]."
          ],
          "intents": [
            "--",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Mask R-CNN",
            "abstract": "We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.",
            "year": 2017,
            "venue": "",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2082991",
                "name": "Georgia Gkioxari"
              },
              {
                "authorId": "3127283",
                "name": "Piotr Dollár"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56597514,
          "isinfluential": false,
          "contexts": [
            "There are metrics that can evaluate the detected baselines [7,20,18] or blob lines [16].",
            "This component can be either a blob line [22,20,16,18,14] strikes through the main body area of the characters that belong to a text line or a baseline [9] passes through the bottom part of the main body of the characters that belong to a text line."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation for Challenging Handwritten Document Images using Fully Convolutional Network",
            "abstract": "This paper presents a method for text line segmentation of challenging historical manuscript images. These manuscript images contain narrow interline spaces with touching components, interpenetrating vowel signs and inconsistent font types and sizes. In addition, they contain curved, multi-skewed and multi-directed side note lines within a complex page layout. Therefore, bounding polygon labeling would be very difficult and time consuming. Instead we rely on line masks that connect the components on the same text line. Then these line masks are predicted using a Fully Convolutional Network (FCN). In the literature, FCN has been successfully used for text line segmentation of regular handwritten document images. The present paper shows that FCN is useful with challenging manuscript images as well. Using a new evaluation metric that is sensitive to over segmentation as well as under segmentation, testing results on a publicly available challenging handwritten dataset are comparable with the results of a previous work on the same dataset.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "39240022",
                "name": "M. Kassis"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 195750543,
          "isinfluential": false,
          "contexts": [
            "Learning-free algorithms would be a natural solution but still they do not achieve state of the art [12] except used in hybrid with deep networks [1]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Labeling, Cutting, Grouping: An Efficient Text Line Segmentation Method for Medieval Manuscripts",
            "abstract": "This paper introduces a new way for text-line extraction by integrating deep-learning based pre-classification and state-of-the-art segmentation methods. Text-line extraction in complex handwritten documents poses a significant challenge, even to the most modern computer vision algorithms. Historical manuscripts are a particularly hard class of documents as they present several forms of noise, such as degradation, bleed-through, interlinear glosses, and elaborated scripts. In this work, we propose a novel method which uses semantic segmentation at pixel level as intermediate task, followed by a text-line extraction step. We measured the performance of our method on a recent dataset of challenging medieval manuscripts and surpassed state-of-the-art results by reducing the error by 80.7%. Furthermore, we demonstrate the effectiveness of our approach on various other datasets written in different scripts. Hence, our contribution is two-fold. First, we demonstrate that semantic pixel segmentation can be used as strong denoising pre-processing step before performing text line extraction. Second, we introduce a novel, simple and robust algorithm that leverages the high-quality semantic segmentation to achieve a text-line extraction performance of 99.42% line IU on a challenging dataset.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "38890619",
                "name": "Michele Alberti"
              },
              {
                "authorId": "147382507",
                "name": "Lars Vögtlin"
              },
              {
                "authorId": "8811132",
                "name": "Vinaychandran Pondenkandath"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 221130277,
          "isinfluential": true,
          "contexts": [
            "FCN+EM method [14] is fully supervised by human annotated blob lines.",
            "Very recently, text line segmentation has been formulated as an instance segmentation problem using Mask-RCNN [10], and its results are available in [14].",
            "We compare our results with those of supervised learning methods, Mask-RCNN [14] and FCN+EM [14], and an unsupervised deep learning method, UTLS [15].",
            "Mask-RCNN is an instance segmentation algorithm which is fully supervised using the pixel labels of the text lines.",
            "Some of these extraction methods assume horizontal text lines [22] whereas some can extract text lines at any orientation, with any font type and font size [14].",
            "This component can be either a blob line [22,20,16,18,14] strikes through the main body area of the characters that belong to a text line or a baseline [9] passes through the bottom part of the main body of the characters that belong to a text line.",
            "The VML-AHTE dataset [14] consists of Arabic handwritten documents with crowded diacritics and cramped text lines."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['result']",
            "--",
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line extraction using fully convolutional network and energy minimization",
            "abstract": "Text lines are important parts of handwritten document images and easier to analyze by further applications. Despite recent progress in text line detection, text line extraction from a handwritten document remains an unsolved task. This paper proposes to use a fully convolutional network for text line detection and energy minimization for text line extraction. Detected text lines are represented by blob lines that strike through the text lines. These blob lines assist an energy function for text line extraction. The detection stage can locate arbitrarily oriented text lines. Furthermore, the extraction stage is capable of finding out the pixels of text lines with various heights and interline proximity independent of their orientations. Besides, it can finely split the touching and overlapping text lines without an orientation assumption. We evaluate the proposed method on VML-AHTE, VML-MOC, and Diva-HisDB datasets. The VML-AHTE dataset contains overlapping, touching and close text lines with rich diacritics. The VML-MOC dataset is very challenging by its multiply oriented and skewed text lines. The Diva-HisDB dataset exhibits distinct text line heights and touching text lines. The results demonstrate the effectiveness of the method despite various types of challenges, yet using the same parameters in all the experiments.",
            "year": 2021,
            "venue": "ICPR Workshops",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "1414748211",
                "name": "Reem Alaasam"
              },
              {
                "authorId": "1573588308",
                "name": "Boraq Madi"
              },
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        }
      ]
    },
    "235166756": {
      "citing_paper_info": {
        "title": "Linecounter: Learning Handwritten Text Line Segmentation By Counting",
        "abstract": "Handwritten Text Line Segmentation (HTLS) is a low-level but important task for many higher-level document processing tasks like handwritten text recognition. It is often formulated in terms of semantic segmentation or object detection in deep learning. However, both formulations have serious shortcomings. The former requires heavy post-processing of splitting/merging adjacent segments, while the latter may fail on dense or curved texts. In this paper, we propose a novel Line Counting formulation for HTLS – that involves counting the number of text lines from the top at every pixel location. This formulation helps learn an end-to-end HTLS solution that directly predicts per-pixel line number for a given document image. Furthermore, we propose a deep neural network (DNN) model LineCounter to perform HTLS through the Line Counting formulation. Our extensive experiments on the three public datasets (ICDAR2013-HSC [1], HIT-MW [2], and VML-AHTE [3]) demonstrate that LineCounter outperforms state-of-the-art HTLS approaches. Source code is available at https://github.com/Leedeng/LineCounter.",
        "year": 2021,
        "venue": "International Conference on Information Photonics",
        "authors": [
          {
            "authorId": "2151284328",
            "name": "Deng Li"
          },
          {
            "authorId": "2119299240",
            "name": "Yue Wu"
          },
          {
            "authorId": "3049217",
            "name": "Yicong Zhou"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 7,
        "influential_count": 0,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "45923001",
        "206777650",
        "619938",
        "46776463",
        "5590763",
        "234469714",
        "56597514"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "For detailed reviews of the classic HTLS methods, please refer to [7].",
            "Such variations include but not limited to line orientation, line/word spacing, font size, script language, writing style, image quality, etc. [7, 8]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5590763,
          "isinfluential": false,
          "contexts": [
            "2, LineCounter is a variant of the classic Encoder-Decoder network [22] with three main modules, namely, Encoder, Counter, and Decoder."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation",
            "abstract": "In this paper, we propose a novel neural network model called RNN Encoder‐ Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder‐Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
            "year": 2014,
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "authors": [
              {
                "authorId": "1979489",
                "name": "Kyunghyun Cho"
              },
              {
                "authorId": "3158246",
                "name": "B. V. Merrienboer"
              },
              {
                "authorId": "1854385",
                "name": "Çaglar Gülçehre"
              },
              {
                "authorId": "3335364",
                "name": "Dzmitry Bahdanau"
              },
              {
                "authorId": "2076086",
                "name": "Fethi Bougares"
              },
              {
                "authorId": "144518416",
                "name": "Holger Schwenk"
              },
              {
                "authorId": "1751762",
                "name": "Yoshua Bengio"
              }
            ]
          }
        },
        {
          "citedcorpusid": 45923001,
          "isinfluential": false,
          "contexts": [
            "Conventional solutions [9, 10, 11] typically work under a constrained setup or require strong assumptions on one or more factors."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Markov chain based line segmentation framework for handwritten character recognition",
            "abstract": "In this paper, we present a novel text line segmentation framework following the divide-and-conquer paradigm: we iteratively identify and re-process regions of ambiguous line segmentation from an input document image until there is no ambiguity. To detect ambiguous line segmentation, we introduce the use of two complimentary line descriptors, referred as to the underline and highlight line descriptors, and identify ambiguities when their patterns mismatch. As a result, we can easily identify already good line segmentations, and largely simplify the original line segmentation problem by only reprocessing ambiguous regions. We evaluate the performance of the proposed line segmentation framework using the ICDAR 2009 handwritten document dataset, and it is close to top-performing systems submitted to the competition. Moreover, the proposed method is also robust against skewness, noise, variable line heights and touching characters. The proposed idea can also be applied to other text analysis tasks such as word segmentation and page layout analysis.",
            "year": 2013,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "2119299240",
                "name": "Yue Wu"
              },
              {
                "authorId": "2815926",
                "name": "Shengxin Zha"
              },
              {
                "authorId": "39784761",
                "name": "Huaigu Cao"
              },
              {
                "authorId": "2504497",
                "name": "Daben Liu"
              },
              {
                "authorId": "145603129",
                "name": "P. Natarajan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 46776463,
          "isinfluential": false,
          "contexts": [
            "DNN-based HTLS problem formulations include: 1) semantic segmentation [12, 13, 14, 15], 2) object detection [16, 17], and 3) sequence learning [18].",
            "For example, one needs to apply a smearing kernel on an HTLS line map to obtain the required binary or ternary line blob mask for the semantic segmentation based HTLS [13, 14].",
            "[13, 14, 15] Semantic Seg."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation using a fully convolutional network in handwritten document images",
            "abstract": "Line detection in handwritten documents is an important problem for processing of scanned documents. While existing approaches mainly use hand-designed features or heuristic rules to estimate the location of text lines, the authors present a novel approach that trains a fully convolutional network (FCN) to predict text line structure in document images. A rough estimation of text line, or a line map, is obtained by using FCN, from which text strings that pass through characters in each text line are constructed. Finally, the touching characters should be separated and assigned to different text lines to complete the segmentation, for which line adjacency graph is used. Experimental results on ICDAR2013 Handwritten Segmentation Contest data set show high performance together with the robustness of the system with different types of languages and multi-skewed text lines.",
            "year": 2017,
            "venue": "IET Image Processing",
            "authors": [
              {
                "authorId": "12581289",
                "name": "Q. Vo"
              },
              {
                "authorId": "2355626",
                "name": "Soohyung Kim"
              },
              {
                "authorId": "97598888",
                "name": "Hyung-Jeong Yang"
              },
              {
                "authorId": "144096223",
                "name": "Gueesang Lee"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56597514,
          "isinfluential": false,
          "contexts": [
            "DNN-based HTLS problem formulations include: 1) semantic segmentation [12, 13, 14, 15], 2) object detection [16, 17], and 3) sequence learning [18].",
            "[13, 14, 15] Semantic Seg.",
            "In this section, we compare the HTLS performance of the proposed LineCounter solution with the state-of-the-art (SoTA) DNN based solutions – the semantic segmentation based HTLS [12, 15], the object detection based HTLS [16], and the start-and-follow based HTLS [19]."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation for Challenging Handwritten Document Images using Fully Convolutional Network",
            "abstract": "This paper presents a method for text line segmentation of challenging historical manuscript images. These manuscript images contain narrow interline spaces with touching components, interpenetrating vowel signs and inconsistent font types and sizes. In addition, they contain curved, multi-skewed and multi-directed side note lines within a complex page layout. Therefore, bounding polygon labeling would be very difficult and time consuming. Instead we rely on line masks that connect the components on the same text line. Then these line masks are predicted using a Fully Convolutional Network (FCN). In the literature, FCN has been successfully used for text line segmentation of regular handwritten document images. The present paper shows that FCN is useful with challenging manuscript images as well. Using a new evaluation metric that is sensitive to over segmentation as well as under segmentation, testing results on a publicly available challenging handwritten dataset are comparable with the results of a previous work on the same dataset.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "39240022",
                "name": "M. Kassis"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206777650,
          "isinfluential": false,
          "contexts": [
            "The Handwritten Text Line Segmentation (HTLS) problem is a classic problem in document analysis that serves as a prerequisite step for many higher-level document processing tasks like keyword spotting [4], table analysis [5] and handwritten text recognition [6]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Table Detection Using Deep Learning",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1402440928",
                "name": "Azka Gilani"
              },
              {
                "authorId": "39404123",
                "name": "S. Qasim"
              },
              {
                "authorId": "49012494",
                "name": "M. I. Malik"
              },
              {
                "authorId": "1688013",
                "name": "F. Shafait"
              }
            ]
          }
        },
        {
          "citedcorpusid": 234469714,
          "isinfluential": false,
          "contexts": [
            "For example, one needs to apply a smearing kernel on an HTLS line map to obtain the required binary [19] or ternary line blob mask for the semantic segmentation based HTLS [13, 14]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "SauvolaNet: Learning Adaptive Sauvola Network for Degraded Document Binarization",
            "abstract": "Inspired by the classic Sauvola local image thresholding approach, we systematically study it from the deep neural network (DNN) perspective and propose a new solution called SauvolaNet for degraded document binarization (DDB). It is composed of three explainable modules, namely, Multi-Window Sauvola (MWS), Pixelwise Window Attention (PWA), and Adaptive Sauolva Threshold (AST). The MWS module honestly reflects the classic Sauvola but with trainable parameters and multi-window settings. The PWA module estimates the preferred window sizes for each pixel location. The AST module further consolidates the outputs from MWS and PWA and predicts the final adaptive threshold for each pixel location. As a result, SauvolaNet becomes end-to-end trainable and significantly reduces the number of required network parameters to 40K -- it is only 1\\% of MobileNetV2. In the meantime, it achieves the State-of-The-Art (SoTA) performance for the DDB task -- SauvolaNet is at least comparable to, if not better than, SoTA binarization solutions in our extensive studies on the 13 public document binarization datasets. Our source code is available at https://github.com/Leedeng/SauvolaNet.",
            "year": 2021,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2151284328",
                "name": "Deng Li"
              },
              {
                "authorId": "2119299240",
                "name": "Yue Wu"
              },
              {
                "authorId": "3049217",
                "name": "Yicong Zhou"
              }
            ]
          }
        }
      ]
    },
    "221663960": {
      "citing_paper_info": {
        "title": "Unsupervised deep learning for text line segmentation",
        "abstract": "We present an unsupervised deep learning method for text line segmentation that is inspired by the relative variance between text lines and spaces among text lines. Handwritten text line segmentation is important for the efficiency of further processing. A common method is to train a deep learning network for embedding the document image into an image of blob lines that are tracing the text lines. Previous methods learned such embedding in a supervised manner, requiring the annotation of many document images. This paper presents an unsupervised embedding of document image patches without a need for annotations. The number of foreground pixels over the text lines is relatively different from the number of foreground pixels over the spaces among text lines. Generating similar and different pairs relying on this principle definitely leads to outliers. However, as the results show, the outliers do not harm the convergence and the network learns to discriminate the text lines from the spaces between text lines. Remarkably, with a challenging Arabic handwritten text line segmentation dataset, VML-AHTE, we achieved superior performance over the supervised methods. Additionally, the proposed method was evaluated on the ICDAR 2017 and ICFHR 2010 handwritten text line segmentation datasets.",
        "year": 2020,
        "venue": "International Conference on Pattern Recognition",
        "authors": [
          {
            "authorId": "51036690",
            "name": "Berat Kurar Barakat"
          },
          {
            "authorId": "27005271",
            "name": "Ahmad Droby"
          },
          {
            "authorId": "1414748211",
            "name": "Reem Alaasam"
          },
          {
            "authorId": "1573588308",
            "name": "Boraq Madi"
          },
          {
            "authorId": "2578300",
            "name": "Irina Rabaev"
          },
          {
            "authorId": "1573588240",
            "name": "Raed Shammes"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 12,
        "unique_cited_count": 12,
        "influential_count": 0,
        "detailed_records_count": 12
      },
      "cited_papers": [
        "4766619",
        "1775179",
        "13749026",
        "18720327",
        "8603144",
        "13776112",
        "2430892",
        "211026904",
        "15921038",
        "195847950",
        "46955576",
        "2245438"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1775179,
          "isinfluential": false,
          "contexts": [
            "According to the Gestalt principle [9], such relevance among the elements of a document image forms the basis of unsupervised segmentation of text lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Principles Of Gestalt Psychology",
            "abstract": "Routledge is now re-issuing this prestigious series of 204 volumes originally published between 1910 and 1965. The titles include works by key figures such asC.G. Jung, Sigmund Freud, Jean Piaget, Otto Rank, James Hillman, Erich Fromm, Karen Horney and Susan Isaacs. Each volume is available on its own, as part of a themed mini-set, or as part of a specially-priced 204-volume set. A brochure listing each title in the \"International Library of Psychology\" series is available upon request.",
            "year": 1936,
            "venue": "",
            "authors": [
              {
                "authorId": "89596835",
                "name": "O. Reiser"
              },
              {
                "authorId": "114409274",
                "name": "K. Koffka"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2245438,
          "isinfluential": false,
          "contexts": [
            "(cid:104)·(cid:105) denotes expectation over all pairs of neighbouring components [34] in a document page image. δ ( (cid:96) c (cid:54) = (cid:96) c (cid:48) ) is equal to 1 if the condition inside the parentheses holds and 0 otherwise."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Interactive graph cuts for optimal boundary & region segmentation of objects in N-D images",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001",
            "authors": [
              {
                "authorId": "1692688",
                "name": "Yuri Boykov"
              },
              {
                "authorId": "144197071",
                "name": "M. Jolly"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2430892,
          "isinfluential": false,
          "contexts": [
            "We adopt the energy minimization framework [33] that uses graph cuts to approximate the minima of an arbitrary function."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Fast approximate energy minimization via graph cuts",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of the Seventh IEEE International Conference on Computer Vision",
            "authors": [
              {
                "authorId": "1692688",
                "name": "Yuri Boykov"
              },
              {
                "authorId": "1922280",
                "name": "Olga Veksler"
              },
              {
                "authorId": "2984143",
                "name": "R. Zabih"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4766619,
          "isinfluential": false,
          "contexts": [
            "Another wide class of methods are grouping or clustering methods that aggregate elements (such as pixels or connected components) in a bottom up strategy [7], [19]–[21]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Robust and Binarization-Free Approach for Text Line Detection in Historical Documents",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "1680083",
                "name": "Gundram Leifert"
              },
              {
                "authorId": "40508719",
                "name": "Tobias Strauß"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8603144,
          "isinfluential": false,
          "contexts": [
            "Seam-carving methods build energy map and compute seams that separate text lines (or seams that pierce through text lines) [25]–[28]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Language-Independent Text Lines Extraction Using Seam Carving",
            "abstract": "",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1741845",
                "name": "Raid Saabni"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13749026,
          "isinfluential": false,
          "contexts": [
            "[3] presented a CNN-based pixel-wise predictor for addressing multiple tasks simultaneously: page extraction, layout analysis, baseline extraction, and illustration and photograph extraction."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "dhSegment: A Generic Deep-Learning Approach for Document Segmentation",
            "abstract": "In recent years there have been multiple successful attempts tackling document processing problems separately by designing task specific hand-tuned strategies. We argue that the diversity of historical document processing tasks prohibits to solve them one at a time and shows a need for designing generic approaches in order to handle the variability of historical series. In this paper, we address multiple tasks simultaneously such as page extraction, baseline extraction, layout analysis or multiple typologies of illustrations and photograph extraction. We propose an open-source implementation of a CNN-based pixel-wise predictor coupled with task dependent post-processing blocks. We show that a single CNN-architecture can be used across tasks with competitive results. Moreover most of the task-specific post-precessing steps can be decomposed in a small number of simple and standard reusable operations, adding to the flexibility of our approach.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2066810458",
                "name": "S. Oliveira"
              },
              {
                "authorId": "2060245962",
                "name": "Benoit Seguin"
              },
              {
                "authorId": "143791091",
                "name": "F. Kaplan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13776112,
          "isinfluential": false,
          "contexts": [
            "The performance is measured using the line segmentation evaluation metrics of ICDAR 2013 [13] and ICDAR 2017 [35]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Open Evaluation Tool for Layout Analysis of Document Images",
            "abstract": "This paper presents an open tool for standardizing the evaluation process of the layout analysis task of document images at pixel level. We introduce a new evaluation tool that is both available as a standalone Java application and as a RESTful web service. This evaluation tool is free and open-source in order to be a common tool that anyone can use and contribute to. It aims at providing as many metrics as possible to investigate layout analysis predictions, and also provides an easy way of visualizing the results. This tool evaluates document segmentation at pixel level, and supports multi-labeled pixel ground truth. Finally, this tool has been successfully used for the ICDAR 2017 competition on Layout Analysis for Challenging Medieval Manuscripts.",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "38890619",
                "name": "Michele Alberti"
              },
              {
                "authorId": "2489964",
                "name": "Manuel Bouillon"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15921038,
          "isinfluential": false,
          "contexts": [
            "Smearing based methods [5]–[7], [22]–[24] target to enhance the text line structure."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document Analysis System",
            "abstract": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included.",
            "year": 1982,
            "venue": "IBM Journal of Research and Development",
            "authors": [
              {
                "authorId": "145470231",
                "name": "Kwan Y. Wong"
              },
              {
                "authorId": "34896449",
                "name": "R. Casey"
              },
              {
                "authorId": "1880661",
                "name": "F. Wahl"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18720327,
          "isinfluential": false,
          "contexts": [
            "Another wide class of methods are grouping or clustering methods that aggregate elements (such as pixels or connected components) in a bottom up strategy [7], [19]–[21]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Detection in Corrupted and Damaged Historical Manuscripts",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "2339207",
                "name": "Ofer Biller"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1686153",
                "name": "I. Dinstein"
              }
            ]
          }
        },
        {
          "citedcorpusid": 46955576,
          "isinfluential": false,
          "contexts": [
            "Renton et al. [1] employed a variant of Fully Convolutional Network (FCN) with dilated convolutions for text line extraction.",
            "Learning based methods [1]–[4] can inherently handle the problems arising from complex layout of text lines and heterogeneity of documents."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Fully convolutional network with dilated convolutions for handwritten text line segmentation",
            "abstract": "",
            "year": 2018,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "47689382",
                "name": "G. Renton"
              },
              {
                "authorId": "2652359",
                "name": "Yann Soullard"
              },
              {
                "authorId": "1712446",
                "name": "Clément Chatelain"
              },
              {
                "authorId": "143680806",
                "name": "Sébastien Adam"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 195847950,
          "isinfluential": false,
          "contexts": [
            "Kiessling et al. [29] presented method based on a fully convolutional encoder-decoder network to detect baselines in document images."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "BADAM: A Public Dataset for Baseline Detection in Arabic-script Manuscripts",
            "abstract": "The application of handwritten text recognition to historical works is highly dependant on accurate text line retrieval. A number of systems utilizing a robust baseline detection paradigm have emerged recently but the advancement of layout analysis methods for challenging scripts is held back by the lack of well-established datasets including works in non-Latin scripts. We present a dataset of 400 annotated document images from different domains and time periods. A short elaboration on the particular challenges posed by handwriting in Arabic script for layout analysis and subsequent processing steps is given. Lastly, we propose a method based on a fully convolutional encoder-decoder network to extract arbitrarily shaped text line images from manuscripts.",
            "year": 2019,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "49034253",
                "name": "Benjamin Kiessling"
              },
              {
                "authorId": "31977716",
                "name": "D. Ezra"
              },
              {
                "authorId": "2111207584",
                "name": "M. Miller"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211026904,
          "isinfluential": false,
          "contexts": [
            "Mechi et al. [30] and Neche et al. [31] used an U-net and RU-net deep-learning models, which are variants of FCN."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation in Historical Document Images Using an Adaptive U-Net Architecture",
            "abstract": "On most document image transcription, indexing and retrieval systems, text line segmentation remains one of the most important preliminary task. Hence, the research community working in document image analysis is particularly interested in providing reliable text line segmentation methods. Recently, an increasing interest in using deep learning-based methods has been noted for solving various sub-fields and tasks related to the issues surrounding document image analysis. Thanks to the computer hardware and software evolution, several methods based on using deep architectures continue to outperform the pattern recognition issues and particularly those related to historical document image analysis. Thus, in this paper we present a novel deep learning-based method for text line segmentation of historical documents. The proposed method is based on using an adaptive U-Net architecture. Qualitative and numerical experiments are given using a large number of historical document images collected from the Tunisian national archives and different recent benchmarking datasets provided in the context of ICDAR and ICFHR competitions. Moreover, the results achieved are compared with those obtained using the state-of-the-art methods.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "51133427",
                "name": "Olfa Mechi"
              },
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "2536574",
                "name": "N. Amara"
              }
            ]
          }
        }
      ]
    },
    "213005473": {
      "citing_paper_info": {
        "title": "Unsupervised text line segmentation",
        "abstract": "We present an unsupervised text line segmentation method that is inspired by the relative variance between text lines and spaces among text lines. Handwritten text line segmentation is important for the efficiency of further processing. A common method is to train a deep learning network for embedding the document image into an image of blob lines that are tracing the text lines. Previous methods learned such embedding in a supervised manner, requiring the annotation of many document images. This paper presents an unsupervised embedding of document image patches without a need for annotations. The main idea is that the number of foreground pixels over the text lines is relatively different from the number of foreground pixels over the spaces among text lines. Generating similar and different pairs relying on this principle definitely leads to outliers. However, as the results show, the outliers do not harm the convergence and the network learns to discriminate the text lines from the spaces between text lines. We experimented with a challenging Arabic handwritten text line segmentation dataset, VML-AHTE, and achieved a superior performance even over the supervised methods.",
        "year": 2020,
        "venue": "arXiv.org",
        "authors": [
          {
            "authorId": "51036690",
            "name": "Berat Kurar Barakat"
          },
          {
            "authorId": "27005271",
            "name": "Ahmad Droby"
          },
          {
            "authorId": "1573576965",
            "name": "Rym Alasam"
          },
          {
            "authorId": "1573588308",
            "name": "Boraq Madi"
          },
          {
            "authorId": "2578300",
            "name": "Irina Rabaev"
          },
          {
            "authorId": "1573588240",
            "name": "Raed Shammes"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 7,
        "influential_count": 0,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "15926594",
        "13776112",
        "3361432",
        "15921038",
        "207938785",
        "9187881",
        "49653345"
      ],
      "citation_details": [
        {
          "citedcorpusid": 3361432,
          "isinfluential": false,
          "contexts": [
            "Between the early approaches are projection proﬁles based methods, which were ﬁrst applied to documents with horizontal text lines [12], [13], and subsequently adapted to document with skewed [14], [15] and multi-skewed text lines [16]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Document page decomposition by the bounding-box project",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2122930",
                "name": "J. Ha"
              },
              {
                "authorId": "1710238",
                "name": "R. Haralick"
              },
              {
                "authorId": "1744200",
                "name": "I. T. Phillips"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": false,
          "contexts": [
            "Smearing based methods [5]–[7], [20]–[22] target to enhance the text line structure.",
            "However, they require vast amount of labeling effort which consumes time not less than carefully designed ad-hoc heuristics [5]–[8]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13776112,
          "isinfluential": false,
          "contexts": [
            "The results are presented using line segmentation evaluation metrics of ICDAR2013 [33] and ICDAR2017 [34]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Open Evaluation Tool for Layout Analysis of Document Images",
            "abstract": "This paper presents an open tool for standardizing the evaluation process of the layout analysis task of document images at pixel level. We introduce a new evaluation tool that is both available as a standalone Java application and as a RESTful web service. This evaluation tool is free and open-source in order to be a common tool that anyone can use and contribute to. It aims at providing as many metrics as possible to investigate layout analysis predictions, and also provides an easy way of visualizing the results. This tool evaluates document segmentation at pixel level, and supports multi-labeled pixel ground truth. Finally, this tool has been successfully used for the ICDAR 2017 competition on Layout Analysis for Challenging Medieval Manuscripts.",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "38890619",
                "name": "Michele Alberti"
              },
              {
                "authorId": "2489964",
                "name": "Manuel Bouillon"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15921038,
          "isinfluential": false,
          "contexts": [
            "Smearing based methods [5]–[7], [20]–[22] target to enhance the text line structure."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document Analysis System",
            "abstract": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included.",
            "year": 1982,
            "venue": "IBM Journal of Research and Development",
            "authors": [
              {
                "authorId": "145470231",
                "name": "Kwan Y. Wong"
              },
              {
                "authorId": "34896449",
                "name": "R. Casey"
              },
              {
                "authorId": "1880661",
                "name": "F. Wahl"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15926594,
          "isinfluential": false,
          "contexts": [
            " [14], [15] and multi-skewed text lines [16]. Another wide class of methods are grouping or clustering methods that aggregate elements (such as pixels or connected components) in a bottom up strategy [7], [17]– [19]. Smearing based methods [5]–[7], [20]–[22] target to enhance the text line structure. Seam-carving methods build energy map and compute seams that separate text lines (or seams that pierc"
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Script-Independent Handwritten Textlines Segmentation using Active Contours",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 49653345,
          "isinfluential": false,
          "contexts": [
            "However, the outliers do not harm the convergence of the machine learning [9].",
            "Then, we reduce dimensions of these vectors into their three principle components, which enables producing pseudo-RGB images where similar pixels in the embedded space correspond to similar colors [9]."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Unsupervised natural image patch learning",
            "abstract": "A metric for natural image patches is an important tool for analyzing images. An efficient means of learning one is to train a deep network to map an image patch to a vector space, in which the Euclidean distance reflects patch similarity. Previous attempts learned such an embedding in a supervised manner, requiring the availability of many annotated images. In this paper, we present an unsupervised embedding of natural image patches, avoiding the need for annotated images. The key idea is that the similarity of two patches can be learned from the prevalence of their spatial proximity in natural images. Clearly, relying on this simple principle, many spatially nearby pairs are outliers. However, as we show, these outliers do not harm the convergence of the metric learning. We show that our unsupervised embedding approach is more effective than a supervised one or one that uses deep patch representations. Moreover, we show that it naturally lends itself to an efficient self-supervised domain adaptation technique onto a target domain that contains a common foreground object.",
            "year": 2018,
            "venue": "Computational Visual Media",
            "authors": [
              {
                "authorId": "34931590",
                "name": "Dov Danon"
              },
              {
                "authorId": "1388323535",
                "name": "Hadar Averbuch-Elor"
              },
              {
                "authorId": "2416503",
                "name": "Ohad Fried"
              },
              {
                "authorId": "1388323541",
                "name": "D. Cohen-Or"
              }
            ]
          }
        },
        {
          "citedcorpusid": 207938785,
          "isinfluential": false,
          "contexts": [
            "Mechi et al. [28] and Neche et al. [29] used an U-net and RU-net deep-learning models, which are variants of FCN."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Arabic Handwritten Documents Segmentation into Text-Lines and Words using Deep Learning",
            "abstract": "One of the most important steps in a handwriting recognition system is text-line and word segmentation. But, this step is made difficult by the differences in handwriting styles, problems of skewness, overlapping and touching of text and the fluctuations of text-lines. It is even more difficult for ancient and calligraphic writings, as in Arabic manuscripts, due to the cursive connection in Arabic text, the erroneous position of diacritic marks, the presence of ascending and descending letters, etc. In this work, we propose an effective segmentation of Arabic handwritten text into text-lines and words, using deep learning. For text-line segmentation, we used an RU-net which allows a pixel-wise classification to separate text-lines pixels from the background ones. For word segmentation, we resorted to the text-line transcription, as we have not got a ground truth at word level. A BLSTM-CTC (Bidirectional Long Short Term Memory followed by a Connectionist Temporal Classification) is then used to perform the mapping between the transcription and text-line image, avoiding the need of the input segmentation. A CNN (Convolutional Neural Network) precedes the BLST-CTC to extract the features and to feed the BLSTM with the essential of the text-line image. Tested on the standard KHATT Arabic database, the experimental results confirm a segmentation success rate of no less than 96.7% for text-lines and 80.1% for words.",
            "year": 2019,
            "venue": "2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)",
            "authors": [
              {
                "authorId": "1404225473",
                "name": "Chemseddine Neche"
              },
              {
                "authorId": "2128453",
                "name": "A. Belaïd"
              },
              {
                "authorId": "144771520",
                "name": "A. Kacem"
              }
            ]
          }
        }
      ]
    },
    "25082992": {
      "citing_paper_info": {
        "title": "Robust Text Line Segmentation for Historical Manuscript Images Using Color and Texture",
        "abstract": "",
        "year": 2014,
        "venue": "International Conference on Pattern Recognition",
        "authors": [
          {
            "authorId": "153819461",
            "name": "Kai Chen"
          },
          {
            "authorId": "2109393868",
            "name": "Hao Wei"
          },
          {
            "authorId": "1743758",
            "name": "M. Liwicki"
          },
          {
            "authorId": "1722800",
            "name": "J. Hennebert"
          },
          {
            "authorId": "1680326",
            "name": "R. Ingold"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 6,
        "influential_count": 0,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "43919463",
        "961425",
        "14408465",
        "16211698",
        "369876",
        "15793605"
      ],
      "citation_details": [
        {
          "citedcorpusid": 369876,
          "isinfluential": false,
          "contexts": [
            "Local binary patterns (LBP) has been successfully used for face recognition [1] and facial gesture recognition [22]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Face Description with Local Binary Patterns: Application to Face Recognition",
            "abstract": "",
            "year": 2006,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "48345000",
                "name": "T. Ahonen"
              },
              {
                "authorId": "144979251",
                "name": "A. Hadid"
              },
              {
                "authorId": "145962204",
                "name": "M. Pietikäinen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 961425,
          "isinfluential": false,
          "contexts": [
            "Therefore, we used for the modelling part default settings of a state-of-the-art SVM implementation [5]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "LIBSVM: A library for support vector machines",
            "abstract": "",
            "year": 2011,
            "venue": "TIST",
            "authors": [
              {
                "authorId": null,
                "name": "Chih-Chung Chang"
              },
              {
                "authorId": "1711460",
                "name": "Chih-Jen Lin"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14408465,
          "isinfluential": false,
          "contexts": [
            "In order to capture the local structure information of each pixel and achieve rotation invariance, we compute the LBP histogram in its n×n neighbors based on the Rotation Invariant Unifrom Pattern (LBP ) [8]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Local Binary Pattern histogram based Texton learning for texture classification",
            "abstract": "Local Binary Pattern (LBP) and Texton are both widely used texture analysis techniques. In this paper we propose a patch-based texture classification method that takes advantage of both LBP and Texton. Unlike the traditional LBP methods that describe a texture with the occurrence of local binary patterns in the entire image, we compute the LBP histogram in a small region around each pixel to capture the local structure information. The texton learning method is then performed on these LBP histograms, resulting in a texture classification algorithm that outperforms the traditional LBP-based methods due to its preservation of local structure information. It also outperforms the traditional filtering-based texton methods due to its robustness to orientation and illumination. Experimental results on two benchmark databases validate the advantages of the proposed method.",
            "year": 2011,
            "venue": "2011 18th IEEE International Conference on Image Processing",
            "authors": [
              {
                "authorId": "49990688",
                "name": "Yonggang He"
              },
              {
                "authorId": "1707161",
                "name": "N. Sang"
              },
              {
                "authorId": "40372975",
                "name": "Rui Huang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15793605,
          "isinfluential": false,
          "contexts": [
            "MEMORIAL [2] aims at the development of a digital document workbench enabling the creation of distributed virtual archives based on printed historical document images."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Document image analysis for World War II personal records",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              },
              {
                "authorId": "1694974",
                "name": "Dimosthenis Karatzas"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16211698,
          "isinfluential": false,
          "contexts": [
            "AGORA [18] uses two maps to segment historical document images: a map of the foreground and a map of the background."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "AGORA: the interactive document image analysis tool of the BVH project",
            "abstract": "",
            "year": 2006,
            "venue": "Document Image Analysis for Libraries",
            "authors": [
              {
                "authorId": "1689847",
                "name": "Jean-Yves Ramel"
              },
              {
                "authorId": "1409108516",
                "name": "S. Busson"
              },
              {
                "authorId": "2070507435",
                "name": "M. Demonet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 43919463,
          "isinfluential": false,
          "contexts": [
            "It has also been used in the filed of character recognition [9].",
            "As described in [9], Gabor filters localize direction spatial frequency at orientation θ, i."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Recognition of gray character using gabor filters",
            "abstract": "",
            "year": 2002,
            "venue": "Proceedings of the Fifth International Conference on Information Fusion. FUSION 2002. (IEEE Cat.No.02EX5997)",
            "authors": [
              {
                "authorId": "2067772631",
                "name": "Peifeng Hu"
              },
              {
                "authorId": "2109705849",
                "name": "Yannan Zhao"
              },
              {
                "authorId": "1774298",
                "name": "Zehong Yang"
              },
              {
                "authorId": "2110238937",
                "name": "Jiaqin Wang"
              }
            ]
          }
        }
      ]
    },
    "2311104": {
      "citing_paper_info": {
        "title": "Text Line Segmentation using AHTC and Watershed Algorithm for Handwritten Document Images",
        "abstract": "Text line segmentation is a critical task in handwritten document recognition. In this paper, we propose a novel text-line segmentation method using baseline estimation and watershed. The baseline-detection algorithm estimates the baseline using Adaptive Head-Tail Connection(AHTC) on the document. Then, the watershed method segments the line region using the baseline-detection result. Finally, the text lines are separated by watershed result and a post-processing algorithm defines the lines more correctly. The scheme successfully segments text lines with 97% accuracy from the handwritten document images in the ICDAR database.",
        "year": 2014,
        "venue": "International Journal of Contents",
        "authors": [
          {
            "authorId": "2100920",
            "name": "K. Oh"
          },
          {
            "authorId": "2355626",
            "name": "Soohyung Kim"
          },
          {
            "authorId": "31725329",
            "name": "In Seop Na"
          },
          {
            "authorId": "8779207",
            "name": "Gwangbok Kim"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 9,
        "unique_cited_count": 7,
        "influential_count": 0,
        "detailed_records_count": 9
      },
      "cited_papers": [
        "1913486",
        "7130275",
        "24241789",
        "9712378",
        "619938",
        "15257932",
        "35215159"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "In this field several other text line segmentation approaches which are different paradigms can be classified as projection based, run-length smearing, and grouping [1]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1913486,
          "isinfluential": false,
          "contexts": [
            "TEI[15] 1637 1549 95."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 7130275,
          "isinfluential": false,
          "contexts": [
            "The result of proposed method is evaluated on public dataset (ICDAR 2009 [13]).",
            "Table 1 shows a comparison between the proposed method and the several competitive methods of text line segmentation in ICDAR 2010 Handwritten Segmentation Contest [13]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ICFHR 2010 Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9712378,
          "isinfluential": false,
          "contexts": [
            "The reference [7] proposed a text line segmentation method using perceptual grouping algorithm."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line detection and segmentation in historical church registers",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2834467",
                "name": "Markus Feldbach"
              },
              {
                "authorId": "145967589",
                "name": "Klaus D. Tönnies"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15257932,
          "isinfluential": false,
          "contexts": [
            "CUBS[14] 1626 1589 97."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition A Steerable Directional Local Profile Technique for Extraction of Handwritten Arabic Text Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 24241789,
          "isinfluential": false,
          "contexts": [
            "IRISA[16] 1626 1578 96."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Interest of perceptive vision for document structure analysis",
            "abstract": "",
            "year": 2010,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "33225210",
                "name": "Aurélie Lemaitre"
              },
              {
                "authorId": "1760753",
                "name": "J. Camillerapp"
              },
              {
                "authorId": "1789181",
                "name": "Bertrand Coüasnon"
              }
            ]
          }
        },
        {
          "citedcorpusid": 35215159,
          "isinfluential": false,
          "contexts": [
            "An author [4] divide image into vertical stripes and profile projection on each strip in order to overcome the skew problem."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Arabic hand-written text-line extraction",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              },
              {
                "authorId": "144484822",
                "name": "P. Mercy"
              },
              {
                "authorId": "2102325551",
                "name": "Said Ramdane"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "The watershed algorithm is a well-known image segmentation approach [10].",
            "The watershed transform computes catchment basins and ridgelines, where catchment basins corresponding to image regions and ridgelines relating to region boundaries [10]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "The projection profile analysis was applied in [2], [3] to segment the boundaries of the text lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "15899667": {
      "citing_paper_info": {
        "title": "Text line extraction for historical document images using steerable directional filters",
        "abstract": "",
        "year": 2014,
        "venue": "International Conferences on Audio, Language and Image Processing",
        "authors": [
          {
            "authorId": "2927015",
            "name": "Omar Alaql"
          },
          {
            "authorId": "144671149",
            "name": "Cheng-Chang Lu"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 0,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "2123198",
        "9187881",
        "12993414",
        "10232002",
        "14628048"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2123198,
          "isinfluential": false,
          "contexts": [
            "In two contests for handwritten segmentation [2, 3], the CUBS approach achieved the highest results in text line segmentation performance evaluation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "144429596",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "2265885161",
                "name": "Umapada Pal"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": false,
          "contexts": [
            "We will continue our tests and comparisons with other methods, such as the CUBS method [1] and the level set method [7].",
            "It is similar to [7, 12, 13], MatchScore matrix is calculated by counting the number of matches between the pixels in the ground-truth object, whether paragraph or text line, and the detected object.",
            "An approach for handwritten text line segmentation using level sets has been presented in [7]."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10232002,
          "isinfluential": false,
          "contexts": [
            "Govindaraju [4] proposed an algorithm to extract the text lines of the complex historical documents using the adaptive local connectivity map (ALCM) technique."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text extraction from gray scale historical document images using adaptive local connectivity map",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1800513",
                "name": "Srirangaraj Setlur"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12993414,
          "isinfluential": false,
          "contexts": [
            "It is similar to [7, 12, 13], MatchScore matrix is calculated by counting the number of matches between the pixels in the ground-truth object, whether paragraph or text line, and the detected object."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text-Line Extraction in Handwritten Chinese Documents Based on an Energy Minimization Framework",
            "abstract": "",
            "year": 2012,
            "venue": "IEEE Transactions on Image Processing",
            "authors": [
              {
                "authorId": "2463454",
                "name": "H. Koo"
              },
              {
                "authorId": "1707645",
                "name": "N. Cho"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14628048,
          "isinfluential": false,
          "contexts": [
            "[10] proposed an algorithm to extract text lines from unconstrained handwritten Arabic documents."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Handwritten Arabic text line segmentation using affinity propagation",
            "abstract": "",
            "year": 2010,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "2069634816",
                "name": "J. Kumar"
              },
              {
                "authorId": "1404588675",
                "name": "W. Abd-Almageed"
              },
              {
                "authorId": "145714522",
                "name": "Le Kang"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              }
            ]
          }
        }
      ]
    },
    "14209826": {
      "citing_paper_info": {
        "title": "Text line extraction for historical document images",
        "abstract": "",
        "year": 2014,
        "venue": "Pattern Recognition Letters",
        "authors": [
          {
            "authorId": "1741845",
            "name": "Raid Saabni"
          },
          {
            "authorId": "145766704",
            "name": "Abedelkadir Asi"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 20,
        "unique_cited_count": 18,
        "influential_count": 2,
        "detailed_records_count": 20
      },
      "cited_papers": [
        "14210437",
        "15181078",
        "10834729",
        "16669882",
        "45222320",
        "15926594",
        "10232002",
        "43027422",
        "23399574",
        "15921038",
        "12534822",
        "1913486",
        "6906729",
        "723272",
        "15257932",
        "9763623",
        "619938",
        "9187881"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "poses different challenges than those in machine-printed documents (Likforman-Sulem et al., 2007), mainly because of the flexible writing style and the degraded image quality.",
            "Extracting text lines from handwritten document images poses different challenges than those in machine-printed documents (Likforman-Sulem et al., 2007), mainly because of the flexible writing style and the degraded image quality."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 723272,
          "isinfluential": false,
          "contexts": [
            ", instead of the entire text line, adaptive fractions are used to compute the projection profile (Zahour et al., 2007; Arivazhagan et al., 2007; Yosef et al., 2009).",
            "Pursuant to these limitations, the global\nprojection profile technique was modified to be employed in an adaptive manner; i.e., instead of the entire text line, adaptive fractions are used to compute the projection profile (Zahour et al., 2007; Arivazhagan et al., 2007; Yosef et al., 2009)."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation of Historical Arabic Documents",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "1983484",
                "name": "Wafa Boussellaa"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1913486,
          "isinfluential": true,
          "contexts": [
            "Nicolaou and Gatos (2009) used local minima tracers, to follow the white-most and black-most paths from one side to other in order to shred the image into text line areas.",
            "Therefore, we have evaluated the two algorithms differently.\nin Nicolaou and Gatos (2009)(the first Column) and the system presented in Shi et al. (2009)(the second Column).",
            "The first by Nicolaou and Gatos (2009), which shreds an image to lines using tracers that follow the white-most and black-most paths and the second by Shi\n2 The datasets and the corresponding groundtruth are available at http:// www.cs.bgu.ac.il/ abedas/#publication.\net al. (2009), which generates…",
            "Hybrid schemes combine techniques from top-down and bottom-up classes to yield better results."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 6906729,
          "isinfluential": false,
          "contexts": [
            "…text lines is a major prerequisite procedure for various document image analysis tasks, such as word spotting, key-word searching, and text alignment (Asi et al., 2011; Rath and Manmatha, 2003; Rath et al., 2004; Kornfield et al., 2004; Shi et al., 2005; Li et al., 2008; Saabni and El-Sana,\n2008).",
            "Document image segmentation into text lines is a major prerequisite procedure for various document image analysis tasks, such as word spotting, key-word searching, and text alignment (Asi et al., 2011; Rath and Manmatha, 2003; Rath et al., 2004; Kornfield et al., 2004; Shi et al., 2005; Li et al., 2008; Saabni and El-Sana, 2008)."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "User-assisted alignment of Arabic historical manuscripts",
            "abstract": "",
            "year": 2011,
            "venue": "The Hip",
            "authors": [
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": false,
          "contexts": [
            "…text lines is a major prerequisite procedure for various document image analysis tasks, such as word spotting, key-word searching, and text alignment (Asi et al., 2011; Rath and Manmatha, 2003; Rath et al., 2004; Kornfield et al., 2004; Shi et al., 2005; Li et al., 2008; Saabni and El-Sana,\n2008).",
            "Some other methods use Level-set techniques for line\nextraction (Li et al., 2008; Bukhari et al., 2009).",
            "Document image segmentation into text lines is a major prerequisite procedure for various document image analysis tasks, such as word spotting, key-word searching, and text alignment (Asi et al., 2011; Rath and Manmatha, 2003; Rath et al., 2004; Kornfield et al., 2004; Shi et al., 2005; Li et al., 2008; Saabni and El-Sana, 2008)."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9763623,
          "isinfluential": false,
          "contexts": [
            "Among hybrid approaches one can find the work presented recently by Kumar et al. (2011) where they first suggest a coarse text line estimation, followed by an error detection and correction step to refine text line estimation and assigning misclassified diacritic symbols."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Handwritten Textlines in Presence of Touching Components",
            "abstract": "",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2069634816",
                "name": "J. Kumar"
              },
              {
                "authorId": "145714522",
                "name": "Le Kang"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "1404588675",
                "name": "W. Abd-Almageed"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10232002,
          "isinfluential": false,
          "contexts": [
            "…the Negev, Beer Sheva, Israel\na r t i c l e i n f o a b s t r a c t\nArticle history: Available online 23 July 2013\nKeywords: Seam carving Line extraction Multilingual Signed distance transform Dynamic programming Handwriting\nIn this paper we present a language independent global method for…",
            "…text lines is a major prerequisite procedure for various document image analysis tasks, such as word spotting, key-word searching, and text alignment (Asi et al., 2011; Rath and Manmatha, 2003; Rath et al., 2004; Kornfield et al., 2004; Shi et al., 2005; Li et al., 2008; Saabni and El-Sana,\n2008)."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text extraction from gray scale historical document images using adaptive local connectivity map",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1800513",
                "name": "Srirangaraj Setlur"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10834729,
          "isinfluential": false,
          "contexts": [
            "Pursuant to these limitations, the global\nprojection profile technique was modified to be employed in an adaptive manner; i.e., instead of the entire text line, adaptive fractions are used to compute the projection profile (Zahour et al., 2007; Arivazhagan et al., 2007; Yosef et al., 2009)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A statistical approach to line segmentation in handwritten documents",
            "abstract": "",
            "year": 2007,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "2066310463",
                "name": "M. Arivazhagan"
              },
              {
                "authorId": "2334238",
                "name": "H. Srinivasan"
              },
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12534822,
          "isinfluential": false,
          "contexts": [
            "Projection profile has been widely used for text line extraction (Hashemi et al., 1995; Manmatha and Rothfeder, 2005; Pavlidis\nrent seams, (c) finding the seam with minimal energy cost, and (d) extracting the\nand Zhou, 1991).",
            "Extracting unconstrained handwritten text lines from document images is a basic procedure for various document processing applications and it has received enormous attention over the last several decades."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A scale space approach for automatically segmenting words from historical handwritten documents",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              },
              {
                "authorId": "1845217",
                "name": "Jamie L. Rothfeder"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14210437,
          "isinfluential": false,
          "contexts": [
            "The Hough transform methodology was exploited for text line segmentation (Likforman-Sulem et al., 1995; Louloudis et al., 2006; Louloudis et al., 2008).",
            "They may cause the Hough transform-based approaches (Likforman-Sulem et al., 1995; Louloudis et al., 2006; Louloudis et al., 2008) to fail in determining text lines mainly because these approaches consider as equally important a whole word and a small stroke in the Hough domain."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "A Block-Based Hough Transform Mapping for Text Line Detection in Handwritten Documents",
            "abstract": "In this paper, we present a new text line detection method for unconstrained handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes preprocessing for image enhancement, connected component extraction and average character height estimation. In the second step, a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible false alarms. The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "70602633",
                "name": "K. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15181078,
          "isinfluential": false,
          "contexts": [
            "…text lines is a major prerequisite procedure for various document image analysis tasks, such as word spotting, key-word searching, and text alignment (Asi et al., 2011; Rath and Manmatha, 2003; Rath et al., 2004; Kornfield et al., 2004; Shi et al., 2005; Li et al., 2008; Saabni and El-Sana,\n2008).",
            "Document image segmentation into text lines is a major prerequisite procedure for various document image analysis tasks, such as word spotting, key-word searching, and text alignment (Asi et al., 2011; Rath and Manmatha, 2003; Rath et al., 2004; Kornfield et al., 2004; Shi et al., 2005; Li et al., 2008; Saabni and El-Sana, 2008)."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text alignment with handwritten documents",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "2711577",
                "name": "E. Kornfield"
              },
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              },
              {
                "authorId": "144890574",
                "name": "James Allan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15257932,
          "isinfluential": true,
          "contexts": [
            "Therefore, we have evaluated the two algorithms differently.\nin Nicolaou and Gatos (2009)(the first Column) and the system presented in Shi et al. (2009)(the second Column).",
            "Hybrid schemes combine techniques from top-down and bottom-up classes to yield better results.",
            "It is common to utilize connected component labeling to count the number of misclassified components within the extracted lines (Shi et al., 2009) and we chose to adopt this scheme.",
            "We have adopted the methodology of evaluation used by Shi et al. (2009), which is based on counting the number of the correctly-classified and misclassified components.",
            "In the same manner, adaptive local connectivity map technique was presented by Shi et al. (2009), where steerable direction filter is used to reveal text line patterns."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition A Steerable Directional Local Profile Technique for Extraction of Handwritten Arabic Text Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 15921038,
          "isinfluential": false,
          "contexts": [
            "Image smearing was among the earliest approaches used to determine text lines; Wong et al. (1982) applied image smearing to binarized printed document images.",
            "Smearing and grouping approaches (Wong et al., 1982; Yosef et al., 2009; OGorman, 1993) may connect dots with some strokes generating new connected components that may be segmented later as a text line."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Document Analysis System",
            "abstract": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included.",
            "year": 1982,
            "venue": "IBM Journal of Research and Development",
            "authors": [
              {
                "authorId": "145470231",
                "name": "Kwan Y. Wong"
              },
              {
                "authorId": "34896449",
                "name": "R. Casey"
              },
              {
                "authorId": "1880661",
                "name": "F. Wahl"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15926594,
          "isinfluential": false,
          "contexts": [
            "Bukhari et al. (2009) apply a filter bank to smooth the input text image.",
            "Some other methods use Level-set techniques for line\nextraction (Li et al., 2008; Bukhari et al., 2009).",
            "Hybrid schemes combine techniques from top-down and bottom-up classes to yield better results."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Script-Independent Handwritten Textlines Segmentation using Active Contours",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 16669882,
          "isinfluential": false,
          "contexts": [
            "Various approaches rely on grouping techniques to determine text line in document images, by applying heuristic rules (Likforman-Sulem and Faure, 1994), learning algorithms (Pu and Shi, 1998), nearest neighbor (OGorman, 1993), and searching trees (Nicolas et al., 2004).",
            "Proximity, similarity, and direction continuity were also used to iteratively construct lines by grouping neighboring connected components (Likforman-Sulem and Faure, 1994).",
            "Various approaches rely on grouping techniques to determine text line in document images, by applying heuristic rules (Likforman-Sulem and Faure, 1994), learning algorithms (Pu and Shi, 1998), nearest neighbor (OGorman, 1993), and searching trees"
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Hough based algorithm for extracting text lines in handwritten documents",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "1409083785",
                "name": "Anahid Hanimyan"
              },
              {
                "authorId": "38138508",
                "name": "C. Faure"
              }
            ]
          }
        },
        {
          "citedcorpusid": 23399574,
          "isinfluential": false,
          "contexts": [
            "Koichi et al. (1998) combine heuristic rules and the Voronoi diagrams to merge connected components into text lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Page Images Using the Area Voronoi Diagram",
            "abstract": "This paper presents a method of page segmentation based on the approximated area Voronoi diagram. The characteristics of the proposed method are as follows: (1) The Voronoi diagram enables us to obtain the candidates of boundaries of document components from page images with non-Manhattan layout and a skew. (2) The candidates are utilized to estimate the intercharacter and interline gaps without the use of domain-specific parameters to select the boundaries. From the experimental results for 128 images with non-Manhattan layout and the skew of 0°~45° as well as 98 images with Manhattan layout, we have confirmed that the method is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis.",
            "year": 1998,
            "venue": "Computer Vision and Image Understanding",
            "authors": [
              {
                "authorId": "3277321",
                "name": "K. Kise"
              },
              {
                "authorId": "2064863306",
                "name": "A. Sato"
              },
              {
                "authorId": "40411993",
                "name": "M. Iwata"
              }
            ]
          }
        },
        {
          "citedcorpusid": 43027422,
          "isinfluential": false,
          "contexts": [
            "The Hough transform methodology was exploited for text line segmentation (Likforman-Sulem et al., 1995; Louloudis et al., 2006; Louloudis et al., 2008).",
            "They may cause the Hough transform-based approaches (Likforman-Sulem et al., 1995; Louloudis et al., 2006; Louloudis et al., 2008) to fail in determining text lines mainly because these approaches consider as equally important a whole word and a small stroke in the Hough domain."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Text line detection in handwritten documents",
            "abstract": "",
            "year": 2008,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 45222320,
          "isinfluential": false,
          "contexts": [
            "Projection profile has been widely used for text line extraction (Hashemi et al., 1995; Manmatha and Rothfeder, 2005; Pavlidis\nrent seams, (c) finding the seam with minimal energy cost, and (d) extracting the\nand Zhou, 1991).",
            "Extracting unconstrained handwritten text lines from document images is a basic procedure for various document processing applications and it has received enormous attention over the last several decades."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Persian cursive script recognition",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "143879523",
                "name": "M. Hashemi"
              },
              {
                "authorId": "50500504",
                "name": "O. Fatemi"
              },
              {
                "authorId": "7175485",
                "name": "R. Safavi"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "A dynamic programming based approach, was presented by Liwicki et al. (2007) for on-line text line segmentation, and adapted by Fischer et al. (2010) for historical documents."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "adapted to work on sub-blocks and stripes (Pavlidis and Zhou, 1991; Nagy et al., 1986; Vladimir et al., 1993; He and Downton, 2003) (see Section 2).",
            "Projection profile, which was initially used to determine text lines in printed image documents, was modified and\nadapted to work on sub-blocks and stripes (Pavlidis and Zhou, 1991; Nagy et al., 1986; Vladimir et al., 1993; He and Downton, 2003) (see Section 2)."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "204968037": {
      "citing_paper_info": {
        "title": "An adaptive threshold algorithm for offline Uyghur handwritten text line segmentation",
        "abstract": "",
        "year": 2019,
        "venue": "Wireless networks",
        "authors": [
          {
            "authorId": "1390128127",
            "name": "Eliyas Suleyman"
          },
          {
            "authorId": "71470116",
            "name": "Palidan Tuerxun"
          },
          {
            "authorId": "52378581",
            "name": "Kamil Moydin"
          },
          {
            "authorId": "50075755",
            "name": "A. Hamdulla"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 2,
        "unique_cited_count": 2,
        "influential_count": 0,
        "detailed_records_count": 2
      },
      "cited_papers": [
        "212646817",
        "8603144"
      ],
      "citation_details": [
        {
          "citedcorpusid": 8603144,
          "isinfluential": false,
          "contexts": [
            "Unlike machine printed documents [6], due to high diversity in writing habits of different writers, distances within text lines are irregular and existence of touching and overlapping text lines makes this work challenging."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Language-Independent Text Lines Extraction Using Seam Carving",
            "abstract": "",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1741845",
                "name": "Raid Saabni"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 212646817,
          "isinfluential": false,
          "contexts": [
            "Preprocessing technique aims to eliminate and minimize harmful or insignificant content and enhance useful features in images, especially for document images [13]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Rethinking Behaviors and Activities of Base Stations in Mobile Cellular Networks Based on Big Data Analysis",
            "abstract": "This paper uses big data technologies to study base stations’ behaviors and activities and their predictability in mobile cellular networks. With new technologies quickly appearing, current cellular networks have become more larger, more heterogeneous, and more complex. This provides network managements and designs with larger challenges. How to use network big data to capture cellular network behavior and activity patterns and perform accurate predictions is recently one of main problems. To the end, first we exploit big data platform and technologies to analyze cellular network big data, i.e., Call Detail Records (CDRs). Our CDRs data set, which includes more than 1,000 cellular towers, more than million lines of CDRs, and several million users and sustains for more than 100 days, is collected from a national cellular network. Second, we propose our methodology to analyze these big data. The data pre-handling and cleaning approach is proposed to obtain the valuable big data sets for our further studies. The feature extraction and call predictability methods are presented to capture base stations’ behaviors and dissect their predictability. Third, based on our method, we perform the detailed activity pattern analysis, including call distributions, cross correlation features, call behavior patterns, and daily activities. The detailed analysis approaches are also proposed to dig out base stations’ activities. A series of findings are found and observed in the analysis process. Finally, a study case is proposed to validate the predictability of base stations’ behaviors and activities. Our studies demonstrates that big data technologies can indeed be utilized to effectively capture network behaviors and predict network activities so that they can help perform highly effective network managements.",
            "year": 2020,
            "venue": "IEEE Transactions on Network Science and Engineering",
            "authors": [
              {
                "authorId": "33367477",
                "name": "Dingde Jiang"
              },
              {
                "authorId": "24336113",
                "name": "Liuwei Huo"
              },
              {
                "authorId": "29907659",
                "name": "Houbing Song"
              }
            ]
          }
        }
      ]
    },
    "10130572": {
      "citing_paper_info": {
        "title": "Text line segmentation in handwritten document using a production system",
        "abstract": "",
        "year": 2004,
        "venue": "Ninth International Workshop on Frontiers in Handwriting Recognition",
        "authors": [
          {
            "authorId": "97014121",
            "name": "Stéphane Nicolas"
          },
          {
            "authorId": "1690399",
            "name": "T. Paquet"
          },
          {
            "authorId": "1804638",
            "name": "L. Heutte"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 0,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "5453548",
        "42681590",
        "10143316",
        "20370792",
        "192949611"
      ],
      "citation_details": [
        {
          "citedcorpusid": 5453548,
          "isinfluential": false,
          "contexts": [
            "Among the most popular ones, we can cite Kise's method based on area Voronoi diagram, O'Gorman's Docstrum method based on neighbor clustering and Nagy's X-Y cut based on the analysis of projection profiles (see [2] for an overview)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Empirical Performance Evaluation Methodology and Its Application to Page Segmentation Algorithms",
            "abstract": "While numerous page segmentation algorithms have been proposed in the literature, there is lack of comparative evaluation of these algorithms. In the existing performance evaluation methods, two crucial components are usually missing: 1) automatic training of algorithms with free parameters and 2) statistical and error analysis of experimental results. We use the following five-step methodology to quantitatively compare the performance of page segmentation algorithms: 1) first, we create mutually exclusive training and test data sets with groundtruth, 2) we then select a meaningful and computable performance metric, 3) an optimization procedure is then used to search automatically for the optimal parameter values of the segmentation algorithms on the training data set, 4) the segmentation algorithms are then evaluated on the test data set, and, finally, 5) a statistical and error analysis is performed to give the statistical significance of the experimental results. In particular, instead of the ad hoc and manual approach typically used in the literature for training algorithms, we pose the automatic training of algorithms as an optimization problem and use the simplex algorithm to search for the optimal parameter value. A paired-model statistical analysis and an error analysis are then conducted to provide confidence intervals for the experimental results of the algorithms. This methodology is applied to the evaluation of live page segmentation algorithms of which, three are representative research algorithms and the other two are well-known commercial products, on 978 images from the University of Washington III data set. It is found that the performance indices of the Voronoi, Docstrum, and Caere segmentation algorithms are not significantly different from each other, but they are significantly better than that of ScanSoft's segmentation algorithm, which, in turn, is significantly better than that of X-Y cut.",
            "year": 2001,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "145695526",
                "name": "Song Mao"
              },
              {
                "authorId": "143626870",
                "name": "T. Kanungo"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10143316,
          "isinfluential": false,
          "contexts": [
            "This value is expressed as an Euclidian distance [9].",
            "The gap measure we have chosen is an Euclidian distance as defined in [9]."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "External word segmentation of off-line handwritten text lines",
            "abstract": "",
            "year": 1994,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1928756",
                "name": "G. Seni"
              },
              {
                "authorId": "2064653407",
                "name": "Edward Cohen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 20370792,
          "isinfluential": false,
          "contexts": [
            "In a production system, the global database is manipulated thanks to some defined operations (the production rules), under the control of a global control strategy (search procedure) [8].",
            "Among them we can cite: the Bristish Museum procedure, the Branch and Bound method, or A* algorithm [8]."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Principles of Artificial Intelligence",
            "abstract": "",
            "year": 1980,
            "venue": "Symbolic computation",
            "authors": [
              {
                "authorId": "144497046",
                "name": "N. Nilsson"
              }
            ]
          }
        },
        {
          "citedcorpusid": 42681590,
          "isinfluential": false,
          "contexts": [
            "A method based on a shortest spanning tree search is presented in [4]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line extraction and stroke ordering of text pages",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2235748489",
                "name": "Isi Abuhaiba"
              },
              {
                "authorId": "52511272",
                "name": "S. Datta"
              },
              {
                "authorId": "2250892765",
                "name": "Mjj Holt"
              }
            ]
          }
        },
        {
          "citedcorpusid": 192949611,
          "isinfluential": false,
          "contexts": [
            "Andre [1], a manuscript is a text with graphical interest."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Traitement mixte image/texte de documents anciens",
            "abstract": "Nous nous interessons aux (( textes a interet graphique )) qui sont des documents (par exemple les manuscrits anciens) que l’on etudie tant pour le fond que pour la forme. Les mettre sous forme electronique necessite de les manipuler a la fois comme du texte et comme des images. La notion de (( zone sensible )) dans des images (en HTML par exemple) permet une premiere approche mais est insuffisante pour manipuler electroniquement des documents anciens de facon professionnelle.",
            "year": 1995,
            "venue": "",
            "authors": [
              {
                "authorId": "113582785",
                "name": "J. André"
              },
              {
                "authorId": "144381703",
                "name": "Jean-Daniel Fekete"
              },
              {
                "authorId": "2898698",
                "name": "H. Richy"
              }
            ]
          }
        }
      ]
    },
    "33748389": {
      "citing_paper_info": {
        "title": "A two-stage method for text line detection in historical documents",
        "abstract": "This work presents a two-stage text line detection method for historical documents. Each detected text line is represented by its baseline. In a first stage, a deep neural network called ARU-Net labels pixels to belong to one of the three classes: baseline, separator and other. The separator class marks beginning and end of each text line. The ARU-Net is trainable from scratch with manageably few manually annotated example images (<50\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$<\\,50$$\\end{document}). This is achieved by utilizing data augmentation strategies. The network predictions are used as input for the second stage which performs a bottom-up clustering to build baselines. The developed method is capable of handling complex layouts as well as curved and arbitrarily oriented text lines. It substantially outperforms current state-of-the-art approaches. For example, for the complex track of the cBAD: ICDAR2017 Competition on Baseline Detection the F value is increased from 0.859 to 0.922. The framework to train and run the ARU-Net is open source.",
        "year": 2018,
        "venue": "International Journal on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "40585315",
            "name": "Tobias Grüning"
          },
          {
            "authorId": "1680083",
            "name": "Gundram Leifert"
          },
          {
            "authorId": "40508719",
            "name": "Tobias Strauß"
          },
          {
            "authorId": "88739357",
            "name": "Johannes Michael"
          },
          {
            "authorId": "1736181",
            "name": "R. Labahn"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 20,
        "unique_cited_count": 20,
        "influential_count": 5,
        "detailed_records_count": 20
      },
      "cited_papers": [
        "9731718",
        "29394502",
        "122794245",
        "151380665",
        "336802",
        "6253771",
        "1889158",
        "11057710",
        "5987534",
        "4659176",
        "19363314",
        "3719281",
        "4706555",
        "49417857",
        "1913486",
        "5575601",
        "3074096",
        "195711868",
        "206594692",
        "62066269"
      ],
      "citation_details": [
        {
          "citedcorpusid": 336802,
          "isinfluential": false,
          "contexts": [
            ", bounding boxes [15], x-height areas [16] or more precise polygonal representations following all ascenders and descenders [7], there is not the one correct text line representation."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "PHOCNet: A Deep Convolutional Neural Network for Word Spotting in Handwritten Documents",
            "abstract": "In recent years, deep convolutional neural networks have achieved state of the art performance in various computer vision tasks such as classification, detection or segmentation. Due to their outstanding performance, CNNs are more and more used in the field of document image analysis as well. In this work, we present a CNN architecture that is trained with the recently proposed PHOC representation. We show empirically that our CNN architecture is able to outperform state-of-the-art results for various word spotting benchmarks while exhibiting short training and test times.",
            "year": 2016,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2596925",
                "name": "Sebastian Sudholt"
              },
              {
                "authorId": "1749475",
                "name": "G. Fink"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1889158,
          "isinfluential": true,
          "contexts": [
            "al clustering. Besides these \\classical&quot; approaches, which are based on image processing techniques, methods based on machine learning gained importance within the last two years. Moysset et al. [34] propose a method based on a recurrent neural network. The network is trained given only the number of lines in the image utilizing Connectionist Temporal Classication which was introduced to train n",
            "267 19:00 IA-2 5655 407 6032 102 14:51 A2iA-3† 6523 2490 2263 181 13:20 SNU[32] 7741 948 2700 25 9:77 [33] 8015 517 2860 21 8:19 ours 9610 358 1942 83 5:39 † According to [28] this is an extension of [34]. Table 4.5 Results for the ICDAR2017 Competition on Layout Analysis for Challenging Medieval Manuscripts { The F-values for Task 2 of all participants and the proposed method are shown for the diere"
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Paragraph text segmentation into lines with Recurrent Neural Networks",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "144899680",
                "name": "Christian Wolf"
              },
              {
                "authorId": "2373952",
                "name": "J. Louradour"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1913486,
          "isinfluential": false,
          "contexts": [
            "Typically, layout analysis algorithms directly work on the input image I or on a binarized version of it [17,23, 29,30,31,33].",
            "In [17,29,30], the principle of Dynamic Programming is utilized to calculate cost optimal paths passing the image from left to right to separate different text lines from each other."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 3074096,
          "isinfluential": false,
          "contexts": [
            "Since the introduction of these is beyond the scope of this work, we refer to [40]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Deep Learning",
            "abstract": "Machine-learning technology powers many aspects of modern society: from web searches to content filtering on social networks to recommendations on e-commerce websites, and it is increasingly present in consumer products such as cameras and smartphones. Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items, posts or products with users’ interests, and select relevant results of search. Increasingly, these applications make use of a class of techniques called deep learning. Conventional machine-learning techniques were limited in their ability to process natural data in their raw form. For decades, constructing a pattern-recognition or machine-learning system required careful engineering and considerable domain expertise to design a feature extractor that transformed the raw data (such as the pixel values of an image) into a suitable internal representation or feature vector from which the learning subsystem, often a classifier, could detect or classify patterns in the input. Representation learning is a set of methods that allows a machine to be fed with raw data and to automatically discover the representations needed for detection or classification. Deep-learning methods are representation-learning methods with multiple levels of representation, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level. With the composition of enough such transformations, very complex functions can be learned. For classification tasks, higher layers of representation amplify aspects of the input that are important for discrimination and suppress irrelevant variations. An image, for example, comes in the form of an array of pixel values, and the learned features in the first layer of representation typically represent the presence or absence of edges at particular orientations and locations in the image. The second layer typically detects motifs by spotting particular arrangements of edges, regardless of small variations in the edge positions. The third layer may assemble motifs into larger combinations that correspond to parts of familiar objects, and subsequent layers would detect objects as combinations of these parts. The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure. Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years. It has turned out to be very good at discovering intricate structures in high-dimensional data and is therefore applicable to many domains of science, business and government. In addition to beating records in image recognition and speech recognition, it has beaten other machine-learning techniques at predicting the activity of potential drug molecules, analysing particle accelerator data, reconstructing brain circuits, and predicting the effects of mutations in non-coding DNA on gene expression and disease. Perhaps more surprisingly, deep learning has produced extremely promising results for various tasks in natural language understanding, particularly topic classification, sentiment analysis, question answering and language translation. We think that deep learning will have many more successes in the near future because it requires very little engineering by hand, so it can easily take advantage of increases in the amount of available computation and data. New learning algorithms and architectures that are currently being developed for deep neural networks will only accelerate this progress.",
            "year": 2015,
            "venue": "",
            "authors": [
              {
                "authorId": "1688882",
                "name": "Yann LeCun"
              },
              {
                "authorId": "1751762",
                "name": "Yoshua Bengio"
              },
              {
                "authorId": "1695689",
                "name": "Geoffrey E. Hinton"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3719281,
          "isinfluential": true,
          "contexts": [
            "a certain class to each pixel like in [21,40,41].",
            "Remarkably, in contrast to the U-Net proposed in [21], we perform border padding.",
            "The U-Net proposed in [21] furthermore introduces shortcuts between layers of the same spatial dimension.",
            "We propose an extension of the U-Net [21], the so-called ARUNet."
          ],
          "intents": [
            "['background']",
            "['result']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
            "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .",
            "year": 2015,
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "authors": [
              {
                "authorId": "1737326",
                "name": "O. Ronneberger"
              },
              {
                "authorId": "152702479",
                "name": "P. Fischer"
              },
              {
                "authorId": "1710872",
                "name": "T. Brox"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4659176,
          "isinfluential": true,
          "contexts": [
            "ndom ane transformation (three corner points of the image are randomly shifted within a circle of diameter 0:025 max(I h;I w) around there original position) { S + A 4.S + A + elastic transformation [49] { S + A + E For the test set the images were sub-sampled by the constant factor of 3 in all scenarios. The results of these 180 experiments are shown in Fig. 4.1. One can see that all 3 data augmenta"
          ],
          "intents": [
            "['result']"
          ],
          "cited_paper_info": {
            "title": "Best practices for convolutional neural networks applied to visual document analysis",
            "abstract": "",
            "year": 2003,
            "venue": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "2812486",
                "name": "Patrice Y. Simard"
              },
              {
                "authorId": "38767254",
                "name": "David Steinkraus"
              },
              {
                "authorId": "144189092",
                "name": "John C. Platt"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4706555,
          "isinfluential": false,
          "contexts": [
            "the statistical significance of the posed superiority of the newly introduced architecture, we follow [47] and provide the results of a statistical analysis."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Are Multidimensional Recurrent Layers Really Necessary for Handwritten Text Recognition?",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1794202",
                "name": "J. Puigcerver"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5575601,
          "isinfluential": false,
          "contexts": [
            "Additionally, error propagation for deep structures is facilitated and the so-called vanishing gradient problems [45] are reduced."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Understanding the difficulty of training deep feedforward neural networks",
            "abstract": "Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert & Weston, 2008; Mnih & Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a “better” basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact).",
            "year": 2010,
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "authors": [
              {
                "authorId": "3119801",
                "name": "Xavier Glorot"
              },
              {
                "authorId": "1751762",
                "name": "Yoshua Bengio"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5987534,
          "isinfluential": false,
          "contexts": [
            "he document analysis community within the last years. Such techniques were recently used to solve several dierent problems such as binarization [18], page boundary extraction [19], page segmentation [20] or text line detection [16]. The presented work to our knowledge is the rst which uses a two-stage method, combining deep learning strategies and stateof-the-art image processing based techniques. We"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Convolutional Neural Networks for Page Segmentation of Historical Document Images",
            "abstract": "This paper presents a page segmentation method for handwritten historical document images based on a Convolutional Neural Network (CNN). We consider page segmentation as a pixel labeling problem, i.e., each pixel is classified as one of the predefined classes. Traditional methods in this area rely on hand-crafted features carefully tuned considering prior knowledge. In contrast, we propose to learn features from raw image pixels using a CNN. While many researchers focus on developing deep CNN architectures to solve different problems, we train a simple CNN with only one convolution layer. We show that the simple architecture achieves competitive results against other deep architectures on different public datasets. Experiments also demonstrate the effectiveness and superiority of the proposed method compared to previous methods.",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "153819461",
                "name": "Kai Chen"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6253771,
          "isinfluential": true,
          "contexts": [
            "This work is based on previous work of [23,33], but adapted to the characteristics of SPs extracted given the ARU-Net output, e.",
            "This approach utilizes so-called states of superpixels [23], which encode local text orientation and interline distances.",
            "Basically, assumption (I) claims that a baseline can be approximated by a polynomial function of a certain degree, see [23].",
            "Typically, layout analysis algorithms directly work on the input image I or on a binarized version of it [17,23, 29,30,31,33].",
            "[23] propose an algorithm which uses certain characteristics (so-called states) of extracted connected components to assign costs to certain clustering results."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Language-Independent Text-Line Extraction Algorithm for Handwritten Documents",
            "abstract": "",
            "year": 2014,
            "venue": "IEEE Signal Processing Letters",
            "authors": [
              {
                "authorId": "2189947",
                "name": "Jewoong Ryu"
              },
              {
                "authorId": "2463454",
                "name": "H. Koo"
              },
              {
                "authorId": "2287480732",
                "name": "Nam Ik Cho"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9731718,
          "isinfluential": false,
          "contexts": [
            "ly annotating volumes [2], it is subject to current research and scientic discussion how to automate this process [3]. Since 2009, tremendous progress in the eld of Automated Text Recognition1 (ATR) [4,5] as well as Keyword Spotting (KWS) [6,7,8] was achieved. The performance of state-of-the-art systems reaches character error rates below 10% for ATR [9] and mean average precisions above 0:9 for KWS [",
            "llowing one of the four strategies: 1.subsampled by a constant factor of 3 (no further data augmentation - one training sample per element of the training set) { B 2.randomly subsampled by a factor s2[2;5] { S 3.S + random ane transformation (three corner points of the image are randomly shifted within a circle of diameter 0:025 max(I h;I w) around there original position) { S + A 4.S + A + elastic tr"
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Cells in Multidimensional Recurrent Neural Networks",
            "abstract": "The transcription of handwritten text on images is one task in machine learning and one solution to solve it is using multi-dimensional recurrent neural networks (MDRNN) with connectionist temporal classification (CTC). The RNNs can contain special units, the long short-term memory (LSTM) cells. They are able to learn long term dependencies but they get unstable when the dimension is chosen greater than one. We defined some useful and necessary properties for the one-dimensional LSTM cell and extend them in the multi-dimensional case. Thereby we introduce several new cells with better stability. We present a method to design cells using the theory of linear shift invariant systems. The new cells are compared to the LSTM cell on the IFN/ENIT and Rimes database, where we can improve the recognition rate compared to the LSTM cell. So each application where the LSTM cells in MDRNNs are used could be improved by substituting them by the new developed cells.",
            "year": 2014,
            "venue": "Journal of machine learning research",
            "authors": [
              {
                "authorId": "1680083",
                "name": "Gundram Leifert"
              },
              {
                "authorId": "40508719",
                "name": "Tobias Strauß"
              },
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "1736181",
                "name": "R. Labahn"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11057710,
          "isinfluential": false,
          "contexts": [
            ", histogram approaches to estimate the xheight [16] or by utilizing Dynamic Programming to calculate separating seams [17] However, this is not within the scope of this work.",
            "Typically, layout analysis algorithms directly work on the input image I or on a binarized version of it [17,23, 29,30,31,33].",
            "In [17,29,30], the principle of Dynamic Programming is utilized to calculate cost optimal paths passing the image from left to right to separate different text lines from each other."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Seam Carving for Text Line Extraction on Color and Grayscale Historical Manuscripts",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2965236",
                "name": "Nikolaos Arvanitopoulos"
              },
              {
                "authorId": "1735035",
                "name": "S. Süsstrunk"
              }
            ]
          }
        },
        {
          "citedcorpusid": 19363314,
          "isinfluential": false,
          "contexts": [
            "4 Origing Point (OP) detection results for the ANDAR-TL test set – Results for the dataset of [14] are shown.",
            "The results achieved by state-of-the-art approaches are not satisfying [14], especially if dealing with heterogeneous data.",
            "We have chosen the 3 most recent competitions on text line detection for historical documents, namely: ICDAR 2015 competition on text line detection in historical documents [14], ICDAR2017 Competition on Layout Analysis for Challenging Medieval Manuscripts (Task 2) [53] and cBAD: ICDAR2017 Competition on Baseline Detection [36]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ICDAR 2015 competition on text line detection in historical documents",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40474413",
                "name": "Michael Murdock"
              },
              {
                "authorId": "27437299",
                "name": "S. Reid"
              },
              {
                "authorId": "2067534881",
                "name": "Blaine Hamilton"
              },
              {
                "authorId": "48163297",
                "name": "J. Reese"
              }
            ]
          }
        },
        {
          "citedcorpusid": 29394502,
          "isinfluential": false,
          "contexts": [
            "In follow-up works, they formulated the problem as a regression problem [35, 36]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Learning Text-Line Localization with Shared and Local Regression Neural Networks",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2373952",
                "name": "J. Louradour"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "144899680",
                "name": "Christian Wolf"
              }
            ]
          }
        },
        {
          "citedcorpusid": 49417857,
          "isinfluential": false,
          "contexts": [
            ", the methods presented in [16,37,38,39] tackle the problem of baseline detection with fully convolutional neural networks."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Baseline Detection in Historical Documents Using Convolutional U-Nets",
            "abstract": "Baseline detection is still a challenging task for heterogeneous collections of historical documents. We present a novel approach to baseline extraction in such settings, turning out the winning entry to the ICDAR 2017 Competition on Baseline detection (cBAD). It utilizes deep convolutional nets (CNNs) for both, the actual extraction of baselines, as well as for a simple form of layout analysis in a pre-processing step. To the best of our knowledge it is the first CNN-based system for baseline extraction applying a U-net architecture and sliding window detection, profiting from a high local accuracy of the candidate lines extracted. Final baseline post-processing complements our approach, compensating for inaccuracies mainly due to missing context information during sliding window detection. We experimentally evaluate the components of our system individually on the cBAD dataset. Moreover, we investigate how it generalizes to different data by means of the dataset used for the baseline extraction task of the ICDAR 2017 Competition on Layout Analysis for Challenging Medieval Manuscripts (HisDoc). A comparison with the results reported for HisDoc shows that it also outperforms the contestants of the latter.",
            "year": 2018,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "2105534484",
                "name": "Michael Fink"
              },
              {
                "authorId": "47837360",
                "name": "T. Layer"
              },
              {
                "authorId": "51011459",
                "name": "Georg Mackenbrock"
              },
              {
                "authorId": "50877255",
                "name": "M. Sprinzl"
              }
            ]
          }
        },
        {
          "citedcorpusid": 62066269,
          "isinfluential": false,
          "contexts": [
            "The morphological skeleton Bs = SKE(Bb) is calculated for Bb following Lantuéjoul’s formula [44]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Image Analysis and Mathematical Morphology",
            "abstract": "",
            "year": 1983,
            "venue": "",
            "authors": [
              {
                "authorId": "1684149",
                "name": "J. Serra"
              }
            ]
          }
        },
        {
          "citedcorpusid": 122794245,
          "isinfluential": false,
          "contexts": [
            "We utilize 95% confidence intervals (CI) provided by non-parametric bootstrapping [51] as well as the Tukey-Duckworth test (level of significance: 5%) [52]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Better Bootstrap Confidence Intervals",
            "abstract": "Abstract We consider the problem of setting approximate confidence intervals for a single parameter θ in a multiparameter family. The standard approximate intervals based on maximum likelihood theory, , can be quite misleading. In practice, tricks based on transformations, bias corrections, and so forth, are often used to improve their accuracy. The bootstrap confidence intervals discussed in this article automatically incorporate such tricks without requiring the statistician to think them through for each new application, at the price of a considerable increase in computational effort. The new intervals incorporate an improvement over previously suggested methods, which results in second-order correctness in a wide variety of problems. In addition to parametric families, bootstrap intervals are also developed for nonparametric situations.",
            "year": 1987,
            "venue": "",
            "authors": [
              {
                "authorId": "2550392",
                "name": "B. Efron"
              }
            ]
          }
        },
        {
          "citedcorpusid": 151380665,
          "isinfluential": false,
          "contexts": [
            "To improve the performance of the NPL on the training set, one can calculate the loss function’s gradient with respect to the model parameters using the wellknown technique of backpropagation [42]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Learning representations by back-propagation errors, nature",
            "abstract": "",
            "year": 1986,
            "venue": "",
            "authors": [
              {
                "authorId": "118969901",
                "name": "D. Rumelhart"
              },
              {
                "authorId": "1695689",
                "name": "Geoffrey E. Hinton"
              },
              {
                "authorId": "145993114",
                "name": "R. William"
              }
            ]
          }
        },
        {
          "citedcorpusid": 195711868,
          "isinfluential": false,
          "contexts": [
            "After years of digitization at an industrial scale to protect and preserve these valuable goods, millions over millions of scanned pages are stored at servers all over the world [1]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Europeana: Moving to Linked Open Data",
            "abstract": "Europeana is the European Union's flagship digital cultural heritage initiative. the europeana portal, launched in November 2008, showcases the possibility of cross-cultural domain interoperability on a pan-european level. To date, metadata and thumbnails for over 23 million objects have been aggregated from over 1500 providers from the library, archive, museum, and audiovisual domains. It was hoped that cultural heritage communities were ready to think outside the traditional information silos and adopt a linked data paradigm that would enable the development of shared semantic context. As a technical starting point, Europeana carried out a linked open data pilot project. This paper gives an outline of the processes of the pilot project and areas for future work.",
            "year": 2012,
            "venue": "",
            "authors": [
              {
                "authorId": "1701529",
                "name": "Antoine Isaac"
              },
              {
                "authorId": "2212614",
                "name": "Robina Clayphan"
              },
              {
                "authorId": "1679379",
                "name": "Bernhard Haslhofer"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206594692,
          "isinfluential": true,
          "contexts": [
            "Hence, the vanishing gradient problems are reduced [22].",
            "[22] introduce very deep neural networks which are still trainable and yield state-of-the-art results.",
            "The fully convolutional U-Net is extended by incorporating residual blocks [22] to increase its representative power."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Deep Residual Learning for Image Recognition",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
            "year": 2015,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "1771551",
                "name": "X. Zhang"
              },
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": null,
                "name": "Jian Sun"
              }
            ]
          }
        }
      ]
    },
    "28662025": {
      "citing_paper_info": {
        "title": "Projection–Based Text Line Segmentation with a Variable Threshold",
        "abstract": "Abstract Document image segmentation into text lines is one of the stages in unconstrained handwritten document recognition. This paper presents a new algorithm for text line separation in handwriting. The developed algorithm is based on a method using the projection profile. It employs thresholding, but the threshold value is variable. This permits determination of low or overlapping peaks of the graph. The proposed technique is shown to improve the recognition rate relative to traditional methods. The algorithm is robust in text line detection with respect to different text line lengths.",
        "year": 2017,
        "venue": "International Journal of Applied Mathematics and Computer Sciences",
        "authors": [
          {
            "authorId": "31739585",
            "name": "R. Ptak"
          },
          {
            "authorId": "10009081",
            "name": "Bartosz Zygadlo"
          },
          {
            "authorId": "1682586",
            "name": "O. Unold"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 16,
        "unique_cited_count": 16,
        "influential_count": 1,
        "detailed_records_count": 16
      },
      "cited_papers": [
        "16358887",
        "1308491",
        "22995244",
        "1413694",
        "8690249",
        "15936873",
        "1383578",
        "15621071",
        "7553535",
        "619938",
        "10207300",
        "3361432",
        "10565704",
        "61696402",
        "2775421",
        "1755700"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "Likforman-Sulem et al. (2007) presented a survey of the methodologies proposed in the literature."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1308491,
          "isinfluential": false,
          "contexts": [
            "A novel “water flow\" text line segmentation method was proposed by Basu et al. (2007)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line extraction from multi-skewed handwritten documents",
            "abstract": "",
            "year": 2008,
            "venue": "Cybersecurity and Cyberforensics Conference",
            "authors": [
              {
                "authorId": "2064966924",
                "name": "Jiang Yong"
              },
              {
                "authorId": "2285625299",
                "name": "Xiaojing Chen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1383578,
          "isinfluential": false,
          "contexts": [
            "To avoid high variance and non-zero bias of cv-based estimators (, 2010), a repeated cross-validation approach (Krstajic et al., 2014) was used."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Cross-validation pitfalls when selecting and assessing regression and classification models",
            "abstract": "BackgroundWe address the problem of selecting and assessing classification and regression models using cross-validation. Current state-of-the-art methods can yield models with high variance, rendering them unsuitable for a number of practical applications including QSAR. In this paper we describe and evaluate best practices which improve reliability and increase confidence in selected models. A key operational component of the proposed methods is cloud computing which enables routine use of previously infeasible approaches.MethodsWe describe in detail an algorithm for repeated grid-search V-fold cross-validation for parameter tuning in classification and regression, and we define a repeated nested cross-validation algorithm for model assessment. As regards variable selection and parameter tuning we define two algorithms (repeated grid-search cross-validation and double cross-validation), and provide arguments for using the repeated grid-search in the general case.ResultsWe show results of our algorithms on seven QSAR datasets. The variation of the prediction performance, which is the result of choosing different splits of the dataset in V-fold cross-validation, needs to be taken into account when selecting and assessing classification and regression models.ConclusionsWe demonstrate the importance of repeating cross-validation when selecting an optimal model, as well as the importance of repeating nested cross-validation when assessing a prediction error.",
            "year": 2014,
            "venue": "Journal of Cheminformatics",
            "authors": [
              {
                "authorId": "3305780",
                "name": "Damjan Krstajic"
              },
              {
                "authorId": "49852539",
                "name": "L. Buturovic"
              },
              {
                "authorId": "37423049",
                "name": "D. Leahy"
              },
              {
                "authorId": "2109721497",
                "name": "Simon Thomas"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1413694,
          "isinfluential": false,
          "contexts": [
            "Furthermore, the following methods may be mentioned: the repulsive-attractive network method (Öztop et al., 1999), the stochastic method (Tseng and Lee, 1999) and a graph-based method (an example is the docstrum method (O’Gorman, 1993))."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Repulsive attractive network for baseline extraction on document images",
            "abstract": "",
            "year": 1997,
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "authors": [
              {
                "authorId": "8222607",
                "name": "Erhan Öztop"
              },
              {
                "authorId": "3049928",
                "name": "Adem Yasar Mülayim"
              },
              {
                "authorId": "1737543",
                "name": "V. Atalay"
              },
              {
                "authorId": "1398326708",
                "name": "F. Yarman-Vural"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1755700,
          "isinfluential": false,
          "contexts": [
            "This scheme has been shown to have good replicability (Bouckaert and Frank, 2004).",
            "According to Nadeau and Bengio (2003), as well as Bouckaert and Frank (2004), the corrected resampled t-test has the type-I error close to the significance level and (opposite to McNemar’s test and the 5-times 2-fold cv test) low type-II error (i.e., the failure to reject a false null hypothesis)."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Evaluating the Replicability of Significance Tests for Comparing Learning Algorithms",
            "abstract": "",
            "year": 2004,
            "venue": "Pacific-Asia Conference on Knowledge Discovery and Data Mining",
            "authors": [
              {
                "authorId": "1680097",
                "name": "R. Bouckaert"
              },
              {
                "authorId": "1767318",
                "name": "E. Frank"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2775421,
          "isinfluential": false,
          "contexts": [
            "This algorithm was extended and further improved (see Brodić and Milivojević, 2011; Brodić, 2012; 2015)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A New Approach to Water Flow Algorithm for Text Line Segmentation",
            "abstract": "This paper proposes a new approach to water flow algorithm for the text line segmentation. Original method assumes hypothetical water flows under a few specified angles to the document image frame from left to right and vice versa. As a result, unwetted image frames are extracted. These areas are of major importance for text line segmentation. Method modifications mean extension values of water flow angle and unwetted image frames function enlargement. Results are encouraging due to text line segmentation improvement which is the most challenging process stage in document image processing.",
            "year": 2011,
            "venue": "Journal of universal computer science (Online)",
            "authors": [
              {
                "authorId": "2008869",
                "name": "D. Brodic"
              },
              {
                "authorId": "2393591",
                "name": "Z. Milivojevic"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3361432,
          "isinfluential": false,
          "contexts": [
            "This technique has been widely used in segmentation for machine printed documents (Ha et al., 1995)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document page decomposition by the bounding-box project",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2122930",
                "name": "J. Ha"
              },
              {
                "authorId": "1710238",
                "name": "R. Haralick"
              },
              {
                "authorId": "1744200",
                "name": "I. T. Phillips"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7553535,
          "isinfluential": true,
          "contexts": [
            "Several methods of relaxing the FWER have been proposed (Romano et al., 2008).",
            "Note that to perform multiple comparisons involving a control method, we are supposed to control the family-wise error (FWER) (Demšar, 2006; Japkowicz and Shah, 2011; Trawiński et al., 2012).",
            "The FWER is the probability of making a type-I error when testing many null hypotheses simultaneously.",
            "Note that to perform multiple comparisons involving a control method, we are supposed to control the family-wise error (FWER) (Demšar, 2006; Japkowicz and Shah, 2011; Trawiński et al., 2012)."
          ],
          "intents": [
            "--",
            "['methodology']",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Statistical Comparisons of Classifiers over Multiple Data Sets",
            "abstract": "While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.",
            "year": 2006,
            "venue": "Journal of machine learning research",
            "authors": [
              {
                "authorId": "2701105",
                "name": "J. Demšar"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8690249,
          "isinfluential": false,
          "contexts": [
            "The score introduced by Yanikoglu and Vincent (1998) is defined as the percentage of the foreground pixels of Gj covered by Ri minus the percentage of the foreground pixels of Ri outside of Gj ,\nMatchScore(i, j) = T (Ri ∩Gj) T (Gj) − T (Ri \\Gj) T (Ri) ,\nwhere T (S) is a function that counts the…"
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Pink Panther: A Complete Environment For Ground-Truthing And Benchmarking Document Page Segmentation",
            "abstract": "",
            "year": 1998,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1757030",
                "name": "B. Yanikoglu"
              },
              {
                "authorId": "1820595",
                "name": "L. Vincent"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10207300,
          "isinfluential": false,
          "contexts": [
            "Marti and Bunke (2001a; 2001b) used a modified method, where the numbers of transitions from background to foreground pixels are counted along horizontal lines through the character image."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Using a Statistical Language Model to Improve the Performance of an HMM-Based Cursive Handwriting Recognition System",
            "abstract": "In this paper, a system for the reading of totally unconstrained handwritten text is presented. The kernel of the system is a hidden Markov model (HMM) for handwriting recognition. The HMM is enhanced by a statistical language model. Thus linguistic knowledge beyond the lexicon level is incorporated in the recognition process. Another novel feature of the system is that the HMM is applied in such a way that the difficult problem of segmenting a line of text into individual words is avoided. A number of experiments with various language models and large vocabularies have been conducted. The language models used in the system were also analytically compared based on their perplexity.",
            "year": 2001,
            "venue": "International journal of pattern recognition and artificial intelligence",
            "authors": [
              {
                "authorId": "37526757",
                "name": "Urs-Viktor Marti"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10565704,
          "isinfluential": false,
          "contexts": [
            "The first phase of the algorithm by dos Santos et al. (2009) is thresholding which requires one parameter: the threshold height (t2) in proportion to the average y-value of the projection profile.",
            "We evaluated the performance of our algorithm on a database of unconstrained handwritten Polish documents and compared it with some projection-based algorithms: the Gaussian filter (Manmatha and Srimal, 1999), the median filter (Lim, 1990), and the Santos approach (dos Santos et al., 2009).",
            "A projection performed profile which results in text\nProjection-based text line segmentation with a variable threshold 197\nline positions (dos Santos et al., 2009)."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Text Line Segmentation Based on Morphology and Histogram Projection",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 15621071,
          "isinfluential": false,
          "contexts": [
            "A method significantly increasing the visibility of some hardly recognisable objects was used by Fabijańska et al. (2014)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Assessment of hydrocephalus in children based on digital image processing and analysis",
            "abstract": "Abstract Hydrocephalus is a pathological condition of the central nervous system which often affects neonates and young children. It manifests itself as an abnormal accumulation of cerebrospinal fluid within the ventricular system of the brain with its subsequent progression. One of the most important diagnostic methods of identifying hydrocephalus is Computer Tomography (CT). The enlarged ventricular system is clearly visible on CT scans. However, the assessment of the disease progress usually relies on the radiologist’s judgment and manual measurements, which are subjective, cumbersome and have limited accuracy. Therefore, this paper regards the problem of semi-automatic assessment of hydrocephalus using image processing and analysis algorithms. In particular, automated determination of popular indices of the disease progress is considered. Algorithms for the detection, semi-automatic segmentation and numerical description of the lesion are proposed. Specifically, the disease progress is determined using shape analysis algorithms. Numerical results provided by the introduced methods are presented and compared with those calculated manually by a radiologist and a trained operator. The comparison proves the correctness of the introduced approach.",
            "year": 2014,
            "venue": "International Journal of Applied Mathematics and Computer Sciences",
            "authors": [
              {
                "authorId": "2036511",
                "name": "A. Fabijańska"
              },
              {
                "authorId": "2894595",
                "name": "T. Weglinski"
              },
              {
                "authorId": "47586960",
                "name": "K. Zakrzewski"
              },
              {
                "authorId": "2749163",
                "name": "E. Nowosławska"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15936873,
          "isinfluential": false,
          "contexts": [
            "This algorithm was extended and further improved (see Brodić and Milivojević, 2011; Brodić, 2012; 2015).",
            "This algorithm was extended and further improved (see Brodić and Milivojević, 2011; Brodić, 2012; 2015)."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Extended Approach to Water Flow Algorithm for Text Line Segmentation",
            "abstract": "",
            "year": 2012,
            "venue": "Journal of Computational Science and Technology",
            "authors": [
              {
                "authorId": "2008869",
                "name": "D. Brodic"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16358887,
          "isinfluential": false,
          "contexts": [
            "The concept of the Hough transform is employed in the field of document analysis for many purposes such as skew and slant detection and text line segmentation (Likforman-Sulem et al., 1995; Louloudis et al., 2008; 2009; Alaei et al., 2011)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Piece-wise painting technique for line segmentation of unconstrained handwritten text: a specific study with Persian text documents",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Analysis and Applications",
            "authors": [
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22995244,
          "isinfluential": false,
          "contexts": [
            "Furthermore, the following methods may be mentioned: the repulsive-attractive network method (Öztop et al., 1999), the stochastic method (Tseng and Lee, 1999) and a graph-based method (an example is the docstrum method (O’Gorman, 1993)).",
            ", 1999), the stochastic method (Tseng and Lee, 1999) and a graph-based method (an example is the docstrum method (O’Gorman, 1993)).",
            "Although algorithms for printed document segmentation have been proposed (O’Gorman, 1993; Hull, 1998), their use in the processing of handwritten documents has been ineffective."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The Document Spectrum for Page Layout Analysis",
            "abstract": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >",
            "year": 1993,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1398550688",
                "name": "L. O'Gorman"
              }
            ]
          }
        },
        {
          "citedcorpusid": 61696402,
          "isinfluential": false,
          "contexts": [
            "This algorithm was extended and further improved (see Brodić and Milivojević, 2011; Brodić, 2012; 2015)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation With Water Flow Algorithm Based on Power Function",
            "abstract": "",
            "year": 2015,
            "venue": "",
            "authors": [
              {
                "authorId": "2008869",
                "name": "D. Brodic"
              }
            ]
          }
        }
      ]
    },
    "18958780": {
      "citing_paper_info": {
        "title": "SOUTH INDIAN TAMIL LANGUAGE HANDWRITTEN DOCUMENT TEXT LINE SEGMENTATION TECHNIQUE WITH AID OF SLIDING WINDOW AND SKEWING OPERATIONS",
        "abstract": "In document image analysis, Text line segmentation is one of the key components. The segmentation logi c presents essential information about skew correctio n, zone segmentation, and character recognition. Th e method of document image segmentation into text lines for printed text has seen numerous contributions from fellow research scholars, yet there is scope f or tremendous improvement. The key challenges for handwritten document are due to writer movement, the inter-line distance changeability and incoherent distance between the components that may differ. These may be directly by segments, or curved. The are a of handwritten segmentation has seen few models; very few of the research paper are proposed for Text line skew segmentation model and hence the stimulus of handwritten south Indian languages. Consequently, a better text line segmentation technique for south I ndian Tamil language is proposed in this paper. The processing of Tamil language is very crucial factor because the Tamil letters are in crucial shapes an d it is harder to segment the touching lines and letters fr om the Tamil image documents. The challenges present in Tamil language process and the existing text line s egmentation methods has been improved by our proposed method, which utilizing two major techniques namely, sliding window and adaptive histogram equalization. Our proposed text line segmentation t echnique initially performs the preprocessing proce ss and these preprocessed document images are given to the adaptive histogram equalization. During the histogram equalization process, the document images text characters are enhanced to view the character s more accurately. The enhanced image text lines are segmented by utilizing the sliding window operation . For accurate line segmentation, the skewing operati on is performed on the line segmented result images . The implementation result shows the effectiveness o f proposed technique, in segmenting the handwritten text lines from the input document. The performance of the proposed technique is evaluated by comparin g the result of proposed technique with the conventio nal text line segmentation technique. The result sh ows that our proposed technique acquires high-quality t ext line segmentation DR, RA and F-Measure values for the number of testing documents in comparison with the conventional technique.",
        "year": 2013,
        "venue": "",
        "authors": [
          {
            "authorId": "9455540",
            "name": "Sunanda Dixit"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 6,
        "influential_count": 0,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "7272464",
        "15032070",
        "15782139",
        "1913486",
        "13396787",
        "13203504"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1913486,
          "isinfluential": false,
          "contexts": [
            "It offers decisive information for skew correction, zone segmentation, and character recognition [1]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 7272464,
          "isinfluential": false,
          "contexts": [
            "[3] Since it is in the commencement of a pipeline o f processing, it is terribly essential to minimize fa ults so that next steps for pipeline get precise input."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A New Algorithm for Detecting Text Line in Handwritten Documents",
            "abstract": "Curvilinear text line detection and segmentation in handwritten documents is a significant challenge for handwriting recognition. Given no prior knowledge of script, we model text line detection as an image segmentation problem by enhancing text line structure using a Gaussian window, and adopting the level set method to evolve text line boundaries. Experiments show that the proposed method achieves high accuracy for detecting text lines in both handwritten and machine printed documents with many scripts.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2053348005",
                "name": "S. Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13203504,
          "isinfluential": false,
          "contexts": [
            "[24] have suggested a method Optical character recognition (OCR) submits to a course of generating a character input by optical means, like scanning, for identification in following steps by which a printe d or handwritten passage."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Skew Detection, Correction and Segmentation of Handwritten Kannada Document",
            "abstract": "Optical character recognition (OCR) refers to a process of generating a character input by optical means, like scanning, for recognition in subsequent stages by which a printed or handwritten text can be converted to a form which a computer can understand and manipulate. A generic character recognition system has different stages like noise removal, skew detection and correction, segmentation, feature extraction and classification. Results of the later stages can affect the performance of the subsequent stages in the OCR process. To make the results of the subsequent stages more accurate, the skew detection and correction and segmentation play an important role. In this paper, we have proposed schemes for skew detection and correction, segmentation of handwritten Kannada document using bounding box technique, Hough transform and contour detection respectively. An average segmentation rate of 91% and 70% for lines and words is obtained respectively.",
            "year": 2012,
            "venue": "",
            "authors": [
              {
                "authorId": "70974442",
                "name": "Mamatha Hosalli Ramappa"
              },
              {
                "authorId": "7662550",
                "name": "S. Krishnamurthy"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13396787,
          "isinfluential": false,
          "contexts": [
            "Thus the line segmentation of unconstrained hand written text is not easy [6]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwritten document image segmentation into text lines and words",
            "abstract": "",
            "year": 2010,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "1799540",
                "name": "Themos Stafylakis"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              },
              {
                "authorId": "143978280",
                "name": "G. Carayannis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15032070,
          "isinfluential": false,
          "contexts": [
            "Manjunath Aradhya et al.[23], there was yet room to develop the identification charge by progressing better feature s.",
            "Multilingual character identification system and their test out performances on standard database has been developed by V. N. Manjunath Aradhya et al.[23], there was yet room to develop the identification charge by progressing better features."
          ],
          "intents": [
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Multilingual OCR system for South Indian scripts and English documents: An approach based on Fourier transform and principal component analysis",
            "abstract": "",
            "year": 2008,
            "venue": "Engineering applications of artificial intelligence",
            "authors": [
              {
                "authorId": "1710382",
                "name": "Manjunath Aradhya"
              },
              {
                "authorId": "144923419",
                "name": "G. Kumar"
              },
              {
                "authorId": "2707426",
                "name": "S. Noushath"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15782139,
          "isinfluential": false,
          "contexts": [
            "Line segmentation can be broadly classified as two kinds: i) Typed text; ii) Handwritten text [5]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "On-Line and Off-Line Handwriting Recognition: A Comprehensive Survey",
            "abstract": "Handwriting has continued to persist as a means of communication and recording information in day-to-day life even with the introduction of new technologies. Given its ubiquity in human transactions, machine recognition of handwriting has practical significance, as in reading handwritten notes in a PDA, in postal addresses on envelopes, in amounts in bank checks, in handwritten fields in forms, etc. This overview describes the nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms. Both the online case (which pertains to the availability of trajectory data during writing) and the off-line case (which pertains to scanned images) are considered. Algorithms for preprocessing, character and word recognition, and performance with practical systems are indicated. Other fields of application, like signature verification, writer authentification, handwriting learning tools are also considered.",
            "year": 2000,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "144586498",
                "name": "R. Plamondon"
              },
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "These 20 text document images are given to the segmentation process and this proposed technique results are compared with the conventional segmentation technique [26]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "66003740": {
      "citing_paper_info": {
        "title": "Text Line Segmentation for Mushaf Al-Quran Using Hybrid Projection Based Neighbouring Properties",
        "abstract": "Text line segmentation is an important step in document image processing. Its part of the pre-processing stage to prepared the images before throughout either feature extraction or classification images. In this paper, we present a method of line segmentation for Mushaf Al-Quran text using a hybrid projection based neighbouring properties. This is based on the pixel, object and histogram properties. This method will identify overlaps between neighbouring text lines and segment each line with precision. Overlap caused by interfering with diacritical marks or stroke of the Arabic word must be properly segmented without change the original meaning of the text. Experimental results show the validity of our method.",
        "year": 2018,
        "venue": "",
        "authors": [
          {
            "authorId": "67298966",
            "name": "Amirul Ramzani Radzid"
          },
          {
            "authorId": "37890319",
            "name": "M. S. Azmi"
          },
          {
            "authorId": "1959188",
            "name": "I. E. A. Jalil"
          },
          {
            "authorId": "9227595",
            "name": "Nur Atikah Arbain"
          },
          {
            "authorId": "49146466",
            "name": "Azrina Tahir"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 7,
        "influential_count": 0,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "2070419",
        "15534800",
        "62421994",
        "9379335",
        "17388229",
        "36363181",
        "15793605"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2070419,
          "isinfluential": false,
          "contexts": [
            "While in 2003, He and Downton [4] used projection (RXY cuts) to segmenting line of Viadocs/Natural history cards."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "User-assisted archive document image analysis for digital library construction",
            "abstract": "",
            "year": 2003,
            "venue": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "2219747383",
                "name": "Jingyu He"
              },
              {
                "authorId": "1798094",
                "name": "A. Downton"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9379335,
          "isinfluential": false,
          "contexts": [
            "This is one of the important steps of Optical Character Recognition (OCR) and keyword spotting [1].",
            "Xi Zhang and Chew Lim Tan [1] proposed line segmentation using constrained seam carving."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation for Handwritten Documents Using Constrained Seam Carving",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2108285825",
                "name": "Xi Zhang"
              },
              {
                "authorId": "1679749",
                "name": "C. Tan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15534800,
          "isinfluential": false,
          "contexts": [
            "Mohd Sanusi Azmi introduced features from triangle geometry for digit recognition of this field [11]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Exploiting features from triangle geometry for digit recognition",
            "abstract": "",
            "year": 2013,
            "venue": "International Conference on Control, Decision and Information Technologies",
            "authors": [
              {
                "authorId": "37890319",
                "name": "M. S. Azmi"
              },
              {
                "authorId": "9391607",
                "name": "M. F. Nasrudin"
              },
              {
                "authorId": "144256107",
                "name": "K. Omar"
              },
              {
                "authorId": "31896773",
                "name": "C. W. Ahmad"
              },
              {
                "authorId": "1854791",
                "name": "K. W. M. Ghazali"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15793605,
          "isinfluential": false,
          "contexts": [
            "In 2004, Antonacopoulos and Karatzast [3] used projection profile for segmenting line of memorial/person record (World war II)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document image analysis for World War II personal records",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              },
              {
                "authorId": "1694974",
                "name": "Dimosthenis Karatzas"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17388229,
          "isinfluential": false,
          "contexts": [
            "Moreover, in 2003, Pal and Datta [5] used piecewise projections for segmenting line for Indian handwritten documents."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Bangla unconstrained handwritten text",
            "abstract": "",
            "year": 2003,
            "venue": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "52511272",
                "name": "S. Datta"
              }
            ]
          }
        },
        {
          "citedcorpusid": 36363181,
          "isinfluential": false,
          "contexts": [
            "Furthermore, in 1993, Shapiro et al [7] used projection profile to skewed separated lines for handwritten documents."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten document image segmentation and analysis",
            "abstract": "",
            "year": 1993,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "145852526",
                "name": "V. Shapiro"
              },
              {
                "authorId": "2329505",
                "name": "G. Gluhchev"
              },
              {
                "authorId": "144088894",
                "name": "V. Sgurev"
              }
            ]
          }
        },
        {
          "citedcorpusid": 62421994,
          "isinfluential": false,
          "contexts": [
            "Thresholding method that is used in this experiment was conducted by using Otsu’s method proposed by Scholar Otsu in 1979 [16]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Review on Otsu Image Segmentation Algorithm",
            "abstract": "Image segmentation is the fundamental approach of digital image processing. Among all the segmentation methods, Otsu method is one of the most successful methods for image thresholding because of its simple calculation. Otsu is an automatic threshold selection region based segmentation method. This paper studies various Otsu algorithms.",
            "year": 2013,
            "venue": "",
            "authors": [
              {
                "authorId": "52313933",
                "name": "Hetal J. Vala"
              },
              {
                "authorId": "30897695",
                "name": "Astha Baxi"
              }
            ]
          }
        }
      ]
    },
    "105842646": {
      "citing_paper_info": {
        "title": "A hybrid text line segmentation approach for the ancient handwritten unconstrained freestyle Modi script documents",
        "abstract": "ABSTRACT In this paper a novel approach for the segmentation of text lines in handwritten, unconstrained, and freestyle Modi script document image is presented. The approach is based on the analysis of the gray level thresholding metric to estimate the text region location. True text line locations are estimated and segmented using the estimated text region location. The connected components of each estimated text region are scrutinized to group and calculate the text line region. The approach is recursively applied on the estimated line segments until the individual text lines are not separated. This algorithm handles various type of documents as multi-skewed, non-uniform Shirorekha, variable size characters or text lines, touching and overlapping line segments therefore it is robust. The algorithm is tested and compared using ancient handwritten Modi script documents and the benchmarking freely available online datasets, respectively.",
        "year": 2018,
        "venue": "Imaging Science Journal",
        "authors": [
          {
            "authorId": "2797934",
            "name": "Manisha S. Deshmukh"
          },
          {
            "authorId": "3080531",
            "name": "M. Patil"
          },
          {
            "authorId": "8920918",
            "name": "S. Kolhe"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 14,
        "unique_cited_count": 13,
        "influential_count": 4,
        "detailed_records_count": 14
      },
      "cited_papers": [
        "2055937",
        "14628048",
        "36389323",
        "12217430",
        "17376493",
        "63189644",
        "18210347",
        "13396787",
        "9187881",
        "63638404",
        "619938",
        "9673364",
        "1610874"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "The Viterbi algorithm-based methods are fail if the contact point contains a lot of black pixels in the touching lines [8].",
            "The horizontal projection pro ﬁ le [11,12,20,21] and connected component-based methods segments the text lines when gaps between lines are signi ﬁ cant [7,8]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1610874,
          "isinfluential": false,
          "contexts": [
            "A system based on fully convolutional network (FCN) is used to predict text line structure in document images is presented by [33]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Dense prediction for text line segmentation in handwritten document images",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Information Photonics",
            "authors": [
              {
                "authorId": "12581289",
                "name": "Q. Vo"
              },
              {
                "authorId": "144096223",
                "name": "Gueesang Lee"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2055937,
          "isinfluential": false,
          "contexts": [
            "These strategies are projection pro ﬁ le [11,12], smearing [9,13], grouping [3], Hough based [14 – 16], graph based [7,17,18], Cut Text Minimization [6,19], and Active Contour [7]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Hough Transform based Technique for Text Segmentation",
            "abstract": "Text segmentation is an inherent part of an OCR system irrespective of the domain of application of it. The OCR system contains a segmentation module where the text lines, words and ultimately the characters must be segmented properly for its successful recognition. The present work implements a Hough transform based technique for line and word segmentation from digitized images. The proposed technique is applied not only on the document image dataset but also on dataset for business card reader system and license plate recognition system. For standardization of the performance of the system the technique is also applied on public domain dataset published in the website by CMATER, Jadavpur University. The document images consist of multi-script printed and hand written text lines with variety in script and line spacing in single document image. The technique performs quite satisfactorily when applied on mobile camera captured business card images with low resolution. The usefulness of the technique is verified by applying it in a commercial project for localization of license plate of vehicles from surveillance camera images by the process of segmentation itself. The accuracy of the technique for word segmentation, as verified experimentally, is 85.7% for document images, 94.6% for business card images and 88% for surveillance camera images.",
            "year": 2010,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "2778425",
                "name": "Satadal Saha"
              },
              {
                "authorId": "145096292",
                "name": "Subhadip Basu"
              },
              {
                "authorId": "1729425",
                "name": "M. Nasipuri"
              },
              {
                "authorId": "143701816",
                "name": "D. K. Basu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": true,
          "contexts": [
            "Horizontal projection pro ﬁ le and fuzzy run-length [22] methods are segment handwritten text lines e ﬃ ciently only when they are straight [5] and dense text lines [14].",
            "The Parzen window-based density estimation hybrid method is presented in [5].",
            "The text line segmentation techniques are categorized into three types: top-down grouping, bottom-up partitioning, and hybrid [5,6].",
            "It cannot deal with the other challenges which include non-text objects such as stamps, logos, and severe noise [5].",
            "The hybrid strategies combine bottom-up and top-down strategies to reduces the limitations of the both and to improve the accuracy of segmentation [5,6]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9673364,
          "isinfluential": false,
          "contexts": [
            "line segmentation techniques are addressed; some provide acceptable results and already joined into working systems [1] ."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation for gray scale historical document images",
            "abstract": "",
            "year": 2011,
            "venue": "The Hip",
            "authors": [
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "1741845",
                "name": "Raid Saabni"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12217430,
          "isinfluential": true,
          "contexts": [
            "degraded or poorly structured documents [7] and to",
            "These strategies are projection pro ﬁ le [11,12], smearing [9,13], grouping [3], Hough based [14 – 16], graph based [7,17,18], Cut Text Minimization [6,19], and Active Contour [7].",
            "These strategies are projection profile [11,12], smearing [9,13], grouping [3], Hough based [14–16], graph based [7,17,18], Cut Text Minimization [6,19], and Active Contour [7].",
            "text lines, touching text lines, fluctuating text lines [7], and handled complex layouts [23].",
            "text lines when gaps between lines are significant [7,8]."
          ],
          "intents": [
            "['background']",
            "--",
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Off-line Handwriting Text Line Segmentation : A Review",
            "abstract": "Summary Text line segmentation is an essential pre-processing stage for off-line handwriting recognition in many Optical Character Recognition (OCR) systems. It is an important step because inaccurately segmented text lines will cause errors in the recognition stage. Text line segmentation of the handwritten documents is still one of the most complicated problems in developing a reliable OCR. The nature of handwriting makes the process of text line segmentation very challenging. Several techniques to segment handwriting text line have been proposed in the past. This paper seeks to provide a comprehensive review of the methods of off-line handwriting text line segmentation proposed by researchers.",
            "year": 2008,
            "venue": "",
            "authors": [
              {
                "authorId": "34325231",
                "name": "N. M. Noor"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13396787,
          "isinfluential": true,
          "contexts": [
            "The method is not e ﬃ cient when characters are broken into many fragments [23].",
            "This framework had segmented dense text lines, touching text lines, ﬂ uctuating text lines [7], and handled complex layouts [23].",
            "The modi ﬁ ed projection-based methods presented in [11,23] can deal with slightly curved text lines [6].",
            "But it is fail on degraded or poorly structured documents [7] and to distinguish touching text lines [23].",
            "The piece wise projection pro ﬁ le with Viterbi approach presented in [23,27] can segment the multi skew, irregular patterns for page margins and touching lines."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten document image segmentation into text lines and words",
            "abstract": "",
            "year": 2010,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "1799540",
                "name": "Themos Stafylakis"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              },
              {
                "authorId": "143978280",
                "name": "G. Carayannis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14628048,
          "isinfluential": false,
          "contexts": [
            "These strategies are projection pro ﬁ le [11,12], smearing [9,13], grouping [3], Hough based [14 – 16], graph based [7,17,18], Cut Text Minimization [6,19], and Active Contour [7]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Arabic text line segmentation using affinity propagation",
            "abstract": "",
            "year": 2010,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "2069634816",
                "name": "J. Kumar"
              },
              {
                "authorId": "1404588675",
                "name": "W. Abd-Almageed"
              },
              {
                "authorId": "145714522",
                "name": "Le Kang"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17376493,
          "isinfluential": false,
          "contexts": [
            "The horizontal projection pro ﬁ le [11,12,20,21] and connected component-based methods segments the text lines when gaps between lines are signi ﬁ cant [7,8].",
            "These strategies are projection pro ﬁ le [11,12], smearing [9,13], grouping [3], Hough based [14 – 16], graph based [7,17,18], Cut Text Minimization [6,19], and Active Contour [7]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Line segmentation for degraded handwritten historical documents",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 18210347,
          "isinfluential": false,
          "contexts": [
            "The horizontal projection profile [11,12,20,21] and connected component-based methods segments the"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "LINE SEGMENTATION USING CONTOUR TRACING",
            "abstract": "Text line segmentation is an important step because inaccurately segmented text lines will cause errors in the recognition stage. Text line segmentation of the handwritten documents is still one of the most complicated problems in developing a reliable OCR. The nature of handwriting makes the process of text line segmentation very challenging. Text characteristics can vary in font, size, orientation, alignment, color, contrast, and background information. These variations turn the process of word detection complex and difficult. Since handwritten text can vary greatly depending on the user skills, disposition and cultural background. The technique of Piece-wise projection alongwith contour tracing to segment a handwritten document into distinct lines of text is presented. The proposed method is robust to handle line fluctuation",
            "year": 2012,
            "venue": "",
            "authors": [
              {
                "authorId": "2118069260",
                "name": "Ashu Kumar"
              },
              {
                "authorId": "144297899",
                "name": "S. Jindal"
              },
              {
                "authorId": "51959213",
                "name": "Galaxy Singla"
              }
            ]
          }
        },
        {
          "citedcorpusid": 36389323,
          "isinfluential": false,
          "contexts": [
            "The piece wise projection pro ﬁ le with Viterbi approach presented in [23,27] can segment the multi skew, irregular patterns for page margins and touching lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A New Scheme for Text Line and Character Segmentation from Gray Scale Images of Palm Leaf Manuscript",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2154407",
                "name": "M. W. A. Kesiman"
              },
              {
                "authorId": "1690398",
                "name": "J. Burie"
              },
              {
                "authorId": "1695766",
                "name": "J. Ogier"
              }
            ]
          }
        },
        {
          "citedcorpusid": 63189644,
          "isinfluential": false,
          "contexts": [
            "text line segment and becomes the part of other text line segment [24]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text-Line and Character Segmentation for Off-line Recognition of Handwritten Japanese Text",
            "abstract": "Text-line and character segmentation is one of the most important steps to develop an Optical Character Recognition (OCR) system for handwritten text. Due to distortions of handwriting, i.e., variations of character size, irregular gaps between characters and touching of characters, etc., however, the step is still a difficult task. This paper proposes a method for segmenting Japanese text-lines and characters from off-line handwritten text pages. The proposed method includes: text-line segmentation using a morphological method, zone projection and character separation for each segmented text-line by vertical projection, Stroke Width Transform (SWT), bridge finding and Voronoi diagrams. The method segments curved, touching and skew text-lines and complicated touching characters.",
            "year": 2016,
            "venue": "",
            "authors": [
              {
                "authorId": "29367641",
                "name": "K. Nguyen"
              },
              {
                "authorId": "145887653",
                "name": "M. Nakagawa"
              }
            ]
          }
        },
        {
          "citedcorpusid": 63638404,
          "isinfluential": true,
          "contexts": [
            "The horizontal projection profile [11,12,20,21] and connected component-based methods segments the",
            "These strategies are projection profile [11,12], smearing [9,13], grouping [3], Hough based [14–16], graph based [7,17,18], Cut Text Minimization [6,19], and Active Contour [7].",
            "The modified projection-based methods presented in [11,23] can deal with slightly curved text lines [6].",
            "the paper presented in [11] used more than 550 images of IAM Hist-DB database with their own collected samples of handwriting images.",
            "Modified projection profile [11][2016] IAM – – – – – 95."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "An Improved Method for Handwritten Document Analysis Using Segmentation, Baseline Recognition and Writing Pressure Detection",
            "abstract": "",
            "year": 2016,
            "venue": "",
            "authors": [
              {
                "authorId": "51296101",
                "name": "A. Bal"
              },
              {
                "authorId": "2071205428",
                "name": "Rajib Saha"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "mented region the divide-and-conquer-based horizontal projection profile-based algorithm is used described in [35]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "258649671": {
      "citing_paper_info": {
        "title": "Historical document image analysis using controlled data for pre-training",
        "abstract": "Using neural networks for semantic labeling has become a dominant technique for layout analysis of historical document images. However, to train or fine-tune appropriate models, large labeled datasets are needed. This paper addresses the case when only limited labeled data are available and promotes a novel approach using so-called controlled data to pre-train the networks. Two different strategies are proposed: The first addresses the real labeling task by using artificial data; the second uses real data to pre-train the networks with a pretext task. To assess these strategies, a large set of experiments has been carried out on a text line detection and classification task using different variants of U-Net. The observations, obtained from two different datasets, show that globally the approach reduces the training time while offering similar or better performance. Furthermore, the effect is bigger on lightweight network architectures.",
        "year": 2023,
        "venue": "International Journal on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "35215669",
            "name": "Najoua Rahal"
          },
          {
            "authorId": "147382507",
            "name": "Lars Vögtlin"
          },
          {
            "authorId": "1680326",
            "name": "R. Ingold"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 16,
        "unique_cited_count": 16,
        "influential_count": 2,
        "detailed_records_count": 16
      },
      "cited_papers": [
        "2202933",
        "234641195",
        "206594692",
        "187547",
        "216056241",
        "233393803",
        "3719281",
        "14683639",
        "4761833",
        "204812057",
        "6628106",
        "210702798",
        "13749026",
        "5987534",
        "3031750",
        "9658690"
      ],
      "citation_details": [
        {
          "citedcorpusid": 187547,
          "isinfluential": false,
          "contexts": [
            "Noroozi and Favaro [25] showed thatwith a simple jigsawpuzzle, a network can learn valuable object representations useful for different downstream tasks.",
            "Noroozi and Favaro [25] showed that with a simple jigsaw puzzle, a network can learn valuable object representations useful for different downstream tasks."
          ],
          "intents": [
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles",
            "abstract": "We propose a novel unsupervised learning approach to build features suitable for object detection and classification. The features are pre-trained on a large dataset without human annotation and later transferred via fine-tuning on a different, smaller and labeled dataset. The pre-training consists of solving jigsaw puzzles of natural images. To facilitate the transfer of features to other tasks, we introduce the context-free network (CFN), a siamese-ennead convolutional neural network. The features correspond to the columns of the CFN and they process image tiles independently (i.e., free of context). The later layers of the CFN then use the features to identify their geometric arrangement. Our experimental evaluations show that the learned features capture semantically relevant content. We pre-train the CFN on the training set of the ILSVRC2012 dataset and transfer the features on the combined training and validation set of Pascal VOC 2007 for object detection (via fast RCNN) and classification. These features outperform all current unsupervised features with \\(51.8\\,\\%\\) for detection and \\(68.6\\,\\%\\) for classification, and reduce the gap with supervised learning (\\(56.5\\,\\%\\) and \\(78.2\\,\\%\\) respectively).",
            "year": 2016,
            "venue": "European Conference on Computer Vision",
            "authors": [
              {
                "authorId": "1811235696",
                "name": "M. Noroozi"
              },
              {
                "authorId": "145646305",
                "name": "P. Favaro"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2202933,
          "isinfluential": false,
          "contexts": [
            "Other simple methods are used, like the rotation of the image [26], inpainting [27], or coloring gray-scale images [28] or more complex techniques like contrastive learning [29]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Context Encoders: Feature Learning by Inpainting",
            "abstract": "We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders - a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "38236002",
                "name": "Deepak Pathak"
              },
              {
                "authorId": "2562966",
                "name": "Philipp Krähenbühl"
              },
              {
                "authorId": "7408951",
                "name": "Jeff Donahue"
              },
              {
                "authorId": "1753210",
                "name": "Trevor Darrell"
              },
              {
                "authorId": "1763086",
                "name": "Alexei A. Efros"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3031750,
          "isinfluential": false,
          "contexts": [
            "The following datasets were used for the evaluation: G. Washington [10], Parzival [11], St.Gall [12], and DIVA-HisDB [13]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Language Model Integration for the Recognition of Handwritten Medieval Documents",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 3719281,
          "isinfluential": false,
          "contexts": [
            "[20], was initially designed for the semantic labeling of medical images.",
            "In this section, we investigate four FCN architectures as references, vanilla U-Net (U-Net-S) [20] and three variants of U-Net, named U-Net-16, Adaptive U-Net [19], and DocUFCN [21].",
            "[19] proposed an Adaptive U-Net model for text line detection in handwritten document images, a variant of the U-Net model [20]."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
            "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .",
            "year": 2015,
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "authors": [
              {
                "authorId": "1737326",
                "name": "O. Ronneberger"
              },
              {
                "authorId": "152702479",
                "name": "P. Fischer"
              },
              {
                "authorId": "1710872",
                "name": "T. Brox"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4761833,
          "isinfluential": true,
          "contexts": [
            "For evaluation, the experiments were running on cBAD dataset [16].",
            "ARU-Net has been tested on cBAD [16] and DIVA-HisDB [13] datasets.",
            "The page extraction task was evaluated on the cBAD: ICDAR2017 Competition [16] dataset.",
            "pixel-wise classifications of text line detection: cBAD [16], DIVA-HisDB [13], and the private ANT1 datasets."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "cBAD: ICDAR2017 Competition on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              },
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5987534,
          "isinfluential": false,
          "contexts": [
            "[9] proposed a simple CNN having only one convolution layer."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Convolutional Neural Networks for Page Segmentation of Historical Document Images",
            "abstract": "This paper presents a page segmentation method for handwritten historical document images based on a Convolutional Neural Network (CNN). We consider page segmentation as a pixel labeling problem, i.e., each pixel is classified as one of the predefined classes. Traditional methods in this area rely on hand-crafted features carefully tuned considering prior knowledge. In contrast, we propose to learn features from raw image pixels using a CNN. While many researchers focus on developing deep CNN architectures to solve different problems, we train a simple CNN with only one convolution layer. We show that the simple architecture achieves competitive results against other deep architectures on different public datasets. Experiments also demonstrate the effectiveness and superiority of the proposed method compared to previous methods.",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "153819461",
                "name": "Kai Chen"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6628106,
          "isinfluential": false,
          "contexts": [
            "Incombinationwiththecross-entropyloss,ADAMoptimizer [37] is used for training with an epsilon of 1 e − 5 and a learning rate equal to 1 e − 3 ."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Adam: A Method for Stochastic Optimization",
            "abstract": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.",
            "year": 2014,
            "venue": "International Conference on Learning Representations",
            "authors": [
              {
                "authorId": "1726807",
                "name": "Diederik P. Kingma"
              },
              {
                "authorId": "2503659",
                "name": "Jimmy Ba"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9658690,
          "isinfluential": false,
          "contexts": [
            "Other simple methods are used, like the rotation of the image [26], inpainting [27], or coloring gray-scale images [28] or more complex techniques like contrastive learning [29]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction",
            "abstract": "We propose split-brain autoencoders, a straightforward modification of the traditional autoencoder architecture, for unsupervised representation learning. The method adds a split to the network, resulting in two disjoint sub-networks. Each sub-network is trained to perform a difficult task &#x2013; predicting one subset of the data channels from another. Together, the sub-networks extract features from the entire input signal. By forcing the network to solve cross-channel prediction tasks, we induce a representation within the network which transfers well to other, unseen tasks. This method achieves state-of-the-art performance on several large-scale transfer learning benchmarks.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2844849",
                "name": "Richard Zhang"
              },
              {
                "authorId": "2094770",
                "name": "Phillip Isola"
              },
              {
                "authorId": "1763086",
                "name": "Alexei A. Efros"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13749026,
          "isinfluential": false,
          "contexts": [
            "[21] presented the Doc-UFCN model, inspired by the dhSegmentmodel [14], for text line detection.",
            "[14] described a generic CNN-based system, dhSegment, for addressing multiple tasks, e."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "dhSegment: A Generic Deep-Learning Approach for Document Segmentation",
            "abstract": "In recent years there have been multiple successful attempts tackling document processing problems separately by designing task specific hand-tuned strategies. We argue that the diversity of historical document processing tasks prohibits to solve them one at a time and shows a need for designing generic approaches in order to handle the variability of historical series. In this paper, we address multiple tasks simultaneously such as page extraction, baseline extraction, layout analysis or multiple typologies of illustrations and photograph extraction. We propose an open-source implementation of a CNN-based pixel-wise predictor coupled with task dependent post-processing blocks. We show that a single CNN-architecture can be used across tasks with competitive results. Moreover most of the task-specific post-precessing steps can be decomposed in a small number of simple and standard reusable operations, adding to the flexibility of our approach.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2066810458",
                "name": "S. Oliveira"
              },
              {
                "authorId": "2060245962",
                "name": "Benoit Seguin"
              },
              {
                "authorId": "143791091",
                "name": "F. Kaplan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14683639,
          "isinfluential": false,
          "contexts": [
            "The following datasets were used for the evaluation: G. Washington [10], Parzival [11], St.Gall [12], and DIVA-HisDB [13]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Transcription alignment of Latin manuscripts using hidden Markov models",
            "abstract": "",
            "year": 2011,
            "venue": "The Hip",
            "authors": [
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1688695",
                "name": "Volkmar Frinken"
              },
              {
                "authorId": "1686569",
                "name": "A. Fornés"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 204812057,
          "isinfluential": false,
          "contexts": [
            "The Doc-UFCN model was evaluated on Balsac [22], Horae [23], READ-BAD [24], and DIVA-HisDB [13] datasets."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "HORAE: an annotated dataset of books of hours",
            "abstract": "We introduce in this paper a new dataset of annotated pages from books of hours, a type of handwritten prayerbooks owned and used by rich lay people in the late middle ages. The dataset was created for conducting historical research on the evolution of the religious mindset in Europe at this period, since book of hours represent one of the major sources of information thanks both to their rich illustrations and the different types of religious sources they contain. We first describe how the corpus was collected and manually annotated then present the evaluation of a state-of-the-art system for text line detection and for zone detection and typing. The corpus is freely available for research.",
            "year": 2019,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "1380222130",
                "name": "Mélodie Boillet"
              },
              {
                "authorId": "1388159793",
                "name": "Marie-Laurence Bonhomme"
              },
              {
                "authorId": "2064656632",
                "name": "Dominique Stutzmann"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206594692,
          "isinfluential": true,
          "contexts": [
            "The system was based on an FCN, where the encoder was a pre-trained ResNet-50 [15], followed by a post-processing block for pixels classification.",
            "The system was based on an FCN, where the encoder was a pre-trained ResNet-50 [15], followed by a post-processing block for pixels classiﬁcation.",
            "The encoder of dhSegment was the ResNet-50 [15] architecture, pre-trained on natural scene images.",
            "The encoder of dhSegment was the ResNet50 [15] architecture, pre-trained on natural scene images."
          ],
          "intents": [
            "['methodology']",
            "--",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Deep Residual Learning for Image Recognition",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
            "year": 2015,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "1771551",
                "name": "X. Zhang"
              },
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": null,
                "name": "Jian Sun"
              }
            ]
          }
        },
        {
          "citedcorpusid": 210702798,
          "isinfluential": false,
          "contexts": [
            "Enormous progress has been reported for various tasks such as image classification [1], segmentation [2], and object detection [3]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Image Segmentation Using Deep Learning: A Survey",
            "abstract": "Image segmentation is a key task in computer vision and image processing with important applications such as scene understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among others, and numerous segmentation algorithms are found in the literature. Against this backdrop, the broad success of deep learning (DL) has prompted the development of new image segmentation approaches leveraging DL models. We provide a comprehensive review of this recent literature, covering the spectrum of pioneering efforts in semantic and instance segmentation, including convolutional pixel-labeling networks, encoder-decoder architectures, multiscale and pyramid-based approaches, recurrent networks, visual attention models, and generative models in adversarial settings. We investigate the relationships, strengths, and challenges of these DL-based segmentation models, examine the widely used datasets, compare performances, and discuss promising research directions.",
            "year": 2020,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2164604",
                "name": "Shervin Minaee"
              },
              {
                "authorId": "1692688",
                "name": "Yuri Boykov"
              },
              {
                "authorId": "29905643",
                "name": "F. Porikli"
              },
              {
                "authorId": "143767945",
                "name": "A. Plaza"
              },
              {
                "authorId": "30567641",
                "name": "N. Kehtarnavaz"
              },
              {
                "authorId": "1750924",
                "name": "Demetri Terzopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 216056241,
          "isinfluential": false,
          "contexts": [
            "[30] that translate the jigsaw puzzle approach to document images."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Self-Supervised Representation Learning on Document Images",
            "abstract": "This work analyses the impact of self-supervised pre-training on document images in the context of document image classification. While previous approaches explore the effect of self-supervision on natural images, we show that patch-based pre-training performs poorly on document images because of their different structural properties and poor intra-sample semantic information. We propose two context-aware alternatives to improve performance on the Tobacco-3482 image classification task. We also propose a novel method for self-supervision, which makes use of the inherent multi-modality of documents (image and text), which performs better than other popular self-supervised methods, including supervised ImageNet pre-training, on document image classification scenarios with a limited amount of data.",
            "year": 2020,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "66618729",
                "name": "Adrian Cosma"
              },
              {
                "authorId": "1648686257",
                "name": "Mihai Ghidoveanu"
              },
              {
                "authorId": "2315136940",
                "name": "Michael Panaitescu-Liess"
              },
              {
                "authorId": "49006356",
                "name": "M. Popescu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 233393803,
          "isinfluential": false,
          "contexts": [
            "Enormous progress has been reported for various tasks such as image classiﬁcation [1], segmentation [2], and object detection [3]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "A Survey of Modern Deep Learning based Object Detection Models",
            "abstract": "",
            "year": 2021,
            "venue": "Digit. Signal Process.",
            "authors": [
              {
                "authorId": null,
                "name": "Syed Sahil Abbas Zaidi"
              },
              {
                "authorId": "153631150",
                "name": "M. S. Ansari"
              },
              {
                "authorId": "48375326",
                "name": "Asra Aslam"
              },
              {
                "authorId": "1723907",
                "name": "N. Kanwal"
              },
              {
                "authorId": "21701715",
                "name": "M. Asghar"
              },
              {
                "authorId": "2110107133",
                "name": "Brian Lee"
              }
            ]
          }
        },
        {
          "citedcorpusid": 234641195,
          "isinfluential": false,
          "contexts": [
            "The Doc-UFCN model was evaluated on Balsac [22], Horae [23], READ-BAD [24], and DIVA-HisDB [13] datasets."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An Overview of the BALSAC Population Database. Past Developments, Current State and Future Prospects",
            "abstract": "The BALSAC database, developed since 1971, contains data on the Quebec population from the beginnings of European settlement in the 17th century to the contemporary period. Today, BALSAC is a major research infrastructure used by researchers from Quebec and elsewhere, both in the social sciences and in the biomedical sciences. This paper presents the evolution and current state of the database and offers a perspective on forthcoming developments. BALSAC contains marriage certificates until 1965. Coverage is complete for Catholic records (80 to 100% of the population depending on the region and the period) and partial for the other denominations. Birth and death certificates from all Catholic parishes have been integrated for the period 1800–1849 and work in underway for 1850–1916. All the records entered in BALSAC are subject to a linkage process which, ultimately, allows the automatic reconstitution of genealogical links and family relationships. The basic principle has remained the same since the beginning, namely to match individuals based on the nominative information contained in the sources. The changes made in recent years and the resulting gains are mostly related to IT advances which now offer more flexibility and increased performance. Future perspectives rest on the diversification of the sources of population data entered or connected to the database and, as a corollary, by continuous optimization of data processing and linkage procedures. In the era of 'big data', BALSAC is gradually moving from a historical population database to a multifaceted infrastructure for interdisciplinary research on the Quebec population.",
            "year": 2020,
            "venue": "",
            "authors": [
              {
                "authorId": "3115011",
                "name": "H. Vézina"
              },
              {
                "authorId": "117993253",
                "name": "Jean-Sébastien Bournival"
              }
            ]
          }
        }
      ]
    },
    "33685302": {
      "citing_paper_info": {
        "title": "Two-stage hybrid binarization around fringe map based text line segmentation for document images",
        "abstract": "",
        "year": 2012,
        "venue": "International Conference on Pattern Recognition",
        "authors": [
          {
            "authorId": "35129473",
            "name": "Saumya Jetley"
          },
          {
            "authorId": "2191480",
            "name": "S. Belhe"
          },
          {
            "authorId": "3197140",
            "name": "V. K. Koppula"
          },
          {
            "authorId": "1728262",
            "name": "A. Negi"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 8,
        "unique_cited_count": 8,
        "influential_count": 2,
        "detailed_records_count": 8
      },
      "cited_papers": [
        "12993414",
        "35215159",
        "8953108",
        "14240014",
        "1048007",
        "11738248",
        "30272350",
        "14210437"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1048007,
          "isinfluential": false,
          "contexts": [
            "The global methods use a single threshold value, calculated over the entire image, to classify image pixels into either object or background class [1-4], whereas the local (adaptive) schemes change the threshold dynamically over the image according to the local information [510]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Thresholding of digital images using two-dimensional entropies",
            "abstract": "",
            "year": 1992,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "47679004",
                "name": "A. D. Brink"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8953108,
          "isinfluential": false,
          "contexts": [
            "We explore the possibility of a multiresolution binarization with Kittler method [19]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Survey over image thresholding techniques and quantitative performance evaluation",
            "abstract": "We conduct an exhaustive survey of image thresholding methods, categorize them, express their formulas under a uniform notation, and finally carry their performance comparison. The thresholding methods are categorized according to the information they are exploiting, such as histogram shape, measurement space clustering, entropy, object attributes, spatial correlation, and local gray-level surface. 40 selected thresholding methods from various categories are compared in the context of nondestructive testing applications as well as for document images. The comparison is based on the combined performance measures. We identify the thresholding algorithms that perform uniformly better over nonde- structive testing and document image applications. © 2004 SPIE and IS&T. (DOI: 10.1117/1.1631316)",
            "year": 2004,
            "venue": "J. Electronic Imaging",
            "authors": [
              {
                "authorId": "2850022",
                "name": "Mehmet Sezgin"
              },
              {
                "authorId": "145940271",
                "name": "B. Sankur"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11738248,
          "isinfluential": true,
          "contexts": [
            "The adaptive binarization techniques like Niblack, Sauvola or their modified versions [7-10] provide the best support in terms of the desired accuracy of binarization.",
            "Niblack [5], Sauvola [6]; their modified variants [7-10] can also be attempted.",
            "These values can be compared with the performance values of other widely used and recommended methods (refer Table-1 in [9]).",
            "Although the performance parameters show that it is considerably below the best methods for binarization (see Table-1 in [9]); it provides sufficient outcomes at fast speeds for subsequent Text Line Segmentation, compiled in Table 2.",
            "Contrarily, the adaptive methods – Niblack [5], Sauvola [6] or their modified versions [7-10], give better results on these images, but are computationally intensive."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['result']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Combination of Document Image Binarization Techniques",
            "abstract": "",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1795547",
                "name": "Bolan Su"
              },
              {
                "authorId": "1771189",
                "name": "Shijian Lu"
              },
              {
                "authorId": "1679749",
                "name": "C. Tan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12993414,
          "isinfluential": false,
          "contexts": [
            "The Grouping methods (Bottom-Up approach) [17-18] have also been implemented."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text-Line Extraction in Handwritten Chinese Documents Based on an Energy Minimization Framework",
            "abstract": "",
            "year": 2012,
            "venue": "IEEE Transactions on Image Processing",
            "authors": [
              {
                "authorId": "2463454",
                "name": "H. Koo"
              },
              {
                "authorId": "1707645",
                "name": "N. Cho"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14210437,
          "isinfluential": false,
          "contexts": [
            "Some researchers have also used Hough transform [16] for line segmentation but it has trouble detecting curved lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Block-Based Hough Transform Mapping for Text Line Detection in Handwritten Documents",
            "abstract": "In this paper, we present a new text line detection method for unconstrained handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes preprocessing for image enhancement, connected component extraction and average character height estimation. In the second step, a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible false alarms. The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "70602633",
                "name": "K. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14240014,
          "isinfluential": false,
          "contexts": [
            "DIBCO 2011 evaluation metrics – F Measure, PSNR, DRDM and MPM, adapted from the DIBCO report [22] are used to establish the performance of the PreSegmentation Binarization algorithm, refer Table 2."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Computational Intelligence",
            "abstract": "There are two complementary views of artificial intelligence (AI): one as an engineering discipline concerned with the creation of intelligent machines, the other as an empirical science concerned with the computational modeling of human intelligence. When the field was young, these two views were seldom distinguished. Since then, a substantial divide has opened up, with the former view dominating modern AI and the latter view characterizing much of modern cognitive science. For this reason, we have adopted the more neutral term “computational intelligence” as the title of this article—both communities are attacking the problem of understanding intelligence in computational terms. It is our belief that the differences between the engineering models and the cognitively inspired models are small compared to the vast gulf in competence between these models and human levels of intelligence. For humans are, to a first approximation, intelligent; they can perceive, act, learn, reason, and communicate successfully despite the enormous difficulty of these tasks. Indeed, we expect that as further progress is made in trying to emulate this success, the engineering and cognitive models will become more similar. Already, the traditionally antagonistic “connectionist” and “symbolic” camps are finding common ground, particularly in their understanding of reasoning under uncertainty and learning. This sort of cross-fertilization was a central aspect of the early vision of cognitive science as an interdisciplinary enterprise.",
            "year": 2020,
            "venue": "International Symposium on Industrial Electronics",
            "authors": [
              {
                "authorId": "2273930444",
                "name": "Michael I. Jordan"
              },
              {
                "authorId": "2261660012",
                "name": "Stuart Russell"
              }
            ]
          }
        },
        {
          "citedcorpusid": 30272350,
          "isinfluential": true,
          "contexts": [
            "In the multi-resolution approach, the greyscale image is processed using the Kittler method, at multiple scales, and the results (at the different scales) are combined together to form the preliminary binarized image.",
            "This is equivalent to the simple global Kittler technique.",
            "The global methods use a single threshold value, calculated over the entire image, to classify image pixels into either object or background class [1-4], whereas the local (adaptive) schemes change the threshold dynamically over the image according to the local information [510].",
            "[2] J. Kittler, J. Illingworth.",
            "We explore the possibility of a multiresolution binarization with Kittler method [19].",
            "Multi Resolution Kittler Method is much faster than the adaptive algorithms.",
            "Global methods like Otsu [1] and Kittler [2] are definitely faster but not completely sufficient for document image binarization where the images display poor quality, non-uniform illumination, low contrast, large signal-dependent noise, smears and strains."
          ],
          "intents": [
            "--",
            "--",
            "['methodology']",
            "--",
            "--",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "On threshold selection using clustering criteria",
            "abstract": "",
            "year": 1985,
            "venue": "IEEE Transactions on Systems, Man and Cybernetics",
            "authors": [
              {
                "authorId": "145801638",
                "name": "J. Kittler"
              },
              {
                "authorId": "144275801",
                "name": "J. Illingworth"
              }
            ]
          }
        },
        {
          "citedcorpusid": 35215159,
          "isinfluential": false,
          "contexts": [
            "For skewed lines of text, the projection method has been modified by Zahour et al [13], Tripathy and Pal [14], Arivazhagan et al.",
            "978-4-9906441-0-9 ©2012 ICPR 343\nFor skewed lines of text, the projection method has been modified by Zahour et al [13], Tripathy and Pal [14], Arivazhagan et al. [15]."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Arabic hand-written text-line extraction",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              },
              {
                "authorId": "144484822",
                "name": "P. Mercy"
              },
              {
                "authorId": "2102325551",
                "name": "Said Ramdane"
              }
            ]
          }
        }
      ]
    },
    "198163584": {
      "citing_paper_info": {
        "title": "Distributed Multi-Agent Implementation of Text Line Segmentation Using Parallel Seam Carving",
        "abstract": "Most Optical Character Recognition systems (OCR) and Handwritten Recognition systems (HWR) are based on sequential processing of document images, while some others use parallelism to alleviate the computational load on single processors by balancing the tasks on parallel hardware using “Single Instruction, Multiple Data” (SIMD) architectures. This does not completely correspond to how humans read, where reading a line rely on parallel decision making based on the central and peripheral vision. Thus, it makes these OCR systems limited in face of highly complex OCR problems, unable to synchronize their multiple tasks in a participative way. This paper proposes a parallel text line segmentation approach based on distributed multi-agent systems using a parallel implementation of seam carving. The seam carving text segmentation technique is a language-independent approach capable of processing grayscale images, and showed promising results at extracting handwritten text lines. Additionally, its “top-down” approach to text segmentation offers an opportunity for building efficient parallel OCR systems, using multiple specialized system components built around a multi-agent architecture. This can be further exploited as a base to build more collaborative neuromorphic systems. Tests on different handwritten documents showed an important runtime speedup with parallelization using MPI as a communication interface, without compromising the efficiency.",
        "year": 2018,
        "venue": "",
        "authors": [
          {
            "authorId": "134380857",
            "name": "M. Daldali"
          },
          {
            "authorId": "2895007",
            "name": "A. Souhar"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 3,
        "unique_cited_count": 2,
        "influential_count": 1,
        "detailed_records_count": 3
      },
      "cited_papers": [
        "20602268",
        "3015502"
      ],
      "citation_details": [
        {
          "citedcorpusid": 3015502,
          "isinfluential": false,
          "contexts": [
            "The last affirmations are backed by studies concerning the role of eye movements in reading and information processing [1], where it was shown that the peripheral field of vision is contributing heavily in the reading process."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Eye movements in reading and information processing: 20 years of research.",
            "abstract": "Recent studies of eye movements in reading and other information processing tasks, such as music reading, typing, visual search, and scene perception, are reviewed. The major emphasis of the review is on reading as a specific example of cognitive processing. Basic topics discussed with respect to reading are (a) the characteristics of eye movements, (b) the perceptual span, (c) integration of information across saccades, (d) eye movement control, and (e) individual differences (including dyslexia). Similar topics are discussed with respect to the other tasks examined. The basic theme of the review is that eye movement data reflect moment-to-moment cognitive processes in the various tasks examined. Theoretical and practical considerations concerning the use of eye movement data are also discussed.",
            "year": 1998,
            "venue": "Psychological bulletin",
            "authors": [
              {
                "authorId": "2148762",
                "name": "K. Rayner"
              }
            ]
          }
        },
        {
          "citedcorpusid": 20602268,
          "isinfluential": false,
          "contexts": [
            "In [8], the problem of OCR system errors was addressed."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Reducing OCR errors by combining two OCR systems",
            "abstract": "This paper describes our efforts in building a heritage corpus of Alpine texts. We have already digitized the yearbooks of the Swiss Alpine Club from 1864 until 1982. \nThis corpus poses special challenges since the yearbooks are multilingual and vary in orthography and layout. We discuss methods to improve OCR performance and experiment with combining two different OCR programs with the goal to reduce the number of OCR errors. We describe a merging procedure that uses a unigram language model trained on the uncorrected corpus itself to select the best alternative, and report on evaluation results which show that the merging procedure helps to improve OCR quality.",
            "year": 2010,
            "venue": "",
            "authors": [
              {
                "authorId": "1753415",
                "name": "M. Volk"
              },
              {
                "authorId": "2132542",
                "name": "T. Marek"
              },
              {
                "authorId": "2082372",
                "name": "Rico Sennrich"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": true,
          "contexts": [
            "And as such, the supervisor agent can be modeled as a simple reflex agent [18] in charge of the over-all process.",
            "Each document agent is a model-based reflex agent [18] in charge of finding the separating seams by reflex decisions made of the interaction resulting from the underlying projection profile agents (PPAs) and the seam carving agents (SCAs).",
            "3) The Projection Profile (PPA) and the Seam Carving (SCA) agents These agents are simple reflex agents [18], where their processing is only bound to the parameters passed by the supervising document agent, acting in partially observable environments defined by the image areas assigned by the document agent."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "235495091": {
      "citing_paper_info": {
        "title": "A Model for Text Line Segmentation and Classification in Printed Documents",
        "abstract": "In this paper, we propose a new model for text line segmentation and classification, which consists of convolutional and two-layer bi-directional long short-term memory (BiLSTM) networks. Trained on the synthetic text dataset, it performs excellently when predicting the real data. Without labelling every line on the real data, a generalized standard for evaluating the accuracy is proposed. We also propose a simplified IoU loss to improve the execution speed greatly. In the experiments, it achieves 98.1% line segmentation accuracy and 99.5% classification accuracy on the English fiction Pride and Prejudice by Jane Austen, and achieves 98.5% line segmentation accuracy and 99.7% classification accuracy on the The Secret Of Plato's Atlantis by John Arundell, outperforming the traditional methods. Furthermore, for 1024 × 724 input samples, it gets 2.95 FPS speed when using a Tesla K80 GPU. Index Terms—Text line segmentation, Text classification, Synthetic text, BiLSTM, Convolutional network.",
        "year": 2021,
        "venue": "International Conference on Machine Learning and Computing",
        "authors": [
          {
            "authorId": "2153690237",
            "name": "Xin Wang"
          },
          {
            "authorId": "2117223305",
            "name": "Jun Guo"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 9,
        "unique_cited_count": 9,
        "influential_count": 0,
        "detailed_records_count": 9
      },
      "cited_papers": [
        "4714433",
        "216077384",
        "786357",
        "2141740",
        "119296375",
        "51923817",
        "67855967",
        "206770307",
        "215827080"
      ],
      "citation_details": [
        {
          "citedcorpusid": 786357,
          "isinfluential": false,
          "contexts": [
            "And then, the methods, such as YOLO9000 [19], RetinaNet [9], YOLOv3 [20] all push forward the state-of-the-art of one-stage detector."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "YOLO9000: Better, Faster, Stronger",
            "abstract": "We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. Using a novel, multi-scale training method the same YOLOv2 model can run at varying sizes, offering an easy tradeoff between speed and accuracy. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that dont have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. YOLO9000 predicts detections for more than 9000 different object categories, all in real-time.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "40497777",
                "name": "Joseph Redmon"
              },
              {
                "authorId": "143787583",
                "name": "Ali Farhadi"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2141740,
          "isinfluential": false,
          "contexts": [
            "At the same time, the representative framework in one-stage such as YOLO [7], SSD [8], RetinaNet [9] were proposed to achieve the real-time detection.",
            "To achieve the aim of real-time object detection, YOLO [7] was proposed by Joseph Redmon et al, and after that Wei Liu et al proposed the SSD [8] to achieve fast detection and obtain more accurate result at the same time.",
            "At the same time, the representative framework in one-stage such as YOLO [7], SSD [8], RetinaNet [9] were proposed to achieve the realtime detection."
          ],
          "intents": [
            "--",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "SSD: Single Shot MultiBox Detector",
            "abstract": "We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets confirm that SSD has comparable accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. Compared to other single stage methods, SSD has much better accuracy, even with a smaller input image size. For $300\\times 300$ input, SSD achieves 72.1% mAP on VOC2007 test at 58 FPS on a Nvidia Titan X and for $500\\times 500$ input, SSD achieves 75.1% mAP, outperforming a comparable state of the art Faster R-CNN model. Code is available at this https URL .",
            "year": 2015,
            "venue": "European Conference on Computer Vision",
            "authors": [
              {
                "authorId": "46641573",
                "name": "W. Liu"
              },
              {
                "authorId": "1838674",
                "name": "Dragomir Anguelov"
              },
              {
                "authorId": "1761978",
                "name": "D. Erhan"
              },
              {
                "authorId": "2574060",
                "name": "Christian Szegedy"
              },
              {
                "authorId": "144828948",
                "name": "Scott E. Reed"
              },
              {
                "authorId": "2084646762",
                "name": "Cheng-Yang Fu"
              },
              {
                "authorId": "39668247",
                "name": "A. Berg"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4714433,
          "isinfluential": false,
          "contexts": [
            "And then, the methods, such as YOLO9000 [19], RetinaNet [9], YOLOv3 [20] all push forward the state-of-the-art of one-stage detector.",
            "And then, the methods, such as YOLO9000 [19], RetinaNet [9], YOLOv3 [20] all push forward the state- of-the-art of one-stage detector."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "YOLOv3: An Incremental Improvement",
            "abstract": "We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at this https URL",
            "year": 2018,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "40497777",
                "name": "Joseph Redmon"
              },
              {
                "authorId": "143787583",
                "name": "Ali Farhadi"
              }
            ]
          }
        },
        {
          "citedcorpusid": 51923817,
          "isinfluential": false,
          "contexts": [
            "In recent years, more and more anchor-free detectors had been proposed, the methods based on key point, such as CornerNet [10], ExtremeNet [11], and the methods using intensive forecasting ideas, such as FSAF [21], FCOS [12], and Fove-aBox [22], while maintaining the speed of real-time prediction,…",
            "Besides, the initial methods need to set the artificial anchor box to achieve object localization, however recently popular anchor-free framework CornerNet [10], ExtremeNet [11], FCOS [12], CenterNet [14] have been put forward to break that limit."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "CornerNet: Detecting Objects as Paired Keypoints",
            "abstract": "We propose CornerNet, a new approach to object detection where we detect an object bounding box as a pair of keypoints, the top-left corner and the bottom-right corner, using a single convolution neural network. By detecting objects as paired keypoints, we eliminate the need for designing a set of anchor boxes commonly used in prior single-stage detectors. In addition to our novel formulation, we introduce corner pooling, a new type of pooling layer that helps the network better localize corners. Experiments show that CornerNet achieves a 42.2% AP on MS COCO, outperforming all existing one-stage detectors.",
            "year": 2018,
            "venue": "International Journal of Computer Vision",
            "authors": [
              {
                "authorId": "32647956",
                "name": "Hei Law"
              },
              {
                "authorId": "153302678",
                "name": "Jia Deng"
              }
            ]
          }
        },
        {
          "citedcorpusid": 67855967,
          "isinfluential": false,
          "contexts": [
            "In recent years, more and more anchorfree detectors had been proposed, the methods based on key point, such as CornerNet [10], ExtremeNet [11], and the methods using intensive forecasting ideas, such as FSAF [21], FCOS [12], and FoveaBox [22], while maintaining the speed of real-time prediction, they are as accurate as many two-stage detectors.",
            "In recent years, more and more anchor-free detectors had been proposed, the methods based on key point, such as CornerNet [10], ExtremeNet [11], and the methods using intensive forecasting ideas, such as FSAF [21], FCOS [12], and Fove-aBox [22], while maintaining the speed of real-time prediction, they are as accurate as many two-stage detectors."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Feature Selective Anchor-Free Module for Single-Shot Object Detection",
            "abstract": "We motivate and present feature selective anchor-free (FSAF) module, a simple and effective building block for single-shot object detectors. It can be plugged into single-shot detectors with feature pyramid structure. The FSAF module addresses two limitations brought up by the conventional anchor-based detection: 1) heuristic-guided feature selection; 2) overlap-based anchor sampling. The general concept of the FSAF module is online feature selection applied to the training of multi-level anchor-free branches. Specifically, an anchor-free branch is attached to each level of the feature pyramid, allowing box encoding and decoding in the anchor-free manner at an arbitrary level. During training, we dynamically assign each instance to the most suitable feature level. At the time of inference, the FSAF module can work independently or jointly with anchor-based branches. We instantiate this concept with simple implementations of anchor-free branches and online feature selection strategy. Experimental results on the COCO detection track show that our FSAF module performs better than anchor-based counterparts while being faster. When working jointly with anchor-based branches, the FSAF module robustly improves the baseline RetinaNet by a large margin under various settings, while introducing nearly free inference overhead. And the resulting best model can achieve a state-of-the-art 44.6% mAP, outperforming all existing single-shot detectors on COCO.",
            "year": 2019,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "47894545",
                "name": "Chenchen Zhu"
              },
              {
                "authorId": "39838894",
                "name": "Yihui He"
              },
              {
                "authorId": "1794486",
                "name": "M. Savvides"
              }
            ]
          }
        },
        {
          "citedcorpusid": 119296375,
          "isinfluential": false,
          "contexts": [
            "Besides, the initial methods need to set the artificial anchor box to achieve object localization, however recently popular anchor-free framework CornerNet [10], ExtremeNet [11], FCOS [12], CenterNet [14] have been put forward to break that limit."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "CenterNet: Keypoint Triplets for Object Detection",
            "abstract": "In object detection, keypoint-based approaches often experience the drawback of a large number of incorrect object bounding boxes, arguably due to the lack of an additional assessment inside cropped regions. This paper presents an efficient solution that explores the visual patterns within individual cropped regions with minimal costs. We build our framework upon a representative one-stage keypoint-based detector named CornerNet. Our approach, named CenterNet, detects each object as a triplet, rather than a pair, of keypoints, which improves both precision and recall. Accordingly, we design two customized modules, cascade corner pooling, and center pooling, that enrich information collected by both the top-left and bottom-right corners and provide more recognizable information from the central regions. On the MS-COCO dataset, CenterNet achieves an AP of 47.0 %, outperforming all existing one-stage detectors by at least 4.9%. Furthermore, with a faster inference speed than the top-ranked two-stage detectors, CenterNet demonstrates a comparable performance to these detectors. Code is available at https://github.com/Duankaiwen/CenterNet.",
            "year": 2019,
            "venue": "IEEE International Conference on Computer Vision",
            "authors": [
              {
                "authorId": "36686543",
                "name": "Kaiwen Duan"
              },
              {
                "authorId": "47651566",
                "name": "S. Bai"
              },
              {
                "authorId": "3041937",
                "name": "Lingxi Xie"
              },
              {
                "authorId": "144097734",
                "name": "H. Qi"
              },
              {
                "authorId": "1689702",
                "name": "Qingming Huang"
              },
              {
                "authorId": "144876831",
                "name": "Q. Tian"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206770307,
          "isinfluential": false,
          "contexts": [
            "The next two approaches, SPP-net [2] and Fast RCNN [3], speeded up the model by sharing computing.",
            "In the former methods, such as RegionCNN (R-CNN) [1], SPP-Net [2], Fast RCNN [3], Faster RCNN [4], Mask R-CNN [5], and Cascaded R-CNN [6] have been developed to push ahead of the state-of-the-art.",
            "In the former methods, such as RegionCNN (R-CNN) [1], SPP-Net [2], Fast R-CNN [3], Faster RCNN [4], Mask R-CNN [5], and Cascaded R-CNN [6] have been developed to push ahead of the state-of-the-art."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Fast R-CNN",
            "abstract": "This paper proposes Fast R-CNN, a clean and fast framework for object detection. Compared to traditional R-CNN, and its accelerated version SPPnet, Fast R-CNN trains networks using a multi-task loss in a single training stage. The multi-task loss simplifies learning and improves detection accuracy. Unlike SPPnet, all network layers can be updated during fine-tuning. We show that this difference has practical ramifications for very deep networks, such as VGG16, where mAP suffers when only the fully-connected layers are updated. Compared to\"slow\"R-CNN, Fast R-CNN is 9x faster at training VGG16 for detection, 213x faster at test-time, and achieves a significantly higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn",
            "year": 2015,
            "venue": "",
            "authors": [
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 215827080,
          "isinfluential": false,
          "contexts": [
            "In the former methods, such as RegionCNN (R-CNN) [1], SPP-Net [2], Fast R-CNN [3], Faster RCNN [4], Mask R-CNN [5], and Cascaded R-CNN [6] have been developed to push ahead of the state-of-the-art.",
            "As the originator of applying a convolutional neural network to solved the problem of object detection, R-CNN [1] once put forward a two-stage method, which took the original image as input, first used Selective Search (SS) [16] to obtained lots of region proposals, and then executed the…"
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation",
            "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.",
            "year": 2013,
            "venue": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              },
              {
                "authorId": "7408951",
                "name": "Jeff Donahue"
              },
              {
                "authorId": "1753210",
                "name": "Trevor Darrell"
              },
              {
                "authorId": "153652147",
                "name": "J. Malik"
              }
            ]
          }
        },
        {
          "citedcorpusid": 216077384,
          "isinfluential": false,
          "contexts": [
            "…neural network to solved the problem of object detection, R-CNN [1] once put forward a two-stage method, which took the original image as input, first used Selective Search (SS) [16] to obtained lots of region proposals, and then executed the classification and localization of candidates.",
            "And then the revolutionary approach, Faster R-CNN [4], used Region Proposal Network (RPN) [4] instead of SS [16] and proposed the mechanism of anchor box."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Selective Search for Object Recognition",
            "abstract": "",
            "year": 2013,
            "venue": "International Journal of Computer Vision",
            "authors": [
              {
                "authorId": "2242508491",
                "name": "Jasper R. R. Uijlings"
              },
              {
                "authorId": "1756979",
                "name": "K. V. D. Sande"
              },
              {
                "authorId": "2257152645",
                "name": "Theo Gevers"
              },
              {
                "authorId": "144638781",
                "name": "A. Smeulders"
              }
            ]
          }
        }
      ]
    },
    "34859591": {
      "citing_paper_info": {
        "title": "Text Line Segmentation for Unconstrained Handwritten Document Images Using Neighborhood Connected Component Analysis",
        "abstract": "",
        "year": 2009,
        "venue": "Pattern Recognition and Machine Intelligence",
        "authors": [
          {
            "authorId": "2997348",
            "name": "Abhishek Khandelwal"
          },
          {
            "authorId": "2065766664",
            "name": "P. Choudhury"
          },
          {
            "authorId": "35846271",
            "name": "R. Sarkar"
          },
          {
            "authorId": "145096292",
            "name": "Subhadip Basu"
          },
          {
            "authorId": "1729425",
            "name": "M. Nasipuri"
          },
          {
            "authorId": "1723341",
            "name": "N. Das"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 4,
        "unique_cited_count": 4,
        "influential_count": 0,
        "detailed_records_count": 4
      },
      "cited_papers": [
        "9187881",
        "60062262",
        "16993962",
        "1308491"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1308491,
          "isinfluential": false,
          "contexts": [
            "A novel technique using hypothetical water flows at specific angles from both sides of the document image for text line extraction is described in [11]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line extraction from multi-skewed handwritten documents",
            "abstract": "",
            "year": 2008,
            "venue": "Cybersecurity and Cyberforensics Conference",
            "authors": [
              {
                "authorId": "2064966924",
                "name": "Jiang Yong"
              },
              {
                "authorId": "2285625299",
                "name": "Xiaojing Chen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": false,
          "contexts": [
            "A technique described in [10] uses density estimation and level set methods for text line extraction."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16993962,
          "isinfluential": false,
          "contexts": [
            "Smearing methods include the Fuzzy RLSA [ 4 ], in which the value of each pixel is the sum of all pixels in the original image within a specified horizontal distance."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line separation for complex document images using fuzzy runlength",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 60062262,
          "isinfluential": false,
          "contexts": [
            "These methods vary in the set of points considered for voting procedure, viz. gravity centers [1] or minima points [2] of the connected components."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A natural learning algorithm based on Hough transform for text lines extraction in handwritten documents",
            "abstract": "",
            "year": 1999,
            "venue": "",
            "authors": [
              {
                "authorId": "2139654987",
                "name": "Yao Pu"
              },
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              }
            ]
          }
        }
      ]
    },
    "12794208": {
      "citing_paper_info": {
        "title": "Southeast Asian palm leaf manuscript images: a review of handwritten text line segmentation methods and new challenges",
        "abstract": "",
        "year": 2016,
        "venue": "J. Electronic Imaging",
        "authors": [
          {
            "authorId": "2154407",
            "name": "M. W. A. Kesiman"
          },
          {
            "authorId": "8700325",
            "name": "Dona Valy"
          },
          {
            "authorId": "8700325",
            "name": "Dona Valy"
          },
          {
            "authorId": "1690398",
            "name": "J. Burie"
          },
          {
            "authorId": "39662991",
            "name": "E. Paulus"
          },
          {
            "authorId": "66618054",
            "name": "I. M. G. Sunarya"
          },
          {
            "authorId": "8714538",
            "name": "S. Hadi"
          },
          {
            "authorId": "8716633",
            "name": "Kimheng Sok"
          },
          {
            "authorId": "1695766",
            "name": "J. Ogier"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 3,
        "unique_cited_count": 3,
        "influential_count": 2,
        "detailed_records_count": 3
      },
      "cited_papers": [
        "10232002",
        "22207418",
        "11057710"
      ],
      "citation_details": [
        {
          "citedcorpusid": 10232002,
          "isinfluential": true,
          "contexts": [
            "The ALCM method was proposed by Shi et al.(7) This method is considered a transform-based method and can be applied directly on grayscale images.",
            "3.3 Adaptive Local Connectivity Map Method The ALCM method was proposed by Shi et al.7 This method is considered a transform-based method and can be applied directly on grayscale images.",
            "Some methods for text line or character segmentation directly applied to grayscale images have already been proposed.(4,7,16,17) A survey of text line segmentation methods for historical documents is given in Ref."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text extraction from gray scale historical document images using adaptive local connectivity map",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1800513",
                "name": "Srirangaraj Setlur"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11057710,
          "isinfluential": false,
          "contexts": [
            "Second, as comparison with a more complete seam carving scheme, we also evaluated the seam carving method that is implemented by Arvanitopoulos and Susstrunk.(24) In their implementation, the medial seams are first computed based on the projection profile matching approach.",
            "Second, as comparison with a more complete seam carving scheme, we also evaluated the seam carving method that is implemented by Arvanitopoulos and Susstrunk.24 In their implementation, the medial seams are first computed based on the projection profile matching approach.",
            "A new approach for text line segmentation based on the seam carving method that works directly on grayscale document images has been also proposed.(24,26) In this method, two types of seams are calculated: the medial seams and separating seams."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Seam Carving for Text Line Extraction on Color and Grayscale Historical Manuscripts",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2965236",
                "name": "Nikolaos Arvanitopoulos"
              },
              {
                "authorId": "1735035",
                "name": "S. Süsstrunk"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22207418,
          "isinfluential": true,
          "contexts": [
            "3.1 Adaptive Partial Projection Line Segmentation Approach\nThe APP line segmentation approach was proposed by Chamchong and Fung.21 It is an improved technique from their previous work22 in which they adapted modified partial projection and smoothed the histogram with recursion.",
            "The APP line segmentation approach was proposed by Chamchong and Fung.(21) It is an improved technique from their previous work(22) in which they adapted modified partial projection and smoothed the histogram with recursion."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Extraction Using Adaptive Partial Projection for Palm Leaf Manuscripts from Thailand",
            "abstract": "",
            "year": 2012,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "1722160",
                "name": "R. Chamchong"
              },
              {
                "authorId": "1866074",
                "name": "L. Fung"
              }
            ]
          }
        }
      ]
    },
    "3885996": {
      "citing_paper_info": {
        "title": "Text line segmentation of multilingual handwritten documents using fourier approximation",
        "abstract": "",
        "year": 2017,
        "venue": "International Conference on Intelligent Information Processing",
        "authors": [
          {
            "authorId": "47879101",
            "name": "Vishal Chavan"
          },
          {
            "authorId": "39476278",
            "name": "Kapil Mehrotra"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 6,
        "influential_count": 0,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "13396787",
        "9712378",
        "45222320",
        "7130275",
        "14196680",
        "33685302"
      ],
      "citation_details": [
        {
          "citedcorpusid": 7130275,
          "isinfluential": false,
          "contexts": [
            "In order to evaluate the performance of the proposed method, we used the dataset of ICDAR Handwritten Segmentation contest 2013[8].",
            "We have evaluated on acceptance threshold [8] T a = 95% for text line segmentation."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ICFHR 2010 Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9712378,
          "isinfluential": false,
          "contexts": [
            "Another approach [6] requires an initiation of parameters based on script under processing which makes it script-dependent which is a big limitation."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Line detection and segmentation in historical church registers",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2834467",
                "name": "Markus Feldbach"
              },
              {
                "authorId": "145967589",
                "name": "Klaus D. Tönnies"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13396787,
          "isinfluential": false,
          "contexts": [
            "43 ILSP (SoA)[10] 2685 2546 96."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Handwritten document image segmentation into text lines and words",
            "abstract": "",
            "year": 2010,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "1799540",
                "name": "Themos Stafylakis"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              },
              {
                "authorId": "143978280",
                "name": "G. Carayannis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14196680,
          "isinfluential": false,
          "contexts": [
            "NCSR (SoA)[9] 2646 2447 92."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Text line and word segmentation of handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33685302,
          "isinfluential": false,
          "contexts": [
            "In other approach[7], the method first generates a Fringe Map of binarized image and then, PFNs between adjacent lines are filtered out in vertical direction based on a certain threshold."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Two-stage hybrid binarization around fringe map based text line segmentation for document images",
            "abstract": "",
            "year": 2012,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "35129473",
                "name": "Saumya Jetley"
              },
              {
                "authorId": "2191480",
                "name": "S. Belhe"
              },
              {
                "authorId": "3197140",
                "name": "V. K. Koppula"
              },
              {
                "authorId": "1728262",
                "name": "A. Negi"
              }
            ]
          }
        },
        {
          "citedcorpusid": 45222320,
          "isinfluential": false,
          "contexts": [
            "The global horizontal projection approach [2], [3] is not directly useful for handwritten documents because it fails to deal with irregular skew, curved and fluctuating lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Persian cursive script recognition",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "143879523",
                "name": "M. Hashemi"
              },
              {
                "authorId": "50500504",
                "name": "O. Fatemi"
              },
              {
                "authorId": "7175485",
                "name": "R. Safavi"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "The global horizontal projection approach [2], [3] is not directly useful for handwritten documents because it fails to deal with irregular skew, curved and ﬂuctuating lines.",
            "A more advanced algorithm [4], [1] use method called piece-wise projection proﬁle where document is divided into vertical strips and valleys of smoothed horizontal projection proﬁle is considered as separation points of lines."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "14657110": {
      "citing_paper_info": {
        "title": "Using Fringe Maps for Text Line Segmentation in Printed or Handwritten Document Images",
        "abstract": "",
        "year": 2010,
        "venue": "2010 Second Vaagdevi International Conference on Information Technology for Real World Problems",
        "authors": [
          {
            "authorId": "3197140",
            "name": "V. K. Koppula"
          },
          {
            "authorId": "1728262",
            "name": "A. Negi"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 3,
        "unique_cited_count": 3,
        "influential_count": 0,
        "detailed_records_count": 3
      },
      "cited_papers": [
        "23676466",
        "13750607",
        "123358012"
      ],
      "citation_details": [
        {
          "citedcorpusid": 13750607,
          "isinfluential": false,
          "contexts": [
            "Analyzing the heights of the water reservoirs obtained from different components of the document, the width of a stripe is calculated [4, 5].",
            "The top-down approaches also have the disadvantage that they cannot process complex non-Manhattan layouts."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwriting segmentation of unconstrained Oriya text",
            "abstract": "",
            "year": 2004,
            "venue": "Ninth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "6504614",
                "name": "N. Tripathy"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 23676466,
          "isinfluential": false,
          "contexts": [
            "Section V presents results and comparison of proposed and previous methods on line segmentation\nII.",
            "Hence variations in spacing due to skew and complexity of the documents this algorithm results split and merge errors.",
            "Most of the old books in the Digital Library of India (http://www.new.dli.ernet.in) were typeset by hand using primitive techniques and show such examples."
          ],
          "intents": [
            "['result']",
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Robust Text Line, Word And Character Extraction from Telugu Document Image",
            "abstract": "Designing an OCR system for Indian languages in general is more complex than those of European languages due the linguistic complexity. Efforts are on the way for the development of efficient OCR systems for Indian languages, especially for Telugu, a popular South Indian language. In this paper, we proposed a method for reliable extraction of text line, word and character from document images of Telugu scripts. In the text line segmentation, first we establish the relationship between the connected components and then cluster the connected components of a line using vertical spatial relation and nearest neighbor algorithm. In word segmentation, the space between two adjacent characters is computed and clustered into word space and character space. Consonant and vowel modifiers are segregated from the word image and segment the characters.",
            "year": 2009,
            "venue": "2009 Second International Conference on Emerging Trends in Engineering & Technology",
            "authors": [
              {
                "authorId": "3197140",
                "name": "V. K. Koppula"
              },
              {
                "authorId": "1728262",
                "name": "A. Negi"
              },
              {
                "authorId": "1804457",
                "name": "Utpal Garain"
              }
            ]
          }
        },
        {
          "citedcorpusid": 123358012,
          "isinfluential": false,
          "contexts": [
            "Connected component based methods [1 ,7] and smearing method [1, 8] also do not do so well for these documents.",
            "3., where the direction of interest is in the vertical direction.",
            "A pixel with a fringe number x is surrounded by at least (x-1) white pixels in all directions."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "The Fringe Distance Measure: An Easily Calculated Image Distance Measure with Recognition Results Comparable to Gaussian Blurring",
            "abstract": "A fast simple distance measure for calculating the degree of dissimilarity between binary images is presented. The new distance measure, called the fringe distance, gives the same degree of distortion tolerance as optimized Gaussian blurring, but can be calculated much more rapidly. Template matching using the fringe distance executes about six times as fast as Gaussian blurring template matching on an IBM AT with coprocessor, and more than three times as fast on a SUN SPARCStation I with floating point accelerator. The greater speed means more templates can be used in process time limited applications, increasing recognition accuracy. >",
            "year": 1994,
            "venue": "IEEE Transactions on Systems, Man & Cybernetics. Systems",
            "authors": [
              {
                "authorId": "144186345",
                "name": "R. Brown"
              }
            ]
          }
        }
      ]
    },
    "9187881": {
      "citing_paper_info": {
        "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
        "abstract": "",
        "year": 2008,
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "authors": [
          {
            "authorId": "2153682487",
            "name": "Yi Li"
          },
          {
            "authorId": "2145273401",
            "name": "Yefeng Zheng"
          },
          {
            "authorId": "48471936",
            "name": "D. Doermann"
          },
          {
            "authorId": "2251174782",
            "name": "Stefan Jaeger"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 12,
        "unique_cited_count": 12,
        "influential_count": 1,
        "detailed_records_count": 12
      },
      "cited_papers": [
        "13750607",
        "7272464",
        "41609314",
        "2530196",
        "9384346",
        "7391071",
        "263866852",
        "2641242",
        "22995244",
        "3356036",
        "2026530",
        "233005125"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2026530,
          "isinfluential": false,
          "contexts": [
            "Results show that our algorithm elegantly degrades under noise and noise reduction and text restoration [29], [30], [31] are helpful but are beyond the scope of our paper."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Quality assessment and restoration of typewritten document images",
            "abstract": "",
            "year": 1999,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "47947838",
                "name": "M. Cannon"
              },
              {
                "authorId": "144530706",
                "name": "J. Hochberg"
              },
              {
                "authorId": "35206821",
                "name": "P. Kelly"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2530196,
          "isinfluential": false,
          "contexts": [
            "Projection-based methods [3] may be one of the most successful top-down algorithms for machine printed documents.",
            "[3] builds a structural tree that represents the document"
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A prototype document image analysis system for technical journals",
            "abstract": "",
            "year": 1992,
            "venue": "Computer",
            "authors": [
              {
                "authorId": "145916951",
                "name": "G. Nagy"
              },
              {
                "authorId": "145062511",
                "name": "S. Seth"
              },
              {
                "authorId": "145266621",
                "name": "M. Viswanathan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2641242,
          "isinfluential": false,
          "contexts": [
            "The performance of connected componentbased methods on a handwritten document can also be improved by estimating the local orientation of the text line and using it to guide the merging of connected components [2].",
            "In the bottom-up approach, connected component-based methods [2], [11] merge neighboring connected components by using rules based on the geometric relationship between neighboring blocks, such as distance, overlap, and size compatibility."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "DOCLIB: a software library for document processing",
            "abstract": "",
            "year": 2006,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "144230620",
                "name": "Stefan Jaeger"
              },
              {
                "authorId": "2114036784",
                "name": "Guangyu Zhu"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2152955082",
                "name": "Kevin Chen"
              },
              {
                "authorId": "2537908",
                "name": "S. Sampat"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3356036,
          "isinfluential": false,
          "contexts": [
            "To segment a document at a specified level, previous work on machine printed document analysis relies on the homogeneity inside a region and a significant gap between neighboring regions [9]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Performance Evaluation of Document Structure Extraction Algorithms",
            "abstract": "This paper presents a performance metric for the document structure extraction algorithms by finding the correspondences between detected entities and ground truth. We describe a method for determining an algorithm's optimal tuning parameters. We evaluate a group of document layout analysis algorithms on 1600 images from the UW-III Document Image Database, and the quantitative performance measures in terms of the rates of correct, miss, false, merging, splitting, and spurious detections are reported.",
            "year": 2001,
            "venue": "Computer Vision and Image Understanding",
            "authors": [
              {
                "authorId": "1780258",
                "name": "Jisheng Liang"
              },
              {
                "authorId": "1744200",
                "name": "I. T. Phillips"
              },
              {
                "authorId": "1710238",
                "name": "R. Haralick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7272464,
          "isinfluential": false,
          "contexts": [
            "Preliminary results of the proposed approach were published in our previous conference proceedings [5], [6]."
          ],
          "intents": [
            "['result']"
          ],
          "cited_paper_info": {
            "title": "A New Algorithm for Detecting Text Line in Handwritten Documents",
            "abstract": "Curvilinear text line detection and segmentation in handwritten documents is a significant challenge for handwriting recognition. Given no prior knowledge of script, we model text line detection as an image segmentation problem by enhancing text line structure using a Gaussian window, and adopting the level set method to evolve text line boundaries. Experiments show that the proposed method achieves high accuracy for detecting text lines in both handwritten and machine printed documents with many scripts.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2053348005",
                "name": "S. Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7391071,
          "isinfluential": false,
          "contexts": [
            "…transform of LS initial as follows: f ¼ DIST ðLS À initial Þ À DIST ðLS þ initial Þ; ð9Þ where LS þ initial ðx; yÞ and LS À initial ðx; yÞ represent the regions inside and outside the boundary of LS initial and DIST ðÞ is the distance transform [25] of the respective regions to the boundary."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Sequential Operations in Digital Picture Processing",
            "abstract": "",
            "year": 1966,
            "venue": "JACM",
            "authors": [
              {
                "authorId": "143766793",
                "name": "A. Rosenfeld"
              },
              {
                "authorId": "2585707",
                "name": "J. Pfaltz"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9384346,
          "isinfluential": false,
          "contexts": [
            "Isotropic kernels are frequently used if no domain-specific prior is given [22]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Pattern Classification",
            "abstract": "",
            "year": 2012,
            "venue": "Springer London",
            "authors": [
              {
                "authorId": "35674406",
                "name": "Shigeo Abe DrEng"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13750607,
          "isinfluential": false,
          "contexts": [
            "Tripathy and Pal [15] proposed a method of dividing the image into multiple columns by using a projection-based method in each column and combining the results of adjacent columns into a longer text line."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting segmentation of unconstrained Oriya text",
            "abstract": "",
            "year": 2004,
            "venue": "Ninth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "6504614",
                "name": "N. Tripathy"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22995244,
          "isinfluential": true,
          "contexts": [
            "(b) Text line segmentation result of (a) using the Docstrum method [1] by using bounding boxes.",
            "The illustration of the collision. fragmented pieces can easily be linked to obtain the final text lines by using a rule-based approach similar to [1].",
            "1 shows the segmentation results of the Docstrum algorithm [1], a well-known layout analysis algorithm, on a machine-printed document and a freestyle handwritten document."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The Document Spectrum for Page Layout Analysis",
            "abstract": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >",
            "year": 1993,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1398550688",
                "name": "L. O'Gorman"
              }
            ]
          }
        },
        {
          "citedcorpusid": 41609314,
          "isinfluential": false,
          "contexts": [
            "It can be used in many problems such as deskewing [12]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A robust and fast skew detection algorithm for generic documents",
            "abstract": "",
            "year": 1996,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "2116415943",
                "name": "B. Yu"
              },
              {
                "authorId": "145295484",
                "name": "Anil K. Jain"
              }
            ]
          }
        },
        {
          "citedcorpusid": 233005125,
          "isinfluential": false,
          "contexts": [
            "Binarize PDFest to obtain initial estimates LSinitial by using the Niblack algorithm [24].",
            "adaptive thresholding (such as the Niblack method [24])"
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An Introduction to Digital Image Processing",
            "abstract": "Digital image processing is the process of manipulating images by computer with the purpose of improving image quality or extracting useful information. This chapter collects basic concepts and terminology necessary to understand the fundamentals of the ﬁeld. Topics discussed are: classiﬁcation of operations in image processing, digitisation, linear ﬁltering, enhancement, restoration, mathematical morphology, segmentation, representation, description and measurement",
            "year": 1998,
            "venue": "",
            "authors": [
              {
                "authorId": "144968753",
                "name": "J. Roerdink"
              }
            ]
          }
        },
        {
          "citedcorpusid": 263866852,
          "isinfluential": false,
          "contexts": [
            "A more efficient implementation with the fast marching methods [32] may significantly speed up the algorithm."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Level Set Methods and Fast Marching Methods: Evolving Interfaces in Computational Geometry, Fluid Mechanics, Computer Vision, and Materials Science (2nd edition)",
            "abstract": "",
            "year": 2000,
            "venue": "",
            "authors": [
              {
                "authorId": "2240303039",
                "name": "Alex M. Andrew"
              }
            ]
          }
        }
      ]
    },
    "13278043": {
      "citing_paper_info": {
        "title": "Fringe Map Based Text Line Segmentation of Printed Telugu Document Images",
        "abstract": "",
        "year": 2011,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "3197140",
            "name": "V. K. Koppula"
          },
          {
            "authorId": "1728262",
            "name": "A. Negi"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 0,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "23676466",
        "5397715",
        "14657110",
        "12577949",
        "17388229"
      ],
      "citation_details": [
        {
          "citedcorpusid": 5397715,
          "isinfluential": false,
          "contexts": [
            "Fringe maps were first used in Telugu OCR to recognize characters [5].",
            "Negi et al [5] used RLSA based method for text line extraction with vertical and horizontal thresholds to extract words."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An OCR system for Telugu",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1728262",
                "name": "A. Negi"
              },
              {
                "authorId": "1716502",
                "name": "C. Bhagvati"
              },
              {
                "authorId": "107998684",
                "name": "B. Krishna"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12577949,
          "isinfluential": false,
          "contexts": [
            ", a combination of a basic consonant with consonant modifiers and/or vowel modifiers [1], [2], [3].",
            "In our previous work [3] we proposed a generic method using fringe maps for segmentation of text lines using a window approach."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Localization, extraction and recognition of text in Telugu document images",
            "abstract": "",
            "year": 2003,
            "venue": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "1728262",
                "name": "A. Negi"
              },
              {
                "authorId": "2071840065",
                "name": "K. Shanker"
              },
              {
                "authorId": "2386565",
                "name": "Chandra Kanth Chereddi"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14657110,
          "isinfluential": false,
          "contexts": [
            "In our recent work we introduced the concept of fringe maps with application to text line segmentation [10]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Using Fringe Maps for Text Line Segmentation in Printed or Handwritten Document Images",
            "abstract": "",
            "year": 2010,
            "venue": "2010 Second Vaagdevi International Conference on Information Technology for Real World Problems",
            "authors": [
              {
                "authorId": "3197140",
                "name": "V. K. Koppula"
              },
              {
                "authorId": "1728262",
                "name": "A. Negi"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17388229,
          "isinfluential": false,
          "contexts": [
            "The methods for other Indic scripts such Tripathy and Pal, also Pal and Datta [7], [8] used piece-wise projection method in text line segmentation.",
            "Analysis of ”water reservoirs” obtained from different components of the document is used to find the width of a stripe [8]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Bangla unconstrained handwritten text",
            "abstract": "",
            "year": 2003,
            "venue": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "52511272",
                "name": "S. Datta"
              }
            ]
          }
        },
        {
          "citedcorpusid": 23676466,
          "isinfluential": false,
          "contexts": [
            "Koppula et al [6] proposed an approach that uses distance metrics between connected components for text line extraction in Telugu documents."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Robust Text Line, Word And Character Extraction from Telugu Document Image",
            "abstract": "Designing an OCR system for Indian languages in general is more complex than those of European languages due the linguistic complexity. Efforts are on the way for the development of efficient OCR systems for Indian languages, especially for Telugu, a popular South Indian language. In this paper, we proposed a method for reliable extraction of text line, word and character from document images of Telugu scripts. In the text line segmentation, first we establish the relationship between the connected components and then cluster the connected components of a line using vertical spatial relation and nearest neighbor algorithm. In word segmentation, the space between two adjacent characters is computed and clustered into word space and character space. Consonant and vowel modifiers are segregated from the word image and segment the characters.",
            "year": 2009,
            "venue": "2009 Second International Conference on Emerging Trends in Engineering & Technology",
            "authors": [
              {
                "authorId": "3197140",
                "name": "V. K. Koppula"
              },
              {
                "authorId": "1728262",
                "name": "A. Negi"
              },
              {
                "authorId": "1804457",
                "name": "Utpal Garain"
              }
            ]
          }
        }
      ]
    },
    "61942274": {
      "citing_paper_info": {
        "title": "An algorithm for Text Line Segmentation in Handwritten Skewed and Overlapped Devanagari Script",
        "abstract": "Text line segmentation is a very crucial step in optical character recognition. Poor line segmentation leads to wrong results in recognition. In printed text, line segmentation is quite easy but in handwritten text, it is quite difficult due to problems like overlapping, touching of characters and also due to different writing style of a writer. In this paper we have discussed a new algorithm that can perform line segmentation in handwritten text. This algorithm mainly deals with skewed text but also with overlapping and touching of characters. This algorithm is based on projection profile technique. We have applied this algorithm on many of document images and it has given promising results.",
        "year": 2014,
        "venue": "",
        "authors": [
          {
            "authorId": "145203564",
            "name": "Rahul Garg"
          },
          {
            "authorId": "2515617",
            "name": "N. Garg"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 1,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "250868",
        "14210437",
        "14374753",
        "16358887",
        "18725667"
      ],
      "citation_details": [
        {
          "citedcorpusid": 250868,
          "isinfluential": false,
          "contexts": [
            "In [7], a graph model is used that describes the possible locations for segmenting neighbouring characters, and then an average longest path algorithm is applied to identify the globally optimal segmentation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten text segmentation using average longest path algorithm",
            "abstract": "",
            "year": 2013,
            "venue": "2013 IEEE Workshop on Applications of Computer Vision (WACV)",
            "authors": [
              {
                "authorId": "2968009",
                "name": "D. Salvi"
              },
              {
                "authorId": "2151549514",
                "name": "Jun Zhou"
              },
              {
                "authorId": "32655613",
                "name": "Jarrell W. Waggoner"
              },
              {
                "authorId": "40696794",
                "name": "Song Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14210437,
          "isinfluential": false,
          "contexts": [
            "In [6], the text line detection method based on Hough transform for unconstrained handwritten text is used."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Block-Based Hough Transform Mapping for Text Line Detection in Handwritten Documents",
            "abstract": "In this paper, we present a new text line detection method for unconstrained handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes preprocessing for image enhancement, connected component extraction and average character height estimation. In the second step, a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible false alarms. The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "70602633",
                "name": "K. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14374753,
          "isinfluential": true,
          "contexts": [
            "Handwritten Hindi text recognition is an important area of Optical Character Recognition (OCR) [1].",
            "The various existing handwritten text line segmentation methods can be categorized as projection profile based, Hough transform based method, smearing, grouping, graph based, and many more[1].",
            "Projection profile methods are based on top-down algorithms which are one of the most successful methods in machine printed text [1]."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A New Method for Line Segmentation of Handwritten Hindi Text",
            "abstract": "",
            "year": 2010,
            "venue": "2010 Seventh International Conference on Information Technology: New Generations",
            "authors": [
              {
                "authorId": "2515617",
                "name": "N. Garg"
              },
              {
                "authorId": "3257647",
                "name": "L. Kaur"
              },
              {
                "authorId": "35495324",
                "name": "M. Jindal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16358887,
          "isinfluential": false,
          "contexts": [
            "In [12], a piecewise painting technique is proposed for line segmentation in unconstrained handwritten text."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Piece-wise painting technique for line segmentation of unconstrained handwritten text: a specific study with Persian text documents",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Analysis and Applications",
            "authors": [
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18725667,
          "isinfluential": false,
          "contexts": [
            "Jindal et al. [9], have worked on recognition of degraded printed Gurumukhi script."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "On Segmentation of Touching Characters and Overlapping Lines in Degraded Printed Gurmukhi Script",
            "abstract": "Character segmentation plays a very important role in a text recognition system. The simple technique of using inter-character gap for segmentation is useful for fine printed documents, but this technique fails to give satisfactory results if the input text contains touching characters. In this paper, we have proposed two algorithms to segment touching characters, and one algorithm to segment overlapping lines in degraded printed Gurmukhi document. Various categories of touching characters in different zones, along with their solutions, have been proposed. The solution methodology extensively uses the structural properties of Gurmukhi script. The algorithm proposed for segmenting horizontally overlapping lines uses a heuristics based upon the height of a character. The problem of multiple horizontally overlapping lines may occur in a number of situations such as printed newspapers, old magazines and books etc. Similarity among Indian scripts allows us to use these algorithms for solving the segmentation problems in other Indian languages also.",
            "year": 2009,
            "venue": "International Journal of Image and Graphics",
            "authors": [
              {
                "authorId": "35495324",
                "name": "M. Jindal"
              },
              {
                "authorId": "7209654",
                "name": "Gurpreet Singh Lehal"
              },
              {
                "authorId": "33407984",
                "name": "R. Sharma"
              }
            ]
          }
        }
      ]
    },
    "222222501": {
      "citing_paper_info": {
        "title": "A Novel Simplified Approach for Text Line Extraction of Handwritten Malayalam Document",
        "abstract": "This paper presents a novel and simple method for extracting individual lines from handwritten Malayalam documents.The challenge involved in text line extraction of handwritten document is segmentation of touching lines. As far as Malayalam language is considered, symbols like chandrakkala will be classified into separate line due to the small gap between the Malayalam alphabet and the symbol chandrakkala. This paper addresses the possibility of touching lines and misclassification of character like chandrakkala into a separate line. In the proposed method, the scanned handwritten document is divided into vertical stripes. Using horizontal projection method lines are extracted in each vertical stripe separately. Touching lines, segmentation of character like chandrakkala into separate line and extra lines due to noise are addressed using the median values of the height of lines in each vertical stripe separately. The handwritten document image is divided into vertical stripes prior to line segmentation to account for the possibility of skewed lines. When the document is divided into vertical stripe, the characters will be cut in between. This paper also presents a solution to join the characters cut in between when the document is divided into vertical stripes. This is done by compensating for the distance of characters from the top of the line at the joining edge of the vertical stripe.",
        "year": 2020,
        "venue": "2020 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA)",
        "authors": [
          {
            "authorId": "9432779",
            "name": "P. Pearlsy"
          },
          {
            "authorId": "40446857",
            "name": "D. Sankar"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 4,
        "unique_cited_count": 4,
        "influential_count": 0,
        "detailed_records_count": 4
      },
      "cited_papers": [
        "14307584",
        "54442925",
        "13750607",
        "3409693"
      ],
      "citation_details": [
        {
          "citedcorpusid": 3409693,
          "isinfluential": false,
          "contexts": [
            "Languages like English [1], Chinese [2] and Arabic [3] has a well developed OCR."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Offline Chinese handwriting recognition: an assessment of current technology",
            "abstract": "",
            "year": 2007,
            "venue": "Frontiers of Computer Science in China",
            "authors": [
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              },
              {
                "authorId": "1985392",
                "name": "Xuanshen Yang"
              },
              {
                "authorId": "34366451",
                "name": "G. R. Ball"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13750607,
          "isinfluential": false,
          "contexts": [
            "Techniques for performing line segmentation, word segmentation and character segmentation for Oriya text is proposed in [6]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting segmentation of unconstrained Oriya text",
            "abstract": "",
            "year": 2004,
            "venue": "Ninth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "6504614",
                "name": "N. Tripathy"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14307584,
          "isinfluential": false,
          "contexts": [
            "Text line extraction using water flow approach was proposed in [7]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line extraction from multi-skewed handwritten documents",
            "abstract": "",
            "year": 2007,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "145096292",
                "name": "Subhadip Basu"
              },
              {
                "authorId": "2004266",
                "name": "C. Chaudhuri"
              },
              {
                "authorId": "143995288",
                "name": "M. Kundu"
              },
              {
                "authorId": "1729425",
                "name": "M. Nasipuri"
              },
              {
                "authorId": "143701816",
                "name": "D. K. Basu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 54442925,
          "isinfluential": false,
          "contexts": [
            "Contour detection was used in [5] to perform line segmentation for handwritten Malayalam document."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Novel Approach for Handwriting Recognition in Malayalam Manuscripts using Contour Detection and Convolutional Neural Nets",
            "abstract": "Neural Networks is a hot area of research for various kind of pattern recognition. Hand writing recognition is a domain coming under the field of pattern recognition which had captured a high research interest during the last 10 years. It is a complex process mainly due to the huge character set, complexity and similarity of Malayalam letters. Our project aims to digitalize Malayalam handwritten text from Malayalam manuscripts like palm leafs, official documents in Government offices etc. An intensive literature survey was conducted on the various methods of handwriting recognition in various languages to find a best suitable approach for digitalizing Malayalam language. A novel approach to digitalize Malayalam manuscripts using contour detection for segmentation and Convolutional Neural Network for classification was proposed. The system was trained using the samples collected from museums and a neural network is constructed for character identification. According to the results obtained the system is proved to have less overhead without compromising the accuracy.",
            "year": 2018,
            "venue": "International Conference on Advances in Computing, Communications and Informatics",
            "authors": [
              {
                "authorId": "2779207",
                "name": "Dhanya Sudarsan"
              },
              {
                "authorId": "52177991",
                "name": "Shelbi Joseph"
              }
            ]
          }
        }
      ]
    },
    "4766619": {
      "citing_paper_info": {
        "title": "A Robust and Binarization-Free Approach for Text Line Detection in Historical Documents",
        "abstract": "",
        "year": 2017,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "40585315",
            "name": "Tobias Grüning"
          },
          {
            "authorId": "1680083",
            "name": "Gundram Leifert"
          },
          {
            "authorId": "40508719",
            "name": "Tobias Strauß"
          },
          {
            "authorId": "1736181",
            "name": "R. Labahn"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 10,
        "unique_cited_count": 10,
        "influential_count": 2,
        "detailed_records_count": 10
      },
      "cited_papers": [
        "174065",
        "14209826",
        "15257932",
        "7194635",
        "14606536",
        "2123198",
        "11057710",
        "2430892",
        "639755",
        "5934826"
      ],
      "citation_details": [
        {
          "citedcorpusid": 174065,
          "isinfluential": false,
          "contexts": [
            ", FAST [20], Difference of Gaussians [23], SIFT [23], MSER [24].",
            "There are various different possibilities for the calculation of meaningful SPs, e.g., FAST [20], Difference of Gaussians [23], SIFT [23], MSER [24]."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Distinctive Image Features from Scale-Invariant Keypoints",
            "abstract": "",
            "year": 2004,
            "venue": "International Journal of Computer Vision",
            "authors": [
              {
                "authorId": "35238678",
                "name": "D. Lowe"
              }
            ]
          }
        },
        {
          "citedcorpusid": 639755,
          "isinfluential": true,
          "contexts": [
            "Although efforts are made to develop systems working solely on the rough input image without any a priori segmentation [8], the widely used standard approach is a pipeline of segmenting the input image first and performing HTR\nor KWS on the segmented image snippets second.",
            "All competitive results published for HTR and KWS within the last years do not work on the character level.",
            "Nowadays peformance of state-of-theart systems reaches character error rates below 10% for HTR [6] and mean average precisions above 0.9 for KWS [7].",
            "Since 2009, tremendous progress in the field of Handwritten Text Recognition (HTR) [1], [2] and Keyword Spotting (KWS) [3]–[5] was achieved."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks",
            "abstract": "Ofﬂine handwriting recognition—the automatic transcription of images of hand-written text—is a challenging task that combines computer vision with sequence learning. In most systems the two elements are handled separately, with sophisticated preprocessing techniques used to extract the image features and sequential models such as HMMs used to provide the transcriptions. By combining two recent innovations in neural networks—multidimensional recurrent neural networks and connectionist temporal classiﬁcation—this paper introduces a globally trained ofﬂine handwriting recogniser that takes raw pixel data as input. Unlike competing systems, it does not require any alphabet speciﬁc preprocessing, and can therefore be used unchanged for any language. Evidence of its generality and power is provided by data from a recent international Arabic recognition competition, where it outperformed all entries (91.4% accuracy compared to 87.2% for the competition winner) despite the fact that neither author understands a word of Arabic.",
            "year": 2008,
            "venue": "Neural Information Processing Systems",
            "authors": [
              {
                "authorId": "2251771699",
                "name": "Alex Graves"
              },
              {
                "authorId": "2252220989",
                "name": "Jürgen Schmidhuber"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2123198,
          "isinfluential": false,
          "contexts": [
            "For these datasets the evaluation scheme of [26] was applied.",
            "Note, this is a brute force approach, since a pixel hit rate above 95% is needed for a text line match [26], there is still room for improvement."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "144429596",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "2265885161",
                "name": "Umapada Pal"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2430892,
          "isinfluential": false,
          "contexts": [
            "over all possible labelings {sp}p∈P (interline spacing sp is assigned to the SP p) using [25] leads to the result depicted in Fig.",
            "Therefore, we utilize a well-known algorithm for energy minimization [25] to smooth the noisy result."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Fast approximate energy minimization via graph cuts",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of the Seventh IEEE International Conference on Computer Vision",
            "authors": [
              {
                "authorId": "1692688",
                "name": "Yuri Boykov"
              },
              {
                "authorId": "1922280",
                "name": "Olga Veksler"
              },
              {
                "authorId": "2984143",
                "name": "R. Zabih"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5934826,
          "isinfluential": false,
          "contexts": [
            "This approach do not stuck on an initial “coarse” clustering [14] neither on connected component based statistics [12] nor on an expert tuned parametrization [11], which makes it applicable without any adaption in various different scenarios (Sec.",
            "text blocks and simple layouts [9], [13], [15], [16], stick on the results of a binarization [12], [14] or rely on an expert tuned parametrization [10], [11].",
            "Binarization, which is a prior step to many text line detection algorithms [12], [14], [19], sometimes tends to fail for complex documents and results in hardly correctable errors."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Detection for Heterogeneous Documents",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1706090",
                "name": "Robert Sablatnig"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7194635,
          "isinfluential": false,
          "contexts": [
            "[29] (8686) our 8692 8615 99."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Corpus-based HIT-MW database for offline recognition of general-purpose Chinese handwritten text",
            "abstract": "",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "40523977",
                "name": "Tonghua Su"
              },
              {
                "authorId": "1821107",
                "name": "Tianwen Zhang"
              },
              {
                "authorId": "2438618",
                "name": "D. Guan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11057710,
          "isinfluential": false,
          "contexts": [
            "Furthermore, we will employ the ideas of [13], [15] to use dynamic programming to allow for a better cluster removal.",
            "In [9], [13], [15] the principle of dynamic programming is utilized to calculate cost optimal paths passing the image from left to right to separate different text lines from each other.",
            "text blocks and simple layouts [9], [13], [15], [16], stick on the results of a binarization [12], [14] or rely on an expert tuned parametrization [10], [11]."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Seam Carving for Text Line Extraction on Color and Grayscale Historical Manuscripts",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2965236",
                "name": "Nikolaos Arvanitopoulos"
              },
              {
                "authorId": "1735035",
                "name": "S. Süsstrunk"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14209826,
          "isinfluential": false,
          "contexts": [
            "Furthermore, we will employ the ideas of [13], [15] to use dynamic programming to allow for a better cluster removal.",
            "In [9], [13], [15] the principle of dynamic programming is utilized to calculate cost optimal paths passing the image from left to right to separate different text lines from each other.",
            "text blocks and simple layouts [9], [13], [15], [16], stick on the results of a binarization [12], [14] or rely on an expert tuned parametrization [10], [11]."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line extraction for historical document images",
            "abstract": "",
            "year": 2014,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "1741845",
                "name": "Raid Saabni"
              },
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14606536,
          "isinfluential": true,
          "contexts": [
            "To estimate s for each p ∈ P , we orient ourselves towards [19].",
            "Binarization, which is a prior step to many text line detection algorithms [12], [14], [19], sometimes tends to fail for complex documents and results in hardly correctable errors.",
            "Unlike [19] we encode the energy Ep( d k ) of the interline spacing d k for SP p by",
            "Following [19] we define the data cost for each SP p ∈ P with assigned interline spacing sp by",
            "cmax(N ) is the maximum connectivity value of all edges, P (Ci) is the polynom of degree 3 fitting best the SPs of Ci (with a normalized regression error of curve(Ci) [19], this value encodes the curvilinearity) and dist(p, P (Ci)) is the distance of p to P (Ci) taking only into account the component orthogonal to the text direction (θ = 0), see Fig."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text-Line Detection in Camera-Captured Document Images Using the State Estimation of Connected Components",
            "abstract": "",
            "year": 2016,
            "venue": "IEEE Transactions on Image Processing",
            "authors": [
              {
                "authorId": "2463454",
                "name": "H. Koo"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15257932,
          "isinfluential": false,
          "contexts": [
            "In a second step we utilize the idea of smearing from [10].",
            "[10] calculate adaptive local connectivity maps (ALCMs) by convolving the gray scale input image with steerable filters of different orientations.",
            "text blocks and simple layouts [9], [13], [15], [16], stick on the results of a binarization [12], [14] or rely on an expert tuned parametrization [10], [11]."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition A Steerable Directional Local Profile Technique for Extraction of Handwritten Arabic Text Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        }
      ]
    },
    "268571010": {
      "citing_paper_info": {
        "title": "An overview of statistical and neural-based line segmentation methods for offline handwriting recognition task",
        "abstract": "The object of the research is the line segmentation task. To recognize the handwritten text from the documents in image format offline handwriting recognition technology is used. The text recognizer module accepts input as separate lines, so one of the important preprocessing steps is the detection and splitting of all handwritten text into distinct lines.\nIn this paper, the handwritten text line segmentation task, its requirements, problems, and challenges are examined. Two main approaches for this task that are used in modern recognition systems are reviewed. These approaches are statistical projection-based methods and neural-based methods. Multiple works and research papers for each type of approach are reviewed analyzing their strengths and weaknesses considering the described tasks, constraints, and input data peculiarities. Overall acquired results are formed in a single table for comparison. \nBased on the latest works that utilize deep neural networks the new possibilities of using these methods in recognition systems are described that were unavailable with traditional statistical segmentation approaches.\nThe constructive conclusions are made based on the review, describing the main pros and cons of these two approaches for the line segmentation task. These results can be further used for the correct selection of suitable methods in handwriting recognition systems to improve their performance and quality, and for further research in this area.",
        "year": 2024,
        "venue": "Technology audit and production reserves",
        "authors": [
          {
            "authorId": "1520034802",
            "name": "Oleg Yakovchuk"
          },
          {
            "authorId": "66835828",
            "name": "W. Rogoza"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 1,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "1889158",
        "221916483",
        "261282154",
        "10834729",
        "28662025"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1889158,
          "isinfluential": false,
          "contexts": [
            "In the literature, one can observe that text lines are defined either as their baseline [4], as their bounding box [5], as the set of pixels corresponding to their handwritten components [6], or as the area corresponding to the core of the text without parts of ascenders and descenders, also called…",
            "One of the first proposals was the combination of a Multi-Dimensional Long-short Term Memory (MDLSTM) neural network combined with convolutional layers to predict a bounding box around the line, contributed in [5]."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Paragraph text segmentation into lines with Recurrent Neural Networks",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "144899680",
                "name": "Christian Wolf"
              },
              {
                "authorId": "2373952",
                "name": "J. Louradour"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10834729,
          "isinfluential": false,
          "contexts": [
            "The method described in [9] was tested on 300 images containing 7201 lines.",
            "To divide the lines into individual regions, an intensity threshold is chosen based on maximum projection concentrations: the more pixels are projected to the same axis point, the more probability to have a text line on this horizontal level [9]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A statistical approach to line segmentation in handwritten documents",
            "abstract": "",
            "year": 2007,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "2066310463",
                "name": "M. Arivazhagan"
              },
              {
                "authorId": "2334238",
                "name": "H. Srinivasan"
              },
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              }
            ]
          }
        },
        {
          "citedcorpusid": 28662025,
          "isinfluential": false,
          "contexts": [
            "Notably, that threshold dynamic calculation increases the algorithm’s overall complexity [10].",
            "The proposed algorithm from [10] was evaluated on specific unconstrained handwritten Polish documents that contain both ordinary images and more difficult images in terms of text line segmentation."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Projection–Based Text Line Segmentation with a Variable Threshold",
            "abstract": "Abstract Document image segmentation into text lines is one of the stages in unconstrained handwritten document recognition. This paper presents a new algorithm for text line separation in handwriting. The developed algorithm is based on a method using the projection profile. It employs thresholding, but the threshold value is variable. This permits determination of low or overlapping peaks of the graph. The proposed technique is shown to improve the recognition rate relative to traditional methods. The algorithm is robust in text line detection with respect to different text line lengths.",
            "year": 2017,
            "venue": "International Journal of Applied Mathematics and Computer Sciences",
            "authors": [
              {
                "authorId": "31739585",
                "name": "R. Ptak"
              },
              {
                "authorId": "10009081",
                "name": "Bartosz Zygadlo"
              },
              {
                "authorId": "1682586",
                "name": "O. Unold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 221916483,
          "isinfluential": false,
          "contexts": [
            "For example, documents with formulas should be split into separate lines with individual formulas in each line, considering that a single formula can consist of multiple levels with frac elements [7]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Methods for Lines and Matrices Segmentation in RNN-based Online Handwriting Mathematical Expression Recognition Systems",
            "abstract": "Modern applications for handwritten mathematical expressions recognition are not limited to single expression input and rather provide the possibility to input several expressions at once, complex elements such as equation systems and matrices, and also support edit modifications. In this paper, we examine segmentation of mathematical expressions and present new techniques: multi-line segmentation method using special Dynamic Threshold Distance and matrix segmentation method based on projection profiling modification. The proposed methods are used for the preliminary structure analysis and utilize only geometrical features of the input strokes, therefore they can be used at the first stage of the recognition workflow. By incorporating these methods into our recognition system we make it possible to recognize multi-line expressions and matrices. The evaluation of the segmentation itself and overall recognition accuracy is performed using open benchmark CROHME datasets and in-house datasets and for matrices it demonstrates segmentation success rate 93.66% on CROHME2016. The proposed methods can be applied for other applications such as analysis of handwritten document layout, tables and charts recognition.",
            "year": 2020,
            "venue": "International Conference on Data Stream Mining & Processing",
            "authors": [
              {
                "authorId": "1520034802",
                "name": "Oleg Yakovchuk"
              },
              {
                "authorId": "1519978765",
                "name": "Anastasiia Cherneha"
              },
              {
                "authorId": "133868426",
                "name": "D. Zhelezniakov"
              },
              {
                "authorId": "2067165027",
                "name": "V. Zaytsev"
              }
            ]
          }
        },
        {
          "citedcorpusid": 261282154,
          "isinfluential": true,
          "contexts": [
            "Compared to older work [14] that is based on a similar approach without the additional mode, the F-score = 65 % is really lower, but the time cost = 0.8 sec is almost three times faster."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Robust Text Detection in Natural Scene Images",
            "abstract": "",
            "year": 2016,
            "venue": "Australasian Conference on Artificial Intelligence",
            "authors": [
              {
                "authorId": "8982801",
                "name": "Van Pham"
              },
              {
                "authorId": "144096223",
                "name": "Gueesang Lee"
              }
            ]
          }
        }
      ]
    },
    "236378949": {
      "citing_paper_info": {
        "title": "Segmentation of text lines using multi-scale CNN from warped printed and handwritten document images",
        "abstract": "",
        "year": 2021,
        "venue": "International Journal on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "3001843",
            "name": "Arpita Dutta"
          },
          {
            "authorId": "51375033",
            "name": "Arpan Garai"
          },
          {
            "authorId": "2150473161",
            "name": "Samit Biswas"
          },
          {
            "authorId": "152167018",
            "name": "A. Das"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 13,
        "unique_cited_count": 13,
        "influential_count": 1,
        "detailed_records_count": 13
      },
      "cited_papers": [
        "208788041",
        "16958669",
        "14935721",
        "10232002",
        "208023057",
        "18915038",
        "15257932",
        "59683040",
        "29394502",
        "14124313",
        "2070419",
        "1779661",
        "6906729"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1779661,
          "isinfluential": false,
          "contexts": [
            "Inspired by various kinds of deep learning approaches [26], we have explored those methods to develop our algorithm and decided that the multi-scale encoder-decoder-based convolutional neural network (CNN) would be the best choice to tackle our problem."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Deep Learning",
            "abstract": "",
            "year": 2016,
            "venue": "International Journal of Semantic Computing",
            "authors": [
              {
                "authorId": "2343609447",
                "name": "Xingbang Hao"
              },
              {
                "authorId": "8273966",
                "name": "Guigang Zhang"
              },
              {
                "authorId": "2118869556",
                "name": "Shang Ma"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2070419,
          "isinfluential": false,
          "contexts": [
            "al [19] Pyraloidea dataset Projection Profile Handwritten"
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "User-assisted archive document image analysis for digital library construction",
            "abstract": "",
            "year": 2003,
            "venue": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "2219747383",
                "name": "Jingyu He"
              },
              {
                "authorId": "1798094",
                "name": "A. Downton"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6906729,
          "isinfluential": false,
          "contexts": [
            "Several methods for line segmentation were proposed in [5,24,28,40,41,48], etc. Table 1 gives a brief description of previous state-of-the-art techniques."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "User-assisted alignment of Arabic historical manuscripts",
            "abstract": "",
            "year": 2011,
            "venue": "The Hip",
            "authors": [
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10232002,
          "isinfluential": false,
          "contexts": [
            "Several methods for line segmentation were proposed in [5,24,28,40,41,48], etc. Table 1 gives a brief description of previous state-of-the-art techniques."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text extraction from gray scale historical document images using adaptive local connectivity map",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1800513",
                "name": "Srirangaraj Setlur"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14124313,
          "isinfluential": false,
          "contexts": [
            "Though deep learning-based methods have been used in several computer vision applications [25,51], application of these methods in text-line segmentation has not been fully explored."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
            "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.",
            "year": 2014,
            "venue": "International Conference on Learning Representations",
            "authors": [
              {
                "authorId": "34838386",
                "name": "K. Simonyan"
              },
              {
                "authorId": "1688869",
                "name": "Andrew Zisserman"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14935721,
          "isinfluential": false,
          "contexts": [
            "[8] proposed a method that used a set of line filters."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text-Line Extraction Using a Convolution of Isotropic Gaussian Filter with a Set of Line Filters",
            "abstract": "",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "145461897",
                "name": "S. S. Bukhari"
              },
              {
                "authorId": "1688013",
                "name": "F. Shafait"
              },
              {
                "authorId": "1733858",
                "name": "T. Breuel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15257932,
          "isinfluential": false,
          "contexts": [
            "[49] proposed methods based on RXY cuts [39] and smearing, respectively."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition A Steerable Directional Local Profile Technique for Extraction of Handwritten Arabic Text Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 16958669,
          "isinfluential": false,
          "contexts": [
            "[18] proposed a novel approach for segmentation of text lines from historical document images based on vertical lines and connected components."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Historical Handwritten Documents into Text Zones and Text Lines",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18915038,
          "isinfluential": false,
          "contexts": [
            "Most of the text-line detection schemes relied on analysis of projection proﬁle [4,52,57] or proﬁle generated through Hough transform [32]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A robust text detection algorithm in images and video frames",
            "abstract": "",
            "year": 2003,
            "venue": "Fourth International Conference on Information, Communications and Signal Processing, 2003 and the Fourth Pacific Rim Conference on Multimedia. Proceedings of the 2003 Joint",
            "authors": [
              {
                "authorId": "1694936",
                "name": "Qixiang Ye"
              },
              {
                "authorId": "101001846",
                "name": "Wen Gao"
              },
              {
                "authorId": "2109080279",
                "name": "Weiqiang Wang"
              },
              {
                "authorId": "144424265",
                "name": "Wei Zeng"
              }
            ]
          }
        },
        {
          "citedcorpusid": 29394502,
          "isinfluential": false,
          "contexts": [
            "[34–36 ,38] used deep learning-based"
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Learning Text-Line Localization with Shared and Local Regression Neural Networks",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2373952",
                "name": "J. Louradour"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "144899680",
                "name": "Christian Wolf"
              }
            ]
          }
        },
        {
          "citedcorpusid": 59683040,
          "isinfluential": false,
          "contexts": [
            "He and Downton [19] and Shi et al. [49] proposed methods based on RXY cuts [39] and smearing, respectively."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "HIERARCHICAL REPRESENTATION OF OPTICALLY SCANNED DOCUMENTS",
            "abstract": "",
            "year": 1984,
            "venue": "",
            "authors": [
              {
                "authorId": "145916951",
                "name": "G. Nagy"
              },
              {
                "authorId": "145062511",
                "name": "S. Seth"
              }
            ]
          }
        },
        {
          "citedcorpusid": 208023057,
          "isinfluential": false,
          "contexts": [
            "[50] utilized the skeletons of the connected components of the text region for line segmentation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Laplacian Approach to Multi-Oriented Text Detection in Video. IEEE Trans",
            "abstract": "",
            "year": 2011,
            "venue": "",
            "authors": [
              {
                "authorId": "46188384",
                "name": "Shivakumara Palaiahnakote"
              }
            ]
          }
        },
        {
          "citedcorpusid": 208788041,
          "isinfluential": true,
          "contexts": [
            "Inter-esting results have also been obtained on various kinds of publicly available benchmark datasets such as IUPR dataset [9], Tobacco-800 dataset [55], ICDAR 2013 Handwritten Segmentation Contest [53] dataset, and cBAD datasets [10].",
            "(a) Printed Document Images Figure 10 shows the outputs of the proposed method tested on printed English document images from Tobacco-800 dataset [55] and IUPR dataset [9].",
            "Tobacco-800 dataset [55] contains a total of 800 scanned printed English document images [27].",
            "They are (i) IUPR dataset [9], (ii) Tobacco-800 dataset [55], (ii) ICDAR 2013 Handwritten Segmentation Contest [53] dataset and (iv) cBAD datasets [10]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Tobacco",
            "abstract": "",
            "year": 1993,
            "venue": "The Lancet",
            "authors": [
              {
                "authorId": "2074979867",
                "name": "C. Bullock"
              }
            ]
          }
        }
      ]
    },
    "253018178": {
      "citing_paper_info": {
        "title": "Line Segmentation of Tibetan Ancient Books Based on A* Algorithm",
        "abstract": "Line segmentation is an important step in image character recognition. However, due to the problems of interline adhesion, overlapping, and skewing of document images, the effect of text line segmentation is not ideal. Therefore, further research on image line segmentation of Tibetan ancient books is urgently needed. The standard A* algorithm is not ideal for line segmentation of Tibetan ancient books, so this paper proposes a block-based A* algorithm for line segmentation of Tibetan ancient books. The method firstly preprocesses the image such as binarization and tilt correction and then performs horizontal projection. The obtained horizontal projection histogram is subjected to smoothing and peak detection to determine the position and number of text lines. Use the peak value to find the core area of the image text, extract the upper vowel and perform line attribution. Then, the image after removing the upper vowel is divided into 7 blocks, and each block is processed separately by the A* algorithm. When the algorithm finds the text line segmentation path, five cost functions are selected to calculate the cost from the starting point to the endpoint of the line segmentation, and the minimum cost path is found for text line segmentation. Finally, merge the segmented text lines, attribute the upper vowels, and rotate the text lines to obtain the final text line segmentation result. Experimental results show that our methos can effectively deal with the problems of text line adhesion and overlap, and achieve a good effect on text line segmentation.",
        "year": 2022,
        "venue": "Journal of Physics: Conference Series",
        "authors": [
          {
            "authorId": "9244976",
            "name": "Huaming Liu"
          },
          {
            "authorId": "2149894694",
            "name": "Rumeng Shi"
          },
          {
            "authorId": "9255457",
            "name": "Xuehui Bi"
          },
          {
            "authorId": "31772353",
            "name": "Xiuyou Wang"
          },
          {
            "authorId": "2254980",
            "name": "Weilan Wang"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 5,
        "influential_count": 0,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "27494128",
        "229036427",
        "228102342",
        "53214848",
        "222127578"
      ],
      "citation_details": [
        {
          "citedcorpusid": 27494128,
          "isinfluential": false,
          "contexts": [
            "References [17-18] use fully convolutional networks for line segmentation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Text Line Segmentation Using Fully Convolutional Network",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "47689382",
                "name": "G. Renton"
              },
              {
                "authorId": "1712446",
                "name": "Clément Chatelain"
              },
              {
                "authorId": "143680806",
                "name": "Sébastien Adam"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 53214848,
          "isinfluential": false,
          "contexts": [
            "[2] proposed a segmentation method of historical Tibetan literature text lines based on connected component analysis."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Research on Text Line Segmentation of Historical Tibetan Documents Based on the Connected Component Analysis",
            "abstract": "",
            "year": 2018,
            "venue": "Chinese Conference on Pattern Recognition and Computer Vision",
            "authors": [
              {
                "authorId": "2108941572",
                "name": "Yiqun Wang"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              },
              {
                "authorId": "49970018",
                "name": "Zhenjiang Li"
              },
              {
                "authorId": "51481292",
                "name": "Yuehui Han"
              },
              {
                "authorId": "2115451526",
                "name": "Xiaojuan Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 222127578,
          "isinfluential": false,
          "contexts": [
            "References [17-18] use fully convolutional networks for line segmentation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line Segmentation of Handwritten Text Using Histograms and Tensor Voting",
            "abstract": "Abstract There are a large number of historical documents in libraries and other archives throughout the world. Most of them are written by hand. In many cases they exist in only one specimen and are hard to reach. Digitization of such artifacts can make them available to the community. But even digitized, they remain unsearchable, and an important task is to draw the contents in the computer readable form. One of the first steps in this direction is to recognize where the lines of the text are. Computational intelligence algorithms can be used to solve this problem. In the present paper, two groups of algorithms, namely, projection-based and tensor voting-based, are compared. The performance is evaluated on a data set and with the procedure proposed by the organizers of the ICDAR 2009 competition.",
            "year": 2020,
            "venue": "International Journal of Applied Mathematics and Computer Sciences",
            "authors": [
              {
                "authorId": "2702308",
                "name": "T. Babczynski"
              },
              {
                "authorId": "31739585",
                "name": "R. Ptak"
              }
            ]
          }
        },
        {
          "citedcorpusid": 228102342,
          "isinfluential": false,
          "contexts": [
            "[20] proposed a learning-free text line segmentation method for historical handwritten documents."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Learning-Free Text Line Segmentation for Historical Handwritten Documents",
            "abstract": "We present a learning-free method for text line segmentation of historical handwritten document images. This method relies on automatic scale selection together with second derivative of anisotropic Gaussian filters to detect the blob lines that strike through the text lines. Detected blob lines guide an energy minimization procedure to extract the text lines. Historical handwritten documents contain noise, heterogeneous text line heights, skews and touching characters among text lines. Automatic scale selection allows for automatic adaption to the heterogeneous nature of handwritten text lines in case the character height range is correctly estimated. In the extraction phase, the method can accurately split the touching characters among the text lines. We provide results investigating various settings and compare the model with recent learning-free and learning-based methods on the cBAD competition dataset.",
            "year": 2020,
            "venue": "Applied Sciences",
            "authors": [
              {
                "authorId": "2126299723",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "51037361",
                "name": "Rafi Cohen"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 229036427,
          "isinfluential": false,
          "contexts": [
            "References [7-8] propose a line segmentation method for Tibetan historical documents that combines local baselines and connected components."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation based on local baselines and connected component centroids for Tibetan historical documents",
            "abstract": "Text line segmentation is one of the key contents in document image analysis and recognition. Due to the complex situation of text images in Tibetan historical document, such as the coexistence of slanting and distortion of text lines, especially the adhesion between lines, text line segmentation has become a challenging task. In this paper, a new method of text segmentation for Tibetan historical document is proposed. This method first obtains the local baseline information of the text line, and then performs the detection and segmentation of the adhesion area. Finally, according to the barycentre coordinates of the connected component and the local baseline information, each connected component is assigned to the corresponding text line. The method avoids the effect of text line distortion on the segmentation of the stuck text line and greatly reduces the error rate of the adhesion text line segmentation and can effectively deal with the segmentation of slanted and distorted Tibetan sticky text lines.",
            "year": 2020,
            "venue": "Journal of Physics: Conference Series",
            "authors": [
              {
                "authorId": "2067770685",
                "name": "Pengfei Hu"
              },
              {
                "authorId": "2144355950",
                "name": "Yang Chen"
              },
              {
                "authorId": "1574182682",
                "name": "Yusheng Hao"
              },
              {
                "authorId": "2108941572",
                "name": "Yiqun Wang"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Li Yanxing [6] proposed a line segmentation method based on baseline estimation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "61696402": {
      "citing_paper_info": {
        "title": "Text Line Segmentation With Water Flow Algorithm Based on Power Function",
        "abstract": "",
        "year": 2015,
        "venue": "",
        "authors": [
          {
            "authorId": "2008869",
            "name": "D. Brodic"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 5,
        "influential_count": 3,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "17135581",
        "8543445",
        "9187881",
        "2775421",
        "14314155"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2775421,
          "isinfluential": false,
          "contexts": [
            "The water flow angle α is set to 14◦ [42]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "A New Approach to Water Flow Algorithm for Text Line Segmentation",
            "abstract": "This paper proposes a new approach to water flow algorithm for the text line segmentation. Original method assumes hypothetical water flows under a few specified angles to the document image frame from left to right and vice versa. As a result, unwetted image frames are extracted. These areas are of major importance for text line segmentation. Method modifications mean extension values of water flow angle and unwetted image frames function enlargement. Results are encouraging due to text line segmentation improvement which is the most challenging process stage in document image processing.",
            "year": 2011,
            "venue": "Journal of universal computer science (Online)",
            "authors": [
              {
                "authorId": "2008869",
                "name": "D. Brodic"
              },
              {
                "authorId": "2393591",
                "name": "Z. Milivojevic"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8543445,
          "isinfluential": false,
          "contexts": [
            "where Dth is given by any local binarization method [23–26]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Adaptive document image binarization",
            "abstract": "",
            "year": 2000,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1704694",
                "name": "J. Sauvola"
              },
              {
                "authorId": "145962204",
                "name": "M. Pietikäinen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": true,
          "contexts": [
            "Although text line segmentation for machine or hand printed documents is usually seen as a solved problem [4], freestyle handwritten text line segmentation still remains an open research field [1–3].",
            "Nevertheless, it provides the essential information for the consecutive steps such as skew correction, zone segmentation, and character recognition [3].",
            "Hence, it is a leading challenge in document analysis [2–3].",
            "Different methods that belong to this group has been proposed [3, 12–14]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14314155,
          "isinfluential": false,
          "contexts": [
            "where Dth is given by any local binarization method [23–26]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An introduction to digital image processing",
            "abstract": "",
            "year": 1990,
            "venue": "",
            "authors": [
              {
                "authorId": "2245243916",
                "name": "Geoffrey A. McKinley"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17135581,
          "isinfluential": true,
          "contexts": [
            "The variance evaluation is given RMSE [34, 35]",
            "Typical values of ε that correspond to the chosen values of skew angle β are those from the set {1/12, 1/6, 1/4, 1/3} [34, 35].",
            "The water flow angle α is set to 14◦ [21,35].",
            "Furthermore, the RMSEseg follow this trend by obtaining minimal values.",
            "Hence, it takes value from the set {5◦, 10◦, 15◦, 20◦} [34, 35].",
            "A sample of the initial binary document image [35] Fig.",
            "Hence, it receives value from the set {5◦, 10◦, 15◦, 20◦} [34, 35].",
            "The variance evaluation is given RMSE [34, 35]\nRMSEseg =\n√ √ √ √ 1\nN\nN ∑\ni=1\n(Oi,ref −Oi,est)2 , (13)\nwhere N is the total number of lines in the reference sample text, Oi,ref is the number of reference objects in the text line i (equal to 1 for each line), and Oi,est is is the number of detected objects in the text line i .",
            "To evaluate the algorithm’s efficiency the following elements are introduced:\n• segmentation line hit rate, ie SLHR,\n• over-segmentation line hit rate, ie OSLHR,\n• under-segmentation line hit rate, ie USLHR,\n• mixed line hit rate, ie MLHR, and\n• segmentation root mean square error, ie RMSEseg .",
            "Experiments framework for the evaluation of algorithm’s text line segmentation consists of the following tests [34, 35]: • multi-line straight text segmentation test, • multi-line waved text segmentation test, • multi-line fractured text segmentation test, • handwritten text segmentation test [36].",
            "The minimum value of RMSEseg confirms it."
          ],
          "intents": [
            "--",
            "['background']",
            "--",
            "--",
            "--",
            "['background']",
            "--",
            "--",
            "--",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation in Images of Handwritten Historical Documents",
            "abstract": "",
            "year": 2008,
            "venue": "2008 First Workshops on Image Processing Theory, Tools and Applications",
            "authors": [
              {
                "authorId": "144837322",
                "name": "A. Sanchez"
              },
              {
                "authorId": "144889138",
                "name": "P. D. Suárez"
              },
              {
                "authorId": "1846903",
                "name": "C. Mello"
              },
              {
                "authorId": "2216183040",
                "name": "A.L.I. Oliveira"
              },
              {
                "authorId": "143755164",
                "name": "V. Alves"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "At present, the conflict occurs between the two alignments [17]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": true,
          "contexts": [
            "The variance evaluation is given RMSE [34, 35]",
            "Typical values of ε that correspond to the chosen values of skew angle β are those from the set {1/12, 1/6, 1/4, 1/3} [34, 35].",
            "Furthermore, the RMSEseg follow this trend by obtaining minimal values.",
            "Hence, it takes value from the set {5◦, 10◦, 15◦, 20◦} [34, 35].",
            "Hence, it receives value from the set {5◦, 10◦, 15◦, 20◦} [34, 35].",
            "The variance evaluation is given RMSE [34, 35]\nRMSEseg =\n√ √ √ √ 1\nN\nN ∑\ni=1\n(Oi,ref −Oi,est)2 , (13)\nwhere N is the total number of lines in the reference sample text, Oi,ref is the number of reference objects in the text line i (equal to 1 for each line), and Oi,est is is the number of detected objects in the text line i .",
            "To evaluate the algorithm’s efficiency the following elements are introduced:\n• segmentation line hit rate, ie SLHR,\n• over-segmentation line hit rate, ie OSLHR,\n• under-segmentation line hit rate, ie USLHR,\n• mixed line hit rate, ie MLHR, and\n• segmentation root mean square error, ie RMSEseg .",
            "Experiments framework for the evaluation of algorithm’s text line segmentation consists of the following tests [34, 35]: • multi-line straight text segmentation test, • multi-line waved text segmentation test, • multi-line fractured text segmentation test, • handwritten text segmentation test [36].",
            "The minimum value of RMSEseg confirms it."
          ],
          "intents": [
            "--",
            "['background']",
            "--",
            "--",
            "--",
            "--",
            "--",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "56598011": {
      "citing_paper_info": {
        "title": "A Hybrid Method for Text Line Extraction in Handwritten Document Images",
        "abstract": "Text line segmentation in handwritten document image, as one of the preliminarily steps for document image recognition, is a challenging problem. In this paper, a hybrid method for text line extraction in handwritten document images is presented. Initially, a connected component (CC) labelling method following by a CC filtering is employed to extract a set of CCs from the input document image. A new distance measure is introduced to compute normal distances between the extracted CCs. By traversing the normal distance matrix from both the right and left directions, half-chains of CCs are constructed. The CCs half-chains are merged to obtain CCs full-chains. From the extracted full-chains separator lines are obtained. A gradient metric is proposed to detect and remove touching text lines. Using remaining separator lines the adaptive projection profile of the image is computed. Based on the projection profile, coarse text line extraction is performed. Finally, a fine text lines extraction is performed by applying a postprocessing step. To evaluate the method, two benchmarks named ICDAR2013 handwriting segmentation contest, and Kannada datasets composed of handwritten document images in English, Greek, Bengali, and Kannada languages were considered for experimentation. Experimental results indicate a promising performance was obtained compared to some of the state-of-the-art methods.",
        "year": 2018,
        "venue": "International Conference on Frontiers in Handwriting Recognition",
        "authors": [
          {
            "authorId": "52424260",
            "name": "Ehsan Kiumarsi"
          },
          {
            "authorId": "1971318",
            "name": "Alireza Alaei"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 8,
        "unique_cited_count": 8,
        "influential_count": 1,
        "detailed_records_count": 8
      },
      "cited_papers": [
        "4651364",
        "43027422",
        "53850504",
        "13396787",
        "16503365",
        "10834729",
        "2123198",
        "17844687"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2123198,
          "isinfluential": true,
          "contexts": [
            "To evaluate the proposed text line extraction method a benchmark dataset composed of 350 handwritten document images was considered for experimentation [13].",
            "Table I provides a comparative analysis of the results obtained from the test data used in [13].",
            "COMPARISON OF THE RESULTS OBTAINED FROM THE PROPOSED METHOD WITH SOME OF THE RESULTS REPORTED IN [13]",
            "The proposed method was first tested on 150 test document images used in [13].",
            "32% for DR, RA and FM were obtained on the ICDAR 2013 test dataset [13], respectively.",
            "Evaluation metrics used in the literature [13] were considered to compute the accuracy of the proposed text line extraction method."
          ],
          "intents": [
            "['methodology']",
            "['result']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "144429596",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "2265885161",
                "name": "Umapada Pal"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4651364,
          "isinfluential": false,
          "contexts": [
            "There are various methods presented in the literature to tackle the problem of text line segmentation in handwritten document images [1-11].",
            "In [6], at the first step a CC labelling technique was employed and distances between CCs were calculated."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Chinese text line segmentation by clustering with distance metric learning",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "145820427",
                "name": "Fei Yin"
              },
              {
                "authorId": "1689269",
                "name": "Cheng-Lin Liu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10834729,
          "isinfluential": false,
          "contexts": [
            "Some researchers have used Gaussian [10] and moving average [11] filters to smooth the projection profile signal.",
            "There are various methods presented in the literature to tackle the problem of text line segmentation in handwritten document images [1-11]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A statistical approach to line segmentation in handwritten documents",
            "abstract": "",
            "year": 2007,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "2066310463",
                "name": "M. Arivazhagan"
              },
              {
                "authorId": "2334238",
                "name": "H. Srinivasan"
              },
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13396787,
          "isinfluential": false,
          "contexts": [
            "In [1], a block-based projection profile method was introduced.",
            "There are various methods presented in the literature to tackle the problem of text line segmentation in handwritten document images [1-11]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten document image segmentation into text lines and words",
            "abstract": "",
            "year": 2010,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "1799540",
                "name": "Themos Stafylakis"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              },
              {
                "authorId": "143978280",
                "name": "G. Carayannis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16503365,
          "isinfluential": false,
          "contexts": [
            "In [3], a document image was initially divided into a number of vertical strips based on the gap between text lines.",
            "There are various methods presented in the literature to tackle the problem of text line segmentation in handwritten document images [1-11]."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A new scheme for unconstrained handwritten text-line segmentation",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17844687,
          "isinfluential": false,
          "contexts": [
            "To evaluate the proposed text line extraction method a benchmark dataset composed of 350 handwritten document images was considered for experimentation [13].",
            "Table I provides a comparative analysis of the results obtained from the test data used in [13].",
            "COMPARISON OF THE RESULTS OBTAINED FROM THE PROPOSED METHOD WITH SOME OF THE RESULTS REPORTED IN [13]",
            "The proposed method was first tested on 150 test document images used in [13].",
            "32% for DR, RA and FM were obtained on the ICDAR 2013 test dataset [13], respectively.",
            "Evaluation metrics used in the literature [13] were considered to compute the accuracy of the proposed text line extraction method."
          ],
          "intents": [
            "['methodology']",
            "['result']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition ICDAR2009 Handwriting Segmentation Contest",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 43027422,
          "isinfluential": false,
          "contexts": [
            "In [5], a hybrid algorithm of Hough transform and grouping method was proposed.",
            "The approach is simple and time complexity is relatively low in simple projection based methods [5].",
            "There are various methods presented in the literature to tackle the problem of text line segmentation in handwritten document images [1-11]."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line detection in handwritten documents",
            "abstract": "",
            "year": 2008,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 53850504,
          "isinfluential": false,
          "contexts": [
            "Otherwise, it is separated using the LAG method in [16]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Automatic recognition of printed music in the context of electronic publishing",
            "abstract": "Computers are used to manipulate music in various forms, for example digital sound recordings, digitized images of printed scores and music representational language (M.R.L.) encodings. This work is concerned with producing M.R.L. data automatically from existing printed music scores. A review of work undertaken in the field of manipulating printed music by computer is provided. This shows that software which permits production of high-quality scores is commercially available, but the necessary data has to be entered using some form of keyboard, possibly in conjunction with a pointing device. It is desirable, for reasons detailed in this work, to be able to convert the musical information contained in the enormous quantity of existing music into computer-readable form. The only practical method for achieving this is via an automatic system. Such an automatic system must cope with the variations in format, content and print-quality of existing scores. Background material relating to previous work on pattern recognition of various types of binary image is included, with a section covering the subject of automatic recognition of printed music. An original system for automatic recognition of printed music developed by the author is described. This is designed to be widely applicable and hence is, in effect, omnifont and size-independent, with significant tolerance of noise, limited rotation, broken print and distortion. Numerous illustrations showing the application of the system are included, together with proposals for future areas of development.",
            "year": 1989,
            "venue": "",
            "authors": [
              {
                "authorId": "2091914757",
                "name": "N. Carter"
              }
            ]
          }
        }
      ]
    },
    "240460736": {
      "citing_paper_info": {
        "title": "An Unsupervised and Robust Line and Word Segmentation Method for Handwritten and Degraded Printed Document",
        "abstract": "Segmentation of text lines and words in an unconstrained handwritten or a machine-printed degraded document is a challenging document analysis problem due to the heterogeneity in the document structure. Often there is un-even skew between the lines and also broken words in a document. In this article, the contribution lies in segmentation of a document page image into lines and words. We have proposed an unsupervised, robust, and simple statistical method to segment a document image that is either handwritten or machine-printed (degraded or otherwise). In our proposed method, the segmentation is treated as a two-class classification problem. The classification is done by considering the distribution of gap size (between lines and between words) in a binary page image. Our method is very simple and easy to implement. Other than the binarization of the input image, no pre-processing is necessary. There is no need of high computational resources. The proposed method is unsupervised in the sense that no annotated document page images are necessary. Thus, the issue of a training database does not arise. In fact, given a document page image, the parameters that are needed for segmentation of text lines and words are learned in an unsupervised manner. We have applied our proposed method on several popular publicly available handwritten and machine-printed datasets (ISIDDI, IAM-Hist, IAM, PBOK) of different Indian and other languages containing different fonts. Several experimental results are presented to show the effectiveness and robustness of our method. We have experimented on ICDAR-2013 handwriting segmentation contest dataset and our method outperforms the winning method. In addition to this, we have suggested a quantitative measure to compute the level of degradation of a document page image.",
        "year": 2021,
        "venue": "ACM Trans. Asian Low Resour. Lang. Inf. Process.",
        "authors": [
          {
            "authorId": "147119639",
            "name": "Jayati Mukherjee"
          },
          {
            "authorId": "1702114",
            "name": "S. K. Parui"
          },
          {
            "authorId": "2059154357",
            "name": "Utpal Roy"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 18,
        "unique_cited_count": 18,
        "influential_count": 3,
        "detailed_records_count": 18
      },
      "cited_papers": [
        "2908640",
        "14894195",
        "12534822",
        "16503365",
        "2908848",
        "16793957",
        "13396787",
        "8835228",
        "16513111",
        "14291778",
        "29622813",
        "7130275",
        "105842646",
        "14683639",
        "43027422",
        "39164368",
        "31517603",
        "49388398"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2908640,
          "isinfluential": true,
          "contexts": [
            "4 % [37] IAM-Hist (Perzival Dataset) Pastor et al.",
            "76% [37] IAM-Hist (Saint Gall Dataset) Pastor et al.",
            "Some of the existing methods are meant only for line segmentation [37, 46], some are only for word segmentation [27, 52].",
            "In another paper [37], a CNN-based line segmentation approach is used."
          ],
          "intents": [
            "--",
            "--",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Complete System for Text Line Extraction Using Convolutional Neural Networks and Watershed Transform",
            "abstract": "",
            "year": 2016,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1403927620",
                "name": "Joan Pastor-Pellicer"
              },
              {
                "authorId": "145181206",
                "name": "Muhammad Zeshan Afzal"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "145816817",
                "name": "María José Castro Bleda"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2908848,
          "isinfluential": false,
          "contexts": [
            "Later on, the algorithm was modified in Reference [43], where the whole document is segmented into vertical strips and the water flow algorithm is applied to these strips."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line Extraction from Unconstraint Handwritten Document Pages using Piece-wise Water-flow Technique",
            "abstract": "To extract the lines from multi-skewed document images of handwritten Bangla or Roman text, a novel technique is described here. In this paper, at first, the document image is partitioned into number of vertical fragments. Then a hypothetical water-flow technique is applied separately in each vertically fragmented portion of the document images, from both left and right sides of the said partition. After identifying the touching segments, separation of the same is done and finally the water-flow technique is applied on the overall document image. The stripes of areas left unwetted on the image frame are finally labelled for extraction of text lines. To test the developed technique, Bangla and Roman scripts are used and the performance of the technique, as observed experimentally, is 95.54% for the document images of the said scripts.",
            "year": 2009,
            "venue": "Indian International Conference on Artificial Intelligence",
            "authors": [
              {
                "authorId": "35846271",
                "name": "R. Sarkar"
              },
              {
                "authorId": "145096292",
                "name": "Subhadip Basu"
              },
              {
                "authorId": "1723341",
                "name": "N. Das"
              },
              {
                "authorId": "1748788",
                "name": "A. F. Mollah"
              },
              {
                "authorId": "143995288",
                "name": "M. Kundu"
              },
              {
                "authorId": "1729425",
                "name": "M. Nasipuri"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7130275,
          "isinfluential": true,
          "contexts": [
            "In Reference [30] the method has been compared with existing standard binarization methods and the result of the method was better than others.",
            "Early works on line and word segmentation based on gap classification include References [36, 49], where gap classification is done mainly by global/local thresholding.",
            "A supervised learning–based gap classification was proposed in Reference [48].",
            "In Reference [44], another modification was proposed to deal mainly with the problem of touching text lines.",
            "Recently, in Reference [14], a hybrid model has been introduced for text line extraction.",
            "• Washington Database [16]: Washington database of IAM-Hist database contains pages written in 1755 by George Washington and his associates in English language.",
            "In Reference [17], a binarization-free line segmentation approach with the help of clustering is proposed.",
            "In Reference [46] the authors have proposed a method for detecting text lines in historical handwritten and printed document images.",
            "Later on, the algorithm was modified in Reference [43], where the whole document is segmented into vertical strips and the water flow algorithm is applied to these strips.",
            "For PBOK dataset the reported line segmentation accuracy on Bengali, Odia, and Kanadda languages are 90.36%, 83.62%, and 95.51%, respectively, in Reference [4].",
            "The gray-level document images are binarized using a modified version of Otsu’s algorithm, proposed in Reference [30].",
            "• Saint Gall Database [15]: The Saint Gall database consists of manuscript images of the hagiography Vita sancti Galli by Walafrid Strabo.",
            "• Perzival Database [16]: The Perzival dataset contains 47 handwritten pages of 13th century middle high German language.",
            "PBOK Database: PBOK dataset [4] is a collection of images of handwritten documents in four different languages: Persian, Bengali, Odia, and Kannada.",
            "Recently, in Reference [42], the gap classification is done by searching for the correlation between the intra-word gaps and inter-word gaps from the local observations on line level.",
            "This database is a benchmarking competition database that contains characteristics such as “difference in the skew angle between text lines or along the same text line, the existence of adjacent text lines or words touching, the existence of characters with different sizes and variable intra-word gaps” as stated in Reference [50].",
            "ICDAR 2013 Database [50]: Handwritten document images in three languages in which two are Latin-based languages (English and Greek) and one in Indian language (Bengali) are there in the dataset of ICDAR2013."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "ICFHR 2010 Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8835228,
          "isinfluential": false,
          "contexts": [
            "Different types of applications such as OCR [5, 10, 13], offline handwritten character recognition [18, 20], key word spotting [21, 25], script identification [31–34], writer identification [19], text separation [8] require segmentation of the document image into its unit components for recognition."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "An architecture for handwritten text recognition systems",
            "abstract": "",
            "year": 1999,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2157691706",
                "name": "Gyeonghwan Kim"
              },
              {
                "authorId": "117208225",
                "name": "Venu Govindaraju"
              },
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12534822,
          "isinfluential": false,
          "contexts": [
            "Another paper [26] has used the concept of connected components labelling."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A scale space approach for automatically segmenting words from historical handwritten documents",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              },
              {
                "authorId": "1845217",
                "name": "Jamie L. Rothfeder"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13396787,
          "isinfluential": false,
          "contexts": [
            "Gap classification is one of the well-known approaches used for segmentation [24, 36, 49].",
            "Early works on line and word segmentation based on gap classification include References [36, 49], where gap classification is done mainly by global/local thresholding."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwritten document image segmentation into text lines and words",
            "abstract": "",
            "year": 2010,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "1799540",
                "name": "Themos Stafylakis"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              },
              {
                "authorId": "143978280",
                "name": "G. Carayannis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14291778,
          "isinfluential": false,
          "contexts": [
            "[27] proposed a word segmentation method that searches for the connected components in a text line by clustering in such a way that each cluster corresponds to one word.",
            "56% [27] IAM (417 Pages forms A,B,C) Zimmerman et al.",
            "Some of the existing methods are meant only for line segmentation [37, 46], some are only for word segmentation [27, 52]."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation and word recognition in a system for general writer independent handwriting recognition",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "37526757",
                "name": "Urs-Viktor Marti"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14683639,
          "isinfluential": false,
          "contexts": [
            "• Saint Gall Database [15]: The Saint Gall database consists of manuscript images of the hagiography Vita sancti Galli by Walafrid Strabo."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Transcription alignment of Latin manuscripts using hidden Markov models",
            "abstract": "",
            "year": 2011,
            "venue": "The Hip",
            "authors": [
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1688695",
                "name": "Volkmar Frinken"
              },
              {
                "authorId": "1686569",
                "name": "A. Fornés"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14894195,
          "isinfluential": false,
          "contexts": [
            "Gap classification is one of the well-known approaches used for segmentation [24, 36, 49].",
            "Early works on line and word segmentation based on gap classification include References [36, 49], where gap classification is done mainly by global/local thresholding."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Robust text-line and word segmentation for handwritten documents images",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "authors": [
              {
                "authorId": "1799540",
                "name": "Themos Stafylakis"
              },
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              },
              {
                "authorId": "143978280",
                "name": "G. Carayannis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16503365,
          "isinfluential": false,
          "contexts": [
            "[3] Line Segmentation This is a smearing-based technique."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A new scheme for unconstrained handwritten text-line segmentation",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16513111,
          "isinfluential": true,
          "contexts": [
            "In Reference [30] the method has been compared with existing standard binarization methods and the result of the method was better than others.",
            "Early works on line and word segmentation based on gap classification include References [36, 49], where gap classification is done mainly by global/local thresholding.",
            "A supervised learning–based gap classification was proposed in Reference [48].",
            "In Reference [44], another modification was proposed to deal mainly with the problem of touching text lines.",
            "Recently, in Reference [14], a hybrid model has been introduced for text line extraction.",
            "In Reference [17], a binarization-free line segmentation approach with the help of clustering is proposed.",
            "In Reference [46] the authors have proposed a method for detecting text lines in historical handwritten and printed document images.",
            "Later on, the algorithm was modified in Reference [43], where the whole document is segmented into vertical strips and the water flow algorithm is applied to these strips.",
            "For PBOK dataset the reported line segmentation accuracy on Bengali, Odia, and Kanadda languages are 90.36%, 83.62%, and 95.51%, respectively, in Reference [4].",
            "The gray-level document images are binarized using a modified version of Otsu’s algorithm, proposed in Reference [30].",
            "[42] Word Segmentation They have treated the problem of word segmentation as a binary classification problem.",
            "Recently, in Reference [42], the gap classification is done by searching for the correlation between the intra-word gaps and inter-word gaps from the local observations on line level.",
            "This database is a benchmarking competition database that contains characteristics such as “difference in the skew angle between text lines or along the same text line, the existence of adjacent text lines or words touching, the existence of characters with different sizes and variable intra-word gaps” as stated in Reference [50]."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "--",
            "['background']",
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Word Segmentation Method for Handwritten Documents based on Structured Learning",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE Signal Processing Letters",
            "authors": [
              {
                "authorId": "2189947",
                "name": "Jewoong Ryu"
              },
              {
                "authorId": "2463454",
                "name": "H. Koo"
              },
              {
                "authorId": "1707645",
                "name": "N. Cho"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16793957,
          "isinfluential": false,
          "contexts": [
            "A supervised learning–based gap classification was proposed in Reference [48]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Arabic Word Spotting using the CEDARABIC Document Analysis System",
            "abstract": "An algorithm and a system for searching handwritten Arabic documents to locate key words is presented. Three main components of the system are a word segmenter, a shape based matcher for words and a search interface. The user types in a query in English within a search window, the system finds the equivalent Arabic word, e.g., by dictionary lookup, locates word images in an indexed (segmented) set of documents. A two-step approach is employed in performing the search: (1) prototype selection: the query is used to obtain a set of handwritten samples of that word from a known set of writers (these are the prototypes), and (2) word matching: the prototypes are used to spot each occurrence of those words in the indexed document database. A ranking is performed on the entire set of test word images– where the ranking criterion is a similarity score between each prototype word and the candidate words based on global word shape features. A database of 20, 000 word images contained in 100 scanned handwritten Arabic documents written by 10 different writers was used to study retrieval performance. Using five writers for providing prototypes and the other five for testing, using manually segmented documents, 55% precision is obtained at 50% recall. Performance increases as more writers are used for training.",
            "year": 2005,
            "venue": "",
            "authors": [
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              },
              {
                "authorId": "2334238",
                "name": "H. Srinivasan"
              },
              {
                "authorId": "144731207",
                "name": "P. Babu"
              },
              {
                "authorId": "2002974",
                "name": "Chetan Bhole"
              }
            ]
          }
        },
        {
          "citedcorpusid": 29622813,
          "isinfluential": false,
          "contexts": [
            "IAMDB: [28] IAM database contains 1,539 scanned pages of 657 writers that are non-degraded handwritten English text."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "The IAM-database: an English sentence database for offline handwriting recognition",
            "abstract": "",
            "year": 2002,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "37526757",
                "name": "Urs-Viktor Marti"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 31517603,
          "isinfluential": false,
          "contexts": [
            "The evaluation tool [39] is used as our evaluation tool."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Empirical Performance Evaluation of Graphics Recognition Systems",
            "abstract": "Presents a methodology for evaluating graphics recognition systems operating on images that contain straight lines, circles, circular arcs, and text blocks. It enables an empirical comparison of vectorization software packages and uses practical performance evaluation methods that can be applied to complete vectorization systems. The methodology includes a set of matching criteria for pairs of graphical entities, a set of performance evaluation metrics, and a benchmark for the evaluation of graphics recognition systems. The benchmark was tested on three systems. The results are reported and analyzed in the paper.",
            "year": 1999,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1744200",
                "name": "I. T. Phillips"
              },
              {
                "authorId": "34817063",
                "name": "A. K. Chhabra"
              }
            ]
          }
        },
        {
          "citedcorpusid": 39164368,
          "isinfluential": false,
          "contexts": [
            "In addition, some methods deal with both line and word segmentation [12, 24].",
            "The horizontal projection method [12, 22] is one of the oldest approaches to line segmentation and is mainly used for segmentation of machine-printed text document images.",
            "The vertical projection method [12, 22] is one of the oldest approaches of word segmentation used mainly for segmentation of machine-printed text document images."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An OCR system to read two Indian language scripts: Bangla and Devnagari (Hindi)",
            "abstract": "",
            "year": 1997,
            "venue": "Proceedings of the Fourth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1759420",
                "name": "B. Chaudhuri"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 43027422,
          "isinfluential": false,
          "contexts": [
            "[23] Line segmentation Their method is based on Hough transformation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line detection in handwritten documents",
            "abstract": "",
            "year": 2008,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 49388398,
          "isinfluential": false,
          "contexts": [
            "Different types of applications such as OCR [5, 10, 13], offline handwritten character recognition [18, 20], key word spotting [21, 25], script identification [31–34], writer identification [19], text separation [8] require segmentation of the document image into its unit components for recognition."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Content Independent Writer Identification on Bangla Script: A Document Level Approach",
            "abstract": "Offline writer identification is one of the major fields of study in behavioral biometric. It is a process of matching a questioned document with other documents of known writers to find the approp...",
            "year": 2018,
            "venue": "International journal of pattern recognition and artificial intelligence",
            "authors": [
              {
                "authorId": "2285164",
                "name": "C. Halder"
              },
              {
                "authorId": "9377086",
                "name": "S. Obaidullah"
              },
              {
                "authorId": "143702038",
                "name": "K. Santosh"
              },
              {
                "authorId": "143915672",
                "name": "K. Roy"
              }
            ]
          }
        },
        {
          "citedcorpusid": 105842646,
          "isinfluential": false,
          "contexts": [
            "Recently, in Reference [14], a hybrid model has been introduced for text line extraction."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A hybrid text line segmentation approach for the ancient handwritten unconstrained freestyle Modi script documents",
            "abstract": "ABSTRACT In this paper a novel approach for the segmentation of text lines in handwritten, unconstrained, and freestyle Modi script document image is presented. The approach is based on the analysis of the gray level thresholding metric to estimate the text region location. True text line locations are estimated and segmented using the estimated text region location. The connected components of each estimated text region are scrutinized to group and calculate the text line region. The approach is recursively applied on the estimated line segments until the individual text lines are not separated. This algorithm handles various type of documents as multi-skewed, non-uniform Shirorekha, variable size characters or text lines, touching and overlapping line segments therefore it is robust. The algorithm is tested and compared using ancient handwritten Modi script documents and the benchmarking freely available online datasets, respectively.",
            "year": 2018,
            "venue": "Imaging Science Journal",
            "authors": [
              {
                "authorId": "2797934",
                "name": "Manisha S. Deshmukh"
              },
              {
                "authorId": "3080531",
                "name": "M. Patil"
              },
              {
                "authorId": "8920918",
                "name": "S. Kolhe"
              }
            ]
          }
        }
      ]
    },
    "14372024": {
      "citing_paper_info": {
        "title": "Content-based text line comparison for historical document retrieval",
        "abstract": "In the historical handwritten document retrieval system that we are currently building, the training data set elements are the images of handwritten lines with the manually made text transcriptions. We apply sequence comparison algorithms to these text transcriptions. We explore several sequence comparison algorithms that have been applied to phonology for their usefulness in solving a problem of retrieving handwritten material. Finding an appropriate method for comparing text lines will allow us to cluster the corresponding images of handwritten lines into training sets. These training sets can then be used for pattern recognition - an important part of the historical handwritten document retrieval system. At first we study the information needs of the users of an archive where the historical documents are stored. Then we explore the longest common substring (LCS), Levenshtein and Jaccard measures for matching the text lines. Taking into account the drawbacks of these methods, we propose to weight the words in the text proportionally to their information content. This weighting is expected to provide results closer to the information needs of users. We evaluate the results in terms of the precision values for k top retrieved text lines. Using the mean precision curves we show that the performance of sequence comparisons increases up to 18% when we use the weighted sequence comparisons.",
        "year": 2007,
        "venue": "",
        "authors": [
          {
            "authorId": "1784334",
            "name": "S. Zinger"
          },
          {
            "authorId": "1806832",
            "name": "J. Nerbonne"
          },
          {
            "authorId": "1799278",
            "name": "Lambert Schomaker"
          },
          {
            "authorId": "65907371",
            "name": "H. Schie"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 4,
        "unique_cited_count": 4,
        "influential_count": 0,
        "detailed_records_count": 4
      },
      "cited_papers": [
        "10856952",
        "18360807",
        "7213481",
        "52800448"
      ],
      "citation_details": [
        {
          "citedcorpusid": 7213481,
          "isinfluential": false,
          "contexts": [
            "To avoid this, we work with entire lines of handwritten text: we divide an image of a handwritten document into lines using its visual features."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Historical documents as monuments and as sources",
            "abstract": "The main functions of a digital library of historical documents are the digital recording of documents, transcriptions and translations of documents, subject indexing, annotation and retrieval. Using such a system, scholars can efficiently study the documents without involvement of the originals, thus ensuring the preservation of documents and the protection of researchers from exposure to potential health hazards. An important part of the study of historical documents consists of classifying the material and annotating it in such a way that retrieval is facilitated in the future. We present the development of a historical document management system that supports both digital library functionality and archival management of the original documents. This system includes semantic indexing and multifaceted classification of historical documents with the use of a built-in thesaurus aimed at attaining satisfactory levels of efficiency of the classification process, completeness and precision of the retrieved information, and user-friendliness.",
            "year": 2002,
            "venue": "",
            "authors": [
              {
                "authorId": "3000550",
                "name": "P. Constantopoulos"
              },
              {
                "authorId": "38587181",
                "name": "M. Doerr"
              },
              {
                "authorId": "2327955",
                "name": "M. Theodoridou"
              },
              {
                "authorId": "69064631",
                "name": "Manolis Tzobanakis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10856952,
          "isinfluential": false,
          "contexts": [
            "Keywords\nSequence comparison, inverse frequency weighting, transcriptions of handwritten text."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Finding Topics in Collections of Documents: A Shared Nearest Neighbor Approach",
            "abstract": "",
            "year": 2003,
            "venue": "Clustering and Information Retrieval",
            "authors": [
              {
                "authorId": "2355878",
                "name": "Levent Ertöz"
              },
              {
                "authorId": "1707756",
                "name": "M. Steinbach"
              },
              {
                "authorId": "2107978833",
                "name": "Vipin Kumar"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18360807,
          "isinfluential": false,
          "contexts": [
            "Keywords\nSequence comparison, inverse frequency weighting, transcriptions of handwritten text."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Search engine for handwritten documents",
            "abstract": "",
            "year": 2005,
            "venue": "IS&T/SPIE Electronic Imaging",
            "authors": [
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              },
              {
                "authorId": "2150607464",
                "name": "Chen Huang"
              },
              {
                "authorId": "2334238",
                "name": "H. Srinivasan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 52800448,
          "isinfluential": false,
          "contexts": [
            "There are several thousands of emails, mostly\nin English and Dutch, received by the Nationaal Archief since the year 2001 till the present time."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Book Reviews: Foundations of Statistical Natural Language Processing",
            "abstract": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications.",
            "year": 1999,
            "venue": "International Conference on Computational Logic",
            "authors": [
              {
                "authorId": "144783904",
                "name": "Christopher D. Manning"
              },
              {
                "authorId": "144418438",
                "name": "Hinrich Schütze"
              }
            ]
          }
        }
      ]
    },
    "49416265": {
      "citing_paper_info": {
        "title": "Manuscript Text Line Detection and Segmentation Using Second-Order Derivatives",
        "abstract": "",
        "year": 2018,
        "venue": "International Workshop on Document Analysis Systems",
        "authors": [
          {
            "authorId": "1763464",
            "name": "David Aldavert"
          },
          {
            "authorId": "143823474",
            "name": "Marçal Rusiñol"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 8,
        "unique_cited_count": 8,
        "influential_count": 0,
        "detailed_records_count": 8
      },
      "cited_papers": [
        "11929620",
        "16167028",
        "2908640",
        "36363181",
        "15257932",
        "15793605",
        "39577325",
        "25040774"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2908640,
          "isinfluential": false,
          "contexts": [
            "Recently, some authors use a learning based methods to detect image regions where text lines are likely to appear [12], [13]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Complete System for Text Line Extraction Using Convolutional Neural Networks and Watershed Transform",
            "abstract": "",
            "year": 2016,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1403927620",
                "name": "Joan Pastor-Pellicer"
              },
              {
                "authorId": "145181206",
                "name": "Muhammad Zeshan Afzal"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "145816817",
                "name": "María José Castro Bleda"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11929620,
          "isinfluential": false,
          "contexts": [
            "Although this is a computationally expensive approach, it allows to obtain the scale parameter automatically and is efficiently computed by employing a spatial pyramid and recursive Gaussian filters [17] that present a computational cost that is independent of the size of the Gaussian."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Recursive Gaussian derivative filters",
            "abstract": "",
            "year": 1998,
            "venue": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)",
            "authors": [
              {
                "authorId": "1729533",
                "name": "L. Vliet"
              },
              {
                "authorId": "145664902",
                "name": "I. Young"
              },
              {
                "authorId": "1708475",
                "name": "P. Verbeek"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15257932,
          "isinfluential": false,
          "contexts": [
            "7% Rectangle [29], [28] – – 96."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition A Steerable Directional Local Profile Technique for Extraction of Handwritten Arabic Text Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 15793605,
          "isinfluential": false,
          "contexts": [
            "The projection profile approach [6], [7] is based on projecting the document pixels which are relevant (detected through binarization for example) into the Y -axis of the image."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Document image analysis for World War II personal records",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              },
              {
                "authorId": "1694974",
                "name": "Dimosthenis Karatzas"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16167028,
          "isinfluential": false,
          "contexts": [
            "1% Hough [27], [22] 94."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Text line detection in handwritten documents",
            "abstract": "Article history: Received 13 April 2007 Received in revised form 26 March 2008",
            "year": 2008,
            "venue": "",
            "authors": [
              {
                "authorId": "2084353304",
                "name": "G. Louloudisa"
              },
              {
                "authorId": "2080207726",
                "name": "B. Gatosb"
              },
              {
                "authorId": "2085864307",
                "name": "I. Pratikakisb"
              },
              {
                "authorId": "2080987605",
                "name": "C. Halatsisa"
              }
            ]
          }
        },
        {
          "citedcorpusid": 25040774,
          "isinfluential": false,
          "contexts": [
            "We have evaluated the segmentation algorithm on the IAM database [21], the GRPOLY-DB dataset [22] and the Saintgall and Parzival datasets [23]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "GRPOLY-DB: An old Greek polytonic document image database",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "1876181",
                "name": "Giorgos Sfikas"
              },
              {
                "authorId": "1730770",
                "name": "George Retsinas"
              },
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "2901255",
                "name": "Fotini Sunistira"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              }
            ]
          }
        },
        {
          "citedcorpusid": 36363181,
          "isinfluential": false,
          "contexts": [
            "The projection profile approach [6], [7] is based on projecting the document pixels which are relevant (detected through binarization for example) into the Y -axis of the image."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Handwritten document image segmentation and analysis",
            "abstract": "",
            "year": 1993,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "145852526",
                "name": "V. Shapiro"
              },
              {
                "authorId": "2329505",
                "name": "G. Gluhchev"
              },
              {
                "authorId": "144088894",
                "name": "V. Sgurev"
              }
            ]
          }
        },
        {
          "citedcorpusid": 39577325,
          "isinfluential": false,
          "contexts": [
            "Therefore, we apply a watershed algorithm [18] on the histogram in order to assign each histogram value to the local maximum that we will reach while following the gradient direction."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An efficient watershed algorithm based on connected components",
            "abstract": "",
            "year": 2000,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "3287487",
                "name": "A. Bieniek"
              },
              {
                "authorId": "34836833",
                "name": "Alina N. Moga"
              }
            ]
          }
        }
      ]
    },
    "36389323": {
      "citing_paper_info": {
        "title": "A New Scheme for Text Line and Character Segmentation from Gray Scale Images of Palm Leaf Manuscript",
        "abstract": "",
        "year": 2016,
        "venue": "International Conference on Frontiers in Handwriting Recognition",
        "authors": [
          {
            "authorId": "2154407",
            "name": "M. W. A. Kesiman"
          },
          {
            "authorId": "1690398",
            "name": "J. Burie"
          },
          {
            "authorId": "1695766",
            "name": "J. Ogier"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 3,
        "unique_cited_count": 3,
        "influential_count": 1,
        "detailed_records_count": 3
      },
      "cited_papers": [
        "12887938",
        "619938",
        "14196680"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "A survey of text line segmentation methods for historical documents was given in [19]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12887938,
          "isinfluential": true,
          "contexts": [
            "Some other methods used the combined information from both binary and gray scale image [2,3].",
            "The overlaps, and interconnection of the neighboring characters further complicate the work of the OCR systems [3].",
            "This scheme is based on the work of [4], [2] and [3].",
            "We also defined the rule to select candidate areas for segmentation path, instead of using the topographic features described in [4] or using the local maxima of the outer counter of the binary image described in [2] and [3]."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Optical Character Recognition for Cursive Handwriting",
            "abstract": "A new analytic scheme, which uses a sequence of image segmentation and recognition algorithms, is proposed for the off-line cursive handwriting recognition problem. First, some global parameters, such as slant angle, baselines, stroke width and height, are estimated. Second, a segmentation method finds character segmentation paths by combining gray-scale and binary information. Third, a hidden Markov model (HMM) is employed for shape recognition to label and rank the character candidates. For this purpose, a string of codes is extracted from each segment to represent the character candidates. The estimation of feature space parameters is embedded in the HMM training stage together with the estimation of the HMM model parameters. Finally, information from a lexicon and from the HMM ranks is combined in a graph optimization problem for word-level recognition. This method corrects most of the errors produced by the segmentation and HMM ranking stages by maximizing an information measure in an efficient graph search algorithm. The experiments indicate higher recognition rates compared to the available methods reported in the literature.",
            "year": 2002,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2853710",
                "name": "N. Arica"
              },
              {
                "authorId": "1398326708",
                "name": "F. Yarman-Vural"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14196680,
          "isinfluential": false,
          "contexts": [
            "Many methods of text line and character segmentation for handwritten document image were already proposed [1,8–13]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line and word segmentation of handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        }
      ]
    },
    "56596928": {
      "citing_paper_info": {
        "title": "Angle Minimization and Graph Analysis for Text Line Segmentation in Handwritten Documents",
        "abstract": "We propose in this paper a novel approach for text line segmentation in handwritten documents. The approach is based on angle minimization and graph analysis for text lines extraction. We apply our approach on images of ICDAR 2013 Handwriting Segmentation Contest, and give details about its robustness against skew and text orientation. We compare the approach to relevant text line segmentation state of art methods, apply it to Algerian manuscripts and report relevant results",
        "year": 2018,
        "venue": "International Conference on Frontiers in Handwriting Recognition",
        "authors": [
          {
            "authorId": "2026692",
            "name": "Insaf Setitra"
          },
          {
            "authorId": "40595480",
            "name": "A. Meziane"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 15,
        "unique_cited_count": 13,
        "influential_count": 3,
        "detailed_records_count": 15
      },
      "cited_papers": [
        "12993414",
        "357655",
        "30900701",
        "18352690",
        "2123198",
        "5690971",
        "17382721",
        "21550039",
        "33674833",
        "7486545",
        "1490277",
        "10786379",
        "22982294"
      ],
      "citation_details": [
        {
          "citedcorpusid": 357655,
          "isinfluential": false,
          "contexts": [
            "[21] proposed text line extraction using foreground and background informations."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line extraction in graphical documents using background and foreground information",
            "abstract": "",
            "year": 2012,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40813600",
                "name": "P. Roy"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "143826881",
                "name": "J. Lladós"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1490277,
          "isinfluential": false,
          "contexts": [
            "[11] H. Goto and H. Aso.",
            "Goto and Aso [11] proposed a local linearity based method to detect text lines in English and Chinese documents."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Extracting curved text lines using local linearity of the text line",
            "abstract": "",
            "year": 1999,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2257624",
                "name": "Hideaki Goto"
              },
              {
                "authorId": "1705095",
                "name": "H. Aso"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2123198,
          "isinfluential": true,
          "contexts": [
            "After preprocessing, we apply our method to get labeled manuscript lines and use the software provided in [24] for qualitative results.",
            "Among activities regardless to text lines segmentation, a contest has been proposed in the International Conference of Document Analysis and Recognition in [24].",
            "Text line segmentation is considered a non-trivial task to solve the field of handwritten document recognition [24].",
            "tif taken from test images of ICDAR 2013 Handwriting Segmentation Contest[24]), (b) Extracted lines (c) Binary mask of lines obtained by thresholding extracted lines in (b), note that there is no disjoint line segments but since line segments are thin, they are not visible (d) Dilated mask (c) resulting manuscript lines labelling.",
            "Our results have been computed using the evaluation software in [24].",
            "We tested our approach on images of ICDAR 2013 Handwriting Segmentation Contest [24].",
            "As depicted in [24], The method gave best results because of the improvement brought by the participants and was able to handle cursive and Indian scripts where many graphemes are connected."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "144429596",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "2265885161",
                "name": "Umapada Pal"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5690971,
          "isinfluential": false,
          "contexts": [
            "Examples include Kalman filter [5] [7] [6] and are applied in areas such as in [14] and [26]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Adaptive Bayesian recognition in tracking rigid objects",
            "abstract": "",
            "year": 2000,
            "venue": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)",
            "authors": [
              {
                "authorId": "1692688",
                "name": "Yuri Boykov"
              },
              {
                "authorId": "1713089",
                "name": "D. Huttenlocher"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7486545,
          "isinfluential": false,
          "contexts": [
            "[8] proposed a line segmentation approach for camera-based warped documents using active contour models."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of stick text based on sub connected area analysis",
            "abstract": "",
            "year": 1997,
            "venue": "Proceedings of the Fourth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2115556264",
                "name": "Jingbo Gao"
              },
              {
                "authorId": "2108482089",
                "name": "Xinyou Li"
              },
              {
                "authorId": "2260165740",
                "name": "Zesheng Tang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10786379,
          "isinfluential": false,
          "contexts": [
            "[17] used a block-Based Hough Transform for text line extraction."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Detection in Unconstrained Handwritten Documents Using a Block-Based Hough Transform Approach",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12993414,
          "isinfluential": false,
          "contexts": [
            "The method is inspired of works in [13] and improved by performing both over-segmentation at the initial stage and adding additional steps based on dynamic programming for the energy minimization algorithm."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text-Line Extraction in Handwritten Chinese Documents Based on an Energy Minimization Framework",
            "abstract": "",
            "year": 2012,
            "venue": "IEEE Transactions on Image Processing",
            "authors": [
              {
                "authorId": "2463454",
                "name": "H. Koo"
              },
              {
                "authorId": "1707645",
                "name": "N. Cho"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17382721,
          "isinfluential": false,
          "contexts": [
            "Examples include Kalman filter [5] [7] [6] and are applied in areas such as in [14] and [26]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A multiple object tracking method using Kalman filter",
            "abstract": "",
            "year": 2010,
            "venue": "The 2010 IEEE International Conference on Information and Automation",
            "authors": [
              {
                "authorId": "2153898595",
                "name": "Xin Li"
              },
              {
                "authorId": "2607007",
                "name": "Ke-jun Wang"
              },
              {
                "authorId": "2158624850",
                "name": "Wei Wang"
              },
              {
                "authorId": "2153494132",
                "name": "Yang Li"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18352690,
          "isinfluential": false,
          "contexts": [
            "Examples include Kalman filter [5] [7] [6] and are applied in areas such as in [14] and [26]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Object Tracking Algorithm Based on Combination of Dynamic Template Matching and Kalman Filter",
            "abstract": "",
            "year": 2012,
            "venue": "International Conference on Intelligent Human-Machine Systems and Cybernetics",
            "authors": [
              {
                "authorId": "2112670928",
                "name": "Bin Zheng"
              },
              {
                "authorId": "48670434",
                "name": "Xiangyang Xu"
              },
              {
                "authorId": "88192388",
                "name": "Y. Dai"
              },
              {
                "authorId": "2143549271",
                "name": "Yuanyuan Lu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 21550039,
          "isinfluential": true,
          "contexts": [
            "[21] P. P. Roy, U. Pal, and J. Lladós.",
            "Pal and Roy [19] proposed a head-line based technique for multi-oriented (printed in several orientations) and curved text lines extraction from Indian documents.",
            "[19] U. Pal and P. P. Roy.",
            "Roy et al. [21] proposed text line extraction using foreground and background informations."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Multioriented and curved text lines extraction from Indian documents",
            "abstract": "",
            "year": 2004,
            "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",
            "authors": [
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "40813600",
                "name": "P. Roy"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22982294,
          "isinfluential": false,
          "contexts": [
            "For more details about this kind of calligraphy, reader can refer to works in [23]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Perimeter histogram based approach for calligraphy classification in ancient manuscripts",
            "abstract": "",
            "year": 2014,
            "venue": "2014 4th International Symposium ISKO-Maghreb: Concepts and Tools for knowledge Management (ISKO-Maghreb)",
            "authors": [
              {
                "authorId": "2026692",
                "name": "Insaf Setitra"
              },
              {
                "authorId": "40595480",
                "name": "A. Meziane"
              }
            ]
          }
        },
        {
          "citedcorpusid": 30900701,
          "isinfluential": false,
          "contexts": [
            "[4] used a traditional perceptual grouping-based algorithm for extracting curved lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Extracting curved text lines using the chain composition and the expanded grouping method",
            "abstract": "",
            "year": 2007,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "2057585369",
                "name": "Bai Noi Nguyen"
              },
              {
                "authorId": "143910084",
                "name": "Kim Nam"
              },
              {
                "authorId": "2823192",
                "name": "Youngjun Song"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33674833,
          "isinfluential": false,
          "contexts": [
            ", E V V ) [25]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Assessing the vulnerability of supply chains using graph theory",
            "abstract": "",
            "year": 2010,
            "venue": "",
            "authors": [
              {
                "authorId": "34938070",
                "name": "Stephan M. Wagner"
              },
              {
                "authorId": "2814808",
                "name": "N. Neshat"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "[20] developed a system for English multi-oriented text line extraction estimating the equation of the text line from the character information."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": true,
          "contexts": [
            "Similar to [10], subtracting x(1) from both sides and crossing with V2 yields to:",
            "In order to find t and s that satisfy equation 2, we follow same rationale as in[10].",
            "In order to get intersection between line segments we use the approach in [10]."
          ],
          "intents": [
            "--",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "6657237": {
      "citing_paper_info": {
        "title": "Text Line Segmentation Based on Matched Filtering and Top-Down Grouping for Handwritten Documents",
        "abstract": "",
        "year": 2014,
        "venue": "2014 11th IAPR International Workshop on Document Analysis Systems",
        "authors": [
          {
            "authorId": "3152399",
            "name": "Youbao Tang"
          },
          {
            "authorId": "47150160",
            "name": "Xiangqian Wu"
          },
          {
            "authorId": "144830523",
            "name": "Wei Bu"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 3,
        "unique_cited_count": 3,
        "influential_count": 0,
        "detailed_records_count": 3
      },
      "cited_papers": [
        "4651364",
        "16503365",
        "14894195"
      ],
      "citation_details": [
        {
          "citedcorpusid": 4651364,
          "isinfluential": false,
          "contexts": [
            "Du et al. [10] use piecewise constant approximation of the Mumford-Shah model to segment handwritten text images and the morphing to remove overlapping CCs. Yin et al. [11] propose a segmentation algorithm based on minimum spanning tree (MST) clustering with distance metric learning."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Chinese text line segmentation by clustering with distance metric learning",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "145820427",
                "name": "Fei Yin"
              },
              {
                "authorId": "1689269",
                "name": "Cheng-Lin Liu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14894195,
          "isinfluential": false,
          "contexts": [
            "In [8, 9], handwritten documents are partitioned into several non-overlapping vertical zones, then the horizontal projection-based method is exploited to segment the text lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Robust text-line and word segmentation for handwritten documents images",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "authors": [
              {
                "authorId": "1799540",
                "name": "Themos Stafylakis"
              },
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              },
              {
                "authorId": "143978280",
                "name": "G. Carayannis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16503365,
          "isinfluential": false,
          "contexts": [
            "Alaei et al. [13] use a new painting technique to smear the foreground portion of the document image for text line detection."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "A new scheme for unconstrained handwritten text-line segmentation",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              }
            ]
          }
        }
      ]
    },
    "41944049": {
      "citing_paper_info": {
        "title": "A Tracking Approach for Text Line Segmentation in Handwritten Documents",
        "abstract": "Tracking of objects in videos consists of giving a label to the same object moving in different frames. This labelling is performed by predicting position of the object given its set of features observed in previous frames. In this work, we apply the same rationale by considering each connected component in the manuscript as a moving object and to track it so that to minimize the distance and angle of of the connected component to its nearest neighbour. The approach was applied to images of ICDAR 2013 handwritten segmentation contest and proved to be robust against text orientation, size and writing script.",
        "year": 2017,
        "venue": "International Conference on Pattern Recognition Applications and Methods",
        "authors": [
          {
            "authorId": "2026692",
            "name": "Insaf Setitra"
          },
          {
            "authorId": "2006290",
            "name": "Zineb Hadjadj"
          },
          {
            "authorId": "40595480",
            "name": "A. Meziane"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 6,
        "influential_count": 1,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "15569222",
        "9187881",
        "8845604",
        "17382721",
        "357655",
        "21550039"
      ],
      "citation_details": [
        {
          "citedcorpusid": 357655,
          "isinfluential": false,
          "contexts": [
            "(Roy et al., 2012) proposed text line extraction using foreground and background informations.",
            "Roy et al. (Roy et al., 2012) proposed text line extraction using foreground and background informations."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line extraction in graphical documents using background and foreground information",
            "abstract": "",
            "year": 2012,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "40813600",
                "name": "P. Roy"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "143826881",
                "name": "J. Lladós"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8845604,
          "isinfluential": false,
          "contexts": [
            "In the method proposed by Hones and Litcher (Hönes and Lichter, 1994), text lines are generated by expanding the line anchors of the document image.",
            "In the method proposed by Hones and Litcher (Hönes and Lichter, 1994), text lines are generated by expanding the line anchors of the document image."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Layout extraction of mixed mode documents",
            "abstract": "",
            "year": 1994,
            "venue": "Machine Vision and Applications",
            "authors": [
              {
                "authorId": "2083596961",
                "name": "Frank Hönes"
              },
              {
                "authorId": "101641932",
                "name": "J. Lichter"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": false,
          "contexts": [
            "(Li et al., 2008) proposed an approach for handwritten text line segmentation using level sets.",
            "Li et al. (Li et al., 2008) proposed an approach for handwritten text line segmentation using level sets."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15569222,
          "isinfluential": false,
          "contexts": [
            "Examples include Kalman filter (Bar-Shalom, 1987) (Broida and Chellappa, 1986) (Boykov and Huttenlocher, 2000) and are applied in areas such as in (Li et al., 2010) and (Zheng et al., 2012).",
            "Examples include Kalman filter (Bar-Shalom, 1987) (Broida and Chellappa, 1986) (Boykov and Huttenlocher, 2000) and are applied in areas such as in (Li et al."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Estimation of Object Motion Parameters from Noisy Images",
            "abstract": "",
            "year": 1986,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "32820669",
                "name": "T. Broida"
              },
              {
                "authorId": "9215658",
                "name": "R. Chellappa"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17382721,
          "isinfluential": false,
          "contexts": [
            "Examples include Kalman filter (Bar-Shalom, 1987) (Broida and Chellappa, 1986) (Boykov and Huttenlocher, 2000) and are applied in areas such as in (Li et al., 2010) and (Zheng et al., 2012).",
            "Examples include Kalman filter (Bar-Shalom, 1987) (Broida and Chellappa, 1986) (Boykov and Huttenlocher, 2000) and are applied in areas such as in (Li et al., 2010) and (Zheng et al."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A multiple object tracking method using Kalman filter",
            "abstract": "",
            "year": 2010,
            "venue": "The 2010 IEEE International Conference on Information and Automation",
            "authors": [
              {
                "authorId": "2153898595",
                "name": "Xin Li"
              },
              {
                "authorId": "2607007",
                "name": "Ke-jun Wang"
              },
              {
                "authorId": "2158624850",
                "name": "Wei Wang"
              },
              {
                "authorId": "2153494132",
                "name": "Yang Li"
              }
            ]
          }
        },
        {
          "citedcorpusid": 21550039,
          "isinfluential": true,
          "contexts": [
            "Roy et al. (Roy et al., 2012) proposed text line extraction using foreground and background informations.",
            "Pal and Roy (Pal and Roy, 2004) proposed a head-line based technique for multi-oriented (printed in several orientations) and curved text lines extraction from Indian documents.",
            "Pal, U. and Roy, P. P. (2004).",
            "Roy, P. P., Pal, U., and Lladós, J. (2012)."
          ],
          "intents": [
            "--",
            "['methodology']",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Multioriented and curved text lines extraction from Indian documents",
            "abstract": "",
            "year": 2004,
            "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",
            "authors": [
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "40813600",
                "name": "P. Roy"
              }
            ]
          }
        }
      ]
    },
    "212505333": {
      "citing_paper_info": {
        "title": "Text Line Segmentation of Arabic Handwritten Documents using Line Height Method",
        "abstract": "",
        "year": 2014,
        "venue": "",
        "authors": [
          {
            "authorId": "41216523",
            "name": "R. Paper"
          },
          {
            "authorId": "2286536457",
            "name": "Mokhtar Abdulrahman"
          },
          {
            "authorId": "2286386496",
            "name": "M. R. Mohammed"
          },
          {
            "authorId": "2286295073",
            "name": "R. Kumar"
          },
          {
            "authorId": "2286514379",
            "name": "Pradeep"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 1,
        "unique_cited_count": 1,
        "influential_count": 0,
        "detailed_records_count": 1
      },
      "cited_papers": [
        "12047294"
      ],
      "citation_details": [
        {
          "citedcorpusid": 12047294,
          "isinfluential": false,
          "contexts": [
            "Experiment results show that the proposed method achieves high accuracy about 95% for detecting text lines in Arabic historical handwritten document images written with different scripts [5]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Unsupervised Block Covering Analysis for Text-Line Segmentation of Arabic Ancient Handwritten Document Images",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "1983484",
                "name": "Wafa Boussellaa"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2801094",
                "name": "H. E. Abed"
              },
              {
                "authorId": "2113394",
                "name": "A. BenAbdelhafid"
              },
              {
                "authorId": "144000830",
                "name": "A. Alimi"
              }
            ]
          }
        }
      ]
    },
    "73579744": {
      "citing_paper_info": {
        "title": "Text Line Segmentation with the Algorithm Based on the Oriented Anisotropic Gaussian Kernel",
        "abstract": "The paper presents the algorithm for text line segmentation based on the oriented anisotropic Gaussian kernel. Initially, the document image is split into connected components achieved by bounding boxes. These connected components are cleared from redundant fragments. Furthermore, the binary moments are applied to each of these connected components evaluating local text skewing. According to this information the orientation of the anisotropic Gaussian kernel is set. After the algorithm application the boundary growing areas around connected components are established. These areas are of major importance for the evaluation of text line segmentation. For testing purposes, the algorithm is evaluated under different text samples. Comparative analysis between algorithm with and without orientation based on the anisotropic Gaussian kernel is made. The results show the improvement in the domain of text line segmentation.",
        "year": 2013,
        "venue": "",
        "authors": [
          {
            "authorId": "2008869",
            "name": "D. Brodic"
          },
          {
            "authorId": "2393591",
            "name": "Z. Milivojevic"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 3,
        "unique_cited_count": 3,
        "influential_count": 0,
        "detailed_records_count": 3
      },
      "cited_papers": [
        "7272464",
        "8543445",
        "55949775"
      ],
      "citation_details": [
        {
          "citedcorpusid": 7272464,
          "isinfluential": false,
          "contexts": [
            "This method has been widely used [3–7]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "A New Algorithm for Detecting Text Line in Handwritten Documents",
            "abstract": "Curvilinear text line detection and segmentation in handwritten documents is a significant challenge for handwriting recognition. Given no prior knowledge of script, we model text line detection as an image segmentation problem by enhancing text line structure using a Gaussian window, and adopting the level set method to evolve text line boundaries. Experiments show that the proposed method achieves high accuracy for detecting text lines in both handwritten and machine printed documents with many scripts.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2053348005",
                "name": "S. Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8543445,
          "isinfluential": false,
          "contexts": [
            "where Dth is given by any local binarization method as threshold sensitivity value [8, 9]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Adaptive document image binarization",
            "abstract": "",
            "year": 2000,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1704694",
                "name": "J. Sauvola"
              },
              {
                "authorId": "145962204",
                "name": "M. Pietikäinen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 55949775,
          "isinfluential": false,
          "contexts": [
            "It is based on the pre-assumption that writing text is extending only in the horizontal direction [7]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Optimization of the Gaussian Kernel Extended by Binary Morphology for Text Line Segmentation",
            "abstract": "In this paper, an approach for text line segmentation by algorithm with the implementation of the Gaussian kernel is presented. As a result of algorithm, the growing area around text is exploited for text line segmentation. To improve text line segmentation process, isotropic Gaussian kernel is extended by dilatation. Furthermore, algorithms with isotropic and extended Gaussian kernels are examined and evaluated under different text samples. Results are given and comparative analysis is made for these algorithms. From the obtained results, optimization of the parameters defining extended Gaussian kernel dimension is proposed. The presented algorithm with the extended Gaussian kernel showed robustness for different types of text samples.",
            "year": 2010,
            "venue": "",
            "authors": [
              {
                "authorId": "2008869",
                "name": "D. Brodic"
              },
              {
                "authorId": "2393591",
                "name": "Z. Milivojevic"
              }
            ]
          }
        }
      ]
    },
    "237099585": {
      "citing_paper_info": {
        "title": "Text line extraction using deep learning and minimal sub seams",
        "abstract": "Accurate text line extraction is a vital prerequisite for efficient and successful text recognition systems ranging from keywords/phrases searching to complete conversion to text. In many cases, the proposed algorithms target binary pre-processed versions of the image, which may cause insufficient results due to poor quality document images. Recently, more papers present solutions that work directly on gray-level images [1,2,7,12,15]. In this paper, we present a novel robust, and efficient algorithm to extract text-lines directly from gray-level document images. The proposed approach uses a combination of two variants of Convolutional Neural Network (CNNs), followed by minimal energy seam extraction. The first ConvNet is a modified version of the autoencoder used for biomedical image segmentation [8]. The second is a deep convolutional Neural Network, working on overlapping vertical slices of the original image. The two variants are combined to one neural net after re-attaching the resulting slices of the second net. The merged results of the two nets are used as a preprocessed image to obtain an energy map for a second phase. In the second step, we use the algorithm presented in [2], to track minimal energy sub-seams accumulated to perform a full local minimal/maximal separating and medial seam defining the text baselines and the text line regions. We have tested our approach on multi-lingual various datasets written at a range of image quality based on the ICDAR datasets.",
        "year": 2021,
        "venue": "ACM Symposium on Document Engineering",
        "authors": [
          {
            "authorId": "2123350701",
            "name": "Adi Azran"
          },
          {
            "authorId": "2424088",
            "name": "A. Schclar"
          },
          {
            "authorId": "1741845",
            "name": "Raid Saabni"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 6,
        "influential_count": 0,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "54445238",
        "54465873",
        "8603144",
        "221663960",
        "4761833",
        "8568424"
      ],
      "citation_details": [
        {
          "citedcorpusid": 4761833,
          "isinfluential": false,
          "contexts": [
            "The data sets we have used for training and testing were from the ICDAR [9,10,11] datasets for Handwriting Segmentation Contest and the PINKAS dataset [11]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "cBAD: ICDAR2017 Competition on Baseline Detection",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1715229",
                "name": "Markus Diem"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              },
              {
                "authorId": "1732418",
                "name": "Stefan Fiel"
              },
              {
                "authorId": "40585315",
                "name": "Tobias Grüning"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8568424,
          "isinfluential": false,
          "contexts": [
            "Projection Profiles or smearing methods [4], along a predetermined direction, are usually used in top-down Permission to make digital or hard copies of part or all this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of historical machine-printed documents using Adaptive Run Length Smoothing and skeleton segmentation paths",
            "abstract": "",
            "year": 2010,
            "venue": "Image and Vision Computing",
            "authors": [
              {
                "authorId": "2093164350",
                "name": "Nikos A. Nikolaou"
              },
              {
                "authorId": "2355097",
                "name": "M. Makridis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "144368634",
                "name": "N. Papamarkos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8603144,
          "isinfluential": false,
          "contexts": [
            "[1-3] to extract lines from binary and gray-level images.",
            "Recently, more papers present solutions that work directly on gray-level images [1,2,7,12,15]."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Language-Independent Text Lines Extraction Using Seam Carving",
            "abstract": "",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1741845",
                "name": "Raid Saabni"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 54445238,
          "isinfluential": false,
          "contexts": [
            "We use dynamic programming to compute the minimal cost sub seam s min (p) , see [2] for more details.",
            "For the seam ’s extraction step, we used the same algorithm presented in [2], which seeks and locates minimal sub-seams on vertical slices of the image energy map."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Robust and Efficient Text: Line Extraction by Local Minimal Sub-Seams",
            "abstract": "Robust text line extraction from document images is vital prerequisite for any successful text recognition or analyzing process. Generally, most of the proposed algorithms for this task assumed kind of binarization pre-processing step in order to insure well performance. In this paper, we present a novel robust and efficient algorithm to extract textlines directly from gray level document images. The algorithm tracks minimal energy sub-seams accumulated to perform a full local minimal/maximal separating and medial seams defining the text lines. To improve the ability of extracting such seams, we enhance the image using double-sided adaptive local density projection profile followed by multi-scale anisotropic second derivative of Gaussian filter bank. Following the observation that center of lines are more reliable to follow, we first extract seams that follow the center of lines to constraint the algorithm for evolving the separating seams. The algorithm is parameter-free and we evaluate the free parameters directly by analyzing the image properties and the pixels distribution. We have tested our approach on multi-lingual various datasets written at range of image quality and received very encouraging results, which outperform state-of-the-art algorithms.",
            "year": 2018,
            "venue": "Proceedings of the 2nd International Symposium on Computer Science and Intelligent Control",
            "authors": [
              {
                "authorId": "1741845",
                "name": "Raid Saabni"
              }
            ]
          }
        },
        {
          "citedcorpusid": 54465873,
          "isinfluential": false,
          "contexts": [
            "[13] present a recurrent NN called Mask, to efficiently detect objects in an image while simultaneously generating a high-quality segmentation mask for each instance."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Mask R-CNN",
            "abstract": "We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.",
            "year": 2017,
            "venue": "",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2082991",
                "name": "Georgia Gkioxari"
              },
              {
                "authorId": "3127283",
                "name": "Piotr Dollár"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 221663960,
          "isinfluential": false,
          "contexts": [
            "[14], propose an unsupervised deep learning algorithm trained to predict whether a document patch contains a text line or interline."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Unsupervised deep learning for text line segmentation",
            "abstract": "We present an unsupervised deep learning method for text line segmentation that is inspired by the relative variance between text lines and spaces among text lines. Handwritten text line segmentation is important for the efficiency of further processing. A common method is to train a deep learning network for embedding the document image into an image of blob lines that are tracing the text lines. Previous methods learned such embedding in a supervised manner, requiring the annotation of many document images. This paper presents an unsupervised embedding of document image patches without a need for annotations. The number of foreground pixels over the text lines is relatively different from the number of foreground pixels over the spaces among text lines. Generating similar and different pairs relying on this principle definitely leads to outliers. However, as the results show, the outliers do not harm the convergence and the network learns to discriminate the text lines from the spaces between text lines. Remarkably, with a challenging Arabic handwritten text line segmentation dataset, VML-AHTE, we achieved superior performance over the supervised methods. Additionally, the proposed method was evaluated on the ICDAR 2017 and ICFHR 2010 handwritten text line segmentation datasets.",
            "year": 2020,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "1414748211",
                "name": "Reem Alaasam"
              },
              {
                "authorId": "1573588308",
                "name": "Boraq Madi"
              },
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "1573588240",
                "name": "Raed Shammes"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        }
      ]
    },
    "26484429": {
      "citing_paper_info": {
        "title": "A Combined System for Text Line Extraction and Handwriting Recognition in Historical Documents",
        "abstract": "",
        "year": 2014,
        "venue": "2014 11th IAPR International Workshop on Document Analysis Systems",
        "authors": [
          {
            "authorId": "153745355",
            "name": "Andreas Fischer"
          },
          {
            "authorId": "1708890",
            "name": "M. Baechler"
          },
          {
            "authorId": "1697354",
            "name": "A. Garz"
          },
          {
            "authorId": "1743758",
            "name": "M. Liwicki"
          },
          {
            "authorId": "1680326",
            "name": "R. Ingold"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 11,
        "unique_cited_count": 10,
        "influential_count": 1,
        "detailed_records_count": 11
      },
      "cited_papers": [
        "60827152",
        "9187881",
        "18168842",
        "9673364",
        "16993962",
        "28027112",
        "12534822",
        "847254",
        "12445460",
        "33247622"
      ],
      "citation_details": [
        {
          "citedcorpusid": 847254,
          "isinfluential": false,
          "contexts": [
            "An HMM word recognizer has been used by Toselli et al. [14] for the interactive transcription of old Spanish manuscripts."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Multimodal interactive transcription of text images",
            "abstract": "",
            "year": 2010,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "52151344",
                "name": "A. Toselli"
              },
              {
                "authorId": "144340605",
                "name": "Verónica Romero"
              },
              {
                "authorId": "143614719",
                "name": "Moisés Pastor"
              },
              {
                "authorId": "143783065",
                "name": "E. Vidal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": true,
          "contexts": [
            "Indeed, the correctness measures correspond with the text-line-level detection rate and the pixel-level hit rate proposed in [11].",
            "The proposed evaluation is based on the symmetric difference and can be seen as an extension of the method proposed by Li et al. in [11] such that insertion errors are taken into account in addition to substitution and deletion errors.",
            "However, in order to avoid the threshold T (cid:2) , a more accurate evaluation can be performed at pixel-level as suggested in [11].",
            "They correspond with the text-line-level detection rate and pixel-level hit rate proposed in [11].",
            "The latter is an extension of the method proposed by Li et al. in [11] such that insertion errors can be included in the evaluation in addition to substitution and deletion errors.",
            "Similar to the procedure proposed in [11], we can take a threshold T (cid:2) into account and reﬁne the cost function for substitutions to In this paper, we use T (cid:2) = 0 .",
            "The scenario of curvilinear lines and small gaps between the text has also been addressed by the level set method proposed by Li et al. in [11] which has shown a high performance for many different scripts.",
            "( A → B ) | A ∩ B | deﬁned in [11]."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['background']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9673364,
          "isinfluential": false,
          "contexts": [
            "In the difﬁcult case of irregular baselines and touching text lines, dynamic programming methods for calculating separat-ing paths have shown promising results in recent years [9], [10]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation for gray scale historical document images",
            "abstract": "",
            "year": 2011,
            "venue": "The Hip",
            "authors": [
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "1741845",
                "name": "Raid Saabni"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12445460,
          "isinfluential": false,
          "contexts": [
            "At training stage, a second semi-automatic annotation tool is employed [18] that allows human users to align an electronic text edition of the manuscript, provided by experts, with the corresponding text line images.",
            "The Parzival database [18] consists of scanned and annotated document images of a medieval German manuscript originating in the 13th century, which contains the famous epic poem Parzival ."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Ground truth creation for handwriting recognition in historical documents",
            "abstract": "",
            "year": 2010,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1693905",
                "name": "Emanuel Indermühle"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              },
              {
                "authorId": "2264628420",
                "name": "Gabriel Viehhauser"
              },
              {
                "authorId": "49561025",
                "name": "Michael Stolz"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12534822,
          "isinfluential": false,
          "contexts": [
            "For layout analysis and text extraction, some approaches attempt to extract individual word images, for instance the scale space approach proposed by Manmatha and Rothfeder in [1], which was successfully applied to historical letters written by George Washington."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A scale space approach for automatically segmenting words from historical handwritten documents",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              },
              {
                "authorId": "1845217",
                "name": "Jamie L. Rothfeder"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16993962,
          "isinfluential": false,
          "contexts": [
            "By extending established concepts, different methods have been proposed based on run length smoothing [3], [4], projection proﬁle analysis [5], [6], and Hough transformation [7], [8]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line separation for complex document images using fuzzy runlength",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18168842,
          "isinfluential": false,
          "contexts": [
            "Details on this assignment-based edit distance can be found in [26], [27]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Approximate graph edit distance computation by means of bipartite graph matching",
            "abstract": "",
            "year": 2009,
            "venue": "Image and Vision Computing",
            "authors": [
              {
                "authorId": "1759104",
                "name": "Kaspar Riesen"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 28027112,
          "isinfluential": false,
          "contexts": [
            "Examples include the DEBORA [15] system for annotating Renaissance documents and the DMOS [16] system proposed for old civil status registers and military forms."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Access by content to handwritten archive documents: generic document recognition method and platform for annotations",
            "abstract": "",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1789181",
                "name": "Bertrand Coüasnon"
              },
              {
                "authorId": "1760753",
                "name": "J. Camillerapp"
              },
              {
                "authorId": "3126026",
                "name": "I. Leplumey"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33247622,
          "isinfluential": false,
          "contexts": [
            "The layout analysis module [20] Note that the NN-based pixel classiﬁcation can be applied to arbitrary layouts.",
            "For more details on text line extraction, we refer to [20]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Extraction Using DMLP Classifiers for Historical Manuscripts",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1708890",
                "name": "M. Baechler"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 60827152,
          "isinfluential": false,
          "contexts": [
            "The standard evaluation method for text line recognition is based on the string edit distance [25] between the sequence of words in the ground truth and the sequence of words in the system output."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Binary codes capable of correcting deletions, insertions, and reversals",
            "abstract": "",
            "year": 1965,
            "venue": "",
            "authors": [
              {
                "authorId": "2154179",
                "name": "V. Levenshtein"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Used software toolkits include HTK 5 for HMM, an earlier version of RNNLIB [28] for RNN, and SRILM 6 for language modeling."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "35471180": {
      "citing_paper_info": {
        "title": "Using Scale-Space Anisotropic Smoothing for Text Line Extraction in Historical Documents",
        "abstract": "",
        "year": 2014,
        "venue": "International Conference on Image Analysis and Recognition",
        "authors": [
          {
            "authorId": "51037361",
            "name": "Rafi Cohen"
          },
          {
            "authorId": "1686153",
            "name": "I. Dinstein"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          },
          {
            "authorId": "1939225",
            "name": "K. Kedem"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 16,
        "unique_cited_count": 15,
        "influential_count": 4,
        "detailed_records_count": 16
      },
      "cited_papers": [
        "16432038",
        "16852030",
        "16167028",
        "15926594",
        "5490524",
        "33247622",
        "11057710",
        "17575742",
        "12445460",
        "7130275",
        "17401851",
        "9187881",
        "917311",
        "7269903",
        "23399574"
      ],
      "citation_details": [
        {
          "citedcorpusid": 917311,
          "isinfluential": false,
          "contexts": [
            "(2) according to d ( c, c (cid:48) ) = exp( − α · d e ( c, c (cid:48) )) (the spatial coherence strength decays exponentially with the Euclidean distance [42])."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "The whole is equal to the sum of its parts: a probabilistic model of grouping by proximity and similarity in regular patterns.",
            "abstract": "The authors investigated whether the gestalt grouping principles can be quantified and whether the conjoint effects of two grouping principles operating at the same time on the same stimuli differ from the sum of their individual effects. After reviewing earlier attempts to discover how grouping principles interact, they developed a probabilistic model of grouping by proximity, which allows measurement of strength on a ratio scale. Then, in 3 experiments using dot lattices, they showed that the strength of the conjoint effect of 2 grouping principles--grouping by proximity and grouping by similarity--is equal to the sum of their separate effects. They propose a physiologically plausible model of this law.",
            "year": 2008,
            "venue": "Psychology Review",
            "authors": [
              {
                "authorId": "3438189",
                "name": "M. Kubovy"
              },
              {
                "authorId": "114221707",
                "name": "M. van den Berg"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5490524,
          "isinfluential": false,
          "contexts": [
            "Garz et al. [30] extract Diﬀerence of Gaussian (DoG) feature points and cluster words in high-density regions to extract text lines by concatenating neighboring word clusters."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Binarization-Free Clustering Approach to Segment Curved Text Lines in Historical Manuscripts",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7130275,
          "isinfluential": true,
          "contexts": [
            "The performance evaluation is based on a MatchScore [16] that computes the maximum overlap of a text region with the ground truth region.",
            "These approaches yield good results and became popular methods for text line extraction (ranked 1st in ICDAR 2009 and ICFHR 2010 contests [8,9], and 3rd in ICDAR 2013 contest [16]).",
            "the datasets are ICDAR 2013 [16], ICDAR 2009 [8], Hebrew [13], Saint Gall [7] and Parzival [1] datasets.",
            "Based on this MatchScore, the Detection Rate (DR), the Recognition Accuracy (RA), and the Performance Metric (FM) are deﬁned using Eq.",
            "The performance evaluation is based on a MatchScore [6] that computes the maximum overlap of a text region with the ground truth region."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "ICFHR 2010 Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7269903,
          "isinfluential": false,
          "contexts": [
            "For our study we separate the main-text from the side-notes text, using graph cuts [44] and focus on the side-notes."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Coarse-to-Fine Approach for Layout Analysis of Ancient Manuscripts",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "51037361",
                "name": "Rafi Cohen"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              },
              {
                "authorId": "1686153",
                "name": "I. Dinstein"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": true,
          "contexts": [
            "Most authors do not provide an algorithm for choosing the correct scale [10,15] or choose the scale based on ad-hoc heuristics [4].",
            "Smearing based methods [4,10,15] apply Gaussian based filtering and binarization to enhance line structure.",
            "The binarization phase also inherits the limitations of the adapted binarization algorithm which is either ad-hoc binarization [15] or based on active-contours [4,10]",
            "Specifically, the PDF is continuous and has smaller values (dark) in the text line area, while there are larger values (bright) in the gap and marginal area [10].",
            "Text line extraction algorithms could be categorized into projection-based methods [2], grouping methods [7,13], seam-based algorithm [14] and smearing methods [4,10,15].",
            "A popular variant of the smearing method [4,10] is based upon convolving the image with an anisotropic Gaussian (or a bank or Gaussians)",
            "Another drawback for the level-set based active contours methods [10] is their complex and slow computation."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['methodology']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11057710,
          "isinfluential": false,
          "contexts": [
            "A seam-carving-based approach has been developed recently [7, 8].",
            "These algorithms often fail to detect short text lines and determining the boundary seams of the text-lines is based on an ad-hoc heuristics [7, 8]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Seam Carving for Text Line Extraction on Color and Grayscale Historical Manuscripts",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2965236",
                "name": "Nikolaos Arvanitopoulos"
              },
              {
                "authorId": "1735035",
                "name": "S. Süsstrunk"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12445460,
          "isinfluential": false,
          "contexts": [
            "A dynamic programming based approach, was presented by Liwicki et al. [36] for on-line text line segmentation, and adapted by Fischer et al. [37] for historical documents."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Ground truth creation for handwriting recognition in historical documents",
            "abstract": "",
            "year": 2010,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1693905",
                "name": "Emanuel Indermühle"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              },
              {
                "authorId": "2264628420",
                "name": "Gabriel Viehhauser"
              },
              {
                "authorId": "49561025",
                "name": "Michael Stolz"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15926594,
          "isinfluential": true,
          "contexts": [
            "Most authors do not provide an algorithm for choosing the correct scale [10,15] or choose the scale based on ad-hoc heuristics [4].",
            "Smearing based methods [4,10,15] apply Gaussian based filtering and binarization to enhance line structure.",
            "The binarization phase also inherits the limitations of the adapted binarization algorithm which is either ad-hoc binarization [15] or based on active-contours [4,10]",
            "Text line extraction algorithms could be categorized into projection-based methods [2], grouping methods [7,13], seam-based algorithm [14] and smearing methods [4,10,15].",
            "[4] suggest to choose the scales of the Gaussians by binarizing the document and inspecting its height histogram, which is susceptible to noise in degraded documents, see Fig.",
            "A popular variant of the smearing method [4,10] is based upon convolving the image with an anisotropic Gaussian (or a bank or Gaussians)"
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Script-Independent Handwritten Textlines Segmentation using Active Contours",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 16167028,
          "isinfluential": false,
          "contexts": [
            "The Hough transform methodology was exploited for text line segmen-55 tation [17, 18, 19].",
            "They may cause the Hough transform-based approaches [18, 19] to fail in determining text lines mainly because these approaches consider a whole word and a small stroke as equally important in the Hough domain."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Text line detection in handwritten documents",
            "abstract": "Article history: Received 13 April 2007 Received in revised form 26 March 2008",
            "year": 2008,
            "venue": "",
            "authors": [
              {
                "authorId": "2084353304",
                "name": "G. Louloudisa"
              },
              {
                "authorId": "2080207726",
                "name": "B. Gatosb"
              },
              {
                "authorId": "2085864307",
                "name": "I. Pratikakisb"
              },
              {
                "authorId": "2080987605",
                "name": "C. Halatsisa"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16432038,
          "isinfluential": false,
          "contexts": [
            "Ouwayed and Bela¨ıd [24] used image meshing and the WignerVille distribution to extract multi-oriented lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A general approach for multi-oriented text line extraction of handwritten documents",
            "abstract": "",
            "year": 2011,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2892336",
                "name": "Nazih Ouwayed"
              },
              {
                "authorId": "2257903477",
                "name": "Abdel Belaïd"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16852030,
          "isinfluential": false,
          "contexts": [
            "The term de(c, c′) is the Euclidean distance between the centroids of components c and c′, and the constant α is defined as (2 〈de(c, c′)〉)−1, where 〈·〉 denotes expectation over all pairs of adjacent elements [5].",
            "As a result of this structure, a convolution of text line with a second derivative of an anisotropic Gaussian, elongated along the horizontal direction generates ridges along text lines and valleys along the gaps between text lines [5]."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Robust text and drawing segmentation algorithm for historical documents",
            "abstract": "",
            "year": 2013,
            "venue": "The Hip",
            "authors": [
              {
                "authorId": "51037361",
                "name": "Rafi Cohen"
              },
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              },
              {
                "authorId": "1686153",
                "name": "I. Dinstein"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17401851,
          "isinfluential": false,
          "contexts": [
            "Some other methods use active contours techniques for line extraction [1, 35, 3].",
            "Moreover, level-set based active contours methods [1, 35] are computationally complex."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation in handwritten documents using Mumford-Shah model",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "70378391",
                "name": "Xiaojun Du"
              },
              {
                "authorId": "1681758",
                "name": "Wumo Pan"
              },
              {
                "authorId": "144957197",
                "name": "T. D. Bui"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17575742,
          "isinfluential": false,
          "contexts": [
            "The inclusion relation enables connected components of the level sets to be organized in a tree structure, which is called the component tree [12].",
            "(h) The same tree, enriched by an attribute (the size of the connected component of each node), courtesy of [12]."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A document binarization method based on connected operators",
            "abstract": "",
            "year": 2010,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "1781065",
                "name": "B. Naegel"
              },
              {
                "authorId": "145440322",
                "name": "L. Wendling"
              }
            ]
          }
        },
        {
          "citedcorpusid": 23399574,
          "isinfluential": false,
          "contexts": [
            "Kise et al. [31] combine heuristic rules and the Voronoi diagrams to merge connected components into text lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Page Images Using the Area Voronoi Diagram",
            "abstract": "This paper presents a method of page segmentation based on the approximated area Voronoi diagram. The characteristics of the proposed method are as follows: (1) The Voronoi diagram enables us to obtain the candidates of boundaries of document components from page images with non-Manhattan layout and a skew. (2) The candidates are utilized to estimate the intercharacter and interline gaps without the use of domain-specific parameters to select the boundaries. From the experimental results for 128 images with non-Manhattan layout and the skew of 0°~45° as well as 98 images with Manhattan layout, we have confirmed that the method is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis.",
            "year": 1998,
            "venue": "Computer Vision and Image Understanding",
            "authors": [
              {
                "authorId": "3277321",
                "name": "K. Kise"
              },
              {
                "authorId": "2064863306",
                "name": "A. Sato"
              },
              {
                "authorId": "40411993",
                "name": "M. Iwata"
              }
            ]
          }
        },
        {
          "citedcorpusid": 33247622,
          "isinfluential": true,
          "contexts": [
            "For Parzival we used the ground-truth generated by [33].",
            "For Saint Gall and Parzival we measure the performance by means of the Pixel-Level Hit Rate (PHR) and the FM (also called Line Accuracy Measure) as in [47, 48].",
            "the datasets are ICDAR 2013 [16], ICDAR 2009 [8], Hebrew [13], Saint Gall [7] and Parzival [1] datasets.",
            "Hence, the presented methodology is script and writer independent and copes nicely with noise. the datasets are ICDAR 2013 [6], ICDAR 2009 [4], Hebrew [33], Saint Gall [47], Parzival [48] and BGU [7] datasets.",
            "For Saint Gall and Parzival we measure the performance by means of the Pixel-Level Hit Rate (PHR) and the FM (also called Line Accuracy Measure) as in [1,7]."
          ],
          "intents": [
            "--",
            "--",
            "['methodology']",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Line Extraction Using DMLP Classifiers for Historical Manuscripts",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1708890",
                "name": "M. Baechler"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "direction continuity were also used to iteratively construct lines by grouping neighboring connected components [25]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "17401851": {
      "citing_paper_info": {
        "title": "Text line segmentation in handwritten documents using Mumford-Shah model",
        "abstract": "",
        "year": 2009,
        "venue": "Pattern Recognition",
        "authors": [
          {
            "authorId": "70378391",
            "name": "Xiaojun Du"
          },
          {
            "authorId": "1681758",
            "name": "Wumo Pan"
          },
          {
            "authorId": "144957197",
            "name": "T. D. Bui"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 3,
        "unique_cited_count": 3,
        "influential_count": 0,
        "detailed_records_count": 3
      },
      "cited_papers": [
        "1794183",
        "222243846",
        "122661119"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1794183,
          "isinfluential": false,
          "contexts": [
            "Because the text image only consists of two uniform regions: text region and background region, the piecewise constant approximation [3] of the MS model is very appropriate for the segmentation of text lines."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Curve evolution implementation of the Mumford-Shah functional for image segmentation, denoising, interpolation, and magnification",
            "abstract": "In this work, we first address the problem of simultaneous image segmentation and smoothing by approaching the Mumford-Shah paradigm from a curve evolution perspective. In particular, we let a set of deformable contours define the boundaries between regions in an image where we model the data via piecewise smooth functions and employ a gradient flow to evolve these contours. Each gradient step involves solving an optimal estimation problem for the data within each region, connecting curve evolution and the Mumford-Shah functional with the theory of boundary-value stochastic processes. The resulting active contour model offers a tractable implementation of the original Mumford-Shah model (i.e., without resorting to elliptic approximations which have traditionally been favored for greater ease in implementation) to simultaneously segment and smoothly reconstruct the data within a given image in a coupled manner. Various implementations of this algorithm are introduced to increase its speed of convergence. We also outline a hierarchical implementation of this algorithm to handle important image features such as triple points and other multiple junctions. Next, by generalizing the data fidelity term of the original Mumford-Shah functional to incorporate a spatially varying penalty, we extend our method to problems in which data quality varies across the image and to images in which sets of pixel measurements are missing. This more general model leads us to a novel PDE-based approach for simultaneous image magnification, segmentation, and smoothing, thereby extending the traditional applications of the Mumford-Shah functional which only considers simultaneous segmentation and smoothing.",
            "year": 2001,
            "venue": "IEEE Transactions on Image Processing",
            "authors": [
              {
                "authorId": "145046191",
                "name": "A. Tsai"
              },
              {
                "authorId": "144599246",
                "name": "A. Yezzi"
              },
              {
                "authorId": "1701607",
                "name": "A. Willsky"
              }
            ]
          }
        },
        {
          "citedcorpusid": 122661119,
          "isinfluential": false,
          "contexts": [
            "Different from the approach in [4], the MS model is a region based approach."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Level set methods : evolving interfaces in geometry, fluid mechanics, computer vision, and materials science",
            "abstract": "Part I. The Theory of Moving Interfaces: 1. Theory of front evolution 2. Level set formulation Part II. Algorithms, Analysis, and Implementations of Level Set Methods: 3. Traditional techniques for tracking interfaces 4. Hyperbolic conservation laws 5. Approximating the level set equation 6. Viscosity solutions and Hamilton-Jacobi equations 7. A hierarchy of fast level set methods 8. A fast marching level set method 9. Extensions to the basic method Part III. Applications: 10. Geometry: curve/surface shrinkage and self-similar surfaces 11. Grid generation 12. Image enhancement and noise removal 13. Minimal surfaces and surfaces of prescribed curvature 14. Combustion, crystal growth, and two-fluid flow 15. Computer vision: shape detection and recognition 16. Applications of the fast marching level set method 17. Etching and deposition in microchip fabrication 18. New areas.",
            "year": 1996,
            "venue": "",
            "authors": [
              {
                "authorId": "9397819",
                "name": "J. Sethian"
              }
            ]
          }
        },
        {
          "citedcorpusid": 222243846,
          "isinfluential": false,
          "contexts": [
            "Keywords: Text line detection, image segmentation, Mumford-Shah model.",
            "The authors of [4] proposed to use the level-set method to segment the text lines."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Optimal approximations by piecewise smooth functions and associated variational problems",
            "abstract": "Abstract : This reprint will introduce and study the most basic properties of three new variational problems which are suggested by applications to computer vision. In computer vision, a fundamental problem is to appropriately decompose the domain R of a function g (x,y) of two variables. This problem starts by describing the physical situation which produces images: assume that a three-dimensional world is observed by an eye or camera from some point P and that g1(rho) represents the intensity of the light in this world approaching the point sub 1 from a direction rho. If one has a lens at P focusing this light on a retina or a film-in both cases a plane domain R in which we may introduce coordinates x, y then let g(x,y) be the strength of the light signal striking R at a point with coordinates (x,y); g(x,y) is essentially the same as sub 1 (rho) -possibly after a simple transformation given by the geometry of the imaging syste. The function g(x,y) defined on the plane domain R will be called an image. What sort of function is g? The light reflected off the surfaces Si of various solid objects O sub i visible from P will strike the domain R in various open subsets R sub i. When one object O1 is partially in front of another object O2 as seen from P, but some of object O2 appears as the background to the sides of O1, then the open sets R1 and R2 will have a common boundary (the 'edge' of object O1 in the image defined on R) and one usually expects the image g(x,y) to be discontinuous along this boundary. (JHD)",
            "year": 1989,
            "venue": "",
            "authors": [
              {
                "authorId": "117481816",
                "name": "D. Mumford"
              },
              {
                "authorId": "80271822",
                "name": "J. Shah"
              }
            ]
          }
        }
      ]
    },
    "14204749": {
      "citing_paper_info": {
        "title": "Text Line detection and Segmentation in Handwritten Gurumukhi Scripts",
        "abstract": "Gurumukhi script is a two dimensional composition of symbols with connected and disconnected diacritics. Handwritten Gurumukhi script has some complexities like connected, overlapped text lines. It is one of the major reasons for errors during the recognition process. Text line segmentation is a challenging job in unconstrained writer independent handwritten document image processing. There is a great need for research in the area of Punjabi handwriting recognition to resolve challenging problems involved in it. In this paper we have proposed an algorithm for text line segmentation in handwritten Punjabi document that deals with the problems like overlapped and connected components in text line and extract text lines from handwritten document image. The text line detection algorithm is based on locating the most favourable segments of text line and associating it with its respective text line inserting a gap between neighbouring text lines.",
        "year": 2013,
        "venue": "",
        "authors": [
          {
            "authorId": "17130737",
            "name": "Namisha Modi"
          },
          {
            "authorId": "3137861",
            "name": "Khushneet Jindal"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 4,
        "influential_count": 0,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "1913486",
        "250868",
        "9187881",
        "16993962"
      ],
      "citation_details": [
        {
          "citedcorpusid": 250868,
          "isinfluential": false,
          "contexts": [
            "(2013) proposed [7] a method that finds the text segmentation with the maximum average likeliness for the resulting characters."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten text segmentation using average longest path algorithm",
            "abstract": "",
            "year": 2013,
            "venue": "2013 IEEE Workshop on Applications of Computer Vision (WACV)",
            "authors": [
              {
                "authorId": "2968009",
                "name": "D. Salvi"
              },
              {
                "authorId": "2151549514",
                "name": "Jun Zhou"
              },
              {
                "authorId": "32655613",
                "name": "Jarrell W. Waggoner"
              },
              {
                "authorId": "40696794",
                "name": "Song Wang"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1913486,
          "isinfluential": false,
          "contexts": [
            "(2009) proposed [5] technique to segment handwritten document images into text lines by shredding their surface with local minima tracer."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 9187881,
          "isinfluential": false,
          "contexts": [
            "(2008) proposed an approach [2] based on density estimation and a state-of-the-art image segmentation technique, the level set method."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16993962,
          "isinfluential": false,
          "contexts": [
            "The fuzzy RLSA [10] measure is calculated for every pixel on the initial image and describes that how far one can see when standing at a pixel along horizontal path."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line separation for complex document images using fuzzy runlength",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "A. Nicolaou et al. (2009) proposed [5] technique to segment handwritten document images into text lines by shredding their surface with local minima tracer."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "…step is to correct feasible splitting, to detect text lines that the previous step did not expose and, finally, to disconnect vertically connected [10] measure is calculated for every pixel on the initial image and describes that how far one can see when standing at a pixel along horizontal path."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "220514458": {
      "citing_paper_info": {
        "title": "Joint Layout Analysis, Character Detection and Recognition for Historical Document Digitization",
        "abstract": "In this paper, we propose an end-to-end trainable framework for restoring historical documents content that follows the correct reading order. In this framework, two branches named character branch and layout branch are added behind the feature extraction network. The character branch localizes individual characters in a document image and recognizes them simultaneously. Then we adopt a post-processing method to group them into text lines. The layout branch based on fully convolutional network outputs a binary mask. We then use Hough transform for line detection on the binary mask and combine character results with the layout information to restore document content. These two branches can be trained in parallel and are easy to train. Furthermore, we propose a re-score mechanism to minimize recognition error. Experiment results on the extended Chinese historical document MTHv2 dataset demonstrate the effectiveness of the proposed framework.",
        "year": 2020,
        "venue": "International Conference on Frontiers in Handwriting Recognition",
        "authors": [
          {
            "authorId": "2111665571",
            "name": "Weihong Ma"
          },
          {
            "authorId": "1816713823",
            "name": "Hesuo Zhang"
          },
          {
            "authorId": "144838978",
            "name": "Lianwen Jin"
          },
          {
            "authorId": "66939932",
            "name": "Sihang Wu"
          },
          {
            "authorId": "48094112",
            "name": "Jiapeng Wang"
          },
          {
            "authorId": "153709848",
            "name": "Yongpan Wang"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 10,
        "unique_cited_count": 10,
        "influential_count": 2,
        "detailed_records_count": 10
      },
      "cited_papers": [
        "10716717",
        "22684617",
        "5808102",
        "2530196",
        "14177552",
        "26232274",
        "211026548",
        "54465873",
        "3719281",
        "204744040"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2530196,
          "isinfluential": false,
          "contexts": [
            "Top-down approaches such as projection profile analysis [3], recursive x-y cuts [4] and white space analysis [5], start from the whole image and then find components recursively."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A prototype document image analysis system for technical journals",
            "abstract": "",
            "year": 1992,
            "venue": "Computer",
            "authors": [
              {
                "authorId": "145916951",
                "name": "G. Nagy"
              },
              {
                "authorId": "145062511",
                "name": "S. Seth"
              },
              {
                "authorId": "145266621",
                "name": "M. Viswanathan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3719281,
          "isinfluential": false,
          "contexts": [
            "Wick et al. [7] classified the image pixels into the background and other text types using a U-Net [15] structure model.",
            "[7] classified the image pixels into the background and other text types using a U-Net [15] structure model."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
            "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .",
            "year": 2015,
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "authors": [
              {
                "authorId": "1737326",
                "name": "O. Ronneberger"
              },
              {
                "authorId": "152702479",
                "name": "P. Fischer"
              },
              {
                "authorId": "1710872",
                "name": "T. Brox"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5808102,
          "isinfluential": false,
          "contexts": [
            "256C3 - BN - ReLU - dropout - 256C3 - BN - ReLU dropout - 2C1, where xCy represents a convolutional layer with kernel size of y×y and output channels of x, BN, dropout means batch normalization layer [19] and dropout layer [20], respectively."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
            "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.",
            "year": 2015,
            "venue": "International Conference on Machine Learning",
            "authors": [
              {
                "authorId": "2054165706",
                "name": "Sergey Ioffe"
              },
              {
                "authorId": "2574060",
                "name": "Christian Szegedy"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10716717,
          "isinfluential": true,
          "contexts": [
            "Functionally, the framework consists of three components: ResNet-50 [17] with feature pyramid network (FPN) [18] as backbone, layout branch for generating binary mask",
            "Functionally, the framework consists of three components: ResNet-50 [17] with feature pyramid network (FPN) [18] as backbone, layout branch for generating binary mask containing a region of lines, character branch for generating character detection and classification results.",
            "In the character branch implementation, following FPN [18], we assign anchors on different stages depending on their size.",
            "FPN uses a top-down architecture with lateral connections to fuse features of different resolutions from a single-scale input, which improves accuracy with marginal cost.",
            "B. Implementation details\nIn the character branch implementation, following FPN [18], we assign anchors on different stages depending on their size.",
            "To extract more robust features at different scales, we use a ResNet-50 with feature pyramid structure [18]."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['methodology']",
            "--",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Feature Pyramid Networks for Object Detection",
            "abstract": "Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But pyramid representations have been avoided in recent object detectors that are based on deep convolutional networks, partially because they are slow to compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "33493200",
                "name": "Tsung-Yi Lin"
              },
              {
                "authorId": "3127283",
                "name": "Piotr Dollár"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              },
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "1790580",
                "name": "Bharath Hariharan"
              },
              {
                "authorId": "50172592",
                "name": "Serge J. Belongie"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14177552,
          "isinfluential": false,
          "contexts": [
            "One efficient way is to use a document digitization system [1], which can protect printed paper documents from the effect of direct manipulation for the purposes of consultation, exchange and remote access [2]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document digitization technology and its application for digital library in China",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "145507765",
                "name": "Xiaoqing Ding"
              },
              {
                "authorId": "145562240",
                "name": "Di Wen"
              },
              {
                "authorId": "1946049",
                "name": "Liangrui Peng"
              },
              {
                "authorId": "2107903806",
                "name": "Changsong Liu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22684617,
          "isinfluential": false,
          "contexts": [
            "[16] focused on the problem of various styles and used style transfer mapping method, which allowed the classifier trained by available printed Chinese characters to work on historical recognition."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Historical Chinese Character Recognition Method Based on Style Transfer Mapping",
            "abstract": "",
            "year": 2014,
            "venue": "2014 11th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "2132843294",
                "name": "Bohan Li"
              },
              {
                "authorId": "1946049",
                "name": "Liangrui Peng"
              },
              {
                "authorId": "2035405",
                "name": "Jingning Ji"
              }
            ]
          }
        },
        {
          "citedcorpusid": 26232274,
          "isinfluential": false,
          "contexts": [
            "[7] classified the image pixels into the background and other text types using a U-Net [15] structure model."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Fully Convolutional Neural Networks for Page Segmentation of Historical Document Images",
            "abstract": "We propose a high-performance fully convolutional neural network (FCN) for historical document segmentation that is designed to process a single page in one step. The advantage of this model beside its speed is its ability to directly learn from raw pixels instead of using preprocessing steps e. g. feature computation or superpixel generation. We show that this network yields better results than existing methods on different public data sets. For evaluation of this model we introduce a novel metric that is independent of ambiguous ground truth called Foreground Pixel Accuracy (FgPA). This pixel based measure only counts foreground pixels in the binarized page, any background pixel is omitted. The major advantage of this metric is, that it enables researchers to compare different segmentation methods on their ability to successfully segment text or pictures and not on their ability to learn and possibly overfit the peculiarities of an ambiguous hand-made ground truth segmentation.",
            "year": 2017,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "144603426",
                "name": "C. Wick"
              },
              {
                "authorId": "1707592",
                "name": "F. Puppe"
              }
            ]
          }
        },
        {
          "citedcorpusid": 54465873,
          "isinfluential": true,
          "contexts": [
            "We adopt RoIAlign to sample the proposals to a 7x7 size.",
            "Since the annotation format of text line is a quadrangle, we use the framework that supports the\nprediction of quadrangle as a comparative experiment, such as EAST [27] and Mask R-CNN [10], which has proven to be successful in other fields.",
            "prediction of quadrangle as a comparative experiment, such as EAST [27] and Mask R-CNN [10], which has proven to be successful in other fields.",
            "Methods such as Mask R-CNN and our character-based method, perform well on document text, and our method reaches the state-of-theart performance when the IoU threshold range from 0.5 to 0.7.",
            "Inspired by Mask R-CNN [10], which extends Faster RCNN [11] by adding a branch for predicting the segmentation mask, we also add a branch for layout analysis.",
            "Following the design of Faster R-CNN, we have two stages in the character branch.",
            "In our implementation, we adopt RoIAlign [10] rather than RoIPool.",
            "The second stage is Fast R-CNN [24], which extracts features using RoIPool from each candidate proposal and performs classification and bounding-box regression."
          ],
          "intents": [
            "--",
            "--",
            "['methodology']",
            "--",
            "['methodology']",
            "--",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Mask R-CNN",
            "abstract": "We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.",
            "year": 2017,
            "venue": "",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2082991",
                "name": "Georgia Gkioxari"
              },
              {
                "authorId": "3127283",
                "name": "Piotr Dollár"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 204744040,
          "isinfluential": false,
          "contexts": [
            "It has been proved in the field of scene text [22], [23]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Convolutional Character Networks",
            "abstract": "Recent progress has been made on developing a unified framework for joint text detection and recognition in natural images, but existing joint models were mostly built on two-stage framework by involving ROI pooling, which can degrade the performance on recognition task. In this work, we propose convolutional character networks, referred as CharNet, which is an one-stage model that can process two tasks simultaneously in one pass. CharNet directly outputs bounding boxes of words and characters, with corresponding character labels. We utilize character as basic element, allowing us to overcome the main difficulty of existing approaches that attempted to optimize text detection jointly with a RNN-based recognition branch. In addition, we develop an iterative character detection approach able to transform the ability of character detection learned from synthetic data to real-world images. These technical improvements result in a simple, compact, yet powerful one-stage model that works reliably on multi-orientation and curved text. We evaluate CharNet on three standard benchmarks, where it consistently outperforms the state-of-the-art approaches [25, 24] by a large margin, e.g., with improvements of 65.33%->71.08% (with generic lexicon) on ICDAR 2015, and 54.0%->69.23% on Total-Text, on end-to-end text recognition. Code is available at: https://github.com/MalongTech/research-charnet.",
            "year": 2019,
            "venue": "IEEE International Conference on Computer Vision",
            "authors": [
              {
                "authorId": "3422833",
                "name": "Linjie Xing"
              },
              {
                "authorId": "2069520672",
                "name": "Zhi Tian"
              },
              {
                "authorId": "49015548",
                "name": "Weilin Huang"
              },
              {
                "authorId": "1915350",
                "name": "Matthew R. Scott"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211026548,
          "isinfluential": false,
          "contexts": [
            "With the development of deep learning in recent years, significant progress has been made in these two stages (layout analysis and text recognition) [6]–[9].",
            "[9] proposed a character attention generative adversarial network to create high visibility images from severely degraded or low visibility input images."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Character Attention Generative Adversarial Network for Degraded Historical Document Restoration",
            "abstract": "Despite of recent breakthroughs in the accuracy of single character recognition using the deeper convolution neural networks, one of the remaining problems is that OCRs almost fail to recognize character patterns when they are severely degraded, especially those of the historical documents. Another problem to recognize characters in historical documents is the lack of sufficient training patterns because of the heavy cost for annotation. This paper proposes a character attention generative adversarial network named CAGAN for restoring heavily degraded character patterns in historical documents so that OCRs improve their accuracy and even help archeologists to decode them. The network is based on the U-Net like architecture [1] with skip connections, and it is trained by the proposed loss function including the common adversarial loss (global loss) and the hierarchical character attentive loss (local loss). We made an experiment on 118 categories of most common Japanese Kanji characters, collected from severely damaged historical documents called Heijokyo mokkan written during the Nara period in Japan. The experiment shows that our method restores the shapes of characters and improves the recognition rate significantly, which is helpful for archeologists to decode damaged character patterns.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "29367641",
                "name": "K. Nguyen"
              },
              {
                "authorId": "2342621",
                "name": "Cuong Tuan Nguyen"
              },
              {
                "authorId": "49084892",
                "name": "S. Hotta"
              },
              {
                "authorId": "145887653",
                "name": "M. Nakagawa"
              }
            ]
          }
        }
      ]
    },
    "15936873": {
      "citing_paper_info": {
        "title": "Extended Approach to Water Flow Algorithm for Text Line Segmentation",
        "abstract": "",
        "year": 2012,
        "venue": "Journal of Computational Science and Technology",
        "authors": [
          {
            "authorId": "2008869",
            "name": "D. Brodic"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 7,
        "influential_count": 0,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "619938",
        "2586526",
        "2775421",
        "16993962",
        "15255033",
        "3086976",
        "2651129"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "Keywords document image analysis, text segmentation, region growing, smearing method, water flow algorithm"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2586526,
          "isinfluential": false,
          "contexts": [
            "They consist of a few text experiments as follows[15-18]: • multi-line straight text segmentation test, • multi-line waved text segmentation test, • multi-line fractured text segmentation test, • handwritten text segmentation test."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Basic Test Framework for the Evaluation of Text Line Segmentation and Text Parameter Extraction",
            "abstract": "Text line segmentation is an essential stage in off-line optical character recognition (OCR) systems. It is a key because inaccurately segmented text lines will lead to OCR failure. Text line segmentation of handwritten documents is a complex and diverse problem, complicated by the nature of handwriting. Hence, text line segmentation is a leading challenge in handwritten document image processing. Due to inconsistencies in measurement and evaluation of text segmentation algorithm quality, some basic set of measurement methods is required. Currently, there is no commonly accepted one and all algorithm evaluation is custom oriented. In this paper, a basic test framework for the evaluation of text feature extraction algorithms is proposed. This test framework consists of a few experiments primarily linked to text line segmentation, skew rate and reference text line evaluation. Although they are mutually independent, the results obtained are strongly cross linked. In the end, its suitability for different types of letters and languages as well as its adaptability are its main advantages. Thus, the paper presents an efficient evaluation method for text analysis algorithms.",
            "year": 2010,
            "venue": "Italian National Conference on Sensors",
            "authors": [
              {
                "authorId": "2008869",
                "name": "D. Brodic"
              },
              {
                "authorId": "2489351",
                "name": "D. Milivojevic"
              },
              {
                "authorId": "2393591",
                "name": "Z. Milivojevic"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2651129,
          "isinfluential": false,
          "contexts": [
            "For the evaluation of the testing results, the methodology based on extended binary classification is exploited([16,18]).",
            "They consist of a few text experiments as follows[15-18]: • multi-line straight text segmentation test, • multi-line waved text segmentation test, • multi-line fractured text segmentation test, • handwritten text segmentation test.",
            "According to the binary classification, the evaluation process is made by precision, recall, and f measure[16,18-20]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An Approach to a Comprehensive Test Framework for Analysis and Evaluation of Text Line Segmentation Algorithms",
            "abstract": "The paper introduces a testing framework for the evaluation and validation of text line segmentation algorithms. Text line segmentation represents the key action for correct optical character recognition. Many of the tests for the evaluation of text line segmentation algorithms deal with text databases as reference templates. Because of the mismatch, the reliable testing framework is required. Hence, a new approach to a comprehensive experimental framework for the evaluation of text line segmentation algorithms is proposed. It consists of synthetic multi-like text samples and real handwritten text as well. Although the tests are mutually independent, the results are cross-linked. The proposed method can be used for different types of scripts and languages. Furthermore, two different procedures for the evaluation of algorithm efficiency based on the obtained error type classification are proposed. The first is based on the segmentation line error description, while the second one incorporates well-known signal detection theory. Each of them has different capabilities and convenience, but they can be used as supplements to make the evaluation process efficient. Overall the proposed procedure based on the segmentation line error description has some advantages, characterized by five measures that describe measurement procedures.",
            "year": 2011,
            "venue": "Italian National Conference on Sensors",
            "authors": [
              {
                "authorId": "2008869",
                "name": "D. Brodic"
              },
              {
                "authorId": "2489351",
                "name": "D. Milivojevic"
              },
              {
                "authorId": "2393591",
                "name": "Z. Milivojevic"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2775421,
          "isinfluential": false,
          "contexts": [
            "In addition, water flow angle α can be selected from 0◦ to 90◦[7-8].",
            "For the purpose of algorithm’s testing, the water flow angle α is used from the reduced set {10◦, 12◦, 14◦}[8,17].",
            "Water flow algorithm is improved in [7-8]."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "A New Approach to Water Flow Algorithm for Text Line Segmentation",
            "abstract": "This paper proposes a new approach to water flow algorithm for the text line segmentation. Original method assumes hypothetical water flows under a few specified angles to the document image frame from left to right and vice versa. As a result, unwetted image frames are extracted. These areas are of major importance for text line segmentation. Method modifications mean extension values of water flow angle and unwetted image frames function enlargement. Results are encouraging due to text line segmentation improvement which is the most challenging process stage in document image processing.",
            "year": 2011,
            "venue": "Journal of universal computer science (Online)",
            "authors": [
              {
                "authorId": "2008869",
                "name": "D. Brodic"
              },
              {
                "authorId": "2393591",
                "name": "Z. Milivojevic"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3086976,
          "isinfluential": false,
          "contexts": [
            "Keywords document image analysis, text segmentation, region growing, smearing method, water flow algorithm"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Robust skew detection in mixed text/graphics documents",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "144434788",
                "name": "A. Amin"
              },
              {
                "authorId": "2297171",
                "name": "S. Wu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15255033,
          "isinfluential": false,
          "contexts": [
            "In addition, water flow angle α can be selected from 0◦ to 90◦[7-8].",
            "Water flow algorithm is improved in [7-8]."
          ],
          "intents": [
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "An Approach to Modification of Water Flow Algorithm for Segmentation and Text Parameters Extraction",
            "abstract": "",
            "year": 2010,
            "venue": "Doctoral Conference on Computing, Electrical and Industrial Systems",
            "authors": [
              {
                "authorId": "2008869",
                "name": "D. Brodic"
              },
              {
                "authorId": "2393591",
                "name": "Z. Milivojevic"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16993962,
          "isinfluential": false,
          "contexts": [
            "Keywords document image analysis, text segmentation, region growing, smearing method, water flow algorithm"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Line separation for complex document images using fuzzy runlength",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        }
      ]
    },
    "8219959": {
      "citing_paper_info": {
        "title": "Text Line Segmentation of Handwritten Documents using Clustering Method based on Thresholding Approach",
        "abstract": "Segmentation of the text lines in an un-constrained handwritten documents still a challenging task because handwritten text lines are often un-uniformly skewed and curved, and the space between lines is not obvious. In this paper, we propose a text-line segmentation algorithm based on clustering using threshold. The connected components of document image are grouped, from which text-lines are extracted dynamically by coloring all the text-lines.",
        "year": 2012,
        "venue": "",
        "authors": [
          {
            "authorId": "2285993352",
            "name": "Ravi Kumar"
          },
          {
            "authorId": "116539712",
            "name": "N. Shetty"
          },
          {
            "authorId": "117554939",
            "name": "B. P. Pragath"
          },
          {
            "authorId": "2286160988",
            "name": "R. Srihari"
          },
          {
            "authorId": "2286156587",
            "name": "S. Srihari"
          },
          {
            "authorId": "2285566780",
            "name": "Fei Yin"
          },
          {
            "authorId": "2260635365",
            "name": "Cheng-Lin Liu"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 1,
        "unique_cited_count": 1,
        "influential_count": 0,
        "detailed_records_count": 1
      },
      "cited_papers": [
        "29276706"
      ],
      "citation_details": [
        {
          "citedcorpusid": 29276706,
          "isinfluential": false,
          "contexts": [
            "The grouping of components to text lines can be considered as a clustering problem, and has been treated using minimal spanning tree (MST) clustering [19]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Fast Algorithm for Bottom-Up Document Layout Analysis",
            "abstract": "This paper describes a new bottom-up method for document layout analysis. The algorithm was implemented in the CLIDE (Chemical Literature Data Extraction) system, but the method described here is suitable for a broader range of documents. It is based on Kruskal's algorithm and uses a special distance-metric between the components to construct the physical page structure. The method has all the major advantages of bottom-up systems: independence from different text spacing and independence from different block alignments. The algorithms computational complexity is reduced to linear by using heuristics and path-compression.",
            "year": 1997,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1863322",
                "name": "Anikó Simon"
              },
              {
                "authorId": "1907819",
                "name": "Jean-Christophe Pret"
              },
              {
                "authorId": "1406054409",
                "name": "A. Johnson"
              }
            ]
          }
        }
      ]
    },
    "8461025": {
      "citing_paper_info": {
        "title": "Graph Clustering-Based Ensemble Method for Handwritten Text Line Segmentation",
        "abstract": "",
        "year": 2011,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "144249397",
            "name": "V. Manohar"
          },
          {
            "authorId": "3306372",
            "name": "S. Vitaladevuni"
          },
          {
            "authorId": "39784761",
            "name": "Huaigu Cao"
          },
          {
            "authorId": "36073757",
            "name": "R. Prasad"
          },
          {
            "authorId": "145603129",
            "name": "P. Natarajan"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 9,
        "unique_cited_count": 9,
        "influential_count": 0,
        "detailed_records_count": 9
      },
      "cited_papers": [
        "15619292",
        "15333906",
        "18052869",
        "17705",
        "18751160",
        "15257932",
        "14628048",
        "14099068",
        "17844687"
      ],
      "citation_details": [
        {
          "citedcorpusid": 17705,
          "isinfluential": false,
          "contexts": [
            "Bertolami and Bunke [11] addressed the problem of text recognition using an ensemble of recognizers that were combined using ROVER."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Hidden Markov model-based ensemble methods for offline handwritten text line recognition",
            "abstract": "",
            "year": 2008,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "2168488",
                "name": "Roman Bertolami"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14099068,
          "isinfluential": false,
          "contexts": [
            "Finally, touching components were split at the contour level and the character images were reconstructed."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Co-clustering of image segments using convex optimization applied to EM neuronal reconstruction",
            "abstract": "",
            "year": 2010,
            "venue": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "3306372",
                "name": "S. Vitaladevuni"
              },
              {
                "authorId": "1760994",
                "name": "R. Basri"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14628048,
          "isinfluential": false,
          "contexts": [
            "In this section, we give a brief description of each line finding algorithm that constitutes the ensemble in this work."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Arabic text line segmentation using affinity propagation",
            "abstract": "",
            "year": 2010,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "2069634816",
                "name": "J. Kumar"
              },
              {
                "authorId": "1404588675",
                "name": "W. Abd-Almageed"
              },
              {
                "authorId": "145714522",
                "name": "Le Kang"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15257932,
          "isinfluential": false,
          "contexts": [
            "(II) Directional filter based approach [13]: This method is based on steerable directional filter, which found the local orientation of a text line by scanning in multiple directions."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition A Steerable Directional Local Profile Technique for Extraction of Handwritten Arabic Text Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 15333906,
          "isinfluential": false,
          "contexts": [
            "In [12], Prasad et al. developed a videotext recognition system that used ROVER for combining the hypotheses of a text region from multiple frames in the video."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Multi-frame combination for robust videotext recognition",
            "abstract": "Optical character recognition (OCR) of overlaid text in video streams is a challenging problem due to various factors including the presence of dynamic backgrounds, color, and low resolution. In video feeds such as Broadcast News, a particular overlaid text region usually persists for multiple frames during which the background may or may not vary. In this paper we explore two innovative techniques that exploit such multi-frame persistence of videotext. The first technique uses multiple instances to generate a single enhanced image for recognition. The second technique uses the NIST ROVER algorithm developed for speech recognition to combine 1-best hypotheses from different frames of a text region. Significant improvement in the word error rate (WER) is obtained by using ROVER when compared to recognizing a single instance. The WER is further reduced by combining hypotheses from frame instances, which were generated using character models trained with different binarization thresholds. A 20% relative reduction in the WER was achieved for multi-frame combination over decoding a single frame instance.",
            "year": 2008,
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "authors": [
              {
                "authorId": "36073757",
                "name": "R. Prasad"
              },
              {
                "authorId": "1808737",
                "name": "S. Saleem"
              },
              {
                "authorId": "2281847",
                "name": "Ehry MacRostie"
              },
              {
                "authorId": "145603129",
                "name": "P. Natarajan"
              },
              {
                "authorId": "2128428",
                "name": "M. Decerbo"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15619292,
          "isinfluential": false,
          "contexts": [
            "Finally, touching components were split at the contour level and the character images were reconstructed."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Clustering with qualitative information",
            "abstract": "",
            "year": 2003,
            "venue": "44th Annual IEEE Symposium on Foundations of Computer Science, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "1745732",
                "name": "M. Charikar"
              },
              {
                "authorId": "1721077",
                "name": "V. Guruswami"
              },
              {
                "authorId": "40009100",
                "name": "Anthony Wirth"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17844687,
          "isinfluential": false,
          "contexts": [
            "We evaluated the line segmentation algorithms using the protocol established in [1] that computes precision and recall metrics by finding one-to-one mapping between the truth lines and the system hypothesized lines.",
            "55% using the FM metric in ICDAR 2009 text line segmentation competition [1] achieved 56."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition ICDAR2009 Handwriting Segmentation Contest",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 18052869,
          "isinfluential": false,
          "contexts": [
            "In isolated word recognition, Wang et al. [10] proposed an approach where instead of using word classes, words were treated as sequences of character classes."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Combination of multiple classifiers for handwritten word recognition",
            "abstract": "",
            "year": 2002,
            "venue": "Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2108936718",
                "name": "Wenwei Wang"
              },
              {
                "authorId": "1711505",
                "name": "A. Brakensiek"
              },
              {
                "authorId": "145512909",
                "name": "G. Rigoll"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18751160,
          "isinfluential": false,
          "contexts": [
            "Ensemble methods have been successfully applied in continuous speech recognition where, a system called ROVER (Recognizer Output Voting Error Reduction) [8] was developed to reduce the word error rate by aligning and combining the results from multiple speech recognizers."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER)",
            "abstract": "",
            "year": 1997,
            "venue": "1997 IEEE Workshop on Automatic Speech Recognition and Understanding Proceedings",
            "authors": [
              {
                "authorId": "3241934",
                "name": "Jonathan G. Fiscus"
              }
            ]
          }
        }
      ]
    },
    "204956514": {
      "citing_paper_info": {
        "title": "Comparative Study of Text Line Segmentation on Handwritten Kannada Documents",
        "abstract": "Optical Character Recognition is the process of transforming printed or handwritten text in to a form in which computer can understand and manipulate. An important task of any Optical Character Recognition(OCR)system is segmentation. Characters, words and lines are separated from image text documents by segmentation. Depending on the segmentation algorithm which is being used can affect the accuracy of OCR system. Segmentation of handwritten Kannada script poses challenges due to writing styles, skewed lines, overlapping lines, inter and intra word gaps. The aim of this paper is to investigate different text line segmentation techniques like Projection profiles, Run Length Smearing method, Median segmentation and Bounding box method on Handwritten Kannada documents. The above said methods have been tested on two different datasets of varying complexity. A total number of 200 samples is used for experimentation. These methods are experimented and compare their accuracy and results. Keywords— Segmentation, Handwriting, Textlines, Handwritten Kannada Documents.",
        "year": 2015,
        "venue": "",
        "authors": [
          {
            "authorId": "91209858",
            "name": "Chethana"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 1,
        "unique_cited_count": 1,
        "influential_count": 0,
        "detailed_records_count": 1
      },
      "cited_papers": [
        "4761367"
      ],
      "citation_details": [
        {
          "citedcorpusid": 4761367,
          "isinfluential": false,
          "contexts": [
            ", [14] Component extension technique 250 Not specified"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of unconstrained handwritten Kannada script",
            "abstract": "",
            "year": 2011,
            "venue": "International Conference on Communication, Computing & Security",
            "authors": [
              {
                "authorId": "1710382",
                "name": "Manjunath Aradhya"
              },
              {
                "authorId": "144991125",
                "name": "C. Naveena"
              }
            ]
          }
        }
      ]
    },
    "31698893": {
      "citing_paper_info": {
        "title": "A Multi-scale Text Line Segmentation Method in Freestyle Handwritten Documents",
        "abstract": "",
        "year": 2011,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "10832548",
            "name": "Yangdong Gao"
          },
          {
            "authorId": "145507765",
            "name": "Xiaoqing Ding"
          },
          {
            "authorId": "2107903806",
            "name": "Changsong Liu"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 4,
        "unique_cited_count": 4,
        "influential_count": 2,
        "detailed_records_count": 4
      },
      "cited_papers": [
        "14210437",
        "1913486",
        "16715193",
        "3345452"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1913486,
          "isinfluential": true,
          "contexts": [
            "In this way the computation amount is reduced compared with [4], in which the paths start from every point along the border of the image, (see Fig.",
            "For each pair of the text lines, there exists a path from the left to right border that separates those two text lines [4].",
            "In practicing experiment, we find it’s a hard task to determine the size of the blurring window, and the result estimated by [4] is not stable or robust enough.",
            "In [4], the input image is blurred to suppress noise before further processing.",
            "The equation (2) inspired by [4] is recursively used to find each coordinate of paths dynamically."
          ],
          "intents": [
            "['background']",
            "['background']",
            "--",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 3345452,
          "isinfluential": false,
          "contexts": [
            "Thanks to the Hungarian algorithm [7], the global optimal solution can be obtained in an acceptable time."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Optimal matching problem in detection and recognition performance evaluation",
            "abstract": "",
            "year": 2002,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "2146562400",
                "name": "Gang Liu"
              },
              {
                "authorId": "1710238",
                "name": "R. Haralick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14210437,
          "isinfluential": false,
          "contexts": [
            "The Hough-based algorithms [2] can not deal with the problem of different skew angles in the same text line."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Block-Based Hough Transform Mapping for Text Line Detection in Handwritten Documents",
            "abstract": "In this paper, we present a new text line detection method for unconstrained handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes preprocessing for image enhancement, connected component extraction and average character height estimation. In the second step, a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible false alarms. The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "70602633",
                "name": "K. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16715193,
          "isinfluential": true,
          "contexts": [
            "EXPERIMENTAL RESULTS The proposed text line segmentation is tested mainly on HIT-MW [8], a freestyle, unconstrained Chinese handwritten text image database written by multiple writers.",
            "TABLE I. COMPARATIVE RESULTS OVER THE HIT-MW DATASET\nA table of segmentation results by other method [9] and our method is given to illustrate the predominance of ours.",
            "The proposed text line segmentation is tested mainly on HIT-MW [8], a freestyle, unconstrained Chinese handwritten text image database written by multiple writers.",
            "In general, the proposed method outperforms the previously reported ones over the HIT-MW dataset."
          ],
          "intents": [
            "--",
            "--",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "HIT-MW Dataset for Offline Chinese Handwritten Text Recognition",
            "abstract": "A Chinese handwritten text dataset, HIT-MW, is presented to facilitate the offline Chinese handwritten text recognition. Texts for handcopying are sampled from China Daily corpus with a stratified random manner. To collect naturally written handwriting, forms are distributed by postal mail or middleman instead of face to face. The current version of HIT-MW includes 853 forms and 186,444 characters that are written by more than 780 participants under an unconstrained condition without preprinted character boxes. Its lexical coverage of 3,041 characters is about 99.33% measured on China Daily corpus with about 80 million characters. Handwritten texts of HIT-MW mainly written by college students follow a balanced distribution both in sex and in department. It can be used to conduct Chinese textline segmentation, segmentation-free recognition, and to verify the effect of statistical language model in a real handwriting situation.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "40523977",
                "name": "Tonghua Su"
              },
              {
                "authorId": "1821107",
                "name": "Tianwen Zhang"
              },
              {
                "authorId": "2438618",
                "name": "D. Guan"
              }
            ]
          }
        }
      ]
    },
    "246883668": {
      "citing_paper_info": {
        "title": "Character Detection and Segmentation of Historical Uchen Tibetan Documents in Complex Situations",
        "abstract": "Tibetan is a low-resource language, and Tibetan culture carried by historical Tibetan documents is an important part of Chinese civilization. The study of historical Tibetan documents is of great significance to the protection of Tibetan culture and the promotion of Chinese culture. Character segmentation is an important step in image analysis and recognition of historical Tibetan documents. However, the following three challenges prevent solving problems of character segmentation in historical Tibetan documents: 1) the text lines have different degrees of tilt and twist; 2) there are many complex situations such as overlapping, crossing, touching and breaking character strokes; and 3) these documents are written by different people with different stroke styles. To resolve these problems, we propose a character segmentation method based on key feature information for historical Tibetan documents. The proposed method consists of three parts: 1) projection and syllable point location information are used to shorten the text lines of historical Tibetan documents and establish a character block database; 2) the local baseline of the character block is detected by using the location information of syllable points or combined with horizontal projection and straight line detection, and the character block is divided into two areas above and below the baseline, and different segmentation methods are adopted; and 3) in view of the large difference in stroke styles, three stroke attribution distances are used to complete the attribution. The experimental results show that the method proposed in this paper can effectively solve the problem of character segmentation of historical Tibetan documents and achieve a better character segmentation effect, which also provides a reference for the relevant document character segmentation.",
        "year": 2022,
        "venue": "IEEE Access",
        "authors": [
          {
            "authorId": null,
            "name": "Ce Zhang"
          },
          {
            "authorId": "2108487739",
            "name": "Weilan Wang"
          },
          {
            "authorId": "9244976",
            "name": "Huaming Liu"
          },
          {
            "authorId": "2116628830",
            "name": "Guowei Zhang"
          },
          {
            "authorId": "40526686",
            "name": "Qiang Lin"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 12,
        "unique_cited_count": 12,
        "influential_count": 0,
        "detailed_records_count": 12
      },
      "cited_papers": [
        "222222512",
        "3900366",
        "206775077",
        "9878029",
        "203673431",
        "127518132",
        "209336542",
        "12153821",
        "125176655",
        "201811495",
        "164777584",
        "23561492"
      ],
      "citation_details": [
        {
          "citedcorpusid": 3900366,
          "isinfluential": false,
          "contexts": [
            "Sahare and Dhok [35] first used the character characteristic information to segment the touching characters and then completed the character segmentation of multilingual Indian documents composed of Latin and Devanagari by using the graph distance."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Multilingual Character Segmentation and Recognition Schemes for Indian Document Images",
            "abstract": "In this paper, robust algorithms for character segmentation and recognition are presented for multilingual Indian document images of Latin and Devanagari scripts. These documents generally suffer from their layout organizations, local skews, and low print quality and contain intermixed texts (machine-printed and handwritten). In the proposed character segmentation algorithm, primary segmentation paths are obtained using structural property of characters, whereas overlapped and joined characters are separated using graph distance theory. Finally, segmentation results are validated using highly accurate support vector machine classifier. For the proposed character recognition algorithm, three new geometrical shape-based features are computed. First and second features are formed with respect to the center pixel of character, whereas neighborhood information of text pixels is used for the calculation of third feature. For recognizing the input character,  $k$ -Nearest Neighbor classifier is used, as it has intrinsically zero training time. Comprehensive experiments are carried out on different databases containing printed as well as handwritten texts. Benchmarking results illustrate that proposed algorithms have better performances compared to other contemporary approaches, where highest segmentation and recognition rates of 98.86% and 99.84%, respectively, are obtained.",
            "year": 2018,
            "venue": "IEEE Access",
            "authors": [
              {
                "authorId": "36512205",
                "name": "Parul Sahare"
              },
              {
                "authorId": "143953729",
                "name": "S. B. Dhok"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9878029,
          "isinfluential": false,
          "contexts": [
            "Ji et al. [33] segmented historical Chinese documents by graph nodes and assigned the segmented characters according to the optimal path of the graph."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Graph Model Optimization Based Historical Chinese Character Segmentation Method",
            "abstract": "",
            "year": 2014,
            "venue": "2014 11th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "2035405",
                "name": "Jingning Ji"
              },
              {
                "authorId": "1946049",
                "name": "Liangrui Peng"
              },
              {
                "authorId": "2132843294",
                "name": "Bohan Li"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12153821,
          "isinfluential": false,
          "contexts": [
            "Since 2010, researchers have carried out relevant studies on image preprocessing [4][5], layout analysis [6][8], text line segmentation [9]- [12], character segmentation [13][14], dataset construction [15][16], character recognition [17][18] and other aspects of historical Tibetan documents."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Recognition of Tibetan wood block prints with generalized hidden Markov and kernelized modified quadratic distance function",
            "abstract": "",
            "year": 2011,
            "venue": "MOCR_AND '11",
            "authors": [
              {
                "authorId": "2714455",
                "name": "Fares Hedayati"
              },
              {
                "authorId": "3185853",
                "name": "J. Chong"
              },
              {
                "authorId": "1732330",
                "name": "K. Keutzer"
              }
            ]
          }
        },
        {
          "citedcorpusid": 23561492,
          "isinfluential": false,
          "contexts": [
            "The projection method and stroke width transform (SWT) were used to solve touching Japanese segmentation [27].",
            "Since 2010, researchers have carried out relevant studies on image preprocessing [4][5], layout analysis [6][8], text line segmentation [9]- [12], character segmentation [13][14], dataset construction [15][16], character recognition [17][18] and other aspects of historical Tibetan documents."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Enhanced Character Segmentation for Format-Free Japanese Text Recognition",
            "abstract": "This paper presents Optical Handwritten Text Recognition (OHTR) for casually handwritten Japanese text. Distortions due to handwriting and the mixture of complex Chinese characters with simple phonetic and alphanumeric characters leave OHTR for handwritten Japanese text as still one of the hardest problems. This paper proposes a method for segmenting characters in handwritten text-pages, and a robust recognition model for over-segmentation. Stroke Width Transform (SWT), a new method of bridge separation at fork points and Voronoi diagrams with two improvements are proposed for character segmentation, and then a recognition model is employed with linguistic context and geometric context to recognize segmented characters. The results of experiments show that the proposed method improves the segmentation and recognition rates and each component in the method contributes to the improvement.",
            "year": 2016,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2070875547",
                "name": "Nguyen Cong Kha"
              },
              {
                "authorId": "30958878",
                "name": "Nakagawa Masaki"
              }
            ]
          }
        },
        {
          "citedcorpusid": 125176655,
          "isinfluential": false,
          "contexts": [
            "Since 2010, researchers have carried out relevant studies on image preprocessing [4][5], layout analysis [6][8], text line segmentation [9][12], character segmentation [13][14], dataset construction [15][16], character recognition [17][18] and other aspects of historical Tibetan documents."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text extraction method for historical Tibetan document images based on block projections",
            "abstract": "",
            "year": 2017,
            "venue": "Optoelectronics Letters",
            "authors": [
              {
                "authorId": "7667827",
                "name": "Lijuan Duan"
              },
              {
                "authorId": "2108171941",
                "name": "Xiqun Zhang"
              },
              {
                "authorId": "2072987",
                "name": "Long-Long Ma"
              },
              {
                "authorId": "46177912",
                "name": "Jian Wu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 127518132,
          "isinfluential": false,
          "contexts": [
            "Since 2010, researchers have carried out relevant studies on image preprocessing [4][5], layout analysis [6][8], text line segmentation [9]- [12], character segmentation [13][14], dataset construction [15][16], character recognition [17][18] and other aspects of historical Tibetan documents."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A novel method of text line segmentation for historical document image of the uchen Tibetan",
            "abstract": "",
            "year": 2019,
            "venue": "Journal of Visual Communication and Image Representation",
            "authors": [
              {
                "authorId": "49970018",
                "name": "Zhenjiang Li"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              },
              {
                "authorId": "145906066",
                "name": "Yang Chen"
              },
              {
                "authorId": "1574182682",
                "name": "Yusheng Hao"
              }
            ]
          }
        },
        {
          "citedcorpusid": 164777584,
          "isinfluential": false,
          "contexts": [
            "Since 2010, researchers have carried out relevant studies on image preprocessing [4][5], layout analysis [6][8], text line segmentation [9]- [12], character segmentation [13][14], dataset construction [15][16], character recognition [17][18] and other aspects of historical Tibetan documents."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Historical Document Image Binarization Based on Edge Contrast Information",
            "abstract": "",
            "year": 2019,
            "venue": "Computer Vision Conference",
            "authors": [
              {
                "authorId": "49970018",
                "name": "Zhenjiang Li"
              },
              {
                "authorId": "2254980",
                "name": "Weilan Wang"
              },
              {
                "authorId": "2113441483",
                "name": "Zhengqi Cai"
              }
            ]
          }
        },
        {
          "citedcorpusid": 201811495,
          "isinfluential": false,
          "contexts": [
            "Ali and Suresha [25] used character geometry and shape information to solve the problem of vertical segmentation of touching Arabic characters."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An Efficient Character Segmentation Algorithm for Recognition of Arabic Handwritten Script",
            "abstract": "This manuscript proposed a new novel algorithm for vertical segmentation because the accuracy of recognition will be very high if there is a good character segmentation. For the purpose of locate the segmentation points used the word image thinning to fetch the width of stroke of one pixel and to detect the ligatures of Arabic characters geometry and shape are used in the segmentation procedure. The proposed segmentation approach is worked with touching characters, in case of ligatures touching segmentation existing between the characters of consecutive closed and the existence of ligatures within characters in the case of open characters. It evaluated on IFN/ENIT, AHDB and our dataset. It shows higher accuracy with an excellent performance by decreasing over-segmentation problem which showed through open characters segmentation and correct the segmentation in cases of the touching characters or the miss-segmentation errors in images of word.",
            "year": 2019,
            "venue": "2019 International Conference on Data Science and Communication (IconDSC)",
            "authors": [
              {
                "authorId": "144413990",
                "name": "A. Ali"
              },
              {
                "authorId": "143755246",
                "name": "M. Suresha"
              }
            ]
          }
        },
        {
          "citedcorpusid": 203673431,
          "isinfluential": false,
          "contexts": [
            "Zhou et al. [19] first used the projection method to perform rough segmentation and divided Chinese characters into touching and untouching categories."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Multi-step Segmentation Method Based on Minimum Weight Segmentation Path for Ancient Handwritten Chinese Character",
            "abstract": "A multi-step segmentation method was put forward in this paper to segment connected or overlaps Chinese character of ancient document.It inherited the fuzzy approach of the rough segmentation and fine segmentation.Firstly,the project profile histogram method was employed to obtain the no touching or overlapping characters from the separated blocks of the characters string.Then,for the touching characters in the wide blocks,the segmentation is performed by searching and modifying the segmentation path in the local neighborhood of initial segmentation path with minimum weight segmentation path algorithm,and the initial segmentation path was obtained according to the statistical data of rough segmentation.Experimental results show that the proposed method solves the problem of insufficient segmentation character and multiple touching character segmentation,the proposed method can improve the accuracy of handwritten Chinese character segmentation effectively,and the algorithm has a lower time complexity.",
            "year": 2012,
            "venue": "",
            "authors": [
              {
                "authorId": "1391302298",
                "name": "Gong Shengrong"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206775077,
          "isinfluential": false,
          "contexts": [
            "The drop fall algorithm [28] was initially applied to the segmentation of touching numbers, and then it was continuously improved and applied to the segmentation of touching numbers [29][30] or touching verification code [31]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Segmentation and Recognition of Handwritten Numeric Chains",
            "abstract": "Automatic reading of numeric chains has been attempted in several application areas such as bank cheque processing, postal code recognition and form processing. Such applications have been very popular in handwriting recognition research, due to the possibility to reduce considerably the manual effort involved in these tasks. In this study we propose an off line system for the recognition of the handwritten numeric chains. Firstly, study was based mainly on the evaluation of neural network performances, trained with the gradient back propagation algorithm. Used parameters to form the input vector of the neural network are extracted on the binary images of the digits by several methods: distribution sequence, Barr features and centred moments of different projections and profiles. Secondly, study was extented for the reading of the handwritten numeric chains constituted of a variable number of digits. Vertical projection was used to segment the numeric chain at isolated digits and every digit (or segment) was presented separately to the entry of the system achieved in the first part (recognition system of the isolated handwritten digits). The performances of the proposed system for the used database attain a recognition rate equal to 91.3%.",
            "year": 2007,
            "venue": "",
            "authors": [
              {
                "authorId": "9377717",
                "name": "Salim Ouchtati"
              },
              {
                "authorId": "2795933",
                "name": "M. Bedda"
              },
              {
                "authorId": "9236920",
                "name": "Abderrazak Lachouri"
              }
            ]
          }
        },
        {
          "citedcorpusid": 209336542,
          "isinfluential": false,
          "contexts": [
            "Thongkanchorn et al. [23] proposed a vertical and horizontal segmentation method based on a 4-direction depth-first search algorithm and completed the segmentation of Thai characters."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Thai Character Segmentation in Handwriting Images using Four Directional Depth First Search",
            "abstract": "One of the key processes for converting handwriting images into digital texts is the character segmentation. It is very challenge especially for the case of segmenting the hand-writing due to intra-variations of various writing styles and overlapping of characters between consecutive characters. This paper works on Thai characters in handwriting images. Thai characters consist of different types of consonants, tones and vowels, which are written in different manners. This paper proposes the 4 directional depth first search based approach for segmenting individual characters in both vertical and horizontal cutting aspects. The vertical cut is applied to segment each text column, while the horizontal cut is applied to segment individual characters. Then, the erosion with two structuring elements is used to split overlapped consecutive characters that may be remained after the main segmentation process. The proposed method is validated with 11,949 Thai characters in handwriting images. It achieves up to 90.76 % of the successful segmentation.",
            "year": 2019,
            "venue": "International Conferences on Information Technologies and Electrical Engineering",
            "authors": [
              {
                "authorId": "9116954",
                "name": "Kittikhun Thongkanchorn"
              },
              {
                "authorId": "32213255",
                "name": "Sarattha Kanchanapreechakorn"
              },
              {
                "authorId": "115720755",
                "name": "Punyanuch Borwarnginn"
              },
              {
                "authorId": "2992582",
                "name": "Worapan Kusakunniran"
              }
            ]
          }
        },
        {
          "citedcorpusid": 222222512,
          "isinfluential": false,
          "contexts": [
            "Gao et al. [36] proposed a character segmentation method based on fully convolutional neural networks (FCNs) to solve the complex problems of Chinese character touching and breaking, which extracts the spatial features of characters using convolutional neural networks."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Novel Semantic Segmentation Model for Chinese Characters",
            "abstract": "Character segmentation plays an important role in optical character recognition (OCR). Due to the limitations of feature representation, traditional image analyzing based methods cannot well segment characters with connected or broken strokes, especially for the Chinese characters which usually have complex structures. To solve this issue, this paper proposes a novel segmentation model based on fully convolutional neural networks (FCN). The model first uses convolutional neural networks to extract spatial features, then shares them throughout the whole model. Two FCNs are used to extract character information to form a score map. Finally, character features are reused to adjust the accurate segmentation points in the score map. What’s more, to strengthen the ability of feature representation, a novel compound character feature which can well describe the characters’ outline is also proposed. The proposed method is validated on two datasets: GBSD and CASIA-HWDB-MT, against the methods proposed in the literature. Experimental results show that the proposed model outperforms state-of-the-art methods.",
            "year": 2020,
            "venue": "IEEE Access",
            "authors": [
              {
                "authorId": "1992839016",
                "name": "Zhenyu Gao"
              },
              {
                "authorId": "2108456711",
                "name": "Jin Liu"
              },
              {
                "authorId": "2125533269",
                "name": "Yiyao Li"
              },
              {
                "authorId": "1717644964",
                "name": "Yihe Yang"
              },
              {
                "authorId": "1992729389",
                "name": "Huihua He"
              }
            ]
          }
        }
      ]
    },
    "212777726": {
      "citing_paper_info": {
        "title": "An Efficient Algorithm to Find the Height of a Text Line and Overcome Overlapped and Broken Line Problem during Segmentation",
        "abstract": "Line segmentation is a critical phase of the Optical Character Recognition (OCR) which separates the individual lines from the image documents. The accuracy rate of the OCR tool is directly proportional to the line segmentation accuracy followed by the word/character segmentation. In this context, an algorithm, named height_based_segmentation is proposed for the text line segmentation of printed Odia documents. The proposed algorithm finds the average height of a text line and it helps to minimize the overlapped text line cases. The algorithm also includes post-processing steps to combine the modifier zone with the base zone. The performance of the algorithm is evaluated through the ground truth and also by comparing it with the existing segmentation approaches.",
        "year": 2019,
        "venue": "International Journal of Advanced Computer Science and Applications",
        "authors": [
          {
            "authorId": "49524342",
            "name": "Sanjibani Sudha Pattanayak"
          },
          {
            "authorId": "2925345",
            "name": "S. Pradhan"
          },
          {
            "authorId": "2208196546",
            "name": "Ramesh Chandra Mallik"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 2,
        "unique_cited_count": 0,
        "influential_count": 0,
        "detailed_records_count": 2
      },
      "cited_papers": [],
      "citation_details": [
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Here few segmentation strategies that have been adopted for Telugu documents are cited as Odia script has lots of similarity with Telugu script [8]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "[2] combines the projection profile and connected component for segmenting lines, words as well as characters."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "195705810": {
      "citing_paper_info": {
        "title": "A robust and multiscale document image segmentation for block line/text line structures extraction",
        "abstract": "",
        "year": 1994,
        "venue": "Proceedings of 12th International Conference on Pattern Recognition",
        "authors": [
          {
            "authorId": "146529005",
            "name": "D. Olivier"
          },
          {
            "authorId": "66807260",
            "name": "B. Dominique"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 2,
        "unique_cited_count": 2,
        "influential_count": 0,
        "detailed_records_count": 2
      },
      "cited_papers": [
        "37131698",
        "30726276"
      ],
      "citation_details": [
        {
          "citedcorpusid": 30726276,
          "isinfluential": false,
          "contexts": [
            "A multiresolution representation of the original image provides the framework for an analysis at different levels [l], [ 2 ]: at least one of them is normally adapted to each written size."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Behavior of Edges in Scale Space",
            "abstract": "An analysis is presented of the behavior of edges in scale space for deriving rules useful in reasoning. This analysis of liner edges at different scales in images includes the mutual influence of edges and identifies at what scale neighboring edges start influencing the response of a Laplacian or Gaussian operator. Dislocation of edges, false edges, and merging of edges in the scale space are examined to formulate rules for reasoning in the scale space. The theorems, corollaries, and assertions presented can be used to recover edges, and related features, in complex images. The results reported include one lemma, three theorems, a number of corollaries and six assertions. The rigorous mathematical proofs for the theorems and corollaries are presented. These theorems and corollaries are further applied to more general situations, and the results are summarized in six assertions. A qualitative description as well as some experimental results are presented for each assertion. >",
            "year": 1989,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2143773585",
                "name": "Yi Lu"
              },
              {
                "authorId": "144938732",
                "name": "R. Jain"
              }
            ]
          }
        },
        {
          "citedcorpusid": 37131698,
          "isinfluential": false,
          "contexts": [
            "Hierarchical classification technique [ 3 ] highlights the potential uniformity inside a subset."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Address location on envelopes",
            "abstract": "",
            "year": 1987,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "3466226",
                "name": "P. Yeh"
              },
              {
                "authorId": "1720626",
                "name": "S. Antoy"
              },
              {
                "authorId": "3260285",
                "name": "Anne Litcher"
              },
              {
                "authorId": "143766793",
                "name": "A. Rosenfeld"
              }
            ]
          }
        }
      ]
    },
    "204812100": {
      "citing_paper_info": {
        "title": "Recognition of Japanese historical text lines by an attention-based encoder-decoder and text line generation",
        "abstract": "Inspired by the recent successes of attention based encoder-decoder (AED) approach on image captioning, machine translation, we present an AED model as an end-to-end recognition system for recognizing Japanese historical documents. The recognition system has two main modules: a dense convolution neural network for extracting features, and a Long Shor Term Memory (LSTM) decoder integrating with attention model for generating target text. We can train the model end-to-end. The model requires only input text line images and corresponding output characters. Therefore, we don't need annotations for characters and save a lot of time for making annotations. We also present a method to generate artificial text lines to solve the imbalance problem of the current annotated database. The results of experiments on the annotated and artificial databases demonstrate the effectiveness of the text line generation. Our recognition system achieved Character Error Rate of 23.76% and 22.52% by training with and without artificial text lines, respectively. Moreover, our recognition system outperforms the CNN-LSTM system, which achieved the state-of-art results in other document recognition tasks.",
        "year": 2019,
        "venue": "HIP@ICDAR",
        "authors": [
          {
            "authorId": "2697883",
            "name": "A. D. Le"
          },
          {
            "authorId": "2619938",
            "name": "D. Mochihashi"
          },
          {
            "authorId": "40595860",
            "name": "Katsuya Masuda"
          },
          {
            "authorId": "35227506",
            "name": "Hideki Mima"
          },
          {
            "authorId": "40325274",
            "name": "N. Ly"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 1,
        "unique_cited_count": 1,
        "influential_count": 0,
        "detailed_records_count": 1
      },
      "cited_papers": [
        "9624257"
      ],
      "citation_details": [
        {
          "citedcorpusid": 9624257,
          "isinfluential": false,
          "contexts": [
            "[1] developed a recognition system for handwritten Hanja historical documents in Korea."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Digitalizing scheme of handwritten Hanja historical documents",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "2116504223",
                "name": "Min-Soo Kim"
              },
              {
                "authorId": "2050741",
                "name": "Man-Dae Jang"
              },
              {
                "authorId": "2217173283",
                "name": "Hyunil Choi"
              },
              {
                "authorId": "153354801",
                "name": "Taik-Heon Rhee"
              },
              {
                "authorId": "2152672892",
                "name": "J. H. Kim"
              }
            ]
          }
        }
      ]
    },
    "60120612": {
      "citing_paper_info": {
        "title": "Text line segmentation of ancient Thai manuscripts on palm leaves",
        "abstract": "Segmentation of handwritten scripts with overlapping text is one of the challenging tasks in the pre-processing for document recognition and optical character recognition (OCR) systems. It is a significant step because errors in the recognition stage will occur if text lines are not separated accurately. This paper aims to address the problem of text line segmentation of ancient Thai manuscripts written on palm leaves, in particular dealing with the issue of overlapping characters. The proposed technique is based on an integration of a partial projection method and smooth horizontal histogram with recurrence in each column. The performance evaluation of the proposed technique was compared with a modified partial projection profile. The experimental results from this study show that the accuracy of the proposed technique has a better performance. This technique will help to resolve the problem of text line segmentation for ancient Thai manuscripts on palm leaves.",
        "year": 2012,
        "venue": "International Conference on Information Photonics",
        "authors": [
          {
            "authorId": "1722160",
            "name": "R. Chamchong"
          },
          {
            "authorId": "38702744",
            "name": "C. Fung"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 4,
        "unique_cited_count": 4,
        "influential_count": 0,
        "detailed_records_count": 4
      },
      "cited_papers": [
        "16916947",
        "16692234",
        "35215159",
        "17948396"
      ],
      "citation_details": [
        {
          "citedcorpusid": 16692234,
          "isinfluential": false,
          "contexts": [
            "In this experiment, the set of test images for this comparison includes 43 binary images which are converted from input images by automatically selecting the optimal binarization algorithm in [10]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Optimal selection of binarization techniques for the processing of ancient palm leaf manuscripts",
            "abstract": "",
            "year": 2010,
            "venue": "IEEE International Conference on Systems, Man and Cybernetics",
            "authors": [
              {
                "authorId": "1722160",
                "name": "R. Chamchong"
              },
              {
                "authorId": "1866074",
                "name": "L. Fung"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16916947,
          "isinfluential": false,
          "contexts": [
            "The first method is a modified partial projection method looking at vowel analysis and touching components of two consecutive lines [8] and the second method is an applied technique that is improved by integrating the partial projection profile and smooth the histogram with recursion.",
            "To separate text lines, the partial projection method [2][4] is applied by dividing the text images into vertical columns and the modified approach [8] to separate the lines is outlined as follows:"
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Character segmentation from ancient palm leaf manuscripts in Thailand",
            "abstract": "",
            "year": 2011,
            "venue": "The Hip",
            "authors": [
              {
                "authorId": "1722160",
                "name": "R. Chamchong"
              },
              {
                "authorId": "1866074",
                "name": "L. Fung"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17948396,
          "isinfluential": false,
          "contexts": [
            "Surinta [5] proposed sorting and distinguishing the histogram of projection profile in order to select the base line."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Optimization of line segmentation techniques for Thai handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "2009 Eighth International Symposium on Natural Language Processing",
            "authors": [
              {
                "authorId": "1728531",
                "name": "Olarik Surinta"
              }
            ]
          }
        },
        {
          "citedcorpusid": 35215159,
          "isinfluential": false,
          "contexts": [
            "Zahour et al.[2] proposed the partial projection profile.",
            "To separate text lines, the partial projection method [2][4] is applied by dividing the text images into vertical columns and the modified approach [8] to separate the lines is outlined as follows:"
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Arabic hand-written text-line extraction",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              },
              {
                "authorId": "144484822",
                "name": "P. Mercy"
              },
              {
                "authorId": "2102325551",
                "name": "Said Ramdane"
              }
            ]
          }
        }
      ]
    },
    "2586526": {
      "citing_paper_info": {
        "title": "Basic Test Framework for the Evaluation of Text Line Segmentation and Text Parameter Extraction",
        "abstract": "Text line segmentation is an essential stage in off-line optical character recognition (OCR) systems. It is a key because inaccurately segmented text lines will lead to OCR failure. Text line segmentation of handwritten documents is a complex and diverse problem, complicated by the nature of handwriting. Hence, text line segmentation is a leading challenge in handwritten document image processing. Due to inconsistencies in measurement and evaluation of text segmentation algorithm quality, some basic set of measurement methods is required. Currently, there is no commonly accepted one and all algorithm evaluation is custom oriented. In this paper, a basic test framework for the evaluation of text feature extraction algorithms is proposed. This test framework consists of a few experiments primarily linked to text line segmentation, skew rate and reference text line evaluation. Although they are mutually independent, the results obtained are strongly cross linked. In the end, its suitability for different types of letters and languages as well as its adaptability are its main advantages. Thus, the paper presents an efficient evaluation method for text analysis algorithms.",
        "year": 2010,
        "venue": "Italian National Conference on Sensors",
        "authors": [
          {
            "authorId": "2008869",
            "name": "D. Brodic"
          },
          {
            "authorId": "2489351",
            "name": "D. Milivojevic"
          },
          {
            "authorId": "2393591",
            "name": "Z. Milivojevic"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 2,
        "unique_cited_count": 1,
        "influential_count": 1,
        "detailed_records_count": 2
      },
      "cited_papers": [
        "12217430"
      ],
      "citation_details": [
        {
          "citedcorpusid": 12217430,
          "isinfluential": false,
          "contexts": [
            "Accordingly, testing result interpretation is quite dissimilar [4]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Off-line Handwriting Text Line Segmentation : A Review",
            "abstract": "Summary Text line segmentation is an essential pre-processing stage for off-line handwriting recognition in many Optical Character Recognition (OCR) systems. It is an important step because inaccurately segmented text lines will cause errors in the recognition stage. Text line segmentation of the handwritten documents is still one of the most complicated problems in developing a reliable OCR. The nature of handwriting makes the process of text line segmentation very challenging. Several techniques to segment handwriting text line have been proposed in the past. This paper seeks to provide a comprehensive review of the methods of off-line handwriting text line segmentation proposed by researchers.",
            "year": 2008,
            "venue": "",
            "authors": [
              {
                "authorId": "34325231",
                "name": "N. M. Noor"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": true,
          "contexts": [
            "For the illustration, above test framework procedure will be examined using as an example the Gaussian isotropic kernel algorithm [7].",
            "Further, RMSEfrac is calculated as [7-9]:",
            "Hence, a medium size K like {15, 20} is the optimal value [7].",
            "Algorithm criteria quality and handwritten referent text line is measured and evaluated by the root mean square error RMSEwav calculated as [7-9]:",
            "Now, the root mean square error RMSEskew is calculated by [7-10]:",
            "Converting all these pixels into black pixels as well as inverting image, forms the new black pixel expanded areas [7]."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "40038038": {
      "citing_paper_info": {
        "title": "An Improved Handwritten Text Line Segmentation Technique",
        "abstract": "",
        "year": 2011,
        "venue": "American Control Conference",
        "authors": [
          {
            "authorId": "2057894520",
            "name": "M. Mohammadi"
          },
          {
            "authorId": "2540686",
            "name": "S. S. M. Chanijani"
          },
          {
            "authorId": "1710382",
            "name": "Manjunath Aradhya"
          },
          {
            "authorId": "144923419",
            "name": "G. Kumar"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 6,
        "influential_count": 1,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "17388229",
        "13396787",
        "4651364",
        "17401851",
        "15257932",
        "16503365"
      ],
      "citation_details": [
        {
          "citedcorpusid": 4651364,
          "isinfluential": false,
          "contexts": [
            "A text line segmentation by clustering with distance metric learning is proposed in [ 11 ]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Chinese text line segmentation by clustering with distance metric learning",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "145820427",
                "name": "Fei Yin"
              },
              {
                "authorId": "1689269",
                "name": "Cheng-Lin Liu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13396787,
          "isinfluential": false,
          "contexts": [
            "A handwritten document image segmentation into texlines and words is presented in [ 8 ]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten document image segmentation into text lines and words",
            "abstract": "",
            "year": 2010,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "1799540",
                "name": "Themos Stafylakis"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              },
              {
                "authorId": "143978280",
                "name": "G. Carayannis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15257932,
          "isinfluential": false,
          "contexts": [
            "A steerable directional local profile technique for extraction of handwritten Arabic text lines is described in [ 12 ]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition A Steerable Directional Local Profile Technique for Extraction of Handwritten Arabic Text Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 16503365,
          "isinfluential": true,
          "contexts": [
            "The proposed model is an improvised scheme to [ 1 ].",
            "Fig.7. Final Segmentation of Method [ 1 ] for Persian Script",
            "The proposed method is an improvised method to Alaei et al., 2010 [ 1 ] by applying block separation and edge detection process.",
            "Fig.8. Final Segmentation of Method [ 1 ] for Kannada Script",
            "The detection rate of the proposed method and method by [ 1 ] was around 99.1% and 95.6% respectively.",
            "In [ 1 ], after the successful completion of painting algorithm and strip connectivity, dilation operation is applied to bridge the connectivity’s.",
            "Final segmetnation of method proposed in [ 1 ] is also showed in Figure 7 and Figure 8. From the results it is very clear that the proposed method segments text line accuretly compared to method proposed in [1].",
            "The idea of painting algorithm is extracted from [ 1 ].",
            "Recently an elegant method for unconstrained handwritten text line segmentation is proposed in [ 1 ].",
            "Final segmetnation of method proposed in [1] is also showed in Figure 7 and Figure 8. From the results it is very clear that the proposed method segments text line accuretly compared to method proposed in [ 1 ].",
            "We also compared our method with standard existing method [ 1 ]."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']",
            "--",
            "['methodology']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['result']"
          ],
          "cited_paper_info": {
            "title": "A new scheme for unconstrained handwritten text-line segmentation",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "1750931",
                "name": "P. Nagabhushan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17388229,
          "isinfluential": false,
          "contexts": [
            "A segmentation of Bangla unconstrained handwritten text is described in [ 2 ]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Bangla unconstrained handwritten text",
            "abstract": "",
            "year": 2003,
            "venue": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "52511272",
                "name": "S. Datta"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17401851,
          "isinfluential": false,
          "contexts": [
            "Du et al (2009) [ 9 ], proposed textline segmentation in handwritten document using Mumford shah model."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation in handwritten documents using Mumford-Shah model",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "70378391",
                "name": "Xiaojun Du"
              },
              {
                "authorId": "1681758",
                "name": "Wumo Pan"
              },
              {
                "authorId": "144957197",
                "name": "T. D. Bui"
              }
            ]
          }
        }
      ]
    },
    "55848912": {
      "citing_paper_info": {
        "title": "A robust Binarization and Text Line Detection in Historical Handwritten Documents Analysis",
        "abstract": "In this paper, we present a novel method of detecting text lines in handwritten documents based on the Block-Based Hough Transform. To maximize its efficiency, the robust binarization algorithm was applied. It is based on the Gaussian filtering and tackles the non-uniform luminance. The proposed technique consists of three steps: preprocessing, detecting of potential text lines and eliminating the false ones. The first step covers the image binarization, extraction of connected components and selection of supporting connected components based on the local maxima in the vertical histogram stripes. Secondly, the appropriate subset of connected components supplemented by one-point components is selected. Finally, the block-based Hough transform is applied to detect potential text lines and found the ones identified incorrectly. The proposed method is applied to the analysis of the fifteenth century Latin manuscripts. Our approach is more effective than the traditional ones, in the best cases by twenty percent.",
        "year": 2016,
        "venue": "Int. J. Comput.",
        "authors": [
          {
            "authorId": "1907413",
            "name": "J. Pach"
          },
          {
            "authorId": "47899706",
            "name": "P. Bilski"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 8,
        "unique_cited_count": 8,
        "influential_count": 1,
        "detailed_records_count": 8
      },
      "cited_papers": [
        "16669882",
        "10834729",
        "7041863",
        "6657237",
        "41585742",
        "14210437",
        "14928340",
        "13334323"
      ],
      "citation_details": [
        {
          "citedcorpusid": 6657237,
          "isinfluential": false,
          "contexts": [
            "Additionally, their computational complexity is high [11]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation Based on Matched Filtering and Top-Down Grouping for Handwritten Documents",
            "abstract": "",
            "year": 2014,
            "venue": "2014 11th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "3152399",
                "name": "Youbao Tang"
              },
              {
                "authorId": "47150160",
                "name": "Xiangqian Wu"
              },
              {
                "authorId": "144830523",
                "name": "Wei Bu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7041863,
          "isinfluential": false,
          "contexts": [
            "Contrary to [13], here three binary images are generated, separately for each channel, eliminating the original hue and saturation retaining the luminance.",
            "Considering the non-uniform luminance of the document and distortion caused by the perspective of the data acquisition hardware, the more efficient method, based on the Gaussian filter [13], was proposed here."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "State Estimation in a Document Image and Its Application in Text Block Identification and Text Line Extraction",
            "abstract": "",
            "year": 2010,
            "venue": "European Conference on Computer Vision",
            "authors": [
              {
                "authorId": "2463454",
                "name": "H. Koo"
              },
              {
                "authorId": "1707645",
                "name": "N. Cho"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10834729,
          "isinfluential": false,
          "contexts": [
            "To increase their immunity to this effect, the input image is cut into horizontal and vertical stripes, for which calculated histograms have a higher accuracy than the single histogram calculated for the whole image [2, 3]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A statistical approach to line segmentation in handwritten documents",
            "abstract": "",
            "year": 2007,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "2066310463",
                "name": "M. Arivazhagan"
              },
              {
                "authorId": "2334238",
                "name": "H. Srinivasan"
              },
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13334323,
          "isinfluential": false,
          "contexts": [
            "To increase their immunity to this effect, the input image is cut into horizontal and vertical stripes, for which calculated histograms have a higher accuracy than the single histogram calculated for the whole image [2, 3]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "An algorithm for extracting cursive text lines",
            "abstract": "",
            "year": 1999,
            "venue": "Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)",
            "authors": [
              {
                "authorId": "2158815",
                "name": "E. Bruzzone"
              },
              {
                "authorId": "1933378",
                "name": "Meri Cristina Coffetti"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14210437,
          "isinfluential": true,
          "contexts": [
            "160 The optimal values of n1, n2, n3 and n4 coefficients were selected after [1].",
            "classical method [1] – black lines; proposed method – gray lines",
            "and relative percentages - %) is the TP and TN ratio for the detection method described in [1], “TP2” and “TN2” is the ratio for the proposed approach, respectively.",
            "Our method is therefore more efficient by 23% and makes mistakes three times less than the method from [1].",
            "The improved Hough transform method divides the wider CC into smaller blocks and uses center points of each block to support the actual text lines [1].",
            "The most popular approaches implemented for this task first extract the rectangular areas surrounding the separable groups of letters (Connected Components – CC, also called bounding boxes) from the scanned text image and process them by the block-based Hough transform mapping [1] to detect the maximum number of text lines.",
            "If there are no more cells in the accumulator with the number of intersections greater than n2, the procedure ends [1].",
            "The classical method [1] - black lines; proposed method - gray lines.",
            "generation for the corresponding blocks of the binary image [1] The efficiency of this step depends on the following factors: - the breadth b of the vertical block dividing the binary image, calculated as b = w ∙ n3."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Block-Based Hough Transform Mapping for Text Line Detection in Handwritten Documents",
            "abstract": "In this paper, we present a new text line detection method for unconstrained handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes preprocessing for image enhancement, connected component extraction and average character height estimation. In the second step, a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible false alarms. The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "70602633",
                "name": "K. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14928340,
          "isinfluential": false,
          "contexts": [
            "In [6] the Otsu binarization method was applied to transform the original image into the black and white version, further processed by the subsequent algorithms.",
            "The problem is suppressed by the introduced modification [6] described later in detail."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A robust text line detection in complex handwritten documents",
            "abstract": "",
            "year": 2015,
            "venue": "International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications",
            "authors": [
              {
                "authorId": "1907413",
                "name": "J. Pach"
              },
              {
                "authorId": "47899706",
                "name": "P. Bilski"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16669882,
          "isinfluential": false,
          "contexts": [
            "(ρ+5,θ) are considered [4], which is important in the next step.",
            "In this step, a Hough transform is calculated from the CC and SCC subsets, as in the traditional approaches [4].",
            "Their set is used to construct the Hough transform accumulator, which is the matrix containing center points of CC, their minimal or maximal values (calculated along the vertical axis) [4, 5]."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Hough based algorithm for extracting text lines in handwritten documents",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "1409083785",
                "name": "Anahid Hanimyan"
              },
              {
                "authorId": "38138508",
                "name": "C. Faure"
              }
            ]
          }
        },
        {
          "citedcorpusid": 41585742,
          "isinfluential": false,
          "contexts": [
            "In [8] the image is represented in the form of onedimensional column and row vectors, with ones and zeros indicating the presence or absence of the ink, respectively."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Block segmentation and text extraction in mixed text/image documents",
            "abstract": "",
            "year": 1982,
            "venue": "Computer Graphics and Image Processing",
            "authors": [
              {
                "authorId": "1880661",
                "name": "F. Wahl"
              },
              {
                "authorId": "145470231",
                "name": "Kwan Y. Wong"
              },
              {
                "authorId": "34896449",
                "name": "R. Casey"
              }
            ]
          }
        }
      ]
    },
    "61976515": {
      "citing_paper_info": {
        "title": "Text Line Segmentation In Handwritten Documents Based On Dynamic Weights",
        "abstract": "Identification of text lines in documents, or text line segmentation, represents the first step in the process called ‘Text recognition”, whose purpose is to extract the text and put it in a more understandable format. The paper proposes a seam carving algorithm as an approach to find the text lines. This algorithm uses a new method that allocates dynamic weights for every processed pixel in the original image. With this addition, the resulting lines follow the text more accurately. The downside of this technique is the computational time overhead.",
        "year": 2013,
        "venue": "",
        "authors": [
          {
            "authorId": "3295205",
            "name": "C. Boiangiu"
          },
          {
            "authorId": "2066046413",
            "name": "Mihai Cristian Tănase"
          },
          {
            "authorId": "1871876",
            "name": "Radu Ioanitescu"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 4,
        "influential_count": 0,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "2055937",
        "13396787",
        "10834729",
        "13750607"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2055937,
          "isinfluential": false,
          "contexts": [
            "Identification of text lines in documents, or text line segmentation, represents the first step in the process called ‘Text recognition”, whose purpose is to extract the text and put it in a more understandable format."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A Hough Transform based Technique for Text Segmentation",
            "abstract": "Text segmentation is an inherent part of an OCR system irrespective of the domain of application of it. The OCR system contains a segmentation module where the text lines, words and ultimately the characters must be segmented properly for its successful recognition. The present work implements a Hough transform based technique for line and word segmentation from digitized images. The proposed technique is applied not only on the document image dataset but also on dataset for business card reader system and license plate recognition system. For standardization of the performance of the system the technique is also applied on public domain dataset published in the website by CMATER, Jadavpur University. The document images consist of multi-script printed and hand written text lines with variety in script and line spacing in single document image. The technique performs quite satisfactorily when applied on mobile camera captured business card images with low resolution. The usefulness of the technique is verified by applying it in a commercial project for localization of license plate of vehicles from surveillance camera images by the process of segmentation itself. The accuracy of the technique for word segmentation, as verified experimentally, is 85.7% for document images, 94.6% for business card images and 88% for surveillance camera images.",
            "year": 2010,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "2778425",
                "name": "Satadal Saha"
              },
              {
                "authorId": "145096292",
                "name": "Subhadip Basu"
              },
              {
                "authorId": "1729425",
                "name": "M. Nasipuri"
              },
              {
                "authorId": "143701816",
                "name": "D. K. Basu"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10834729,
          "isinfluential": false,
          "contexts": [
            "Identification of text lines in documents, or text line segmentation, represents the first step in the process called ‘Text recognition”, whose purpose is to extract the text and put it in a more understandable format."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A statistical approach to line segmentation in handwritten documents",
            "abstract": "",
            "year": 2007,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "2066310463",
                "name": "M. Arivazhagan"
              },
              {
                "authorId": "2334238",
                "name": "H. Srinivasan"
              },
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13396787,
          "isinfluential": false,
          "contexts": [
            "The downside of this technique is the computational time overhead."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten document image segmentation into text lines and words",
            "abstract": "",
            "year": 2010,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1918919",
                "name": "V. Papavassiliou"
              },
              {
                "authorId": "1799540",
                "name": "Themos Stafylakis"
              },
              {
                "authorId": "1684430",
                "name": "V. Katsouros"
              },
              {
                "authorId": "143978280",
                "name": "G. Carayannis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13750607,
          "isinfluential": false,
          "contexts": [
            "The downside of this technique is the computational time overhead."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting segmentation of unconstrained Oriya text",
            "abstract": "",
            "year": 2004,
            "venue": "Ninth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "6504614",
                "name": "N. Tripathy"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "There are numerous methods ([13], [9], [5]) that address the printed document line extraction problem which is usually reduced to global skew search (the text lines are parallel with each other, but not necessarily horizontal)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "35577": {
      "citing_paper_info": {
        "title": "A Model Based Text Line Segmentation Method for Off-line Handwritten Documents",
        "abstract": "",
        "year": 2010,
        "venue": "International Conference on Frontiers in Handwriting Recognition",
        "authors": [
          {
            "authorId": "31474787",
            "name": "J. D. Gupta"
          },
          {
            "authorId": "1784810",
            "name": "B. Chanda"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 4,
        "influential_count": 0,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "14210437",
        "13750607",
        "35215159",
        "16669882"
      ],
      "citation_details": [
        {
          "citedcorpusid": 13750607,
          "isinfluential": false,
          "contexts": [
            "For skewed line segmentation, this method is modified by Zabour et al [4], Tripathy and Pal [5], Arivazhagan et al. [6] where the\nimage of given text is divided into vertical strips.",
            "For skewed line segmentation, this method is modified by Zabour et al [4], Tripathy and Pal [5], Arivazhagan et al."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting segmentation of unconstrained Oriya text",
            "abstract": "",
            "year": 2004,
            "venue": "Ninth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "6504614",
                "name": "N. Tripathy"
              },
              {
                "authorId": "144167309",
                "name": "U. Pal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14210437,
          "isinfluential": false,
          "contexts": [
            "6% and for the block based Hough transform mapping[8] is 96.",
            "Some researchers [7], [8], [9], [10] used Hough transform for line segmentation."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Block-Based Hough Transform Mapping for Text Line Detection in Handwritten Documents",
            "abstract": "In this paper, we present a new text line detection method for unconstrained handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes preprocessing for image enhancement, connected component extraction and average character height estimation. In the second step, a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible false alarms. The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "70602633",
                "name": "K. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16669882,
          "isinfluential": false,
          "contexts": [
            "Some researchers [7], [8], [9], [10] used Hough transform for line segmentation."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Hough based algorithm for extracting text lines in handwritten documents",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "1409083785",
                "name": "Anahid Hanimyan"
              },
              {
                "authorId": "38138508",
                "name": "C. Faure"
              }
            ]
          }
        },
        {
          "citedcorpusid": 35215159,
          "isinfluential": false,
          "contexts": [
            "For skewed line segmentation, this method is modified by Zabour et al [4], Tripathy and Pal [5], Arivazhagan et al. [6] where the\nimage of given text is divided into vertical strips.",
            "For skewed line segmentation, this method is modified by Zabour et al [4], Tripathy and Pal [5], Arivazhagan et al."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Arabic hand-written text-line extraction",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              },
              {
                "authorId": "144484822",
                "name": "P. Mercy"
              },
              {
                "authorId": "2102325551",
                "name": "Said Ramdane"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "They may be grouped as (i) projection based approach [1] (ii) smearing approach [2] and (iii) grouping approach [3] ."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "62131537": {
      "citing_paper_info": {
        "title": "Handwritten Documents Text Line Segmentation based on Information Energy",
        "abstract": "The first step in the text recognition process is represented by the text line segmentation procedures. Only after text lines are correctly identified can the process proceed to the recognition of individual characters. This paper proposes a line segmentation algorithm based on the computation of an information content level, called energy, for each pixel of the image and using it to execute the seam carving procedure. The algorithm proposes the identification of text lines which follow the text more accurately with the expected downside of the computational overhead.",
        "year": 2014,
        "venue": "International Journal of Computers Communications & Control",
        "authors": [
          {
            "authorId": "3295205",
            "name": "C. Boiangiu"
          },
          {
            "authorId": "2066046413",
            "name": "Mihai Cristian Tănase"
          },
          {
            "authorId": "1871876",
            "name": "Radu Ioanitescu"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 2,
        "unique_cited_count": 2,
        "influential_count": 0,
        "detailed_records_count": 2
      },
      "cited_papers": [
        "17376493",
        "17187622"
      ],
      "citation_details": [
        {
          "citedcorpusid": 17187622,
          "isinfluential": false,
          "contexts": [
            "Similarly to [4] and [11], for each pixel, the energy value is calculated using the next formula:",
            "Algorithms trying to address these increased complexities have also been attempted in [4] - [13]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Minimal Cost-Path for Path-Based Distances",
            "abstract": "",
            "year": 2007,
            "venue": "International Symposium on Image and Signal Processing and Analysis",
            "authors": [
              {
                "authorId": "144408003",
                "name": "R. Strand"
              },
              {
                "authorId": "2065685065",
                "name": "F. Malmberg"
              },
              {
                "authorId": "40482479",
                "name": "S. Svensson"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17376493,
          "isinfluential": false,
          "contexts": [
            "Algorithms trying to address these increased complexities have also been attempted in [4] - [13]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Line segmentation for degraded handwritten historical documents",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        }
      ]
    },
    "260355918": {
      "citing_paper_info": {
        "title": "Laypa: A Novel Framework for Applying Segmentation Networks to Historical Documents",
        "abstract": "We present novel software to process scans of historical documents to extract their layout information. We do this using a ResNet backbone with a feature pyramid head. We extract region information directly into PageXML. For baseline extraction, we use a two stage processing approach. The software has been applied successfully to several projects. The results show the feasibility to automatically label text lines and regions in historical documents.",
        "year": 2023,
        "venue": "HIP@ICDAR",
        "authors": [
          {
            "authorId": "2052358757",
            "name": "Stefan Klut"
          },
          {
            "authorId": "2211625821",
            "name": "Rutger van Koert"
          },
          {
            "authorId": "73082752",
            "name": "R. Sluijter"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 8,
        "unique_cited_count": 6,
        "influential_count": 0,
        "detailed_records_count": 8
      },
      "cited_papers": [
        "60447873",
        "247619049",
        "209531740",
        "53592270",
        "232404723",
        "13749026"
      ],
      "citation_details": [
        {
          "citedcorpusid": 13749026,
          "isinfluential": false,
          "contexts": [
            "Various tools for extracting layout information from historical documents such as baselines and region polygons already exist; we not exhaustively mention here: P2PaLA [17], dhSegment [3], Kraken, ARUNet [8], Eynollah [1], LayoutParser[19], pero-ocr [12]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "dhSegment: A Generic Deep-Learning Approach for Document Segmentation",
            "abstract": "In recent years there have been multiple successful attempts tackling document processing problems separately by designing task specific hand-tuned strategies. We argue that the diversity of historical document processing tasks prohibits to solve them one at a time and shows a need for designing generic approaches in order to handle the variability of historical series. In this paper, we address multiple tasks simultaneously such as page extraction, baseline extraction, layout analysis or multiple typologies of illustrations and photograph extraction. We propose an open-source implementation of a CNN-based pixel-wise predictor coupled with task dependent post-processing blocks. We show that a single CNN-architecture can be used across tasks with competitive results. Moreover most of the task-specific post-precessing steps can be decomposed in a small number of simple and standard reusable operations, adding to the flexibility of our approach.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2066810458",
                "name": "S. Oliveira"
              },
              {
                "authorId": "2060245962",
                "name": "Benoit Seguin"
              },
              {
                "authorId": "143791091",
                "name": "F. Kaplan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 53592270,
          "isinfluential": false,
          "contexts": [
            "The model is trained using the AdamW [13] Optimizer with a learning rate of 2 · 10 − 5 ."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Decoupled Weight Decay Regularization",
            "abstract": "L$_2$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \\emph{not} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L$_2$ regularization (often calling it \"weight decay\" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \\emph{decoupling} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at this https URL",
            "year": 2017,
            "venue": "International Conference on Learning Representations",
            "authors": [
              {
                "authorId": "1678656",
                "name": "I. Loshchilov"
              },
              {
                "authorId": "144661829",
                "name": "F. Hutter"
              }
            ]
          }
        },
        {
          "citedcorpusid": 60447873,
          "isinfluential": false,
          "contexts": [
            "The baseline is simplified using the Ramer–Douglas–Peucker algorithm [7, 18] to remove redundant coordinates."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ALGORITHMS FOR THE REDUCTION OF THE NUMBER OF POINTS REQUIRED TO REPRESENT A DIGITIZED LINE OR ITS CARICATURE",
            "abstract": "All digitizing methods, as a general rule, record lines with far more data than is necessary for accurate graphic reproduction or for computer analysis. Two algorithms to reduce the number of points required to represent the line and, if desired, produce caricatures, are presented and compared with the most promising methods so far suggested. Line reduction will form a major part of automated generalization. Regle generale, les methodes numeriques enregistrent des lignes avec beaucoup plus de donnees qu'il n'est necessaire a la reproduction graphique precise ou a la recherche par ordinateur. L'auteur presente deux algorithmes pour reduire le nombre de points necessaires pour representer la ligne et produire des caricatures si desire, et les compare aux methodes les plus prometteuses suggerees jusqu'ici. La reduction de la ligne constituera une partie importante de la generalisation automatique.",
            "year": 1973,
            "venue": "",
            "authors": [
              {
                "authorId": "145700931",
                "name": "David H. Douglas"
              },
              {
                "authorId": "2531388",
                "name": "T. Peucker"
              }
            ]
          }
        },
        {
          "citedcorpusid": 209531740,
          "isinfluential": false,
          "contexts": [
            "Extracting text information from images has long been a domain in computer vision [14]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Optical Character Recognition (OCR): A Comprehensive Systematic Literature Review (SLR)",
            "abstract": "Given the ubiquity of handwritten documents in human transactions, Optical Character Recognition (OCR) of documents have invaluable practical worth. Optical character recognition is a science that enables to translate various types of documents or images into analyzable, editable and searchable data. During last decade, researchers have used artificial intelligence/machine learning tools to automatically analyze handwritten and printed documents in order to convert them into electronic format. The objective of this review paper is to summarize research that has been conducted on character recognition of handwritten documents and to provide research directions. In this Systematic Literature Review (SLR) we collected, synthesized and analyzed research articles on the topic of handwritten OCR (and closely related topics) which were published between year 2000 to 2019. We followed widely used electronic databases by following pre-defined review protocol. Articles were searched using keywords, forward reference searching and backward reference searching in order to search all the articles related to the topic. After carefully following study selection process 176 articles were selected for this SLR. This review article serves the purpose of presenting state of the art results and techniques on OCR and also provide research directions by highlighting research gaps.",
            "year": 2020,
            "venue": "IEEE Access",
            "authors": [
              {
                "authorId": "3169373",
                "name": "Jamshed Memon"
              },
              {
                "authorId": "1473077187",
                "name": "Maira Sami"
              },
              {
                "authorId": "144553570",
                "name": "Rizwan Ahmed Khan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 232404723,
          "isinfluential": false,
          "contexts": [
            "Various tools for extracting layout information from historical documents such as baselines and region polygons already exist; we not exhaustively mention here: P2PaLA [17], dhSegment [3], Kraken, ARUNet [8], Eynollah [1], LayoutParser[19], pero-ocr [12]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis",
            "abstract": "Recent advances in document image analysis (DIA) have been primarily driven by the application of neural networks. Ideally, research outcomes could be easily deployed in production and extended for further investigation. However, various factors like loosely organized codebases and sophisticated model configurations complicate the easy reuse of important innovations by a wide audience. Though there have been on-going efforts to improve reusability and simplify deep learning (DL) model development in disciplines like natural language processing and computer vision, none of them are optimized for challenges in the domain of DIA. This represents a major gap in the existing toolkit, as DIA is central to academic research across a wide range of disciplines in the social sciences and humanities. This paper introduces layoutparser, an open-source library for streamlining the usage of DL in DIA research and applications. The core layoutparser library comes with a set of simple and intuitive interfaces for applying and customizing DL models for layout detection, character recognition, and many other document processing tasks. To promote extensibility, layoutparser also incorporates a community platform for sharing both pre-trained models and full document digitization pipelines. We demonstrate that layoutparser is helpful for both lightweight and large-scale digitization pipelines in real-word use cases. The library is publicly available at https://layout-parser.github.io/.",
            "year": 2021,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "101568984",
                "name": "Zejiang Shen"
              },
              {
                "authorId": "49775305",
                "name": "Ruochen Zhang"
              },
              {
                "authorId": "2065276972",
                "name": "Melissa Dell"
              },
              {
                "authorId": "145485725",
                "name": "Benjamin Charles Germain Lee"
              },
              {
                "authorId": "2060946945",
                "name": "Jacob Carlson"
              },
              {
                "authorId": "2108801852",
                "name": "Weining Li"
              }
            ]
          }
        },
        {
          "citedcorpusid": 247619049,
          "isinfluential": false,
          "contexts": [
            "approaches used to provide significantly less quality than HTR with a separate layout analysis step, but seem to be closing the gap and currently yield low Character Error Rates [4].",
            "These segmentation free approaches used to provide significantly less quality than HTR with a separate layout analysis step, but seem to be closing the gap and currently yield low Character Error Rates [4]."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "DAN: A Segmentation-Free Document Attention Network for Handwritten Document Recognition",
            "abstract": "Unconstrained handwritten text recognition is a challenging computer vision task. It is traditionally handled by a two-step approach, combining line segmentation followed by text line recognition. For the first time, we propose an end-to-end segmentation-free architecture for the task of handwritten document recognition: the Document Attention Network. In addition to text recognition, the model is trained to label text parts using begin and end tags in an XML-like fashion. This model is made up of an FCN encoder for feature extraction and a stack of transformer decoder layers for a recurrent token-by-token prediction process. It takes whole text documents as input and sequentially outputs characters, as well as logical layout tokens. Contrary to the existing segmentation-based approaches, the model is trained without using any segmentation label. We achieve competitive results on the READ 2016 dataset at page level, as well as double-page level with a CER of 3.43% and 3.70%, respectively. We also provide results for the RIMES 2009 dataset at page level, reaching 4.54% of CER. We provide all source code and pre-trained model weights at https://github.com/FactoDeepLearning/DAN.",
            "year": 2022,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1404330446",
                "name": "Denis Coquenet"
              },
              {
                "authorId": "1712446",
                "name": "Clément Chatelain"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "This dataset [22] can be found at https://zenodo.org/record/7928973 .",
            "Thesoftwarehasbeen successfullytestedontheRepublicdatasets [20, 22] and the cBAD dataset [5]."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "This dataset is part of data released by the Republic Project [15] and corrected by hand for the use of document analysis."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "207938138": {
      "citing_paper_info": {
        "title": "VML-MOC: Segmenting a Multiply Oriented and Curved Handwritten Text Line Dataset",
        "abstract": "This paper publishes a natural and very complicated dataset of handwritten documents with multiply oriented and curved text lines, namely VML-MOC dataset. These text lines were written as remarks on the page margins by different writers over the years. They appear at different locations within the orientations that range between 0° and 180° or as curvilinear forms. We evaluate a multi-oriented Gaussian based method to segment these handwritten text lines that are skewed or curved in any orientation. It achieves a mean pixel Intersection over Union score of 80.96% on the test documents. The results are compared with the results of a single-oriented Gaussian based text line segmentation method.",
        "year": 2019,
        "venue": "2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)",
        "authors": [
          {
            "authorId": "51036690",
            "name": "Berat Kurar Barakat"
          },
          {
            "authorId": "51037361",
            "name": "Rafi Cohen"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 8,
        "unique_cited_count": 7,
        "influential_count": 1,
        "detailed_records_count": 8
      },
      "cited_papers": [
        "9811883",
        "12794447",
        "14000898",
        "26514936",
        "528469",
        "254110674",
        "7269903"
      ],
      "citation_details": [
        {
          "citedcorpusid": 528469,
          "isinfluential": false,
          "contexts": [
            "For annotation we used Aletheia [25], a semi-automated ground truthing system."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Aletheia - An Advanced Document Layout and Text Ground-Truthing System for Production Environments",
            "abstract": "Large-scale digitisation has led to a number of new possibilities with regard to adaptive and learning based methods in the field of Document Image Analysis and OCR. For ground truth production of large corpora, however, there is still a gap in terms of productivity. Ground truth is not only crucial for training and evaluation at the development stage of tools but also for quality assurance in the scope of production workflows for digital libraries. This paper describes Aletheia, an advanced system for accurate and yet cost-effective ground truthing of large amounts of documents. It aids the user with a number of automated and semi-automated tools which were partly developed and improved based on feedback from major libraries across Europe and from their digitisation service providers which are using the tool in a production environment. Novel features are, among others, the support of top-down ground truthing with sophisticated split and shrink tools as well as bottom-up ground truthing supporting the aggregation of lower-level elements to more complex structures. Special features have been developed to support working with the complexities of historical documents. The integrated rules and guidelines validator, in combination with powerful correction tools, enable efficient production of highly accurate ground truth.",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2764871",
                "name": "C. Clausner"
              },
              {
                "authorId": "1980669",
                "name": "Stefan Pletschacher"
              },
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7269903,
          "isinfluential": false,
          "contexts": [
            "[21] adopted Gabor Transform for identifying multi-oriented text blocks in handwritten documents, where lines of each text block share homogeneous orientations."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Coarse-to-Fine Approach for Layout Analysis of Ancient Manuscripts",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "51037361",
                "name": "Rafi Cohen"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              },
              {
                "authorId": "1686153",
                "name": "I. Dinstein"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9811883,
          "isinfluential": true,
          "contexts": [
            "PAGE xml file contains a bounding polygon for every text line in a document image.",
            "Figure 1 shows colored visualization of bounding polygons in PAGE xml file.",
            "To prepare DIVA pixel labeling, we first overlaid the binarized document image with the polygons given by the PAGE xml file.",
            "The ground truth is provided in three forms: raw pixel labeling, DIVA pixel labeling and PAGE [26] xml file."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The PAGE (Page Analysis and Ground-Truth Elements) Format Framework",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "1980669",
                "name": "Stefan Pletschacher"
              },
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12794447,
          "isinfluential": false,
          "contexts": [
            "[19] approximated baselines with piece-wise linear curves, based on a language specific features."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "New Algorithm of Straight or Curved Baseline Detection for Short Arabic Handwritten Writing",
            "abstract": "",
            "year": 2009,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "3246183",
                "name": "H. Boubaker"
              },
              {
                "authorId": "2139481",
                "name": "M. Kherallah"
              },
              {
                "authorId": "144000830",
                "name": "A. Alimi"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14000898,
          "isinfluential": false,
          "contexts": [
            "[23] used machine learning to identify text areas of different orientations in Arabic manuscripts."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Layout Analysis for Arabic Historical Document Images Using Machine Learning",
            "abstract": "",
            "year": 2012,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "145461897",
                "name": "S. S. Bukhari"
              },
              {
                "authorId": "1733858",
                "name": "T. Breuel"
              },
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 26514936,
          "isinfluential": false,
          "contexts": [
            "Multi-oriented Gaussian based method was previously proposed as a part of a whole framework for simplifying reading of historical manuscripts [12]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Simplifying the reading of historical manuscripts",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "51037361",
                "name": "Rafi Cohen"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 254110674,
          "isinfluential": false,
          "contexts": [
            "[8], [13]–[15] presented active contour models for segmenting warped textlines from camera-captured printed documents."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Coupled snakelets for curled text-line segmentation from warped document images",
            "abstract": "",
            "year": 2011,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "145461897",
                "name": "S. S. Bukhari"
              },
              {
                "authorId": "1688013",
                "name": "F. Shafait"
              },
              {
                "authorId": "1733858",
                "name": "T. Breuel"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "There are works on slightly skewed handwritten text lines [6], [7] and on curved printed text lines [8]–[11]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "212542209": {
      "citing_paper_info": {
        "title": "Text Line Segmentation of Handwritten Documents in Hindi and English",
        "abstract": "",
        "year": 2014,
        "venue": "",
        "authors": [
          {
            "authorId": "9455540",
            "name": "Sunanda Dixit"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 2,
        "unique_cited_count": 1,
        "influential_count": 1,
        "detailed_records_count": 2
      },
      "cited_papers": [
        "60062262"
      ],
      "citation_details": [
        {
          "citedcorpusid": 60062262,
          "isinfluential": false,
          "contexts": [
            "A Natural Learning Algorithm based on Hough Transform for Text Lines Extraction [3] is proposed by Yao.",
            "[3] Yao Pu,Zhixin Shi, A Natural Learning Algorithm based on Hough Transform for Text\nLines Extraction in Handwritten Documents,in: Proceedings of the 6th International Workshop on Frontiers in Handwriting Recognition, Korea,1998,pp637-646."
          ],
          "intents": [
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "A natural learning algorithm based on Hough transform for text lines extraction in handwritten documents",
            "abstract": "",
            "year": 1999,
            "venue": "",
            "authors": [
              {
                "authorId": "2139654987",
                "name": "Yao Pu"
              },
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": true,
          "contexts": [
            "[9] Fei Yin,Cheng-Lin Liu,Handwritten text line segmentation by clustering with distance metric\nlearning, in: International Conference on Frontiers in HandwritinG Recognition (ICFHR’08), Montreal,Canada, August 2008,pp. 229-234.",
            "[8] Fei Yin,Cheng-Lin Liu, Handwritten Text Line Extraction based on mimimum spanning tree\nclustering, in:International Conference on Wavelet Analysis and Pattern Recognition, Beijing,China,November 2007, pp.1123-1128.",
            "Handwritten text line segmentation by clustering with distance metric learning is proposed by Fei Yin [9].",
            "Handwritten text line segmentation by\nclustering with distance metric learning is proposed by Fei Yin [9]."
          ],
          "intents": [
            "--",
            "--",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "33247622": {
      "citing_paper_info": {
        "title": "Text Line Extraction Using DMLP Classifiers for Historical Manuscripts",
        "abstract": "",
        "year": 2013,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "1708890",
            "name": "M. Baechler"
          },
          {
            "authorId": "1743758",
            "name": "M. Liwicki"
          },
          {
            "authorId": "1680326",
            "name": "R. Ingold"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 6,
        "unique_cited_count": 6,
        "influential_count": 1,
        "detailed_records_count": 6
      },
      "cited_papers": [
        "15709769",
        "16669882",
        "16167028",
        "9187881",
        "18094322",
        "63214254"
      ],
      "citation_details": [
        {
          "citedcorpusid": 9187881,
          "isinfluential": true,
          "contexts": [
            "[15] uses a level set approach to first generate rough estimations of the text line boundaries and refines them at later stages.",
            "As defined in [15], a line i in the groundtruth is correctly detected if and only if Gij(Smax) |GTi| ≥ 0.",
            "For evaluating the performance of our grouping algorithm, the pixel-level hit rate and the line accuracy measure presented by [15] and by [13] are applied on the binary image in where the foreground (text) is represented in black and background in white, respectively.",
            "For an assignment S(i) = j between groundtruth lines and detected lines, [15] defined a goodness measure G(S) = ∑ k pkS(k), which corresponds to the total number of shared pixels."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2251174782",
                "name": "Stefan Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15709769,
          "isinfluential": false,
          "contexts": [
            "[11] discriminate drawing and text block in gray level images by using multiresolution texture features."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document image characterization using a multiresolution analysis of the texture: application to old documents",
            "abstract": "",
            "year": 2008,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1748667",
                "name": "N. Journet"
              },
              {
                "authorId": "1689847",
                "name": "Jean-Yves Ramel"
              },
              {
                "authorId": "1682986",
                "name": "R. Mullot"
              },
              {
                "authorId": "1721326",
                "name": "V. Eglin"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16167028,
          "isinfluential": false,
          "contexts": [
            "Wellknown segmentation techniques for documents are the Projection Profile Algorithm [3], [4], [5], Hough Transformation [6], [7], and Run Length Smoothing Algorithm [8], [9]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line detection in handwritten documents",
            "abstract": "Article history: Received 13 April 2007 Received in revised form 26 March 2008",
            "year": 2008,
            "venue": "",
            "authors": [
              {
                "authorId": "2084353304",
                "name": "G. Louloudisa"
              },
              {
                "authorId": "2080207726",
                "name": "B. Gatosb"
              },
              {
                "authorId": "2085864307",
                "name": "I. Pratikakisb"
              },
              {
                "authorId": "2080987605",
                "name": "C. Halatsisa"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16669882,
          "isinfluential": false,
          "contexts": [
            "Wellknown segmentation techniques for documents are the Projection Profile Algorithm [3], [4], [5], Hough Transformation [6], [7], and Run Length Smoothing Algorithm [8], [9]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Hough based algorithm for extracting text lines in handwritten documents",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "1409083785",
                "name": "Anahid Hanimyan"
              },
              {
                "authorId": "38138508",
                "name": "C. Faure"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18094322,
          "isinfluential": false,
          "contexts": [
            "In order to retrieve the ground-truth for text line extraction, we annotated the physical structure for these sets using the XML format specified in [18]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Medieval manuscript layout model",
            "abstract": "",
            "year": 2010,
            "venue": "ACM Symposium on Document Engineering",
            "authors": [
              {
                "authorId": "1708890",
                "name": "M. Baechler"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 63214254,
          "isinfluential": false,
          "contexts": [
            "The work on this paper is motivated by the HisDoc project [1] which aims to exploit such manuscript images and transform them into a searchable electronic text edition.",
            "The HisDoc project [1] provides public access to three data sets for developing handwriting recognition systems1.",
            "Previous work on the database [1] provides a partition of the corpus into training sets, validation sets and testing sets.",
            "In the scope of the HisDoc project this step is feasible since small text blocks with only a few text lines are not considered for the recognition [1]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "The HisDoc Project. Automatic Analysis, Recognition, and Retrieval of Handwritten Historical Documents for Digital Libraries",
            "abstract": "",
            "year": 2014,
            "venue": "",
            "authors": [
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              },
              {
                "authorId": "145004544",
                "name": "Nada Naji"
              },
              {
                "authorId": "145129426",
                "name": "J. Savoy"
              },
              {
                "authorId": "1708890",
                "name": "M. Baechler"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        }
      ]
    },
    "18720327": {
      "citing_paper_info": {
        "title": "Text Line Detection in Corrupted and Damaged Historical Manuscripts",
        "abstract": "",
        "year": 2013,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "2578300",
            "name": "Irina Rabaev"
          },
          {
            "authorId": "2339207",
            "name": "Ofer Biller"
          },
          {
            "authorId": "1397974623",
            "name": "Jihad El-Sana"
          },
          {
            "authorId": "1939225",
            "name": "K. Kedem"
          },
          {
            "authorId": "1686153",
            "name": "I. Dinstein"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 0,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "10232002",
        "5252785",
        "1413694",
        "2123198",
        "6873248"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1413694,
          "isinfluential": false,
          "contexts": [
            "[13] introduced repulsive attractive (RA) network for baseline extraction on document images."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Repulsive attractive network for baseline extraction on document images",
            "abstract": "",
            "year": 1997,
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "authors": [
              {
                "authorId": "8222607",
                "name": "Erhan Öztop"
              },
              {
                "authorId": "3049928",
                "name": "Adem Yasar Mülayim"
              },
              {
                "authorId": "1737543",
                "name": "V. Atalay"
              },
              {
                "authorId": "1398326708",
                "name": "F. Yarman-Vural"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2123198,
          "isinfluential": false,
          "contexts": [
            "The evaluation strategy presented in [19] is defined for binary images, so we slightly modified it for gray scale images.",
            "We adapted the evaluation strategy as used in ICDAR handwriting segmentation contest [19]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "144429596",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "2265885161",
                "name": "Umapada Pal"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5252785,
          "isinfluential": false,
          "contexts": [
            "[17] relies on interest points which represent letters.",
            "[17] used slightly different evaluation criteria."
          ],
          "intents": [
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Binarization-Free Text Line Segmentation for Historical Documents Based on Interest Point Clustering",
            "abstract": "",
            "year": 2012,
            "venue": "2012 10th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1697354",
                "name": "A. Garz"
              },
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1706090",
                "name": "Robert Sablatnig"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6873248,
          "isinfluential": false,
          "contexts": [
            "we built it manually for our set using an interactive webbased system [18]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "WebGT: An Interactive Web-Based System for Historical Document Ground Truth Generation",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2339207",
                "name": "Ofer Biller"
              },
              {
                "authorId": "145766704",
                "name": "Abedelkadir Asi"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1686153",
                "name": "I. Dinstein"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10232002,
          "isinfluential": false,
          "contexts": [
            "[14] converted an input gray scale image into so called adaptive local connectivity map (ALCM), where the value of each pixel is defined to be the cumulative intensity of all pixel values inside a window of a predefined size."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text extraction from gray scale historical document images using adaptive local connectivity map",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1800513",
                "name": "Srirangaraj Setlur"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        }
      ]
    },
    "54213991": {
      "citing_paper_info": {
        "title": "Weighted-Gradient Features for Handwritten Line Segmentation",
        "abstract": "Text line segmentation from handwritten documents is challenging when a document image contains severe touching. In this paper, we propose a new idea based on Weighted-Gradient Features (WGF) for segmenting text lines. The proposed method finds the number of zero crossing points for every row of Canny edge image of the input one, which is considered as the weights of respective rows. The weights are then multiplied with gradient values of respective rows of the image to widen the gap between pixels in the middle portion of text and the other portions. Next, k-means clustering is performed on WGF to classify middle and other pixels of text. The method performs morphological operation to obtain word components as patches for the result of clustering. The patches in both the clusters are matched to find common patch areas, which helps in reducing touching effect. Then the proposed method checks linearity and non-linearity iteratively based on patch direction to segment text lines. The method is tested on our own and standard datasets, namely, Alaei, ICDAR 2013 robust competition on handwriting context and ICDAR 2015-HTR, to evaluate the performance. Further, the method is compared with the state of art methods to show its effectiveness and usefulness.",
        "year": 2018,
        "venue": "International Conference on Pattern Recognition",
        "authors": [
          {
            "authorId": "2589871",
            "name": "Vijeta Khare"
          },
          {
            "authorId": "1744575",
            "name": "P. Shivakumara"
          },
          {
            "authorId": "144942234",
            "name": "B. Navya"
          },
          {
            "authorId": "144976948",
            "name": "G. Swetha"
          },
          {
            "authorId": "1741813",
            "name": "D. S. Guru"
          },
          {
            "authorId": "144167309",
            "name": "U. Pal"
          },
          {
            "authorId": "144720255",
            "name": "Tong Lu"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 5,
        "unique_cited_count": 5,
        "influential_count": 2,
        "detailed_records_count": 5
      },
      "cited_papers": [
        "1610874",
        "2123198",
        "3885996",
        "15096034",
        "36389323"
      ],
      "citation_details": [
        {
          "citedcorpusid": 1610874,
          "isinfluential": false,
          "contexts": [
            "Vo and Lee [10] proposed dense prediction for text line segmentation in handwritten document images.",
            "[10] [10] Q. N. Vo and G. Lee, “Dense prediction for text line segmentation in handwritten document images”, In Proc."
          ],
          "intents": [
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Dense prediction for text line segmentation in handwritten document images",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Information Photonics",
            "authors": [
              {
                "authorId": "12581289",
                "name": "Q. Vo"
              },
              {
                "authorId": "144096223",
                "name": "Gueesang Lee"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2123198,
          "isinfluential": true,
          "contexts": [
            "Segmentation dataset [13]",
            "ICDAR2013 [13] 96.",
            "[12] which contains 200 Bangla, 228 Kannada and 140 Oriya handwritten images, ICDAR 2013 handwriting context competition [13] which provides 350 handwritten images, and ICDAR 2015HTR [14] handwriting recognition context which provides 746 handwritten images.",
            "The acceptance threshold is used as Ta=95% according to ICDAR 2013 [13].",
            "To calculate measures, we use the standard evaluation scheme proposed in ICDAR 2013 handwriting segmentation contest [13], where they defined the following measures."
          ],
          "intents": [
            "--",
            "--",
            "['background']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwriting Segmentation Contest",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1700033",
                "name": "N. Stamatopoulos"
              },
              {
                "authorId": "144429596",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "2265885161",
                "name": "Umapada Pal"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              },
              {
                "authorId": "1971318",
                "name": "Alireza Alaei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 3885996,
          "isinfluential": true,
          "contexts": [
            "16%) of the latest method [11], there is a marginal difference 3.",
            "[11] V. Chavan and K. Mehrotra, “Text line segmentation of multilingual handwritten documents using Fourier approximation”, In Proc.",
            "Chavan and Mehrotra [11] proposed a method for text line segmentation of multilingual handwritten documents using Fourier approximation."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of multilingual handwritten documents using fourier approximation",
            "abstract": "",
            "year": 2017,
            "venue": "International Conference on Intelligent Information Processing",
            "authors": [
              {
                "authorId": "47879101",
                "name": "Vishal Chavan"
              },
              {
                "authorId": "39476278",
                "name": "Kapil Mehrotra"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15096034,
          "isinfluential": false,
          "contexts": [
            "[7] A. Sushma and G. S. Veena, “Kannada handwritten word conversion to electronic textual format using HMM model”, In Proc.",
            "Sushma and Veena [7] proposed Kannada handwritten line and word segmentation."
          ],
          "intents": [
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Kannada handwritten word conversion to electronic textual format using HMM model",
            "abstract": "",
            "year": 2016,
            "venue": "2016 International Conference on Computation System and Information Technology for Sustainable Solutions (CSITSS)",
            "authors": [
              {
                "authorId": "143998009",
                "name": "A. Sushma"
              },
              {
                "authorId": "145614878",
                "name": "G. Veena"
              }
            ]
          }
        },
        {
          "citedcorpusid": 36389323,
          "isinfluential": false,
          "contexts": [
            "[8] proposed a new scheme for text line and character segmentation from gray scale images of Palm leaf manuscript.",
            "[8] proposed a new scheme for text line and character segmentation from gray scale image of palm leaf manuscript."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A New Scheme for Text Line and Character Segmentation from Gray Scale Images of Palm Leaf Manuscript",
            "abstract": "",
            "year": 2016,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2154407",
                "name": "M. W. A. Kesiman"
              },
              {
                "authorId": "1690398",
                "name": "J. Burie"
              },
              {
                "authorId": "1695766",
                "name": "J. Ogier"
              }
            ]
          }
        }
      ]
    },
    "17306209": {
      "citing_paper_info": {
        "title": "A novel approach to text line and word segmentation on odia printed documents",
        "abstract": "",
        "year": 2012,
        "venue": "International Conference on Computing Communication and Networking Technologies",
        "authors": [
          {
            "authorId": "49244506",
            "name": "D. Senapati"
          },
          {
            "authorId": "34675875",
            "name": "S. Rout"
          },
          {
            "authorId": "38351189",
            "name": "M. Nayak"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 2,
        "unique_cited_count": 2,
        "influential_count": 0,
        "detailed_records_count": 2
      },
      "cited_papers": [
        "59216984",
        "262766948"
      ],
      "citation_details": [
        {
          "citedcorpusid": 59216984,
          "isinfluential": false,
          "contexts": [
            "Typically zero is taken to be black, and 255 are taken to be white, Values in between make up the different shades of gray [2]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Hypermedia image processing reference",
            "abstract": "USER GUIDE Introduction to HIPR How to Use HIPR Advanced Topics IMAGE PROCESSING OPERATION REFERENCE Image Arithmetic Point Operations Geometric Operations Image Analysis Morphology Digital Filters Feature Detectors Image Transforms THE IMAGE LIBRARY Image Synthesis Appendices.",
            "year": 1996,
            "venue": "",
            "authors": [
              {
                "authorId": "145594335",
                "name": "R. Fisher"
              }
            ]
          }
        },
        {
          "citedcorpusid": 262766948,
          "isinfluential": false,
          "contexts": [
            "Global binarization and locally adaptive binarization are two popular types of binarization methods [4].",
            "Rotating the image by the skew angle in the opposite direction [4]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Line and Word Segmentation Approach for Printed Documents",
            "abstract": "Line and word segmentation is one of the important step of OCR systems. In this paper we have proposed a robust method for segmentation of individual text lines based on the modified histogram obtained from run length based smearing. A complete line and word segmentation system for some popular Indian printed languages is presented here. Both foreground and background information are used here for accurate line segmentation. There may be some touching or overlapping characters between two consecutive text lines and most of the line segmentation errors are generated due to touching and overlapping character occurrences. Sometimes, interline space and noises make line segmentation a difficult task. Our method can take care of this situation accurately. Word segmentation from individual lines is also discussed here. We have tested our method on documents of Bangla, Devnagari, Kannada, Telugu scripts as well as some multi-script documents and we have obtained encouraging results from our proposed technique.",
            "year": 2010,
            "venue": "",
            "authors": [
              {
                "authorId": "2300212125",
                "name": "Nallapareddy Priyanka"
              },
              {
                "authorId": "1752887",
                "name": "S. Pal"
              },
              {
                "authorId": "2478791",
                "name": "Ranju Mandal"
              }
            ]
          }
        }
      ]
    },
    "56595963": {
      "citing_paper_info": {
        "title": "Text Line Extraction Based on Distance Map Features and Dynamic Programming",
        "abstract": "Text Line Segmentation is a basic document layout task that consists in detecting and extracting the text lines present in a document page image. Although considered a basic task, generally, it is a necessary step for Handwritten Text Recognition (HTR) higher level tasks. Most state of the art automatic text recognition, text-to-line image alignment and key word spotting systems require it due to their need for isolated text line images as input. Traditionally most Text Line Segmentation approaches cover both detection and extraction sub steps. However, the community has recently shifted its focus to tackle independently the baseline detection in document images. This shift generates the need for extraction methods that use these detected baselines as input. In this paper, a binarization free dynamic programming approach that generates an equidistant text line extraction polygon is presented. The approach performs this calculation, based on the information provided by priorly detected text baselines and automatically generated foreground pixels distance maps. We evaluate our approach both in a synthetic competition corpus and in a challenging real handwritten text recognition task corpus. We evaluate it not only at the graphical error level but also the impact it produces on an HTR task trained with the line images it yields. We compare our solution with other solutions ranging from the actual human reviewed ground-truth polygons to simpler automatic generated rectangle areas.",
        "year": 2018,
        "venue": "International Conference on Frontiers in Handwriting Recognition",
        "authors": [
          {
            "authorId": "52316905",
            "name": "Vicente Bosch Campos"
          },
          {
            "authorId": "52518287",
            "name": "Verónica Romero Gómez"
          },
          {
            "authorId": "52318154",
            "name": "Alejandro Héctor Toselli Rossi"
          },
          {
            "authorId": "52588313",
            "name": "Enrique Vidal Ruiz"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 11,
        "unique_cited_count": 11,
        "influential_count": 4,
        "detailed_records_count": 11
      },
      "cited_papers": [
        "2543004",
        "2442996",
        "17844687",
        "4764898",
        "12495425",
        "14811420",
        "1532725",
        "14196680",
        "619938",
        "14885714",
        "16602694"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "The detection step usually consists in detecting the number of text lines and their general localization by means of a baseline or median line [8]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1532725,
          "isinfluential": true,
          "contexts": [
            "In order to train the extremely randomized trees required for the automatic text baseline detection method [21], used in the aforementioned second scenario, only 5 pages from the training partition in the case of the ICDAR 2013 data set were required.",
            "These automatic baselines were provided by a state of the art baseline detection method [21] based on extremely randomized trees and the dbscan algorithm.",
            "When using the PRHLT-17 [21] automatically detected baselines, our second scenario, our approach has an adequate performance."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Baseline Detection on Arabic Handwritten Documents",
            "abstract": "",
            "year": 2017,
            "venue": "ACM Symposium on Document Engineering",
            "authors": [
              {
                "authorId": "24058767",
                "name": "Ahmed Fawzi"
              },
              {
                "authorId": "143614719",
                "name": "Moisés Pastor"
              },
              {
                "authorId": "1401155500",
                "name": "C. Martínez-Hinarejos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2442996,
          "isinfluential": false,
          "contexts": [
            "Both of them were automatically generated and corrected manually [18]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Semiautomatic Text Baseline Detection in Large Historical Handwritten Documents",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "3277118",
                "name": "Vicente Bosch"
              },
              {
                "authorId": "66364727",
                "name": "A. Rossi"
              },
              {
                "authorId": "143783065",
                "name": "E. Vidal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 2543004,
          "isinfluential": true,
          "contexts": [
            "In Table II we present how the quality of the extraction polygon affects the WER and CER in this HTR task and compare the results to the already existing results for this corpus [15].",
            "The documents text lines were annotated in three ways as described in [15].",
            "In order to obtain the WER and CER results we performed an 8-block (of 5 pages each) crossvalidation experiment per segmentation technique (Read [15] for further detail on the block contents).",
            "These 40 non-consecutive pages of the manuscript were selected by a human expert in order to ensure a reduced set that would be representative of all the different page formats, page deterioration and ink variation that appear throughout the book, as described in [14], [15].",
            "tion from the already existing baselines in order to compute the extraction polygon [15]."
          ],
          "intents": [
            "['result']",
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Influence of text line segmentation in Handwritten Text Recognition",
            "abstract": "Text line segmentation is the process by which text lines in a document image are localized and extracted. It is an important step in off-line Handwritten Text Recognition (HTR) given that the input of these systems is the line image of the text to be transcribed. A myriad of solutions to the text line segmentation problem have been proposed in the literature. Although these solutions may differ greatly on what is actually applied to perform the segmentation, they can be classified by the level of precision and detail in the final extracted lines. In this paper we study the influence and real needs of different levels of precision and detail in the segmentation solutions in a real HTR task. We test three technics of text line segmentation whose output range from a simple rectangle for each line to a perfect fitted polygon surrounding the detected lines. Experiments have been carried out with a historical collection and results show that good HTR accuracy can be obtained with simple extraction algorithms.",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "144340605",
                "name": "Verónica Romero"
              },
              {
                "authorId": "1928123",
                "name": "Joan Andreu Sánchez"
              },
              {
                "authorId": "3277118",
                "name": "Vicente Bosch"
              },
              {
                "authorId": "11514804",
                "name": "K. Depuydt"
              },
              {
                "authorId": "3302102",
                "name": "J. Does"
              }
            ]
          }
        },
        {
          "citedcorpusid": 4764898,
          "isinfluential": false,
          "contexts": [
            "page image are currently being explored [1], currently most of the approaches for Handwritten Text Recognition (HTR) [2], [3] and Keyword Spotting (KWS) [4], [5] are dependent on TLS."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Gated Convolutional Recurrent Neural Networks for Multilingual Handwriting Recognition",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "3387810",
                "name": "Théodore Bluche"
              },
              {
                "authorId": "3480666",
                "name": "Ronaldo O. Messina"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12495425,
          "isinfluential": false,
          "contexts": [
            "The line images of the training partitions were used to train corresponding character HMM models using the standard embedded Baum-Welch training algorithm [22]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Statistical methods for speech recognition",
            "abstract": "The speech recognition problem hidden Markov models the acoustic model basic language modelling the Viterbi search hypothesis search on a tree and the fast match elements of information theory the complexity of tasks - the quality of language models the expectation - maximization algorithm and its consequences decision trees and tree language models phonetics from orthography - spelling-to-base from mappings triphones and allophones maximum entropy probability estimation and language models three applications of maximum entropy estimation to language modelling estimation of probabilities from counts and the Back-Off method.",
            "year": 1997,
            "venue": "",
            "authors": [
              {
                "authorId": "2472759",
                "name": "F. Jelinek"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14196680,
          "isinfluential": false,
          "contexts": [
            "Text line extraction polygon groundtruth was generated automatically [16] and any system errors were manually corrected afterwards."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line and word segmentation of handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14811420,
          "isinfluential": false,
          "contexts": [
            "page image are currently being explored [1], currently most of the approaches for Handwritten Text Recognition (HTR) [2], [3] and Keyword Spotting (KWS) [4], [5] are dependent on TLS."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A study of Bag-of-Visual-Words representations for handwritten keyword spotting",
            "abstract": "",
            "year": 2015,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1763464",
                "name": "David Aldavert"
              },
              {
                "authorId": "143823474",
                "name": "Marçal Rusiñol"
              },
              {
                "authorId": "144083430",
                "name": "R. Toledo"
              },
              {
                "authorId": "143826881",
                "name": "J. Lladós"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14885714,
          "isinfluential": true,
          "contexts": [
            "As explained in [14], this medieval manuscript is full of abbreviations that were indicated in the script using special symbols that are currently not in use any more.",
            "Hattem Manuscript Experiments were carried out using the C5 Hattem Manuscript [14].",
            "Next, we will evaluate the impact that our approach has on a real historical corpus the C5 Hattem Manuscript.",
            "The HTR experimentation could only be performed in the C5 Hattem Manuscript.",
            "These 40 non-consecutive pages of the manuscript were selected by a human expert in order to ensure a reduced set that would be representative of all the different page formats, page deterioration and ink variation that appear throughout the book, as described in [14], [15].",
            "Experiments were carried out using the C5 Hattem Manuscript [14]."
          ],
          "intents": [
            "['background']",
            "--",
            "--",
            "--",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten text recognition for historical documents in the transcriptorium project",
            "abstract": "Transcription of historical handwritten documents is a crucial problem for making easier the access to these documents to the general public. Currently, huge amount of historical handwritten documents are being made available by on-line portals worldwide. It is not realistic to obtain the transcription of these documents manually, and therefore automatic techniques has to be used. tranScriptorium is a project that aims at researching on modern Handwritten Text Recognition (HTR) technology for transcribing historical handwritten documents. The HTR technology used in tranScriptorium is based on models that are learnt automatically from examples. This HTR technology has been used on a Dutch collection from 15th century selected for the tranScriptorium project. This paper provides preliminary HTR results on this Dutch collection that are very encouraging, taken into account that minimal resources have been deployed to develop the transcription system.",
            "year": 2014,
            "venue": "Digital Access to Textual Cultural Heritage",
            "authors": [
              {
                "authorId": "1928123",
                "name": "Joan Andreu Sánchez"
              },
              {
                "authorId": "3277118",
                "name": "Vicente Bosch"
              },
              {
                "authorId": "144340605",
                "name": "Verónica Romero"
              },
              {
                "authorId": "11514804",
                "name": "K. Depuydt"
              },
              {
                "authorId": "3302102",
                "name": "J. Does"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16602694,
          "isinfluential": false,
          "contexts": [
            "In Table II we present how the quality of the extraction polygon affects the WER and CER in this HTR task and compare the results to the already existing results for this corpus [15].",
            "The performance variations in the HTR system will be measured by the Word Error Rate (WER) and the Character Error Rate (CER) [19], defined as the ration between the minimum number of words/characters that need to be substituted, deleted or inserted to convert the sentences recognized by the system into the reference transcriptions and the total number of words/characters in these transcriptions.",
            "In order to obtain the WER and CER results we performed an 8-block (of 5 pages each) crossvalidation experiment per segmentation technique (Read [15] for further detail on the block contents)."
          ],
          "intents": [
            "--",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "On the Use of Information Retrieval Measures for Speech Recognition Evaluation",
            "abstract": "This paper discusses the evaluation of automatic speech recognition (ASR) systems developed for practical applications, suggesting a set of criteria for application-oriented performance measures. The commonly used word error rate (WER), which poses ASR evaluation as a string editing process, is shown to have a number of limitations with respect to these criteria, motivating alternative or additional measures. This paper suggests that posing speech recognition evaluation as an information retrieval problem, where each word is one unit of information, offers a flexible framework for application-oriented performance analysis based on the concepts of recall and precision.",
            "year": 2004,
            "venue": "",
            "authors": [
              {
                "authorId": "1762976",
                "name": "I. McCowan"
              },
              {
                "authorId": "143929295",
                "name": "Darren Moore"
              },
              {
                "authorId": "37787729",
                "name": "J. Dines"
              },
              {
                "authorId": "1403029865",
                "name": "D. Gática-Pérez"
              },
              {
                "authorId": "38059118",
                "name": "Mike Flynn"
              },
              {
                "authorId": "2751729",
                "name": "P. Wellner"
              },
              {
                "authorId": "1733733",
                "name": "H. Bourlard"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17844687,
          "isinfluential": true,
          "contexts": [
            "The ICDAR 2013 data set is a synthetic corpus created for competition purposes [13].",
            "To evaluate graphical error, the difference between the hypothesis extraction polygon and the ground truth, we used the ICDAR Handwritten Segmentation Contest metrics (at line level) [13].",
            "In the first experiment, we compare the results provided by the benchmark method and our approach with the results of the initial ICDAR 2013 participants [13], a more recent graph",
            "This was evaluated via the ICDAR 2013 competition corpus and the results presented with it [13], [12], [20]."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['result']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition ICDAR2009 Handwriting Segmentation Contest",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        }
      ]
    },
    "51949944": {
      "citing_paper_info": {
        "title": "Slant Removal Technique for Historical Document Images",
        "abstract": "Slanted text has been demonstrated to be a salient feature of handwriting. Its estimation is a necessary preprocessing task in many document image processing systems in order to improve the required training. This paper describes and evaluates a new technique for removing the slant from historical document pages that avoids the segmentation procedure into text lines and words. The proposed technique first relies on slant angle detection from an accurate selection of fragments. Then, a slant removal technique is applied. However, the presented slant removal technique may be combined with any other slant detection algorithm. Experimental results are provided for four document image databases: two historical document databases, the TrigraphSlant database (the only database dedicated to slant removal), and a printed database in order to check the precision of the proposed technique.",
        "year": 2018,
        "venue": "Journal of Imaging",
        "authors": [
          {
            "authorId": "1752313",
            "name": "E. Kavallieratou"
          },
          {
            "authorId": "1398902377",
            "name": "Laurence Likforman-Sulem"
          },
          {
            "authorId": "2513102",
            "name": "Nikos Vasilopoulos"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 12,
        "unique_cited_count": 9,
        "influential_count": 4,
        "detailed_records_count": 12
      },
      "cited_papers": [
        "38394533",
        "26861255",
        "7858893",
        "17052863",
        "13927885",
        "28950443",
        "15241313",
        "34510496",
        "21952159"
      ],
      "citation_details": [
        {
          "citedcorpusid": 7858893,
          "isinfluential": true,
          "contexts": [
            "As it is obvious in Figure 12, the value of just five main-bodies seems to give significantly better results (smaller SSE) which is far smaller than seven, initially used in [17].",
            "A preliminary approach has been described in [17], while in this paper the parameter set up is considered and described in detail.",
            "In [17], the rate of 10% was used as approved amount of text in the selected windows just by test and trial.",
            "As initial parameter values, the parameters used in [17] are used in our experiments, and as soon as the best parameter value is estimated, it is used further on."
          ],
          "intents": [
            "['result']",
            "['methodology']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A slant removal technique for document page",
            "abstract": "",
            "year": 2013,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "1752313",
                "name": "E. Kavallieratou"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13927885,
          "isinfluential": false,
          "contexts": [
            "Techniques that are based on the statistics of chain-coded contours [10–12]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Improvement in handwritten numeral string recognition by slant normalization and contextual information",
            "abstract": "This work describes a way of enhancing handwritten numeral string recognition by considering slant normalization and contextual information to train an implicit segmentation­based system. A word slant normalization method is modified in order to improve the results for handwritten numeral strings. We assume that each connected component (CC) in the string has its own slant. The slant and contour length of each CC are used for obtaining the mean slant of the string. Both the original and modified methods are evaluated by means of some interesting analyses on the NIST SD19 database. These analyses show (a) the positive impact of slant correction on the number of overlapping numerals in strings, and (b) the difference in normalizing isolated numerals based on the slant estimated from their own images and the slant estimated from their original string images. Slant normalization and contextual information regarding string slant and digit size variations within the string are used to train numeral HMMs. Preliminary string recognition results, produced by a system under construction, are shown.",
            "year": 2004,
            "venue": "",
            "authors": [
              {
                "authorId": "143772141",
                "name": "A. Britto"
              },
              {
                "authorId": "1744351",
                "name": "R. Sabourin"
              },
              {
                "authorId": "2833834",
                "name": "E. Lethelier"
              },
              {
                "authorId": "1682534",
                "name": "Flávio Bortolozzi"
              },
              {
                "authorId": "1713795",
                "name": "C. Suen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15241313,
          "isinfluential": false,
          "contexts": [
            "The technique [24] estimates the slant by using the peaks of the slanted words."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Slant estimation and core-region detection for handwritten Latin words",
            "abstract": "",
            "year": 2014,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "143977856",
                "name": "A. Papandreou"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17052863,
          "isinfluential": true,
          "contexts": [
            "This archive contains a set of 20 page images from the George Washington collection [19] at the Library of Congress in the United States.",
            "George Washington DB This archive contains a set of 20 page images from the George Washington collection [19] at the Library of Congress in the United States.",
            "The George Washington DB [19], in order to perform tests on a renowned DB of historical documents.",
            " the TrigraphSlant database [18] (the only available database for slant estimation),  two databases of historical documents (George Washington [19] and Barcelona historical, handwritten marriages database BH2M [20])  a synthetic printed databas where slants are fully determined.",
            "• the TrigraphSlant database [18] (the only available database for slant estimation), • two databases of historical documents (George Washington [19] and Barcelona historical, handwritten marriages database BH2M [20]) • a synthetic printed database where slants are fully determined."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Holistic word recognition for handwritten historical documents",
            "abstract": "",
            "year": 2004,
            "venue": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings.",
            "authors": [
              {
                "authorId": "1757708",
                "name": "V. Lavrenko"
              },
              {
                "authorId": "2352980",
                "name": "T. Rath"
              },
              {
                "authorId": "1758550",
                "name": "R. Manmatha"
              }
            ]
          }
        },
        {
          "citedcorpusid": 21952159,
          "isinfluential": false,
          "contexts": [
            "Non-uniform slant correction techniques [13–16]: they handle the characters apart and deal with the existence of several slants, simultaneously."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Non-Uniform Slant Correction for Handwritten Text Line Recognition",
            "abstract": "",
            "year": 2007,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2168488",
                "name": "Roman Bertolami"
              },
              {
                "authorId": "1809705",
                "name": "S. Uchida"
              },
              {
                "authorId": "2054206556",
                "name": "Matthias Zimmermann"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 26861255,
          "isinfluential": false,
          "contexts": [
            "This specific algorithm makes use of the To detect that, it uses the Wigner Ville distribution (WVD) [21], a space-frequency distribution of Cohen’s class, which is given by the formula difference between the ascenders and descenders.",
            "Wigner Ville distribution (WVD) [21], a space-frequency distribution of Cohen’s class, which is given by the formula where s the signal, f the frequency, z ( s ) represents the analytical signal associated with the discrete signal h(s), that in the paper [9] is the vertical projection profile of…"
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "THE WIGNER DISTRIBUTION - A TOOL FOR TIME-FREQUENCY SIGNAL ANALYSIS",
            "abstract": "In this second part of the paper the Wigner distribution is adapted to the case of discrete-time signals. It is shown that most of the properties of this time-frequency signal representation carry over directly to the discrete-time case, but some.others cause problems. These problems are associated with the fact that in general the Wigner distribution of a discrete-time signal contains aliasing contributions. It is indicated that these aliasing components will not be present if the signal is either oversampled by a factor of at least two, or is analytic. 1. Introduetion In part I of this paper 1) the Wigner distribution (WD) of continuous-time signals was discussed, and it was shown that this function has some very interesting properties. The determination of this distribution function requires, like the spectrum, an integral of the Fourier type to be evaluated. Ideally this requires the signal to be known for all. time, but in practice windowing techniques can be used to relax this requirement. The effects of windowing on the WD were discussed in part 1. In general two different approaches can be distinguished to compute these Fourier-type integrals. The first is by means of analogue signal processing, and recently optical signal processing methods have been proposed for determining suitable approximations to the WD 2). The second approach is based on digital signal processing. This opens the way to apply computationally efficient methods for evaluating the discrete Fourier transform, but requires the concept of the Wigner distribution to be transferred to the case of discretetime signals. This is the aim of this part of the paper. As can be expected, the WD for discrete-time signals shows much similarity with that for continuous-time signals, but in some respects it has characteristic differences. To emphasize the similarities and point out the differences we will try to follow as closely as possible the same lines as in part I, and give comments only on those results that differ from that of the continuous-time counterpart. 276 Phillps Journalof Research Vol.35 Nos.4/5 1980 Philips Journalof Research Vol.35 Nos.4/5 1980 277 The Wigner distribution Also the numbering of the equations is made such that corresponding equations have the same number. This has the consequence that sometimes equation numbers are not successive if equations have been deleted, and that equations that do not occur in part I have a special numbering. If reference is made to an equation in part I the equation is given the prefix I. All sections, except sec. 7, have the same topic and heading as in part I. Section 7, which in part I deals with the WD of band-limited signals, now deals with the WD of finite duration sequences. Equations in this section do not correspond in general with an equation of part I. 2. The Wigner distribution for discrete-time signals 2.1 Preliminaries In this paper Weconsider in general complex valued, discrete-time signals f(n), feC, n e Z for which the (Fourier) spectrum is defined by 3) 00 F(e) = (fJdf) (e) = L f(n) e -jnlJ. (2.l.a) n=-c:o The inverse transform is given by 11 f(n) = (fJd-l F) (n) = _1_ J F(e) ejnlJ de, 21t (2.l.b) -11 Inner products are defined for the signals and spectra by 00 (I, g) = L f(n) g*(n) (2.2.a) n=-oo and 11 (F, G) = _1 J F(e) G*(e) de 21t (2.2.b) -11 respectively. Norms and Parseval's relation are then the same as in eqs (1.2.3) and (1.2.4) respectively. The following operators will be used. The shift operator for the signals (9{f) (n) = f(n k), kEZ (2.5.a) and for the spectrum (.9'cF) (e) = F(e C), CE R, (complex) modulation in the time domain T. A. C. M. Claasen and W. F. G. Mecklenbrauker ( .At!!,!) (n) = f (n) ein!!, and in the frequency domain . c;«; F) (0) = F(O) einD ceR (2.6.a) neZ, (2.6.b) differentiation of the spectrum 1 (fi))F) (0) = -;-F 1(0), J (2.7) multiplication by the running variable (Rlf) (n) = nf(n), (2.8) time reversal (f!JlJ)(n) = f( -nl· (2.9) There are several different ways to link analogue and. digital signals and systems, and hence a variety of ways to define a discrete-time version of the Wigner distribution. What one would like with such a definition is (1) to obtain a simple concept; (2) to retain as many as possible of the properties of the WD of continuoustime signals; (3) to find a simple relation between the discrete-time and continuous-time WD's for discrete-time signals that are obtained by sampling of analogue signals. The definition which, in our opinion, best matches these requirements is the one suggested by eq. (1.7.10). 2.2. Definition of the Wigner distribution The cross-Wigner distribution of two discrete-time signals f(n) and g(n) is defined by 00 u-j,g(n, 0) = 2 L e-i2kDf(n + k)g*(n kl. (2.10) k=-oo The autoWigner distribution of a signal is then given by 00 u-j(n, 0) = Wj,f(n, 0) = 2 L e-i2kDf(n+k)f*(n kl. (2.11) k=-oo Both functions will be called a Wigner distribution (WD). Aiming at obtaining a relation similar to (1.2.13) the WD for the spectra must be defined by 278 Philips Journalor Research Vol.35 Nos.4/5 1980 The Wigner distribution so that 11 wF,G(e, n)= ~ J et; F(e + C) G*(e C) dc (2.12)",
            "year": 1980,
            "venue": "",
            "authors": [
              {
                "authorId": "2052863",
                "name": "T. Claasen"
              },
              {
                "authorId": "98206069",
                "name": "W. Mecklenbrauker"
              }
            ]
          }
        },
        {
          "citedcorpusid": 28950443,
          "isinfluential": true,
          "contexts": [
            "[3] categorized the proposed techniques by angle-frequency and repeated-shearing approaches that are described as follows:",
            "Moreover, writer identification/verification systems also use slant estimation and/or detection [3].",
            "The reason is that an algorithm for the detection is needed and this one has proved to be popular and successful [3].",
            "Last but not least, in the specific experiments, the pages were sheared entirely, since the alternative line or word segmentation is characterized as “less reliable and breaks ink traces at region boundaries” [3].",
            "[3], the slant detection techniques are the most popular with the most precise results."
          ],
          "intents": [
            "['methodology']",
            "--",
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Towards robust writer verification by correcting unnatural slant",
            "abstract": "",
            "year": 2011,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "1913949",
                "name": "Axel Brink"
              },
              {
                "authorId": "2196766",
                "name": "Ralph Niels"
              },
              {
                "authorId": "3348272",
                "name": "R. A. V. Batenburg"
              },
              {
                "authorId": "143681917",
                "name": "C. E. V. D. Heuvel"
              },
              {
                "authorId": "1799278",
                "name": "Lambert Schomaker"
              }
            ]
          }
        },
        {
          "citedcorpusid": 34510496,
          "isinfluential": false,
          "contexts": [
            "Non-uniform slant correction techniques [13–16]: they handle the characters apart and deal with the existence of several slants, simultaneously."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Non-uniform slant estimation and correction for Farsi/Arabic handwritten words",
            "abstract": "",
            "year": 2009,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2394658",
                "name": "M. Ziaratban"
              },
              {
                "authorId": "1692435",
                "name": "K. Faez"
              }
            ]
          }
        },
        {
          "citedcorpusid": 38394533,
          "isinfluential": false,
          "contexts": [
            "The main body height detection [22], since it does not require line or word segmentation; 2."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Detecting Main Body Size in Document Images",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2705163",
                "name": "Diamantatos Paraskevas"
              },
              {
                "authorId": "3077613",
                "name": "Vasileios Verras"
              },
              {
                "authorId": "1752313",
                "name": "E. Kavallieratou"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "In handwriting, slant removal is a necessary component of the text normalization procedure in systems that perform recognition (e.g., optical character recognition (OCR) [1] or word-spotting [2]), in order to improve the training procedure (less samples, lower computational cost)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "In handwriting, slant removal is a necessary component of the text normalization procedure in systems that perform recognition (e.g., optical character recognition (OCR) [1] or word-spotting [2]), in order to improve the training procedure (less samples, lower computational cost)."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": true,
          "contexts": [
            "Moreover, writer identiﬁcation/veriﬁcation systems also use slant estimation and/or detection [3].",
            "…not least, in the specific experiments, the pages were sheared entirely, since the alternative line or word segmentation is characterized as “less reliable and breaks ink traces at region The proposed techniques up to now require line or word segmentation in order to be applied. boundaries” [3].",
            "Slant estimation techniques are presented in [4–7], whereas a slant detection technique is presented According to Brink et al. [3], the slant detection techniques are the most popular with the most precise results. in [9].",
            "According to Brink et al. [3], the slant detection techniques are the most popular with the most precise The technique described in [9] is also used in that paper where extensive experiments over slant are performed. results.",
            "The reason is that an algorithm for the detection is needed and this one has proved to be popular and successful [3]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "12943905": {
      "citing_paper_info": {
        "title": "Novel Approach for Baseline Detection and Text Line Segmentation",
        "abstract": "Baseline detection and line segmentation are essential preprocessing steps of any OCR system. In this paper we have proposed a robust and fast method for base lines detection based on projected pattern analysis of Radon Transform. The algorithm have been tested on more than 350 samples including both printed and handwriting of Persian/Arabic, English and also multilingual documents. Obtained results indicate that in spite of narrow interline spaces and noisy components our method is capable to extract baseline in documents precisely. In addition, in the case of multi-frequencies pattern, it has been shown that proposed method can reach its performance to accurate detection of base lines.",
        "year": 2012,
        "venue": "",
        "authors": [
          {
            "authorId": "1391913274",
            "name": "Mahdi KeshavarzBahaghighat"
          },
          {
            "authorId": "47158466",
            "name": "J. Mohammadi"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 7,
        "unique_cited_count": 6,
        "influential_count": 0,
        "detailed_records_count": 7
      },
      "cited_papers": [
        "262766948",
        "15601450",
        "57510553",
        "3039566",
        "16767557",
        "35215159"
      ],
      "citation_details": [
        {
          "citedcorpusid": 3039566,
          "isinfluential": false,
          "contexts": [
            "To represent an image, the radon function takes multiple, parallel-beam projections of the image from different angles by rotating the source around the center of the image [1, 5, 10]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Offline Signature Verification Using Local Radon Transform and Support Vector Machines",
            "abstract": "In this paper, we propose a new method for signature verification using local Radon Transform. The proposed method uses Radon Transform locally as feature extractor and Support Vector Machine (SVM) as classifier. The main idea of our method is using Radon Transform locally for line segments detection and feature extraction, against using it globally. The advantages of the proposed method are robustness to noise, size invariance and shift invariance. Having used a dataset of 600 signatures from 20 Persian writers, and another dataset of 924 signatures from 22 English writers, our system achieves good results. The experimental results of our method are compared with two other methods. This comparison shows that our method has good performance for signature identification and verification in different cultures.",
            "year": 2009,
            "venue": "",
            "authors": [
              {
                "authorId": "2536246",
                "name": "Vahid Kiani"
              },
              {
                "authorId": "101324435",
                "name": "Reza Pourreza Shahri"
              },
              {
                "authorId": "1799405",
                "name": "H. Pourreza"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15601450,
          "isinfluential": false,
          "contexts": [
            "On the other hand, in[22] a new two-stage method for estimating and correcting the baseline of handwritten sub words in Farsi and Arabic text lines was introduced."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A novel two-stage algorithm for baseline estimation and correction in Farsi and Arabic handwritten text line",
            "abstract": "",
            "year": 2008,
            "venue": "International Conference on Pattern Recognition",
            "authors": [
              {
                "authorId": "2394658",
                "name": "M. Ziaratban"
              },
              {
                "authorId": "1692435",
                "name": "K. Faez"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16767557,
          "isinfluential": false,
          "contexts": [
            "In general, the Radon transform of f(x,y) is the line integral of f parallel to the y´-axis[11, 12, 13]: cos( ) sin( ) (2)   cos( ) sin( ) (4) sin( ) cos( )     Figure2 indicates geometry of Radon Transform ."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Vehicle speed estimation based on the image motion blur using RADON transform",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Signal Processing Systems",
            "authors": [
              {
                "authorId": "47158466",
                "name": "J. Mohammadi"
              },
              {
                "authorId": "38243260",
                "name": "R. Akbari"
              },
              {
                "authorId": "9366843",
                "name": "Mehdi Keshavarz Ba haghighat"
              }
            ]
          }
        },
        {
          "citedcorpusid": 35215159,
          "isinfluential": false,
          "contexts": [
            "The profile curve is then analyzed to find its maxima and minima [15, 16, 17]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Arabic hand-written text-line extraction",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              },
              {
                "authorId": "144484822",
                "name": "P. Mercy"
              },
              {
                "authorId": "2102325551",
                "name": "Said Ramdane"
              }
            ]
          }
        },
        {
          "citedcorpusid": 57510553,
          "isinfluential": false,
          "contexts": [
            "Likforman-Sulem and Faure [19] proposed an approach based on perceptual grouping of connected components of black pixels."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Advances in Handwriting and Drawing: a multidisciplinary approach",
            "abstract": "",
            "year": 1994,
            "venue": "",
            "authors": [
              {
                "authorId": "38138508",
                "name": "C. Faure"
              },
              {
                "authorId": "3806481",
                "name": "P. Keuss"
              },
              {
                "authorId": "2915873",
                "name": "G. Lorette"
              },
              {
                "authorId": "2377682",
                "name": "A. Vinter"
              }
            ]
          }
        },
        {
          "citedcorpusid": 262766948,
          "isinfluential": false,
          "contexts": [
            "In any OCR system, preprocessing including scanning, image enhancement, skew estimation and correction, base line extraction are the primary steps that playan important role[2,3,7] in performance of a OCR system.",
            "The outcome is a binary image containing two levels of information, the foreground ridges and the background valleys[3, 7]."
          ],
          "intents": [
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Line and Word Segmentation Approach for Printed Documents",
            "abstract": "Line and word segmentation is one of the important step of OCR systems. In this paper we have proposed a robust method for segmentation of individual text lines based on the modified histogram obtained from run length based smearing. A complete line and word segmentation system for some popular Indian printed languages is presented here. Both foreground and background information are used here for accurate line segmentation. There may be some touching or overlapping characters between two consecutive text lines and most of the line segmentation errors are generated due to touching and overlapping character occurrences. Sometimes, interline space and noises make line segmentation a difficult task. Our method can take care of this situation accurately. Word segmentation from individual lines is also discussed here. We have tested our method on documents of Bangla, Devnagari, Kannada, Telugu scripts as well as some multi-script documents and we have obtained encouraging results from our proposed technique.",
            "year": 2010,
            "venue": "",
            "authors": [
              {
                "authorId": "2300212125",
                "name": "Nallapareddy Priyanka"
              },
              {
                "authorId": "1752887",
                "name": "S. Pal"
              },
              {
                "authorId": "2478791",
                "name": "Ranju Mandal"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "To represent an image, the radon function takes multiple, parallel-beam projections of the image from different angles by rotating the source around the center of the image [1, 5, 10]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "237563224": {
      "citing_paper_info": {
        "title": "Including Keyword Position in Image-based Models for Act Segmentation of Historical Registers",
        "abstract": "The segmentation of complex images into semantic regions has seen a growing interest these last years with the advent of Deep Learning. Until recently, most existing methods for Historical Document Analysis focused on the visual appearance of documents, ignoring the rich information that textual content can offer. However, the segmentation of complex documents into semantic regions is sometimes impossible relying only on visual features and recent models embed both visual and textual information. In this paper, we focus on the use of both visual and textual information for segmenting historical registers into structured and meaningful units such as acts. An act is a text recording containing valuable knowledge such as demographic information (baptism, marriage or death) or royal decisions (donation or pardon). We propose a simple pipeline to enrich document images with the position of text lines containing key-phrases and show that running a standard image-based layout analysis system on these images can lead to significant gains. Our experiments show that the detection of acts increases from 38 % of mAP to 74 % when adding textual information, in real use-case conditions where text lines positions and content are extracted with an automatic recognition system.",
        "year": 2021,
        "venue": "HIP@ICDAR",
        "authors": [
          {
            "authorId": "1380222130",
            "name": "Mélodie Boillet"
          },
          {
            "authorId": "1724401528",
            "name": "Martin Maarand"
          },
          {
            "authorId": "1690399",
            "name": "T. Paquet"
          },
          {
            "authorId": "2156685",
            "name": "Christopher Kermorvant"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 9,
        "unique_cited_count": 9,
        "influential_count": 4,
        "detailed_records_count": 9
      },
      "cited_papers": [
        "209515395",
        "25099654",
        "227220175",
        "9147779",
        "234641195",
        "178894636",
        "13749026",
        "2272015",
        "211026904"
      ],
      "citation_details": [
        {
          "citedcorpusid": 2272015,
          "isinfluential": true,
          "contexts": [
            "They use the same textual representation as in [19] but on tokens produced by an OCR process instead of sentences which is more realistic.",
            "[19] were amongst the first to propose a multi-modal Fully Convolutional Network for extracting semantic structures frommodern documents.",
            "Inspired by the idea proposed in [19] to incorporate the detected texts during the layout segmentation of modern documents, our work focuses on the use of both modalities at the input of a deep learning segmentation system to improve the act segmentation of historical documents."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Learning to Extract Semantic Structure from Documents Using Multimodal Fully Convolutional Neural Networks",
            "abstract": "We present an end-to-end, multimodal, fully convolutional network for extracting semantic structures from document images. We consider document semantic structure extraction as a pixel-wise segmentation task, and propose a unified model that classifies pixels based not only on their visual appearance, as in the traditional page segmentation task, but also on the content of underlying text. Moreover, we propose an efficient synthetic document generation process that we use to generate pretraining data for our network. Once the network is trained on a large set of synthetic documents, we fine-tune the network on unlabeled real documents using a semi-supervised approach. We systematically study the optimum network architecture and show that both our multimodal approach and the synthetic data pretraining significantly boost the performance.",
            "year": 2017,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2112096491",
                "name": "Xiao Yang"
              },
              {
                "authorId": "8020964",
                "name": "Ersin Yumer"
              },
              {
                "authorId": "2934421",
                "name": "P. Asente"
              },
              {
                "authorId": "1389971134",
                "name": "Mike Kraley"
              },
              {
                "authorId": "1852261",
                "name": "Daniel Kifer"
              },
              {
                "authorId": "145157784",
                "name": "C. Lee Giles"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9147779,
          "isinfluential": false,
          "contexts": [
            "For our experiments, we used two datasets, Balsac [15] andHimanisAct [4] and we trained a handwritten document recognition system for each of them."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Preparatory KWS Experiments for Large-Scale Indexing of a Vast Medieval Manuscript Collection in the HIMANIS Project",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "3387810",
                "name": "Théodore Bluche"
              },
              {
                "authorId": "2005661775",
                "name": "Sébastien Hamel"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "1794202",
                "name": "J. Puigcerver"
              },
              {
                "authorId": "2064656632",
                "name": "Dominique Stutzmann"
              },
              {
                "authorId": "52151344",
                "name": "A. Toselli"
              },
              {
                "authorId": "143783065",
                "name": "E. Vidal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13749026,
          "isinfluential": true,
          "contexts": [
            "1), Doc-UFCN trained with 4 input channels containing the raw image and the polygons mask (Image+TextMask) and finally Doc-UFCN and dhSegment [1] trained on the raw images with the polygons of the text lines drawn using two colors depending on the presence of a key-phrase (Image+KeyLines).",
            "Another text line segmentation system based on dhSegment [1] was also trained to provide a reference comparison with the proposed system.",
            "Even if additional challenges emerge with historical documents such as a low quality and degradation of the documents or a bad digitization process, current proposed systems have shown high performances for various tasks such as baseline detection [8], line segmentation [1] [5] [12] and more recently act segmentation [13] [14].",
            "They first detect the signatures of the priests located at the end of each act using a Ushaped neural network (dhSegment [1] or {LARU}-Net [8]) before using a rule-based system to generate the acts."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "dhSegment: A Generic Deep-Learning Approach for Document Segmentation",
            "abstract": "In recent years there have been multiple successful attempts tackling document processing problems separately by designing task specific hand-tuned strategies. We argue that the diversity of historical document processing tasks prohibits to solve them one at a time and shows a need for designing generic approaches in order to handle the variability of historical series. In this paper, we address multiple tasks simultaneously such as page extraction, baseline extraction, layout analysis or multiple typologies of illustrations and photograph extraction. We propose an open-source implementation of a CNN-based pixel-wise predictor coupled with task dependent post-processing blocks. We show that a single CNN-architecture can be used across tasks with competitive results. Moreover most of the task-specific post-precessing steps can be decomposed in a small number of simple and standard reusable operations, adding to the flexibility of our approach.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2066810458",
                "name": "S. Oliveira"
              },
              {
                "authorId": "2060245962",
                "name": "Benoit Seguin"
              },
              {
                "authorId": "143791091",
                "name": "F. Kaplan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 25099654,
          "isinfluential": true,
          "contexts": [
            "The Transkribus training interface provides an evaluation for CER only and can not be directly compared to ours since the train/dev/test splits are not identical but results are in the same range.",
            "For comparison, a HTR+ model was trained using the standard Transkribus service [11].",
            "The evaluation is done using the Transkribus Baseline Evaluation Scheme (TBES) [7].",
            "The annotated Himanis-GMV dataset is composed of 1,435 pages extracted from the Himanis dataset, automatically aligned at line level from printed editions [9, 10, 16] with Transkribus [11].",
            "Transkribus model shows higher CER on the training set due to the data augmentation process."
          ],
          "intents": [
            "--",
            "['methodology']",
            "--",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Transkribus - A Service Platform for Transcription, Recognition and Retrieval of Historical Documents",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "37197949",
                "name": "Philip Kahle"
              },
              {
                "authorId": "2180200",
                "name": "S. Colutto"
              },
              {
                "authorId": "3087076",
                "name": "Günter Hackl"
              },
              {
                "authorId": "32708042",
                "name": "Günter Mühlberger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 178894636,
          "isinfluential": false,
          "contexts": [
            "The annotated Himanis-GMV dataset is composed of 1,435 pages extracted from the Himanis dataset, automatically aligned at line level from printed editions [9, 10, 16] with Transkribus [11]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Olivier Guyotjeannin et Serge Lusignan (éds), Le Formulaire d’Odart Morchesne dans la version du ms. BnF fr. 5024",
            "abstract": "Des formulaires de la chancellerie royale, celui d’Odart Morchesne est le plus connu et celui qui a eu le plus d’influence sur les autres formulaires jusqu’au debut du XVIe siecle. Il n’est cependant pas le premier, Jean de Caux en avait redige un, perdu, en 1286, qui renfermait environ 550 formules et Odart a utilise quelques autres formulaires anterieurs. Son œuvre est cependant originale et, parmi les formulaires de la chancellerie, c’est evidemment celui qu’il fallait editer. Odart Morcha...",
            "year": 2008,
            "venue": "",
            "authors": [
              {
                "authorId": "104504395",
                "name": "G. Giordanengo"
              }
            ]
          }
        },
        {
          "citedcorpusid": 209515395,
          "isinfluential": false,
          "contexts": [
            "As a future work, we will compare this approach to pre-trained models recently proposed for taking into account both the textual content and its layout [18]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "LayoutLM: Pre-training of Text and Layout for Document Image Understanding",
            "abstract": "Pre-training techniques have been verified successfully in a variety of NLP tasks in recent years. Despite the widespread use of pre-training models for NLP applications, they almost exclusively focus on text-level manipulation, while neglecting layout and style information that is vital for document image understanding. In this paper, we propose the LayoutLM to jointly model interactions between text and layout information across scanned document images, which is beneficial for a great number of real-world document image understanding tasks such as information extraction from scanned documents. Furthermore, we also leverage image features to incorporate words' visual information into LayoutLM. To the best of our knowledge, this is the first time that text and layout are jointly learned in a single framework for document-level pre-training. It achieves new state-of-the-art results in several downstream tasks, including form understanding (from 70.72 to 79.27), receipt understanding (from 94.02 to 95.24) and document image classification (from 93.07 to 94.42). The code and pre-trained LayoutLM models are publicly available at https://aka.ms/layoutlm.",
            "year": 2019,
            "venue": "Knowledge Discovery and Data Mining",
            "authors": [
              {
                "authorId": "3032611",
                "name": "Yiheng Xu"
              },
              {
                "authorId": "123545597",
                "name": "Minghao Li"
              },
              {
                "authorId": "145500855",
                "name": "Lei Cui"
              },
              {
                "authorId": "3110003",
                "name": "Shaohan Huang"
              },
              {
                "authorId": "49807919",
                "name": "Furu Wei"
              },
              {
                "authorId": "92660691",
                "name": "Ming Zhou"
              }
            ]
          }
        },
        {
          "citedcorpusid": 211026904,
          "isinfluential": false,
          "contexts": [
            "Even if additional challenges emerge with historical documents such as a low quality and degradation of the documents or a bad digitization process, current proposed systems have shown high performances for various tasks such as baseline detection [8], line segmentation [1] [5] [12] and more recently act segmentation [13] [14]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation in Historical Document Images Using an Adaptive U-Net Architecture",
            "abstract": "On most document image transcription, indexing and retrieval systems, text line segmentation remains one of the most important preliminary task. Hence, the research community working in document image analysis is particularly interested in providing reliable text line segmentation methods. Recently, an increasing interest in using deep learning-based methods has been noted for solving various sub-fields and tasks related to the issues surrounding document image analysis. Thanks to the computer hardware and software evolution, several methods based on using deep architectures continue to outperform the pattern recognition issues and particularly those related to historical document image analysis. Thus, in this paper we present a novel deep learning-based method for text line segmentation of historical documents. The proposed method is based on using an adaptive U-Net architecture. Qualitative and numerical experiments are given using a large number of historical document images collected from the Tunisian national archives and different recent benchmarking datasets provided in the context of ICDAR and ICFHR competitions. Moreover, the results achieved are compared with those obtained using the state-of-the-art methods.",
            "year": 2019,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "51133427",
                "name": "Olfa Mechi"
              },
              {
                "authorId": "2131158",
                "name": "Maroua Mehri"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              },
              {
                "authorId": "2536574",
                "name": "N. Amara"
              }
            ]
          }
        },
        {
          "citedcorpusid": 227220175,
          "isinfluential": true,
          "contexts": [
            "Indeed, when compared to the visual system of [13], our method outperforms it by up to 10 percentage points.",
            "The annotated Himanis-Act dataset [13] consists in a sample of 739 pages from the Himanis dataset, annotated at act level.",
            "To run our experiments, we used the split proposed in [13] obtained after eliminating pages containing no information such as blank pages so as to be comparable to their results.",
            "In addition to these experiments, we compared our results with the state-of-the-art ones of [13].",
            "[13] also studied the case where the graphical appearance of the images is not sufficient to segment medieval charters into acts.",
            "Even if additional challenges emerge with historical documents such as a low quality and degradation of the documents or a bad digitization process, current proposed systems have shown high performances for various tasks such as baseline detection [8], line segmentation [1] [5] [12] and more recently act segmentation [13] [14]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['methodology']",
            "['result']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Content Based Layout Analysis",
            "abstract": "State-of-the-art Document Layout Analysis methods rely on graphical appearance features in order to detect and classify the different layout regions present in a scanned text image. In many cases, however, performing this task using only graphical information is problematic or impossible. Only by actually reading some text in the boundaries of the problematic regions it becomes possible to reliably detect and separate these regions. In these situations, textual, content-based features would be required, but since transcription is usually performed after layout analysis, a vicious circle arises. In this work, we circumvent this deadlock by making use of the recently introduced concept of Probabilistic Index Map. We use the word relevance probabilities provided by this map to calculate relevant text content based features at the pixel level. We assess the impact of these new features on a historical document complex paragraph classification task. The experiments are performed using both a classical Hidden Markov Model approach and Deep Neural Networks. The obtained results are encouraging and showcase the positive impact text content based features will have on the Document Layout Analysis research field.",
            "year": 2020,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2029290748",
                "name": "J. R. Prieto"
              },
              {
                "authorId": "3277118",
                "name": "Vicente Bosch"
              },
              {
                "authorId": "143783065",
                "name": "E. Vidal"
              },
              {
                "authorId": "2064656632",
                "name": "Dominique Stutzmann"
              },
              {
                "authorId": "2005661775",
                "name": "Sébastien Hamel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 234641195,
          "isinfluential": false,
          "contexts": [
            "For our experiments, we used two datasets, Balsac [15] andHimanisAct [4] and we trained a handwritten document recognition system for each of them."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An Overview of the BALSAC Population Database. Past Developments, Current State and Future Prospects",
            "abstract": "The BALSAC database, developed since 1971, contains data on the Quebec population from the beginnings of European settlement in the 17th century to the contemporary period. Today, BALSAC is a major research infrastructure used by researchers from Quebec and elsewhere, both in the social sciences and in the biomedical sciences. This paper presents the evolution and current state of the database and offers a perspective on forthcoming developments. BALSAC contains marriage certificates until 1965. Coverage is complete for Catholic records (80 to 100% of the population depending on the region and the period) and partial for the other denominations. Birth and death certificates from all Catholic parishes have been integrated for the period 1800–1849 and work in underway for 1850–1916. All the records entered in BALSAC are subject to a linkage process which, ultimately, allows the automatic reconstitution of genealogical links and family relationships. The basic principle has remained the same since the beginning, namely to match individuals based on the nominative information contained in the sources. The changes made in recent years and the resulting gains are mostly related to IT advances which now offer more flexibility and increased performance. Future perspectives rest on the diversification of the sources of population data entered or connected to the database and, as a corollary, by continuous optimization of data processing and linkage procedures. In the era of 'big data', BALSAC is gradually moving from a historical population database to a multifaceted infrastructure for interdisciplinary research on the Quebec population.",
            "year": 2020,
            "venue": "",
            "authors": [
              {
                "authorId": "3115011",
                "name": "H. Vézina"
              },
              {
                "authorId": "117993253",
                "name": "Jean-Sébastien Bournival"
              }
            ]
          }
        }
      ]
    },
    "6069782": {
      "citing_paper_info": {
        "title": "Joint Line Segmentation and Transcription for End-to-End Handwritten Paragraph Recognition",
        "abstract": "Offline handwriting recognition systems require cropped text line images for both training and recognition. On the one hand, the annotation of position and transcript at line level is costly to obtain. On the other hand, automatic line segmentation algorithms are prone to errors, compromising the subsequent recognition. In this paper, we propose a modification of the popular and efficient multi-dimensional long short-term memory recurrent neural networks (MDLSTM-RNNs) to enable end-to-end processing of handwritten paragraphs. More particularly, we replace the collapse layer transforming the two-dimensional representation into a sequence of predictions by a recurrent version which can recognize one line at a time. In the proposed model, a neural network performs a kind of implicit line segmentation by computing attention weights on the image representation. The experiments on paragraphs of Rimes and IAM database yield results that are competitive with those of networks trained at line level, and constitute a significant step towards end-to-end transcription of full documents.",
        "year": 2016,
        "venue": "Neural Information Processing Systems",
        "authors": [
          {
            "authorId": "3387810",
            "name": "Théodore Bluche"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 25,
        "unique_cited_count": 25,
        "influential_count": 1,
        "detailed_records_count": 25
      },
      "cited_papers": [
        "14521054",
        "7398247",
        "1697424",
        "15955585",
        "15011847",
        "18720327",
        "6939865",
        "29622813",
        "12217430",
        "3179635",
        "8468286",
        "14196680",
        "14136313",
        "7680181",
        "619938",
        "1913486",
        "9919769",
        "11518",
        "453615",
        "1055111",
        "8608310",
        "196116247",
        "39171119",
        "15034932",
        "1889158"
      ],
      "citation_details": [
        {
          "citedcorpusid": 11518,
          "isinfluential": false,
          "contexts": [
            "All the information in the vertical dimension is reduced to a single vector, regardless of its position in the feature maps, preventing the recognition of multiple lines within this framwork."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "text Detection with Convolutional Neural Networks",
            "abstract": "Text detection is an important preliminary step before text can be recognized in unconstrained image environments. We present an approach based on convolutional neural networks to detect and localize horizontal text lines from raw color pixels. The network learns to extract and combine its own set of features through learning instead of using hand-crafted ones. Learning was also used in order to precisely localize the text lines by simply training the network to reject badly-cut text and without any use of tedious knowledge-based postprocessing. Although the network was trained with synthetic examples, experimental results demonstrated that it can outperform other methods on the real-world test set of ICDAR’03.",
            "year": 2008,
            "venue": "International Conference on Computer Vision Theory and Applications",
            "authors": [
              {
                "authorId": "1812064",
                "name": "M. Delakis"
              },
              {
                "authorId": "144723337",
                "name": "Christophe Garcia"
              }
            ]
          }
        },
        {
          "citedcorpusid": 453615,
          "isinfluential": false,
          "contexts": [
            "This paradigm, already suggested by Fukushima in 1987 [19], was successfully applied to various problems such as machine translation [3], image caption generation [13, 51], speech recognition [11, 14, 15], or cropped words in scene text [30].",
            "We propose a model for multi-line recognition based on the popular MDLSTM-RNNs, augmented with an attention mechanism inspired from the recent models for machine translation [3], image caption generation [13, 51], or speech recognition [11, 14, 15]."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "End-to-end Continuous Speech Recognition using Attention-based Recurrent NN: First Results",
            "abstract": "We replace the Hidden Markov Model (HMM) which is traditionally used in in continuous speech recognition with a bi-directional recurrent neural network encoder coupled to a recurrent neural network decoder that directly emits a stream of phonemes. The alignment between the input and output sequences is established using an attention mechanism: the decoder emits each symbol based on a context created with a subset of input symbols elected by the attention mechanism. We report initial results demonstrating that this new approach achieves phoneme error rates that are comparable to the state-of-the-art HMM-based decoders, on the TIMIT dataset.",
            "year": 2014,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "2292403",
                "name": "J. Chorowski"
              },
              {
                "authorId": "3335364",
                "name": "Dzmitry Bahdanau"
              },
              {
                "authorId": "1979489",
                "name": "Kyunghyun Cho"
              },
              {
                "authorId": "1751762",
                "name": "Yoshua Bengio"
              }
            ]
          }
        },
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "surveys state that it is a crucial step for handwriting text recognition systems [8, 28]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1055111,
          "isinfluential": false,
          "contexts": [
            "This paradigm, already suggested by Fukushima in 1987 [19], was successfully applied to various problems such as machine translation [3], image caption generation [13, 51], speech recognition [11, 14, 15], or cropped words in scene text [30].",
            "All the information in the vertical dimension is reduced to a single vector, regardless of its position in the feature maps, preventing the recognition of multiple lines within this framwork.",
            "We propose a model for multi-line recognition based on the popular MDLSTM-RNNs, augmented with an attention mechanism inspired from the recent models for machine translation [3], image caption generation [13, 51], or speech recognition [11, 14, 15]."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",
            "abstract": "Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr9k, Flickr30k and MS COCO.",
            "year": 2015,
            "venue": "International Conference on Machine Learning",
            "authors": [
              {
                "authorId": "2117101253",
                "name": "Ke Xu"
              },
              {
                "authorId": "2503659",
                "name": "Jimmy Ba"
              },
              {
                "authorId": "3450996",
                "name": "Ryan Kiros"
              },
              {
                "authorId": "1979489",
                "name": "Kyunghyun Cho"
              },
              {
                "authorId": "1760871",
                "name": "Aaron C. Courville"
              },
              {
                "authorId": "145124475",
                "name": "R. Salakhutdinov"
              },
              {
                "authorId": "1804104",
                "name": "R. Zemel"
              },
              {
                "authorId": "1751762",
                "name": "Yoshua Bengio"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1697424,
          "isinfluential": false,
          "contexts": [
            "a few digits with DRAW [20] or RAM [2], or short online handwritten sequences [19])."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Generating Sequences With Recurrent Neural Networks",
            "abstract": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.",
            "year": 2013,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "1753223",
                "name": "Alex Graves"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1889158,
          "isinfluential": false,
          "contexts": [
            "The advantages over the neural networks trained for line segmentation [13, 24, 32, 31] are that (i) it works on the same features as those used for the transcription (multi-task encoder) and (ii) it is trained to maximize the transcription accuracy (i.",
            "However, some methods were devised using statistical models and machine learning techniques such as hidden Markov models [8], conditional random fields [21], or neural networks [24, 31, 32]."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Paragraph text segmentation into lines with Recurrent Neural Networks",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "144899680",
                "name": "Christian Wolf"
              },
              {
                "authorId": "2373952",
                "name": "J. Louradour"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1913486,
          "isinfluential": false,
          "contexts": [
            "Classical text line segmentation algorithms are mostly based on image processing techniques and heuristics [32, 37, 38, 40, 42, 45, 53]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 3179635,
          "isinfluential": false,
          "contexts": [
            "Some examples are the sliding window approach [25], in which features are extracted from vertical frames of the line image, or space-displacement neural networks [4]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "LeRec: A NN/HMM Hybrid for On-Line Handwriting Recognition",
            "abstract": "",
            "year": 1995,
            "venue": "Neural Computation",
            "authors": [
              {
                "authorId": "1751762",
                "name": "Yoshua Bengio"
              },
              {
                "authorId": "1688882",
                "name": "Yann LeCun"
              },
              {
                "authorId": "2975061",
                "name": "C. Nohl"
              },
              {
                "authorId": "2676309",
                "name": "C. Burges"
              }
            ]
          }
        },
        {
          "citedcorpusid": 6939865,
          "isinfluential": false,
          "contexts": [
            "The advantages over the neural networks trained for line segmentation [13, 24, 32, 31] are that (i) it works on the same features as those used for the transcription (multi-task encoder) and (ii) it is trained to maximize the transcription accuracy (i.",
            "However, some methods were devised using statistical models and machine learning techniques such as hidden Markov models [8], conditional random fields [21], or neural networks [24, 31, 32]."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Space Displacement Localization Neural Networks to locate origin points of handwritten text lines in historical documents",
            "abstract": "",
            "year": 2015,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "3344452",
                "name": "Bastien Moysset"
              },
              {
                "authorId": "2060115898",
                "name": "P. Adam"
              },
              {
                "authorId": "144899680",
                "name": "Christian Wolf"
              },
              {
                "authorId": "2373952",
                "name": "J. Louradour"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7398247,
          "isinfluential": false,
          "contexts": [
            "[14, 26, 30] used a hybrid character/word language model to tackle the issue of out-of-vocabulary words."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Fast and Robust Training of Recurrent Neural Networks for Offline Handwriting Recognition",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "145460901",
                "name": "P. Doetsch"
              },
              {
                "authorId": "2250860",
                "name": "M. Kozielski"
              },
              {
                "authorId": "145322333",
                "name": "H. Ney"
              }
            ]
          }
        },
        {
          "citedcorpusid": 7680181,
          "isinfluential": false,
          "contexts": [
            "We recently proposed an attention-based model to transcribe full paragraphs of handwritten text, which predicts each character in turn [6]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Recurrent Spatial Transformer Networks",
            "abstract": "We integrate the recently proposed spatial transformer network (SPN) [Jaderberg et. al 2015] into a recurrent neural network (RNN) to form an RNN-SPN model. We use the RNN-SPN to classify digits in cluttered MNIST sequences. The proposed model achieves a single digit error of 1.5% compared to 2.9% for a convolutional networks and 2.0% for convolutional networks with SPN layers. The SPN outputs a zoomed, rotated and skewed version of the input image. We investigate different down-sampling factors (ratio of pixel in input and output) for the SPN and show that the RNN-SPN model is able to down-sample the input images without deteriorating performance. The down-sampling in RNN-SPN can be thought of as adaptive down-sampling that minimizes the information loss in the regions of interest. We attribute the superior performance of the RNN-SPN to the fact that it can attend to a sequence of regions of interest.",
            "year": 2015,
            "venue": "arXiv.org",
            "authors": [
              {
                "authorId": "1388358166",
                "name": "Søren Kaae Sønderby"
              },
              {
                "authorId": "1402816540",
                "name": "C. Sønderby"
              },
              {
                "authorId": "7435149",
                "name": "Lars Maaløe"
              },
              {
                "authorId": "1724252",
                "name": "O. Winther"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8468286,
          "isinfluential": false,
          "contexts": [
            " into characters. Early methods tried to compute segmentation hypotheses for characters, for example by performing an heuristic over-segmentation, followed by a scoring of groups of segments (e.g. in [4, 28]). In the nineties, this kind of approach was progressively replaced by segmentation-free methods, where a whole word image is fed to a system providing a sequence of scores. A lexicon constrains a de"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Hidden Markov Model Based Word Recognition and Its Application to Legal Amount Reading on French Checks",
            "abstract": "A hidden Markov model (HMM) based word recognition algorithm for the recognition of legal amounts from French bank checks is presented. This algorithm is part of the A2iA INTERCHEQUE recognition system. The algorithm starts from images of handwritten words which have been automatically segmented from binary check images. After finding the lower-case zone on the complete amount, words are slant corrected and then segmented into graphemes. Then, features are extracted from the graphemes, and the feature vectors are vector quantized resulting in a sequence of symbols for each word. Likelihoods of all word classes are computed by a set of HMMs, which have been previously trained using either the Viterbi algorithm or the Baum?Welch algorithm. The various parameters of the system have been identified and their importance evaluated. Results have been obtained on large real-life data bases of French handwritten checks. The HMM-based system has been shown to outperform a holistic word recognizer and another HMM-type word recognizer from the A2iA INTERCHEQUE recognition system. Word recognition rates of about 89% for the 26-word vocabulary relevant for legal amount recognition on French bank checks have been obtained. More recently, a Neural Network?HMM hybrid has been designed, which produces even better recognition rates.",
            "year": 1998,
            "venue": "Computer Vision and Image Understanding",
            "authors": [
              {
                "authorId": "15058655",
                "name": "S. Knerr"
              },
              {
                "authorId": "39933279",
                "name": "E. Augustin"
              },
              {
                "authorId": "2953853",
                "name": "O. Baret"
              },
              {
                "authorId": "2085271779",
                "name": "David Price"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8608310,
          "isinfluential": false,
          "contexts": [
            "This paradigm, already suggested by Fukushima in 1987 [15], was successfully applied to various problems such as machine translation [3], image caption generation [38], speech recognition [11, 12], or cropped words in scene text [27]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Recursive Recurrent Nets with Attention Modeling for OCR in the Wild",
            "abstract": "We present recursive recurrent neural networks with attention modeling (R2AM) for lexicon-free optical character recognition in natural scene images. The primary advantages of the proposed method are: (1) use of recursive convolutional neural networks (CNNs), which allow for parametrically efficient and effective image feature extraction, (2) an implicitly learned character-level language model, embodied in a recurrent neural network which avoids the need to use N-grams, and (3) the use of a soft-attention mechanism, allowing the model to selectively exploit image features in a coordinated way, and allowing for end-to-end training within a standard backpropagation framework. We validate our method with state-of-the-art performance on challenging benchmark datasets: Street View Text, IIIT5k, ICDAR and Synth90k.",
            "year": 2016,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "50521003",
                "name": "Chen-Yu Lee"
              },
              {
                "authorId": "2217144",
                "name": "Simon Osindero"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9919769,
          "isinfluential": true,
          "contexts": [
            "The system for 300 dpi images is comparable to the best single system [33] in WER% with a significantly better CER%.",
            "Dropout is applied after each LSTM layer [33].",
            "Moreover, all systems except [30, 33] carefully pre-processed the line image (e."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Dropout Improves Recurrent Neural Networks for Handwriting Recognition",
            "abstract": "Recurrent neural networks (RNNs) with Long Short-Term memory cells currently hold the best known results in unconstrained handwriting recognition. We show that their performance can be greatly improved using dropout - a recently proposed regularization method for deep architectures. While previous works showed that dropout gave superior performance in the context of convolutional networks, it had never been applied to RNNs. In our approach, dropout is carefully used in the network so that it does not affect the recurrent connections, hence the power of RNNs in modeling sequences is preserved. Extensive experiments on a broad range of handwritten databases confirm the effectiveness of dropout on deep architectures even when the network mainly consists of recurrent and shared connections.",
            "year": 2013,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "50506272",
                "name": "Vu Pham"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              },
              {
                "authorId": "2373952",
                "name": "J. Louradour"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12217430,
          "isinfluential": false,
          "contexts": [
            "Although the segmentation of documents into lines is assumed in most descriptions of handwriting recognition systems, several papers or surveys state that it is a crucial step for handwriting text recognition systems [8, 31, 41]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Off-line Handwriting Text Line Segmentation : A Review",
            "abstract": "Summary Text line segmentation is an essential pre-processing stage for off-line handwriting recognition in many Optical Character Recognition (OCR) systems. It is an important step because inaccurately segmented text lines will cause errors in the recognition stage. Text line segmentation of the handwritten documents is still one of the most complicated problems in developing a reliable OCR. The nature of handwriting makes the process of text line segmentation very challenging. Several techniques to segment handwriting text line have been proposed in the past. This paper seeks to provide a comprehensive review of the methods of off-line handwriting text line segmentation proposed by researchers.",
            "year": 2008,
            "venue": "",
            "authors": [
              {
                "authorId": "34325231",
                "name": "N. M. Noor"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14136313,
          "isinfluential": false,
          "contexts": [
            "n closest to our problem, most systems still rely on a two-step process (localization, then recognition) [52], even though some approaches jointly optimize character segmentation and word recognition [12, 49, 50]. Recently, many “attention-based” models were proposed to iteratively select in an encoded signal the relevant parts to make the next prediction. This paradigm, already suggested by Fukushima in 1987"
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "End-to-end scene text recognition",
            "abstract": "This paper focuses on the problem of word detection and recognition in natural images. The problem is significantly more challenging than reading text in scanned documents, and has only recently gained attention from the computer vision community. Sub-components of the problem, such as text detection and cropped image word recognition, have been studied in isolation [7, 4, 20]. However, what is unclear is how these recent approaches contribute to solving the end-to-end problem of word recognition. We fill this gap by constructing and evaluating two systems. The first, representing the de facto state-of-the-art, is a two stage pipeline consisting of text detection followed by a leading OCR engine. The second is a system rooted in generic object recognition, an extension of our previous work in [20]. We show that the latter approach achieves superior performance. While scene text recognition has generally been treated with highly domain-specific methods, our results demonstrate the suitability of applying generic computer vision methods. Adopting this approach opens the door for real world scene text recognition to benefit from the rapid advances that have been taking place in object recognition.",
            "year": 2011,
            "venue": "Vision",
            "authors": [
              {
                "authorId": "2148896777",
                "name": "Kai Wang"
              },
              {
                "authorId": "2490700",
                "name": "Boris Babenko"
              },
              {
                "authorId": "50172592",
                "name": "Serge J. Belongie"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14196680,
          "isinfluential": false,
          "contexts": [
            "atively performs an implicit line segmentation at the level of intermediate representations. Classical text line segmentation algorithms are mostly based on image processing techniques and heuristics [32, 37, 38, 40, 42, 45, 53]. However, some methods were devised using statistical models and machine learing techniques such as hidden Markov models [8], conditional random ﬁelds [24], or neural networks [16, 26, 35, 36]. In ou"
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text line and word segmentation of handwritten documents",
            "abstract": "",
            "year": 2009,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "1759370",
                "name": "C. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14521054,
          "isinfluential": false,
          "contexts": [
            "In a sense, our model is quite related to the DenseCap model for image captioning [23], itself similar to STNs."
          ],
          "intents": [
            "['result']"
          ],
          "cited_paper_info": {
            "title": "DenseCap: Fully Convolutional Localization Networks for Dense Captioning",
            "abstract": "We introduce the dense captioning task, which requires a computer vision system to both localize and describe salient regions in images in natural language. The dense captioning task generalizes object detection when the descriptions consist of a single word, and Image Captioning when one predicted region covers the full image. To address the localization and description task jointly we propose a Fully Convolutional Localization Network (FCLN) architecture that processes an image with a single, efficient forward pass, requires no external regions proposals, and can be trained end-to-end with a single round of optimization. The architecture is composed of a Convolutional Network, a novel dense localization layer, and Recurrent Neural Network language model that generates the label sequences. We evaluate our network on the Visual Genome dataset, which comprises 94,000 images and 4,100,000 region-grounded captions. We observe both speed and accuracy improvements over baselines based on current state of the art approaches in both generation and retrieval settings.",
            "year": 2015,
            "venue": "Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "2115231104",
                "name": "Justin Johnson"
              },
              {
                "authorId": "2354728",
                "name": "A. Karpathy"
              },
              {
                "authorId": "48004138",
                "name": "Li Fei-Fei"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15011847,
          "isinfluential": false,
          "contexts": [
            "n closest to our problem, most systems still rely on a two-step process (localization, then recognition) [52], even though some approaches jointly optimize character segmentation and word recognition [12, 49, 50]. Recently, many “attention-based” models were proposed to iteratively select in an encoded signal the relevant parts to make the next prediction. This paradigm, already suggested by Fukushima in 1987"
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Toward Integrated Scene Text Reading",
            "abstract": "",
            "year": 2014,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "2862313",
                "name": "Jerod J. Weinman"
              },
              {
                "authorId": "2919402",
                "name": "Zachary Butler"
              },
              {
                "authorId": "40257969",
                "name": "Dugan Knoll"
              },
              {
                "authorId": "36389113",
                "name": "Jacqueline L. Feild"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15034932,
          "isinfluential": false,
          "contexts": [
            "The advantages over the neural networks trained for line segmentation [13, 24, 32, 31] are that (i) it works on the same features as those used for the transcription (multi-task encoder) and (ii) it is trained to maximize the transcription accuracy (i.",
            "However, some methods were devised using statistical models and machine learning techniques such as hidden Markov models [8], conditional random fields [21], or neural networks [24, 31, 32]."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Neural network-based text location in color images",
            "abstract": "",
            "year": 2001,
            "venue": "Pattern Recognition Letters",
            "authors": [
              {
                "authorId": "121267347",
                "name": "K. Jung"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15955585,
          "isinfluential": false,
          "contexts": [
            "Moreover, all systems except [30, 33] carefully pre-processed the line image (e.",
            "[14, 26, 30] used a hybrid character/word language model to tackle the issue of out-of-vocabulary words."
          ],
          "intents": [
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Over-Generative Finite State Transducer N-Gram for Out-of-Vocabulary Word Recognition",
            "abstract": "",
            "year": 2014,
            "venue": "2014 11th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "3480666",
                "name": "Ronaldo O. Messina"
              },
              {
                "authorId": "2156685",
                "name": "Christopher Kermorvant"
              }
            ]
          }
        },
        {
          "citedcorpusid": 18720327,
          "isinfluential": false,
          "contexts": [
            "Classical text line segmentation algorithms are mostly based on image processing techniques and heuristics [32, 37, 38, 40, 42, 45, 53]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Text Line Detection in Corrupted and Damaged Historical Manuscripts",
            "abstract": "",
            "year": 2013,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2578300",
                "name": "Irina Rabaev"
              },
              {
                "authorId": "2339207",
                "name": "Ofer Biller"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              },
              {
                "authorId": "1939225",
                "name": "K. Kedem"
              },
              {
                "authorId": "1686153",
                "name": "I. Dinstein"
              }
            ]
          }
        },
        {
          "citedcorpusid": 29622813,
          "isinfluential": false,
          "contexts": [
            "The IAM database [29] is made of handwritten English texts copied from the LOB corpus."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "The IAM-database: an English sentence database for offline handwriting recognition",
            "abstract": "",
            "year": 2002,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "37526757",
                "name": "Urs-Viktor Marti"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              }
            ]
          }
        },
        {
          "citedcorpusid": 39171119,
          "isinfluential": false,
          "contexts": [
            "These models have become very popular and won the recent evaluations of handwriting recognition [9, 34, 37]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "The Maurdor Project: Improving Automatic Processing of Digital Documents",
            "abstract": "",
            "year": 2014,
            "venue": "2014 11th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "1990445",
                "name": "S. Brunessaux"
              },
              {
                "authorId": "2102383646",
                "name": "Patrick Giroux"
              },
              {
                "authorId": "1809808",
                "name": "B. Grilhères"
              },
              {
                "authorId": "49586578",
                "name": "M. Manta"
              },
              {
                "authorId": "28476916",
                "name": "Maylis Bodin"
              },
              {
                "authorId": "1678451",
                "name": "K. Choukri"
              },
              {
                "authorId": "1701385",
                "name": "Olivier Galibert"
              },
              {
                "authorId": "35798452",
                "name": "Juliette Kahn"
              }
            ]
          }
        },
        {
          "citedcorpusid": 196116247,
          "isinfluential": false,
          "contexts": [
            "For scene text recognition, which is maybe the topic in computer vision closest to our problem, most systems still rely on a two-step process (localization, then recognition) [52], even though some approaches jointly optimize character segmentation and word recognition [12, 49, 50]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Image and Graphics : 8th International Conference, ICIG 2015, Tianjin, China, August 13-16, 2015, Proceedings, Part II",
            "abstract": "This book constitutes the refereed conference proceedings of the 8th International Conference on Image and Graphics, ICIG 2015 held in Tianjin, China, in August 2015. The 164 revised full papers and 6 special issue papers were carefully reviewed and selected from 339 submissions. The papers focus on various advances of theory, techniques and algorithms in the fields of images and graphics",
            "year": 2015,
            "venue": "",
            "authors": [
              {
                "authorId": "1591128560",
                "name": "Yujin Zhang"
              }
            ]
          }
        }
      ]
    },
    "274180357": {
      "citing_paper_info": {
        "title": "Arabic Handwritten Document OCR Solution with Binarization and Adaptive Scale Fusion Detection",
        "abstract": "The problem of converting images of text into plain text is a widely researched topic in both academia and industry. Arabic handwritten Text Recognation (AHTR) poses additional challenges due to diverse handwriting styles and limited labeled data. In this paper we present a complete OCR pipeline that starts with line segmentation using Differentiable Binarization and Adaptive Scale Fusion techniques to ensure accurate detection of text lines. Following segmentation, a CNN-BiLSTM-CTC architecture is applied to recognize characters. Our system, trained on the Arabic Multi-Fonts Dataset (AMFDS), achieves a Character Recognition Rate (CRR) of 99.20% and a Word Recognition Rate (WRR) of 93.75% on single-word samples containing 7 to 10 characters, along with a CRR of 83.76% for sentences. These results demonstrate the system's strong performance in handling Arabic scripts, establishing a new benchmark for AHTR systems.",
        "year": 2024,
        "venue": "Novel Intelligent and Leading Emerging Sciences Conference",
        "authors": [
          {
            "authorId": "2331737221",
            "name": "Alhossien Waly"
          },
          {
            "authorId": "2331739458",
            "name": "Bassant Tarek"
          },
          {
            "authorId": "2331737434",
            "name": "Ali Feteha"
          },
          {
            "authorId": "2331759015",
            "name": "Rewan Yehia"
          },
          {
            "authorId": "2331740107",
            "name": "Gasser Amr"
          },
          {
            "authorId": "2331759023",
            "name": "Ahmed Fares"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 8,
        "unique_cited_count": 6,
        "influential_count": 4,
        "detailed_records_count": 8
      },
      "cited_papers": [
        "260432782",
        "17533066",
        "11412987",
        "206591895",
        "15106190",
        "14635907"
      ],
      "citation_details": [
        {
          "citedcorpusid": 11412987,
          "isinfluential": true,
          "contexts": [
            "Ahmad et al. [7] made a notable advancement by applying a CNN-BLSTM-CTC model to the KHATT dataset, achieving a Character Recognition Rate (CRR) of 80.02%."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Improvements in Sub-character HMM Model Based Arabic Text Recognition",
            "abstract": "",
            "year": 2014,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "151503424",
                "name": "Irfan Ahmad"
              },
              {
                "authorId": "1749475",
                "name": "G. Fink"
              },
              {
                "authorId": "35063144",
                "name": "S. Mahmoud"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14635907,
          "isinfluential": false,
          "contexts": [
            "Recent progress in deep learning the work of Graves et al. [3] presents the CNN-BLSTM-CTC model now much more increases state-of-the-art accuracy for sequence modeling and recognition in complex scripts, such as Arabic.",
            "A significant breakthrough came with the work of Graves et al. [3], who introduced the CNN-BLSTM-CTC architecture."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "A Novel Connectionist System for Unconstrained Handwriting Recognition",
            "abstract": "",
            "year": 2009,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1753223",
                "name": "Alex Graves"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "143913738",
                "name": "Santiago Fernández"
              },
              {
                "authorId": "2168488",
                "name": "Roman Bertolami"
              },
              {
                "authorId": "1720945",
                "name": "H. Bunke"
              },
              {
                "authorId": "145341374",
                "name": "J. Schmidhuber"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15106190,
          "isinfluential": true,
          "contexts": [
            "Similarly, Elzobi et al. [2] utilized Gabor filter-based feature extraction coupled with Support Vector Machine classification, obtaining a 94.3% character recognition performance on the IFN/ENIT dataset [6]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "IFN/ENIT: database of handwritten arabic words",
            "abstract": "Dans cet article on presente une nouvelle base de donnees, qui contient des noms manuscrits de villes/villages arabes. Pour chaque nom les informations de base, par exemple l'ordre des formes de caractere, les informations sur le style de l'ecriture et la ligne de base, sont codees. 411 auteurs ont rempli des formulaires avec plus de 26400 noms contenant plus de 210 000 caracteres. La base de donnees est decrite en detail, et elle est concue pour la formation et l'essai des systemes d'identification pour les mots arabes manuscrits. La base de donnees IFA/ENIT est disponible pour la recherche.",
            "year": 2002,
            "venue": "",
            "authors": [
              {
                "authorId": "1683324",
                "name": "M. Pechwitz"
              },
              {
                "authorId": "1681421",
                "name": "Samia Maddouri"
              },
              {
                "authorId": "1774130",
                "name": "V. Märgner"
              },
              {
                "authorId": "1683433",
                "name": "N. Ellouze"
              },
              {
                "authorId": "145198897",
                "name": "H. Amiri"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17533066,
          "isinfluential": true,
          "contexts": [
            "While earlier, early OCR systems did display moderate success with the help of techniques such as Hidden Markov Models (HMM) and Support Vector Machines (SVM) applied on it [1], [2], they were not able to generalize the rules across distinct styles of writing.",
            "Notable among these was the work of Al-Hajj et al. [1], who combined structural and statistical features with Hidden Markov Models (HMMs) to achieve a character accuracy of 92.1% on a proprietary dataset.",
            "Such problems are, however, more profound in the instance where datasets are not properly labeled; hence, the development of robust Optical Character Recognition (OCR) for handwritten Arabic is indeed a very hard task [1], [2]."
          ],
          "intents": [
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Combining Slanted-Frame Classifiers for Improved HMM-Based Arabic Handwriting Recognition",
            "abstract": "",
            "year": 2009,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1957671",
                "name": "Ramy Al-Hajj Mohamad"
              },
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "1699564",
                "name": "C. Mokbel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 206591895,
          "isinfluential": false,
          "contexts": [
            "Neumann and Matas [5] suggested using Extremal Regions (ERs) classification to find characters."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Real-time scene text localization and recognition",
            "abstract": "",
            "year": 2012,
            "venue": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "145532509",
                "name": "Lukás Neumann"
              },
              {
                "authorId": "145564537",
                "name": "Jiri Matas"
              }
            ]
          }
        },
        {
          "citedcorpusid": 260432782,
          "isinfluential": true,
          "contexts": [
            "1) Model background (DBNet++) [4]: The model starts by feeding the image into the ResNet50 Backbone for Feature Extraction then scales them up until to reach same scale for all to pass the features to The Adaptive Scale Fusion (ASF) module.",
            "…fall into one of three broad categories: segmentation-based, part-based, and regression-based techniques Following the recently proposed DBNet++ [4] which performed more accurately and more efficiently owing to the simple and efficient differentiable binarization algorithm with adaptive fusion…",
            "These techniques enhance the resilience of text detection systems by managing variable text scales and preserving critical contextual details, leading to more accurate and efficient processing of handwritten Arabic text Liao et al. [4].",
            "The difference between the initial weights ”best-weights of the DBNet++ [4] Model” and our Fine-Tuned weights on The Arabic dataset can be seen in Table III.",
            "Our work Method initially Follows the recently proposed DBNet++ [4] which performed well on several printed text datasets."
          ],
          "intents": [
            "--",
            "--",
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Real-Time Scene Text Detection With Differentiable Binarization and Adaptive Scale Fusion",
            "abstract": "Recently, segmentation-based scene text detection methods have drawn extensive attention in the scene text detection field, because of their superiority in detecting the text instances of arbitrary shapes and extreme aspect ratios, profiting from the pixel-level descriptions. However, the vast majority of the existing segmentation-based approaches are limited to their complex post-processing algorithms and the scale robustness of their segmentation models, where the post-processing algorithms are not only isolated to the model optimization but also time-consuming and the scale robustness is usually strengthened by fusing multi-scale feature maps directly. In this paper, we propose a Differentiable Binarization (DB) module that integrates the binarization process, one of the most important steps in the post-processing procedure, into a segmentation network. Optimized along with the proposed DB module, the segmentation network can produce more accurate results, which enhances the accuracy of text detection with a simple pipeline. Furthermore, an efficient Adaptive Scale Fusion (ASF) module is proposed to improve the scale robustness by fusing features of different scales adaptively. By incorporating the proposed DB and ASF with the segmentation network, our proposed scene text detector consistently achieves state-of-the-art results, in terms of both detection accuracy and speed, on five standard benchmarks.",
            "year": 2022,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "8155680",
                "name": "Minghui Liao"
              },
              {
                "authorId": "2226725324",
                "name": "Zhisheng Zou"
              },
              {
                "authorId": "81049704",
                "name": "Zhaoyi Wan"
              },
              {
                "authorId": "2146721",
                "name": "C. Yao"
              },
              {
                "authorId": "145905113",
                "name": "X. Bai"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "However, the deployment of Transformer in resource-constrained environments remains challenging [10]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "As our detection objective ”Handwritten Arabic Text” is similar to the printed text, we fine-tuned Universal best-weights trained on ICDAR 2015[12], Total-Text [13], MSRA-TD500 [14], and Chinese Baidu[15] using Handwritten text images to add value to the universal weights."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "12217430": {
      "citing_paper_info": {
        "title": "Off-line Handwriting Text Line Segmentation : A Review",
        "abstract": "Summary Text line segmentation is an essential pre-processing stage for off-line handwriting recognition in many Optical Character Recognition (OCR) systems. It is an important step because inaccurately segmented text lines will cause errors in the recognition stage. Text line segmentation of the handwritten documents is still one of the most complicated problems in developing a reliable OCR. The nature of handwriting makes the process of text line segmentation very challenging. Several techniques to segment handwriting text line have been proposed in the past. This paper seeks to provide a comprehensive review of the methods of off-line handwriting text line segmentation proposed by researchers.",
        "year": 2008,
        "venue": "",
        "authors": [
          {
            "authorId": "34325231",
            "name": "N. M. Noor"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 14,
        "unique_cited_count": 14,
        "influential_count": 1,
        "detailed_records_count": 14
      },
      "cited_papers": [
        "60785986",
        "57510553",
        "13580763",
        "16688674",
        "10130572",
        "9712378",
        "17388229",
        "16669882",
        "22995244",
        "16084781",
        "8835228",
        "15335538",
        "7272464",
        "14210437"
      ],
      "citation_details": [
        {
          "citedcorpusid": 7272464,
          "isinfluential": false,
          "contexts": [
            "Li et. al [11] proposed a new approach for text line detection by adopting a state-of-the-art image segmentation technique.",
            "The algorithm in [11] was tested on more than 10,000 diverse handwritten documents in different scripts, such as Arabic, Hindi, and Chinese."
          ],
          "intents": [
            "--",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A New Algorithm for Detecting Text Line in Handwritten Documents",
            "abstract": "Curvilinear text line detection and segmentation in handwritten documents is a significant challenge for handwriting recognition. Given no prior knowledge of script, we model text line detection as an image segmentation problem by enhancing text line structure using a Gaussian window, and adopting the level set method to evolve text line boundaries. Experiments show that the proposed method achieves high accuracy for detecting text lines in both handwritten and machine printed documents with many scripts.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "2153682487",
                "name": "Yi Li"
              },
              {
                "authorId": "2145273401",
                "name": "Yefeng Zheng"
              },
              {
                "authorId": "48471936",
                "name": "D. Doermann"
              },
              {
                "authorId": "2053348005",
                "name": "S. Jaeger"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8835228,
          "isinfluential": false,
          "contexts": [
            "Related work can be found in [18-35]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "An architecture for handwritten text recognition systems",
            "abstract": "",
            "year": 1999,
            "venue": "International Journal on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2157691706",
                "name": "Gyeonghwan Kim"
              },
              {
                "authorId": "117208225",
                "name": "Venu Govindaraju"
              },
              {
                "authorId": "1696384",
                "name": "S. Srihari"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9712378,
          "isinfluential": false,
          "contexts": [
            "Feldbach and Tönnies [13] proposed a method for line detection and segmentation in historical church registers (Fig.",
            "5: Line segmentation using a grouping approach (from Feldbach and Tönnies [13]) In [2] the text line extraction problem is seen in the view of artificial intelligence using a production system.",
            "The algorithm in [13] 1."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {
            "title": "Line detection and segmentation in historical church registers",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2834467",
                "name": "Markus Feldbach"
              },
              {
                "authorId": "145967589",
                "name": "Klaus D. Tönnies"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10130572,
          "isinfluential": true,
          "contexts": [
            "5: Line segmentation using a grouping approach (from Feldbach and Tönnies [13]) In [2] the text line extraction problem is seen in the view of artificial intelligence using a production system.",
            "In [2], overlapped text lines and text lines where the interline distance is smaller than the intra line distance will cause segmentation errors.",
            "Fluctuating lines or skew variability [2,3].",
            "…the same orientation, • multiple skew: unaligned paragraphs or slant is different in different blocks of the page such as the FLAUBERT's drafts [2] which contain several blocks of text arranged in a non linear way, and numerous editorial marks such as erasures and word insertion, and • non…"
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "--",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation in handwritten document using a production system",
            "abstract": "",
            "year": 2004,
            "venue": "Ninth International Workshop on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "97014121",
                "name": "Stéphane Nicolas"
              },
              {
                "authorId": "1690399",
                "name": "T. Paquet"
              },
              {
                "authorId": "1804638",
                "name": "L. Heutte"
              }
            ]
          }
        },
        {
          "citedcorpusid": 13580763,
          "isinfluential": false,
          "contexts": [
            "Small gaps between neighboring text lines will cause touching or overlapping of ascenders or descenders [1,3,5,6].",
            "The method in [6] was tested on 30 images from NIST special database consisting data in 34 text boxes from 2100 forms scanned at a resolution of 300 pixels / inch and saved in binary format.",
            "In [6], the CTM method finds a path or cut line in between the text lines to be separated which minimizes the text line pixels cut by the segmentation line, especially descenders from the upper line and ascenders from the lower line."
          ],
          "intents": [
            "['background']",
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Handwritten Document Offline Text Line Segmentation",
            "abstract": "",
            "year": 2005,
            "venue": "International Conference on Digital Image Computing: Techniques and Applications",
            "authors": [
              {
                "authorId": "2115871",
                "name": "C. Weliwitage"
              },
              {
                "authorId": "32691211",
                "name": "A. Harvey"
              },
              {
                "authorId": "144813074",
                "name": "A. Jennings"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14210437,
          "isinfluential": false,
          "contexts": [
            "Louloudis et al. [15] presented a text line detection method for unconstrained handwritten documents based on a strategy that consists of three distinct steps.",
            "The proposed text line detection method in [15] which uses a Block-Based Hough Transform approach was tested on unconstrained handwritten Greek documents using 20 document images taken from the historical archives of the University of Athens for which corresponding text line detection ground truth…"
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Block-Based Hough Transform Mapping for Text Line Detection in Handwritten Documents",
            "abstract": "In this paper, we present a new text line detection method for unconstrained handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes preprocessing for image enhancement, connected component extraction and average character height estimation. In the second step, a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible false alarms. The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1748249",
                "name": "I. Pratikakis"
              },
              {
                "authorId": "70602633",
                "name": "K. Halatsis"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15335538,
          "isinfluential": false,
          "contexts": [
            "Yanikoglu and Sandon [9] first searched for the handwriting text line boundaries and then processed each text line in turn."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Segmentation of off-line cursive handwriting using linear programming",
            "abstract": "",
            "year": 1998,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1757030",
                "name": "B. Yanikoglu"
              },
              {
                "authorId": "2002388",
                "name": "P. A. Sandon"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16084781,
          "isinfluential": false,
          "contexts": [
            "Related work can be found in [18-35]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Local reference lines for handwritten phrase recognition",
            "abstract": "",
            "year": 1999,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "2234121",
                "name": "S. Madhvanath"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16669882,
          "isinfluential": false,
          "contexts": [
            "In [14] an iterative hypothesis validation strategy based on Hough transform was proposed."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Hough based algorithm for extracting text lines in handwritten documents",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "1409083785",
                "name": "Anahid Hanimyan"
              },
              {
                "authorId": "38138508",
                "name": "C. Faure"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16688674,
          "isinfluential": false,
          "contexts": [
            "Related work can be found in [18-35]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "An HMM-Based Approach for Off-Line Unconstrained Handwritten Word Modeling and Recognition",
            "abstract": "Describes a hidden Markov model-based approach designed to recognize off-line unconstrained handwritten words for large vocabularies. After preprocessing, a word image is segmented into letters or pseudoletters and represented by two feature sequences of equal length, each consisting of an alternating sequence of shape-symbols and segmentation-symbols, which are both explicitly modeled. The word model is made up of the concatenation of appropriate letter models consisting of elementary HMMs and an HMM-based interpolation technique is used to optimally combine the two feature sets. Two rejection mechanisms are considered depending on whether or not the word image is guaranteed to belong to the lexicon. Experiments carried out on real-life data show that the proposed approach can be successfully used for handwritten word recognition.",
            "year": 1999,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1398821307",
                "name": "M. El-Yacoubi"
              },
              {
                "authorId": "2787007",
                "name": "M. Gilloux"
              },
              {
                "authorId": "1744351",
                "name": "R. Sabourin"
              },
              {
                "authorId": "2247640259",
                "name": "Ching Y. Suen"
              }
            ]
          }
        },
        {
          "citedcorpusid": 17388229,
          "isinfluential": false,
          "contexts": [
            "Pal and Datta [8])."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Segmentation of Bangla unconstrained handwritten text",
            "abstract": "",
            "year": 2003,
            "venue": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.",
            "authors": [
              {
                "authorId": "144167309",
                "name": "U. Pal"
              },
              {
                "authorId": "52511272",
                "name": "S. Datta"
              }
            ]
          }
        },
        {
          "citedcorpusid": 22995244,
          "isinfluential": false,
          "contexts": [
            "Related work can be found in [18-35]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "The Document Spectrum for Page Layout Analysis",
            "abstract": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >",
            "year": 1993,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1398550688",
                "name": "L. O'Gorman"
              }
            ]
          }
        },
        {
          "citedcorpusid": 57510553,
          "isinfluential": false,
          "contexts": [
            "Likforman-Sulem and Faure [12] proposed an approach based on perceptual grouping of connected components of black pixels.",
            "al [12] Unconstrained handwritten rough drafts, address blocks, letters and manuscripts.",
            "Likforman-Sulem and Faure [12] tested their method on handwritten documents."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Advances in Handwriting and Drawing: a multidisciplinary approach",
            "abstract": "",
            "year": 1994,
            "venue": "",
            "authors": [
              {
                "authorId": "38138508",
                "name": "C. Faure"
              },
              {
                "authorId": "3806481",
                "name": "P. Keuss"
              },
              {
                "authorId": "2915873",
                "name": "G. Lorette"
              },
              {
                "authorId": "2377682",
                "name": "A. Vinter"
              }
            ]
          }
        },
        {
          "citedcorpusid": 60785986,
          "isinfluential": false,
          "contexts": [
            "[ 10 ] 10 pages of a handwriting database containing 7000 words from the LOB corpus (Lancaster-Oslo / Bergen) written by a single writer Conducted using the MatCNN simulator in Matlab software Correctly segmented each line in every page Not stated",
            "The algorithm in [ 10 ] localized lines by computing the horizontal histograms for the entire image at a couple of relevant skew angles; then the angle and position where the histograms have local minima were chosen as the location between lines."
          ],
          "intents": [
            "['methodology']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Analogic preprocessing and segmentation algorithms for off-line handwriting recognition",
            "abstract": "",
            "year": 2002,
            "venue": "Proceedings of the 2002 7th IEEE International Workshop on Cellular Neural Networks and Their Applications",
            "authors": [
              {
                "authorId": "35231658",
                "name": "G. Tímár"
              },
              {
                "authorId": "1934871",
                "name": "K. Karacs"
              },
              {
                "authorId": "2064150",
                "name": "C. Rekeczky"
              }
            ]
          }
        }
      ]
    },
    "12851175": {
      "citing_paper_info": {
        "title": "Text lines and PAWs segmentation of handwritten Arabic document by two hybrid methods",
        "abstract": "",
        "year": 2014,
        "venue": "International Conference on Advanced Technologies for Signal and Image Processing",
        "authors": [
          {
            "authorId": "1681421",
            "name": "Samia Maddouri"
          },
          {
            "authorId": "3270819",
            "name": "Fethi Ghazouani"
          },
          {
            "authorId": "2003418",
            "name": "F. B. Samoud"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 9,
        "unique_cited_count": 6,
        "influential_count": 0,
        "detailed_records_count": 9
      },
      "cited_papers": [
        "111387790",
        "11253582",
        "585756",
        "216050861",
        "1913486",
        "8046523"
      ],
      "citation_details": [
        {
          "citedcorpusid": 585756,
          "isinfluential": false,
          "contexts": [
            "On the same, some works are proposed for the segmentation in pieces of words for instance: contour technique [7], labeling-recognition [8] and projection methods [9]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Two-Tier Approach for Arabic Offline Handwriting Recognition",
            "abstract": "In this paper we present a novel approach for the recognition of offline Arabic handwritten text that is motivated by the Arabic letters' conditional joining rules. A lexicon of Arabic words can be expressed in terms of a new alphabet of PAWs (Part of Arabic Word). PAWs can be expressed in terms of letters. The recognition problem is decomposed into two problems that are solved simultaneously. To find the best matching word for an input image, a Two-Tier Beam search is performed. In Tier one the search is constrained by a letter to PAW lexicon. In Tier two, the search is constrained by a PAW to word lexicon. Directing the searches is a Neural Net based PAW recognizer. Experiments conducted on the standard IFN/ENIT database [7] of handwritten Tunisian town names show word error rates of about 11%. This result is comparable to the results of the commonly used HMM based approaches.",
            "year": 2006,
            "venue": "",
            "authors": [
              {
                "authorId": "1859983",
                "name": "Ahmad Abdulkader"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1913486,
          "isinfluential": false,
          "contexts": [
            "Several segmentation methods for lines extraction have been presented such as: projection method ([1], [2]), k-means algorithm [3],\nHough transform method ([4], [5]) and snake technique or active contour [6]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "2009 10th International Conference on Document Analysis and Recognition Handwritten Text Line Segmentation by Shredding Text into its Lines",
            "abstract": "",
            "year": null,
            "venue": "",
            "authors": []
          }
        },
        {
          "citedcorpusid": 8046523,
          "isinfluential": false,
          "contexts": [
            "Fig.2(a) presents the initial image (image from KSU 1) and Fig.2(b) shows the morphologic operator effect."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Word Segmentation and Baseline Detection in Handwritten Documents Using Isothetic Covers",
            "abstract": "",
            "year": 2010,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2965167",
                "name": "Aisharjya Sarkar"
              },
              {
                "authorId": "144984407",
                "name": "A. Biswas"
              },
              {
                "authorId": "1701712",
                "name": "Partha Bhowmick"
              },
              {
                "authorId": "1718671",
                "name": "B. Bhattacharya"
              }
            ]
          }
        },
        {
          "citedcorpusid": 11253582,
          "isinfluential": false,
          "contexts": [
            "A. Impact of MM on OIC\nThe Arabic script is generally represented in the form of pieces or parts of words called Pieces of Arabic Words (PAWs) [11]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "A hybrid method for three segmentation level of handwritten Arabic script",
            "abstract": "",
            "year": 2009,
            "venue": "MOCR '09",
            "authors": [
              {
                "authorId": "2003418",
                "name": "F. B. Samoud"
              },
              {
                "authorId": "1681421",
                "name": "Samia Maddouri"
              },
              {
                "authorId": "1683433",
                "name": "N. Ellouze"
              }
            ]
          }
        },
        {
          "citedcorpusid": 111387790,
          "isinfluential": false,
          "contexts": [
            "Fig.2(a) presents the initial image (image from KSU 1) and Fig.2(b) shows the morphologic operator effect."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Baseline Extraction : Comparison of Six Methods on IFN / ENIT Database",
            "abstract": "Baseline extraction is hailed as an important step in handwriting primitive extraction process, seen the insights it proffers into the position and the length of the word. It further facilitates feature extraction. As regards Arabic words, tow baselines can be extracted: an upper baseline and a lower one. These tow lines divide the word into three parts, namely, Ascender and upper diacritic points above the upper baseline, Descender and lower diacritic points under the lower baseline. The main content of the word lies between the two baselines, it generally involves loops. In this paper we start with a presentation of six baseline extraction methods. These methods are developed and evaluated with reference to IFN/ENIT-database . Some of them are combined in order to improve baseline position. A comparison between these methods is made on the basis of the IFN/ENIT-database. Results on the set a of IFN/ENIT-database evince that the Skeletonbased method and the Min-Max & Primitives achieve very promising results reaching about 77% of good results and about 87% of acceptable results.",
            "year": 2008,
            "venue": "",
            "authors": [
              {
                "authorId": "1681421",
                "name": "Samia Maddouri"
              },
              {
                "authorId": "69331718",
                "name": "K. Bouriel"
              },
              {
                "authorId": "1683433",
                "name": "N. Ellouze"
              },
              {
                "authorId": "2801094",
                "name": "H. E. Abed"
              }
            ]
          }
        },
        {
          "citedcorpusid": 216050861,
          "isinfluential": false,
          "contexts": [
            "Several segmentation methods for lines extraction have been presented such as: projection method ([1], [2]), k-means algorithm [3],\nHough transform method ([4], [5]) and snake technique or active contour [6]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text Lines and Snippets Extraction for 19th Century Handwriting Documents Layout Analysis",
            "abstract": "",
            "year": 2009,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2104187182",
                "name": "Vincent Malleron"
              },
              {
                "authorId": "1721326",
                "name": "V. Eglin"
              },
              {
                "authorId": "1739381",
                "name": "H. Emptoz"
              },
              {
                "authorId": "2093671870",
                "name": "Stéphanie Dord-Crouslé"
              },
              {
                "authorId": "1796597",
                "name": "Philippe Régnier"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Several segmentation methods for lines extraction have been presented such as: projection method ([1], [2]), k-means algorithm [3],\nHough transform method ([4], [5]) and snake technique or active contour [6]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "On the same, some works are proposed for the segmentation in pieces of words for instance: contour technique [7], labeling-recognition [8] and projection methods [9]."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Subsequent grid points are classified, marked as visited, and the direction is determined from each grid point to the start vertex.",
            "Fig.2(a) presents the initial image (image from KSU 1) and Fig.2(b) shows the morphologic operator effect."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "23676466": {
      "citing_paper_info": {
        "title": "Robust Text Line, Word And Character Extraction from Telugu Document Image",
        "abstract": "Designing an OCR system for Indian languages in general is more complex than those of European languages due the linguistic complexity. Efforts are on the way for the development of efficient OCR systems for Indian languages, especially for Telugu, a popular South Indian language. In this paper, we proposed a method for reliable extraction of text line, word and character from document images of Telugu scripts. In the text line segmentation, first we establish the relationship between the connected components and then cluster the connected components of a line using vertical spatial relation and nearest neighbor algorithm. In word segmentation, the space between two adjacent characters is computed and clustered into word space and character space. Consonant and vowel modifiers are segregated from the word image and segment the characters.",
        "year": 2009,
        "venue": "2009 Second International Conference on Emerging Trends in Engineering & Technology",
        "authors": [
          {
            "authorId": "3197140",
            "name": "V. K. Koppula"
          },
          {
            "authorId": "1728262",
            "name": "A. Negi"
          },
          {
            "authorId": "1804457",
            "name": "Utpal Garain"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 2,
        "unique_cited_count": 2,
        "influential_count": 0,
        "detailed_records_count": 2
      },
      "cited_papers": [
        "5397715",
        "15921038"
      ],
      "citation_details": [
        {
          "citedcorpusid": 5397715,
          "isinfluential": false,
          "contexts": [
            "It also improves upon the algorithms as shown in ICDAR 2001 paper [7] and the subsequent LEC 2002 paper [1] for text segmentation in Telugu script",
            "Text line can be defined as a group of CCs with spatial relation [7].",
            "Atul Negi [7] gave connected component based method for text line extraction."
          ],
          "intents": [
            "['methodology']",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "An OCR system for Telugu",
            "abstract": "",
            "year": 2001,
            "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1728262",
                "name": "A. Negi"
              },
              {
                "authorId": "1716502",
                "name": "C. Bhagvati"
              },
              {
                "authorId": "107998684",
                "name": "B. Krishna"
              }
            ]
          }
        },
        {
          "citedcorpusid": 15921038,
          "isinfluential": false,
          "contexts": [
            "The Smearing (run-length smearing algorithm) algorithm classifies text lines [2] and [6] but Vertical smearing may conjuncts vowel and consonant modifier of above line and results merged lines."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Document Analysis System",
            "abstract": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included.",
            "year": 1982,
            "venue": "IBM Journal of Research and Development",
            "authors": [
              {
                "authorId": "145470231",
                "name": "Kwan Y. Wong"
              },
              {
                "authorId": "34896449",
                "name": "R. Casey"
              },
              {
                "authorId": "1880661",
                "name": "F. Wahl"
              }
            ]
          }
        }
      ]
    },
    "272943786": {
      "citing_paper_info": {
        "title": "Automation of historical weather data rescue",
        "abstract": "Data rescuers worldwide have been trying to retrieve millions of valuable weather historical records so the observations contained in those records are preserved, searchable, analysable and machine readable. The majority of the records are written by hand, in print or cursive handwriting. Automatic transcriptions to date have not been reliable or sufficiently accurate on handwritten data so most of the historical records are transcribed manually. Recent attempts integrate artificial intelligence (AI) to automatically transcribe the historical records but the results have not been promising. Currently there is no end‐to‐end workflow to automatically transcribe historical handwritten tabular records into digital datasets. We propose a workflow that uses AI to automate the handwriting transcription process. The workflow is tested using the historical climate records from the Data Rescue: Archives and Weather (DRAW) project. This workflow is composed of five steps: (1) image pre‐processing, (2) text line segmentation, (3) bounding boxes detection, (4) AI‐enabled optical character recognition (OCR) and (5) layout re‐arrangement. These steps are modular to better accommodate future advances (e.g., new image training data, better layout detectors). We hope the workflow proposed can serve as a guideline that is easily replicable and can be utilized to transcribe other historical datasets.",
        "year": 2024,
        "venue": "Geoscience Data Journal",
        "authors": [
          {
            "authorId": "2323306707",
            "name": "Y. Zhang"
          },
          {
            "authorId": "2323220084",
            "name": "R. E. Sieber"
          },
          {
            "authorId": "2361242031",
            "name": "DRAWMcGill R. E. Sieber"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 9,
        "unique_cited_count": 8,
        "influential_count": 0,
        "detailed_records_count": 9
      },
      "cited_papers": [
        "19184269",
        "209531740",
        "181736636",
        "259470901",
        "221159378",
        "49407309",
        "130403250",
        "60282629"
      ],
      "citation_details": [
        {
          "citedcorpusid": 19184269,
          "isinfluential": false,
          "contexts": [
            "Nonetheless, researchers have found that even advanced algorithms cannot easily recognize historical handwritten documents (Alabau & Leiva, 2012; Firmani et al., 2017; Jander, 2016; Swindall et al., 2021).",
            "More recent SOTA OCR algorithms have made extensive use of deep learning algorithms (Chamchong et al., 2019; Ferro et al., 2023; Firmani et al., 2017; Memon et al., 2020), for example to describe the numerous new algorithms for OCR and the availability of various natural languages for handwritten…"
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "In Codice Ratio: OCR of Handwritten Latin Documents using Deep Convolutional Networks",
            "abstract": "Automatic transcription of historical handwritten documents is a challenging research problem, requiring in general expensive transcriptions from expert paleographers. In Codice Ratio is designed to be an end-to-end architecture requiring instead limited labeling effort, whose aim is the automatic transcription of a portion of the Vatican Secret Archives (one of the largest historical libraries in the world). In this paper, we describe in particular the design of our OCR component for Latin characters. To this end, we first annotated a large corpus of Latin characters with a custom crowdsourcing platform. Leveraging over recent progresses in deep learning, we designed and trained a deep convolutional network achieving an overall accuracy of 96% over the entire dataset, which is one of the highest results reported in the literature so far. Our training data are publicly available.",
            "year": 2017,
            "venue": "AI*CH@AI*IA",
            "authors": [
              {
                "authorId": "1728335",
                "name": "D. Firmani"
              },
              {
                "authorId": "1796590",
                "name": "P. Merialdo"
              },
              {
                "authorId": "40483335",
                "name": "Elena Nieddu"
              },
              {
                "authorId": "1752983",
                "name": "Simone Scardapane"
              }
            ]
          }
        },
        {
          "citedcorpusid": 49407309,
          "isinfluential": false,
          "contexts": [
            "Clinchant et al. (2018) recommended treating transcription automation as a series of steps.",
            "Clinchant et al. (2018) found that some contributors tightly packed observations into rows; whereas others left considerable spacing."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Comparing Machine Learning Approaches for Table Recognition in Historical Register Books",
            "abstract": "We present in this paper experiments on Table Recognition in hand-written register books. We first explain how the problem of row and column detection is modelled, and then compare two Machine Learning approaches (Conditional Random Field and Graph Convolutional Network) for detecting these table elements. Evaluation was conducted on death records provided by the Archives of the Diocese of Passau. With an F-1 score of 89, both methods provide a quality which allows for Information Extraction. Software and dataset are open source/data.",
            "year": 2018,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "2207074",
                "name": "S. Clinchant"
              },
              {
                "authorId": "2131960",
                "name": "Hervé Déjean"
              },
              {
                "authorId": "2066113788",
                "name": "J. Meunier"
              },
              {
                "authorId": "2059294500",
                "name": "E. Lang"
              },
              {
                "authorId": "1729636",
                "name": "Florian Kleber"
              }
            ]
          }
        },
        {
          "citedcorpusid": 60282629,
          "isinfluential": false,
          "contexts": [
            "One model was retrained on the Modified National Institute of Standards and Technology (MNIST) dataset (LeCun & Cortes, 1998), which is one of the most cited dataset for handwritten digits in a normalized form (mnist.traineddata)."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "The mnist database of handwritten digits",
            "abstract": "Disclosed is an improved articulated bar flail having shearing edges for efficiently shredding materials. An improved shredder cylinder is disclosed with a plurality of these flails circumferentially spaced and pivotally attached to the periphery of a rotatable shaft. Also disclosed is an improved shredder apparatus which has a pair of these shredder cylinders mounted to rotate about spaced parallel axes which cooperates with a conveyer apparatus which has a pair of inclined converging conveyer belts with one of the belts mounted to move with respect to the other belt to allow the transport of articles of various sizes therethrough.",
            "year": 2005,
            "venue": "",
            "authors": [
              {
                "authorId": "1688882",
                "name": "Yann LeCun"
              },
              {
                "authorId": "145115014",
                "name": "Corinna Cortes"
              }
            ]
          }
        },
        {
          "citedcorpusid": 130403250,
          "isinfluential": false,
          "contexts": [
            "It has difficulty accommodating records in different formats (e.g., text, table, graph) (Stickler, Brönnimann, Jourdain, et al., 2014; Stickler, Brönnimann, Valente, et al., 2014; Wilkinson et al., 2019) and context (e.g., digits, characters, alphanumeric) (Brönnimann et al., 2006; Stickler,…",
            "…records in different formats (e.g., text, table, graph) (Stickler, Brönnimann, Jourdain, et al., 2014; Stickler, Brönnimann, Valente, et al., 2014; Wilkinson et al., 2019) and context (e.g., digits, characters, alphanumeric) (Brönnimann et al., 2006; Stickler, Brönnimann, Jourdain, et al., 2014).",
            "Automated approaches for weather data rescue have yielded low accuracy, for example due to the poor quality of the original source document or the scanned/photographed image (Blancq, 2010; Stickler, Brönnimann, Jourdain, et al., 2014; Stickler, Brönnimann, Valente, et al., 2014)."
          ],
          "intents": [
            "--",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "ERA-CLIM Historical Upper-Air Data 1900-1972",
            "abstract": "",
            "year": 2014,
            "venue": "",
            "authors": [
              {
                "authorId": "66311140",
                "name": "A. Stickler"
              },
              {
                "authorId": "4959798",
                "name": "S. Brönnimann"
              },
              {
                "authorId": "50730138",
                "name": "S. Jourdain"
              },
              {
                "authorId": "8284867",
                "name": "Eméline Roucaute"
              },
              {
                "authorId": "47275074",
                "name": "A. Sterin"
              },
              {
                "authorId": "49898748",
                "name": "Dmitrii Nikolaev"
              },
              {
                "authorId": "49083735",
                "name": "M. Valente"
              },
              {
                "authorId": "40859607",
                "name": "R. Wartenburger"
              },
              {
                "authorId": "13392292",
                "name": "H. Hersbach"
              },
              {
                "authorId": "66843831",
                "name": "L. R. Pralungo"
              },
              {
                "authorId": "145194412",
                "name": "D. Dee"
              }
            ]
          }
        },
        {
          "citedcorpusid": 181736636,
          "isinfluential": false,
          "contexts": [
            "…the percentage of characters incorrectly predicted (substituted, deleted, or inserted) and word error rate (WER), which is a similar percentage but at the word level, are the most common evaluation metrics used to examine OCR performance (Sánchez et al., 2019), were then used to evaluate accuracy.",
            "…many studies have suggested that we should develop a workflow that combines techniques for document transcription that includes, but is not limited to, pre-processing, layout analysis, text recognition and post-processing (Chamchong et al., 2019; Neudecker et al., 2019; Sánchez et al., 2019)."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "A set of benchmarks for Handwritten Text Recognition on historical documents",
            "abstract": "",
            "year": 2019,
            "venue": "Pattern Recognition",
            "authors": [
              {
                "authorId": "1928123",
                "name": "Joan Andreu Sánchez"
              },
              {
                "authorId": "2218294739",
                "name": "Joan-Andreu Sánchez"
              },
              {
                "authorId": "144340605",
                "name": "Verónica Romero"
              },
              {
                "authorId": "52151344",
                "name": "A. Toselli"
              },
              {
                "authorId": "41206897",
                "name": "M. Villegas"
              },
              {
                "authorId": "143783065",
                "name": "E. Vidal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 209531740,
          "isinfluential": false,
          "contexts": [
            "…recent SOTA OCR algorithms have made extensive use of deep learning algorithms (Chamchong et al., 2019; Ferro et al., 2023; Firmani et al., 2017; Memon et al., 2020), for example to describe the numerous new algorithms for OCR and the availability of various natural languages for handwritten…"
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Handwritten Optical Character Recognition (OCR): A Comprehensive Systematic Literature Review (SLR)",
            "abstract": "Given the ubiquity of handwritten documents in human transactions, Optical Character Recognition (OCR) of documents have invaluable practical worth. Optical character recognition is a science that enables to translate various types of documents or images into analyzable, editable and searchable data. During last decade, researchers have used artificial intelligence/machine learning tools to automatically analyze handwritten and printed documents in order to convert them into electronic format. The objective of this review paper is to summarize research that has been conducted on character recognition of handwritten documents and to provide research directions. In this Systematic Literature Review (SLR) we collected, synthesized and analyzed research articles on the topic of handwritten OCR (and closely related topics) which were published between year 2000 to 2019. We followed widely used electronic databases by following pre-defined review protocol. Articles were searched using keywords, forward reference searching and backward reference searching in order to search all the articles related to the topic. After carefully following study selection process 176 articles were selected for this SLR. This review article serves the purpose of presenting state of the art results and techniques on OCR and also provide research directions by highlighting research gaps.",
            "year": 2020,
            "venue": "IEEE Access",
            "authors": [
              {
                "authorId": "3169373",
                "name": "Jamshed Memon"
              },
              {
                "authorId": "1473077187",
                "name": "Maira Sami"
              },
              {
                "authorId": "144553570",
                "name": "Rizwan Ahmed Khan"
              }
            ]
          }
        },
        {
          "citedcorpusid": 221159378,
          "isinfluential": false,
          "contexts": [
            "Sufficient training data can be impossible to accumulate, especially for small collections (Lehenmeier et al., 2020).",
            "Although useful for other types of data, Lehenmeier et al. (2020) found that transcription tools such as Transkribus and OCRopy failed to work well with dense tabular data, which is detecting the table and locating the text."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Layout Detection and Table Recognition - Recent Challenges in Digitizing Historical Documents and Handwritten Tabular Data",
            "abstract": "",
            "year": 2020,
            "venue": "International Conference on Theory and Practice of Digital Libraries",
            "authors": [
              {
                "authorId": "1868530",
                "name": "Constantin Lehenmeier"
              },
              {
                "authorId": "2745991",
                "name": "M. Burghardt"
              },
              {
                "authorId": "1885326976",
                "name": "Bernadette Mischka"
              }
            ]
          }
        },
        {
          "citedcorpusid": 259470901,
          "isinfluential": false,
          "contexts": [
            "The reader may be unaware that pretrained models are often a sequence of training on increasingly specialized training datasets (also seen in the emergence of domain-customized ChatGPTs – Lappalainen & Narayanan, 2023)."
          ],
          "intents": [
            "--"
          ],
          "cited_paper_info": {
            "title": "Aisha: A Custom AI Library Chatbot Using the ChatGPT API",
            "abstract": "Abstract This article focuses on the development of a custom chatbot for Zayed University Library (United Arab Emirates) using Python and the ChatGPT API. The chatbot, named Aisha, was designed to provide quick and efficient reference and support services to students and faculty outside the library’s regular operating hours. The article also discusses the benefits of chatbots in academic libraries, and reviews the early literature on ChatGPT's applicability in this field. The article describes the development process, perceived capabilities and limitations of the bot, and plans for further development. This project represents the first fully reported attempt to explore the potential of a ChatGPT-based bot in academic libraries, and provides insights into the future of AI-based chatbot technology in this context.",
            "year": 2023,
            "venue": "Journal of Web Librarianship",
            "authors": [
              {
                "authorId": "144262735",
                "name": "Yrjö Lappalainen"
              },
              {
                "authorId": "40532432",
                "name": "N. Narayanan"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "Two common means of automating text line segmentation are thresh-olding and reducing (we assisted these means with the less common noise cancelling and enhancement meth-ods of erosion, opening and dilation, details of which can be found in Zhang, 2023).",
            "Like Transkribus, many historical weather data rescue projects struggle with long-term sustainability and some fail to secure the resources to follow through with developing automation solutions or to improve the system post-development (Zhang, 2023)."
          ],
          "intents": [
            "--",
            "--"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "209376578": {
      "citing_paper_info": {
        "title": "Indiscapes: Instance Segmentation Networks for Layout Parsing of Historical Indic Manuscripts",
        "abstract": "Historical palm-leaf manuscript and early paper documents from Indian subcontinent form an important part of the world's literary and cultural heritage. Despite their importance, large-scale annotated Indic manuscript image datasets do not exist. To address this deficiency, we introduce Indiscapes, the first ever dataset with multi-regional layout annotations for historical Indic manuscripts. To address the challenge of large diversity in scripts and presence of dense, irregular layout elements (e.g. text lines, pictures, multiple documents per image), we adapt a Fully Convolutional Deep Neural Network architecture for fully automatic, instance-level spatial layout parsing of manuscript images. We demonstrate the effectiveness of proposed architecture on images from the Indiscapes dataset. For annotation flexibility and keeping the non-technical nature of domain experts in mind, we also contribute a custom, web-based GUI annotation tool and a dashboard-style analytics portal. Overall, our contributions set the stage for enabling downstream applications such as OCR and word-spotting in historical Indic manuscripts at scale.",
        "year": 2019,
        "venue": "IEEE International Conference on Document Analysis and Recognition",
        "authors": [
          {
            "authorId": "1387889364",
            "name": "A. Prusty"
          },
          {
            "authorId": "1468797312",
            "name": "Sowmya Aitha"
          },
          {
            "authorId": "2055113392",
            "name": "Abhishek Trivedi"
          },
          {
            "authorId": "1730952",
            "name": "Ravi Kiran Sarvadevabhatla"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 15,
        "unique_cited_count": 14,
        "influential_count": 2,
        "detailed_records_count": 15
      },
      "cited_papers": [
        "57246310",
        "14690643",
        "12688730",
        "5987534",
        "53950088",
        "528469",
        "14404162",
        "10328909",
        "26232274",
        "54465873",
        "56598571",
        "56597514",
        "9814021",
        "1531387"
      ],
      "citation_details": [
        {
          "citedcorpusid": 528469,
          "isinfluential": false,
          "contexts": [
            "The ready availability of annotation and analysis tools has facilitated progress in creation and analysis of historical document manuscripts [34]–[36]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Aletheia - An Advanced Document Layout and Text Ground-Truthing System for Production Environments",
            "abstract": "Large-scale digitisation has led to a number of new possibilities with regard to adaptive and learning based methods in the field of Document Image Analysis and OCR. For ground truth production of large corpora, however, there is still a gap in terms of productivity. Ground truth is not only crucial for training and evaluation at the development stage of tools but also for quality assurance in the scope of production workflows for digital libraries. This paper describes Aletheia, an advanced system for accurate and yet cost-effective ground truthing of large amounts of documents. It aids the user with a number of automated and semi-automated tools which were partly developed and improved based on feedback from major libraries across Europe and from their digitisation service providers which are using the tool in a production environment. Novel features are, among others, the support of top-down ground truthing with sophisticated split and shrink tools as well as bottom-up ground truthing supporting the aggregation of lower-level elements to more complex structures. Special features have been developed to support working with the complexities of historical documents. The integrated rules and guidelines validator, in combination with powerful correction tools, enable efficient production of highly accurate ground truth.",
            "year": 2011,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "2764871",
                "name": "C. Clausner"
              },
              {
                "authorId": "1980669",
                "name": "Stefan Pletschacher"
              },
              {
                "authorId": "1803149",
                "name": "A. Antonacopoulos"
              }
            ]
          }
        },
        {
          "citedcorpusid": 1531387,
          "isinfluential": false,
          "contexts": [
            "Other collections contain character-level and wordlevel spatial annotations for South-East Asian palm-leaf manuscripts [5], [10], [14].",
            "A variety of layout parsing approaches, including those employing the modern paradigm of deep learning, have been proposed for Indic [18], [20], [21], [30] and South-East Asian [14], [24], [31]–[33] palm-leaf and paper manuscript images.",
            "A unique aspect of Indic and South-East Asian manuscripts is the frequent presence of holes punched in the document for the purpose of binding [7], [9], [10]."
          ],
          "intents": [
            "['background']",
            "['background']",
            "--"
          ],
          "cited_paper_info": {
            "title": "The Handwritten Sundanese Palm Leaf Manuscript Dataset from 15th Century",
            "abstract": "",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "9165810",
                "name": "M. Suryani"
              },
              {
                "authorId": "39662991",
                "name": "E. Paulus"
              },
              {
                "authorId": "8714538",
                "name": "S. Hadi"
              },
              {
                "authorId": "105030981",
                "name": "Undang A. Darsa"
              },
              {
                "authorId": "1690398",
                "name": "J. Burie"
              }
            ]
          }
        },
        {
          "citedcorpusid": 5987534,
          "isinfluential": true,
          "contexts": [
            "Note that our approach for computing class-wise scores prevents documents with a relatively larger number of class instances from dominating the score and in this sense, differs from existing approaches [25]",
            "A number of contributions can also be found for the task of historical document layout parsing [22]–[25].",
            "To characterize performance for each region type, we report two additional measures [25] – average class-wise IoU (cwIoU) and average class-wise per-pixel accuracy (cwAcc).",
            "[25] explore the use of Fully Convolutional Networks (FCN) for the same datasets."
          ],
          "intents": [
            "['result']",
            "['background']",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Convolutional Neural Networks for Page Segmentation of Historical Document Images",
            "abstract": "This paper presents a page segmentation method for handwritten historical document images based on a Convolutional Neural Network (CNN). We consider page segmentation as a pixel labeling problem, i.e., each pixel is classified as one of the predefined classes. Traditional methods in this area rely on hand-crafted features carefully tuned considering prior knowledge. In contrast, we propose to learn features from raw image pixels using a CNN. While many researchers focus on developing deep CNN architectures to solve different problems, we train a simple CNN with only one convolution layer. We show that the simple architecture achieves competitive results against other deep architectures on different public datasets. Experiments also demonstrate the effectiveness and superiority of the proposed method compared to previous methods.",
            "year": 2017,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "153819461",
                "name": "Kai Chen"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9814021,
          "isinfluential": false,
          "contexts": [
            "Given its importance, a number of active research efforts exist across the world [1]–[6]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Page segmentation of historical document images with convolutional autoencoders",
            "abstract": "",
            "year": 2015,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "153819461",
                "name": "Kai Chen"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1722800",
                "name": "J. Hennebert"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10328909,
          "isinfluential": false,
          "contexts": [
            "Within the task branches, we use categorical cross entropy loss Lr for region classification branch, smooth L1 loss [46] (Lbb) for final bounding box prediction and perpixel binary cross entropy loss Lmask for mask prediction."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
            "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available",
            "year": 2015,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "3080683",
                "name": "Shaoqing Ren"
              },
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              },
              {
                "authorId": "2032184078",
                "name": "Jian Sun"
              }
            ]
          }
        },
        {
          "citedcorpusid": 12688730,
          "isinfluential": false,
          "contexts": [
            "In this respect, our annotation system is closer to the recent trend of collaborative, cloud/webbased annotation systems and services [37]–[39]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Ground-Truth Production in the Transcriptorium Project",
            "abstract": "Tran Scriptorium is a 3-years project that aims to develop innovative, cost-effective solutions for the indexing, search and full transcription of historical handwritten document images, using Handwritten Text Recognition (HTR) technology. The production of ground-truth (GT) of a dataset of handwritten document images is among the first tasks. We address novel approaches for the faster production of this GT based on crowd-sourcing and on prior-knowledge methods. We also address here a novel low-cost semi-supervised procedure for obtaining pairs of correct line-level aligned detected/extracted text line images and text line transcripts, specially suitable for training models of the HTR technology employed in Tran Scriptorium.",
            "year": 2014,
            "venue": "2014 11th IAPR International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "7232446",
                "name": "B. Gatos"
              },
              {
                "authorId": "1746772",
                "name": "G. Louloudis"
              },
              {
                "authorId": "1761923",
                "name": "T. Causer"
              },
              {
                "authorId": "1853639",
                "name": "Kris Grint"
              },
              {
                "authorId": "144340605",
                "name": "Verónica Romero"
              },
              {
                "authorId": "1928123",
                "name": "Joan Andreu Sánchez"
              },
              {
                "authorId": "52151344",
                "name": "A. Toselli"
              },
              {
                "authorId": "143783065",
                "name": "E. Vidal"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14404162,
          "isinfluential": false,
          "contexts": [
            "A variety of layout parsing approaches, including those employing the modern paradigm of deep learning, have been proposed for Indic [18], [20], [21], [30] and South-East Asian [14], [24], [31]–[33] palm-leaf and paper manuscript images."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Digital Enhancement of Palm Leaf Manuscript Images using Normalization Techniques",
            "abstract": "Palm leaves were one of the earliest forms of writing media and their use as writing material in South and Southeast Asia has been recorded from as early as the fifth century B.C. until as recently as the late 19th century. Palm leaf manuscripts relating to art and architecture, mathematics, astronomy, astrology, and medicine dating back several hundreds of years are still available for reference today thanks to many ongoing efforts for preservation of ancient documents by libraries and universities around the world. Palm leaf manuscripts typically last a few centuries but with time the palm leaves degrade and the writing becomes illegible to be useful in any form. Image processing techniques can help enhance the images of these manuscripts so as to enable retrieval of the written text from these degraded documents. In this paper we propose a transform based method for enhancing digital images of palm leaf manuscripts. The method uses a dynamically selected pivoting background color in a linear transform to enhance the legibility of the foreground text. Then a combination of two other image processing algorithms viz., histogram normalization and background normalization developed in our earlier research, are applied to the transformed image. The algorithms can be mathematically combined into one or two transformations for computational efficiency. The method is tested on a set of palm leaf images from various sources and the preliminary results show significant improvement in readability. The techniques can also be used to enhance images of ancient, historical, degraded papyrus and paper documents.",
            "year": 2004,
            "venue": "",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1800513",
                "name": "Srirangaraj Setlur"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 14690643,
          "isinfluential": false,
          "contexts": [
            "[23] explore the effect of using a hybrid feature selection method while using autoencoders for semantic segmentation in five historical English and Medieval European manuscript datasets."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Selecting Autoencoder Features for Layout Analysis of Historical Documents",
            "abstract": "",
            "year": 2015,
            "venue": "HIP@ICDAR",
            "authors": [
              {
                "authorId": "2109393868",
                "name": "Hao Wei"
              },
              {
                "authorId": "2700495",
                "name": "Mathias Seuret"
              },
              {
                "authorId": "153819461",
                "name": "Kai Chen"
              },
              {
                "authorId": "153745355",
                "name": "Andreas Fischer"
              },
              {
                "authorId": "1743758",
                "name": "M. Liwicki"
              },
              {
                "authorId": "1680326",
                "name": "R. Ingold"
              }
            ]
          }
        },
        {
          "citedcorpusid": 26232274,
          "isinfluential": false,
          "contexts": [
            "A number of contributions can also be found for the task of historical document layout parsing [22]–[25]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Fully Convolutional Neural Networks for Page Segmentation of Historical Document Images",
            "abstract": "We propose a high-performance fully convolutional neural network (FCN) for historical document segmentation that is designed to process a single page in one step. The advantage of this model beside its speed is its ability to directly learn from raw pixels instead of using preprocessing steps e. g. feature computation or superpixel generation. We show that this network yields better results than existing methods on different public data sets. For evaluation of this model we introduce a novel metric that is independent of ambiguous ground truth called Foreground Pixel Accuracy (FgPA). This pixel based measure only counts foreground pixels in the binarized page, any background pixel is omitted. The major advantage of this metric is, that it enables researchers to compare different segmentation methods on their ability to successfully segment text or pictures and not on their ability to learn and possibly overfit the peculiarities of an ambiguous hand-made ground truth segmentation.",
            "year": 2017,
            "venue": "International Workshop on Document Analysis Systems",
            "authors": [
              {
                "authorId": "144603426",
                "name": "C. Wick"
              },
              {
                "authorId": "1707592",
                "name": "F. Puppe"
              }
            ]
          }
        },
        {
          "citedcorpusid": 53950088,
          "isinfluential": false,
          "contexts": [
            "While studies on Indic palm-leaf and paper-based manuscripts exist, these are typically conducted on small and often, private collections of documents [15]–[21].",
            "A variety of layout parsing approaches, including those employing the modern paradigm of deep learning, have been proposed for Indic [18], [20], [21], [30] and South-East Asian [14], [24], [31]–[33] palm-leaf and paper manuscript images."
          ],
          "intents": [
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Digitalization of Malayalam Palmleaf Manuscripts Based on Contrast-Based Adaptive Binarization and Convolutional Neural Networks",
            "abstract": "",
            "year": 2018,
            "venue": "2018 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)",
            "authors": [
              {
                "authorId": "2779207",
                "name": "Dhanya Sudarsan"
              },
              {
                "authorId": "2066147638",
                "name": "Parvathy Vijayakumar"
              },
              {
                "authorId": "23764514",
                "name": "Sharon Biju"
              },
              {
                "authorId": "31750726",
                "name": "Soniya Sanu"
              },
              {
                "authorId": "52072849",
                "name": "Sreelakshmi K. Shivadas"
              }
            ]
          }
        },
        {
          "citedcorpusid": 54465873,
          "isinfluential": true,
          "contexts": [
            "We specifically report AP50 and AP75, corresponding to AP at IoU thresholds 50 and 75 respectively [41].",
            "Next, we briefly describe the Mask R-CNN architecture and our modifications of the same.",
            "To meet all of these requirements, we model our problem as one of semantic instance-level segmentation and employ the Mask R-CNN [41] architecture which has proven to be very effective at the task of object-instance segmentation in photos.",
            "Given the relatively smaller size of our manuscript dataset compared to the photo dataset\n(MS-COCO) used to originally train the base Mask R-CNN, we adopt a multi-stage training strategy.",
            "1) Training: The network is initialized with weights obtained from a Mask R-CNN trained on the MS-COCO [44] dataset with a ResNet-50 backbone."
          ],
          "intents": [
            "['background']",
            "--",
            "['methodology']",
            "--",
            "--"
          ],
          "cited_paper_info": {
            "title": "Mask R-CNN",
            "abstract": "We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.",
            "year": 2017,
            "venue": "",
            "authors": [
              {
                "authorId": "39353098",
                "name": "Kaiming He"
              },
              {
                "authorId": "2082991",
                "name": "Georgia Gkioxari"
              },
              {
                "authorId": "3127283",
                "name": "Piotr Dollár"
              },
              {
                "authorId": "2983898",
                "name": "Ross B. Girshick"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56597514,
          "isinfluential": false,
          "contexts": [
            "[26] propose a FCN for segmenting closely spaced, arbitrarily oriented text lines from an Arabic manuscript dataset."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text Line Segmentation for Challenging Handwritten Document Images using Fully Convolutional Network",
            "abstract": "This paper presents a method for text line segmentation of challenging historical manuscript images. These manuscript images contain narrow interline spaces with touching components, interpenetrating vowel signs and inconsistent font types and sizes. In addition, they contain curved, multi-skewed and multi-directed side note lines within a complex page layout. Therefore, bounding polygon labeling would be very difficult and time consuming. Instead we rely on line masks that connect the components on the same text line. Then these line masks are predicted using a Fully Convolutional Network (FCN). In the literature, FCN has been successfully used for text line segmentation of regular handwritten document images. The present paper shows that FCN is useful with challenging manuscript images as well. Using a new evaluation metric that is sensitive to over segmentation as well as under segmentation, testing results on a publicly available challenging handwritten dataset are comparable with the results of a previous work on the same dataset.",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "51036690",
                "name": "Berat Kurar Barakat"
              },
              {
                "authorId": "27005271",
                "name": "Ahmad Droby"
              },
              {
                "authorId": "39240022",
                "name": "M. Kassis"
              },
              {
                "authorId": "1397974623",
                "name": "Jihad El-Sana"
              }
            ]
          }
        },
        {
          "citedcorpusid": 56598571,
          "isinfluential": false,
          "contexts": [
            "The mentioned approaches, coupled with efforts to conduct competitions on various aspects of historical document layout analysis have aided progress in this area [27]–[29]."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "ICFHR 2018 Competition On Document Image Analysis Tasks for Southeast Asian Palm Leaf Manuscripts",
            "abstract": "This paper presents the results of the Competition on Document Image Analysis Tasks for Southeast Asian Palm Leaf Manuscripts that was organized in the context of the 16th International Conference on Frontiers in Handwriting Recognition (ICFHR-2018). For this competition, three different corpus of palm leaf manuscripts written in three different scripts and languages (Balinese, Sundanese and Khmer) are used. Four Document Image Analysis (DIA) tasks are proposed as the challenges in this competition: binarization, text line segmentation, solated character/glyph recognition, and word transliteration. The results of this competition will be very useful in benchmarking analysis for the collection of palm leaf manuscripts, accelerating, evaluating and improving the performance of existing DIA system for a new type of document collection. This paper describes the competition details including the dataset, the evaluation measures used, a short description of each participant as well as the performance of the all submitted methods",
            "year": 2018,
            "venue": "International Conference on Frontiers in Handwriting Recognition",
            "authors": [
              {
                "authorId": "2154407",
                "name": "M. W. A. Kesiman"
              },
              {
                "authorId": "8700325",
                "name": "Dona Valy"
              },
              {
                "authorId": "1690398",
                "name": "J. Burie"
              },
              {
                "authorId": "39662991",
                "name": "E. Paulus"
              },
              {
                "authorId": "9165810",
                "name": "M. Suryani"
              },
              {
                "authorId": "8714538",
                "name": "S. Hadi"
              },
              {
                "authorId": "1782629",
                "name": "M. Verleysen"
              },
              {
                "authorId": "153584768",
                "name": "Sophea Chhun"
              },
              {
                "authorId": "1695766",
                "name": "J. Ogier"
              }
            ]
          }
        },
        {
          "citedcorpusid": 57246310,
          "isinfluential": false,
          "contexts": [
            "We found that this results in faster convergence and stabler training compared to using weights from a Mask-RCNN trained on ImageNet [45] or training from scratch."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "ImageNet: A large-scale hierarchical image database",
            "abstract": "",
            "year": 2009,
            "venue": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
            "authors": [
              {
                "authorId": "153302678",
                "name": "Jia Deng"
              },
              {
                "authorId": "144847596",
                "name": "Wei Dong"
              },
              {
                "authorId": "2166511",
                "name": "R. Socher"
              },
              {
                "authorId": "2040091191",
                "name": "Li-Jia Li"
              },
              {
                "authorId": "94451829",
                "name": "K. Li"
              },
              {
                "authorId": "48004138",
                "name": "Li Fei-Fei"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "In this respect, our annotation system is closer to the recent trend of collaborative, cloud/web-based annotation systems and services [37]–[39]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "16940217": {
      "citing_paper_info": {
        "title": "Delaunay and Graph Modal-Based Bagua Layout Text Line Extraction for Shui Script",
        "abstract": "",
        "year": 2015,
        "venue": "2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing",
        "authors": [
          {
            "authorId": "47998725",
            "name": "Zhang Guofeng"
          },
          {
            "authorId": "2097922335",
            "name": "Zhang Weiqin"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 2,
        "unique_cited_count": 0,
        "influential_count": 0,
        "detailed_records_count": 2
      },
      "cited_papers": [],
      "citation_details": [
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "The document image for processing was obtained from the social science projects of the country conducted by Liang Guanghua [12] et al.",
            "To verify the effectiveness of the proposed method, the 20 document images of text with Bagua layout in Jiugong in Shui Script were segmented [12], and the results are shown in Table 1.",
            "The document image for processing was obtained from the social science projects of the country conducted by Liang Guanghua [12] et al., that is, Volume of Jiugong in Shui Script of Systematic Research on Voice Language Database of Shui Script."
          ],
          "intents": [
            "['methodology']",
            "['methodology']",
            "--"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "The main task was to extract according to the different natures of the Delaunay triangular mesh generated by the character area and not by the character area in the document image."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {}
        }
      ]
    },
    "16585008": {
      "citing_paper_info": {
        "title": "Ancient document analysis based on text line extraction",
        "abstract": "",
        "year": 2008,
        "venue": "International Conference on Pattern Recognition",
        "authors": [
          {
            "authorId": "1729636",
            "name": "Florian Kleber"
          },
          {
            "authorId": "1706090",
            "name": "Robert Sablatnig"
          },
          {
            "authorId": "39054567",
            "name": "M. Gau"
          },
          {
            "authorId": "1919633",
            "name": "Heinz Miklas"
          }
        ]
      },
      "citation_summary": {
        "citation_count": 10,
        "unique_cited_count": 8,
        "influential_count": 0,
        "detailed_records_count": 10
      },
      "cited_papers": [
        "57510553",
        "9284084",
        "10232002",
        "60788031",
        "8746521",
        "61087042",
        "619938",
        "16669882"
      ],
      "citation_details": [
        {
          "citedcorpusid": 619938,
          "isinfluential": false,
          "contexts": [
            "the layout analysis of handwritten historical documents [1] and text line segmentation in handwritten documents [11, 10, 19] have been published.",
            "In [10] the characteristics and representation of text lines are defined by a baseline, a median line, an upper line, a lower line, overlapping components, and touching components.",
            "Further problems according to [10] are line fluctuation, line proximity, and writing fragmentation, which are influenced by the scribe."
          ],
          "intents": [
            "['background']",
            "['background']",
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Text line segmentation of historical documents: a survey",
            "abstract": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest.",
            "year": 2007,
            "venue": "International Journal of Document Analysis and Recognition (IJDAR)",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "2320185",
                "name": "Abderrazak Zahour"
              },
              {
                "authorId": "2080593310",
                "name": "B. Taconet"
              }
            ]
          }
        },
        {
          "citedcorpusid": 8746521,
          "isinfluential": false,
          "contexts": [
            "[17]) and make comparison of the results possible."
          ],
          "intents": [
            "['result']"
          ],
          "cited_paper_info": {
            "title": "Performance Evaluation and Benchmarking of Six-Page Segmentation Algorithms",
            "abstract": "",
            "year": 2008,
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "authors": [
              {
                "authorId": "1688013",
                "name": "F. Shafait"
              },
              {
                "authorId": "51027911",
                "name": "Daniel Keysers"
              },
              {
                "authorId": "1733858",
                "name": "T. Breuel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 9284084,
          "isinfluential": false,
          "contexts": [
            "Integral images are used for an efficient implementation of the binarization algorithm [18]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Efficient implementation of local adaptive thresholding techniques using integral images",
            "abstract": "",
            "year": 2008,
            "venue": "Electronic imaging",
            "authors": [
              {
                "authorId": "1688013",
                "name": "F. Shafait"
              },
              {
                "authorId": "51027911",
                "name": "Daniel Keysers"
              },
              {
                "authorId": "1733858",
                "name": "T. Breuel"
              }
            ]
          }
        },
        {
          "citedcorpusid": 10232002,
          "isinfluential": false,
          "contexts": [
            "Methods proposing algorithms for text line extraction include techniques based on projection profiles, the Hough transformation [11, 9], perceptual grouping/clustering [8], Adaptive Local Connectivity Maps (ALCM) [19] or e.g. methods based on smearing [10].",
            "the layout analysis of handwritten historical documents [1] and text line segmentation in handwritten documents [11, 10, 19] have been published.",
            "Methods proposing algorithms for text line extraction include techniques based on projection profiles, the Hough transformation [11, 9], perceptual grouping/clustering [8], Adaptive Local Connectivity Maps (ALCM) [19] or e."
          ],
          "intents": [
            "--",
            "['background']",
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Text extraction from gray scale historical document images using adaptive local connectivity map",
            "abstract": "",
            "year": 2005,
            "venue": "IEEE International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1708019",
                "name": "Zhixin Shi"
              },
              {
                "authorId": "1800513",
                "name": "Srirangaraj Setlur"
              },
              {
                "authorId": "1723877",
                "name": "V. Govindaraju"
              }
            ]
          }
        },
        {
          "citedcorpusid": 16669882,
          "isinfluential": false,
          "contexts": [
            "Methods proposing algorithms for text line extraction include techniques based on projection profiles, the Hough transformation [11, 9], perceptual grouping/clustering [8], Adaptive Local Connectivity Maps (ALCM) [19] or e."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "A Hough based algorithm for extracting text lines in handwritten documents",
            "abstract": "",
            "year": 1995,
            "venue": "Proceedings of the International Conference on Document Analysis and Recognition",
            "authors": [
              {
                "authorId": "1398902377",
                "name": "Laurence Likforman-Sulem"
              },
              {
                "authorId": "1409083785",
                "name": "Anahid Hanimyan"
              },
              {
                "authorId": "38138508",
                "name": "C. Faure"
              }
            ]
          }
        },
        {
          "citedcorpusid": 57510553,
          "isinfluential": false,
          "contexts": [
            "If entire libraries or parts of libraries of national archives or museums are digitized1, manual analysis or digital restoration of documents will not be feasible due to costs and time."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {
            "title": "Advances in Handwriting and Drawing: a multidisciplinary approach",
            "abstract": "",
            "year": 1994,
            "venue": "",
            "authors": [
              {
                "authorId": "38138508",
                "name": "C. Faure"
              },
              {
                "authorId": "3806481",
                "name": "P. Keuss"
              },
              {
                "authorId": "2915873",
                "name": "G. Lorette"
              },
              {
                "authorId": "2377682",
                "name": "A. Vinter"
              }
            ]
          }
        },
        {
          "citedcorpusid": 60788031,
          "isinfluential": false,
          "contexts": [
            "Afterwards the image is labelled with a standard label algorithm [5]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Computer and Robot Vision",
            "abstract": "",
            "year": 1995,
            "venue": "",
            "authors": [
              {
                "authorId": "1750195",
                "name": "E. Trucco"
              }
            ]
          }
        },
        {
          "citedcorpusid": 61087042,
          "isinfluential": false,
          "contexts": [
            "Afterwards the image is labelled with a standard label algorithm [5]."
          ],
          "intents": [
            "['methodology']"
          ],
          "cited_paper_info": {
            "title": "Computer and Robot Vision",
            "abstract": "From the Publisher: \nThis two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach. The discussion in \"Volume I\" focuses on image in, and image out or feature set out. \"Volume II\" covers the higher level techniques of illumination, perspective projection, analytical photogrammetry, motion, image matching, consistent labeling, model matching, and knowledge-based vision systems.",
            "year": 1991,
            "venue": "",
            "authors": [
              {
                "authorId": "1604429801",
                "name": "Robert M. Haralock"
              },
              {
                "authorId": "1809809",
                "name": "L. Shapiro"
              }
            ]
          }
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "5/N, 11 th century) [13].",
            "Therefore, this paper proposes a method for estimating the ruling on the basis of the text line information, on the one hand, and the a priori knowledge of the ruling scheme [13], on the other.",
            "Although this definition is suitable for handwritten documents with the aforementioned characteristics it cannot be applied to all types of scripts (e.g. Missale Sinaiticum which is written hanging as well as standing and floating [13])."
          ],
          "intents": [
            "--",
            "['methodology']",
            "['background']"
          ],
          "cited_paper_info": {}
        },
        {
          "citedcorpusid": null,
          "isinfluential": false,
          "contexts": [
            "The folios are degraded due to water influence (possible degradations of parchment see [3])."
          ],
          "intents": [
            "['background']"
          ],
          "cited_paper_info": {}
        }
      ]
    }
  }
}