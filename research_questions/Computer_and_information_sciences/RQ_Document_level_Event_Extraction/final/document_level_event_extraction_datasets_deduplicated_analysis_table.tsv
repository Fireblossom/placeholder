Name (extracted)	Citing Article	Citied Article	Features	Analysis_Source	Homepage_URL
80Days	https://doi.org/10.18653/v1/2020.acl-main.667	https://www.semanticscholar.org/paper/d8259bcbe9cb0cf5bad6ea25645f4407fc544a1c	The 80Days dataset is primarily used for training and evaluating models in document-level event extraction, focusing on identifying events across multiple sentences. It is also utilized for semantic role labeling, particularly with nominal predicates, and for exploring implicit arguments in a novel domain, covering a limited set of predicate types. This dataset enables researchers to address specific challenges in these areas by providing a structured resource for model development and evaluation.	cited_context	
ACE	https://doi.org/10.18653/v1/2021.findings-emnlp.32	https://www.semanticscholar.org/paper/0617dd6924df7a3491c299772b70e90507b195dc	The ACE dataset is used to define and benchmark the task of event extraction, specifically focusing on detecting event triggers and their arguments within sentences. It serves as a standard evaluation resource for comparing the performance of different event extraction systems, ensuring consistent and reliable assessment across various methodologies.	citing_context	
ACE 2005	https://doi.org/10.48550/arXiv.2309.14258, https://doi.org/10.1609/aaai.v35i14.17478, https://doi.org/10.18653/v1/D19-1032	https://www.semanticscholar.org/paper/50d06ea19d514e9d60347b3399214fe54949e64e	The ACE 2005 dataset is primarily used for event extraction and relation tasks, focusing on annotated news articles and broadcast transcripts. It serves as a benchmark for training and evaluating event extraction systems, particularly in identifying, classifying, and predicting event triggers and their arguments. The dataset supports cross-lingual transfer experiments among English, Chinese, and Arabic, ensuring annotation consistency. Its expert-annotated nature makes it a reliable resource for document-level event extraction, enabling researchers to address specific event types and their contextual nuances.	cited_context	
ACE 2005 (zh)	https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.18653/v1/D19-1585	The ACE 2005 (zh) dataset is used for Chinese event extraction, specifically focusing on identifying named entities, relations, and events within news articles. Researchers employ this dataset to develop and evaluate models that can accurately extract and classify these elements, enhancing the understanding and processing of Chinese text in news contexts.	cited_context	
ACE 2005 corpus	https://doi.org/10.1609/aaai.v35i14.17478		The ACE 2005 corpus is used to conduct experiments on relation and event mentions with manual annotations in English, Chinese, and Arabic, specifically focusing on document-level event extraction. This dataset enables researchers to analyze and extract events and their relations within documents, facilitating the development and evaluation of natural language processing systems across multiple languages.	cited_context	
ACE04	https://doi.org/10.48550/arXiv.2402.06973, https://doi.org/10.1109/IJCNN54540.2023.10191142	https://doi.org/10.18653/v1/2020.emnlp-main.751	The ACE04 dataset is used for evaluating event extraction systems, primarily through annotated news articles that include both events and entities. It serves as a benchmark to assess the performance of these systems, enabling researchers to compare different methodologies and approaches in event extraction. The dataset's detailed annotations facilitate precise evaluation and improvement of natural language processing techniques.	citing_context	
Ace05	https://doi.org/10.48550/arXiv.2402.06973, https://doi.org/10.1109/IJCNN54540.2023.10191142, https://doi.org/10.18653/v1/2022.acl-long.466	https://doi.org/10.18653/v1/2020.emnlp-main.751	The ACE05 dataset is used for evaluating event extraction systems, primarily through annotated news articles that include both events and entities. It serves as a benchmark to assess the performance of these systems, enabling researchers to compare different methodologies and approaches in event extraction. The dataset's detailed annotations facilitate precise evaluation and improvement of natural language processing techniques.; The ACE05 dataset is primarily used for evaluating and benchmarking event argument extraction systems in document-level event extraction tasks. It features 36 role types and is employed to identify, classify, and link arguments to events in text. Researchers use it to test and compare the performance of various extraction methods, including role-specific selectors and conditional generation approaches, focusing on improving the accuracy of event and argument identification in documents.	cited_context | citing_context	
AIDA Phase 1 data	https://doi.org/10.18653/v1/2020.acl-main.718	https://doi.org/10.1162/COLI_a_00110	The AIDA Phase 1 data is used for event and role annotations, primarily to serve as a baseline for comparing the coverage and scope of the RAMS dataset in semantic role labeling. It is also utilized for benchmarking against RAMS to evaluate implicit argument identification in nominal predicates. This dataset enables researchers to assess and improve the accuracy and comprehensiveness of semantic role labeling models.	cited_context	
ASTRE	https://doi.org/10.18653/v1/P19-1276	https://doi.org/10.1177/001316446002000104	The ASTRE dataset is mentioned in the citation context but lacks detailed descriptions of its usage, methodology, research questions, or specific characteristics. Therefore, there is insufficient evidence to provide a comprehensive synthesis of how this dataset is actually used in research.	cited_context	
automatically labeled data	https://doi.org/10.18653/v1/D18-1158	https://doi.org/10.18653/v1/P17-1038	The 'automatically labeled data' dataset is used to augment the DMCNN method for large-scale event extraction, providing additional labeled instances to enhance model training. This dataset enables researchers to improve the performance and scalability of event extraction models by increasing the volume of training data.	cited_context	
BC5CDR	https://doi.org/10.18653/v1/P19-1074	https://doi.org/10.18653/v1/D18-1247	The BC5CDR dataset is used for document-level relation extraction, specifically focusing on identifying chemical and disease relations within biomedical texts. This dataset enables researchers to develop and evaluate models that can accurately extract these relationships, enhancing the understanding of biomedical interactions and supporting various applications in biomedicine.	cited_context	
Beyond Nombank	https://doi.org/10.18653/V1/2021.NAACL-MAIN.69, https://doi.org/10.18653/v1/2020.acl-main.718	https://doi.org/10.1162/COLI_a_00110	The 'Beyond NomBank' dataset is used to extend semantic role labeling beyond traditional verb-based predicates, incorporating nominal and adjectival predicates. This extension enhances the coverage and accuracy of semantic role labeling systems, addressing research questions related to the identification and annotation of a broader range of linguistic predicates. The dataset's inclusion of diverse predicate types enables more comprehensive semantic analysis in natural language processing tasks.; The 'Beyond NomBank' dataset is used for semantic role labeling of implicit arguments for nominal predicates, particularly focusing on multi-sentence arguments and nominal event triggers. It extends NomBank by studying implicit arguments beyond existing resources, enhancing document-level event extraction for both verb and nominal predicates. This dataset supports research in improving the accuracy and scope of event extraction methodologies.	cited_context | citing_context	
CausalTB	https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.18653/v1/2022.acl-long.466	The CausalTB dataset is used for causal event extraction, specifically to identify causal relationships and chains in narrative texts. It provides annotated texts that enable researchers to evaluate and develop methods for recognizing these causal structures, enhancing the understanding of cause-and-effect dynamics in textual data.	cited_context	
Chfinann	https://doi.org/10.1145/3589335.3651921, https://doi.org/10.1145/3604237.3626844, https://doi.org/10.1109/ICASSP48485.2024.10447478 (+3) (+3)	https://doi.org/10.18653/v1/P18-4009	The ChFinAnn dataset is primarily used for evaluating document-level event extraction methods, particularly in the context of Chinese financial announcements. It focuses on identifying and extracting financial events from documents, often using F1 score as a performance metric. The dataset supports both trigger-based and trigger-free approaches, enabling researchers to assess the accuracy and performance of their methods in predicting event types and arguments within Chinese financial documents.; The ChfinAnn dataset is primarily used for document-level event extraction in the Chinese financial domain, serving as a benchmark for evaluating baseline models. It supports research through distant supervision and a two-stage extraction process involving sequence tagging and key-event-sentence detection, facilitating the development and assessment of event extraction models.	cited_context | citing_context	
Chifinann	https://doi.org/10.48550/arXiv.2206.03377, https://doi.org/10.1145/3698261	https://doi.org/10.18653/v1/D19-1032	The ChiFinAnn dataset is used for document-level event extraction in Chinese financial news, focusing on identifying and classifying financial events in announcements. It employs distant supervised alignment methods to generate automatically labeled data, enhancing model performance and accuracy in event detection. The dataset supports offline evaluations and analyzes the distribution of event records across sentences, enabling robust research in financial document event extraction.; The ChiFinAnn dataset is used for Chinese financial event extraction, focusing on document-level annotations to enhance and evaluate the accuracy of event detection models. It supports research by analyzing the distribution of event records across sentences in financial news articles and conducting offline evaluations to assess model performance in a document-level context.	cited_context | citing_context	
Chinese financial dataset from the Interdisciplinary Information Science Research at Tsinghua University	https://doi.org/10.1145/3584376.3584478	https://doi.org/10.18653/v1/D19-1032		citing_context	
CIFAR-10	https://doi.org/10.48550/arXiv.2402.06973	https://doi.org/10.18653/v1/P19-1213	The CIFAR-10 dataset is used to evaluate summarization systems, particularly focusing on different topics and evaluation criteria compared to MUC-4/MUCSUM. It enables researchers to assess the performance of summarization models across diverse content, providing a benchmark for comparing system effectiveness in generating concise and accurate summaries.	citing_context	
CMNEE	https://doi.org/10.48550/arXiv.2411.08708	https://doi.org/10.18653/v1/2020.acl-main.718	The CMNEE dataset is used for document-level event extraction, primarily focusing on open-source Chinese military and financial news. It evaluates event extraction models, particularly in handling multi-event documents. Non-Chinese researchers require translation to use the dataset. Its large scale and focus on specific domains enable detailed analysis and model evaluation in these areas.	citing_context	
CodRED	https://doi.org/10.48550/arXiv.2406.16021	https://doi.org/10.18653/v1/2020.acl-main.622	The CodRED dataset is used for acquiring knowledge through cross-document relation extraction, focusing on identifying and analyzing real-world entities and their relationships across diverse documents. This methodology enables researchers to explore complex interactions and connections within and between documents, enhancing the understanding of entity relationships in various contexts.	citing_context	
DCFEE	https://doi.org/10.48550/arXiv.2411.08708, https://doi.org/10.1145/3589335.3651921	https://doi.org/10.18653/v1/P18-4009	The DCFEE dataset is used for document-level financial event extraction in Chinese, focusing on multi-event documents. It leverages automatically labeled training data, constructed through a distant supervision approach, which is essential for training models in the financial domain. The dataset is particularly useful for Chinese-language research but requires translation for non-Chinese researchers. It enables the study of complex financial events within documents, enhancing the accuracy of event extraction models.	citing_context	
Do-cEE	https://doi.org/10.48550/arXiv.2404.12242	https://doi.org/10.18653/v1/D19-1032	The dataset 'Do-cEE' is mentioned in the citation context but lacks detailed descriptions of its usage, methodology, research questions, or specific characteristics. Therefore, there is insufficient evidence to provide a comprehensive description of how it is actually used in research.	cited_context	
Doc-EE	https://doi.org/10.48550/arXiv.2411.08708	https://doi.org/10.18653/v1/2020.acl-main.718	The Doc-EE dataset is primarily used for document-level event extraction, serving as a large-scale and fine-grained benchmark. It focuses on the complexity and fine-grained nature of events within documents, enabling researchers to investigate events across multiple sentences. The dataset facilitates the study of event extraction at the document level, though specific structural details and limitations are not fully described in the literature.	citing_context	
Docee	https://doi.org/10.48550/arXiv.2404.12242, https://doi.org/10.48550/arXiv.2209.02203	https://doi.org/10.18653/v1/2022.naacl-main.291	DocEE is used as a large-scale, fine-grained benchmark for document-level event extraction, containing 27,000+ events and 180,000+ arguments across 27,485 Wikipedia articles. It is employed to train and evaluate models for comprehensive and precise event and argument identification, particularly in cross-domain settings such as natural disasters. The dataset supports research by providing fine-grained annotations and a diverse range of event types, enabling the evaluation of model performance on complex, multi-event documents.; DocEE is utilized as a benchmark dataset for document-level event extraction, providing fine-grained annotations to evaluate models on complex, multi-event documents. Researchers use it to assess the performance of their models in identifying and extracting events within documents, focusing on the accuracy and robustness of these models in handling intricate textual data.	cited_context | citing_context	
DocRED	https://doi.org/10.18653/v1/2020.acl-main.670, https://doi.org/10.18653/v1/P19-1074, https://doi.org/10.18653/v1/2021.eacl-main.52	https://doi.org/10.18653/v1/P19-1074	The DocRED dataset is used for constructing and evaluating document-level relation extraction models, particularly focusing on cross-sentence relations in Wikipedia paragraphs. It enables researchers to develop and test models that can handle complex, multi-sentence relationships, and it is also used to compare performance metrics with other relation extraction datasets. This dataset facilitates advancements in understanding and processing document-level relational data.	cited_context	
DuEE	https://doi.org/10.48550/arXiv.2309.14258, https://doi.org/10.48550/arXiv.2404.12242	https://doi.org/10.18653/v1/D19-1585	The DuEE dataset is primarily used for Chinese event extraction, covering a wide range of domains such as finance and legal. It is employed to train and evaluate models on fine-grained event types, addressing the linguistic and cultural nuances of the Chinese language. The dataset enables researchers to assess event extraction performance in diverse contexts, enhancing model accuracy and robustness.	cited_context	
Duee-Fin	https://doi.org/10.48550/arXiv.2206.03377, https://doi.org/10.1145/3589335.3651921, https://doi.org/10.1109/ICASSP48485.2024.10447478 (+1) (+1)	https://doi.org/10.18653/v1/D19-1032	The DuEE-fin dataset is primarily used for document-level event extraction in financial documents, particularly in Chinese. It provides a large-scale resource for training and evaluating models focused on 13 financial event types and 92 event roles. Researchers use it to enhance the identification and classification of complex financial events, analyze the distribution of event types and records, and benchmark model performance on a challenging test set. The dataset's focus on document-level context aids in capturing events dispersed across multiple sentences, making it valuable for financial event analysis.; The DuEE-fin dataset is primarily used for financial event extraction, focusing on document-level annotations and evaluation. It is employed to assess event detection models, analyze the distribution of event types and records, and enhance the understanding of complex financial events. The dataset supports research by providing a diverse set of event types and a challenging test set, enabling comparisons with baseline models and real-time performance evaluations. It includes fine-grained event types and arguments, facilitating detailed analysis of event occurrences and contexts in financial documents.	cited_context | citing_context	
EventStoryLine	https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.18653/v1/2022.acl-long.466	The EventStoryLine dataset is used for event storyline extraction, focusing on identifying sequences of events within narratives. It evaluates the performance of event extraction models by analyzing narrative structures in text. This dataset enables researchers to assess how well models can capture and sequence events, enhancing the understanding of narrative dynamics in documents.	cited_context	
FEED	https://doi.org/10.1145/3589335.3651921	https://doi.org/10.18653/v1/P18-4009	The FEED dataset is used for document-level event extraction, specifically focusing on fine-grained event detection and argument linking. Researchers employ this dataset to enhance the precision of identifying and linking events within documents, addressing challenges in natural language processing. The dataset's fine-grained nature supports advanced methodologies for improving event extraction accuracy.	citing_context	
Few-NERD	https://doi.org/10.48550/arXiv.2209.02203	https://doi.org/10.18653/v1/2021.acl-long.248	The Few-NERD dataset is used to train and evaluate few-shot named entity recognition (NER) models, focusing on incorporating cross-sentence information to enhance document-level understanding. This dataset enables researchers to address the challenge of recognizing entities with limited labeled data, making it particularly useful for scenarios where annotated resources are scarce. The dataset's design supports the development of models that can generalize well from a few examples, thereby advancing the field of NER in low-resource settings.	citing_context	
Fewfc	https://doi.org/10.48550/arXiv.2404.12242, https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.48550/arXiv.2209.02693	The FewFC dataset is used to study overlapping events in document-level event extraction. Despite its small size and limited instances of overlapping events, it provides sentence-based annotations. Researchers employ this dataset to address challenges in identifying and extracting overlapping events within documents, leveraging its annotated sentences to develop and evaluate methodologies for handling such complexities.; The FewFC dataset is primarily used for few-shot event extraction, particularly in scenarios with limited labeled data. It is applied across various domains, including finance, to enhance model generalization and address rare events. Despite its small size and limited instances of overlapping events, the dataset facilitates research by enabling the study of event extraction from minimal annotated sentences.	cited_context | citing_context	
FKIE itf 2021	https://doi.org/10.18653/v1/2021.case-1.11	https://doi.org/10.18653/v1/2021.case-1.15	The FKIE itf 2021 dataset is used for event detection and clustering in document-level event extraction. Researchers employ small, densely fully connected neural networks to process the data. This methodology helps in identifying and grouping events within documents, enabling more accurate and nuanced event extraction. The dataset's structure supports these neural network models, facilitating the development and evaluation of event detection algorithms.	cited_context	
FrameNet	https://doi.org/10.18653/v1/2020.acl-main.718, https://doi.org/10.18653/v1/2020.acl-main.667	https://doi.org/10.1162/0891201053630264	FrameNet is used in research to analyze and label semantic roles, particularly focusing on the distinction between 'core' and 'non-core' frame elements. It supports semantic role labeling for nominal predicates and evaluates implicit arguments across various predicate types. This dataset enables detailed comparisons of different ontologies and domains, enhancing the understanding of event arguments and their semantic structures.	cited_context	
GDELT	https://doi.org/10.18653/v1/2021.case-1.11		The GDELT dataset is used to create a global database of events extracted from news sources, employing automated extraction and coding techniques. This enables large-scale analysis of events, facilitating research into global trends, conflicts, and societal changes by providing a comprehensive, systematically coded dataset of news events.	cited_context	
Glacier	https://doi.org/10.18653/V1/2020.ACL-MAIN.714	https://doi.org/10.3115/1699510.1699530	The GLACIER dataset is used for document-level event extraction, focusing on jointly considering phrasal and sentential evidence in information extraction tasks. This approach enhances the accuracy of extracting events by integrating context from phrases and sentences, addressing the need for more nuanced and context-aware extraction methods in natural language processing research.; The GLACIER dataset is used to enhance information extraction by jointly considering cross-sentential and phrasal evidence, which improves the model's ability to capture complex relationships in text. This approach addresses the need for more nuanced and context-aware extraction methods, enabling researchers to better understand and analyze intricate textual data.	cited_context | citing_context	
GNBusiness-Full-Text	https://doi.org/10.18653/v1/P19-1276	https://doi.org/10.18653/v1/N18-1202	The GNBusiness-Full-Text dataset is used to fine-tune the ELMo model for document-level event extraction, specifically enhancing contextual word representations in business-related texts. This approach improves the model's ability to identify and extract events within documents, addressing research questions related to the accuracy and context sensitivity of event extraction in business contexts.	cited_context	
Gun Violence Database (GVDB)	https://doi.org/10.18653/v1/2020.acl-main.718	https://doi.org/10.3115/1072064.1072066	The Gun Violence Database (GVDB) is used to study gun violence incidents by providing structured data for event extraction and analysis from news articles. Researchers employ this dataset to analyze event-related events, focusing on the detailed examination and extraction of information from textual sources to understand patterns and contexts of gun violence.	cited_context	
GVDB	https://doi.org/10.18653/v1/2020.acl-main.718	https://doi.org/10.18653/v1/N18-2108	The GVDB dataset is used for slot filling tasks, particularly to evaluate and adapt span-based models for multi-sentence argument linking. This involves assessing model performance in identifying and linking arguments across multiple sentences, enhancing the accuracy of argument extraction in complex textual contexts.	cited_context	
HiEve	https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.18653/v1/2022.acl-long.466	The HiEve dataset is used for hierarchical event extraction, providing annotated texts to extract event hierarchies and analyze their structural relationships. It focuses on understanding the organization and connections between events at various levels, enabling researchers to delve into complex event dynamics and relationships within documents.	cited_context	
ICEWS	https://doi.org/10.18653/v1/2021.case-1.11		The Integrated Crisis Early Warning System (ICEWS) dataset is utilized to compile a comprehensive database of political events, focusing on automated event detection and coding from news articles. This dataset enables researchers to analyze large volumes of textual data, extracting and categorizing political events with precision. It supports methodologies centered on natural language processing and machine learning, facilitating the study of political dynamics and conflict prediction.	cited_context	
IREE	https://doi.org/10.1145/3589335.3651921	https://doi.org/10.1007/978-981-19-7596-7_16	The IREE dataset is used to extract fine-grained events from investment-related news, specifically focusing on 59 types of risk events across five major news categories. Researchers employ this dataset to identify and analyze these risk events, enhancing understanding of financial risks and their reporting in news media. The dataset's detailed categorization of events enables precise event extraction and analysis in financial contexts.	citing_context	
KBP 2016	https://doi.org/10.48550/arXiv.2309.14258	https://www.semanticscholar.org/paper/50d06ea19d514e9d60347b3399214fe54949e64e	The KBP 2016 dataset is used to predict event triggers in document-level event extraction, focusing on identifying specific event types within complex texts. This involves methodologies that analyze and classify textual data to pinpoint events, enabling researchers to enhance the accuracy of event detection in natural language processing tasks.	cited_context	
KBP 2017	https://doi.org/10.48550/arXiv.2309.14258	https://www.semanticscholar.org/paper/50d06ea19d514e9d60347b3399214fe54949e64e	The KBP 2017 dataset is used to predict event triggers in document-level event extraction, focusing on identifying specific event types within complex texts. This involves methodologies that analyze and classify textual data to pinpoint events, enabling researchers to enhance the accuracy of event detection in natural language processing tasks.	cited_context	
LEVEN	https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.18653/v1/D19-1585	The LEVEN dataset is primarily used for document-level event extraction, focusing on legal event detection and event prediction in narratives. It supports the evaluation of event extraction models, particularly in handling document-level event coreference resolution and identifying event relationships. The dataset is also applied to event extraction in low-resource languages, aiding in scenarios with limited training data. Its annotated legal documents and narrative contexts enable robust training and evaluation of event extraction systems.	cited_context	
MATRES	https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.18653/v1/2021.findings-emnlp.416	The MATRES dataset is primarily used for temporal relation extraction and classification, focusing on identifying and evaluating the temporal relationships between events in text, such as before, after, and simultaneous events. It enables researchers to address the challenge of determining the temporal ordering of events, enhancing the accuracy of temporal relation extraction methodologies.	cited_context	
Maven	https://doi.org/10.48550/arXiv.2404.12242, https://doi.org/10.48550/arXiv.2411.08708, https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.18653/v1/2020.emnlp-main.129	The MAVEN dataset is used for training and evaluating event detection models across various domains, focusing on 168 event types. It supports general domain event detection tasks, particularly useful for evaluating models on categories like 'Attack' and 'Defending'. With 19,640 labeled events, MAVEN provides a large-scale resource for enhancing model performance and robustness in diverse contexts.; The MAVEN dataset is primarily used for large-scale event detection in general domain texts, covering a wide range of event types. It is employed to train and evaluate event detection models, particularly focusing on categories such as 'Attack' and 'Defending.' The dataset supports multi-aspect, multi-grained event extraction, enabling researchers to address various levels of event granularity and complexity. Its large scale and diverse event types make it suitable for evaluating the performance of event detection systems across different contexts.	cited_context | citing_context	
MAVEN-ERE	https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.18653/v1/2021.findings-emnlp.416	The MAVEN-ERE dataset is used for event relation extraction and entity recognition, with a focus on cross-document coreference resolution and consistency. It extends MAVEN by adding event relation annotations and new event and relation types. Researchers use it to train and evaluate models like RoBERTa for event detection, relation extraction, and cross-document coherence in a general domain. The dataset supports both academic research and practical applications in online systems, enhancing the accuracy and robustness of event and relation extraction tasks.	cited_context	
Message Understanding Conference-6	https://doi.org/10.48550/arXiv.2404.12242	https://www.semanticscholar.org/paper/8955186c6000decdf713acf1423468df50f427e1	The Message Understanding Conference-6 dataset is used to evaluate systems for processing and understanding terrorist attack events. It focuses on information extraction and event detection methodologies, enabling researchers to assess the accuracy and effectiveness of these systems in identifying and extracting relevant event data from documents.; The Message Understanding Conference-6 dataset is used to evaluate systems for processing and understanding terrorist attack events. It focuses on information extraction and event detection methodologies, enabling researchers to assess the accuracy and effectiveness of these systems in identifying and extracting relevant event information from documents.	cited_context | citing_context	
MMAD	https://doi.org/10.18653/v1/2021.case-1.11		The MMAD dataset is used to generate a database of violent events, employing automated methods for conflict monitoring and analysis. This involves applying machine learning techniques to identify and categorize violent events from documents. The dataset enables researchers to enhance the accuracy and efficiency of conflict analysis by providing structured data for training and testing algorithms.	cited_context	
MNEE	https://doi.org/10.48550/arXiv.2404.12242	https://doi.org/10.18653/v1/D19-1032	The MNEE dataset is used for multi-sentence argument linking in document-level event extraction, specifically enhancing the ability to link arguments across sentences. This methodology involves analyzing and connecting event-related arguments within and between sentences, which improves the coherence and accuracy of event extraction in documents. The dataset's focus on cross-sentence relationships enables more nuanced and contextually rich event extraction, addressing research questions related to the structural and semantic connections between events and their arguments.	cited_context	
MUC	https://doi.org/10.48550/arXiv.2411.08708	https://doi.org/10.3115/1071958.1071960	The MUC dataset is used for document-level event extraction, specifically focusing on message understanding and evaluation in news articles. It enables researchers to analyze and extract events from textual data, enhancing the accuracy of event identification and context understanding in news corpora. This dataset supports methodologies aimed at improving natural language processing techniques for event detection.	citing_context	
MUC 4	https://doi.org/10.18653/v1/P19-1276	https://doi.org/10.3115/v1/P15-1019	The MUC 4 dataset is used in research for document-level event extraction, specifically for implementing automatic greedy slot mapping and comparing performance with state-of-the-art models. It focuses on event extraction, role assignment, and entity representation using triples, enabling detailed analysis and improvement of natural language processing techniques.	cited_context	
MUC datasets	https://doi.org/10.18653/v1/2020.acl-main.718	https://doi.org/10.3115/1072064.1072066	The MUC datasets are used to evaluate argument linking and slot filling tasks in information extraction from text. These datasets provide annotated examples that facilitate training and evaluation, enabling researchers to assess the performance of their models in identifying and linking event arguments within documents.	cited_context	
MUC-3	https://doi.org/10.18653/v1/2022.acl-long.274		The MUC-3 dataset is used to evaluate information extraction systems, specifically focusing on the performance of entity recognition and relation extraction in news articles. It enables researchers to assess the accuracy and effectiveness of these systems in identifying and linking entities within textual content, providing a benchmark for comparing different methodologies.	cited_context	
Muc-4	https://doi.org/10.1145/3589335.3651921, https://doi.org/10.48550/arXiv.2402.06973, https://doi.org/10.1145/3578741.3578768 (+1) (+2)	https://doi.org/10.3115/1072064.1072066	The MUC-4 dataset is primarily used for document-level event extraction, focusing on complex event structures and relationships in news articles. It is utilized to evaluate and compare event extraction systems, particularly in template-filling tasks to identify specific event role fillers. The dataset also supports the creation of benchmarks like MUCSUM for evaluating summarization methods and comparing multi-granularity contextualized encoding techniques.; The MUC-4 dataset is primarily used to evaluate and train neural and traditional information extraction (IE) systems, focusing on document-level event extraction from news articles, particularly those concerning terrorist incidents in Latin America. It serves as a benchmark for comparing model performance, assessing event identification, linking, and template filling tasks. The dataset enables researchers to test and improve the accuracy and completeness of event extraction methodologies.	cited_context | citing_context	
MUC1	https://www.semanticscholar.org/paper/0fb0595be9400709a79040a1a7ef5346d331e28e	https://doi.org/10.3115/1071958.1071960	The MUC1 dataset is used to define and simplify the event-based template-filling task, facilitating easier application in document-level event extraction. It enables researchers to focus on extracting structured information from documents by providing a standardized framework, enhancing the clarity and consistency of event extraction methodologies.	cited_context	
MUC3	https://doi.org/10.18653/v1/2021.eacl-main.52	https://doi.org/10.3115/1071958.1071960	The MUC3 dataset is used as a foundational resource for the Relation Extraction and Event (REE) task, simplified to align with prior research methodologies. It supports the development and evaluation of REE systems by providing a standardized benchmark. This dataset enables researchers to compare their methods against established baselines and advance the state-of-the-art in REE.	cited_context	
Nom-Bank	https://doi.org/10.18653/v1/2020.acl-main.718	https://doi.org/10.1162/COLI_a_00110	The Nom-Bank dataset is expanded and utilized to explore implicit arguments for nominal predicates, enhancing the original dataset with additional annotations and data. This expansion supports research into the linguistic and semantic properties of nominal predicates, enabling more nuanced analysis and understanding of their roles in text.	cited_context	
Nombank	https://doi.org/10.18653/v1/2020.acl-main.667	https://www.semanticscholar.org/paper/d8259bcbe9cb0cf5bad6ea25645f4407fc544a1c	The Nombank dataset is used to study implicit arguments for nominal predicates, particularly focusing on a limited set of predicate types within the G&C domain. This involves analyzing the syntactic and semantic roles of these predicates to understand their implicit arguments. The dataset's detailed annotations enable researchers to explore specific linguistic phenomena and refine models for argument identification.	cited_context	
On5V	https://doi.org/10.18653/V1/2021.NAACL-MAIN.69		The dataset 'ON5V' is mentioned in the citation context but lacks detailed descriptions of its usage, methodology, research questions, or specific characteristics. Therefore, there is insufficient evidence to provide a comprehensive synthesis of how this dataset is actually used in research.; The ON5V dataset is utilized for verb valency annotation, focusing on enhancing the understanding of argument structure in complex sentences. This involves detailed analysis and annotation of verbs to identify and describe their syntactic and semantic arguments. The dataset enables researchers to explore the intricacies of sentence structure, contributing to more accurate models of linguistic analysis.	cited_context | citing_context	
PHOENIX	https://doi.org/10.18653/v1/2021.case-1.11		The PHOENIX dataset is used to develop a database of political and social events through automated techniques for event extraction and classification. This involves leveraging advanced methodologies to identify and categorize events from documents, enabling researchers to analyze patterns and dynamics in political and social phenomena. The dataset's automated extraction capabilities enhance the scalability and accuracy of event data compilation, supporting detailed and systematic research into these areas.	cited_context	
ProMED	https://doi.org/10.18653/v1/2022.acl-long.274	https://doi.org/10.18653/V1/2021.NAACL-MAIN.70	The ProMED dataset is used to train and evaluate neural-based information extraction models, particularly focusing on disease outbreak reports. It is employed to compare and assess the performance of models like DyGIE++, GTT, and DyGIE in extracting disease-related events from specialized documents, including news articles and scientific texts. The dataset's smaller size allows for extensive training, such as 36 epochs for the GTT model, enabling researchers to highlight the models' capabilities in handling specialized language and document-level event extraction.	cited_context	
PropBank	https://doi.org/10.18653/v1/2020.acl-main.718	https://doi.org/10.1162/0891201053630264	The PropBank dataset is used to analyze the distinction between 'core' and 'non-core' frame elements, which aids in understanding event arguments in semantic roles. This analysis contributes to the broader field of semantic role labeling, focusing on the precise identification and categorization of arguments within events. The dataset's detailed annotation of these elements enables researchers to develop and refine methodologies for more accurate semantic parsing and event extraction.	cited_context	
Rams	https://doi.org/10.48550/arXiv.2411.08708, https://doi.org/10.1145/3589335.3651921, https://doi.org/10.48550/arXiv.2205.00241 (+4) (+3)	https://doi.org/10.18653/v1/2020.acl-main.718	The RAMS dataset is used for document-level event extraction, focusing on identifying and classifying events and their arguments across multiple sentences. It supports multi-sentence argument linking and generative approaches for event entity extraction. With 9124 documents, it provides a large-scale resource for training and evaluating models, particularly for fine-grained event types and complex event structures. Research using RAMS evaluates model performance using metrics like Span F1 and Head F1, and provides detailed data statistics on event distribution and characteristics.; The RAMS dataset is used for evaluating and improving event argument extraction, particularly in the context of multi-sentence argument linking and role-specific annotations. It is employed to compare the scale and coverage of event argument datasets, adapt span-based models, and enhance semantic role labeling. The dataset's large size and broad coverage make it suitable for comprehensive training and evaluation, especially for identifying and linking arguments across sentences and handling complex events with multiple roles.	cited_context | citing_context	
RAMS dataset	https://doi.org/10.18653/v1/2022.acl-long.466	https://doi.org/10.18653/v1/2020.acl-main.718	The RAMS dataset is used to evaluate and compare the performance of EEQA-BART and BART-Gen models in document-level event argument extraction. It focuses on assessing the accuracy of argument classification within documents, enabling researchers to analyze and enhance model capabilities in understanding complex event structures.	cited_context	
RichERE	https://doi.org/10.48550/arXiv.2309.14258	https://www.semanticscholar.org/paper/50d06ea19d514e9d60347b3399214fe54949e64e	The RichERE dataset is primarily used for enhancing event and entity extraction in text, focusing on identifying event types, argument roles, and event triggers. It supports rich event role extraction and detailed semantic analysis, enabling researchers to improve the depth and breadth of information extracted from documents. This dataset facilitates the prediction of event triggers and the extraction of complex relationships, making it valuable for detailed document-level event extraction tasks.	cited_context	
Roles Across Multiple Sentences (Rams)	https://doi.org/10.18653/v1/2021.acl-long.492	https://doi.org/10.18653/v1/2020.acl-main.718	The Roles Across Multiple Sentences (RAMS) dataset is used for multi-sentence argument linking, specifically to connect arguments across multiple sentences. It provides annotations that facilitate the task of identifying and linking event arguments within and across sentences, enabling research in natural language processing focused on coherent event representation and argument structure.; The 'Roles Across Multiple Sentences (RAMS)' dataset is mentioned in research contexts but lacks detailed descriptions of its usage. There is no explicit evidence of its application in document-level event extraction or any specific methodology, research questions, or characteristics. Its actual role in research remains unspecified based on the provided information.	cited_context | citing_context	
SCIERC	https://doi.org/10.18653/v1/2020.acl-main.670	https://doi.org/10.18653/v1/D18-1360	The SCIERC dataset is used for information extraction from scientific article abstracts, focusing on identifying entities, relations, and coreferences to construct scientific knowledge graphs. It supports the annotation of entity mentions, coreference information, and binary relations. The dataset is also used to evaluate and compare model performance on document-level event extraction tasks, particularly in scientific documents.	cited_context	
SciREX	https://doi.org/10.18653/v1/2022.acl-long.274, https://doi.org/10.18653/v1/2020.acl-main.670	https://doi.org/10.18653/v1/P19-1513	The SciREX dataset is primarily used for evaluating and comparing neural models in scientific document information extraction, focusing on tasks such as event extraction, entity recognition, and relation identification. It is employed to train and test models like DyGIE++ and GTT, assessing their performance in handling technical content and document-level tasks. The dataset facilitates research by providing a benchmark for model effectiveness in scientific document processing, highlighting challenges and enabling comparisons across different subtasks.	cited_context	
SemEval shared task training set	https://doi.org/10.18653/v1/2020.acl-main.718	https://doi.org/10.1162/0891201053630264	The SemEval shared task training set is used to highlight the limited scale of datasets for non-local argument annotation, featuring 1,370 frame instantiations over 438 sentences. It serves as a benchmark to illustrate the challenges and constraints in annotating non-local arguments, enabling researchers to assess and develop methods for handling smaller, more complex datasets in natural language processing tasks.	cited_context	
SemEval-2010	https://doi.org/10.18653/v1/2020.acl-main.667	https://www.semanticscholar.org/paper/d8259bcbe9cb0cf5bad6ea25645f4407fc544a1c	The SemEval-2010 dataset is primarily used for evaluating semantic role labeling systems, particularly focusing on identifying implicit arguments for nominal predicates. This dataset supports research in document-level event extraction by providing annotated data that helps assess the performance of systems in recognizing and labeling these implicit arguments, enhancing the accuracy of event extraction tasks.	cited_context	
SemEval-2010 Task 10	https://doi.org/10.18653/v1/2020.acl-main.718	https://doi.org/10.1162/COLI_a_00110	The SemEval-2010 Task 10 dataset is primarily used to study implicit semantic role labeling in narrative contexts, focusing on the identification of non-local arguments in stories. Researchers employ this dataset to develop and evaluate methods for recognizing and labeling these implicit roles, which are crucial for understanding the deeper semantics of narratives. This dataset enables detailed analysis and modeling of complex linguistic structures in storytelling.	cited_context	
TAC KBP	https://doi.org/10.48550/arXiv.2309.14258	https://www.semanticscholar.org/paper/50d06ea19d514e9d60347b3399214fe54949e64e	The TAC KBP dataset is utilized for knowledge base population, specifically for extracting entities, relations, and events from diverse text sources. It is employed to evaluate entity, relation, and event extraction systems, with a focus on handling complex event structures and cross-document coreference. This dataset enables researchers to assess and improve the accuracy and robustness of natural language processing systems in populating structured knowledge bases.	cited_context	
TACRED	https://doi.org/10.18653/v1/P19-1074	https://doi.org/10.18653/v1/D18-1247	The TACRED dataset is primarily used as a benchmark for evaluating sentence-level relation extraction in the context of document-level event extraction. It enables researchers to assess the performance of models in identifying and classifying relationships between entities within sentences. This dataset supports the development and testing of methodologies aimed at improving relation extraction accuracy, which is crucial for advancing natural language processing tasks.	cited_context	
TB-Dense	https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.18653/v1/2021.findings-emnlp.416	The TB-Dense dataset is used for dense event annotation in narrative texts, particularly in news articles. It enhances the granularity of event extraction by providing detailed event structures and focusing on temporal relations. Researchers employ this dataset to study fine-grained event ordering, which aids in understanding complex narrative sequences and their temporal dynamics.	cited_context	
TCR	https://doi.org/10.48550/arXiv.2309.14258	https://doi.org/10.18653/v1/2021.findings-emnlp.416	The TCR dataset is primarily used for causal relation extraction, focusing on identifying cause-effect relationships in text and between events. It is also applied for temporal relation extraction, specifically to analyze event ordering and duration. This dataset enables researchers to assess and improve algorithms for extracting these relational structures, enhancing the understanding of complex textual data.	cited_context	
Wikidata	https://doi.org/10.18653/v1/P19-1074	https://doi.org/10.3115/1690219.1690287	Wikidata is used in conjunction with Wikipedia documents to align and select articles for human annotation under the distant supervision assumption. This methodology supports the creation of annotated datasets, enabling research in areas such as information extraction and natural language processing. The alignment process leverages the structured data in Wikidata to enhance the accuracy and efficiency of document selection for annotation tasks.	cited_context	
Wikievents	https://doi.org/10.48550/arXiv.2411.08708, https://doi.org/10.1145/3578741.3578768, https://doi.org/10.48550/arXiv.2404.12242 (+3) (+3)	https://doi.org/10.18653/V1/2021.NAACL-MAIN.69	The WikiEvents dataset is primarily used for document-level event extraction, focusing on event detection, entity linking, and argument extraction in Wikipedia articles. Researchers employ it to evaluate and advance conditional generation methods, particularly in overcoming input sequence length limitations. The dataset's 246 documents facilitate detailed analysis and provide data statistics on event and relation distributions, enabling robust performance evaluations and methodological improvements.; The WIKIEVENTS dataset is primarily used for evaluating and training document-level event argument extraction models, particularly focusing on conditional generation techniques. It provides a large-scale resource derived from Wikipedia articles, enabling researchers to assess the effectiveness of role-specific selectors in improving argument classification and linking arguments to events. The dataset includes 59 role types, which are crucial for identifying and disambiguating event arguments, and is often used to measure Argument Head F1 scores, emphasizing the importance of headword matching in argument identification.	cited_context | citing_context	
Wikipedia documents	https://doi.org/10.18653/v1/P19-1074	https://doi.org/10.3115/1690219.1690287	The Wikipedia documents dataset is used to align with Wikidata for selecting documents for human annotation under the distant supervision assumption. This methodology leverages the structured data in Wikidata to identify and annotate relevant documents, facilitating the creation of annotated datasets for various natural language processing tasks.	cited_context	
Wikipedia-based dataset	https://doi.org/10.48550/arXiv.2411.08708	https://doi.org/10.18653/V1/2021.NAACL-MAIN.69	The Wikipedia-based dataset is used to study the distribution of event arguments across sentences, particularly those appearing outside the event trigger sentence. Researchers employ conditional generation methods to analyze these distributions, focusing on how event arguments are spread beyond the immediate context of the event trigger. This approach helps in understanding the structural and contextual aspects of event representation in text.	citing_context	
