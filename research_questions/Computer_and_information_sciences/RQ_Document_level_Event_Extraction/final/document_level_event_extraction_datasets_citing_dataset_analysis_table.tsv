Name (extracted)	Citing Article	Citied Article	Features
RAMS	https://doi.org/10.48550/arXiv.2411.08708, https://doi.org/10.1145/3589335.3651921, https://doi.org/10.48550/arXiv.2205.00241 (+4)	https://doi.org/10.18653/v1/2020.acl-main.718	The RAMS dataset is used for document-level event extraction, focusing on identifying and classifying events and their arguments across multiple sentences. It supports multi-sentence argument linking and generative approaches for event entity extraction. With 9124 documents, it provides a large-scale resource for training and evaluating models, particularly for fine-grained event types and complex event structures. Research using RAMS evaluates model performance using metrics like Span F1 and Head F1, and provides detailed data statistics on event distribution and characteristics.
DuEE-fin	https://doi.org/10.48550/arXiv.2206.03377, https://doi.org/10.1145/3589335.3651921, https://doi.org/10.1109/ICASSP48485.2024.10447478 (+1)	https://doi.org/10.18653/v1/D19-1032	The DuEE-fin dataset is primarily used for document-level event extraction in financial documents, particularly in Chinese. It provides a large-scale resource for training and evaluating models focused on 13 financial event types and 92 event roles. Researchers use it to enhance the identification and classification of complex financial events, analyze the distribution of event types and records, and benchmark model performance on a challenging test set. The dataset's focus on document-level context aids in capturing events dispersed across multiple sentences, making it valuable for financial event analysis.
WikiEvents	https://doi.org/10.48550/arXiv.2411.08708, https://doi.org/10.1145/3578741.3578768, https://doi.org/10.48550/arXiv.2404.12242 (+3)	https://doi.org/10.18653/V1/2021.NAACL-MAIN.69	The WikiEvents dataset is primarily used for document-level event extraction, focusing on event detection, entity linking, and argument extraction in Wikipedia articles. Researchers employ it to evaluate and advance conditional generation methods, particularly in overcoming input sequence length limitations. The dataset's 246 documents facilitate detailed analysis and provide data statistics on event and relation distributions, enabling robust performance evaluations and methodological improvements.
CMNEE	https://doi.org/10.48550/arXiv.2411.08708	https://doi.org/10.18653/v1/2020.acl-main.718	The CMNEE dataset is used for document-level event extraction, primarily focusing on open-source Chinese military and financial news. It evaluates event extraction models, particularly in handling multi-event documents. Non-Chinese researchers require translation to use the dataset. Its large scale and focus on specific domains enable detailed analysis and model evaluation in these areas.
DocEE	https://doi.org/10.48550/arXiv.2209.02203, https://doi.org/10.48550/arXiv.2404.12242	https://doi.org/10.18653/v1/2022.naacl-main.291	DocEE is used as a large-scale, fine-grained benchmark for document-level event extraction, containing 27,000+ events and 180,000+ arguments across 27,485 Wikipedia articles. It is employed to train and evaluate models for comprehensive and precise event and argument identification, particularly in cross-domain settings such as natural disasters. The dataset supports research by providing fine-grained annotations and a diverse range of event types, enabling the evaluation of model performance on complex, multi-event documents.
DCFEE	https://doi.org/10.48550/arXiv.2411.08708, https://doi.org/10.1145/3589335.3651921	https://doi.org/10.18653/v1/P18-4009	The DCFEE dataset is used for document-level financial event extraction in Chinese, focusing on multi-event documents. It leverages automatically labeled training data, constructed through a distant supervision approach, which is essential for training models in the financial domain. The dataset is particularly useful for Chinese-language research but requires translation for non-Chinese researchers. It enables the study of complex financial events within documents, enhancing the accuracy of event extraction models.
ChFinAnn	https://doi.org/10.1145/3589335.3651921, https://doi.org/10.1145/3604237.3626844, https://doi.org/10.1109/ICASSP48485.2024.10447478 (+3)	https://doi.org/10.18653/v1/P18-4009	The ChFinAnn dataset is primarily used for evaluating document-level event extraction methods, particularly in the context of Chinese financial announcements. It focuses on identifying and extracting financial events from documents, often using F1 score as a performance metric. The dataset supports both trigger-based and trigger-free approaches, enabling researchers to assess the accuracy and performance of their methods in predicting event types and arguments within Chinese financial documents.
MAVEN	https://doi.org/10.48550/arXiv.2411.08708, https://doi.org/10.48550/arXiv.2404.12242	https://doi.org/10.18653/v1/2020.emnlp-main.129	The MAVEN dataset is used for training and evaluating event detection models across various domains, focusing on 168 event types. It supports general domain event detection tasks, particularly useful for evaluating models on categories like 'Attack' and 'Defending'. With 19,640 labeled events, MAVEN provides a large-scale resource for enhancing model performance and robustness in diverse contexts.
ChiFinAnn	https://doi.org/10.48550/arXiv.2206.03377, https://doi.org/10.1145/3698261	https://doi.org/10.18653/v1/D19-1032	The ChiFinAnn dataset is used for document-level event extraction in Chinese financial news, focusing on identifying and classifying financial events in announcements. It employs distant supervised alignment methods to generate automatically labeled data, enhancing model performance and accuracy in event detection. The dataset supports offline evaluations and analyzes the distribution of event records across sentences, enabling robust research in financial document event extraction.
MUC-4	https://doi.org/10.1145/3589335.3651921, https://doi.org/10.48550/arXiv.2402.06973, https://doi.org/10.1145/3578741.3578768 (+1)	https://doi.org/10.3115/1072064.1072066	The MUC-4 dataset is primarily used for document-level event extraction, focusing on complex event structures and relationships in news articles. It is utilized to evaluate and compare event extraction systems, particularly in template-filling tasks to identify specific event role fillers. The dataset also supports the creation of benchmarks like MUCSUM for evaluating summarization methods and comparing multi-granularity contextualized encoding techniques.
FEED	https://doi.org/10.1145/3589335.3651921	https://doi.org/10.18653/v1/P18-4009	The FEED dataset is used for document-level event extraction, specifically focusing on fine-grained event detection and argument linking. Researchers employ this dataset to enhance the precision of identifying and linking events within documents, addressing challenges in natural language processing. The dataset's fine-grained nature supports advanced methodologies for improving event extraction accuracy.
Doc-EE	https://doi.org/10.48550/arXiv.2411.08708	https://doi.org/10.18653/v1/2020.acl-main.718	The Doc-EE dataset is primarily used for document-level event extraction, serving as a large-scale and fine-grained benchmark. It focuses on the complexity and fine-grained nature of events within documents, enabling researchers to investigate events across multiple sentences. The dataset facilitates the study of event extraction at the document level, though specific structural details and limitations are not fully described in the literature.
MUC	https://doi.org/10.48550/arXiv.2411.08708	https://doi.org/10.3115/1071958.1071960	The MUC dataset is used for document-level event extraction, specifically focusing on message understanding and evaluation in news articles. It enables researchers to analyze and extract events from textual data, enhancing the accuracy of event identification and context understanding in news corpora. This dataset supports methodologies aimed at improving natural language processing techniques for event detection.
Message Understanding Conference-6	https://doi.org/10.48550/arXiv.2404.12242	https://www.semanticscholar.org/paper/8955186c6000decdf713acf1423468df50f427e1	The Message Understanding Conference-6 dataset is used to evaluate systems for processing and understanding terrorist attack events. It focuses on information extraction and event detection methodologies, enabling researchers to assess the accuracy and effectiveness of these systems in identifying and extracting relevant event data from documents.
CIFAR-10	https://doi.org/10.48550/arXiv.2402.06973	https://doi.org/10.18653/v1/P19-1213	The CIFAR-10 dataset is used to evaluate summarization systems, particularly focusing on different topics and evaluation criteria compared to MUC-4/MUCSUM. It enables researchers to assess the performance of summarization models across diverse content, providing a benchmark for comparing system effectiveness in generating concise and accurate summaries.
ACE05	https://doi.org/10.48550/arXiv.2402.06973, https://doi.org/10.1109/IJCNN54540.2023.10191142	https://doi.org/10.18653/v1/2020.emnlp-main.751	The ACE05 dataset is used for evaluating event extraction systems, primarily through annotated news articles that include both events and entities. It serves as a benchmark to assess the performance of these systems, enabling researchers to compare different methodologies and approaches in event extraction. The dataset's detailed annotations facilitate precise evaluation and improvement of natural language processing techniques.
ACE04	https://doi.org/10.48550/arXiv.2402.06973, https://doi.org/10.1109/IJCNN54540.2023.10191142	https://doi.org/10.18653/v1/2020.emnlp-main.751	The ACE04 dataset is used for evaluating event extraction systems, primarily through annotated news articles that include both events and entities. It serves as a benchmark to assess the performance of these systems, enabling researchers to compare different methodologies and approaches in event extraction. The dataset's detailed annotations facilitate precise evaluation and improvement of natural language processing techniques.
Beyond NomBank	https://doi.org/10.18653/V1/2021.NAACL-MAIN.69		The 'Beyond NomBank' dataset is used to extend semantic role labeling beyond traditional verb-based predicates, incorporating nominal and adjectival predicates. This extension enhances the coverage and accuracy of semantic role labeling systems, addressing research questions related to the identification and annotation of a broader range of linguistic predicates. The dataset's inclusion of diverse predicate types enables more comprehensive semantic analysis in natural language processing tasks.
CodRED	https://doi.org/10.48550/arXiv.2406.16021	https://doi.org/10.18653/v1/2020.acl-main.622	The CodRED dataset is used for acquiring knowledge through cross-document relation extraction, focusing on identifying and analyzing real-world entities and their relationships across diverse documents. This methodology enables researchers to explore complex interactions and connections within and between documents, enhancing the understanding of entity relationships in various contexts.
Wikipedia-based dataset	https://doi.org/10.48550/arXiv.2411.08708	https://doi.org/10.18653/V1/2021.NAACL-MAIN.69	The Wikipedia-based dataset is used to study the distribution of event arguments across sentences, particularly those appearing outside the event trigger sentence. Researchers employ conditional generation methods to analyze these distributions, focusing on how event arguments are spread beyond the immediate context of the event trigger. This approach helps in understanding the structural and contextual aspects of event representation in text.
IREE	https://doi.org/10.1145/3589335.3651921	https://doi.org/10.1007/978-981-19-7596-7_16	The IREE dataset is used to extract fine-grained events from investment-related news, specifically focusing on 59 types of risk events across five major news categories. Researchers employ this dataset to identify and analyze these risk events, enhancing understanding of financial risks and their reporting in news media. The dataset's detailed categorization of events enables precise event extraction and analysis in financial contexts.
Roles Across Multiple Sentences (RAMS)	https://doi.org/10.18653/v1/2021.acl-long.492	https://doi.org/10.18653/v1/2020.acl-main.718	The Roles Across Multiple Sentences (RAMS) dataset is used for multi-sentence argument linking, specifically to connect arguments across multiple sentences. It provides annotations that facilitate the task of identifying and linking event arguments within and across sentences, enabling research in natural language processing focused on coherent event representation and argument structure.
ACE	https://doi.org/10.18653/v1/2021.findings-emnlp.32	https://www.semanticscholar.org/paper/0617dd6924df7a3491c299772b70e90507b195dc	The ACE dataset is used to define and benchmark the task of event extraction, specifically focusing on detecting event triggers and their arguments within sentences. It serves as a standard evaluation resource for comparing the performance of different event extraction systems, ensuring consistent and reliable assessment across various methodologies.
Chinese financial dataset from the Interdisciplinary Information Science Research at Tsinghua University	https://doi.org/10.1145/3584376.3584478	https://doi.org/10.18653/v1/D19-1032	The Chinese financial dataset from Tsinghua University is used for document-level event extraction in Chinese financial texts. Researchers employ an end-to-end framework to evaluate and assess the performance of event extraction models. This dataset enables detailed analysis and benchmarking of methodologies designed to identify and extract events from complex financial documents.
ON5V	https://doi.org/10.18653/V1/2021.NAACL-MAIN.69		The dataset 'ON5V' is mentioned in the citation context but lacks detailed descriptions of its usage, methodology, research questions, or specific characteristics. Therefore, there is insufficient evidence to provide a comprehensive synthesis of how this dataset is actually used in research.
Few-NERD	https://doi.org/10.48550/arXiv.2209.02203	https://doi.org/10.18653/v1/2021.acl-long.248	The Few-NERD dataset is used to train and evaluate few-shot named entity recognition (NER) models, focusing on incorporating cross-sentence information to enhance document-level understanding. This dataset enables researchers to address the challenge of recognizing entities with limited labeled data, making it particularly useful for scenarios where annotated resources are scarce. The dataset's design supports the development of models that can generalize well from a few examples, thereby advancing the field of NER in low-resource settings.
FewFC	https://doi.org/10.48550/arXiv.2404.12242	https://doi.org/10.48550/arXiv.2209.02693	The FewFC dataset is used to study overlapping events in document-level event extraction. Despite its small size and limited instances of overlapping events, it provides sentence-based annotations. Researchers employ this dataset to address challenges in identifying and extracting overlapping events within documents, leveraging its annotated sentences to develop and evaluate methodologies for handling such complexities.
GLACIER	https://doi.org/10.18653/V1/2020.ACL-MAIN.714	https://doi.org/10.3115/1699510.1699530	The GLACIER dataset is used for document-level event extraction, focusing on jointly considering phrasal and sentential evidence in information extraction tasks. This approach enhances the accuracy of extracting events by integrating context from phrases and sentences, addressing the need for more nuanced and context-aware extraction methods in natural language processing research.
