{
  "results": [
    {
      "context_text": "…a reliable training set for document RE is extremely expensive, it is also a meaningful topic that how to alleviate the dataset shift problem (Moreno-Torres et al., 2012) by injecting appropriate inductive bias into the model’s structure, instead of inheriting the bias in the training data.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset names, only a general discussion about dataset shift and training sets. No clear, verifiable resource is identified.",
      "processing_time": 69.01083540916443,
      "citing_paper_id": "248227853",
      "cited_paper_id": 9536442
    },
    {
      "context_text": "Some works apply general approaches like positive unlabeled learning (Xie et al., 2021; Peng et al., 2019) or inference learning (Roller et al., 2015).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 17.18267273902893,
      "citing_paper_id": "248227853",
      "cited_paper_id": 9989066
    },
    {
      "context_text": "Some works apply general approaches like positive unlabeled learning (Xie et al., 2021; Peng et al., 2019) or inference learning (Roller et al., 2015).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 17.18267273902893,
      "citing_paper_id": "248227853",
      "cited_paper_id": 174797886
    },
    {
      "context_text": "Task-speciﬁc models are also designed, like Partial CRF (Tsuboi et al., 2008) for NER (Yang et al., 2018), and novel paradigm for joint RE (Xie et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 17.177668571472168,
      "citing_paper_id": "248227853",
      "cited_paper_id": 52011076
    },
    {
      "context_text": "…from a single sentence (Lin et al., 2016; Zhang et al., 2018), recent studies begin to explore RE at document level (Peng et al., 2017; Zeng et al., 2020; Nan et al., 2020; Huang et al., 2021; Zhang et al., 2021), which is more challenging as it often requires reasoning across multiple sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to studies exploring document-level relation extraction.",
      "processing_time": 18.184354066848755,
      "citing_paper_id": "248227853",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "This is especially worth worrying about in real practice, where anno-tators are recruited to complete a certain number of annotations, and typically paid according to the estimated number of hours or the total number of instances they devote to the annotation(Draws et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses issues related to annotator recruitment and payment in crowdsourcing.",
      "processing_time": 30.456526279449463,
      "citing_paper_id": "248227853",
      "cited_paper_id": 249494286
    },
    {
      "context_text": "interdependent structures (Miller, 1981; Sebrechts and Gross, 1985) with features such as inheritance and type annotation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only features of interdependent structures. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 29.512314796447754,
      "citing_paper_id": "258887711",
      "cited_paper_id": 5600989
    },
    {
      "context_text": "interdependent structures (Miller, 1981; Sebrechts and Gross, 1985) with features such as inheritance and type annotation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only features of interdependent structures. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 29.512314796447754,
      "citing_paper_id": "258887711",
      "cited_paper_id": 62236084
    },
    {
      "context_text": "C L\n] 2\n5 M\nay 2\n02 3\ninterdependent structures (Miller, 1981; Sebrechts and Gross, 1985) with features such as inheritance and type annotation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only concepts related to programming and natural language. No verifiable resources are identified.",
      "processing_time": 18.971194744110107,
      "citing_paper_id": "258887711",
      "cited_paper_id": 5600989
    },
    {
      "context_text": "C L\n] 2\n5 M\nay 2\n02 3\ninterdependent structures (Miller, 1981; Sebrechts and Gross, 1985) with features such as inheritance and type annotation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only concepts related to programming and natural language. No verifiable resources are identified.",
      "processing_time": 18.971194744110107,
      "citing_paper_id": "258887711",
      "cited_paper_id": 62236084
    },
    {
      "context_text": "We use the average euclidean distance from the centroid example similar to (Halkidi et al., 2001) to measure the variability of in-context examples for each event type e:\nVariability(e) = 1 |Ve| ∑ v∈Ve d(v, v̄)\nwhere d(·, ·) is the euclidean distance between two vectors and v̄ = 1|Ve| ∑ v∈Ve v is…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for measuring variability in clustering. No dataset names are present in the context.",
      "processing_time": 17.522920846939087,
      "citing_paper_id": "258887711",
      "cited_paper_id": 17100109
    },
    {
      "context_text": "We follow Wadden et al. (2019); Lin et al. (2020) for dataset processing.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to dataset processing methods from other works.",
      "processing_time": 15.665528774261475,
      "citing_paper_id": "258887711",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "We follow Wadden et al. (2019); Lin et al. (2020) for dataset processing.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to dataset processing methods from other works.",
      "processing_time": 15.665528774261475,
      "citing_paper_id": "258887711",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Following Hsu et al. (2022), we also compare with classification-based (DyGIE++ Wadden et al. (2019), BERT_QA Du and Cardie (2020), OneIE Lin et al. (2020)) or generationbased (TANL (Paolini et al., 2021), BART-Gen Li et al. (2021), DEGREE Hsu et al. (2022)) models trained on the full training set.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several models but does not specify any datasets. The citation intent is to compare different models, and the resource type is methods.",
      "processing_time": 32.610689878463745,
      "citing_paper_id": "258887711",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Following Hsu et al. (2022), we also compare with classification-based (DyGIE++ Wadden et al. (2019), BERT_QA Du and Cardie (2020), OneIE Lin et al. (2020)) or generationbased (TANL (Paolini et al., 2021), BART-Gen Li et al. (2021), DEGREE Hsu et al. (2022)) models trained on the full training set.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several models but does not specify any datasets. The citation intent is to compare different models, and the resource type is methods.",
      "processing_time": 32.610689878463745,
      "citing_paper_id": "258887711",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Following Hsu et al. (2022), we also compare with classification-based (DyGIE++ Wadden et al. (2019), BERT_QA Du and Cardie (2020), OneIE Lin et al. (2020)) or generationbased (TANL (Paolini et al., 2021), BART-Gen Li et al. (2021), DEGREE Hsu et al. (2022)) models trained on the full training set.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several models but does not specify any datasets. The citation intent is to compare different models, and the resource type is methods.",
      "processing_time": 32.610689878463745,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Following Hsu et al. (2022), we also compare with classification-based (DyGIE++ Wadden et al. (2019), BERT_QA Du and Cardie (2020), OneIE Lin et al. (2020)) or generationbased (TANL (Paolini et al., 2021), BART-Gen Li et al. (2021), DEGREE Hsu et al. (2022)) models trained on the full training set.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several models but does not specify any datasets. The citation intent is to compare different models, and the resource type is methods.",
      "processing_time": 32.610689878463745,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "Event Extraction Li et al. (2013); Nguyen et al. (2016); Yang and Mitchell (2016); Wadden et al. (2019); Lin et al. (2020) use classification models and mitigate error propagation from pipeline models by leveraging global features to predict event triggers and arguments jointly.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 19.310011625289917,
      "citing_paper_id": "258887711",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Event Extraction Li et al. (2013); Nguyen et al. (2016); Yang and Mitchell (2016); Wadden et al. (2019); Lin et al. (2020) use classification models and mitigate error propagation from pipeline models by leveraging global features to predict event triggers and arguments jointly.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 19.310011625289917,
      "citing_paper_id": "258887711",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Code-LLM for Structured Task Sun et al. (2019); Singh et al. (2022) focus on procedural tasks that aim to control situated agents in an embodied environment by representing the procedure plan in code.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only procedural tasks and embodied agents. No clear identifiers for datasets are present.",
      "processing_time": 29.315446615219116,
      "citing_paper_id": "258887711",
      "cited_paper_id": 209476572
    },
    {
      "context_text": "A wide range of NLP tasks have benefited from LLM (Brown et al., 2020; Hoffmann et al., 2022; Chowdhery et al., 2022) trained on web-scale language corpora.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions 'web-scale language corpora' but does not specify any particular dataset. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 18.124800205230713,
      "citing_paper_id": "258887711",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "A wide range of NLP tasks have benefited from LLM (Brown et al., 2020; Hoffmann et al., 2022; Chowdhery et al., 2022) trained on web-scale language corpora.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions 'web-scale language corpora' but does not specify any particular dataset. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 18.124800205230713,
      "citing_paper_id": "258887711",
      "cited_paper_id": 247951931
    },
    {
      "context_text": "However, discrimination and bias are possible, as observed in the foundational LLMs we used (Brown et al., 2020; Chen et al., 2021; Ouyang et al., 2022), which we refer to Brown et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to foundational LLMs which are not considered datasets.",
      "processing_time": 16.283334732055664,
      "citing_paper_id": "258887711",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "However, discrimination and bias are possible, as observed in the foundational LLMs we used (Brown et al., 2020; Chen et al., 2021; Ouyang et al., 2022), which we refer to Brown et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to foundational LLMs which are not considered datasets.",
      "processing_time": 16.283334732055664,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235755472
    },
    {
      "context_text": "LLM We use CODEX code-davinci-002 (Chen et al., 2021), a GPT-3 (Brown et al., 2020) model finetuned on code, which supports up to 8k input tokens.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a model (CODEX code-davinci-002) and its training data (code), but does not specify any named, verifiable datasets. The context is focused on the capabilities and training of the model rather than the use of a specific dataset.",
      "processing_time": 36.00109601020813,
      "citing_paper_id": "258887711",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "LLM We use CODEX code-davinci-002 (Chen et al., 2021), a GPT-3 (Brown et al., 2020) model finetuned on code, which supports up to 8k input tokens.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a model (CODEX code-davinci-002) and its training data (code), but does not specify any named, verifiable datasets. The context is focused on the capabilities and training of the model rather than the use of a specific dataset.",
      "processing_time": 36.00109601020813,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235755472
    },
    {
      "context_text": ", 2021), a GPT-3 (Brown et al., 2020) model finetuned on code, which supports up to 8k input tokens.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (GPT-3) and its capabilities. No verifiable resources are identified.",
      "processing_time": 30.412436962127686,
      "citing_paper_id": "258887711",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "However, discrimination and bias are possible, as observed in the foundational LLMs we used (Brown et al., 2020; Chen et al., 2021; Ouyang et al., 2022), which we refer to Brown et al. (2020) for detailed discussion.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only foundational LLMs which are not considered datasets. The context focuses on the potential for discrimination and bias in these models.",
      "processing_time": 31.68790888786316,
      "citing_paper_id": "258887711",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "However, discrimination and bias are possible, as observed in the foundational LLMs we used (Brown et al., 2020; Chen et al., 2021; Ouyang et al., 2022), which we refer to Brown et al. (2020) for detailed discussion.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only foundational LLMs which are not considered datasets. The context focuses on the potential for discrimination and bias in these models.",
      "processing_time": 31.68790888786316,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235755472
    },
    {
      "context_text": "We expect better selecting (Liu et al., 2021) and ordering (Lu et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other papers. There are no clear identifiers for datasets, models, or methods.",
      "processing_time": 17.117741107940674,
      "citing_paper_id": "258887711",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "We expect better selecting (Liu et al., 2021) and ordering (Lu et al., 2022) incontext examples can benefit CODE4STRUCT performance, which we leave for future work.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to future work on improving in-context examples and prompt ordering. No verifiable resources are identified.",
      "processing_time": 20.607437133789062,
      "citing_paper_id": "258887711",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "We expect better selecting (Liu et al., 2021) and ordering (Lu et al., 2022) incontext examples can benefit CODE4STRUCT performance, which we leave for future work.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to future work on improving in-context examples and prompt ordering. No verifiable resources are identified.",
      "processing_time": 20.607437133789062,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233296494
    },
    {
      "context_text": "Prior work (Zhao et al., 2021; Lu et al., 2022) has demonstrated a strong relationship between performance and in-context demonstrations; however, for ease of comparison to supervised baselines, we use the same set of examples from the training set for in-context learning.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to 'examples from the training set'. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 21.63724374771118,
      "citing_paper_id": "258887711",
      "cited_paper_id": 231979430
    },
    {
      "context_text": "Prior work (Zhao et al., 2021; Lu et al., 2022) has demonstrated a strong relationship between performance and in-context demonstrations; however, for ease of comparison to supervised baselines, we use the same set of examples from the training set for in-context learning.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to 'examples from the training set'. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 21.63724374771118,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233296494
    },
    {
      "context_text": "BART-Gen (Li et al., 2021) <arg1> transported <arg2> in <arg3> vehicle from <arg4> place to <arg5> place Text2Event (Lu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models or methods. The citation is focused on describing the capabilities of BART-Gen and Text2Event, which are not datasets.",
      "processing_time": 22.21927571296692,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "In particular, the target structure (e.g., event-argument graph in Figure 1) can be mapped to code more straightforwardly compared to natural language, which often requires careful prompt engineering (Hsu et al. 2022, Li et al. 2021, Table 2).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to papers discussing methodologies. No clear identifiers for datasets are present.",
      "processing_time": 18.685304880142212,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "In particular, the target structure (e.g., event-argument graph in Figure 1) can be mapped to code more straightforwardly compared to natural language, which often requires careful prompt engineering (Hsu et al. 2022, Li et al. 2021, Table 2).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to papers discussing methodologies. No clear identifiers for datasets are present.",
      "processing_time": 18.685304880142212,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "The event description templates are modified from Li et al. (2021) by replacing each role with their corresponding member variable (e.g., self.agent).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a modification of event description templates from a previous work.",
      "processing_time": 16.246758699417114,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Evaluation metrics We use Argument F1-score following prior work (Ji and Grishman, 2008; Li et al., 2021; Hsu et al., 2022): We consider an argument to be correctly identified when the head word span of predicted text9 matches that of the humanannotated text (denoted as Arg-I); We consider an…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and criteria for argument identification. No verifiable resources are named.",
      "processing_time": 19.25806975364685,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Evaluation metrics We use Argument F1-score following prior work (Ji and Grishman, 2008; Li et al., 2021; Hsu et al., 2022): We consider an argument to be correctly identified when the head word span of predicted text9 matches that of the humanannotated text (denoted as Arg-I); We consider an…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and criteria for argument identification. No verifiable resources are named.",
      "processing_time": 19.25806975364685,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "Evaluation metrics We use Argument F1-score following prior work (Ji and Grishman, 2008; Li et al., 2021; Hsu et al., 2022): We consider an argument to be correctly identified when the head word span of predicted text9 matches that of the humanannotated text (denoted as Arg-I); We consider an…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and criteria for argument identification. No verifiable resources are named.",
      "processing_time": 19.25806975364685,
      "citing_paper_id": "258887711",
      "cited_paper_id": null
    },
    {
      "context_text": "Gen style prompt (Li et al., 2021) (Figure A.6) which resembles natural language more compared to T (1).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between two generation styles. No verifiable resources are identified.",
      "processing_time": 18.390889644622803,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "There is a tradeoff between the effort put into defining the output or designing the prompt (e.g., Text2Event in Table 2) and the benefit from pretraining in natural language (e.g., DEGREE and BART-Gen in Table 2).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited paper titles do not introduce any specific datasets either.",
      "processing_time": 17.471962451934814,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "There is a tradeoff between the effort put into defining the output or designing the prompt (e.g., Text2Event in Table 2) and the benefit from pretraining in natural language (e.g., DEGREE and BART-Gen in Table 2).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited paper titles do not introduce any specific datasets either.",
      "processing_time": 17.471962451934814,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "There is a tradeoff between the effort put into defining the output or designing the prompt (e.g., Text2Event in Table 2) and the benefit from pretraining in natural language (e.g., DEGREE and BART-Gen in Table 2).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited paper titles do not introduce any specific datasets either.",
      "processing_time": 17.471962451934814,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "Recent work such as Liu et al. (2020) formulates event extraction as a reading comprehension problem and Li et al. (2021); Huang et al. (2021); Paolini et al. (2021); Hsu et al. (2022) converts event extraction to a text generation task to better exploit label semantics from pretrained language…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 17.469090461730957,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Recent work such as Liu et al. (2020) formulates event extraction as a reading comprehension problem and Li et al. (2021); Huang et al. (2021); Paolini et al. (2021); Hsu et al. (2022) converts event extraction to a text generation task to better exploit label semantics from pretrained language…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 17.469090461730957,
      "citing_paper_id": "258887711",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "Towards the other end, Hsu et al. (2022); Li et al. (2021) design manual templates for the model to fill in.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of manual templates in a model. No clear identifiers for datasets are present.",
      "processing_time": 30.61997365951538,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Towards the other end, Hsu et al. (2022); Li et al. (2021) design manual templates for the model to fill in.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of manual templates in a model. No clear identifiers for datasets are present.",
      "processing_time": 30.61997365951538,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "• There is no clear trend on Arg-I F1 to differentiate code and text prompts, except for text-davinci-003, which exhibits similar behavior that code prompt performs better with larger k.\n• Text prompt T (2) (BART-Gen style), which resembles natural language more, performs poorly under low-shot (k ≤ 1), primarily due to the LLM being unable to produce the desired structure output described using language in T (2), causing the low-shot code-text performance gap ∆(2)C−T to be larger compared to T (1).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses model performance and prompt styles.",
      "processing_time": 15.77076530456543,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "5) and T (2) following BARTGen style prompt (Li et al., 2021) (Figure A.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or style of prompt generation. There are no clear identifiers for datasets in the given context.",
      "processing_time": 30.621658086776733,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We follow the same keywords used by Li et al. (2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only keywords used in another study. No verifiable resources are identified.",
      "processing_time": 16.202117204666138,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We also design two variants of language prompt as shown in Figure A.5 and A.6 miciking our code prompt and BART-Gen style prompt for comparison.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only variants of language prompts. No clear identifiers for datasets are present.",
      "processing_time": 17.448728322982788,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Evaluation metrics We use Argument F1score following prior work (Ji and Grishman, 2008; Li et al., 2021; Hsu et al., 2022): We consider an argument to be correctly identified when the head word span of predicted text9 matches that of the human-annotated text (denoted as Arg-I); We consider an argument to be correctly classified if the role (e.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only evaluation metrics and criteria for argument identification and classification.",
      "processing_time": 16.492857694625854,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Evaluation metrics We use Argument F1score following prior work (Ji and Grishman, 2008; Li et al., 2021; Hsu et al., 2022): We consider an argument to be correctly identified when the head word span of predicted text9 matches that of the human-annotated text (denoted as Arg-I); We consider an argument to be correctly classified if the role (e.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only evaluation metrics and criteria for argument identification and classification.",
      "processing_time": 16.492857694625854,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": ", 2021) and ordering (Lu et al., 2022) incontext examples can benefit CODE4STRUCT performance, which we leave for future work.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only future work on in-context examples. No verifiable resources are identified.",
      "processing_time": 18.040369272232056,
      "citing_paper_id": "258887711",
      "cited_paper_id": 233296494
    },
    {
      "context_text": "Text2Event (Lu et al., 2021) resides at one end of the spectrum with a concise but unnatural output format.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or tool called Text2Event. The context focuses on the output format of Text2Event, which is not a dataset.",
      "processing_time": 20.195802688598633,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "To ensure a fair comparison, for each event type t in the test set, we train a Text2Event model (Lu et al., 2021) and a DEGREE model (SOTA, Hsu et al. (2022)) on 20-shot and 50-shot in-context examples CODE4STRUCT used while providing gold-standard trigger words.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions '20-shot and 50-shot in-context examples' but does not specify a named dataset. The cited papers do not provide additional dataset names.",
      "processing_time": 20.191514015197754,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "To ensure a fair comparison, for each event type t in the test set, we train a Text2Event model (Lu et al., 2021) and a DEGREE model (SOTA, Hsu et al. (2022)) on 20-shot and 50-shot in-context examples CODE4STRUCT used while providing gold-standard trigger words.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions '20-shot and 50-shot in-context examples' but does not specify a named dataset. The cited papers do not provide additional dataset names.",
      "processing_time": 20.191514015197754,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "The most similar work to ours is Text2Event (Lu et al., 2021), which uses controlled generation to generate structures in a manually specified linearized format directly, hindering the model in leveraging pre-trained NL knowledge.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called Text2Event. The context focuses on the methodology and limitations of the cited work.",
      "processing_time": 18.356471300125122,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "Text2Event (Lu et al., 2021) resides at one end of the spectrum with a concise\nbut unnatural output format.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or tool called Text2Event. No verifiable datasets are referenced.",
      "processing_time": 18.025091648101807,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235458429
    },
    {
      "context_text": ", 2021) <arg1> transported <arg2> in <arg3> vehicle from <arg4> place to <arg5> place Text2Event (Lu et al., 2021) ( (Transport returned (Agent <arg>) (Artifact <arg>) (Destination <arg>) (Origin <arg>) (Vehicle <arg>) )",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or tool called Text2Event. The citation is used to describe the structure of events extracted, not a dataset.",
      "processing_time": 20.892743825912476,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "To ensure a fair comparison, for each event type t in the test set, we train a Text2Event model (Lu et al., 2021) and a DEGREE model (SOTA, Hsu et al.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (Text2Event and DEGREE). The context focuses on model training and evaluation for event extraction.",
      "processing_time": 18.886454582214355,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "Large Language Model (LLM) trained on massive corpora of code mixed with natural language (NL) comments and docstrings4 (e.g., Chen et al. 2021,\n1Inheritance is a way to create a hierarchy of classes in PL.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'massive corpora of code mixed with natural language' which is too generic.",
      "processing_time": 20.18961000442505,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235755472
    },
    {
      "context_text": "LLM We use CODEX code-davinci-002 (Chen et al., 2021), a GPT-3 (Brown et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 18.82991862297058,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235755472
    },
    {
      "context_text": "Such Code-LLMs have the ability to convert text into corresponding code as demonstrated by (Chen et al., 2021; Nijkamp et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers demonstrating the capabilities of Code-LLMs.",
      "processing_time": 16.709649085998535,
      "citing_paper_id": "258887711",
      "cited_paper_id": 235755472
    },
    {
      "context_text": "Surprisingly, similar to the observation made by Min et al. (2022), using in-context examples from a random non-sibling type also benefits CODE4STRUCT performance, albeit not as helpful as sibling examples under 10-shot.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to 'in-context examples' which is too generic.",
      "processing_time": 15.914030313491821,
      "citing_paper_id": "258887711",
      "cited_paper_id": 247155069
    },
    {
      "context_text": "In the few-shot setting, 20-shot CODE4STRUCT using text-davinci-003 can surpass DEGREE (Hsu et al., 2022), the current state-ofthe-art, by a large margin (+29.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and performance metrics. The cited paper title confirms that 'DEGREE' is a model, not a dataset.",
      "processing_time": 33.53936529159546,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "In the few-shot setting, 20-shot CODE4STRUCT using text-davinci-003 can surpass DEGREE (Hsu et al., 2022), the current state-ofthe-art, by a large margin (+29.5% Arg-C F1).",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and performance metrics. The context focuses on comparing model performance rather than using a particular dataset.",
      "processing_time": 18.83250665664673,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "Our zero-shot CODE4STRUCT using the bestperforming text-davinci-003 model can already achieve higher Arg-I and Arg-C performance than the 20-shot and 50-shot DEGREE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model performance comparisons. The cited paper title suggests a method or model, not a dataset.",
      "processing_time": 17.387166023254395,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "We report the performance of supervised models using the full dataset from Hsu et al. (2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'the full dataset from Hsu et al. (2022)', but does not provide a specific name for the dataset. The title of the cited paper does not help in identifying a specific dataset name.",
      "processing_time": 22.8575382232666,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "DEGREE (Hsu et al., 2022) somebody was moved to somewhere from some place by some way.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not mention any specific datasets, only a model (DEGREE). The context is too vague to infer any dataset usage.",
      "processing_time": 16.993161916732788,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "…work such as Liu et al. (2020) formulates event extraction as a reading comprehension problem and Li et al. (2021); Huang et al. (2021); Paolini et al. (2021); Hsu et al. (2022) converts event extraction to a text generation task to better exploit label semantics from pretrained language models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers are referenced for their methodologies, not for using specific datasets.",
      "processing_time": 19.375226497650146,
      "citing_paper_id": "258887711",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "Evaluation metrics We use Argument F1-score following prior work (Ji and Grishman, 2008; Li et al., 2021; Hsu et al., 2022): We consider an argument to be correctly identified when the head word span of predicted text9 matches that of the humanannotated text (denoted as Arg-I); We consider an argument to be correctly classified if the role (e.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and criteria for argument identification and classification.",
      "processing_time": 15.503273487091064,
      "citing_paper_id": "258887711",
      "cited_paper_id": null
    },
    {
      "context_text": "For an argument span = ( 𝑤 𝑙 , · · · , 𝑤 𝑟 ) , we follow Lee et al. (2017) to generate a span embedding.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method for generating span embeddings.",
      "processing_time": 14.858587741851807,
      "citing_paper_id": "226283556",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "Implicit role resolution Palmer et al. (1986) treated unﬁlled semantic roles as special cases of anaphora and coreference resolution.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach to treating unfilled semantic roles.",
      "processing_time": 15.878012895584106,
      "citing_paper_id": "226283556",
      "cited_paper_id": 5249956
    },
    {
      "context_text": "Dhingra et al. (2017) augmented such methods with external knowledge bases (KBs) to create a multi-turn dialogue agent which helps users search KBs. Chen et al. (2019) proposed joint models over potential slots in dialogue to output which contextual slots should be carried over to the most recent…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on dialogue systems and slot carryover, which are methods or approaches rather than datasets.",
      "processing_time": 21.150396585464478,
      "citing_paper_id": "226283556",
      "cited_paper_id": 8951658
    },
    {
      "context_text": "Dhingra et al. (2017) augmented such methods with external knowledge bases (KBs) to create a multi-turn dialogue agent which helps users search KBs. Chen et al. (2019) proposed joint models over potential slots in dialogue to output which contextual slots should be carried over to the most recent…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on dialogue systems and slot carryover, which are methods or approaches rather than datasets.",
      "processing_time": 21.150396585464478,
      "citing_paper_id": "226283556",
      "cited_paper_id": 174797908
    },
    {
      "context_text": "Silberer and Frank (2012) considered the problem as an anaphora resolution task within the discourse context.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to anaphora resolution.",
      "processing_time": 15.657839298248291,
      "citing_paper_id": "226283556",
      "cited_paper_id": 9016539
    },
    {
      "context_text": "…perfect performance in SRL will be limited by the existence of arguments outside the sentence boundary, leading to prior work (Das et al., 2010; Silberer and Frank, 2012; Ebner et al., 2020) on an alternative paradigm variously called implicit role resolution or argument linking , where an…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to prior work on implicit role resolution or argument linking. No verifiable resources are identified.",
      "processing_time": 18.548102378845215,
      "citing_paper_id": "226283556",
      "cited_paper_id": 9016539
    },
    {
      "context_text": "Chen et al. (2010) approached this with their SRL system S E - MAFOR (Das et al., 2010), casting the task as extended SRL by admitting constituents (potential arguments) from context larger than sentence boundaries.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (SEMAFOR) and a research approach. The context is about extending SRL to handle document-level information.",
      "processing_time": 20.4806809425354,
      "citing_paper_id": "226283556",
      "cited_paper_id": 12258556
    },
    {
      "context_text": "Sig-niﬁcant work has focused at the level of single sentence contexts, such as in semantic role labeling (SRL; Gildea and Jurafsky, 2000; He et al., 2017; Ouchi et al., 2018, inter alia ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general research areas and methods. The cited papers are about semantic role labeling but do not introduce or use specific datasets.",
      "processing_time": 20.122310161590576,
      "citing_paper_id": "226283556",
      "cited_paper_id": 33626727
    },
    {
      "context_text": "Sig-niﬁcant work has focused at the level of single sentence contexts, such as in semantic role labeling (SRL; Gildea and Jurafsky, 2000; He et al., 2017; Ouchi et al., 2018, inter alia ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general research areas and methods. The cited papers are about semantic role labeling but do not introduce or use specific datasets.",
      "processing_time": 20.122310161590576,
      "citing_paper_id": "226283556",
      "cited_paper_id": 52920257
    },
    {
      "context_text": "The models are setup with 𝑑 tok = 𝑑 span = 768 , and are trained using AdamW optimizer (Loshchilov and Hutter, 2019) with learning rate of 3 × 10 − 5 for 200 epochs, and the tolerance = 1 × 10 − 8 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only training parameters and an optimizer. The cited paper title 'Decoupled Weight Decay Regularization' is about a method, not a dataset.",
      "processing_time": 21.47993278503418,
      "citing_paper_id": "226283556",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "For an argument span < = (F;, · · · , FA ), we follow Lee et al. (2017) to generate a span embedding.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating span embeddings.",
      "processing_time": 16.11906099319458,
      "citing_paper_id": "226283556",
      "cited_paper_id": 59222677
    },
    {
      "context_text": "6 The width embeddings in Lee et al. (2017) are not used.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any datasets, only a method (width embeddings) that is not used.",
      "processing_time": 15.179312705993652,
      "citing_paper_id": "226283556",
      "cited_paper_id": 59222677
    },
    {
      "context_text": "(2019); (2) since the arguments do not take an explicit sequential order, we forgo the positional embeddings in Transformers, effectively modeling the input as a set of spans instead of a sequence (self-attention exhibits the property of permutation invariance without positional embeddings (Lee et al., 2019)).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methodological aspects of the Transformer model.",
      "processing_time": 15.851294755935669,
      "citing_paper_id": "226283556",
      "cited_paper_id": 59222677
    },
    {
      "context_text": "…since the arguments do not take an explicit sequential order, we forgo the positional embeddings in Transformers, effectively modeling the input as a set of spans instead of a sequence (self-attention exhibits the property of permutation invariance without positional embeddings (Lee et al., 2019)).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological choice regarding positional embeddings in Transformers.",
      "processing_time": 16.381373643875122,
      "citing_paper_id": "226283556",
      "cited_paper_id": 59222677
    },
    {
      "context_text": "Such systems often output an interpretation of dialogues represented as intents and slots (Wang et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or system for interpreting dialogues.",
      "processing_time": 29.285191535949707,
      "citing_paper_id": "226283556",
      "cited_paper_id": 60857975
    },
    {
      "context_text": "Such systems often output an interpretation of di-alogues represented as intents and slots (Wang et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or system for interpreting dialogues as intents and slots.",
      "processing_time": 17.696202993392944,
      "citing_paper_id": "226283556",
      "cited_paper_id": 60857975
    },
    {
      "context_text": "token F8 has 1 vector representation w8 ∈ R(3)tok , following Zhang et al. (2019). For an argument span < = (F;, · · · , FA ), we follow Lee et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods or models. There are no clear identifiers for datasets in the given context.",
      "processing_time": 19.671899795532227,
      "citing_paper_id": "226283556",
      "cited_paper_id": 60857975
    },
    {
      "context_text": "All non-linearities used in the paper are GELU (Hendrycks and Gimpel, 2016).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions GELU, which is a method, not a dataset. No datasets are mentioned in the context.",
      "processing_time": 15.83107304573059,
      "citing_paper_id": "226283556",
      "cited_paper_id": 125617073
    },
    {
      "context_text": "Each token might be split into more than 1 subword units—in this case we take the average of these subword representations so that each token has 1 vector representation w 𝑖 ∈ R tok , following Zhang et al. (2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for handling subword units in token representation.",
      "processing_time": 15.272360563278198,
      "citing_paper_id": "226283556",
      "cited_paper_id": 160009452
    },
    {
      "context_text": "Dhingra et al. (2017) augmented such methods with external knowledge bases (KBs) to create a multi-turn dialogue agent which helps users search KBs. Chen et al. (2019) proposed joint models over potential slots in dialogue to output which contextual slots should be carried over to the most recent utterance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on dialogue systems and slot carryover, which are not directly related to document-level event extraction.",
      "processing_time": 18.738792419433594,
      "citing_paper_id": "226283556",
      "cited_paper_id": 174797908
    },
    {
      "context_text": "Note two major differences as compared to a Trans-former that runs on tokens: (1) each input to the Transformer represents a span instead of a token, following Chen et al. (2019); (2) since the arguments do not take an explicit sequential order, we forgo the positional embeddings in Transformers,…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methodological differences from a Transformer model.",
      "processing_time": 14.939615249633789,
      "citing_paper_id": "226283556",
      "cited_paper_id": 174797908
    },
    {
      "context_text": "Intent type Event type We propose a novel model for joint modeling of potential arguments inspired by Chen et al. (2019) for slot-ﬁlling in dialogue systems, which proposed to jointly predict spans that are relevant to the intent of the current round of dialogue.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for slot-filling in dialogue systems. No dataset names are present in the citation span.",
      "processing_time": 18.488056659698486,
      "citing_paper_id": "226283556",
      "cited_paper_id": 174797908
    },
    {
      "context_text": "…differences as compared to a Trans-former that runs on tokens: (1) each input to the Transformer represents a span instead of a token, following Chen et al. (2019); (2) since the arguments do not take an explicit sequential order, we forgo the positional embeddings in Transformers, effectively…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methodological differences in using Transformers. No verifiable resources are identified.",
      "processing_time": 16.345292806625366,
      "citing_paper_id": "226283556",
      "cited_paper_id": 174797908
    },
    {
      "context_text": "Unfortunately even perfect performance in SRL will be limited by the existence of arguments outside the sentence boundary, leading to prior work (Das et al., 2010; Silberer and Frank, 2012; Ebner et al., 2020) on an alternative paradigm variously called implicit role resolution or argument linking, where an event trigger (e.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to prior work on implicit role resolution or argument linking.",
      "processing_time": 15.40804123878479,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "RAMS-TCD refers to Ebner et al. (2020)’s type-constrained decoding approach (see Table 4).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method or approach. The term 'RAMS-TCD' is not identified as a dataset but rather as a reference to a method.",
      "processing_time": 21.05744504928589,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "tion extraction, we focus primarily on evaluating the model a discourse-level dataset, RAMS (Ebner et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the model on discourse-level event extraction, focusing on multi-sentence argument linking and the relationships between events and arguments."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'RAMS' as a discourse-level dataset used for evaluation. The title 'Multi-Sentence Argument Linking' suggests that RAMS is used for argument linking, which is related to document-level event extraction.",
      "processing_time": 26.44432520866394,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "See O’Gorman (2019) and Ebner et al. (2020) for further background.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only refers to other works for background information.",
      "processing_time": 17.652973651885986,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We demonstrate this leads to state-of-the-art performance on the RAMS argument linking dataset introduced by Ebner et al. (2020), 3 showing the beneﬁts of joint modeling when linking arguments to roles of events.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS argument linking dataset"
      ],
      "dataset_descriptions": {
        "RAMS argument linking dataset": "Used to evaluate the performance of the proposed model on argument linking tasks, demonstrating the benefits of joint modeling in linking arguments to event roles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'RAMS argument linking dataset' which is a specific dataset used for evaluating the performance of the model described in the paper.",
      "processing_time": 25.505500078201294,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Following Ebner et al. (2020) we consider argu-ment linking as the task of choosing amongst detected mention span candidates given detected event trigger spans.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a task definition. No verifiable resources are identified.",
      "processing_time": 16.579848766326904,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Ebner et al. (2020) similarly considered the task as related to anaphora resolution, and introduced a new dataset, RAMS, for exploring non-local argument linking.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to explore non-local argument linking in the context of anaphora resolution, providing a new resource for document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the introduction of a new dataset called RAMS, which is relevant to the research topic of document-level event extraction.",
      "processing_time": 24.425763845443726,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Following the same conditions as Ebner et al. (2020), our joint model outperforms that work, and our independent baseline, by a substantial margin of 6.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of performance metrics.",
      "processing_time": 14.908021926879883,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Roles Across Multiple Sentences (RAMS; Ebner et al., 2020) is an event extraction dataset that considers discourse-level, non-local arguments in document-level context.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Roles Across Multiple Sentences (RAMS)"
      ],
      "dataset_descriptions": {
        "Roles Across Multiple Sentences (RAMS)": "Used to consider discourse-level, non-local arguments in document-level context for event extraction, enhancing the understanding of complex event structures."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Roles Across Multiple Sentences (RAMS)' as an event extraction dataset, which is directly relevant to the topic of document-level event extraction.",
      "processing_time": 26.548235177993774,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "8 This scoring function for triples (A, C, <) is similar to Ebner et al. (2020)’s model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model or method. There are no clear identifiers for datasets in the context.",
      "processing_time": 18.685938835144043,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "RAMS.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event extraction, focusing on identifying and linking argument structures across multiple sentences."
      },
      "confidence_score": 0.6,
      "reasoning": "The context 'RAMS' is a multi-word proper noun that appears to be a specific dataset. However, without additional context, it is unclear how it is used in the research.",
      "processing_time": 24.83081817626953,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Following the same conditions as Ebner et al. (2020), our joint model outperforms that work, and our independent baseline, by a substantial margin of 6.6%, illustrating the beneﬁt of modeling potential arguments jointly.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of performance metrics. The context is focused on model performance rather than data usage.",
      "processing_time": 18.167746543884277,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "As we draw the connections between SLU in dialogue systems and argument linking in information extraction, we focus primarily on evaluating the model a discourse-level dataset, RAMS (Ebner et al., 2020 Baseline Aside from joint modeling of arguments, we also include an independent model as a case in ablation studies (while our proposed method labeled as joint ).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the model on discourse-level argument linking, focusing on the joint modeling of arguments and comparing it with an independent model in ablation studies."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS' as a discourse-level dataset used for evaluating the model. The dataset is clearly identified and used in the research context.",
      "processing_time": 25.47330331802368,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "…SRL will be limited by the existence of arguments outside the sentence boundary, leading to prior work (Das et al., 2010; Silberer and Frank, 2012; Ebner et al., 2020) on an alternative paradigm variously called implicit role resolution or argument linking , where an event trigger (e.g. “attack”)…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses prior work on implicit role resolution or argument linking. No verifiable resources are identified.",
      "processing_time": 19.231093168258667,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "…SLU in dialogue systems and argument linking in information extraction, we focus primarily on evaluating the model a discourse-level dataset, RAMS (Ebner et al., 2020 Baseline Aside from joint modeling of arguments, we also include an independent model as a case in ablation studies (while our…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the model on discourse-level tasks, focusing on joint modeling of arguments and ablation studies to assess performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS' as a discourse-level dataset used for evaluation. The dataset is clearly identified and used in the research context.",
      "processing_time": 25.08730959892273,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Following Ebner et al. (2020) we consider argument linking as the task of choosing amongst detected mention span candidates given detected event trigger spans.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a task definition. No verifiable resources are identified.",
      "processing_time": 17.593623638153076,
      "citing_paper_id": "226283556",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "First however we look at a more established dataset, ACE 2005 (Walker et al., 2006)7, to verify if our model can reasonable performance compared to prior work in event understanding.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to verify model performance in event understanding, comparing results to prior work in the field of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE 2005' as a dataset used to verify model performance in event understanding, which aligns with the research topic of document-level event extraction.",
      "processing_time": 26.147754192352295,
      "citing_paper_id": "226283556",
      "cited_paper_id": null
    },
    {
      "context_text": "Recently, neural network-based methods have also achieved promising improvement (Meng et al., 2017; Meng and Rumshisky, 2018; Ning et al., 2018a, 2019; Han et al., 2019; Wang et al., 2020; Cheng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural network-based methods and their improvements. No verifiable resources are identified.",
      "processing_time": 19.596730947494507,
      "citing_paper_id": "243865639",
      "cited_paper_id": 5066019
    },
    {
      "context_text": "Recently, neural network-based methods have also achieved promising improvement (Meng et al., 2017; Meng and Rumshisky, 2018; Ning et al., 2018a, 2019; Han et al., 2019; Wang et al., 2020; Cheng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural network-based methods and their improvements. No verifiable resources are identified.",
      "processing_time": 19.596730947494507,
      "citing_paper_id": "243865639",
      "cited_paper_id": 6987624
    },
    {
      "context_text": "Recently, neural network-based methods have also achieved promising improvement (Meng et al., 2017; Meng and Rumshisky, 2018; Ning et al., 2018a, 2019; Han et al., 2019; Wang et al., 2020; Cheng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural network-based methods and their improvements. No verifiable resources are identified.",
      "processing_time": 19.596730947494507,
      "citing_paper_id": "243865639",
      "cited_paper_id": 202537879
    },
    {
      "context_text": "Recently, neural network-based methods have also achieved promising improvement (Meng et al., 2017; Meng and Rumshisky, 2018; Ning et al., 2018a, 2019; Han et al., 2019; Wang et al., 2020; Cheng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural network-based methods and their improvements. No verifiable resources are identified.",
      "processing_time": 19.596730947494507,
      "citing_paper_id": "243865639",
      "cited_paper_id": 202565622
    },
    {
      "context_text": "Recently, neural network-based methods have also achieved promising improvement (Meng et al., 2017; Meng and Rumshisky, 2018; Ning et al., 2018a, 2019; Han et al., 2019; Wang et al., 2020; Cheng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural network-based methods and their improvements. No verifiable resources are identified.",
      "processing_time": 19.596730947494507,
      "citing_paper_id": "243865639",
      "cited_paper_id": 222306079
    },
    {
      "context_text": "(ILP) based methods (Bramsen et al., 2006; Cham-bers and Jurafsky, 2008; Yoshikawa et al., 2009; Do et al., 2012; Ning et al., 2017, 2018a, 2019; Han et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and papers. The cited paper titles also do not provide any additional context about datasets.",
      "processing_time": 21.002703428268433,
      "citing_paper_id": "243865639",
      "cited_paper_id": 5066019
    },
    {
      "context_text": "(ILP) based methods (Bramsen et al., 2006; Cham-bers and Jurafsky, 2008; Yoshikawa et al., 2009; Do et al., 2012; Ning et al., 2017, 2018a, 2019; Han et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and papers. The cited paper titles also do not provide any additional context about datasets.",
      "processing_time": 21.002703428268433,
      "citing_paper_id": "243865639",
      "cited_paper_id": 202537879
    },
    {
      "context_text": "(ILP) based methods (Bramsen et al., 2006; Cham-bers and Jurafsky, 2008; Yoshikawa et al., 2009; Do et al., 2012; Ning et al., 2017, 2018a, 2019; Han et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and papers. The cited paper titles also do not provide any additional context about datasets.",
      "processing_time": 21.002703428268433,
      "citing_paper_id": "243865639",
      "cited_paper_id": 202565622
    },
    {
      "context_text": "MATRES contains reﬁned annotations on TimeBank (Pustejovsky et al., 2003 1.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TimeBank"
      ],
      "dataset_descriptions": {
        "TimeBank": "Used to refine annotations for event temporal relations, specifically focusing on improving the accuracy and consistency of temporal annotations in the MATRES project."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'TimeBank' as a dataset used for refined annotations in the MATRES project. TimeBank is a well-known dataset in the field of temporal relations and event extraction.",
      "processing_time": 26.50429630279541,
      "citing_paper_id": "243865639",
      "cited_paper_id": 5066019
    },
    {
      "context_text": "We conduct our experiments on MATRES (Ning et al., 2018b).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MATRES"
      ],
      "dataset_descriptions": {
        "MATRES": "Used to conduct experiments on event temporal relations, specifically focusing on multi-axis annotation schemes for improving temporal relation identification."
      },
      "confidence_score": 1.0,
      "reasoning": "MATRES is identified as a dataset used for experiments in the context of event temporal relations.",
      "processing_time": 23.780197143554688,
      "citing_paper_id": "243865639",
      "cited_paper_id": 5066019
    },
    {
      "context_text": "Neural network based methods have achieved promising improvement for temporal relation extraction (Meng et al., 2017; Meng and Rumshisky, 2018; Cheng et al., 2020; Ballesteros et al., 2020; Wen et al., 2021a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only neural network methods for temporal relation extraction. No verifiable resources are identified.",
      "processing_time": 19.22037386894226,
      "citing_paper_id": "243865639",
      "cited_paper_id": 6987624
    },
    {
      "context_text": "Neural network based methods have achieved promising improvement for temporal relation extraction (Meng et al., 2017; Meng and Rumshisky, 2018; Cheng et al., 2020; Ballesteros et al., 2020; Wen et al., 2021a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only neural network methods for temporal relation extraction. No verifiable resources are identified.",
      "processing_time": 19.22037386894226,
      "citing_paper_id": "243865639",
      "cited_paper_id": 235097403
    },
    {
      "context_text": "It takes a sequence of tokens X with length n as input after preprocessing required by pretrained language models, such as subword tokenization (Devlin et al., 2019) or byte pair encoding (BPE, Liu et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only preprocessing methods used by pretrained language models.",
      "processing_time": 16.82874608039856,
      "citing_paper_id": "243865639",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "It takes a sequence of tokens X with length n as input after preprocessing required by pretrained language models, such as subword tokenization (Devlin et al., 2019) or byte pair encoding (BPE, Liu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only preprocessing methods used by pretrained language models.",
      "processing_time": 16.824555158615112,
      "citing_paper_id": "243865639",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "The model ﬁrst computes the contextualized representation for each input token using a pretrained language model (Devlin et al., 2019; Liu et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions pretrained language models but does not specify any datasets. The focus is on the method (pretrained language models) rather than a specific dataset.",
      "processing_time": 20.635060787200928,
      "citing_paper_id": "243865639",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We use F1 to evaluate our system performance, following (Ning et al., 2019), where we consider",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of F1 as a metric. No datasets are referenced in the context.",
      "processing_time": 19.203553676605225,
      "citing_paper_id": "243865639",
      "cited_paper_id": 202537879
    },
    {
      "context_text": "2) LSTM+T EM P ROB +ILP: LSTM-based method incorporating pretrained language model embedding, commensense prior (T EM P ROB ) and ILP (Ning et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method combining LSTM, pretrained language model embedding, commonsense prior (TEMPROB), and ILP.",
      "processing_time": 21.163928747177124,
      "citing_paper_id": "243865639",
      "cited_paper_id": 202537879
    },
    {
      "context_text": "method incorporating pretrained language model embedding, commensense prior (TEMPROB) and ILP (Ning et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. TEMPROB is a method, not a dataset.",
      "processing_time": 18.616017818450928,
      "citing_paper_id": "243865639",
      "cited_paper_id": 202537879
    },
    {
      "context_text": "We use F 1 to evaluate our system performance, following (Ning et al., 2019), where we consider V AGUE as “no relation”.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (F1) and a vague reference to 'no relation'. No verifiable resources are identified.",
      "processing_time": 20.96297001838684,
      "citing_paper_id": "243865639",
      "cited_paper_id": 202537879
    },
    {
      "context_text": "Precision and recall are not reported by (Han et al., 2019; Ballesteros et al., 2020).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to precision and recall metrics not being reported.",
      "processing_time": 19.218026876449585,
      "citing_paper_id": "243865639",
      "cited_paper_id": 202565622
    },
    {
      "context_text": "We compare our model with existing systems including 1) BiLSTM+MAP: A BiLSTM based joint event and temporal relation extraction model with MAP inference (Han et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method/model. The context focuses on comparing a model with existing systems, which are also models.",
      "processing_time": 20.9419424533844,
      "citing_paper_id": "243865639",
      "cited_paper_id": 202565622
    },
    {
      "context_text": "3) Joint Constrained Learning: A constrained learning based optimization for joint event temporal and hierarchy relation extraction (Wang et al., 2020).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for joint event temporal and hierarchy relation extraction.",
      "processing_time": 17.744399070739746,
      "citing_paper_id": "243865639",
      "cited_paper_id": 222306079
    },
    {
      "context_text": "However, explicit time arguments can be rarely found in text, especially in news articles (Wen et al., 2021b).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about time arguments in news articles.",
      "processing_time": 16.486406803131104,
      "citing_paper_id": "243865639",
      "cited_paper_id": 235097403
    },
    {
      "context_text": "…2015; Peng et al., 2022a), RNN-based methods (Zhang et al., 2015; Cai et al., 2016), GNN-based methods (Zhang et al., 2018; Zhu et al., 2019) and attention-based methods (Lin et al., 2016; Dai et al., 2019; Ye and Ling, 2019; For better visual effect, we only show part of relations as Figure 3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various methods and models. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 20.942429780960083,
      "citing_paper_id": "254877738",
      "cited_paper_id": 397533
    },
    {
      "context_text": "…2015; Peng et al., 2022a), RNN-based methods (Zhang et al., 2015; Cai et al., 2016), GNN-based methods (Zhang et al., 2018; Zhu et al., 2019) and attention-based methods (Lin et al., 2016; Dai et al., 2019; Ye and Ling, 2019; For better visual effect, we only show part of relations as Figure 3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various methods and models. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 20.942429780960083,
      "citing_paper_id": "254877738",
      "cited_paper_id": 203658323
    },
    {
      "context_text": "Earlier work mainly focuses on predicting the relationship of a given entity pair within a single sentence , i.e., sentence-level relation extraction (SentRE) (Zeng et al., 2014; Lin et al., 2016; Vashishth et al., 2018; Han et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods. No dataset names are present in the text.",
      "processing_time": 19.169506072998047,
      "citing_paper_id": "254877738",
      "cited_paper_id": 397533
    },
    {
      "context_text": "Earlier work mainly focuses on predicting the relationship of a given entity pair within a single sentence , i.e., sentence-level relation extraction (SentRE) (Zeng et al., 2014; Lin et al., 2016; Vashishth et al., 2018; Han et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods. No dataset names are present in the text.",
      "processing_time": 19.169506072998047,
      "citing_paper_id": "254877738",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Earlier work mainly focuses on predicting the relationship of a given entity pair within a single sentence , i.e., sentence-level relation extraction (SentRE) (Zeng et al., 2014; Lin et al., 2016; Vashishth et al., 2018; Han et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods. No dataset names are present in the text.",
      "processing_time": 19.169506072998047,
      "citing_paper_id": "254877738",
      "cited_paper_id": 53064621
    },
    {
      "context_text": "Earlier work mainly focuses on predicting the relationship of a given entity pair within a single sentence , i.e., sentence-level relation extraction (SentRE) (Zeng et al., 2014; Lin et al., 2016; Vashishth et al., 2018; Han et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods. No dataset names are present in the text.",
      "processing_time": 19.169506072998047,
      "citing_paper_id": "254877738",
      "cited_paper_id": 234762787
    },
    {
      "context_text": "Similar to label correlations in the multi-label learning ﬁeld (Zhu et al., 2018; Zhang and Zhou, 2014), relation correlations are originally proposed by Jin et al. (2020), they deﬁne this phenomenon as “Relation of Relations (ROR)” through statistical analysis.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the concept of relation correlations and its definition. No verifiable resources are identified.",
      "processing_time": 19.922616720199585,
      "citing_paper_id": "254877738",
      "cited_paper_id": 3744963
    },
    {
      "context_text": "Similar to label correlations in the multi-label learning ﬁeld (Zhu et al., 2018; Zhang and Zhou, 2014), relation correlations are originally proposed by Jin et al. (2020), they deﬁne this phenomenon as “Relation of Relations (ROR)” through statistical analysis.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the concept of relation correlations and its definition. No verifiable resources are identified.",
      "processing_time": 19.922616720199585,
      "citing_paper_id": "254877738",
      "cited_paper_id": 219531712
    },
    {
      "context_text": "Similar to label correlations in the multi-label learning field (Zhu et al., 2018; Zhang and Zhou, 2014), relation correlations are originally proposed by Jin et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to prior work on label correlations in multi-label learning.",
      "processing_time": 18.580634117126465,
      "citing_paper_id": "254877738",
      "cited_paper_id": 3744963
    },
    {
      "context_text": "All entity mentions are wrapped with a special token “*” (Zhang et al., 2017; Soares et al., 2019), and the embedding of “*” in front of each mention is regarded as its representation h m ij .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for representing entity mentions using special tokens. The cited papers do not provide additional context to identify a dataset.",
      "processing_time": 21.51110816001892,
      "citing_paper_id": "254877738",
      "cited_paper_id": 3782112
    },
    {
      "context_text": "All entity mentions are wrapped with a special token “*” (Zhang et al., 2017; Soares et al., 2019), and the embedding of “*” in front of each mention is regarded as its representation h m ij .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for representing entity mentions using special tokens. The cited papers do not provide additional context to identify a dataset.",
      "processing_time": 21.51110816001892,
      "citing_paper_id": "254877738",
      "cited_paper_id": 174801632
    },
    {
      "context_text": "Baselines We compare our model with some typical or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al., 2016), Context-Aware (Sorokin and Gurevych, 2017), CorefBERT (Ye et al., 2020), GAIN (Zeng et al., 2020), SSAN (Xu et al., 2021a), ATLOP (Zhou et al., 2021), ERA/ERACL (Du et al., 2022) and RSMAN (Yu et al., 2022).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods used as baselines. No dataset names are present in the context.",
      "processing_time": 20.22180485725403,
      "citing_paper_id": "254877738",
      "cited_paper_id": 6263378
    },
    {
      "context_text": "Baselines We compare our model with some typical or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al., 2016), Context-Aware (Sorokin and Gurevych, 2017), CorefBERT (Ye et al., 2020), GAIN (Zeng et al., 2020), SSAN (Xu et al., 2021a), ATLOP (Zhou et al., 2021), ERA/ERACL (Du et al., 2022) and RSMAN (Yu et al., 2022).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods used as baselines. No dataset names are present in the context.",
      "processing_time": 20.22180485725403,
      "citing_paper_id": "254877738",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Baselines We compare our model with some typical or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al., 2016), Context-Aware (Sorokin and Gurevych, 2017), CorefBERT (Ye et al., 2020), GAIN (Zeng et al., 2020), SSAN (Xu et al., 2021a), ATLOP (Zhou et al., 2021), ERA/ERACL (Du et al., 2022) and RSMAN (Yu et al., 2022).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods used as baselines. No dataset names are present in the context.",
      "processing_time": 20.22180485725403,
      "citing_paper_id": "254877738",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "Baselines We compare our model with some typical or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al., 2016), Context-Aware (Sorokin and Gurevych, 2017), CorefBERT (Ye et al., 2020), GAIN (Zeng et al., 2020), SSAN (Xu et al., 2021a), ATLOP (Zhou et al., 2021), ERA/ERACL (Du et al., 2022) and RSMAN (Yu et al., 2022).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods used as baselines. No dataset names are present in the context.",
      "processing_time": 20.22180485725403,
      "citing_paper_id": "254877738",
      "cited_paper_id": 248987560
    },
    {
      "context_text": "Baselines We compare our model with some typical or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al., 2016), Context-Aware (Sorokin and Gurevych, 2017), CorefBERT (Ye et al., 2020), GAIN (Zeng et al., 2020), SSAN (Xu et al., 2021a), ATLOP (Zhou et al., 2021), ERA/ERACL (Du et al., 2022) and RSMAN (Yu et al., 2022).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods used as baselines. No dataset names are present in the context.",
      "processing_time": 20.22180485725403,
      "citing_paper_id": "254877738",
      "cited_paper_id": 249191749
    },
    {
      "context_text": "…We compare our model with some typical or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al., 2016), Context-Aware (Sorokin and Gurevych, 2017), CorefBERT (Ye et al., 2020), GAIN (Zeng et al., 2020), SSAN (Xu et al., 2021a), ATLOP (Zhou et al., 2021), ERA/ERACL (Du…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 20.575591325759888,
      "citing_paper_id": "254877738",
      "cited_paper_id": 6263378
    },
    {
      "context_text": "Baselines We compare our model with some typical or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al., 2016), Context-Aware (Sorokin and Gurevych, 2017), CorefBERT (Ye et al., 2020), GAIN (Zeng et al., 2020), SSAN (Xu et al., 2021a), ATLOP (Zhou et al., 2021), ERA/ERACL…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods used as baselines.",
      "processing_time": 17.747623920440674,
      "citing_paper_id": "254877738",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Sentence-level Relation Extraction Sentencelevel relation extraction mainly includes CNNbased methods (Zeng et al., 2014; dos Santos et al., 2015; Zeng et al., 2015; Peng et al., 2022a), RNNbased methods (Zhang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets.",
      "processing_time": 19.141163110733032,
      "citing_paper_id": "254877738",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Sentence-level Relation Extraction Sentence-level relation extraction mainly includes CNN-based methods (Zeng et al., 2014; dos Santos et al., 2015; Zeng et al., 2015; Peng et al., 2022a), RNN-based methods (Zhang et al., 2015; Cai et al., 2016), GNN-based methods (Zhang et al., 2018; Zhu et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and models for sentence-level relation extraction.",
      "processing_time": 18.555784940719604,
      "citing_paper_id": "254877738",
      "cited_paper_id": 12873739
    },
    {
      "context_text": ", sentence-level relation extraction (SentRE) (Zeng et al., 2014; Lin et al., 2016; Vashishth et al., 2018; Han et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only sentence-level relation extraction methods and papers. No verifiable resources are identified.",
      "processing_time": 20.22027015686035,
      "citing_paper_id": "254877738",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Baselines We compare our model with some typical or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources or datasets mentioned.",
      "processing_time": 19.518399000167847,
      "citing_paper_id": "254877738",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Sentence-level Relation Extraction Sentence-level relation extraction mainly includes CNN-based methods (Zeng et al., 2014; dos Santos et al., 2015; Zeng et al., 2015; Peng et al., 2022a), RNN-based methods (Zhang et al., 2015; Cai et al., 2016), GNN-based methods (Zhang et al., 2018; Zhu et al., 2019) and attention-based methods (Lin et al., 2016; Dai et al., 2019; Ye and Ling, 2019; For better visual effect, we only show part of relations as Figure 3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches for sentence-level relation extraction.",
      "processing_time": 18.574714183807373,
      "citing_paper_id": "254877738",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "The sequence-based models use CNN (Goodfel-low et al., 2016) or LSTM (Schuster and Paliwal, 1997) to encode the entire document directly, just copying the SentRE models and yielding poor performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria.",
      "processing_time": 19.87943935394287,
      "citing_paper_id": "254877738",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "For example, on DocRED dataset (Yao et al., 2019), about 60 of the 96 non-NA relations are long-tailed, with less than 200 training triplets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to study the distribution of relations in document-level relation extraction, focusing on the prevalence of long-tailed relations with fewer than 200 training triplets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocRED' dataset, which is a specific, verifiable resource used for document-level relation extraction. The dataset is described as having many long-tailed relations, which is relevant to the research topic.",
      "processing_time": 28.17459774017334,
      "citing_paper_id": "254877738",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "be mainly divided into three categories, including sequence-based models (Yao et al., 2019), graph-based models (Nan et al., 2020; Zeng et al., 2020; Xu et al., 2021b,c; Li et al., 2022; Peng et al., 2022b) and Transformer-based models (Zhou et al., 2021; Yu et al., 2022; Xie et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of models. However, the cited papers' titles suggest they are related to document-level relation extraction, which is closely related to the research topic.",
      "processing_time": 22.921008586883545,
      "citing_paper_id": "254877738",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "be mainly divided into three categories, including sequence-based models (Yao et al., 2019), graph-based models (Nan et al., 2020; Zeng et al., 2020; Xu et al., 2021b,c; Li et al., 2022; Peng et al., 2022b) and Transformer-based models (Zhou et al., 2021; Yu et al., 2022; Xie et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of models. However, the cited papers' titles suggest they are related to document-level relation extraction, which is closely related to the research topic.",
      "processing_time": 22.921008586883545,
      "citing_paper_id": "254877738",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "be mainly divided into three categories, including sequence-based models (Yao et al., 2019), graph-based models (Nan et al., 2020; Zeng et al., 2020; Xu et al., 2021b,c; Li et al., 2022; Peng et al., 2022b) and Transformer-based models (Zhou et al., 2021; Yu et al., 2022; Xie et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of models. However, the cited papers' titles suggest they are related to document-level relation extraction, which is closely related to the research topic.",
      "processing_time": 22.921008586883545,
      "citing_paper_id": "254877738",
      "cited_paper_id": 249191749
    },
    {
      "context_text": "Further, we count the frequency of co-occurrence be-tween every two relations on DocRED (Yao et al., 2019), and use the positive point-wise mutual information values to measure the correlation of relations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to measure the correlation of relations by counting the frequency of co-occurrence between every two relations, applying positive point-wise mutual information values."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is explicitly mentioned as a dataset used for measuring the correlation of relations through co-occurrence frequency.",
      "processing_time": 24.94177746772766,
      "citing_paper_id": "254877738",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "For instance, more than 40.7% of relational facts on DocRED (a popular relation extraction dataset) can only be extracted across multiple sentences (Yao et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to demonstrate the challenge of extracting relational facts across multiple sentences, highlighting the need for document-level processing in relation extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is explicitly mentioned as a dataset used for document-level relation extraction, which is highly relevant to the research topic of document-level event extraction.",
      "processing_time": 25.201416969299316,
      "citing_paper_id": "254877738",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Yuan et al., 2019; Han et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate document-level relation extraction models, focusing on complex relations across multiple sentences in large-scale documents."
      },
      "confidence_score": 0.8,
      "reasoning": "The citation context does not provide specific information about the datasets used. However, the cited paper titles suggest the use of document-level relation extraction datasets.",
      "processing_time": 25.620509147644043,
      "citing_paper_id": "254877738",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Yuan et al., 2019; Han et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate document-level relation extraction models, focusing on complex relations across multiple sentences in large-scale documents."
      },
      "confidence_score": 0.8,
      "reasoning": "The citation context does not provide specific information about the datasets used. However, the cited paper titles suggest the use of document-level relation extraction datasets.",
      "processing_time": 25.620509147644043,
      "citing_paper_id": "254877738",
      "cited_paper_id": 234762787
    },
    {
      "context_text": "We conduct statistical analysis on DocRED dataset (Yao et al., 2019",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for conducting statistical analysis on document-level relation extraction, focusing on identifying relations within and across sentences in long documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocRED dataset' which is a specific, verifiable dataset used for document-level relation extraction.",
      "processing_time": 24.45391011238098,
      "citing_paper_id": "254877738",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "We build our base model ( BERT BASE ) on the existing baselines (Wang et al., 2019; Zhou et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and baselines. No verifiable resources are identified.",
      "processing_time": 19.0921049118042,
      "citing_paper_id": "254877738",
      "cited_paper_id": 202889074
    },
    {
      "context_text": "We build our base model ( BERT BASE ) on the existing baselines (Wang et al., 2019; Zhou et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and baselines. No verifiable resources are identified.",
      "processing_time": 19.0921049118042,
      "citing_paper_id": "254877738",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "The resulting representation is fed to the grouped bilinear classiﬁer (Tang et al., 2020). where the number of groups and σ is the sigmoid activation function.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context is focused on the technical details of a classifier.",
      "processing_time": 20.51596760749817,
      "citing_paper_id": "254877738",
      "cited_paper_id": 207863292
    },
    {
      "context_text": "Macro@500 Macro@200 Macro@100 Macro Macro@100 Macro@50 Correl BASE .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific dataset names or verifiable resources. It appears to be a list of evaluation metrics or settings.",
      "processing_time": 20.511510610580444,
      "citing_paper_id": "254877738",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "…or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al., 2016), Context-Aware (Sorokin and Gurevych, 2017), CorefBERT (Ye et al., 2020), GAIN (Zeng et al., 2020), SSAN (Xu et al., 2021a), ATLOP (Zhou et al., 2021), ERA/ERACL (Du et al., 2022) and RSMAN (Yu et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 21.04501438140869,
      "citing_paper_id": "254877738",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "Further, our model BERT-Correl BASE improves the performance of BERT BASE by 1.30%, 1.24%, 1.09%, 1.12% for each column on DocRED dataset and 1.70%, 2.35%, 2.72%, 2.44% for each column on DWIE dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "DWIE"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate the performance of BERT-Correl BASE compared to BERT BASE, focusing on document-level relation extraction and coreference resolution.",
        "DWIE": "Used to evaluate the performance of BERT-Correl BASE compared to BERT BASE, focusing on document-level information extraction and entity linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, DocRED and DWIE, which are used to evaluate the performance of the BERT-Correl BASE model against BERT BASE.",
      "processing_time": 34.3416588306427,
      "citing_paper_id": "254877738",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "In particular, for entity pairs with 4 labels on DocRED, our BERT-Correl BASE improves by 12.39%.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance improvements on a task. The context is too limited to infer the use of a dataset.",
      "processing_time": 21.4282546043396,
      "citing_paper_id": "254877738",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "The subscript “ BASE ” indicates using BERT-base as the backbone encoder.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BERT-base). No verifiable resources are identified.",
      "processing_time": 19.430379152297974,
      "citing_paper_id": "254877738",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "We conduct experiments on long-tailed relations and multi-label entity pairs of DocRED, respectively, using our base model ( BERT BASE ).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to conduct experiments on long-tailed relations and multi-label entity pairs, focusing on document-level event extraction using a base model."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' as a dataset used for experiments on long-tailed relations and multi-label entity pairs. BERT BASE is mentioned as a model, not a dataset.",
      "processing_time": 36.186020374298096,
      "citing_paper_id": "254877738",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "We can ﬁnd that our base model ( BERT BASE ) outperforms some earlier BERT-based baselines, CorefBERT BASE (Ye et al., 2020) and SSAN (Xu et al., 2021a), on all result columns of DocRED and DWIE datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "DWIE"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate model performance on document-level relation extraction, focusing on coreference resolution and entity linking.",
        "DWIE": "Used to assess model performance on document-level information extraction, emphasizing the identification of complex events and relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' and 'DWIE' as datasets used for evaluating model performance. These are specific datasets relevant to document-level event extraction.",
      "processing_time": 39.255178451538086,
      "citing_paper_id": "254877738",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "However, existing studies rely heavily on Transformer (Zhou et al., 2021; Xie et al., 2022) or rule-based document graph (Nan et al., 2020; Zeng et al., 2020; Xu et al., 2021b; Peng et al., 2022b) to obtain contextual representations, ignore the inter-dependencies among relations and therefore…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the methodologies used for obtaining contextual representations in document-level relation extraction.",
      "processing_time": 28.60294222831726,
      "citing_paper_id": "254877738",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "These meth-ods mainly beneﬁt from local features (Peng et al., 2020) such as entity type, entity position, etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and features. There are no clear identifiers for datasets in the given context.",
      "processing_time": 27.94730234146118,
      "citing_paper_id": "254877738",
      "cited_paper_id": 222133166
    },
    {
      "context_text": "Then Peng et al. (2022a) and Han et al. (2022) introduce relation correlations into the hierarchical relation extraction task under the distant supervision paradigm, and achieve state-of-the-art performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The focus is on the introduction of relation correlations in hierarchical relation extraction.",
      "processing_time": 28.602582216262817,
      "citing_paper_id": "254877738",
      "cited_paper_id": 234762787
    },
    {
      "context_text": ", 2021), ERA/ERACL (Du et al., 2022) and RSMAN (Yu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions ERA/ERACL and RSMAN, but these are likely methods or models rather than datasets. No clear dataset names are provided in the context.",
      "processing_time": 29.749521493911743,
      "citing_paper_id": "254877738",
      "cited_paper_id": 248987560
    },
    {
      "context_text": "…or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al., 2016), Context-Aware (Sorokin and Gurevych, 2017), CorefBERT (Ye et al., 2020), GAIN (Zeng et al., 2020), SSAN (Xu et al., 2021a), ATLOP (Zhou et al., 2021), ERA/ERACL (Du et al., 2022) and RSMAN (Yu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No dataset names are present in the text.",
      "processing_time": 28.105602979660034,
      "citing_paper_id": "254877738",
      "cited_paper_id": 248987560
    },
    {
      "context_text": "…or recent baselines, including CNN (Zeng et al., 2014), LSTM/BiLSTM (Cai et al., 2016), Context-Aware (Sorokin and Gurevych, 2017), CorefBERT (Ye et al., 2020), GAIN (Zeng et al., 2020), SSAN (Xu et al., 2021a), ATLOP (Zhou et al., 2021), ERA/ERACL (Du et al., 2022) and RSMAN (Yu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No dataset names are present in the text.",
      "processing_time": 28.105602979660034,
      "citing_paper_id": "254877738",
      "cited_paper_id": 249191749
    },
    {
      "context_text": "For DocRED, the results are from their original paper, while for DWIE, we use the results reported in Yu et al. (2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "DWIE"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate document-level relation extraction, focusing on complex relations across multiple sentences in scientific articles.",
        "DWIE": "Used to assess document-level information extraction, specifically for identifying and linking entities and relations within Wikipedia articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, DocRED and DWIE, which are used for document-level relation extraction. The citation intent is to report results from these datasets.",
      "processing_time": 40.064645528793335,
      "citing_paper_id": "254877738",
      "cited_paper_id": 249191749
    },
    {
      "context_text": "Thus, based on the semantics of the dependency relations (De Marneﬀe and Manning, 2008; De Marneﬀe et al., 2014; Schuster and Manning, 2016), we further process the dependency structure with heuristic rules to obtain a simpliﬁed dependency tree with informative phrases, as shown in Figure 3(b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only dependency relations and processing methods.",
      "processing_time": 27.03919792175293,
      "citing_paper_id": "268249143",
      "cited_paper_id": 14221870
    },
    {
      "context_text": "For instance, there are approximately 68.7% of causal relationships in English corpora (Caselli and Vossen, 2017) are attributed to inter-sentence event pairs.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'English corpora' but does not specify a named dataset. The cited paper title suggests a specific dataset, but it is not mentioned in the context.",
      "processing_time": 29.52617120742798,
      "citing_paper_id": "268249143",
      "cited_paper_id": 38234032
    },
    {
      "context_text": "Recently, cross-lingual contextualized embeddings have achieved promising results. e.g., mBERT (Devlin et al., 2019), XLMR (Conneau et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models (mBERT, XLMR) but does not refer to any specific datasets. The citation is used to reference the models, not datasets.",
      "processing_time": 29.905518293380737,
      "citing_paper_id": "268249143",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We utilize the multilingual PLMs, i.e., mBERT (Devlin et al., 2019) or XLMR (Con-neau et al., 2020) as the backbone.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions multilingual PLMs (mBERT and XLMR) but does not refer to them as datasets. They are models, not datasets.",
      "processing_time": 29.528043031692505,
      "citing_paper_id": "268249143",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "As depicted in the",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation span does not contain any specific dataset names or verifiable resources. The context is incomplete and does not provide enough information to identify datasets.",
      "processing_time": 29.128361463546753,
      "citing_paper_id": "268249143",
      "cited_paper_id": 109933467
    },
    {
      "context_text": "As depicted in the",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation span does not contain any specific dataset names or verifiable resources. The context is incomplete and does not provide enough information to identify datasets.",
      "processing_time": 29.128361463546753,
      "citing_paper_id": "268249143",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "As depicted in the",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation span does not contain any specific dataset names or verifiable resources. The context is incomplete and does not provide enough information to identify datasets.",
      "processing_time": 29.128361463546753,
      "citing_paper_id": "268249143",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "Previous studies only exploit the nodes in dependency tree as language-independent information to enhance ECI systems (Gao et al., 2019; Tran Phu and Nguyen, 2021) and overlook the rich semantics of dependency relations.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only previous studies and their approaches. No verifiable resources are identified.",
      "processing_time": 28.343849420547485,
      "citing_paper_id": "268249143",
      "cited_paper_id": 109933467
    },
    {
      "context_text": "Most previous methods (Kadowaki et al., 2019; Liu et al., 2020a; Zuo et al., 2021; Cao et al., 2021) focus on sentence-level with English corpora.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'English corpora' but does not specify any particular dataset names. The term 'corpora' is too generic without specific identifiers.",
      "processing_time": 29.888630628585815,
      "citing_paper_id": "268249143",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "Most previous methods (Kadowaki et al., 2019; Liu et al., 2020a; Zuo et al., 2021; Cao et al., 2021) focus on sentence-level with English corpora.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'English corpora' but does not specify any particular dataset names. The term 'corpora' is too generic without specific identifiers.",
      "processing_time": 29.888630628585815,
      "citing_paper_id": "268249143",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Most previous methods (Kadowaki et al., 2019; Liu et al., 2020a; Zuo et al., 2021; Cao et al., 2021) focus on sentence-level with English corpora.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'English corpora' but does not specify any particular dataset names. The term 'corpora' is too generic without specific identifiers.",
      "processing_time": 29.888630628585815,
      "citing_paper_id": "268249143",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "While pre-trained language models have exhibited remarkable capabilities across various tasks (Brown et al., 2020 Chowdhery et al., 2022; Wang et al., 2023; Tan et al., 2023; Liang Zhang et al., 2023), they still struggle in multilingual setting, as evidenced in recent studies (Chang et al., 2023;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to pre-trained language models and their performance in multilingual settings.",
      "processing_time": 28.761946201324463,
      "citing_paper_id": "268249143",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "Qin et al. (2020) leverage a data augmentation framework to generate multi-lingual codeswitching data to ﬁne-tune mBERT.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'multi-lingual codeswitching data' but does not specify a named dataset. The cited paper title suggests a method for data augmentation rather than a specific dataset.",
      "processing_time": 31.468571662902832,
      "citing_paper_id": "268249143",
      "cited_paper_id": 219573540
    },
    {
      "context_text": "We select appropriate positive and negative samples for anchor statement: Positive Samples Given each anchor causal statement, we follow Qin et al. (2020) to use MUSE bilingual dictionaries to generate multilingual code-switched statements as the positive samples.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUSE bilingual dictionaries"
      ],
      "dataset_descriptions": {
        "MUSE bilingual dictionaries": "Used to generate multilingual code-switched statements as positive samples for anchor causal statements, enhancing cross-lingual NLP capabilities."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions using MUSE bilingual dictionaries to generate positive samples for multilingual code-switched statements. MUSE is a specific resource used for this purpose.",
      "processing_time": 37.05295205116272,
      "citing_paper_id": "268249143",
      "cited_paper_id": 219573540
    },
    {
      "context_text": "Unlike Qin et al. (2020) which randomly replace a word at a time, we operate on phrases in statements.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological difference from another work.",
      "processing_time": 27.15651559829712,
      "citing_paper_id": "268249143",
      "cited_paper_id": 219573540
    },
    {
      "context_text": "We compare our method with the vanilla PLM, LLM and three strong monolingual baselines (we replace their backbones with multilingual PLM): (1) PLM By leveraging the embeddings h i , h j of two events, the overall representation vector is formed (2) Know Liu et al. (2020a) retrieves exter-nal knowledge from knowledge base and event-agnostic, context-speciﬁc patterns to enrich the representations of events for causality identiﬁcation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on comparing methods and using external knowledge from a knowledge base, which is not a dataset.",
      "processing_time": 31.46621870994568,
      "citing_paper_id": "268249143",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Inspired by sentence-level ECI studies (Liu et al., 2020a; Zuo et al., 2021), which leverage the context-speciﬁc causal patterns of statements, for example, we can leverage the causal pattern “ The [EVENT] generates [EVENT] ... ” to identify the causation between traﬃc congestion and environmental…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general concepts and methods. No clear identifiers for datasets are present.",
      "processing_time": 28.74187731742859,
      "citing_paper_id": "268249143",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Inspired by sentence-level ECI studies (Liu et al., 2020a; Zuo et al., 2021), which leverage the context-speciﬁc causal patterns of statements, for example, we can leverage the causal pattern “ The [EVENT] generates [EVENT] ... ” to identify the causation between traﬃc congestion and environmental…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general concepts and methods. No clear identifiers for datasets are present.",
      "processing_time": 28.74187731742859,
      "citing_paper_id": "268249143",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "Recently, Liu et al. (2020a) exploits event-agnostic, context-speciﬁc patterns which achieve promising performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context is too vague to identify a reusable resource.",
      "processing_time": 29.303436040878296,
      "citing_paper_id": "268249143",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "…backbones with multilingual PLM): (1) PLM By leveraging the embeddings h i , h j of two events, the overall representation vector is formed (2) Know Liu et al. (2020a) retrieves exter-nal knowledge from knowledge base and event-agnostic, context-speciﬁc patterns to enrich the representations of…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited paper title suggests the use of a knowledge base, but no specific dataset name is provided.",
      "processing_time": 31.110878705978394,
      "citing_paper_id": "268249143",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Given a sentence s = { w j } | s | j =1 ∈ D , we use the multilingual NLP toolkit Trankit (Nguyen et al., 2021), which has an overall performance of about 93% across diﬀerent languages in sentence parsing, to obtain the dependency tree as shown in Figure 3(a).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of Trankit, a multilingual NLP toolkit, for obtaining dependency trees. However, Trankit is a toolkit, not a dataset, and there are no specific datasets mentioned.",
      "processing_time": 33.32237434387207,
      "citing_paper_id": "268249143",
      "cited_paper_id": 231572779
    },
    {
      "context_text": "Event Causality Identiﬁcation (ECI) is an important task in natural language processing (NLP), which can facilitate various applications, including explain-able question answering (Yang et al., 2018b), intelligent search (Rudnik et al., 2019) and complex reasoning (Dalvi et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications of Event Causality Identification. No dataset names are present.",
      "processing_time": 29.081192016601562,
      "citing_paper_id": "268249143",
      "cited_paper_id": 233297051
    },
    {
      "context_text": "As Zuo et al. (2021) learn context-speciﬁc causal patterns from causal statements, we propose a statement-level causal pattern contrastive learning loss to explicitly align causal representations of anchor statement with the generated positive sample.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for learning causal patterns from causal statements.",
      "processing_time": 28.354351043701172,
      "citing_paper_id": "268249143",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "Hence, identifying causality of events at the document-level is necessary, which gains increasing attention recently (Tran Phu and Nguyen, 2021; Fan et al., 2022; Boxi Cao et al., 2024; Chen et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 31.121584177017212,
      "citing_paper_id": "268249143",
      "cited_paper_id": 250340267
    },
    {
      "context_text": "Note that the performance of RichGCN with mBERT drops signiﬁcantly for three target languages Danish (by 25.1%), Spanish (by 25.7%), and Urdu (by 12.9%), we observed the same trend in our experiments with GPT-3.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics across languages. No verifiable resources are identified.",
      "processing_time": 28.015265703201294,
      "citing_paper_id": "268249143",
      "cited_paper_id": 258079179
    },
    {
      "context_text": "Due to its distinct morphology and syntax compared to the other four languages, Urdu exhibits below-average performance, warranting further attention in future research.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general observation about Urdu performance in multilingual learning.",
      "processing_time": 28.499049186706543,
      "citing_paper_id": "268249143",
      "cited_paper_id": 258079179
    },
    {
      "context_text": "5 performs the best in English and the worst in Urdu.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance comparisons across languages.",
      "processing_time": 27.568482637405396,
      "citing_paper_id": "268249143",
      "cited_paper_id": 258079179
    },
    {
      "context_text": "We use language speciﬁc PLMs, i.e., BotXO2 2 for Danish, BERT (De-vlin et al., 2019) for English, BETO (Canete et al., 2020) for Spanish, BERTurk (Schweter, 2020) for Turkish, and UrduHack 3 for Urdu.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several language models but does not refer to any specific datasets. The context is about using different models for different languages, which is not relevant to document-level event extraction datasets.",
      "processing_time": 32.27431392669678,
      "citing_paper_id": "268249143",
      "cited_paper_id": 258079179
    },
    {
      "context_text": "5, demonstrating that despite extensive training on high-resource language English, LLM fails to achieve plug-and-play functionality when faced with complex cross-lingual tasks, which is consistent with Lai et al. (2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general evaluation of language models across languages.",
      "processing_time": 28.281965017318726,
      "citing_paper_id": "268249143",
      "cited_paper_id": 258079179
    },
    {
      "context_text": "It comprises as many as 3591 documents of ﬁve ty-pologically diverse languages, i.e., English, Danish, Spanish, Turkish, and Urdu, the details are shown in Table 1.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions a collection of documents across multiple languages but does not provide a specific name for the dataset. The description is too generic and lacks a clear identifier.",
      "processing_time": 30.740206956863403,
      "citing_paper_id": "268249143",
      "cited_paper_id": 258079179
    },
    {
      "context_text": "English Danish Spanish Turkish Urdu shown in Table 5, the F1 score would decreases 1.3% ~3.8% without the top ﬁve types of edges.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics across languages. No clear identifiers for datasets are present.",
      "processing_time": 29.045227766036987,
      "citing_paper_id": "268249143",
      "cited_paper_id": 258079179
    },
    {
      "context_text": "Moreover, The drop of RichGCN for Urdu → Turkish is smaller compared to ours.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between models. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 30.282315492630005,
      "citing_paper_id": "268249143",
      "cited_paper_id": 258079179
    },
    {
      "context_text": "Particularly for low-resource languages, the model performs even worse, such as achieving only a 6.3% accuracy in Urdu (Lai et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics for a model in a low-resource language.",
      "processing_time": 28.267119646072388,
      "citing_paper_id": "268249143",
      "cited_paper_id": 258079179
    },
    {
      "context_text": "We separately report the cross-lingual performance with low-source language Danish, Spanish, Turkish, and Urdu as source language.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only languages used for evaluation. No clear identifiers for datasets are present.",
      "processing_time": 29.022263765335083,
      "citing_paper_id": "268249143",
      "cited_paper_id": 258079179
    },
    {
      "context_text": "Recent studies (Mintz et al. 2009; Zeng et al. 2015) have demonstrated its effectiveness in various NLP tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to studies demonstrating effectiveness in NLP tasks.",
      "processing_time": 28.684237241744995,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9700115
    },
    {
      "context_text": "Using the structured tables from FreeBase and Wikipedia, we are able to automatically generate a large number of training instances – resulting in a training dataset that is 14x greater than the widely used ACE Challenge dataset(Doddington et al. 2004), and our dataset was automatically constructed within hours instead of costing years of linguists and annotators’ time.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE Challenge dataset"
      ],
      "dataset_descriptions": {
        "ACE Challenge dataset": "Used as a benchmark to compare the size and construction time of the automatically generated dataset, highlighting the efficiency and scale of the new approach."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE Challenge dataset' which is a specific, verifiable dataset. It is used for comparison with the automatically generated dataset described in the current research.",
      "processing_time": 37.80300688743591,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "On ACE : We also test our strategy on the ACE dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE"
      ],
      "dataset_descriptions": {
        "ACE": "Used to test the proposed strategy on document-level event extraction, focusing on the performance and accuracy of the method in identifying events within documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE dataset, which is a specific, verifiable dataset used in the research. The title confirms it is a dataset.",
      "processing_time": 36.575634717941284,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "We follow IMP&TIME + DIS to examine every sentence whether it can be selected as an annotated instance within the ACE event types.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'ACE event types' which refers to the ACE program, but does not explicitly mention a dataset. The title confirms it's about the ACE program, which is a task and evaluation framework rather than a dataset.",
      "processing_time": 33.720322132110596,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "For feature-based methods, we apply CRF (using the CRF++ toolkit (Kudo 2005) ) and Maximum Entropy (Berger, Pietra, and Pietra 1996) (Le Zhang’s MaxEnt toolkit) to explore a variety of elaborate features, according to the state-of-art feature-based ACE event extractors (Li, Ji, and Huang 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'state-of-art feature-based ACE event extractors' which refers to the ACE program, but does not explicitly mention using a specific dataset. The citation is more about the method and the evaluation framework rather than a reusable dataset.",
      "processing_time": 34.9112024307251,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "We ﬁrst collect all annotated events, without triggers, as the knowledge base to compute the importance values for all arguments, and select the key arguments for each ACE event type accordingly.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE"
      ],
      "dataset_descriptions": {
        "ACE": "Used to compute importance values for arguments and select key arguments for each event type, enhancing document-level event extraction accuracy."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ACE event type' which is likely referring to the ACE dataset, a well-known resource in the field of information extraction.",
      "processing_time": 36.16973829269409,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "Using the structured tables from FreeBase and Wikipedia, we are able to automatically generate a large number of training instances – resulting in a training dataset that is 14x greater than the widely used ACE Challenge dataset(Dod-dington et al. 2004), and our dataset was automatically constructed within hours instead of costing years of linguists and annotators’ time.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE Challenge dataset"
      ],
      "dataset_descriptions": {
        "ACE Challenge dataset": "Used for comparison with an automatically generated dataset, highlighting the size and construction time differences. The research investigates the efficiency of automatic dataset generation for event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE Challenge dataset' which is a specific, verifiable dataset. It is used for comparison with the automatically generated dataset in terms of size and construction time.",
      "processing_time": 39.20690941810608,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "Among all strategies, the dataset by IMP&TIME + DIS achieves the best quality, while still accounting for 46735 sentences with 50109 events, almost 10 times more than the ACE dataset, showing that it is feasible to automatically collect quality training data for event extraction without either human-designed event schemas or extra human annotations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "IMP&TIME + DIS",
        "ACE"
      ],
      "dataset_descriptions": {
        "IMP&TIME + DIS": "Used to automatically collect quality training data for event extraction, containing 46735 sentences with 50109 events, demonstrating feasibility without human-designed event schemas or extra annotations.",
        "ACE": "Used as a benchmark for comparison, containing significantly fewer sentences and events, highlighting the scalability of the IMP&TIME + DIS dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets: 'IMP&TIME + DIS' and 'ACE'. Both are specific and have clear identifiers. The IMP&TIME + DIS dataset is described as having a large number of sentences and events, making it suitable for automatic collection of training data for event extraction.",
      "processing_time": 51.617255210876465,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "We ﬁnd that the main reason for the missing 35.3% is that many arguments in the ACE dataset are pronouns, where our strategy is currently unable to treat pronouns as key arguments.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE"
      ],
      "dataset_descriptions": {
        "ACE": "Used to evaluate the system's performance in handling pronouns as key arguments, highlighting issues with current strategies in argument extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE dataset, which is a specific, verifiable dataset used in the research. The dataset is used to evaluate the performance of the system in handling pronouns as key arguments.",
      "processing_time": 37.964932680130005,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "Eventually, we correctly obtain 3,448 sentences as positive instances, covering 64.7% of the original ACE dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE dataset"
      ],
      "dataset_descriptions": {
        "ACE dataset": "Used to extract positive instances for document-level event extraction, focusing on identifying sentences that contain events. The dataset is utilized to cover 64.7% of the original content."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'ACE dataset', which is a specific, verifiable dataset used in the research. The cited paper title confirms it is a dataset.",
      "processing_time": 38.71929955482483,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9776219
    },
    {
      "context_text": ", MUC (Grishman and Sundheim 1996), ACE (Doddington et al. 2004), ERE (Song et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE",
        "ERE"
      ],
      "dataset_descriptions": {
        "MUC": "Used for evaluating document-level event extraction, focusing on named entity recognition and relation extraction tasks.",
        "ACE": "Used for document-level event extraction, specifically for identifying and classifying events and entities in text.",
        "ERE": "Used for document-level event extraction, emphasizing cross-document coreference and event argument linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions MUC, ACE, and ERE, which are known datasets in the field of information extraction. The context suggests these are used for document-level event extraction.",
      "processing_time": 46.48672103881836,
      "citing_paper_id": "19224644",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "The model used in stage 1 consists of a Bidirectional Long Short-Term Memory (BLSTM) network with a conditional random ﬁeld (Lafferty, McCallum, and Pereira 2001) (CRF) layer and an Integer Linear Programming (ILP) based post inference.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the architecture of the model used in stage 1.",
      "processing_time": 31.350545167922974,
      "citing_paper_id": "19224644",
      "cited_paper_id": 219683473
    },
    {
      "context_text": ", 2019) as well as incorporating global features for joint inference (Li et al., 2013; Yang and Mitchell, 2016; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and approaches. The cited papers' titles also do not provide clear evidence of specific datasets.",
      "processing_time": 32.22117209434509,
      "citing_paper_id": "258865260",
      "cited_paper_id": 2114517
    },
    {
      "context_text": ", 2019) as well as incorporating global features for joint inference (Li et al., 2013; Yang and Mitchell, 2016; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and approaches. The cited papers' titles also do not provide clear evidence of specific datasets.",
      "processing_time": 32.22117209434509,
      "citing_paper_id": "258865260",
      "cited_paper_id": 2367456
    },
    {
      "context_text": ", 2019) as well as incorporating global features for joint inference (Li et al., 2013; Yang and Mitchell, 2016; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and approaches. The cited papers' titles also do not provide clear evidence of specific datasets.",
      "processing_time": 32.22117209434509,
      "citing_paper_id": "258865260",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Previous classification-based approaches have utilized pipelined approaches (Yang et al., 2019a; Wadden et al., 2019) as well as incorporating global features for joint inference (Li et al., 2013; Yang and Mitchell, 2016; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 31.582266569137573,
      "citing_paper_id": "258865260",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Previous classification-based approaches have utilized pipelined approaches (Yang et al., 2019a; Wadden et al., 2019) as well as incorporating global features for joint inference (Li et al., 2013; Yang and Mitchell, 2016; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 31.582266569137573,
      "citing_paper_id": "258865260",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Previous classification-based approaches have utilized pipelined approaches (Yang et al., 2019a; Wadden et al., 2019) as well as incorporating global features for joint inference (Li et al., 2013; Yang and Mitchell, 2016; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 31.582266569137573,
      "citing_paper_id": "258865260",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Previous classification-based approaches have utilized pipelined approaches (Yang et al., 2019a; Wadden et al., 2019) as well as incorporating global features for joint inference (Li et al., 2013; Yang and Mitchell, 2016; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 31.582266569137573,
      "citing_paper_id": "258865260",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "The final IAA measured as Cohen’s Kappa (McHugh, 2012) was 0.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a statistical measure (Cohen’s Kappa) used to assess inter-rater reliability.",
      "processing_time": 31.022597551345825,
      "citing_paper_id": "258865260",
      "cited_paper_id": 5421278
    },
    {
      "context_text": "The final IAA measured as Cohen’s Kappa (McHugh, 2012) was 0 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a statistical measure (Cohen’s Kappa) used to assess inter-rater reliability.",
      "processing_time": 31.018131256103516,
      "citing_paper_id": "258865260",
      "cited_paper_id": 5421278
    },
    {
      "context_text": "We observe that GENEVA is relatively more diverse than the other datasets. question answering (Berant et al., 2014), and others (Hogenboom et al., 2016; Wen et al., 2021; Yang et al., 2019b).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENEVA"
      ],
      "dataset_descriptions": {
        "GENEVA": "Mentioned as being more diverse than other datasets, but no specific usage details are provided in the citation context."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'GENEVA' as a dataset and compares its diversity to other datasets. However, no specific usage details are provided in the citation context.",
      "processing_time": 37.57566833496094,
      "citing_paper_id": "258865260",
      "cited_paper_id": 8471750
    },
    {
      "context_text": "We observe that GENEVA is relatively more diverse than the other datasets. question answering (Berant et al., 2014), and others (Hogenboom et al., 2016; Wen et al., 2021; Yang et al., 2019b).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENEVA"
      ],
      "dataset_descriptions": {
        "GENEVA": "Mentioned as being more diverse than other datasets, but no specific usage details are provided in the citation context."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'GENEVA' as a dataset and compares its diversity to other datasets. However, no specific usage details are provided in the citation context.",
      "processing_time": 37.57566833496094,
      "citing_paper_id": "258865260",
      "cited_paper_id": 41089825
    },
    {
      "context_text": "We observe that GENEVA is relatively more diverse than the other datasets. question answering (Berant et al., 2014), and others (Hogenboom et al., 2016; Wen et al., 2021; Yang et al., 2019b).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENEVA"
      ],
      "dataset_descriptions": {
        "GENEVA": "Mentioned as being more diverse than other datasets, but no specific usage details are provided in the citation context."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'GENEVA' as a dataset and compares its diversity to other datasets. However, no specific usage details are provided in the citation context.",
      "processing_time": 37.57566833496094,
      "citing_paper_id": "258865260",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "question answering (Berant et al., 2014), and others (Hogenboom et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There are no clear identifiers for datasets or resources.",
      "processing_time": 30.96969199180603,
      "citing_paper_id": "258865260",
      "cited_paper_id": 8471750
    },
    {
      "context_text": "In our work, we follow MUC to consider a broader range of events and event arguments.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MUC' which is likely referring to the Message Understanding Conferences, but it does not specify a dataset. The citation is more about following a method or standard rather than using a specific dataset.",
      "processing_time": 33.889301776885986,
      "citing_paper_id": "258865260",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "Following the early works of MUC (Sundheim, 1992; Grish-man and Sundheim, 1996), event arguments are defined as participants in the event which provide specific and salient information about the event.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC but does not specify it as a dataset. It is referenced as a conference and early work in the field, not as a reusable dataset.",
      "processing_time": 31.897001266479492,
      "citing_paper_id": "258865260",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "Through extensive human expert annotations, we design mappings 2 Related Work Event Extraction Datasets and Ontologies: The earliest datasets in event extraction date back to MUC (Sundheim, 1992; Grishman and Sundheim, 1996).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to trace the history of event extraction datasets, focusing on the early development of annotated corpora for information extraction tasks."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which is a well-known series of conferences that produced datasets for event extraction. However, the specific dataset name is not clearly identified beyond the conference acronym.",
      "processing_time": 38.6825909614563,
      "citing_paper_id": "258865260",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "Event Extraction Datasets and Ontologies: The earliest datasets in event extraction date back to MUC (Sundheim, 1992; Grishman and Sundheim, 1996).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to develop and evaluate early event extraction systems, focusing on named entity recognition and relation extraction tasks."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which is a well-known series of conferences that produced datasets for event extraction. However, the specific dataset names are not provided, only the conference name.",
      "processing_time": 38.15629267692566,
      "citing_paper_id": "258865260",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "Following the early works of MUC (Sundheim, 1992; Grishman and Sundheim, 1996), event arguments are defined as participants in the event which provide specific and salient information about the event.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC but does not refer to it as a dataset. It is used to provide historical context for the definition of event arguments.",
      "processing_time": 30.989776372909546,
      "citing_paper_id": "258865260",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "To reduce human effort, we exploit the shared properties between semantic role labeling (SRL) and EAE (Aguilar et al., 2014) and leverage a diverse and exhaustive SRL dataset, FrameNet (Baker et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FrameNet"
      ],
      "dataset_descriptions": {
        "FrameNet": "Leveraged as a diverse and exhaustive SRL dataset to exploit shared properties with event argument extraction, reducing human effort in annotation."
      },
      "confidence_score": 1.0,
      "reasoning": "FrameNet is mentioned as a dataset used for semantic role labeling (SRL), which shares properties with event argument extraction (EAE). It is described as diverse and exhaustive.",
      "processing_time": 38.84020495414734,
      "citing_paper_id": "258865260",
      "cited_paper_id": 12793034
    },
    {
      "context_text": "The similarity between SRL and EAE (Aguilar et al., 2014) provides us with the ground for leveraging FrameNet.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a reference to FrameNet which is a lexical resource, not a dataset. No other specific resources are mentioned.",
      "processing_time": 32.94580817222595,
      "citing_paper_id": "258865260",
      "cited_paper_id": 12793034
    },
    {
      "context_text": "The similarity be-tween SRL and EAE (Aguilar et al., 2014) provides us with the ground for leveraging FrameNet.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a reference to FrameNet which is a lexical resource, not a dataset. No other specific resources are mentioned.",
      "processing_time": 33.16813802719116,
      "citing_paper_id": "258865260",
      "cited_paper_id": 12793034
    },
    {
      "context_text": "Event Type: Leadership However, it is a challenging and tedious task that requires extensive expert supervision if building from scratch. to victory King Hammurabi led Babylon to To reduce human effort while maintaining high quality, we leverage the shared properties of SRL and EAE and utilize a diverse and comprehensive SRL dataset — FrameNet to design our ontology.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FrameNet"
      ],
      "dataset_descriptions": {
        "FrameNet": "Utilized to design the ontology for event argument extraction, leveraging shared properties with semantic role labeling to reduce human effort while maintaining high quality."
      },
      "confidence_score": 1.0,
      "reasoning": "FrameNet is mentioned as a dataset used to design the ontology for event argument extraction, leveraging shared properties with SRL.",
      "processing_time": 37.34022903442383,
      "citing_paper_id": "258865260",
      "cited_paper_id": 12793034
    },
    {
      "context_text": "In our work, we exploit the shared relations be-tween SRL and EAE to create a new large and diverse event argument ontology spanning 115 event types and 220 argument roles.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a new ontology created by the authors. No verifiable resources are identified.",
      "processing_time": 30.94319176673889,
      "citing_paper_id": "258865260",
      "cited_paper_id": 12793034
    },
    {
      "context_text": "To reduce human effort, we exploit the shared properties between semantic role labeling (SRL) and EAE (Aguilar et al., 2014) and leverage a diverse and exhaustive SRL dataset, FrameNet (Baker et al., 1998), to build the ontology.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FrameNet"
      ],
      "dataset_descriptions": {
        "FrameNet": "Leveraged to build the ontology, exploiting shared properties with semantic role labeling and event argument extraction, providing a diverse and exhaustive resource."
      },
      "confidence_score": 1.0,
      "reasoning": "FrameNet is mentioned as a specific dataset used to build the ontology, leveraging its properties similar to SRL and EAE.",
      "processing_time": 37.074355125427246,
      "citing_paper_id": "258865260",
      "cited_paper_id": 12793034
    },
    {
      "context_text": "The ACE ontology was further simplified and extended to ERE (Song et al., 2015) and various TAC KBP Challenges (Ellis et al., 2014, 2015; Getman et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions TAC KBP Challenges, which are typically associated with evaluation datasets, but does not specify any particular dataset names. The context focuses on the simplification and extension of ontologies rather than the use of specific datasets.",
      "processing_time": 35.27428984642029,
      "citing_paper_id": "258865260",
      "cited_paper_id": 63410500
    },
    {
      "context_text": "It comprises 1200+ semantic frames (Fillmore et al., 1976), where a frame is a holistic background that unites similar words.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to semantic frames, which are part of a theoretical framework rather than a dataset.",
      "processing_time": 32.92183876037598,
      "citing_paper_id": "258865260",
      "cited_paper_id": 85223883
    },
    {
      "context_text": "Previous classification-based approaches have utilized pipelined approaches (Yang et al., 2019a; Wadden et al., 2019) as well as incorporating global features for joint inference (Li et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 30.351420879364014,
      "citing_paper_id": "258865260",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Previous classification-based approaches have utilized pipelined approaches (Yang et al., 2019a; Wadden et al., 2019) as well as incorporating global features for joint inference (Li et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 30.351420879364014,
      "citing_paper_id": "258865260",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "We use these test suites to benchmark various classes of EAE models - traditional classificationbased models (Wadden et al., 2019; Lin et al., 2020; Wang et al., 2022a), question-answeringbased models (Du and Cardie, 2020), and generative approaches (Paolini et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 32.118504762649536,
      "citing_paper_id": "258865260",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "We use these test suites to benchmark various classes of EAE models - traditional classificationbased models (Wadden et al., 2019; Lin et al., 2020; Wang et al., 2022a), question-answeringbased models (Du and Cardie, 2020), and generative approaches (Paolini et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 32.118504762649536,
      "citing_paper_id": "258865260",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "We use these test suites to benchmark various classes of EAE models - traditional classificationbased models (Wadden et al., 2019; Lin et al., 2020; Wang et al., 2022a), question-answeringbased models (Du and Cardie, 2020), and generative approaches (Paolini et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 32.118504762649536,
      "citing_paper_id": "258865260",
      "cited_paper_id": 238856763
    },
    {
      "context_text": "Second, macro score evaluation reveals how models like TANL and DyGIE++ can be easily biased toward high-data events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance. There are no clear identifiers for datasets in the text.",
      "processing_time": 31.854397535324097,
      "citing_paper_id": "258865260",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Experiments for DyGIE++ were run on a NVIDIA GeForce RTX 2080 Ti machine with support for 4 GPUs.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only hardware details. There are no verifiable resources or datasets mentioned.",
      "processing_time": 30.91559147834778,
      "citing_paper_id": "258865260",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "We also detect a stark drop from micro to macro F1 scores for TANL and DyGIE++ in the low resource test suite.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics and models. The context is focused on the evaluation of models rather than the use of a specific dataset.",
      "processing_time": 32.592286348342896,
      "citing_paper_id": "258865260",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Models like DyGIE++ and TANL cannot support unseen events or argument roles and thus, we do not include these models in the experiments for these test suites.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their limitations. There are no verifiable resources or datasets mentioned.",
      "processing_time": 31.489662170410156,
      "citing_paper_id": "258865260",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "We experiment with three models: (1) DyGIE++ (Wadden et al., 2019), a traditional model utilizing multisentence BERT encodings and span graph propagation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is focused on describing the models used in the experiments.",
      "processing_time": 32.08231711387634,
      "citing_paper_id": "258865260",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Recent works have introduced document-level EAE datasets like RAMS (Ebner et al., 2020), WikiEvents (Li et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate document-level event argument extraction, focusing on complex events and their arguments across multiple sentences.",
        "WikiEvents": "Applied to study document-level event extraction, specifically addressing the challenge of identifying and linking events within and across sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are relevant to document-level event argument extraction.",
      "processing_time": 41.25132417678833,
      "citing_paper_id": "258865260",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We present the statistics of our full ontology in Table 1 and compare it with existing ACE (Dod-dington et al., 2004) and RAMS (Ebner et al., 2020) ontologies.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'ACE' and 'RAMS' ontologies, which are specific resources used for comparison with the presented ontology. However, they are not datasets but rather ontologies or frameworks.",
      "processing_time": 34.20575833320618,
      "citing_paper_id": "258865260",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "It is worth mentioning that these definitions are disparate from the ones that previous works like ACE, and its inheritors, ERE and RAMS, follow.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE",
        "ERE",
        "RAMS"
      ],
      "dataset_descriptions": {
        "ACE": "Referenced for its definitions of events, which differ from those used in the current research.",
        "ERE": "Referenced for its definitions of events, which differ from those used in the current research.",
        "RAMS": "Referenced for its definitions of events, which differ from those used in the current research."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions ACE, ERE, and RAMS, which are known datasets or frameworks in the field of event extraction. However, the context does not specify how these are used in the current research.",
      "processing_time": 48.65280294418335,
      "citing_paper_id": "258865260",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "EAE is a classic topic (Sundheim, 1992) and elemental for a wide range of applications like building knowledge graphs (Zhang et al., 2020), Figure 1: Distribution of event types into various abstract event types 1 for GENEVA, ACE, ERE, RAMS, and WikiEvents datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENEVA",
        "ACE",
        "ERE",
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "GENEVA": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories.",
        "ACE": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories.",
        "ERE": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories.",
        "RAMS": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories.",
        "WikiEvents": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets by name, which are relevant to document-level event extraction. These datasets are used for building knowledge graphs and analyzing event types.",
      "processing_time": 61.11081051826477,
      "citing_paper_id": "258865260",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "EAE is a classic topic (Sundheim, 1992) and elemental for a wide range of applications like building knowledge graphs (Zhang et al., 2020), Figure 1: Distribution of event types into various abstract event types 1 for GENEVA, ACE, ERE, RAMS, and WikiEvents datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENEVA",
        "ACE",
        "ERE",
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "GENEVA": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories.",
        "ACE": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories.",
        "ERE": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories.",
        "RAMS": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories.",
        "WikiEvents": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets by name, which are relevant to document-level event extraction. These datasets are used for building knowledge graphs and analyzing event types.",
      "processing_time": 61.11081051826477,
      "citing_paper_id": "258865260",
      "cited_paper_id": null
    },
    {
      "context_text": "Recent works have introduced document-level EAE datasets like RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021), and Do-cEE (Tong et al., 2022); but their ontologies are also entity-centric, and their event coverage is limited to specific abstract event types (Figure 1).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to highlight the entity-centric nature and limited event coverage in document-level event extraction, focusing on specific abstract event types.",
        "WikiEvents": "Used to highlight the entity-centric nature and limited event coverage in document-level event extraction, focusing on specific abstract event types.",
        "Do-cEE": "Used to highlight the entity-centric nature and limited event coverage in document-level event extraction, focusing on specific abstract event types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets relevant to document-level event extraction, which are used to highlight the limitations in their ontologies and event coverage.",
      "processing_time": 50.41512680053711,
      "citing_paper_id": "258865260",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Recent works have introduced document-level EAE datasets like RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021), and Do-cEE (Tong et al., 2022); but their ontologies are also entity-centric, and their event coverage is limited to specific abstract event types (Figure 1).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to highlight the entity-centric nature and limited event coverage in document-level event extraction, focusing on specific abstract event types.",
        "WikiEvents": "Used to highlight the entity-centric nature and limited event coverage in document-level event extraction, focusing on specific abstract event types.",
        "Do-cEE": "Used to highlight the entity-centric nature and limited event coverage in document-level event extraction, focusing on specific abstract event types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets relevant to document-level event extraction, which are used to highlight the limitations in their ontologies and event coverage.",
      "processing_time": 50.41512680053711,
      "citing_paper_id": "258865260",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Abstract event types are defined as the top nodes of the event ontology created by MAVEN (Wang et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used to define abstract event types as top nodes of an event ontology, focusing on general domain event detection and classification."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions MAVEN as a dataset used for defining abstract event types in an event ontology. The cited paper title confirms MAVEN is a dataset.",
      "processing_time": 37.47676086425781,
      "citing_paper_id": "258865260",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "Later, MAVEN (Wang et al., 2020) introduced a massive dataset spanning a wide range of event types.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN"
      ],
      "dataset_descriptions": {
        "MAVEN": "MAVEN is used to train and evaluate models for detecting a wide range of event types across general domains, enhancing the robustness of event extraction systems."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions MAVEN as a dataset introduced for event detection, which aligns with the document-level event extraction topic.",
      "processing_time": 37.62170696258545,
      "citing_paper_id": "258865260",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "Event Ontology: In order to build the event on-3 tology, we utilize the event mapping designed by MAVEN (Wang et al., 2020), which is an event detection dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used to build the event ontology by utilizing its event mapping, focusing on general domain event detection and providing a large-scale dataset for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "MAVEN is identified as an event detection dataset used to build the event ontology. The context clearly indicates its use as a reusable resource.",
      "processing_time": 38.575435161590576,
      "citing_paper_id": "258865260",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "Defining abstract event types as the top nodes of the ontology tree created by MAVEN (Wang et al., 2020), we show that our ontology spans 5 different abstract types and is the most diverse.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used to define abstract event types as top nodes of an ontology tree, demonstrating diversity across 5 different types in a general domain event detection context."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions MAVEN as a dataset used for defining abstract event types in an ontology tree. The cited paper title confirms MAVEN is a dataset.",
      "processing_time": 38.417595624923706,
      "citing_paper_id": "258865260",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "tology, we utilize the event mapping designed by MAVEN (Wang et al., 2020), which is an event detection dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN"
      ],
      "dataset_descriptions": {
        "MAVEN": "Utilized for event detection in general domain texts, focusing on identifying and categorizing events across diverse topics and contexts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions MAVEN as an event detection dataset, which is relevant to document-level event extraction.",
      "processing_time": 36.273629903793335,
      "citing_paper_id": "258865260",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "To improve generalizability, some works have explored better usage of label semantics by formulating EAE as a question-answering task (Liu et al., 2020; Li et al., 2020; Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on formulating event argument extraction (EAE) as a question-answering task.",
      "processing_time": 34.47002935409546,
      "citing_paper_id": "258865260",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "To improve generalizability, some works have explored better usage of label semantics by formulating EAE as a question-answering task (Liu et al., 2020; Li et al., 2020; Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on formulating event argument extraction (EAE) as a question-answering task.",
      "processing_time": 34.47002935409546,
      "citing_paper_id": "258865260",
      "cited_paper_id": 226283533
    },
    {
      "context_text": "However, these approaches exhibit poor generalizability in the low-data setting (Liu et al., 2020; Hsu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue of poor generalizability in low-data settings.",
      "processing_time": 32.0513014793396,
      "citing_paper_id": "258865260",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "However, these approaches exhibit poor generalizability in the low-data setting (Liu et al., 2020; Hsu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue of poor generalizability in low-data settings.",
      "processing_time": 32.0513014793396,
      "citing_paper_id": "258865260",
      "cited_paper_id": 248512779
    },
    {
      "context_text": ", 2022a), question-answeringbased models (Du and Cardie, 2020), and generative approaches (Paolini et al., 2021; Hsu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and models. No verifiable resources are identified.",
      "processing_time": 32.31994438171387,
      "citing_paper_id": "258865260",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "Recent approaches have explored the use of natural language generative models for structured prediction to boost generalizability (Schick and Schütze, 2021a,b; Paolini et al., 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only generative models and structured prediction methods.",
      "processing_time": 30.533106565475464,
      "citing_paper_id": "258865260",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "We consider two such models: (6) TANL (Paolini et al., 2021), a multi-task language generation model which treats EAE as a translation task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (TANL) and its application to event argument extraction (EAE).",
      "processing_time": 33.5111768245697,
      "citing_paper_id": "258865260",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "Another set of works transfers knowledge from similar tasks like abstract meaning representation and semantic role labeling (Huang et al., 2018; Lyu et al., 2021; Zhang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only related works and tasks. There are no clear identifiers for datasets in the text.",
      "processing_time": 33.055352449417114,
      "citing_paper_id": "258865260",
      "cited_paper_id": 236477798
    },
    {
      "context_text": "We report the hyperparameter settings for the Query&Extract experiments in",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a reference to hyperparameter settings for experiments.",
      "processing_time": 31.417813062667847,
      "citing_paper_id": "258865260",
      "cited_paper_id": 238856763
    },
    {
      "context_text": "(3) Query&Extract (Wang et al., 2022a) utilizing the attention mechanism to extract arguments from argument role queries.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or model called 'Query&Extract'. The citation is focused on describing the method rather than a dataset.",
      "processing_time": 34.44129467010498,
      "citing_paper_id": "258865260",
      "cited_paper_id": 238856763
    },
    {
      "context_text": "Due to their inferior performance, we do not include OneIE and Query&Extract in the benchmarking results.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods that were excluded from benchmarking.",
      "processing_time": 31.748159408569336,
      "citing_paper_id": "258865260",
      "cited_paper_id": 238856763
    },
    {
      "context_text": "Recently, there has been an advent of Generative AI in the form of Large Language Models (LLMs) like GPT-3 (Brown et al., 2020), GPT-4, PaLM (Chowdhery et al., 2022), Code4Struct (Wang et al., 2022b), and many more.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 33.73247194290161,
      "citing_paper_id": "258865260",
      "cited_paper_id": 238856763
    },
    {
      "context_text": "Recently, there has been an advent of Generative AI in the form of Large Language Models (LLMs) like GPT-3 (Brown et al., 2020), GPT-4, PaLM (Chowdhery et al., 2022), Code4Struct (Wang et al., 2022b), and many more.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 33.73247194290161,
      "citing_paper_id": "258865260",
      "cited_paper_id": 253098161
    },
    {
      "context_text": "When trained on complete training data, we observe that OneIE and Query&Extract models achieve poor micro F1 scores of just 30 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'complete training data', which is too generic.",
      "processing_time": 33.7183940410614,
      "citing_paper_id": "258865260",
      "cited_paper_id": 238856763
    },
    {
      "context_text": "(7) DEGREE (Hsu et al., 2022b), an encoder-decoder framework that extracts event arguments using natural language input prompts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DEGREE, which is described as an encoder-decoder framework, not a dataset. The title confirms it is a model, not a dataset.",
      "processing_time": 35.153260231018066,
      "citing_paper_id": "258865260",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "D EGREE (Hsu et al., 2022b) is a recently introduced state-of-the-art generative model which has shown the best performance in the limited data regime.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DEGREE as a generative model, not a dataset. No other datasets are mentioned.",
      "processing_time": 33.949673891067505,
      "citing_paper_id": "258865260",
      "cited_paper_id": 248512779
    },
    {
      "context_text": ", 2021), and DocEE (Tong et al., 2022); but their ontologies are also entity-centric, and their event coverage is limited to specific abstract event types (Figure 1).",
      "catation_intent": "research work",
      "resource_type": "benchmark",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "DocEE is mentioned as a benchmark, but it is not used as a dataset in the given context. The citation does not indicate that the resource is used for training, evaluation, or any other form of data analysis.",
      "processing_time": 37.19944787025452,
      "citing_paper_id": "258865260",
      "cited_paper_id": 250390839
    },
    {
      "context_text": ", 2022), Code4Struct (Wang et al., 2022b), and many more.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Code4Struct' but does not indicate it is a dataset. It appears to be a method or tool for code generation.",
      "processing_time": 36.065269231796265,
      "citing_paper_id": "258865260",
      "cited_paper_id": 253098161
    },
    {
      "context_text": "We follow the definition of event as a class attribute with values such as occurrence, state, or reporting (Pustejovsky et al., 2003; Han et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a definition of events. No verifiable resources are identified.",
      "processing_time": 35.79339361190796,
      "citing_paper_id": "258865260",
      "cited_paper_id": null
    },
    {
      "context_text": "EAE is a classic topic (Sundheim, 1992) and elemental for a wide range of applications like building knowledge graphs (Zhang et al., 2020), Figure 1: Distribution of event types into various abstract event types(1) for GENEVA, ACE, ERE, RAMS, and WikiEvents datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENEVA",
        "ACE",
        "ERE",
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "GENEVA": "Used to analyze distribution of event types, focusing on abstract event categories for document-level event extraction.",
        "ACE": "Used to analyze distribution of event types, focusing on abstract event categories for document-level event extraction.",
        "ERE": "Used to analyze distribution of event types, focusing on abstract event categories for document-level event extraction.",
        "RAMS": "Used to analyze distribution of event types, focusing on abstract event categories for document-level event extraction.",
        "WikiEvents": "Used to analyze distribution of event types, focusing on abstract event categories for document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions several datasets by name, which are used for event extraction. These datasets are clearly identified and are relevant to the topic of document-level event extraction.",
      "processing_time": 64.37374925613403,
      "citing_paper_id": "258865260",
      "cited_paper_id": null
    },
    {
      "context_text": "Motivated by the cognitive progress of humans and animals that learn knowledge from easy to hard gradually, we propose a curriculum learning [Bengio et al. , 2009] framework to resolve implicit EAE by several stages, which learns to extract arguments from trigger around sentences to the whole…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (curriculum learning). There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 37.54609990119934,
      "citing_paper_id": "248496246",
      "cited_paper_id": 873046
    },
    {
      "context_text": "Most previous methods decode arguments according to their orders in the document or guideline [Du et al. , 2020; Li et al. , 2021], which may violate the cognitive process of learning from easy-level to hard-level [Bengio et al. , 2009].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 36.589231967926025,
      "citing_paper_id": "248496246",
      "cited_paper_id": 873046
    },
    {
      "context_text": "Most previous methods decode arguments according to their orders in the document or guideline [Du et al. , 2020; Li et al. , 2021], which may violate the cognitive process of learning from easy-level to hard-level [Bengio et al. , 2009].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 36.589231967926025,
      "citing_paper_id": "248496246",
      "cited_paper_id": 230433941
    },
    {
      "context_text": "Most previous methods decode arguments according to their orders in the document or guideline [Du et al. , 2020; Li et al. , 2021], which may violate the cognitive process of learning from easy-level to hard-level [Bengio et al. , 2009].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 36.589231967926025,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": "Most previous methods decode arguments according to their orders in the document or guideline [Du et al. , 2020; Li et al. , 2021], which may violate the cognitive process of learning from easy-level to hard-level [Bengio et al. , 2009].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 36.589231967926025,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": "Unlike traditional EAE that mainly focuses on extracting arguments within a single sentence given a trigger, implicit EAE focuses on document-level argument extraction that arguments may span over multiple sentences, which is more challenging [Ebner et al. , 2020].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a type of task (document-level argument extraction). No verifiable resources are named.",
      "processing_time": 37.03969049453735,
      "citing_paper_id": "248496246",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We conduct extensive experiments on two implicit EAE datasets, namely RAMS [ Ebner et al. , 2020 ] and WikiEvents [ Li et al. , 2021 ] , which have been widely used in previous studies [ Li et al. , 2021; Liu et al. , 2021a ] .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for conducting experiments on implicit event argument extraction, focusing on identifying arguments in complex, multi-sentence contexts.",
        "WikiEvents": "Used for evaluating implicit event argument extraction models, providing a rich set of annotated documents for training and testing."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for conducting experiments on implicit EAE (Event Argument Extraction). These datasets are widely used in previous studies, indicating their relevance and reusability.",
      "processing_time": 52.54380774497986,
      "citing_paper_id": "248496246",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We conduct extensive experiments on two implicit EAE datasets, namely RAMS [ Ebner et al. , 2020 ] and WikiEvents [ Li et al. , 2021 ] , which have been widely used in previous studies [ Li et al. , 2021; Liu et al. , 2021a ] .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for conducting experiments on implicit event argument extraction, focusing on identifying arguments in complex, multi-sentence contexts.",
        "WikiEvents": "Used for evaluating implicit event argument extraction models, providing a rich set of annotated documents for training and testing."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for conducting experiments on implicit EAE (Event Argument Extraction). These datasets are widely used in previous studies, indicating their relevance and reusability.",
      "processing_time": 52.54380774497986,
      "citing_paper_id": "248496246",
      "cited_paper_id": 230433941
    },
    {
      "context_text": "We conduct extensive experiments on two implicit EAE datasets, namely RAMS [ Ebner et al. , 2020 ] and WikiEvents [ Li et al. , 2021 ] , which have been widely used in previous studies [ Li et al. , 2021; Liu et al. , 2021a ] .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for conducting experiments on implicit event argument extraction, focusing on identifying arguments in complex, multi-sentence contexts.",
        "WikiEvents": "Used for evaluating implicit event argument extraction models, providing a rich set of annotated documents for training and testing."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for conducting experiments on implicit EAE (Event Argument Extraction). These datasets are widely used in previous studies, indicating their relevance and reusability.",
      "processing_time": 52.54380774497986,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": "Experiments are performed on two well-known benchmark datasets, namely RAMS[Ebner et al. , 2020] and WikiEvents[Li et al. , 2021], and the results show the effectiveness of our proposed approach.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the effectiveness of the proposed approach in document-level event extraction, focusing on multi-sentence argument linking.",
        "WikiEvents": "Used to assess the performance of the proposed method in document-level event extraction, emphasizing the identification and linking of events across multiple sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used to evaluate the effectiveness of the proposed approach in document-level event extraction.",
      "processing_time": 51.0002167224884,
      "citing_paper_id": "248496246",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Experiments are performed on two well-known benchmark datasets, namely RAMS[Ebner et al. , 2020] and WikiEvents[Li et al. , 2021], and the results show the effectiveness of our proposed approach.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the effectiveness of the proposed approach in document-level event extraction, focusing on multi-sentence argument linking.",
        "WikiEvents": "Used to assess the performance of the proposed method in document-level event extraction, emphasizing the identification and linking of events across multiple sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used to evaluate the effectiveness of the proposed approach in document-level event extraction.",
      "processing_time": 51.0002167224884,
      "citing_paper_id": "248496246",
      "cited_paper_id": 230433941
    },
    {
      "context_text": "Experiments are performed on two well-known benchmark datasets, namely RAMS[Ebner et al. , 2020] and WikiEvents[Li et al. , 2021], and the results show the effectiveness of our proposed approach.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the effectiveness of the proposed approach in document-level event extraction, focusing on multi-sentence argument linking.",
        "WikiEvents": "Used to assess the performance of the proposed method in document-level event extraction, emphasizing the identification and linking of events across multiple sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used to evaluate the effectiveness of the proposed approach in document-level event extraction.",
      "processing_time": 51.0002167224884,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": "We compare our approach with the recent advanced baselines: 1) SpanSel [ Ebner et al. , 2020 ] is a method based on span ranking, which enumerates each possible span in a document to identify the argument; 2) Head-Expand [ Li et al. , 2019 ] extends SpanSel by ﬁrst identifying an argu-ment’s head…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and baselines. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 39.19843363761902,
      "citing_paper_id": "248496246",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Ebner et al. [ 2020 ] determined the best argument span according to the matching score be-tween the candidate span and the trigger-role representations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for determining the best argument span.",
      "processing_time": 37.521968126297,
      "citing_paper_id": "248496246",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "…the argument; 2) Head-Expand [ Li et al. , 2019 ] extends SpanSel by ﬁrst identifying an argu-ment’s head and then its region; 3) BART-Gen [ Ebner et al. , 2020 ] treats implicit EAE as a generation task, and generates the arguments based on BART architecture 4 ; 4) DocMRC [ Liu et al. ,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 39.19861602783203,
      "citing_paper_id": "248496246",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "…identify the argument; 2) Head-Expand [ Li et al. , 2019 ] extends SpanSel by ﬁrst identifying an argu-ment’s head and then its region; 3) BART-Gen [ Ebner et al. , 2020 ] treats implicit EAE as a generation task, and generates the arguments based on BART architecture 4 ; 4) DocMRC [ Liu et al. ,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 39.659650564193726,
      "citing_paper_id": "248496246",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We compare our approach with the recent advanced baselines: 1) SpanSel [ Ebner et al. , 2020 ] is a method based on span ranking, which enumerates each possible span in a document to identify the argument; 2) Head-Expand [ Li et al. , 2019 ] extends SpanSel by ﬁrst identifying an argu-ment’s head and then its region; 3) BART-Gen [ Ebner et al. , 2020 ] treats implicit EAE as a generation task, and generates the arguments based on BART architecture 4 ; 4) DocMRC [ Liu et al. , 2021a ] models implicit EAE as a MRC problem, which devises the role-speciﬁc questions for argument extraction; 5) DocMRC (IDA) is an enhanced version of DocMRC, which uses implicit data augmentation by pre-training on other related tasks, including question answering, natural language inference and sentence level event argument extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 39.648489475250244,
      "citing_paper_id": "248496246",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Other studies attempt to explore automatic searched prompts to alleviate the manual cost [ Li and Liang, 2021 ][ Lester et al. , 2021 ] .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other studies exploring automatic prompt searching.",
      "processing_time": 39.186787366867065,
      "citing_paper_id": "248496246",
      "cited_paper_id": 230433941
    },
    {
      "context_text": "Recently, prompt-based learning has been investigated to elicit knowledge from pre-trained language models (PLMs) for low-data scenarios [Li and Liang, 2021; Lester et al. , 2021].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on prompt-based learning and pre-trained language models.",
      "processing_time": 39.88796591758728,
      "citing_paper_id": "248496246",
      "cited_paper_id": 230433941
    },
    {
      "context_text": "Li et al. [2021] incorporated a template with masked arguments into the encoder-decoder framework, which conditionally generated the complete template by ar-gument ﬁlling, and achieved good performance in the zero-shot scenarios.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving zero-shot performance using templates and argument filling.",
      "processing_time": 39.46166443824768,
      "citing_paper_id": "248496246",
      "cited_paper_id": 230433941
    },
    {
      "context_text": "Whereas, the order of argument generation is difﬁcult to determine, which is vulnerable to the error propagation as shown in previous studies [Xiangyu et al. , 2021].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or finding related to the order of argument generation and error propagation.",
      "processing_time": 40.36644005775452,
      "citing_paper_id": "248496246",
      "cited_paper_id": 235694418
    },
    {
      "context_text": "Whereas, the order of argument generation is difﬁcult to determine, which is vulnerable to the error propagation as shown in previous studies [Xiangyu et al. , 2021].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or finding related to the order of argument generation and error propagation.",
      "processing_time": 40.36644005775452,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": "Most previous methods decode arguments according to their orders in the document or guideline [Du et al., 2020; Li et al., 2021], which may violate the cognitive process of learning from easy-level to hard-level [Bengio et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and cognitive processes. There are no clear identifiers for datasets.",
      "processing_time": 40.75928616523743,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": "Most previous methods decode arguments according to their orders in the document or guideline [Du et al., 2020; Li et al., 2021], which may violate the cognitive process of learning from easy-level to hard-level [Bengio et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and cognitive processes. There are no clear identifiers for datasets.",
      "processing_time": 40.75928616523743,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": "Whereas, the order of argument generation is difficult to determine, which is vulnerable to the error propagation as shown in previous studies [Xiangyu et al., 2021].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to a general challenge in argument generation.",
      "processing_time": 40.10997748374939,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": ", 2020] and WikiEvents[Li et al., 2021], and the results show the effectiveness of our proposed approach.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to evaluate the effectiveness of the proposed approach in document-level event extraction, focusing on multi-event documents and their temporal and causal relationships."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions 'WikiEvents' which is a known dataset for document-level event extraction. No other specific datasets are mentioned.",
      "processing_time": 48.73146319389343,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": ", 2020] and WikiEvents [Li et al., 2021], which have been widely used in previous studies [Li et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to train and evaluate document-level event extraction models, focusing on identifying and classifying events within documents.",
        "WikiEvents": "Utilized for evaluating document-level event extraction systems, emphasizing the identification of complex event structures and relations."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions two datasets, 'ACE 2005' and 'WikiEvents', which are known document-level event extraction datasets. The context indicates their use in previous studies.",
      "processing_time": 55.90173029899597,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": ", 2021], which have been widely used in previous studies [Li et al., 2021; Liu et al., 2021a].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only that certain unnamed resources have been widely used in previous studies.",
      "processing_time": 40.346580266952515,
      "citing_paper_id": "248496246",
      "cited_paper_id": null
    },
    {
      "context_text": "To utilize more knowledge, some studies leverage document context (Chen et al., 2018; Zhao et al., 2018), pre-trained language model (Yang et al., 2019), and explicit external knowledge (Liu et al., 2019a; Tong et al., 2020) such as WordNet (Miller, 1995).",
      "catation_intent": "reusable resource",
      "resource_type": "lexicon",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions WordNet as a source of explicit external knowledge, which is a lexical database and not a dataset in the strict sense of the term. No other specific datasets are mentioned.",
      "processing_time": 43.96108412742615,
      "citing_paper_id": "235253912",
      "cited_paper_id": 1671874
    },
    {
      "context_text": "To utilize more knowledge, some studies leverage document context (Chen et al., 2018; Zhao et al., 2018), pre-trained language model (Yang et al., 2019), and explicit external knowledge (Liu et al., 2019a; Tong et al., 2020) such as WordNet (Miller, 1995).",
      "catation_intent": "reusable resource",
      "resource_type": "lexicon",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions WordNet as a source of explicit external knowledge, which is a lexical database and not a dataset in the strict sense of the term. No other specific datasets are mentioned.",
      "processing_time": 43.96108412742615,
      "citing_paper_id": "235253912",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "To utilize more knowledge, some studies leverage document context (Chen et al., 2018; Zhao et al., 2018), pre-trained language model (Yang et al., 2019), and explicit external knowledge (Liu et al., 2019a; Tong et al., 2020) such as WordNet (Miller, 1995).",
      "catation_intent": "reusable resource",
      "resource_type": "lexicon",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions WordNet as a source of explicit external knowledge, which is a lexical database and not a dataset in the strict sense of the term. No other specific datasets are mentioned.",
      "processing_time": 43.96108412742615,
      "citing_paper_id": "235253912",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "To take advantage of such interdependency, we propose a novel Tracker module inspired by memory network (Weston et al., 2015).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (memory network) which is not included as per instructions.",
      "processing_time": 41.06897497177124,
      "citing_paper_id": "235253912",
      "cited_paper_id": 2926851
    },
    {
      "context_text": "They conduct experiments on MUC-4 (Sundheim, 1992) dataset with 1, 700 documents and 5 kinds of entity-based arguments, and it is formulated as a table-filling task, coping with single event record of single event",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used for experiments involving entity-based arguments with 1,700 documents, formulated as a table-filling task to handle single event records."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a specific, verifiable dataset used in the research. The dataset is used for experiments involving entity-based arguments and is formulated as a table-filling task.",
      "processing_time": 52.471088886260986,
      "citing_paper_id": "235253912",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "They conduct experiments on MUC-4 (Sundheim, 1992) dataset with 1, 700 documents and 5 kinds of entity-based arguments, and it is formulated as a table-filling task, coping with single event record of single event\ntype.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used for experiments involving entity-based arguments, formulated as a table-filling task to handle single event records of single event types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a specific, verifiable dataset used in the research. The dataset is used for experiments involving entity-based arguments and is formulated as a table-filling task.",
      "processing_time": 51.76674294471741,
      "citing_paper_id": "235253912",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "In our implementation of G IT , we use 8 and 4 layers Transformer (Vaswani et al., 2017) in encoding and decoding module respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the architecture of the Transformer model. No verifiable resources are identified.",
      "processing_time": 40.54224944114685,
      "citing_paper_id": "235253912",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Finally we introduce a Tracker module to continuously track all the records with global memory, in which we utilize the global interdependency among records for multi-event extraction (Sec 3.4). former (Vaswani et al., 2017):",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Tracker module) and a reference to a paper. The cited paper 'Attention is All you Need' is a methodological paper and not a dataset.",
      "processing_time": 45.109764099121094,
      "citing_paper_id": "235253912",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Although Zheng et al. (2019) use Transformer to fuse sentences and entities, interdependency among events is neglected.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Transformer).",
      "processing_time": 39.40950798988342,
      "citing_paper_id": "235253912",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "In our implementation of GIT, we use 8 and 4 layers Transformer (Vaswani et al., 2017) in encoding and decoding module respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the architecture details of the Transformer model.",
      "processing_time": 40.23215174674988,
      "citing_paper_id": "235253912",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "The task does not require to identify event triggers (Zeng et al., 2018; Liu et al., 2019b), which reduces manual effort of annotation and the application scenarios becomes more extensive.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the reduction of manual annotation effort and broader application scenarios.",
      "processing_time": 41.094069957733154,
      "citing_paper_id": "235253912",
      "cited_paper_id": 19224644
    },
    {
      "context_text": "To utilize more knowledge, some studies leverage document context (Chen et al., 2018; Zhao et al., 2018), pre-trained language model (Yang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 41.60397267341614,
      "citing_paper_id": "235253912",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "Most previous methods (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Yang et al., 2019; Du and Cardie, 2020b) focus on sentence-level EE, extracting events from a single sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods and their focus on sentence-level event extraction.",
      "processing_time": 41.238544940948486,
      "citing_paper_id": "235253912",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Most of the previous methods (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Yang et al., 2019; Du and Cardie, 2020b) focus on sentence-level EE, extracting events from a single sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods focusing on sentence-level event extraction.",
      "processing_time": 41.08217716217041,
      "citing_paper_id": "235253912",
      "cited_paper_id": 196178503
    },
    {
      "context_text": ", 2018), pre-trained language model (Yang et al., 2019), and explicit external knowledge (Liu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to pre-trained language models and external knowledge. No verifiable datasets are identified.",
      "processing_time": 42.58824396133423,
      "citing_paper_id": "235253912",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Since a document can express events of different types, we formulate the task as a multi-label classification and leverage sentences feature matrix S to\n*Traditional methods in sentence-level EE also utilize graph to extract events (Liu et al., 2018; Yan et al., 2019), based on the dependency tree.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the use of graph-based methods for event extraction.",
      "processing_time": 42.76666331291199,
      "citing_paper_id": "235253912",
      "cited_paper_id": 202773239
    },
    {
      "context_text": "*Traditional methods in sentence-level EE also utilize graph to extract events (Liu et al., 2018; Yan et al., 2019), based on the dependency tree.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the use of graph-based methods for event extraction.",
      "processing_time": 42.94107532501221,
      "citing_paper_id": "235253912",
      "cited_paper_id": 202773239
    },
    {
      "context_text": "Some studies also utilize dependency tree information (Liu et al., 2018; Yan et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. No dataset names are present in the citation span.",
      "processing_time": 42.07595682144165,
      "citing_paper_id": "235253912",
      "cited_paper_id": 202773239
    },
    {
      "context_text": "Hence, extracting events at the document-level is critical and has attracted much attention recently (Yang et al., 2018; Zheng et al., 2019; Du and Cardie, 2020a; Du et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. No dataset names are provided in the context.",
      "processing_time": 42.313618898391724,
      "citing_paper_id": "235253912",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "Focusing on single event extraction, Du and Cardie (2020a) and Du et al. (2020) concatenate multiple sentences and only consider a single event, which lacks the ability to model multiple events scattered in a long document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methodological approaches to event extraction.",
      "processing_time": 40.393959522247314,
      "citing_paper_id": "235253912",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "Du and Cardie (2020a) try to encode the sentences in a multi-granularity way and Du et al. (2020) leverage a seq2seq model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context is about encoding sentences and using seq2seq models, which are not datasets.",
      "processing_time": 43.98963785171509,
      "citing_paper_id": "235253912",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "It has attracted much attention recently (Yang et al., 2018; Zheng et al., 2019; Du and Cardie, 2020a; Du et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 43.62871313095093,
      "citing_paper_id": "235253912",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "After heterogeneous graph construction *, we apply multi-layer Graph Convolution Network (Kipf and Welling, 2017) to model the global interactions inspired by Zeng et al. (2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the application of a Graph Convolution Network and does not reference any data sources.",
      "processing_time": 44.83656334877014,
      "citing_paper_id": "235253912",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "After heterogeneous graph construction *, we apply multi-layer Graph Convolution Network (Kipf and Welling, 2017) to model the global interactions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Graph Convolution Network).",
      "processing_time": 41.406458377838135,
      "citing_paper_id": "235253912",
      "cited_paper_id": null
    },
    {
      "context_text": "After heterogeneous graph construction * , we apply multi-layer Graph Convolution Network (Kipf and Welling, 2017) to model the global interactions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Graph Convolution Network).",
      "processing_time": 41.5515456199646,
      "citing_paper_id": "235253912",
      "cited_paper_id": null
    },
    {
      "context_text": "These studies usually conduct experiments on sentencelevel event extraction dataset, ACE05 (Walker et al., 2006).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05"
      ],
      "dataset_descriptions": {
        "ACE05": "Used for sentence-level event extraction, focusing on identifying and classifying events within individual sentences using a well-established annotated corpus."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE05' as a specific dataset used for sentence-level event extraction. It is a well-known dataset in the field of NLP and fits the criteria for inclusion.",
      "processing_time": 52.01225185394287,
      "citing_paper_id": "235253912",
      "cited_paper_id": null
    },
    {
      "context_text": "These studies usually conduct experiments on sentence-level event extraction dataset, ACE05 (Walker et al., 2006).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05"
      ],
      "dataset_descriptions": {
        "ACE05": "Used for sentence-level event extraction experiments, focusing on identifying events within individual sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE05 dataset, which is a well-known resource for event extraction tasks. It is used for sentence-level event extraction experiments.",
      "processing_time": 49.41932415962219,
      "citing_paper_id": "235253912",
      "cited_paper_id": null
    },
    {
      "context_text": "TIER (Huang and Riloff, 2011) proposes to first determine the document genre with a classifier and then identify event-relevant sentences and role fillers in the",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (TIER) for document-level event extraction.",
      "processing_time": 41.702717304229736,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "C L\n] 1\n3 M\nay 2\n02 0\nwith separate classifiers for each type of role and for relevant context detection (Patwardhan and Riloff, 2009; Huang and Riloff, 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 43.76724720001221,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "C L\n] 1\n3 M\nay 2\n02 0\nwith separate classifiers for each type of role and for relevant context detection (Patwardhan and Riloff, 2009; Huang and Riloff, 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 43.76724720001221,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Similar to Huang and Riloff (2012), we also incorporate both intra-sentence and cross-sentence features (paragraph-level features), but instead of using manually designed linguistic information,",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. There are no clear identifiers for datasets in the given context.",
      "processing_time": 43.75460982322693,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "TIER (Huang and Riloff, 2011) proposes to first determine the document genre with a classifier and then identify event-relevant sentences and role fillers in the document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (TIER) for document-level event extraction.",
      "processing_time": 41.8873872756958,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "The final extraction decisions are based on the product of normalized sentential and phrasal probabilities; TIER (Huang and Riloff, 2011) proposes a multi-stage approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions TIER, which is a method, not a dataset. No datasets are explicitly mentioned or used in the context provided.",
      "processing_time": 43.74686932563782,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "8011 relevant context detection (Patwardhan and Riloff, 2009; Huang and Riloff, 2011).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to papers. No clear identifiers for datasets are present.",
      "processing_time": 42.8766872882843,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "8011 relevant context detection (Patwardhan and Riloff, 2009; Huang and Riloff, 2011).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to papers. No clear identifiers for datasets are present.",
      "processing_time": 42.8766872882843,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Cohesion Extract obtains substantially better precision and with similar level of recall as compared to GLACIER and TIER.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods (GLACIER and TIER). No verifiable resources are identified.",
      "processing_time": 43.9380464553833,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Cohesion Extract obtains substantially better precision and with similar level of recall as compared to GLACIER and TIER.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods (GLACIER and TIER). No verifiable resources are identified.",
      "processing_time": 43.9380464553833,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Huang and Riloff (2012) propose a bottom-up approach that first aggressively identifies candidate role fillers (with lexico-syntactic pattern features), and then removes the candidates that are in spurious sentences (i.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for identifying event role fillers.",
      "processing_time": 42.00678253173828,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "08 - - TIER (Huang and Riloff, 2011) 50.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or tool called TIER. No verifiable datasets are referenced.",
      "processing_time": 43.353930950164795,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "decisions are based on the product of normalized sentential and phrasal probabilities; TIER (Huang and Riloff, 2011) proposes a multi-stage approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions TIER, which is a method or tool, not a dataset. No datasets are explicitly mentioned or used in the context provided.",
      "processing_time": 44.54559016227722,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Ji and Grishman (2008) enforce event role consistency across documents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for refining event extraction.",
      "processing_time": 41.14551091194153,
      "citing_paper_id": "218630327",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Many variations of models have been proposed to mitigate the effect of long sequence length, such as Long Short Term Memory (LSTM) Networks (Hochre-iter and Schmidhuber, 1997; Gers et al., 1999; Graves, 2013) and Gated Recurrent Unit Networks (Cho et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria.",
      "processing_time": 43.91810345649719,
      "citing_paper_id": "218630327",
      "cited_paper_id": 1697424
    },
    {
      "context_text": "…Layer In the embedding layer, we represent each token x i in the input sequence as the concatenation of its word embedding and contextual token representation: • Word Embedding : We use the 100-dimensional GloVe pre-trained word embeddings (Pennington et al., 2014) trained from 6B Web crawl data.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using GloVe pre-trained word embeddings, which is a method/model, not a dataset. No specific dataset is mentioned.",
      "processing_time": 44.54466676712036,
      "citing_paper_id": "218630327",
      "cited_paper_id": 1957433
    },
    {
      "context_text": "Li et al. (2013, 2015) explore various hand-designed features; Nguyen and Grishman (2015); Nguyen et al. (2016); Chen et al. (2015); Liu et al. (2017, 2018) employ deep learning based models such as recurrent neural networks (RNNs) and convolutional neural network (CNN).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the context.",
      "processing_time": 43.559346199035645,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Li et al. (2013, 2015) explore various hand-designed features; Nguyen and Grishman (2015); Nguyen et al. (2016); Chen et al. (2015); Liu et al. (2017, 2018) employ deep learning based models such as recurrent neural networks (RNNs) and convolutional neural network (CNN).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the context.",
      "processing_time": 43.559346199035645,
      "citing_paper_id": "218630327",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "features; Nguyen and Grishman (2015); Nguyen et al. (2016); Chen et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers. There are no clear identifiers for datasets within the given context.",
      "processing_time": 44.261828899383545,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "features; Nguyen and Grishman (2015); Nguyen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation does not provide enough context to identify specific datasets. It mentions a method or research work but lacks details on datasets.",
      "processing_time": 43.884570360183716,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "GLACIER (Patwardhan and Riloff, 2009) jointly considers crosssentence and noun phrase evidence in a probabilistic framework to extract role fillers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions GLACIER as a method for information extraction, not as a dataset. It describes the method's approach to extracting role fillers using cross-sentence and noun phrase evidence.",
      "processing_time": 46.741771936416626,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "We compare to the pipeline and manual feature engineering based systems: GLACIER (Patwardhan and Riloff, 2009) consists of a sentential event classifier and a set of plausible role filler recog-",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a system called GLACIER which is a method or tool, not a dataset.",
      "processing_time": 44.51309061050415,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "We compare to the pipeline and manual feature engineering based systems: GLACIER (Patwardhan and Riloff, 2009) consists of a sentential event classifier and a set of plausible role filler recognizers for each event role.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a system called GLACIER which is a method or tool, not a dataset.",
      "processing_time": 44.74950814247131,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "GLACIER (Patwardhan and Riloff, 2009) jointly considers cross-",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GLACIER"
      ],
      "dataset_descriptions": {
        "GLACIER": "Used to jointly consider phrasal and sentential evidence for information extraction, enhancing the model's ability to capture contextual information."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions 'GLACIER' which is a specific dataset used for information extraction, particularly for joint consideration of phrasal and sentential evidence.",
      "processing_time": 52.463271141052246,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Apart from event extraction, there has been increasing interest on cross-sentence relation extraction (Mintz et al., 2009; Peng et al., 2017; Jia et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to cross-sentence relation extraction. No dataset names are present in the context.",
      "processing_time": 44.86783146858215,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2797612
    },
    {
      "context_text": "Apart from event extraction, there has been increasing interest on cross-sentence relation extraction (Mintz et al., 2009; Peng et al., 2017; Jia et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to cross-sentence relation extraction. No dataset names are present in the context.",
      "processing_time": 44.86783146858215,
      "citing_paper_id": "218630327",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "First, capturing long-term dependencies in long sequences remains a fundamental challenge for recurrent neural networks (Trinh et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological challenge in RNNs.",
      "processing_time": 41.95016956329346,
      "citing_paper_id": "218630327",
      "cited_paper_id": 4760632
    },
    {
      "context_text": "Capturing Long-term Dependencies for Neural Sequence Models For training neural sequence models such as RNNs, capturing long-term dependencies in sequences remains a fundamental challenge (Trinh et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological challenge in training RNNs.",
      "processing_time": 43.01201844215393,
      "citing_paper_id": "218630327",
      "cited_paper_id": 4760632
    },
    {
      "context_text": "Many variations of models have been proposed to mitigate the effect of long sequence length, such as Long Short Term Memory (LSTM) Networks (Hochreiter and Schmidhuber, 1997; Gers et al., 1999; Graves, 2013) and Gated Recurrent Unit Networks (Cho et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 45.05992650985718,
      "citing_paper_id": "218630327",
      "cited_paper_id": 5590763
    },
    {
      "context_text": ", 1999; Graves, 2013) and Gated Recurrent Unit Networks (Cho et al., 2014).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only neural network architectures. No dataset names are present in the context.",
      "processing_time": 43.866588830947876,
      "citing_paper_id": "218630327",
      "cited_paper_id": 5590763
    },
    {
      "context_text": "CRF Layer Drawing inspirations for sentencelevel sequence tagging models on tasks like NER (Lample et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CRF Layer) inspired by sentence-level sequence tagging models for NER.",
      "processing_time": 45.28391075134277,
      "citing_paper_id": "218630327",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "We use a multi-layer (3 layers) bi-directional LSTM encoder on top of the token representations, which we denote as BiLSTM:\n{p1,p2, ...,pm} = BiLSTM({x1,x2, ...,xm})\nCRF Layer Drawing inspirations for sentencelevel sequence tagging models on tasks like NER (Lample et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BiLSTM) and a reference to NER tasks. The cited paper title 'Neural Architectures for Named Entity Recognition' confirms the focus on methods rather than datasets.",
      "processing_time": 49.07838225364685,
      "citing_paper_id": "218630327",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "Neural end-to-end models have been shown to excel at sentence-level information extraction tasks, such as named entity recognition (Lample et al., 2016; Chiu and Nichols, 2016) and ACE-type within-sentence event extraction (Chen et al., 2015; Nguyen et al., 2016; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is about neural end-to-end models excelling at sentence-level tasks, but no datasets are named.",
      "processing_time": 47.0764946937561,
      "citing_paper_id": "218630327",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "Neural end-to-end models have been shown to excel at sentence-level information extraction tasks, such as named entity recognition (Lample et al., 2016; Chiu and Nichols, 2016) and ACE-type within-sentence event extraction (Chen et al., 2015; Nguyen et al., 2016; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is about neural end-to-end models excelling at sentence-level tasks, but no datasets are named.",
      "processing_time": 47.0764946937561,
      "citing_paper_id": "218630327",
      "cited_paper_id": 6300165
    },
    {
      "context_text": "Neural end-to-end models have been shown to excel at sentence-level information extraction tasks, such as named entity recognition (Lample et al., 2016; Chiu and Nichols, 2016) and ACE-type within-sentence event extraction (Chen et al., 2015; Nguyen et al., 2016; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is about neural end-to-end models excelling at sentence-level tasks, but no datasets are named.",
      "processing_time": 47.0764946937561,
      "citing_paper_id": "218630327",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Liao and Grishman (2010) explore event type co-occurrence patterns to propagate event clas-siﬁcation decisions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving event extraction using document-level cross-event inference.",
      "processing_time": 44.204997301101685,
      "citing_paper_id": "218630327",
      "cited_paper_id": 11187670
    },
    {
      "context_text": "Second, although pretrained bi-directional transformer models such as BERT (Devlin et al., 2019) better capture long-distance dependencies as compared to an RNN architecture, they still have a constraint on the maximum length of the sequence, which is below the length of many articles about events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their limitations. There are no verifiable resources or datasets mentioned.",
      "processing_time": 44.83109474182129,
      "citing_paper_id": "218630327",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Transformer based models (Vaswani et al., 2017; Devlin et al., 2019) have also shown improvements in modeling long text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their improvements in modeling long text.",
      "processing_time": 43.48379421234131,
      "citing_paper_id": "218630327",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "• Pre-trained LM representation: Contextualized embeddings produced by pre-trained language models (Peters et al., 2018; Devlin et al., 2019) have been proved to be capable of modeling context beyond the sentence boundary and improve performance on a variety of tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only pre-trained language models. The cited papers are about methods, not datasets.",
      "processing_time": 44.82336139678955,
      "citing_paper_id": "218630327",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Specifically, we use the average of all the 12 layers’ representations and freeze the\nweights (Peters et al., 2019) during training after empirical trials4.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for using pretrained representations.",
      "processing_time": 42.95736002922058,
      "citing_paper_id": "218630327",
      "cited_paper_id": 76666127
    },
    {
      "context_text": "Specifically, we use the average of all the 12 layers’ representations and freeze the weights (Peters et al., 2019) during training",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for using pretrained representations.",
      "processing_time": 42.967286825180054,
      "citing_paper_id": "218630327",
      "cited_paper_id": 76666127
    },
    {
      "context_text": "There has also been work on unsupervised event schema induction (Chambers and Jurafsky, 2011; Chambers, 2013) and open-domain event extraction (Liu et al., 2019) from documents: the main idea is to group entities corresponding to the same role into an event template.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on unsupervised event schema induction and open-domain event extraction, which are methodological concepts.",
      "processing_time": 47.24615168571472,
      "citing_paper_id": "218630327",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Similar results regarding the context length have also been found in document-level coreference resolution (Joshi et al., 2019).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a research finding related to document-level coreference resolution.",
      "processing_time": 44.45208430290222,
      "citing_paper_id": "218630327",
      "cited_paper_id": 201646551
    },
    {
      "context_text": "We model labeling decisions jointly using a conditional random field (Lafferty et al., 2001).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (conditional random field).",
      "processing_time": 43.8178391456604,
      "citing_paper_id": "218630327",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "Upon such observation, there have been some feature-based studies (Ji and Grishman, 2008; Liao and Grishman, 2010; Huang and Riloff, 2012) that construct rules to capture document-level information for improving sentence-level ED.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies that use feature-based approaches for event extraction. No clear, verifiable datasets are named.",
      "processing_time": 47.0357506275177,
      "citing_paper_id": "51871927",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Upon such observation, there have been some feature-based studies (Ji and Grishman, 2008; Liao and Grishman, 2010; Huang and Riloff, 2012) that construct rules to capture document-level information for improving sentence-level ED.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies that use feature-based approaches for event extraction. No clear, verifiable datasets are named.",
      "processing_time": 47.0357506275177,
      "citing_paper_id": "51871927",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "Upon such observation, there have been some feature-based studies (Ji and Grishman, 2008; Liao and Grishman, 2010; Huang and Riloff, 2012) that construct rules to capture document-level information for improving sentence-level ED.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies that use feature-based approaches for event extraction. No clear, verifiable datasets are named.",
      "processing_time": 47.0357506275177,
      "citing_paper_id": "51871927",
      "cited_paper_id": 11187670
    },
    {
      "context_text": "Joint Local is a feature-based model developed in (Li et al., 2013), which incorporates such features that explicitly capture the dependency among multiple triggers and arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called 'Joint Local'. The context focuses on describing the model and its features.",
      "processing_time": 46.18615674972534,
      "citing_paper_id": "51871927",
      "cited_paper_id": 2114517
    },
    {
      "context_text": ", (McClosky et al., 2011; Hong et al., 2011; Li et al., 2014)) and representation-based methods (e.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The titles do not provide additional context to identify datasets.",
      "processing_time": 45.8425669670105,
      "citing_paper_id": "51871927",
      "cited_paper_id": 2867611
    },
    {
      "context_text": "Sentence-level is a feature-based model proposed in (Hong et al., 2011), which regards entitytype consistency as a key feature to predict event mentions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context focuses on the feature-based model and entity-type consistency, which are not datasets.",
      "processing_time": 47.42547082901001,
      "citing_paper_id": "51871927",
      "cited_paper_id": 2867611
    },
    {
      "context_text": "Existing ED methods can mainly be categorized into two classes, namely, feature-based methods (e.g., (McClosky et al., 2011; Hong et al., 2011; Li et al., 2014)) and representation-based methods (e.g., (Nguyen and Grishman, 2015; Chen et al.,\n2015; Liu et al., 2016a; Chen et al., 2017)).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of methods. No dataset names are present in the text.",
      "processing_time": 45.70880103111267,
      "citing_paper_id": "51871927",
      "cited_paper_id": 2867611
    },
    {
      "context_text": "Existing ED methods can mainly be categorized into two classes, namely, feature-based methods (e.g., (McClosky et al., 2011; Hong et al., 2011; Li et al., 2014)) and representation-based methods (e.g., (Nguyen and Grishman, 2015; Chen et al.,\n2015; Liu et al., 2016a; Chen et al., 2017)).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of methods. No dataset names are present in the text.",
      "processing_time": 45.70880103111267,
      "citing_paper_id": "51871927",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "Existing ED methods can mainly be categorized into two classes, namely, feature-based methods (e.g., (McClosky et al., 2011; Hong et al., 2011; Li et al., 2014)) and representation-based methods (e.g., (Nguyen and Grishman, 2015; Chen et al.,\n2015; Liu et al., 2016a; Chen et al., 2017)).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of methods. No dataset names are present in the text.",
      "processing_time": 45.70880103111267,
      "citing_paper_id": "51871927",
      "cited_paper_id": 16884406
    },
    {
      "context_text": "All the data preprocessing and evaluation criteria follow those in (Ghaeini et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only that the data preprocessing and evaluation criteria follow those in the cited paper.",
      "processing_time": 46.169254779815674,
      "citing_paper_id": "51871927",
      "cited_paper_id": 3608203
    },
    {
      "context_text": "…attention mechanism has recently been applied effectively in various tasks, including machine translation (Zhang et al., 2017), question answering (Hao et al., 2017), document summarization (Tan et al., 2017), etc., this is the first study, to the best of our knowledge, which adopts a…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only various tasks where attention mechanisms have been applied. There are no clear identifiers for datasets in the given context.",
      "processing_time": 47.209118604660034,
      "citing_paper_id": "51871927",
      "cited_paper_id": 3896491
    },
    {
      "context_text": "JRNN is a representation-based model proposed in (Nguyen et al., 2016), which exploits the inter-dependency between event triggers and argument roles via discrete structures.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (JRNN) and its purpose. There are no clear identifiers for datasets in the text.",
      "processing_time": 47.409175395965576,
      "citing_paper_id": "51871927",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Here, similar to that in (Yang et al., 2016), cw is a vector representing the wordlevel context of wit, which is initialized at random.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes a method for initializing word-level context vectors.",
      "processing_time": 45.9913911819458,
      "citing_paper_id": "51871927",
      "cited_paper_id": 6857205
    },
    {
      "context_text": "Here, similar to that in (Yang et al., 2016), cw is a vector representing the wordlevel context ofwit, which is initialized at random.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes a method for initializing word-level context vectors.",
      "processing_time": 46.153701305389404,
      "citing_paper_id": "51871927",
      "cited_paper_id": 6857205
    },
    {
      "context_text": "For each word wit, we first concatenate its embedding wit and its entity type embedding1 eit (Nguyen and Grishman, 2015) as the input git of a Bi-GRU and thus obtain the bidirectional hidden state hit:",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method involving word embeddings and entity type embeddings.",
      "processing_time": 46.61622738838196,
      "citing_paper_id": "51871927",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "For each word wit, we first concatenate its embedding wit and its entity type embedding1 eit (Nguyen and Grishman, 2015) as the input git of a Bi-GRU and thus obtain the bidirectional hidden state hit:\nhit = [ −−−−→ GRUw(git), ←−−−− GRUw(git)].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving word embeddings and entity type embeddings.",
      "processing_time": 46.41197347640991,
      "citing_paper_id": "51871927",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "Cross-event is a feature-based model proposed in (Liao and Grishman, 2010), which learns relations among event types from training corpus and futher helps predict the occurrence of events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a 'training corpus' but does not specify a named dataset. The focus is on the method (Cross-event model) rather than a specific dataset.",
      "processing_time": 49.21750855445862,
      "citing_paper_id": "51871927",
      "cited_paper_id": 11187670
    },
    {
      "context_text": "Skip-CNN is a representation-based model presented in (Nguyen and Grishman, 2016), which proposes a novel convolution to exploit nonconsecutive k-grams for event detection.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its application to event detection.",
      "processing_time": 46.76327633857727,
      "citing_paper_id": "51871927",
      "cited_paper_id": 11331864
    },
    {
      "context_text": ", (Nguyen and Grishman, 2015; Chen et al., 2015; Liu et al., 2016a; Chen et al., 2017)).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers. No dataset names are present in the context.",
      "processing_time": 48.069751262664795,
      "citing_paper_id": "51871927",
      "cited_paper_id": 16884406
    },
    {
      "context_text": "PSL is a feature-based model developed in (Liu et al., 2016b), which encods global information such as event-event association in the form of logic using the probabilistic soft logic model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (PSL) and its application in encoding global information for event detection.",
      "processing_time": 48.981789350509644,
      "citing_paper_id": "51871927",
      "cited_paper_id": 16884406
    },
    {
      "context_text": "It should be mentioned that although the attention mechanism has recently been applied effectively in various tasks, including machine translation (Zhang et al., 2017), question answering (Hao et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the application of attention mechanisms in machine translation and question answering.",
      "processing_time": 48.07158827781677,
      "citing_paper_id": "51871927",
      "cited_paper_id": 35844178
    },
    {
      "context_text": "It should be mentioned that although the attention mechanism has recently been applied effectively in various tasks, including machine translation (Zhang et al., 2017), question answering (Hao et al., 2017), document summarization (Tan et al., 2017), etc., this is the first study, to the best of…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only applications of the attention mechanism in various NLP tasks.",
      "processing_time": 48.31256818771362,
      "citing_paper_id": "51871927",
      "cited_paper_id": 35844178
    },
    {
      "context_text": "Previous work has focused on event causality, creating corpora like CausalTimeBank (CTB) (Mirza et al., 2014) from news, CaTeRS (Mostafazadeh et al., 2016) from short stories and EventStoryLine (Caselli and Vossen, 2017) from online news articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CausalTimeBank (CTB)",
        "CaTeRS",
        "EventStoryLine"
      ],
      "dataset_descriptions": {
        "CausalTimeBank (CTB)": "Used to study event causality in news articles, providing annotated data for training and evaluating causal relation extraction systems.",
        "CaTeRS": "Applied to annotate causal and temporal relations in short stories, enhancing the understanding of narrative structures and event sequences.",
        "EventStoryLine": "Utilized to analyze event causality in online news articles, offering a rich resource for studying event chains and their temporal dynamics."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three corpora that are relevant to document-level event extraction, specifically focusing on event causality. These corpora are clearly identified and used in previous research.",
      "processing_time": 70.37015867233276,
      "citing_paper_id": "248377560",
      "cited_paper_id": 8387007
    },
    {
      "context_text": ", 2014) from news, CaTeRS (Mostafazadeh et al., 2016) from short stories and EventStoryLine (Caselli and Vossen, 2017) from online news articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005",
        "CaTeRS",
        "EventStoryLine"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to extract events from news articles, focusing on identifying and classifying events in a structured format.",
        "CaTeRS": "Used to annotate causal and temporal relations in short stories, enhancing the understanding of event structures and their relationships.",
        "EventStoryLine": "Used to extract event storylines from online news articles, focusing on the chronological and causal connections between events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three datasets: 'ACE 2005', 'CaTeRS', and 'EventStoryLine'. These are specific datasets used in the research for document-level event extraction.",
      "processing_time": 70.5453851222992,
      "citing_paper_id": "248377560",
      "cited_paper_id": 8387007
    },
    {
      "context_text": "For example, EventStoryLine (ESL) has 1,770 causal event pairs, CaTeRS has 488 causal links, while CTB has 318 causal event pairs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine (ESL)",
        "CaTeRS",
        "CTB"
      ],
      "dataset_descriptions": {
        "EventStoryLine (ESL)": "Used to study causal event pairs, providing 1,770 instances for document-level event extraction and analysis.",
        "CaTeRS": "Used to annotate causal and temporal relations in event structures, containing 488 causal links for semantic annotation.",
        "CTB": "Used to analyze causal event pairs, offering 318 instances for document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets with clear identifiers and their usage in the context of causal event pairs.",
      "processing_time": 67.749831199646,
      "citing_paper_id": "248377560",
      "cited_paper_id": 8387007
    },
    {
      "context_text": "However, in the real world, implicit relations are more common but more challenging to identify (Hidey and McKeown, 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general challenge in identifying implicit relations.",
      "processing_time": 48.30776906013489,
      "citing_paper_id": "248377560",
      "cited_paper_id": 9137624
    },
    {
      "context_text": "All metrics were calculated using the scikit-learn (Pedregosa et al., 2011) package.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions scikit-learn, which is a software toolkit, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 50.1627779006958,
      "citing_paper_id": "248377560",
      "cited_paper_id": 10659969
    },
    {
      "context_text": "Penn Discourse Treebank (PDTB) (Prasad et al., 2008; Webber et al., 2019; Prasad et al., 2006) is a corpus that annotates semantic relations (including causal relations) between clauses, expressed either explicitly or implicitly.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Penn Discourse Treebank (PDTB)"
      ],
      "dataset_descriptions": {
        "Penn Discourse Treebank (PDTB)": "Used to annotate semantic relations between clauses, including causal relations, both explicit and implicit, enhancing discourse analysis in natural language processing."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the Penn Discourse Treebank (PDTB) as a corpus that annotates semantic relations between clauses. It is clearly identified as a reusable resource.",
      "processing_time": 61.304980993270874,
      "citing_paper_id": "248377560",
      "cited_paper_id": 13374927
    },
    {
      "context_text": "Penn Discourse Treebank (PDTB) (Prasad et al., 2008; Webber et al., 2019; Prasad et al., 2006) is a corpus that annotates semantic relations (including causal relations) between clauses, expressed either explicitly or implicitly.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Penn Discourse Treebank (PDTB)"
      ],
      "dataset_descriptions": {
        "Penn Discourse Treebank (PDTB)": "Used to annotate semantic relations between clauses, including causal relations, both explicit and implicit, enhancing discourse analysis in natural language processing."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the Penn Discourse Treebank (PDTB) as a corpus that annotates semantic relations between clauses. It is clearly identified as a reusable resource.",
      "processing_time": 61.304980993270874,
      "citing_paper_id": "248377560",
      "cited_paper_id": 263864984
    },
    {
      "context_text": "Rule-based approaches (Girju and Moldovan, 2002; Khoo et al., 2000; Sakaji et al., 2008) have been shown to work well on such constructions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only rule-based approaches. There are no clear identifiers for datasets in the text.",
      "processing_time": 50.14754128456116,
      "citing_paper_id": "248377560",
      "cited_paper_id": 14521571
    },
    {
      "context_text": "When discussing causality in text, many corpora only focus on explicit relations (Girju and Moldovan, 2002; Dunietz et al., 2017).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'corpora' but does not specify any particular dataset. It is a general statement about the nature of existing corpora, not a specific reference to a reusable dataset.",
      "processing_time": 51.91270041465759,
      "citing_paper_id": "248377560",
      "cited_paper_id": 14521571
    },
    {
      "context_text": "In the subsequent discussions, we focus our key evaluation metrics to be F1, Accuracy and MCC.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only evaluation metrics. There are no multi-word proper nouns, acronyms, or hyphenated names with digits that could indicate a dataset.",
      "processing_time": 52.036396980285645,
      "citing_paper_id": "248377560",
      "cited_paper_id": 44596673
    },
    {
      "context_text": "From the third row in Table 3, when we trained on our training set and applied on the test set, we achieved a reasonable F1 score of 81.20%, Accuracy of 77.81%, and MCC of 54.52%, each exceeding the dummy base-lines scores reﬂected in the ﬁrst two rows.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'our training set' and 'test set', which are generic placeholders.",
      "processing_time": 51.50394940376282,
      "citing_paper_id": "248377560",
      "cited_paper_id": 44596673
    },
    {
      "context_text": "A reasonable F1 score of 64.05%, Accuracy of 64.63% and MCC of 32.13% was obtained, similar to or slightly better than PDTB’s performance, despite CTB Bal being much smaller in size.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics and a comparison to PDTB. No clear, verifiable dataset names are present.",
      "processing_time": 50.4880096912384,
      "citing_paper_id": "248377560",
      "cited_paper_id": 44596673
    },
    {
      "context_text": "For all experiments, we evaluated the predictions against true labels using ﬁve evaluation metrics: Precision (P), Recall (R), F1, Accuracy (Acc) and Matthews Correlation Coefﬁcient (MCC) (Matthews, 1975).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. The cited paper title is irrelevant to the current context.",
      "processing_time": 50.31592631340027,
      "citing_paper_id": "248377560",
      "cited_paper_id": 44596673
    },
    {
      "context_text": "CNC obtained the highest TRF across the three corpora for both F1 and MCC, reﬂecting good transferability.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not provide specific dataset names, only mentions 'three corpora' without naming them. The cited paper title is irrelevant to the context.",
      "processing_time": 51.05420923233032,
      "citing_paper_id": "248377560",
      "cited_paper_id": 44596673
    },
    {
      "context_text": "We constructed a baseline model by ﬁne-tuning the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model (Devlin et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions fine-tuning BERT but does not reference any specific dataset. BERT is a model, not a dataset.",
      "processing_time": 51.06031250953674,
      "citing_paper_id": "248377560",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Neural Network Baselines We constructed a baseline model by fine-tuning the pretrained Bidirectional Encoder Representations from Transformers (BERT) model (Devlin et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT but does not refer to it as a dataset. It is described as a pretrained model used for fine-tuning, which is a method, not a dataset.",
      "processing_time": 53.43748426437378,
      "citing_paper_id": "248377560",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Caselli and Inel (2018) argues that discrepancies in the quality of crowd-sourced annotations from experts should be used as an estimate on how complex the task is.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a discussion about crowd-sourced annotations and their complexity.",
      "processing_time": 51.052063941955566,
      "citing_paper_id": "248377560",
      "cited_paper_id": 53627072
    },
    {
      "context_text": "Causality is a core cognitive concept and appears in many natural language processing (NLP) works that aim to tackle inference and understanding (Jo et al., 2021; Dunietz et al., 2020; Feder et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and works in NLP. No verifiable resources are identified.",
      "processing_time": 52.0034921169281,
      "citing_paper_id": "248377560",
      "cited_paper_id": 218487111
    },
    {
      "context_text": "Causality is a core cognitive concept and appears in many natural language processing (NLP) works that aim to tackle inference and understanding (Jo et al., 2021; Dunietz et al., 2020; Feder et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and works in NLP. No verifiable resources are identified.",
      "processing_time": 52.0034921169281,
      "citing_paper_id": "248377560",
      "cited_paper_id": 237386009
    },
    {
      "context_text": "The data is based on randomly sampled articles from multiple sources and periods, and all annotations were performed by two annotators, adjudicated and spot-checked by a supervisor, and corrected further semi-automatically (Hürriyeto˘glu et al., 2021c; Yörük et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'randomly sampled articles' but does not specify a named dataset. The cited papers do not provide additional specific dataset names.",
      "processing_time": 52.75727581977844,
      "citing_paper_id": "248377560",
      "cited_paper_id": 236257646
    },
    {
      "context_text": "The data is based on randomly sampled articles from multiple sources and periods, and all annotations were performed by two annotators, adjudicated and spot-checked by a supervisor, and corrected further semi-automatically (Hürriyeto˘glu et al., 2021c; Yörük et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'randomly sampled articles' but does not specify a named dataset. The cited papers do not provide additional specific dataset names.",
      "processing_time": 52.75727581977844,
      "citing_paper_id": "248377560",
      "cited_paper_id": 236486186
    },
    {
      "context_text": "…Socio-political Events from News (AESPEN) in 2020 (Hürriyeto˘glu et al., 2020b; Hürriyeto˘glu et al., 2020a) and Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE) in 2021 (Hür-riyeto˘glu et al., 2021a; Hürriyeto˘glu et al., 2021b; Hür-riyeto˘glu, 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "AESPEN",
        "CASE"
      ],
      "dataset_descriptions": {
        "AESPEN": "Used to extract socio-political events from news articles, focusing on multilingual protest news detection and event classification.",
        "CASE": "Utilized for the automated extraction of socio-political events from text, emphasizing challenges and applications in multilingual settings."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions two specific datasets, AESPEN and CASE, which are relevant to the topic of document-level event extraction. Both are used in the context of socio-political events from news and text.",
      "processing_time": 67.50577783584595,
      "citing_paper_id": "248377560",
      "cited_paper_id": 236486186
    },
    {
      "context_text": "NEGRESULT and NEGATIVE-CONDITION types Quoting the PDTB-3 annotation manual (Webber et al., 2019), “CAUSE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only types of discourse relations from the PDTB-3 annotation manual.",
      "processing_time": 52.41740012168884,
      "citing_paper_id": "248377560",
      "cited_paper_id": 263864984
    },
    {
      "context_text": "The example is likely to be causal if it can be rephrased into “X causes Y” or “Due to X, Y.” C AUSE types Quoting the PDTB-3 annotation manual (Webber et al., 2019), “C AUSE .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to the PDTB-3 annotation manual. The citation is used to explain the definition of 'CAUSE' types in discourse analysis.",
      "processing_time": 54.840325117111206,
      "citing_paper_id": "248377560",
      "cited_paper_id": 263864984
    },
    {
      "context_text": "For causality, we utilized the deﬁnition of C ONTINGENCY from PDTB-3, which assigns this label for samples where “one argument provides the reason, explanation or justiﬁcation for the situation described by the other” (Webber et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PDTB-3"
      ],
      "dataset_descriptions": {
        "PDTB-3": "Used to define the 'contingency' label for causality, where one argument provides the reason, explanation, or justification for the situation described by the other."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions PDTB-3, which is a specific version of the Penn Discourse Treebank, a well-known dataset in NLP. However, the context does not indicate that the dataset is used for document-level event extraction, but rather for defining a specific label for causality.",
      "processing_time": 68.38650512695312,
      "citing_paper_id": "248377560",
      "cited_paper_id": 263864984
    },
    {
      "context_text": "For causality, we utilized the definition of CONTINGENCY from PDTB-3, which assigns this label for samples where “one argument provides the reason, explanation or justification for the situation described by the other” (Webber et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions PDTB-3, which is a specific version of the Penn Discourse Treebank. However, it is used to define a concept (CONTINGENCY) rather than as a dataset for empirical analysis.",
      "processing_time": 56.55311608314514,
      "citing_paper_id": "248377560",
      "cited_paper_id": 263864984
    },
    {
      "context_text": "CAUSE types Quoting the PDTB-3 annotation manual (Webber et al., 2019), “CAUSE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to the PDTB-3 annotation manual. The manual itself is not a dataset but a guide for annotation.",
      "processing_time": 54.82797408103943,
      "citing_paper_id": "248377560",
      "cited_paper_id": 263864984
    },
    {
      "context_text": "In this section, we present a battery of baseline models and results of causal sentence classification on the CNC data and the two existing news corpora, PDTB-3 (Webber et al., 2019) and CTB (Mirza et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CNC data",
        "PDTB-3",
        "CTB"
      ],
      "dataset_descriptions": {
        "CNC data": "Used for causal sentence classification, focusing on the performance of baseline models in identifying causal relationships in Chinese news articles.",
        "PDTB-3": "Used for causal sentence classification, evaluating the effectiveness of baseline models in detecting causal relationships in English news articles.",
        "CTB": "Used for causal sentence classification, assessing the performance of baseline models in identifying causal relationships in Chinese text."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific datasets used for causal sentence classification, including CNC data, PDTB-3, and CTB. These are clearly identified and used in the research.",
      "processing_time": 74.18503499031067,
      "citing_paper_id": "248377560",
      "cited_paper_id": 263864984
    },
    {
      "context_text": "In this section, we present a battery of baseline models and results of causal sentence classiﬁcation on the CNC data and the two existing news corpora, PDTB-3 (Webber et al., 2019) and CTB (Mirza et al., 2014).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CNC data",
        "PDTB-3",
        "CTB"
      ],
      "dataset_descriptions": {
        "CNC data": "Used for causal sentence classification, providing a domain-specific dataset to evaluate baseline models and results.",
        "PDTB-3": "Used for causal sentence classification, serving as a benchmark news corpus to compare against baseline models and results.",
        "CTB": "Used for causal sentence classification, serving as another benchmark news corpus to evaluate baseline models and results."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions specific datasets used for causal sentence classification, including CNC data, PDTB-3, and CTB. These are clearly identified and used in the research context.",
      "processing_time": 73.60105776786804,
      "citing_paper_id": "248377560",
      "cited_paper_id": 263864984
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role ﬁllers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 54.384358406066895,
      "citing_paper_id": "236460259",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role ﬁllers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 54.384358406066895,
      "citing_paper_id": "236460259",
      "cited_paper_id": 2213149
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role ﬁllers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 54.384358406066895,
      "citing_paper_id": "236460259",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role ﬁllers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 54.384358406066895,
      "citing_paper_id": "236460259",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "…Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to previous works focusing on sentence-level event extraction. The term 'ACE' is mentioned but it is likely referring to a method or benchmark rather than a dataset.",
      "processing_time": 57.941057443618774,
      "citing_paper_id": "236460259",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "A great number of previous studies (Ahn, 2006; Ji and Grish-man, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 55.71634840965271,
      "citing_paper_id": "236460259",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "These studies are mainly based on hand-designed features (Li et al., 2013; Kai and Gr-ishman, 2015) and neural-based to learn features automatically (Chen et al., 2015; Nguyen et al., 2016; Bj¨orne and Salakoski, 2018; Yang et al., 2019; Chan et al., 2019; Yang et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches used in event extraction.",
      "processing_time": 53.80205988883972,
      "citing_paper_id": "236460259",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "These studies are mainly based on hand-designed features (Li et al., 2013; Kai and Gr-ishman, 2015) and neural-based to learn features automatically (Chen et al., 2015; Nguyen et al., 2016; Bj¨orne and Salakoski, 2018; Yang et al., 2019; Chan et al., 2019; Yang et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches used in event extraction.",
      "processing_time": 53.80205988883972,
      "citing_paper_id": "236460259",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "These studies are mainly based on hand-designed features (Li et al., 2013; Kai and Gr-ishman, 2015) and neural-based to learn features automatically (Chen et al., 2015; Nguyen et al., 2016; Bj¨orne and Salakoski, 2018; Yang et al., 2019; Chan et al., 2019; Yang et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches used in event extraction.",
      "processing_time": 53.80205988883972,
      "citing_paper_id": "236460259",
      "cited_paper_id": 14117526
    },
    {
      "context_text": "These studies are mainly based on hand-designed features (Li et al., 2013; Kai and Gr-ishman, 2015) and neural-based to learn features automatically (Chen et al., 2015; Nguyen et al., 2016; Bj¨orne and Salakoski, 2018; Yang et al., 2019; Chan et al., 2019; Yang et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches used in event extraction.",
      "processing_time": 53.80205988883972,
      "citing_paper_id": "236460259",
      "cited_paper_id": 51878680
    },
    {
      "context_text": "…studies (Ahn, 2006; Ji and Grish-man, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies focusing on sentence-level event extraction. No verifiable resources are identified.",
      "processing_time": 54.80063009262085,
      "citing_paper_id": "236460259",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "Yang and Mitchell (2016) introduced event structure to jointly extract events and entities within a document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the introduction of a method for joint extraction of events and entities, but does not mention any specific datasets.",
      "processing_time": 53.61145734786987,
      "citing_paper_id": "236460259",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "All of these de-coders are based on the non-autoregressive mechanism (Gu et al., 2018), which supports the extraction of all events in parallel.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (non-autoregressive mechanism).",
      "processing_time": 53.60767197608948,
      "citing_paper_id": "236460259",
      "cited_paper_id": 3480671
    },
    {
      "context_text": "Both of them are based on the non-autoregressive mechanism (Gu et al., 2018), which supports the extraction of multiple events in parallel.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (non-autoregressive mechanism).",
      "processing_time": 53.778968811035156,
      "citing_paper_id": "236460259",
      "cited_paper_id": 3480671
    },
    {
      "context_text": "…great number of previous studies (Ahn, 2006; Ji and Grish-man, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies focusing on sentence-level event extraction.",
      "processing_time": 54.35250163078308,
      "citing_paper_id": "236460259",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "During training, we employ the AdamW optimizer (Kingma and Ba, 2014) with the learning rate 1e-5 with batch size 16.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the AdamW optimizer, which is a method, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 54.7803053855896,
      "citing_paper_id": "236460259",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "Finally, for comparing extracted events to ground truths, we propose a matching loss function inspired by the Hungarian algorithm (Kuhn, 1955; Munkres, 1957).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Hungarian algorithm) used for a matching loss function.",
      "processing_time": 54.0480535030365,
      "citing_paper_id": "236460259",
      "cited_paper_id": 9426884
    },
    {
      "context_text": "Inspired by the assigning problem in the operation research (Kuhn, 1955; Munkres, 1957), we propose a matching loss function, which can produce an optimal bipartite matching between predicted and ground-truth events.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Hungarian method) used for solving the assignment problem. No datasets are referenced for use in the research context.",
      "processing_time": 57.128090143203735,
      "citing_paper_id": "236460259",
      "cited_paper_id": 9426884
    },
    {
      "context_text": "…Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE"
      ],
      "dataset_descriptions": {
        "ACE": "Used to evaluate sentence-level event extraction systems, providing annotated data for benchmarking performance across various event types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE evaluation' which is a specific dataset used for evaluating event extraction systems. The title confirms it is a dataset.",
      "processing_time": 61.786980390548706,
      "citing_paper_id": "236460259",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "…and Grish-man, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works focusing on sentence-level event extraction.",
      "processing_time": 54.7634859085083,
      "citing_paper_id": "236460259",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "These studies are mainly based on handdesigned features (Li et al., 2013; Kai and Grishman, 2015) and neural-based to learn features automatically (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. No dataset names are present in the text.",
      "processing_time": 55.67933392524719,
      "citing_paper_id": "236460259",
      "cited_paper_id": 14117526
    },
    {
      "context_text": "A two-step approach (Zhang et al., 2020) is proposed for argument linking by detecting implicit argument across sentences.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for argument linking. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 56.30960726737976,
      "citing_paper_id": "236460259",
      "cited_paper_id": 43095407
    },
    {
      "context_text": "A two-step approach (Zhang et al., 2020) is proposed for argument linking by detecting implicit argument across sentences.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for argument linking. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 56.30960726737976,
      "citing_paper_id": "236460259",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Recently, Ebner et al. (2020) published the Roles Across Multiple Sentences (RAMS) dataset, which contains annotation for the task of multi-sentence argument linking.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Roles Across Multiple Sentences (RAMS)"
      ],
      "dataset_descriptions": {
        "Roles Across Multiple Sentences (RAMS)": "Used to annotate and link arguments across multiple sentences, supporting the development of models for document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for multi-sentence argument linking.",
      "processing_time": 64.16386938095093,
      "citing_paper_id": "236460259",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "tated event pairs via external dictionaries, such as WordNet (Miller, 1995) and VerbNet (Schuler, 2005).",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions WordNet and VerbNet as external dictionaries but does not indicate their use as datasets for document-level event extraction.",
      "processing_time": 56.04457497596741,
      "citing_paper_id": "235313431",
      "cited_paper_id": 1671874
    },
    {
      "context_text": "(1) Lexical knowledge expanding: expanding annotated event pairs via external dictionaries, such as WordNet (Miller, 1995) and VerbNet (Schuler, 2005).",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions external dictionaries like WordNet and VerbNet, which are not datasets but lexical resources. No specific datasets are mentioned.",
      "processing_time": 35.1133975982666,
      "citing_paper_id": "235313431",
      "cited_paper_id": 1671874
    },
    {
      "context_text": "Some focus on explicit causal textual patterns (Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 57.10010480880737,
      "citing_paper_id": "235313431",
      "cited_paper_id": 3030259
    },
    {
      "context_text": "Some focus on explicit causal textual patterns (Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 57.10010480880737,
      "citing_paper_id": "235313431",
      "cited_paper_id": 9137624
    },
    {
      "context_text": "Recently, inspired by Xia et al. (2017) who implemented the duality in a neural-based dual learning system, the above primal-dual tasks are implemented in two different ways: 1) providing additional labeled samples via bootstrapping, and 2) adding rewards at\nthe training stage for each agent.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is about implementing dual learning systems and does not reference any data sources.",
      "processing_time": 56.29221272468567,
      "citing_paper_id": "235313431",
      "cited_paper_id": 3730033
    },
    {
      "context_text": "And some others pay attention on statistical causal association and cues (Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to papers discussing methods or findings. No verifiable resources are identified.",
      "processing_time": 56.28749656677246,
      "citing_paper_id": "235313431",
      "cited_paper_id": 6323983
    },
    {
      "context_text": "And some others pay attention on statistical causal association and cues (Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to papers discussing methods or findings. No verifiable resources are identified.",
      "processing_time": 56.28749656677246,
      "citing_paper_id": "235313431",
      "cited_paper_id": 31562985
    },
    {
      "context_text": "Furthermore, we calculate the BLEU (Papineni et al., 2002) value to further evaluate the\ndiversity.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BLEU but does not refer to a dataset. BLEU is a metric, not a dataset, and there are no other specific, verifiable datasets mentioned.",
      "processing_time": 58.022329568862915,
      "citing_paper_id": "235313431",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "Furthermore, we calculate the BLEU (Papineni et al., 2002) value to further evaluate the\ndiversity.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BLEU but does not refer to a dataset. BLEU is a metric, not a dataset, and there are no other specific, verifiable datasets mentioned.",
      "processing_time": 58.022329568862915,
      "citing_paper_id": "235313431",
      "cited_paper_id": 18925286
    },
    {
      "context_text": "Furthermore, we calculate the BLEU (Papineni et al., 2002) value to further evaluate the",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a metric (BLEU) which is excluded according to the rules.",
      "processing_time": 55.62884855270386,
      "citing_paper_id": "235313431",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "…2019); (5) Generative method tries to generate additional training data while preserving the class label (Anaby-Tavor et al., 2019; Yang et al., 2019); (6) Distantly supervision and self-supervision try to introduce new training data from unlabeled text (Chen et al., 2017; Ruiter et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It discusses methods and approaches for generating or using training data, but does not name any particular datasets.",
      "processing_time": 58.0298957824707,
      "citing_paper_id": "235313431",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "CauSE corpus (Dunietz et al., 2015) of causal relation and other seven relations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CauSE corpus"
      ],
      "dataset_descriptions": {
        "CauSE corpus": "Used to annotate causal and other relations in text, focusing on corpus lexicography of constructions to enhance understanding of linguistic patterns."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the CauSE corpus, which is a specific dataset used for annotating causal language and other relations. The corpus is directly relevant to document-level event extraction.",
      "processing_time": 65.4324152469635,
      "citing_paper_id": "235313431",
      "cited_paper_id": 12134535
    },
    {
      "context_text": "Dunietz et al. (2017) presented BECauSE 2.0, a new version of the BECauSE corpus (Dunietz et al., 2015) of causal relation and other seven relations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "BECauSE 2.0",
        "BECauSE corpus"
      ],
      "dataset_descriptions": {
        "BECauSE 2.0": "Used to annotate causal and other relations in text, enhancing the original BECauSE corpus with additional data and annotations.",
        "BECauSE corpus": "Used to annotate causal and other relations in text, serving as a foundational resource for studying linguistic constructions of causality."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'BECauSE 2.0' and 'BECauSE corpus', both of which are specific datasets used for annotating causal language and other relations.",
      "processing_time": 73.87588834762573,
      "citing_paper_id": "235313431",
      "cited_paper_id": 12134535
    },
    {
      "context_text": "Event causality identification (ECI) aims to identify causal relations between events in texts, which can provide crucial clues for NLP tasks, such as logical reasoning and question answering (Girju, 2003; Oh et al., 2013, 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of event causality identification and its importance for NLP tasks.",
      "processing_time": 55.6241672039032,
      "citing_paper_id": "235313431",
      "cited_paper_id": 12440940
    },
    {
      "context_text": "Then, inspired by Bordes et al. (2013), we filter the extracted event pairs by converting them into triples <ei, causal/noncausal, ej> and calculating the causal-distance by maximizing L in a causal representation space:\nL = ∑\n(ei,ej)∈T ∑ (e′i,e ′ j)∈T ′ [λ+ d(e′i, e ′ j)− d(ei, ej)]+, (3)\nwhere T…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for filtering extracted event pairs using causal distance. No verifiable resources are identified.",
      "processing_time": 57.25223112106323,
      "citing_paper_id": "235313431",
      "cited_paper_id": 14941970
    },
    {
      "context_text": "9 (ESC) (Caselli and Vossen, 2017) described above; and (2) Causal-TimeBank (Causal-TB) (Mirza and Tonelli, 2014) which contains 184 documents, 6813",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ESC",
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "ESC": "Used to analyze event causality in documents, focusing on the relationship between events and their causal implications.",
        "Causal-TimeBank": "Used to study causality and temporal information in 184 documents, specifically examining the interplay between events and time."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ESC and Causal-TimeBank, both of which are used in the context of event and causality analysis.",
      "processing_time": 69.9465696811676,
      "citing_paper_id": "235313431",
      "cited_paper_id": 17440009
    },
    {
      "context_text": "For ESC, we prefer 1) LSTM (Cheng and Miyao, 2017), a dependency path based",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (LSTM).",
      "processing_time": 54.89623427391052,
      "citing_paper_id": "235313431",
      "cited_paper_id": 32821791
    },
    {
      "context_text": "3) Comparing MM+ConceptNet with MM, with the same knowledge base, our dual augmented data can further improve the performance Methods P R F1 ESC LSTM (Cheng and Miyao, 2017) 34.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (ESC LSTM) and a comparison of performance metrics. No verifiable resources are identified.",
      "processing_time": 57.81740689277649,
      "citing_paper_id": "235313431",
      "cited_paper_id": 32821791
    },
    {
      "context_text": "For ESC, we prefer 1) LSTM (Cheng and Miyao, 2017), a dependency path based\n4https://github.com/google-research/ bert\nsequential model that models the context between events to identify causality; 2) Seq (Choubey and Huang, 2017), a sequence model explores complex human designed features for ECI; 3) LR+ and ILP (Gao et al., 2019), document-level models adopt document structures for ECI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context focuses on describing different models used for event causality identification and event coreference resolution.",
      "processing_time": 59.25844144821167,
      "citing_paper_id": "235313431",
      "cited_paper_id": 32821791
    },
    {
      "context_text": "Specifically, we design a classifier based on BERT (Devlin et al., 2019) to build our identifier.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT, which is a model, not a dataset. No datasets are explicitly mentioned or used in the described research.",
      "processing_time": 57.23235321044922,
      "citing_paper_id": "235313431",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Therefore, we complete sentences by filling the cohesive words between given events and assigned entities with masked BERT (Devlin et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BERT) which is excluded according to the instructions.",
      "processing_time": 56.38941788673401,
      "citing_paper_id": "235313431",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Specifically, the sentences produced by EDA has a certain degree of causality and diversity due to the lexical substitution assisted by external knowledge.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (EDA) and its effects. No verifiable resources are identified.",
      "processing_time": 56.583179235458374,
      "citing_paper_id": "235313431",
      "cited_paper_id": 59523656
    },
    {
      "context_text": "As shown in Figure 1, S3 is produced by EDA, it lacks a linguistic expression that expresses the causal semantics between kill and attack.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (EDA) and a figure. There are no clear identifiers for datasets.",
      "processing_time": 57.55416655540466,
      "citing_paper_id": "235313431",
      "cited_paper_id": 59523656
    },
    {
      "context_text": "For example, easy data augmentation (EDA) (Wei and Zou, 2019) is the most representative method that relies on lexical substitution, deletion, swapping, and insertion to produce new data.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'easy data augmentation (EDA)' but does not refer to a specific dataset. It describes a method for data augmentation.",
      "processing_time": 56.835747480392456,
      "citing_paper_id": "235313431",
      "cited_paper_id": 59523656
    },
    {
      "context_text": "Specifically, 1) text surface transformation brings a slight change to the labeled data, thus it has relatively little impact on ECI; 2) Back translation introduces limited new causal expressions by translation, thus it slightly increases the recall value on ECI; 3) EDA can introduce new expressions via substitution, but the augmented data is not canonical and cannot accurately express the causality, therefore, its impact on ECI is also limited.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses data augmentation techniques and their impact on ECI, but does not reference any named datasets.",
      "processing_time": 59.419960498809814,
      "citing_paper_id": "235313431",
      "cited_paper_id": 59523656
    },
    {
      "context_text": "For many Natural Language Processing (NLP) tasks, there exist many primal and dual tasks, such as open information narration (OIN) and open information extraction (OIE) (Sun et al., 2018), natural language understanding (NLU) and natural language generation (NLG) (Su et al., 2019, 2020), semantic parsing and natural language generation (Ye et al., 2019; Cao et al., 2019, 2020), link prediction and entailment graph induction (Cao et al., 2019), query-to-response and response-to-query generation (Shen and Feng, 2020) and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and their dual counterparts. No verifiable resources are named.",
      "processing_time": 57.945462465286255,
      "citing_paper_id": "235313431",
      "cited_paper_id": 155092173
    },
    {
      "context_text": "…(OIN) and open information extraction (OIE) (Sun et al., 2018), natural language understanding (NLU) and natural language generation (NLG) (Su et al., 2019, 2020), semantic parsing and natural language generation (Ye et al., 2019; Cao et al., 2019, 2020), link prediction and entailment…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It primarily discusses various methods and tasks in natural language processing.",
      "processing_time": 57.53781056404114,
      "citing_paper_id": "235313431",
      "cited_paper_id": 155092173
    },
    {
      "context_text": "…language understanding (NLU) and natural language generation (NLG) (Su et al., 2019, 2020), semantic parsing and natural language generation (Ye et al., 2019; Cao et al., 2019, 2020), link prediction and entailment graph induction (Cao et al., 2019), query-to-response and response-to-query…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various tasks and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 58.352072954177856,
      "citing_paper_id": "235313431",
      "cited_paper_id": 173990567
    },
    {
      "context_text": "…language generation (NLG) (Su et al., 2019, 2020), semantic parsing and natural language generation (Ye et al., 2019; Cao et al., 2019, 2020), link prediction and entailment graph induction (Cao et al., 2019), query-to-response and response-to-query generation (Shen and Feng, 2020) and so on.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various tasks and methods. No clear identifiers for datasets are present.",
      "processing_time": 57.38893413543701,
      "citing_paper_id": "235313431",
      "cited_paper_id": 195886068
    },
    {
      "context_text": "…(NLU) and natural language generation (NLG) (Su et al., 2019, 2020), semantic parsing and natural language generation (Ye et al., 2019; Cao et al., 2019, 2020), link prediction and entailment graph induction (Cao et al., 2019), query-to-response and response-to-query generation (Shen…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various tasks and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 57.93916630744934,
      "citing_paper_id": "235313431",
      "cited_paper_id": 195886068
    },
    {
      "context_text": "2) Comparing KnowDis with LearnDAFull, we note that training data generated by LearnDA is more helpful to ECI than distant supervision with external knowledge (+2.9%/+2.1%).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'training data' but does not specify a named dataset. The reference to 'distant supervision with external knowledge' suggests the use of a method rather than a specific dataset.",
      "processing_time": 61.04217457771301,
      "citing_paper_id": "235313431",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "Secondly, we assemble any two events from obtained causal triples to generate causal event pairs set and filter them via the filter of KonwDis.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'KnowDis' but does not indicate it is a dataset. It appears to be a method or tool for filtering causal event pairs.",
      "processing_time": 42.877695083618164,
      "citing_paper_id": "235313431",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "From the results:\n1) Our LearnDAFull outperforms all baselines and achieves the best performance (52.6%/51.9% on F1 value), outperforming the no-bert (ILP/VRC) and bert (MM/KnowDis) state-of-the-art methods by a margin of 7.9%/8.7% and 2.5%/2.1% respectively, which justifies its effectiveness.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance comparisons with other methods. The context is focused on the effectiveness of the proposed method.",
      "processing_time": 58.33996391296387,
      "citing_paper_id": "235313431",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "Next, we employ filtered causal event pairs to collect preliminary noisy labeled sentences from external documents via the DistantAnnotator of KonwDis.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to a method or tool called 'DistantAnnotator' within 'KnowDis', which is not a dataset.",
      "processing_time": 60.67384052276611,
      "citing_paper_id": "235313431",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "4) KnowDis (Zuo et al., 2020) improved the performance of ECI",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'KnowDis' which is a method or tool, not a dataset. There are no other specific datasets mentioned in the context.",
      "processing_time": 57.93344259262085,
      "citing_paper_id": "235313431",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "To make a fair comparison, we introduce causalrelated events from ConceptNet based on causal-\nrelated concepts, and obtain the causal sentence via the method in KonwDis (Zuo et al., 2020) to further re-train MM (Liu et al., 2020).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'ConceptNet' and 'KonwDis', but neither is used as a dataset. ConceptNet is a knowledge graph, and KonwDis is a method for data augmentation. No specific dataset is mentioned.",
      "processing_time": 62.129058599472046,
      "citing_paper_id": "235313431",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "Zuo et al. (2020) solved the data lacking problem of ECI with the distantly supervised labeled training data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'distantly supervised labeled training data' which is likely a dataset used for training models in the context of event causality detection. However, the name is too generic and lacks a specific identifier.",
      "processing_time": 61.428921699523926,
      "citing_paper_id": "235313431",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "4) KnowDis (Zuo et al., 2020) improved the performance of ECI with the distantly labeled training data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "distantly labeled training data"
      ],
      "dataset_descriptions": {
        "distantly labeled training data": "Used to train models for event causality detection, enhancing performance through distant supervision. The dataset provides labeled examples for improving ECI (Event Causality Identification)."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'distantly labeled training data' which is likely a dataset used for training purposes in the cited paper. However, the name 'KnowDis' is a method, not a dataset.",
      "processing_time": 69.68211364746094,
      "citing_paper_id": "235313431",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "Then, we use the CommonFilter of KnowDis assisted with causal commonsense knowledge to pick out labeled sentences that express causal semantics between events.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset names, only a method (CommonFilter of KnowDis) and a type of knowledge (causal commonsense knowledge).",
      "processing_time": 59.36346888542175,
      "citing_paper_id": "235313431",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "5) MM+ConceptAug, to make a fair comparison, we introduce causalrelated events from ConceptNet that employed by MM, and generate new sentences via KonwDis and LearnDA to further re-train MM (see Appendix C for details).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and tools. The cited paper title suggests the use of a method for data augmentation, but no specific dataset is named.",
      "processing_time": 60.20495128631592,
      "citing_paper_id": "235313431",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "Table 5 shows how different components in ProCNet contribute to performance: − Hypernetwork Hypernetwork is removed by replacing GNN-FiLM with RGCN (Schlichtkrull et al., 2018), where all proxy nodes in RGCN share the same message-passing function.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RGCN) and a model (GNN-FiLM).",
      "processing_time": 59.16306114196777,
      "citing_paper_id": "258967833",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "(13) can be computed efficiently with (Ramakrishnan et al., 1991; Bertsekas, 1981).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to algorithms and methods.",
      "processing_time": 56.77144265174866,
      "citing_paper_id": "258967833",
      "cited_paper_id": 11246193
    },
    {
      "context_text": "As the standard Hausdorff distance is highly sensitive to outliers, we use the average Hausdorff distance (Schütze et al., 2012; Taha and Hanbury, 2015): However, in our task, the average Hausdorff distance could suffer a problem that a predicted event, represented by a proxy node, may be guided to…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a performance measure. The context is about a methodological choice in evaluating event prediction.",
      "processing_time": 59.34762978553772,
      "citing_paper_id": "258967833",
      "cited_paper_id": 22130590
    },
    {
      "context_text": "Two variants of DCFEE are DCFEE-O for single-event and DCFEE-M for multi-event.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only variants of a system. The title suggests the use of training data but does not specify a dataset name.",
      "processing_time": 59.601754665374756,
      "citing_paper_id": "258967833",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Yang et al. (2018) proposed a key-event detection model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model. The title of the cited paper suggests the use of automatically labeled training data, but no specific dataset name is provided.",
      "processing_time": 60.81295824050903,
      "citing_paper_id": "258967833",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "We can observe that a simple argument completion strategy (DCFEE-O and DCFEE-M) produces the worst results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DCFEE) and its performance. The cited paper title suggests a system for document-level event extraction but does not provide a dataset name.",
      "processing_time": 43.379440784454346,
      "citing_paper_id": "258967833",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "More implementation details are in Appendix A.2 Baselines The baselines that we compare with are as follows: DCFEE (Yang et al., 2018) uses an argument-completion strategy in the table-filling task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DCFEE) and its approach. The title confirms DCFEE is a system, not a dataset.",
      "processing_time": 61.1778678894043,
      "citing_paper_id": "258967833",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Finally, Hausdorff Distance Minimization minimizes the distance between the set of predicted events and the set of ground-truth events to perform a global training in the new event-level metric space. on joint-learning of the two sub-tasks (Nguyen and Nguyen, 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the methodology used for joint-learning of entity and event extraction.",
      "processing_time": 60.35542559623718,
      "citing_paper_id": "258967833",
      "cited_paper_id": 54437926
    },
    {
      "context_text": "Much research has been done on sentence-level event extraction (Du and Cardie, 2020; Lin et al., 2020; Lu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to prior research on sentence-level event extraction.",
      "processing_time": 58.114185094833374,
      "citing_paper_id": "258967833",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Recently, multi-turn Question-Answer (QA) methods have been investigated for EE with hand-designed or automatically generated questions (Du and Cardie, 2020; Li et al., 2020; Wang et al., 2020; Liu et al., 2020; Lyu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.308268547058105,
      "citing_paper_id": "258967833",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "More recently, prompt-based learning has been explored using the knowledge in pre-trained language models (Lin et al., 2021; Hsu et al., 2021; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 60.16184663772583,
      "citing_paper_id": "258967833",
      "cited_paper_id": 237499254
    },
    {
      "context_text": "More recently, prompt-based learning has been explored using the knowledge in pre-trained language models (Lin et al., 2021; Hsu et al., 2021; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 60.16184663772583,
      "citing_paper_id": "258967833",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "To address the problem, conditional generation have been proposed, which are conditioned on pre-specified templates or prompts (Du et al., 2021; Huang et al., 2021; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 60.35849332809448,
      "citing_paper_id": "258967833",
      "cited_paper_id": 237499254
    },
    {
      "context_text": "To address the problem, conditional generation have been proposed, which are conditioned on pre-specified templates or prompts (Du et al., 2021; Huang et al., 2021; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 60.35849332809448,
      "citing_paper_id": "258967833",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Existing approaches (Zheng et al., 2019; Yang et al., 2021; Huang and Jia, 2021; Xu et al., 2021; Liang et al., 2022) usually involve two steps: (1) first model the entity interactions based on contextual representations; (2) then design a decoding strategy to decode the entity interactions into events and arguments.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to existing approaches and their methodologies. No verifiable resources are identified.",
      "processing_time": 60.355664014816284,
      "citing_paper_id": "258967833",
      "cited_paper_id": 244119148
    },
    {
      "context_text": "For ChFinAnn, the baseline results are reported in (Zheng et al., 2019; Yang et al., 2021; Xu et al., 2021; Zhu et al., 2022; Liang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers. No dataset names are provided in the context.",
      "processing_time": 59.96537756919861,
      "citing_paper_id": "258967833",
      "cited_paper_id": 245123950
    },
    {
      "context_text": "PTPCG (Zhu et al., 2022) combines event arguments together in a non-autoregressive decoding approach with pruned complete graphs, aiming to consume lower computational resources.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (PTPCG) and its purpose. The title confirms it is about a method, not a dataset.",
      "processing_time": 61.160154581069946,
      "citing_paper_id": "258967833",
      "cited_paper_id": 245123950
    },
    {
      "context_text": "For ChFinAnn, the base-line results are reported in (Zheng et al., 2019; Yang et al., 2021; Xu et al., 2021; Zhu et al., 2022; Liang et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used for document-level event extraction, serving as a benchmark for evaluating baseline models in financial document processing."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'ChFinAnn' which appears to be a dataset name. However, there is no explicit description of how the dataset is used or its specific characteristics in the given context.",
      "processing_time": 67.53110361099243,
      "citing_paper_id": "258967833",
      "cited_paper_id": 245123950
    },
    {
      "context_text": "Lu et al. (2022a) captured event clues as a series of intermediate results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for capturing event clues.",
      "processing_time": 58.48295259475708,
      "citing_paper_id": "258967833",
      "cited_paper_id": 248371142
    },
    {
      "context_text": "Apart from QA-based approaches, sequence-to-sequence learning has also been explored, where the event annotation is flattened as a sequence (Paolini et al., 2021; Lu et al., 2021; Li et al., 2021; Lu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers exploring sequence-to-sequence learning for event annotation.",
      "processing_time": 60.31957721710205,
      "citing_paper_id": "258967833",
      "cited_paper_id": 248371142
    },
    {
      "context_text": ", 2012a) for specifics of the annotation, but note here one systematic difference between our annotation and the scope of the reference ontologies: the ontologies define idealized types— canonical anatomy and physiological processes—but texts primarily refer to real-world instances that do not fill these exacting criteria (Bada and Hunter, 2011).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only ontologies and annotation practices. No verifiable resources are identified.",
      "processing_time": 39.94794583320618,
      "citing_paper_id": "13981987",
      "cited_paper_id": 164
    },
    {
      "context_text": "…here one systematic difference between our annotation and the scope of the reference ontologies: the ontologies define idealized types— canonical anatomy and physiological processes—but texts primarily refer to real-world instances that do not fill these exacting criteria (Bada and Hunter, 2011).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the differences between ontologies and real-world instances in text.",
      "processing_time": 60.30884909629822,
      "citing_paper_id": "13981987",
      "cited_paper_id": 164
    },
    {
      "context_text": "A detailed understanding of biological systems requires the ability to trace cause and effect across multiple levels of biological organization, from molecular-level reactions to cellular, tissue- and organ-level effects to organism-level outcomes (Kitano, 2002).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general overview of systems biology. No verifiable resources are identified.",
      "processing_time": 60.5684232711792,
      "citing_paper_id": "13981987",
      "cited_paper_id": 2703843
    },
    {
      "context_text": "However, event extraction resources and methods have so far focused almost exclusively on molecular-level entities and processes, limiting their applicability.",
      "catation_intent": "research work",
      "resource_type": "limitation",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general limitation in the field of event extraction resources and methods.",
      "processing_time": 60.57495045661926,
      "citing_paper_id": "13981987",
      "cited_paper_id": 2703843
    },
    {
      "context_text": ", 2009) and the dependency analyses of the GDep parser (Sagae and Tsujii, 2007).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'GDep parser' which is a tool, not a dataset. No specific datasets are mentioned in the citation context.",
      "processing_time": 61.12893748283386,
      "citing_paper_id": "13981987",
      "cited_paper_id": 2768696
    },
    {
      "context_text": "…problem, using the one-versus-rest SVM implementation of (Fan et al., 2008), with a rich feature set generated from tokens and paths in the predicate-argument structure analyses of the Enju parser (Miyao et al., 2009) and the dependency analyses of the GDep parser (Sagae and Tsujii, 2007).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and tools. The cited papers do not introduce datasets either.",
      "processing_time": 60.56845998764038,
      "citing_paper_id": "13981987",
      "cited_paper_id": 2768696
    },
    {
      "context_text": "…problem, using the one-versus-rest SVM implementation of (Fan et al., 2008), with a rich feature set generated from tokens and paths in the predicate-argument structure analyses of the Enju parser (Miyao et al., 2009) and the dependency analyses of the GDep parser (Sagae and Tsujii, 2007).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and tools. The cited papers do not introduce datasets either.",
      "processing_time": 60.56845998764038,
      "citing_paper_id": "13981987",
      "cited_paper_id": 14219803
    },
    {
      "context_text": "We refer to the supplementary documentation and these guidelines (Pyysalo et al., 2012a) for further details of the annotation scheme and the detailed definitions of all annotated types.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to supplementary documentation and annotation guidelines.",
      "processing_time": 58.45155644416809,
      "citing_paper_id": "13981987",
      "cited_paper_id": 3175781
    },
    {
      "context_text": "2Some recent tasks have considered also organisms (primarily unicellular, see e.g. Bossy et al., 2012; Pyysalo et al., 2012c), but prior event extraction efforts have not specifically targeted entities and processes between the molecular and organism levels.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general tasks and efforts in event extraction. No clear, verifiable resources are identified.",
      "processing_time": 60.73673987388611,
      "citing_paper_id": "13981987",
      "cited_paper_id": 3175781
    },
    {
      "context_text": "…structure of the Common Anatomy Reference Ontology (CARO) (Haendel et al., 2008), an organism-independent ontology of anatomy based on the human-specific Foundational Model of Anatomy (Rosse and Mejino, 2003, 2008), as outlined in our previous work on anatomical entities (Pyysalo et al., 2012b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only ontologies and previous work. The context focuses on the structure and use of ontologies, not datasets.",
      "processing_time": 61.647828578948975,
      "citing_paper_id": "13981987",
      "cited_paper_id": 3175781
    },
    {
      "context_text": "…including DNA methylation (Ohta et al., 2011a), protein modifications (Pyysalo et al., 2011) and the molecular mechanisms of infectious diseases (Pyysalo et al., 2012c); event extraction methods have been applied to automatically analyze all 20 million PubMed abstracts (Björne et al., 2010);…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of event extraction methods. The context focuses on the application of these methods to various biological processes and the analysis of PubMed abstracts.",
      "processing_time": 63.60717225074768,
      "citing_paper_id": "13981987",
      "cited_paper_id": 3175781
    },
    {
      "context_text": "We refer to the detailed annotation guidelines (Pyysalo et al., 2012a) for specifics of the annotation, but note here one systematic difference between our annotation and the scope of the reference ontologies: the ontologies define idealized types— canonical anatomy and physiological processes—but…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only annotation guidelines and reference ontologies. The context is about annotation standards and differences from idealized types in ontologies.",
      "processing_time": 63.21921348571777,
      "citing_paper_id": "13981987",
      "cited_paper_id": 3175781
    },
    {
      "context_text": "The domain involves a tissue/organ-level process that is closely associated with cancer and other organism-level pathologies and whose molecular basis is increasingly understood (Carmeliet and Jain, 2000), and domain texts thus represent a good test case for structured IE across multiple levels of biological organization.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general domain and its relevance for information extraction.",
      "processing_time": 60.263880491256714,
      "citing_paper_id": "13981987",
      "cited_paper_id": 4405580
    },
    {
      "context_text": "…process that is closely associated with cancer and other organism-level pathologies and whose molecular basis is increasingly understood (Carmeliet and Jain, 2000), and domain texts thus represent a good test case for structured IE across multiple levels of biological organization.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to domain texts which are not specific enough to be considered a dataset.",
      "processing_time": 61.82571196556091,
      "citing_paper_id": "13981987",
      "cited_paper_id": 4405580
    },
    {
      "context_text": "EventMine consists of four modules: (i) event trigger detection marks likely triggers and assigns them types, (ii) argument detection identifies likely trigger-argument pairs and assigns them roles, (iii) multi-argument event detection combines trigger-argument pairs into likely event structures…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only describes the components of the EventMine system. No dataset names are present in the text.",
      "processing_time": 62.69157814979553,
      "citing_paper_id": "13981987",
      "cited_paper_id": 5261517
    },
    {
      "context_text": "org Following initial sentence splitting and tokenization, we perform lemmatization, POS-tagging and shallow parsing using the GENIA tagger (Tsuruoka and Tsujii, 2005).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only tools and methods used for preprocessing text.",
      "processing_time": 59.90263319015503,
      "citing_paper_id": "13981987",
      "cited_paper_id": 5882669
    },
    {
      "context_text": "…(Tanabe et al., 2005), effectively matching the performance of the best available systems for the task.9\n9http://nersuite.nlplab.org\nFollowing initial sentence splitting and tokenization, we perform lemmatization, POS-tagging and shallow parsing using the GENIA tagger (Tsuruoka and Tsujii, 2005).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tools and methods. The context focuses on the use of the GENIA tagger for preprocessing steps.",
      "processing_time": 18.807039260864258,
      "citing_paper_id": "13981987",
      "cited_paper_id": 5882669
    },
    {
      "context_text": "7This annotation strategy can be viewed as partly analogous to efforts to make GO term structure explicit (Mungall et al., 2011).\nentity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to making GO term structure explicit, which is more about a method or ontology.",
      "processing_time": 62.67892265319824,
      "citing_paper_id": "13981987",
      "cited_paper_id": 6413297
    },
    {
      "context_text": "We use these annotations created by domain experts as a reference for identifying statements of interest for our annotation, which focuses on introducing structured event annotation and solidifying the ontological basis of the existing entity annotation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to annotations created by domain experts, which are used as a reference for structured event annotation.",
      "processing_time": 63.72108244895935,
      "citing_paper_id": "13981987",
      "cited_paper_id": 6446644
    },
    {
      "context_text": "For reference, the best results in the recent, widely attended BioNLP Shared Task 2011 for the same evaluation criteria were 56.0% F score for the GE task, 53.3% F score for the EPI task and 55.6% F score for the ID task (Table 4) (Kim et al., 2011b).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the BioNLP Shared Task 2011 but does not refer to a specific dataset. It is used to compare performance metrics.",
      "processing_time": 63.195146322250366,
      "citing_paper_id": "13981987",
      "cited_paper_id": 6446644
    },
    {
      "context_text": "…behind the move to richer representations for IE: more than 30 groups have introduced methods for biomedical event extraction in shared tasks (Kim et al., 2011a, b); event-annotated corpora have been introduced for many extraction targets, including DNA methylation (Ohta et al., 2011a),…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'event-annotated corpora' but does not specify any particular dataset name. The reference to 'DNA methylation' is part of a broader statement about various extraction targets, not a specific dataset.",
      "processing_time": 65.56710815429688,
      "citing_paper_id": "13981987",
      "cited_paper_id": 6446644
    },
    {
      "context_text": "For detailed definitions, we refer to (Kim et al., 2011a).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to detailed definitions in another paper.",
      "processing_time": 61.596128940582275,
      "citing_paper_id": "13981987",
      "cited_paper_id": 6446644
    },
    {
      "context_text": "EventMine outperforms the best systems participating in the original BioNLP Shared Task 2011 on the GE and ID data sets (with F scores 58.0% and 57.6%, respectively) and is competitive with the best systems on the EPI data set (Kim et al., 2011b; Miwa et al., 2012).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GE",
        "ID",
        "EPI"
      ],
      "dataset_descriptions": {
        "GE": "Used to evaluate EventMine's performance on gene expression events, demonstrating superior F scores compared to other systems.",
        "ID": "Used to assess EventMine's effectiveness in identifying interaction detection events, showing high F scores.",
        "EPI": "Used to test EventMine's capabilities in extracting protein-protein interactions, achieving competitive results."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific datasets used in the BioNLP Shared Task 2011, which are relevant to document-level event extraction.",
      "processing_time": 77.99489855766296,
      "citing_paper_id": "13981987",
      "cited_paper_id": 6446644
    },
    {
      "context_text": "EventMine outperforms the best systems participating in the original BioNLP Shared Task 2011 on the GE and ID data sets (with F scores 58.0% and 57.6%, respectively) and is competitive with the best systems on the EPI data set (Kim et al., 2011b; Miwa et al., 2012).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GE",
        "ID",
        "EPI"
      ],
      "dataset_descriptions": {
        "GE": "Used to evaluate EventMine's performance on gene expression events, demonstrating superior F scores compared to other systems.",
        "ID": "Used to assess EventMine's effectiveness in identifying interaction detection events, showing high F scores.",
        "EPI": "Used to test EventMine's capabilities in extracting protein-protein interactions, achieving competitive results."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific datasets used in the BioNLP Shared Task 2011, which are relevant to document-level event extraction.",
      "processing_time": 77.99489855766296,
      "citing_paper_id": "13981987",
      "cited_paper_id": 16250626
    },
    {
      "context_text": "For event extraction, we adapt the evaluation protocol and tools introduced in the BioNLP Shared Task 2011 (Kim et al., 2011a), including providing gold entity annotations as given for event extraction.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the BioNLP Shared Task 2011, which is a specific evaluation task, not a dataset. It does not mention a specific dataset name.",
      "processing_time": 64.76884007453918,
      "citing_paper_id": "13981987",
      "cited_paper_id": 6446644
    },
    {
      "context_text": "Contact: pyysalos@cs.man.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only supplementary information availability. The cited papers' titles suggest a focus on event extraction from literature, but no specific datasets are named in the context.",
      "processing_time": 65.35428047180176,
      "citing_paper_id": "13981987",
      "cited_paper_id": 6446644
    },
    {
      "context_text": "Contact: pyysalos@cs.man.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only supplementary information availability. The cited papers' titles suggest a focus on event extraction from literature, but no specific datasets are named in the context.",
      "processing_time": 65.35428047180176,
      "citing_paper_id": "13981987",
      "cited_paper_id": 33862651
    },
    {
      "context_text": "We refer to (Kim et al., 2011a) for a detailed presentation of the representation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a reference to a detailed presentation of a representation. The title of the cited paper suggests a shared task but does not specify a dataset.",
      "processing_time": 65.15899562835693,
      "citing_paper_id": "13981987",
      "cited_paper_id": 6446644
    },
    {
      "context_text": "We performed event extraction experiments in two settings: training only on the newly introduced data (base model) and training using stacking, incorporating predictions from a model trained on the BioNLP Shared Task 2011 GE data set (Kim et al., 2011b) as the source corpus.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "BioNLP Shared Task 2011 GE data set"
      ],
      "dataset_descriptions": {
        "BioNLP Shared Task 2011 GE data set": "Used to train a model for event extraction, specifically incorporating predictions from this dataset into a stacking approach to enhance the base model's performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'BioNLP Shared Task 2011 GE data set' which is a specific dataset used for training a model in the research.",
      "processing_time": 76.00606870651245,
      "citing_paper_id": "13981987",
      "cited_paper_id": 6446644
    },
    {
      "context_text": "…and processes involving them such as growth, remodeling and death.5\nFor anatomical entity types, we adopt a top-level division by granularity (Kumar et al., 2004) based primarily on the upperlevel structure of the Common Anatomy Reference Ontology (CARO) (Haendel et al., 2008), an…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to ontologies and granularity concepts.",
      "processing_time": 63.16804242134094,
      "citing_paper_id": "13981987",
      "cited_paper_id": 9387422
    },
    {
      "context_text": "Thus, for molecular-level entity and process types, we adopt the scope, semantics and annotation guidelines of these resources as closely as possible without compromising coverage of mentions marked as relevant by domain experts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only ontologies and annotation guidelines. No verifiable dataset names are present in the context.",
      "processing_time": 64.57897901535034,
      "citing_paper_id": "13981987",
      "cited_paper_id": 9411442
    },
    {
      "context_text": "We refer to supplementary documentation and (Miwa et al., 2012) for further details on EventMine.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a method or tool called EventMine.",
      "processing_time": 63.837143421173096,
      "citing_paper_id": "13981987",
      "cited_paper_id": 16250626
    },
    {
      "context_text": "Next, we optionally perform a matching step using dictionaries compiled from the UMLS Metathesaurus (Bodenreider, 2004), Entrez Gene (Maglott et al., 2005) and OBO Foundry (Smith et al., 2007) resources.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions resources but does not indicate they are used as datasets. They are likely used as reference dictionaries or ontologies.",
      "processing_time": 64.57820415496826,
      "citing_paper_id": "13981987",
      "cited_paper_id": 205228801
    },
    {
      "context_text": "5Although the existing corpus annotation of (Wang et al., 2011) identifies such mentions, they are typed nonspecifically, using e.g. Positive regulation to mark ‘development’ and Negative regulation for ‘[cell] death’.\ni576\n[12:52 6/8/2012 Bioinformatics-bts407.tex] Page: i577 i575–i581\nLabels in…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses corpus annotation but does not provide a name for the corpus or dataset.",
      "processing_time": 41.813114166259766,
      "citing_paper_id": "13981987",
      "cited_paper_id": 272684222
    },
    {
      "context_text": "5Although the existing corpus annotation of (Wang et al., 2011) identifies such mentions, they are typed nonspecifically, using e.g. Positive regulation to mark ‘development’ and Negative regulation for ‘[cell] death’.\ni576\n[12:52 6/8/2012 Bioinformatics-bts407.tex] Page: i577 i575–i581\nLabels in…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses corpus annotation but does not provide a name for the corpus or dataset.",
      "processing_time": 41.813114166259766,
      "citing_paper_id": "13981987",
      "cited_paper_id": null
    },
    {
      "context_text": "The corpus texts were previously annotated by Wang et al. (2011) using a typed-span representation, marking references to molecular level entities, cells, tissues and domain-relevant processes.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions a corpus that has been annotated, but does not specify a name for the corpus. The annotation details suggest it is a domain-specific dataset, but without a specific name, it cannot be included.",
      "processing_time": 67.39723229408264,
      "citing_paper_id": "13981987",
      "cited_paper_id": 272684222
    },
    {
      "context_text": "The corpus texts were previously annotated by Wang et al. (2011) using a typed-span representation, marking references to molecular level entities, cells, tissues and domain-relevant processes.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions a corpus that has been annotated, but does not specify a name for the corpus. The annotation details suggest it is a domain-specific dataset, but without a specific name, it cannot be included.",
      "processing_time": 67.39723229408264,
      "citing_paper_id": "13981987",
      "cited_paper_id": null
    },
    {
      "context_text": "The effort required to produce structured event annotation is thus broadly comparable to the initial effort by domain experts to mark text spans of interest (Wang et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to the effort required for structured event annotation.",
      "processing_time": 64.43586659431458,
      "citing_paper_id": "13981987",
      "cited_paper_id": 272684222
    },
    {
      "context_text": "The effort required to produce structured event annotation is thus broadly comparable to the initial effort by domain experts to mark text spans of interest (Wang et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to the effort required for structured event annotation.",
      "processing_time": 64.43586659431458,
      "citing_paper_id": "13981987",
      "cited_paper_id": null
    },
    {
      "context_text": "…Page: i578 i575–i581\nLabels in gray identify categories used in evaluation: events of the Anatomical category involve Organism or Anatomy entities (Table 1); Molecular involve Molecule entities; others can involve any entity type. aAnnotated also in previously introduced event extraction resources.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to categories used in evaluation and mentions previous event extraction resources without naming them.",
      "processing_time": 65.52878451347351,
      "citing_paper_id": "13981987",
      "cited_paper_id": 272684222
    },
    {
      "context_text": "…Page: i578 i575–i581\nLabels in gray identify categories used in evaluation: events of the Anatomical category involve Organism or Anatomy entities (Table 1); Molecular involve Molecule entities; others can involve any entity type. aAnnotated also in previously introduced event extraction resources.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to categories used in evaluation and mentions previous event extraction resources without naming them.",
      "processing_time": 65.52878451347351,
      "citing_paper_id": "13981987",
      "cited_paper_id": null
    },
    {
      "context_text": "We further adapt and evaluate named entity and event extraction methods for the new task, demonstrating that both can be achieved with performance broadly comparable with that for established molecular entity and event extraction tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general tasks and methods. There are no clear identifiers for datasets in the text.",
      "processing_time": 65.13267302513123,
      "citing_paper_id": "13981987",
      "cited_paper_id": null
    },
    {
      "context_text": "Further, to meet the criteria of context dependence and indicative guidance, we developed a R einforcement L earning-based Q uestion G eneration framework, RLQG to refine the generation process (Christiano et al., 2017; Rafailov et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reinforcement learning framework. The context is about developing a method, not using a dataset.",
      "processing_time": 65.52238059043884,
      "citing_paper_id": "269900068",
      "cited_paper_id": 4787508
    },
    {
      "context_text": "Recently, the paradigm of EE has shifted from conventional classification-based approaches (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016) to question-answering-based (QA-based) methods (Du and Cardie, 2020; Liu et al., 2020, 2021; Ma et al., 2022; Lu et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a shift in methodologies from classification-based to QA-based approaches in event extraction.",
      "processing_time": 65.3028073310852,
      "citing_paper_id": "269900068",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Recently, the paradigm of EE has shifted from conventional classification-based approaches (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016) to question-answering-based (QA-based) methods (Du and Cardie, 2020; Liu et al., 2020, 2021; Ma et al., 2022; Lu et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a shift in methodologies from classification-based to QA-based approaches in event extraction.",
      "processing_time": 65.3028073310852,
      "citing_paper_id": "269900068",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Recently, the paradigm of EE has shifted from conventional classification-based approaches (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016) to question-answering-based (QA-based) methods (Du and Cardie, 2020; Liu et al., 2020, 2021; Ma et al., 2022; Lu et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a shift in methodologies from classification-based to QA-based approaches in event extraction.",
      "processing_time": 65.3028073310852,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259370619
    },
    {
      "context_text": "Traditionally, methods formulate it as a classification problem (Ahn, 2006; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016), but recent meth-ods have started a QA-based paradigm.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and paradigms. There are no clear identifiers for datasets.",
      "processing_time": 65.71188426017761,
      "citing_paper_id": "269900068",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Previous research has proven the efficiency of prompt engineering (Radford et al., 2019; Liu et al., 2023); practical prompt engineering can drastically improve the efficiency and output quality of language models, making them more useful across a wide range of applications, from creative writing…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of prompt engineering and its benefits. No verifiable resources are identified.",
      "processing_time": 65.50359416007996,
      "citing_paper_id": "269900068",
      "cited_paper_id": 160025533
    },
    {
      "context_text": "We follow the step to preprocess and split the data in (Wadden et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a general reference to 'data'. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 67.94893217086792,
      "citing_paper_id": "269900068",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "According to the results, on the full ACE (Doddington et al., 2004) and RAMS (Ebner et al., 2020) benchmarks, our method outperforms previous methods by 2.69% and 1.96%.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the ACE and RAMS benchmarks, which are used to evaluate the performance of the method. However, these are benchmark suites, not specific datasets. Therefore, they are excluded.",
      "processing_time": 67.94613099098206,
      "citing_paper_id": "269900068",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We conduct our experiments on the widely used dataset ACE 2005 (Doddington et al., 2004) and RAMS (Ebner et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005",
        "RAMS"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to conduct experiments on document-level event extraction, focusing on identifying and linking events within documents.",
        "RAMS": "Used to conduct experiments on document-level event extraction, focusing on identifying and linking events within documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ACE 2005 and RAMS, which are used for conducting experiments in document-level event extraction.",
      "processing_time": 78.36140441894531,
      "citing_paper_id": "269900068",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We conduct our experiments on the widely used dataset ACE 2005 (Doddington et al., 2004) and RAMS (Ebner et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005",
        "RAMS"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to conduct experiments on document-level event extraction, focusing on identifying and linking events within documents.",
        "RAMS": "Used to conduct experiments on document-level event extraction, focusing on identifying and linking events within documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ACE 2005 and RAMS, which are used for conducting experiments in document-level event extraction.",
      "processing_time": 78.36140441894531,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259950998
    },
    {
      "context_text": "Then (Li et al., 2020) reformulate the task as multi-turn question answering, finish the trigger identification, and argument extraction by asking different questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to event extraction.",
      "processing_time": 64.26184558868408,
      "citing_paper_id": "269900068",
      "cited_paper_id": 226283533
    },
    {
      "context_text": "…practical prompt engineering can drastically improve the efficiency and output quality of language models, making them more useful across a wide range of applications, from creative writing and content generation (Zou et al., 2021) to technical problem-solving and data analysis (Chen et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only applications of language models. No dataset names are present in the citation span.",
      "processing_time": 66.05673599243164,
      "citing_paper_id": "269900068",
      "cited_paper_id": 232290492
    },
    {
      "context_text": "Specifically, in each stage (supervised fine-tuning and reinforcement learning), we utilize low-rank adaptation (LoRA) (Hu et al., 2021) as PEFT method, the trainable parameters occupy 0.0622% of full parameters.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (LoRA) for parameter-efficient fine-tuning of large language models.",
      "processing_time": 66.48841643333435,
      "citing_paper_id": "269900068",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "Nevertheless, one of the biggest challenges in QA-based EE is obtaining “good questions” to guide the QA model, and the quality of the questions often significantly affects the results.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general challenge in QA-based Event Extraction. No verifiable resources are identified.",
      "processing_time": 66.65826559066772,
      "citing_paper_id": "269900068",
      "cited_paper_id": 253265328
    },
    {
      "context_text": "Recently, (Du and Cardie, 2020) and (Lu et al., 2023) studied the effect on question quality in question answering; they trained a question generation (QG) model to generate a better question and also fine-tuned a model to do the question answering to finish the EE task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The focus is on the impact of question quality in question answering systems.",
      "processing_time": 17.615968227386475,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259370619
    },
    {
      "context_text": "To explore the performance of our model in the data-scarcity settings, we randomly choose x% number of dynamic templates (Lu et al., 2023) to fill in and use these questions as our training data.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to 'dynamic templates' which are part of a method or model, not a dataset.",
      "processing_time": 67.71236395835876,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259370619
    },
    {
      "context_text": "Considering that the best performance models are usually proprietary models, we do not train an additional QA model like in previous works (Du and Cardie, 2020; Lu et al., 2023) but directly use an off-the-shelf QA model such as LLaMA-2-13b-Chat or ChatGPT.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers do not introduce new datasets either.",
      "processing_time": 66.2666277885437,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259370619
    },
    {
      "context_text": "Considering that the best performance models are usually proprietary models, we do not train an additional QA model like in previous works (Du and Cardie, 2020; Lu et al., 2023) but directly use an off-the-shelf QA model such as LLaMA-2-13b-Chat or ChatGPT.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers do not introduce new datasets either.",
      "processing_time": 66.2666277885437,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259950998
    },
    {
      "context_text": "QGA-EE (Lu et al., 2023), which designed a dynamic template for different event type and their corresponding role, denoted as Dynamic-Q.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method called QGA-EE and a dynamic template. No verifiable datasets are referenced.",
      "processing_time": 67.01382732391357,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259370619
    },
    {
      "context_text": "To get the template question, the simple template (Du and Cardie, 2020; Liu et al., 2020) can be directly adopted, and the dynamic template (Lu et al., 2023) needs to be filled in.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or templates for event extraction.",
      "processing_time": 65.08226418495178,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259370619
    },
    {
      "context_text": "In practice, we utilize LLaMA-2 (Touvron et al., 2023) as the base model, and the learning is performed by minimizing the cross-entropy loss func-2",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (LLaMA-2) and a loss function. No verifiable datasets are referenced.",
      "processing_time": 67.70096063613892,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259950998
    },
    {
      "context_text": "3) In-context learning-based methods: These perform 0-shot and 5-shot on LLaMA-2-13b-Chat and GPT-4, respectively.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (LLaMA-2-13b-Chat and GPT-4).",
      "processing_time": 67.33164143562317,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259950998
    },
    {
      "context_text": "In our implementations of the QG module, we use LLaMA-2-7b (Touvron et al., 2023) as the base model; the learning rate is set as 5e-5, selected from the interval [1e-5, 1e-4].",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions LLaMA-2-7b as a base model but does not refer to it as a dataset. It is a model, not a dataset, and thus should not be included.",
      "processing_time": 69.19284343719482,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259950998
    },
    {
      "context_text": "For the QA model, we adopt the freeze (off-the-shelf) model in both training and testing, LLaMA-2-13b-Chat, and we also adopt a 5-shot in prompting to help the QA model’s understanding.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (LLaMA-2-13b-Chat) which is excluded according to the rules.",
      "processing_time": 68.0810055732727,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259950998
    },
    {
      "context_text": "Moreover, we also discuss the performance with some variations of the inverse prompting model (IPM): 1) Removing the SFT process that directly uses an off-the-shelf model instead (specifically, LLaMA-2-7b-Chat).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 67.17083716392517,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259950998
    },
    {
      "context_text": "As previously introduced, the base model of question generation we selected is LLaMA-2-7b; the training details are listed in We also verified our method on different model’s size and variations, as shown in",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and training details. There are no verifiable resources that meet the criteria.",
      "processing_time": 67.0021584033966,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259950998
    },
    {
      "context_text": "In section 4, we compared our method with method LLaMA-2-13b-Chat (5-shot) and GPT-4 (5-shot) .",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (LLaMA-2-13b-Chat and GPT-4).",
      "processing_time": 67.68376612663269,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259950998
    },
    {
      "context_text": "The question answering in our research are conducted under calling a freeze chat model: LLaMA-2-13b-Chat with 5-shot.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a model (LLaMA-2-13b-Chat) but does not refer to any specific dataset. The citation is used to describe the model used for question answering.",
      "processing_time": 69.4120454788208,
      "citing_paper_id": "269900068",
      "cited_paper_id": 259950998
    },
    {
      "context_text": "Fol-456 lowing (Kowsari et al., 2019), we use Precision(P),457 Recall(R) and Macro-F1 score as the evaluation458 metrics.459\nOverall Performance Table 4 shows the experi-460 mental results under the normal and cross-domain461 settings, from which we have the following ob-462\nservations: 1) Compared with TextCNN, trans- 463 former based models (BERT, ALBERT, DistillBert, 464 RoBERTa) perform better, which are pre-trained on 465 a large-scale unsupervised corpus and have more 466 background semantic knowledge to rely on.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and model performance comparisons.",
      "processing_time": 66.00783348083496,
      "citing_paper_id": "250390839",
      "cited_paper_id": 3719231
    },
    {
      "context_text": "Baselines We adopt a CNN-based method and442 various pre-trained transformer-based methods as443 our baselines, including: 1) TextCNN (Kim, 2014)444 uses different sizes CNN kernels to extract key in-445 formation in text for classification.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets.",
      "processing_time": 66.73183608055115,
      "citing_paper_id": "250390839",
      "cited_paper_id": 3719231
    },
    {
      "context_text": "Baselines We adopt a CNN-based method and 442 various pre-trained transformer-based methods as 443 our baselines, including: 1) TextCNN (Kim, 2014) 444 uses different sizes CNN kernels to extract key in445 formation in text for classification.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets.",
      "processing_time": 66.8538761138916,
      "citing_paper_id": "250390839",
      "cited_paper_id": 3719231
    },
    {
      "context_text": "Following (Hamborg et al., 2018; Hsi, 2018), we focus on main event classification, so Stage 1 is a single-label classification task.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a classification task. No verifiable resources are identified.",
      "processing_time": 66.85120701789856,
      "citing_paper_id": "250390839",
      "cited_paper_id": 3867049
    },
    {
      "context_text": "tive works are EventKG (Gottschalk and Demidova, 2018), Event Wiki (Ge et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventKG"
      ],
      "dataset_descriptions": {
        "EventKG": "Used to construct a multilingual event-centric temporal knowledge graph, focusing on integrating and representing events across multiple languages and sources."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'EventKG' and 'Event Wiki', but only 'EventKG' is a specific, verifiable dataset as indicated by the cited paper title.",
      "processing_time": 75.48475360870361,
      "citing_paper_id": "250390839",
      "cited_paper_id": 4803246
    },
    {
      "context_text": "Based on them, various superior models have been proposed to improve the sentence-level EE and have achieved great success (Orr et al., 2018; Nguyen and Grishman, 2018; Tong et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods for improving sentence-level event extraction.",
      "processing_time": 67.30603361129761,
      "citing_paper_id": "250390839",
      "cited_paper_id": 19235598
    },
    {
      "context_text": "Following Vargas-Vera and Motta (2004), we refine the initial query in BERT_QA with argument ontology knowledge obtained from Oxford dictionary (Dictionary, 1989).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BERT_QA) and a reference to the Oxford English Dictionary. The dictionary is used for obtaining argument ontology knowledge, not as a dataset.",
      "processing_time": 70.55125594139099,
      "citing_paper_id": "250390839",
      "cited_paper_id": 30370175
    },
    {
      "context_text": "The representative works are Event Logic Graph (Ding et al., 2019) and Giveme5W1H (Hamborg et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or tools. The context focuses on describing representative works in the field of event extraction.",
      "processing_time": 68.33328580856323,
      "citing_paper_id": "250390839",
      "cited_paper_id": 197544867
    },
    {
      "context_text": "5) RoBERTa (Liu et al., 2019) is built on BERT and trains with much larger mini-batches and learning rates.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and training parameters.",
      "processing_time": 66.21105766296387,
      "citing_paper_id": "250390839",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "RAMS(Ebner et al., 2020) limits the scope of the arguments in a 5-sentence window around its event trigger, which is not in line with the actual application, and the number of the argument types in RAMS is only 65, which is quite limited.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions RAMS, but it is described as a method or model rather than a dataset. No other specific datasets are mentioned.",
      "processing_time": 67.49700975418091,
      "citing_paper_id": "250390839",
      "cited_paper_id": 207853145
    },
    {
      "context_text": ", 2021) and RAMS(Ebner et al., 2020) consist of 246/9,124 documents with only 59/65 argument types, and most of the arguments in the two datasets are shared among",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to study document-level event extraction, focusing on argument linking across multiple sentences with a limited set of argument types."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions two datasets, RAMS and another unnamed dataset, which are used for document-level event extraction. The datasets are described in terms of their size and argument types.",
      "processing_time": 76.64643955230713,
      "citing_paper_id": "250390839",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "RAMS(Ebner et al., 2020) limits the scope of the arguments in a 5-sentence window around its event trigger, which is not in line with the ac-056 tual application, and the number of the argument types in RAMS is only 65, which is quite limited.",
      "catation_intent": "limitation",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions RAMS, but it is described as a method or dataset with limitations rather than a reusable resource. No other datasets are mentioned.",
      "processing_time": 68.57616019248962,
      "citing_paper_id": "250390839",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We adopt Longformer (Beltagy et al., 2020) as encoder for the (doc) baseline, and BERT-base for the other baselines.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions Longformer and BERT-base as encoders but does not refer to any specific datasets. These are models, not datasets.",
      "processing_time": 68.44084930419922,
      "citing_paper_id": "250390839",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "Following prior work (Du and Cardie, 2020b), we use Head noun phrase Match (HM) and Exact Match (EM) as two evaluation metrics.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. No datasets are referenced or used in the described context.",
      "processing_time": 67.84934902191162,
      "citing_paper_id": "250390839",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "…of NLP, including knowledge base construction (Demeester et al., 2016; Ding et al., 2018), natural language inference (Li and Srikumar, 2019), sentiment analysis (Deng and Wiebe, 2015), knowledge graph validation (Du et al., 2019) and information extraction (Wang and Pan, 2020; Zhou et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and papers. No clear identifiers for datasets are present.",
      "processing_time": 68.56015968322754,
      "citing_paper_id": "271923564",
      "cited_paper_id": 425481
    },
    {
      "context_text": "Although both LogicRE and MILR have shown promising results in enhancing DocRE, they still suffer from the error propagation issue due to their pipeline natures.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (LogicRE and MILR). The context focuses on the limitations of these methods rather than the use of datasets.",
      "processing_time": 70.16678476333618,
      "citing_paper_id": "271923564",
      "cited_paper_id": 425481
    },
    {
      "context_text": "To enhance existing DocRE models with logical rules, two rule-based frameworks have been proposed, namely LogicRE (Ru et al., 2021) and MILR (Fan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only rule-based frameworks for enhancing document-level relation extraction models.",
      "processing_time": 68.0119252204895,
      "citing_paper_id": "271923564",
      "cited_paper_id": 2949428
    },
    {
      "context_text": "To enhance existing DocRE models with logical rules, two rule-based frameworks have been proposed, namely LogicRE (Ru et al., 2021) and MILR (Fan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only rule-based frameworks for enhancing document-level relation extraction models.",
      "processing_time": 68.0119252204895,
      "citing_paper_id": "271923564",
      "cited_paper_id": 256461209
    },
    {
      "context_text": "…targets a training objective coming from relation extraction, a natural language processing (NLP) task involving texts, while previous methods only designed for specific tasks in knowledge graph completion such as link prediction (Bor-des et al., 2013) and triple classification (Lin et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and tasks. The context focuses on the comparison of training objectives and tasks in NLP and knowledge graph completion.",
      "processing_time": 69.91543531417847,
      "citing_paper_id": "271923564",
      "cited_paper_id": 2949428
    },
    {
      "context_text": "A CR is a datalog rule (Abiteboul et al., 1995) where all atoms are binary and every body atom shares variables with the previous atom and the next atom.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a definition of a datalog rule. No verifiable resources are referenced.",
      "processing_time": 68.01400947570801,
      "citing_paper_id": "271923564",
      "cited_paper_id": 5513123
    },
    {
      "context_text": "downstream applications such as question answering (QA) (Sorokin and Gurevych, 2017), knowledge graph construction (Luan et al., 2018), etc. Compared to sentence-level RE, DocRE imposes a greater challenge for modeling longer contexts and capturing the more complex interdependencies between entity…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general applications and challenges of document-level relation extraction.",
      "processing_time": 67.82177090644836,
      "citing_paper_id": "271923564",
      "cited_paper_id": 6263378
    },
    {
      "context_text": "…methods for DocRE focus on capturing interdependencies between entity pairs by learning powerful representations through neural models, such as pre-trained language models (Xu et al., 2021; Zhou et al., 2021a) and graph neural networks (Peng et al., 2017; Sahu et al., 2019; Zeng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide additional dataset information.",
      "processing_time": 69.11704778671265,
      "citing_paper_id": "271923564",
      "cited_paper_id": 184487889
    },
    {
      "context_text": "…methods for DocRE focus on capturing interdependencies between entity pairs by learning powerful representations through neural models, such as pre-trained language models (Xu et al., 2021; Zhou et al., 2021a) and graph neural networks (Peng et al., 2017; Sahu et al., 2019; Zeng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide additional dataset information.",
      "processing_time": 69.11704778671265,
      "citing_paper_id": "271923564",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "…models in different tasks of NLP, including knowledge base construction (Demeester et al., 2016; Ding et al., 2018), natural language inference (Li and Srikumar, 2019), sentiment analysis (Deng and Wiebe, 2015), knowledge graph validation (Du et al., 2019) and information extraction (Wang and…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and models. There are no clear identifiers for datasets in the text.",
      "processing_time": 69.34015941619873,
      "citing_paper_id": "271923564",
      "cited_paper_id": 189898023
    },
    {
      "context_text": "Figure 1 illustrates such an example, where sub-figure (a) in Figure 1 shows an example of a document in the DocRED dataset, and sub-figure (b) shows the corresponding predictions yielded by ATLOP, a state-of-the-art (SOTA) method for DocRE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to illustrate document-level relation extraction, specifically showing an example document and the corresponding predictions from a state-of-the-art method."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocRED dataset' as a specific dataset used to illustrate an example in the figure. The dataset is clearly identified and used for document-level relation extraction.",
      "processing_time": 50.88304281234741,
      "citing_paper_id": "271923564",
      "cited_paper_id": 225039888
    },
    {
      "context_text": "…focus on better contextualized representations of relations by employing various technologies such as attention mechanisms (Yao et al., 2019; Zhou et al., 2021a), pre-trained language models (Tang et al., 2020; Xu et al., 2021), and knowledge distillation (Tan et al., 2022a; Ma et al., 2023a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 27.273569107055664,
      "citing_paper_id": "271923564",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "For a more comprehensive comparison, we also applied JMRL to enhance the SOTA model DREEAM (Ma et al., 2023a) and compared with other SOTA methods SSAN (Xu et al., 2021), DocuNet (Zhang et al., 2021) and KD-DocRE (Tan et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing different models for document-level relation extraction.",
      "processing_time": 15.098277568817139,
      "citing_paper_id": "271923564",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "Apart from information extraction, we argue that JMRL can also benefit the field of knowledge-aware recommendations (Spillo et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context is about the potential benefits of JMRL in knowledge-aware recommendations.",
      "processing_time": 16.08269691467285,
      "citing_paper_id": "271923564",
      "cited_paper_id": 252216532
    },
    {
      "context_text": "To compare JMRL with the SOTA rule-based frameworks LogicRE (Ru et al., 2021) and MILR (Fan et al., 2022), we enhanced four base-line models, including LSTM (Yao et al., 2019), Bi-LSTM (Yao et al., 2019), GAIN (Zeng et al., 2020) and ATLOP (Zhou et al., 2021a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing different models and frameworks.",
      "processing_time": 29.055660009384155,
      "citing_paper_id": "271923564",
      "cited_paper_id": 256461209
    },
    {
      "context_text": "To capture more complex interdependencies between entity pairs, recent studies aim at enhancing DocRE models with external modules such as graph neural networks (GNNs) (Christopoulou et al., 2019; Zhang et al., 2020; Zeng et al., 2020) or rule-based frameworks (Ru et al., 2021; Fan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the use of external modules like GNNs and rule-based frameworks to enhance DocRE models.",
      "processing_time": 17.857346534729004,
      "citing_paper_id": "271923564",
      "cited_paper_id": 256461209
    },
    {
      "context_text": "Specifically, LogicRE (Ru et al., 2021) and MILR (Fan et al., 2022) are two SOTA rule-based frameworks for enhancing DocRE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions two frameworks, LogicRE and MILR, but does not refer to any specific datasets. The context is about methodologies, not datasets.",
      "processing_time": 18.24998641014099,
      "citing_paper_id": "271923564",
      "cited_paper_id": 256461209
    },
    {
      "context_text": "Based on SemEval-2010 Task 8, some new tasks about extraction were proposed [8, 13].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SemEval-2010 Task 8"
      ],
      "dataset_descriptions": {
        "SemEval-2010 Task 8": "Used as a basis for proposing new tasks in event extraction, focusing on relation classification using recurrent neural networks."
      },
      "confidence_score": 0.7,
      "reasoning": "The citation mentions SemEval-2010 Task 8, which is a known dataset for relation classification in the context of event extraction. However, the citation does not provide specific details on how this dataset is used in the current research.",
      "processing_time": 28.833784580230713,
      "citing_paper_id": "246241684",
      "cited_paper_id": 8729417
    },
    {
      "context_text": "These methods have achieved the promising performance on ACE dataset [20].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE dataset"
      ],
      "dataset_descriptions": {
        "ACE dataset": "Used to evaluate the performance of relation extraction methods, focusing on the accuracy of identifying relations in text without labeled training data."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'ACE dataset' which is a well-known dataset in the field of information extraction, particularly for event and relation extraction tasks.",
      "processing_time": 22.459599494934082,
      "citing_paper_id": "246241684",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "Event extraction (EE) [9], a crucial but challenging task which aims at identifying event mentions and extracting event triggers and arguments from various texts, plays a vital role in natural language processing (NLP) as it produces valuable structured information that can be beneficial to downstream NLP tasks, such as language understanding [16], question answering [15] and text summarization [1].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the general task of event extraction and its importance in NLP.",
      "processing_time": 25.949621200561523,
      "citing_paper_id": "246241684",
      "cited_paper_id": 11467837
    },
    {
      "context_text": "Lefever and Hoste [14] realized that if events in financial news content can be identified accurately and automatically in a timely manner, such as stock splits and mergers, it will have an extremely significant impact on the participating amount market.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the potential impact of event detection in financial news. No clear, verifiable resource is named.",
      "processing_time": 15.831427812576294,
      "citing_paper_id": "246241684",
      "cited_paper_id": 45273520
    },
    {
      "context_text": "However, existing datasets only consider financial EE in sentence-level [26].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'existing datasets' but does not specify any particular dataset name. The cited paper title suggests a focus on document-level financial event extraction, but no specific dataset is named in the citation span.",
      "processing_time": 17.838929653167725,
      "citing_paper_id": "246241684",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "• DCFEE divides the event extraction into two-stage tasks for processing.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or system called DCFEE. There are no clear identifiers for datasets.",
      "processing_time": 16.38383960723877,
      "citing_paper_id": "246241684",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Specifically, we use TIER [11], DCFEE [26] and Doc2EDAG [27] as our baselines.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions TIER, DCFEE, and Doc2EDAG as baselines. However, these are methods or systems, not datasets. The cited paper titles confirm that DCFEE and Doc2EDAG are systems for document-level event extraction.",
      "processing_time": 21.16270351409912,
      "citing_paper_id": "246241684",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Specifically, we use TIER [11], DCFEE [26] and Doc2EDAG [27] as our baselines.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions TIER, DCFEE, and Doc2EDAG as baselines. However, these are methods or systems, not datasets. The cited paper titles confirm that DCFEE and Doc2EDAG are systems for document-level event extraction.",
      "processing_time": 21.16270351409912,
      "citing_paper_id": "246241684",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "built datasets on automatically labeled training data by making use of distance supervision (DS) [26] .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'automatically labeled training data' but does not specify a named dataset. The cited paper title confirms the use of automatically labeled data but does not introduce a specific dataset name.",
      "processing_time": 18.556448221206665,
      "citing_paper_id": "246241684",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Although DCFEE uses contextual information to predict event triggers, its context-agnostic arguments completion strategy makes it unable to effectively solve the event arguments scattering problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DCFEE) and its limitations. No verifiable resources are identified.",
      "processing_time": 15.03575348854065,
      "citing_paper_id": "246241684",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Note that Doc2EDAG as a state-of-the-art model, performs much better than its counter-part on FEED, indicating the distinguishability between them.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FEED"
      ],
      "dataset_descriptions": {
        "FEED": "Used to evaluate the performance of the Doc2EDAG model on Chinese financial event extraction, focusing on document-level event detection and the distinguishability between different models."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'FEED' as a dataset used to evaluate the performance of the Doc2EDAG model. The dataset is relevant to document-level event extraction, particularly in the financial domain.",
      "processing_time": 36.78577542304993,
      "citing_paper_id": "246241684",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "added the Equity Underweight (EU) data type and utilized ten years (2008-2018) ChFinAnn4 documents and human-summarized event knowledge bases to conduct the DS-based event labeling to construct datasets [27].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn4",
        "human-summarized event knowledge bases"
      ],
      "dataset_descriptions": {
        "ChFinAnn4": "Used to construct datasets for document-level event labeling, focusing on Chinese financial documents over a decade (2008-2018).",
        "human-summarized event knowledge bases": "Utilized to provide event knowledge for DS-based event labeling, enhancing the accuracy of event extraction in financial documents."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ChFinAnn4 documents' and 'human-summarized event knowledge bases', which are specific datasets used for constructing datasets for document-level event labeling.",
      "processing_time": 32.274794816970825,
      "citing_paper_id": "246241684",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Therefore, Doc2EDAG may fail to extract such event.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a potential limitation of the Doc2EDAG framework.",
      "processing_time": 13.080477237701416,
      "citing_paper_id": "246241684",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "• Doc2EDAG uses an end-to-end method to identify event arguments at the sentence-level first.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event argument identification.",
      "processing_time": 13.95717453956604,
      "citing_paper_id": "246241684",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "We first build an event knowledge base with Fonduer, which is an open source knowledge extraction system for extracting structured information from large-scale data by combining machine learning, weakly supervised learning [6], rules and dictionaries.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions building an event knowledge base using Fonduer, but does not specify a dataset. Fonduer is a method/system, not a dataset.",
      "processing_time": 17.839895725250244,
      "citing_paper_id": "246241684",
      "cited_paper_id": 208004535
    },
    {
      "context_text": "built datasets on collected documents from financial news and announcements [23].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'built datasets on collected documents from financial news and announcements', which indicates the creation of a dataset rather than the use of an existing, named dataset.",
      "processing_time": 30.776529788970947,
      "citing_paper_id": "246241684",
      "cited_paper_id": 235681526
    },
    {
      "context_text": "We use the Li et al. (2013) systems, which identiﬁes a range of entities and events.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions using systems from Li et al. (2013) for identifying entities and events, but does not mention any specific datasets.",
      "processing_time": 16.008937120437622,
      "citing_paper_id": "14492070",
      "cited_paper_id": 2114517
    },
    {
      "context_text": ", 2015) or learning silly facts about the world, like that 〈white suites, will never go out of, style〉 (Fader et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or system for learning facts. No verifiable resources are identified.",
      "processing_time": 27.938735723495483,
      "citing_paper_id": "14492070",
      "cited_paper_id": 10318045
    },
    {
      "context_text": "…are profound, often times we as researchers apply them to somewhat trivial settings like learning about the latest Hollywood divorces (Wijaya et al., 2015) or learning silly facts about the world, like that (cid:104) white suites , will never go out of , style (cid:105) (Fader et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of research methods. The context is too vague to identify any verifiable resources.",
      "processing_time": 15.801318168640137,
      "citing_paper_id": "14492070",
      "cited_paper_id": 10318045
    },
    {
      "context_text": ", 2015), and the quality of patient care (Nakhasi et al., 2016; Ranard et al., 2016).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing the potential of Twitter as a data source for patient safety.",
      "processing_time": 15.005812644958496,
      "citing_paper_id": "14492070",
      "cited_paper_id": 15393598
    },
    {
      "context_text": "…income (Preoctiuc-Pietro et al., 2015b) to mental health (Preoctiuc-Pietro et al., 2015a; Schwartz et al., 2016; Choudhury et al., 2016), disease (Santil-lana et al., 2015; Ireland et al., 2015; Eichstaedt et al., 2015), and the quality of patient care (Nakhasi et al., 2016; Ranard et al., 2016).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research. The cited paper title does not provide additional context to identify a specific dataset.",
      "processing_time": 16.014191150665283,
      "citing_paper_id": "14492070",
      "cited_paper_id": 15393598
    },
    {
      "context_text": "…scientists measure everything from income (Preoctiuc-Pietro et al., 2015b) to mental health (Preoctiuc-Pietro et al., 2015a; Schwartz et al., 2016; Choudhury et al., 2016), disease (Santil-lana et al., 2015; Ireland et al., 2015; Eichstaedt et al., 2015), and the quality of patient care (Nakhasi…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research such as income, mental health, disease, and patient care. No specific dataset names are provided.",
      "processing_time": 30.78191065788269,
      "citing_paper_id": "14492070",
      "cited_paper_id": 15870680
    },
    {
      "context_text": "This approach has revolutionized the way we design and evaluate the effectiveness of business practices (Brynjolfsson et al., 2011; Kohavi et al., 2009), advertisements (Breese et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general references to business practices and advertisements. No clear, verifiable resources are identified.",
      "processing_time": 16.593199491500854,
      "citing_paper_id": "14492070",
      "cited_paper_id": 17165746
    },
    {
      "context_text": "This approach has revolutionized the way we design and evaluate the effectiveness of business practices (Brynjolfsson et al., 2011; Kohavi et al., 2009), advertisements (Breese et al., 1998), and political campaigns (Issenberg, 2013).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of an approach. No dataset names are present in the text.",
      "processing_time": 15.406417846679688,
      "citing_paper_id": "14492070",
      "cited_paper_id": 17165746
    },
    {
      "context_text": "In turn, we believe these NLP technologies can help overcome the data vacuum that is currently preventing productive discussion about gun violence and its possible solutions.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general lack of data. There are no multi-word proper nouns, acronyms, or other specific identifiers.",
      "processing_time": 16.842368841171265,
      "citing_paper_id": "14492070",
      "cited_paper_id": 25746868
    },
    {
      "context_text": "In turn, we believe these NLP technologies can help overcome the data vacuum that is currently preventing productive discussion about gun violence and its possible solutions.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general lack of data. There are no multi-word proper nouns, acronyms, or other specific identifiers.",
      "processing_time": 16.842368841171265,
      "citing_paper_id": "14492070",
      "cited_paper_id": null
    },
    {
      "context_text": "Gun violence causes approximately 34,000 deaths in the US every year and more than twice as many injuries (FICAP, 2006), with violence especially high among young people and racial minorities (CDC, 2013).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only statistics and general references to studies. No clear, verifiable datasets are identified.",
      "processing_time": 14.458724975585938,
      "citing_paper_id": "14492070",
      "cited_paper_id": 25993641
    },
    {
      "context_text": "Gun violence causes approximately 34,000 deaths in the US every year and more than twice as many injuries (FICAP, 2006), with violence especially high among young people and racial minorities (CDC, 2013).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only statistics and general references to studies. No clear, verifiable datasets are identified.",
      "processing_time": 14.458724975585938,
      "citing_paper_id": "14492070",
      "cited_paper_id": null
    },
    {
      "context_text": ", 1993) and in the worst case, actively blocked by federal legislation (Kassirer, 1995; Frankel, 2015; Bertrand, 2015).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only references federal legislation and studies, which do not qualify as verifiable resources under the given criteria.",
      "processing_time": 30.13245916366577,
      "citing_paper_id": "14492070",
      "cited_paper_id": null
    },
    {
      "context_text": "Several projects collect data about gun violence via newspaper teams (Boyle, 2013; Swaine et al., 2015) or volunteer crowds (Burghart, 2014; Wagner, 2014; Kirk and Kois, 2013).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions data collection efforts but does not specify any named, verifiable datasets. It refers to general data collection methods rather than specific datasets.",
      "processing_time": 17.171733379364014,
      "citing_paper_id": "14492070",
      "cited_paper_id": null
    },
    {
      "context_text": "Several projects collect data about gun violence via newspaper teams (Boyle, 2013; Swaine et al., 2015) or volunteer crowds (Burghart, 2014; Wagner, 2014; Kirk and Kois, 2013).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions data collection efforts but does not specify any named, verifiable datasets. It refers to general data collection methods rather than specific datasets.",
      "processing_time": 17.171733379364014,
      "citing_paper_id": "14492070",
      "cited_paper_id": null
    },
    {
      "context_text": "Several projects collect data about gun violence via newspaper teams (Boyle, 2013; Swaine et al., 2015) or volunteer crowds (Burghart, 2014; Wagner, 2014; Kirk and Kois, 2013).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions data collection efforts but does not specify any named, verifiable datasets. It refers to general data collection methods rather than specific datasets.",
      "processing_time": 17.171733379364014,
      "citing_paper_id": "14492070",
      "cited_paper_id": null
    },
    {
      "context_text": "Several projects collect data about gun violence via newspaper teams (Boyle, 2013; Swaine et al., 2015) or volunteer crowds (Burghart, 2014; Wagner, 2014; Kirk and Kois, 2013).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions data collection efforts but does not specify any named, verifiable datasets. It refers to general data collection methods rather than specific datasets.",
      "processing_time": 17.171733379364014,
      "citing_paper_id": "14492070",
      "cited_paper_id": null
    },
    {
      "context_text": "Without locally-aggregated data, it is impossible to conduct meaningful studies of how ﬁrearm injury varies by community, a key step toward designing good policies for prevention (FICAP, 2006).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'FICAP, 2006' which appears to be a report or publication rather than a dataset. No specific dataset is mentioned.",
      "processing_time": 17.752355575561523,
      "citing_paper_id": "14492070",
      "cited_paper_id": null
    },
    {
      "context_text": "The input data to QA systems is usually text, such as a full article including headline, lead paragraph, and main text [30], or a single sentence, e.g., in news ticker format [36].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes the types of text inputs used in QA systems, which are not specific datasets.",
      "processing_time": 42.39369606971741,
      "citing_paper_id": "3867049",
      "cited_paper_id": 781199
    },
    {
      "context_text": "The input data to QA systems is usually text, such as a full article including headline, lead paragraph, and main text [30], or a single sentence, e.g., in news ticker format [36].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes the types of text inputs used in QA systems, which are not specific datasets.",
      "processing_time": 42.39369606971741,
      "citing_paper_id": "3867049",
      "cited_paper_id": 212495816
    },
    {
      "context_text": "Others approaches use SRL to identify the agent (“who”) performing the action (“what”) and location-and temporal information (“where” and “when”) [36].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach using SRL. No verifiable resources are identified.",
      "processing_time": 29.19275665283203,
      "citing_paper_id": "3867049",
      "cited_paper_id": 781199
    },
    {
      "context_text": "While the evaluations of the reviewed papers generally indicate sufficient quality to be usable for news event extraction, e.g., the system from [36] achieved F ’ =0.85 on the Darpa corpus from 2009, they lack comparability for two reasons: (1) There is no gold standard for journalistic 5W QA on…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Darpa corpus from 2009"
      ],
      "dataset_descriptions": {
        "Darpa corpus from 2009": "Used to evaluate a system's performance in news event extraction, specifically measuring F-score to assess the system's accuracy and robustness."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions the 'Darpa corpus from 2009' as a dataset used for evaluating a system's performance in news event extraction. The dataset is specific and has a clear identifier.",
      "processing_time": 25.5711932182312,
      "citing_paper_id": "3867049",
      "cited_paper_id": 781199
    },
    {
      "context_text": "Approaches of the third category extract explicit event descriptors but are not publicly available [29, 34–36].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to approaches that are not publicly available.",
      "processing_time": 14.140522003173828,
      "citing_paper_id": "3867049",
      "cited_paper_id": 781199
    },
    {
      "context_text": "Approaches of the third category extract explicit event descriptors but are not publicly available [29, 34–36].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to approaches that are not publicly available.",
      "processing_time": 14.140522003173828,
      "citing_paper_id": "3867049",
      "cited_paper_id": 18987345
    },
    {
      "context_text": "More complex methods are discussed in various linguistic publications, and involve supervised ML [19, 36].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and publications.",
      "processing_time": 12.711498975753784,
      "citing_paper_id": "3867049",
      "cited_paper_id": 781199
    },
    {
      "context_text": "The best system in [36] achieves a precision of 0.89, which is 0.19 higher than our MAgP and surprisingly even better than the ICR of our assessors.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 16.569263458251953,
      "citing_paper_id": "3867049",
      "cited_paper_id": 781199
    },
    {
      "context_text": "Therefore, we look for NE classified as a location, date, time, or a combined datetime (cf. [36]).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only types of named entities. There are no clear identifiers for datasets in the given context.",
      "processing_time": 15.348431587219238,
      "citing_paper_id": "3867049",
      "cited_paper_id": 781199
    },
    {
      "context_text": "…event extraction, e.g., the system from [36] achieved F ’ =0.85 on the Darpa corpus from 2009, they lack comparability for two reasons: (1) There is no gold standard for journalistic 5W QA on news; even worse, evaluation data sets of previous papers are no longer available publicly [29, 35, 36].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Darpa corpus from 2009"
      ],
      "dataset_descriptions": {
        "Darpa corpus from 2009": "Used to evaluate event extraction systems, specifically focusing on performance metrics like F-score. The dataset is noted for its historical significance but lacks current public availability."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions 'Darpa corpus from 2009' as a dataset used for event extraction. However, it also notes that the evaluation datasets from previous papers are no longer publicly available, which affects the comparability of results.",
      "processing_time": 27.69897961616516,
      "citing_paper_id": "3867049",
      "cited_paper_id": 781199
    },
    {
      "context_text": "…the performance of Giveme5W with other systems is not straightforward for several reasons: other systems were tested on non-disclosed datasets [29, 35, 36], were translated from other languages [29], or used different evaluation measures, such as error rates [35] or binary relevance assessments…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to non-disclosed datasets, which are not identifiable.",
      "processing_time": 15.365005493164062,
      "citing_paper_id": "3867049",
      "cited_paper_id": 781199
    },
    {
      "context_text": "Yaman et al. use three independent subsystems to extract 5W answers [36].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for extracting 5W answers using three independent subsystems.",
      "processing_time": 14.125036716461182,
      "citing_paper_id": "3867049",
      "cited_paper_id": 781199
    },
    {
      "context_text": "…systems were tested on non-disclosed datasets [29, 35, 36], were translated from other languages [29], or used different evaluation measures, such as error rates [35] or binary relevance assessments [36], which are both not optimal because of the non-binary relevance of 5W answers (cf. [ 20]).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It refers to non-disclosed datasets and different evaluation measures, which do not meet the criteria for inclusion.",
      "processing_time": 17.73933696746826,
      "citing_paper_id": "3867049",
      "cited_paper_id": 4192580
    },
    {
      "context_text": "Table 1 shows the mean average generalized precision (MAgP), a precision score suitable in multi-graded relevance assessments [20].",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (MAgP) which is not a dataset. The context is about evaluating information retrieval systems using a specific metric.",
      "processing_time": 18.135620594024658,
      "citing_paper_id": "3867049",
      "cited_paper_id": 4192580
    },
    {
      "context_text": "Though main event extraction from news is a fundamental task in news analysis [16, 27], no method is publicly available that extracts explicit descriptors of the main event.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general statement about the lack of methods for extracting explicit descriptors of main events from news.",
      "processing_time": 16.538554906845093,
      "citing_paper_id": "3867049",
      "cited_paper_id": 5171778
    },
    {
      "context_text": "Though main event extraction from news is a fundamental task in news analysis [16, 27], no method is publicly available that extracts explicit descriptors of the main event.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general statement about the lack of methods for extracting explicit descriptors of main events from news.",
      "processing_time": 16.538554906845093,
      "citing_paper_id": "3867049",
      "cited_paper_id": 31271854
    },
    {
      "context_text": "Some approaches afterward compute cluster labels that describe what is common to the group of related articles, typically the shared event or topic [2, 16, 27].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods for computing cluster labels in news articles.",
      "processing_time": 13.661426305770874,
      "citing_paper_id": "3867049",
      "cited_paper_id": 5171778
    },
    {
      "context_text": "Some approaches afterward compute cluster labels that describe what is common to the group of related articles, typically the shared event or topic [2, 16, 27].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods for computing cluster labels in news articles.",
      "processing_time": 13.661426305770874,
      "citing_paper_id": "3867049",
      "cited_paper_id": 31271854
    },
    {
      "context_text": "Giveme5W integrates with the news crawler and extractor news-please [17].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'news-please' as a tool used for crawling and extracting news, which is not a dataset but a method or tool.",
      "processing_time": 15.947641611099243,
      "citing_paper_id": "3867049",
      "cited_paper_id": 5830937
    },
    {
      "context_text": "The applied methods range from simple approaches, e.g., looking for explicit markers of causal relations [21], such as “because”, to complex approaches, e.g., training machine learning (ML) methods on annotated corpora [4].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'annotated corpora' but does not specify a particular dataset name. The cited papers do not provide additional specific dataset names.",
      "processing_time": 29.167041778564453,
      "citing_paper_id": "3867049",
      "cited_paper_id": 12259931
    },
    {
      "context_text": "The applied methods range from simple approaches, e.g., looking for explicit markers of causal relations [21], such as “because”, to complex approaches, e.g., training machine learning (ML) methods on annotated corpora [4].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'annotated corpora' but does not specify a particular dataset name. The cited papers do not provide additional specific dataset names.",
      "processing_time": 29.167041778564453,
      "citing_paper_id": "3867049",
      "cited_paper_id": 62757908
    },
    {
      "context_text": "The clear majority of research has focused on explicit causal relations, while only few approaches address implicit causal relations, which also achieve lower precision than methods for explicit causes [6].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about research focus.",
      "processing_time": 12.995052814483643,
      "citing_paper_id": "3867049",
      "cited_paper_id": 14821809
    },
    {
      "context_text": "News summarization extracts an article’s main event to enable users to quickly see what multiple articles are reporting on [16, 25].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the general concept of news summarization. No verifiable resources are identified.",
      "processing_time": 15.339656114578247,
      "citing_paper_id": "3867049",
      "cited_paper_id": 15433021
    },
    {
      "context_text": "News summarization extracts an article’s main event to enable users to quickly see what multiple articles are reporting on [16, 25].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the general concept of news summarization. No verifiable resources are identified.",
      "processing_time": 15.339656114578247,
      "citing_paper_id": "3867049",
      "cited_paper_id": 31271854
    },
    {
      "context_text": "(2) Previous papers use different quality measures, such as precision and recall [11] or error rates [35].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only quality measures. There are no verifiable resources or datasets mentioned.",
      "processing_time": 13.638783693313599,
      "citing_paper_id": "3867049",
      "cited_paper_id": 18064820
    },
    {
      "context_text": "Systems for 5W QA on news texts typically perform three tasks to determine the article’s main event: (1) pre-processing , (2) phrase extraction , and (3) candidate scoring [34, 35].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tasks and processes involved in 5W QA systems.",
      "processing_time": 15.36894178390503,
      "citing_paper_id": "3867049",
      "cited_paper_id": 18987345
    },
    {
      "context_text": "We also plan to add an extractor for “how”-phrases (cf. [30, 34]).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a plan to add an extractor for 'how'-phrases. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 18.80163311958313,
      "citing_paper_id": "3867049",
      "cited_paper_id": 18987345
    },
    {
      "context_text": "We also plan to add an extractor for “how”-phrases (cf. [30, 34]).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a plan to add an extractor for 'how'-phrases. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 18.80163311958313,
      "citing_paper_id": "3867049",
      "cited_paper_id": 212495816
    },
    {
      "context_text": "Most systems use manually created linguistic rules to extract phrase candidates from the preprocessed text [21, 30, 35].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods for extracting phrase candidates using linguistic rules.",
      "processing_time": 14.089723825454712,
      "citing_paper_id": "3867049",
      "cited_paper_id": 62757908
    },
    {
      "context_text": "Most systems use manually created linguistic rules to extract phrase candidates from the preprocessed text [21, 30, 35].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods for extracting phrase candidates using linguistic rules.",
      "processing_time": 14.089723825454712,
      "citing_paper_id": "3867049",
      "cited_paper_id": 212495816
    },
    {
      "context_text": "We then check if a pattern contains an action verb, such as “allow” or “result”, by using the list of verbs from [21].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method involving a list of verbs. No verifiable resource is identified.",
      "processing_time": 15.325475215911865,
      "citing_paper_id": "3867049",
      "cited_paper_id": 62757908
    },
    {
      "context_text": "𝑠 23X (𝑐) = 𝑤 9 KLM(N) K + 𝑤 ’ CT(𝑐) , where 𝑤 9 = 𝑤 ’ = 1 , and TC(𝑐) = 1 if 𝑐 is a bi-clausal phrase, 0.6 if it starts with a causal RB, and 0.3 else (cf. [21, 22]).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or formulas. No verifiable resources are identified.",
      "processing_time": 15.323005676269531,
      "citing_paper_id": "3867049",
      "cited_paper_id": 62757908
    },
    {
      "context_text": "The second category of approaches is highly specialized on task-specific event properties, such as the number of dead or injured people for crisis monitoring [32] or the number of protestors in demonstrations [26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to task-specific event properties in crisis monitoring and protests, which are not datasets.",
      "processing_time": 17.338433027267456,
      "citing_paper_id": "3867049",
      "cited_paper_id": 67426382
    },
    {
      "context_text": "The second category of approaches is highly specialized on task-specific event properties, such as the number of dead or injured people for crisis monitoring [32] or the number of protestors in demonstrations [26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to task-specific event properties in crisis monitoring and protests, which are not datasets.",
      "processing_time": 17.338433027267456,
      "citing_paper_id": "3867049",
      "cited_paper_id": 143514109
    },
    {
      "context_text": ", they find groups of textually similar articles by employing topic modeling or other clustering methods [32].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to general methods for finding groups of textually similar articles.",
      "processing_time": 14.632736444473267,
      "citing_paper_id": "3867049",
      "cited_paper_id": 67426382
    },
    {
      "context_text": "The preprocessing task (1) performs sentence splitting, tokenizes them, and often applies further NLP methods, including part-of-speech (POS) tagging, coreference resolution [30], NER [12], parsing [24], or semantic role labeling (SRL) [8].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only NLP methods and tasks. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 17.079663038253784,
      "citing_paper_id": "3867049",
      "cited_paper_id": 115386587
    },
    {
      "context_text": "The preprocessing task (1) performs sentence splitting, tokenizes them, and often applies further NLP methods, including part-of-speech (POS) tagging, coreference resolution [30], NER [12], parsing [24], or semantic role labeling (SRL) [8].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only NLP methods and tasks. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 17.079663038253784,
      "citing_paper_id": "3867049",
      "cited_paper_id": 212495816
    },
    {
      "context_text": "Other disciplines also analyze the events of articles, e.g., in so called frame analyses researchers from the social sciences identify how media reports on certain events [31].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It refers to a general method (frame analyses) used in social sciences to study media reporting.",
      "processing_time": 16.238602876663208,
      "citing_paper_id": "3867049",
      "cited_paper_id": 168048982
    },
    {
      "context_text": "Typical heuristics include: shortness of a candidate, as longer candidates may contain too many irrelevant details [30], “who” candidates that contain an NE, and active speech [35].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general heuristics for event extraction. No clear identifiers for datasets are present.",
      "processing_time": 14.88549518585205,
      "citing_paper_id": "3867049",
      "cited_paper_id": 212495816
    },
    {
      "context_text": "First, we look for any NE that was identified as a person or organization during preprocessing (cf. [ 12, 30]).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to named entities (NE) identified as persons or organizations. No clear dataset names are provided.",
      "processing_time": 15.906450510025024,
      "citing_paper_id": "3867049",
      "cited_paper_id": 212495816
    },
    {
      "context_text": "We also add a sentence’s first NP to the list if it contains any noun (NN*) 1 or personal pronoun (PRP) (cf. [ 30]).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The cited paper title suggests a focus on news event extraction, but no specific dataset is named in the citation context.",
      "processing_time": 19.690509796142578,
      "citing_paper_id": "3867049",
      "cited_paper_id": 212495816
    },
    {
      "context_text": "Noun phrases (NP) yield candidates for “who”, while sibling verb phrases (VP) are candidates for “what” [30].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction. No verifiable resources are identified.",
      "processing_time": 14.063784122467041,
      "citing_paper_id": "3867049",
      "cited_paper_id": 212495816
    },
    {
      "context_text": "The resulting scoring formula is 𝑠 234 (𝑐) = 𝑤 9 (𝑑 − 𝑝(𝑐)) + 𝑤 ’ 𝑓(𝑐) + 𝑤 > NE(𝑐) , where the weights 𝑤 9 = 𝑤 ’ = 𝑤 > = 1 (cf. [30, 35]), 𝑑 the document length measured in sentences, 𝑝(𝑐) the position measured in sentences of candidate 𝑐 within the document, 𝑓(𝑐) the frequency…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a scoring formula and its components. The cited paper title suggests event extraction but does not introduce a dataset.",
      "processing_time": 18.77019953727722,
      "citing_paper_id": "3867049",
      "cited_paper_id": 212495816
    },
    {
      "context_text": "[1] with title (bold), lead paragraph (italic), and first of remaining paragraphs.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to 'document-level event extraction'. No verifiable resources are identified.",
      "processing_time": 15.294185400009155,
      "citing_paper_id": "3867049",
      "cited_paper_id": null
    },
    {
      "context_text": "1 shows an excerpt of an article reporting on a terrorist attack in Afghanistan [1].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to an article about a terrorist attack. No verifiable resources are identified.",
      "processing_time": 14.597933292388916,
      "citing_paper_id": "3867049",
      "cited_paper_id": null
    },
    {
      "context_text": "For instance, news aggregators, such as Google News, must identify the main event to cluster related articles, i.e., articles reporting on the same event [5, 15].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general application scenario for event identification in news articles.",
      "processing_time": 12.78055739402771,
      "citing_paper_id": "3867049",
      "cited_paper_id": null
    },
    {
      "context_text": "We employ the one-layer BiLSTM (Hochreiter and Schmidhuber, 1997) as Enc θ and Enc δ .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BiLSTM).",
      "processing_time": 39.79220724105835,
      "citing_paper_id": "235313618",
      "cited_paper_id": 1915014
    },
    {
      "context_text": "The size of the space in the contrastive transfer module and the hidden layer of BiLSTM are both set as 50.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model architecture details.",
      "processing_time": 12.469459056854248,
      "citing_paper_id": "235313618",
      "cited_paper_id": 1915014
    },
    {
      "context_text": "3.1), we choose the BiLSTM as an encoder in SelfRL that could be initialized completely independently.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BiLSTM). The cited paper title 'Long Short-Term Memory' is a method, not a dataset.",
      "processing_time": 17.662301063537598,
      "citing_paper_id": "235313618",
      "cited_paper_id": 1915014
    },
    {
      "context_text": "3) Comparing Enc θ − freeze + Sel-fRL with Enc θ − finetune + SelfRL, we ﬁnd that the causal representations encoded by pre-trained BERT and BiLSTM have similar effects.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (BERT and BiLSTM). The citation is focused on comparing the effects of causal representations encoded by these models.",
      "processing_time": 17.65946388244629,
      "citing_paper_id": "235313618",
      "cited_paper_id": 1915014
    },
    {
      "context_text": "…to now, identifying the causality implied in the text has at-tracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works. The cited papers also do not provide clear evidence of dataset usage.",
      "processing_time": 16.204084396362305,
      "citing_paper_id": "235313618",
      "cited_paper_id": 3030259
    },
    {
      "context_text": "…to now, identifying the causality implied in the text has at-tracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works. The cited papers also do not provide clear evidence of dataset usage.",
      "processing_time": 16.204084396362305,
      "citing_paper_id": "235313618",
      "cited_paper_id": 9130816
    },
    {
      "context_text": "…to now, identifying the causality implied in the text has at-tracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and Walker, 2017b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works. The cited papers also do not provide clear evidence of dataset usage.",
      "processing_time": 16.204084396362305,
      "citing_paper_id": "235313618",
      "cited_paper_id": 15125226
    },
    {
      "context_text": "Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TempEval-3 Corpus"
      ],
      "dataset_descriptions": {
        "TempEval-3 Corpus": "Used to annotate causal relations in texts, focusing on event temporal relations using a rule-based multi-sieve approach."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'TempEval-3 Corpus' which is a specific dataset used for temporal and causal relation annotation. No other datasets are mentioned.",
      "processing_time": 23.125508546829224,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TempEval-3 Corpus"
      ],
      "dataset_descriptions": {
        "TempEval-3 Corpus": "Used to annotate causal relations in texts, focusing on event temporal relations using a rule-based multi-sieve approach."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'TempEval-3 Corpus' which is a specific dataset used for temporal and causal relation annotation. No other datasets are mentioned.",
      "processing_time": 23.125508546829224,
      "citing_paper_id": "235313618",
      "cited_paper_id": 14877527
    },
    {
      "context_text": "Speciﬁcally, CauSeRL outperforms the no-bert (ILP/VerR-C) and bert (MasG/KnowDis) baseline methods by a margin of 7.4%/10.0% and 2.0%/3.4% on two benchmarks respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'benchmarks' but does not specify any dataset names. The cited paper title suggests the use of the TempEval-3 corpus, but the citation itself does not confirm this.",
      "processing_time": 19.644323348999023,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "…55.8 44.7 BERT 36.0 56.8 44.1 KnowDis (Zuo et al., 2020) 39.7 66.5 49.7 MasG (Liu et al., 2020) 41.9 62.5 41.9 69.0 52.1 * Causal-TimeBank Rule-B (Mirza and Tonelli, 2014) 36.8 12.3 18.4 Data-D (Mirza and Tonelli, 2014) 67.3 22.6 33.9 VerR-C (Mirza, 2014) 69.0 31.5 43.2 BERT 39.5 44.5 41.9 MasG…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank",
        "Data-D"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate causality annotation in the TempEval-3 corpus, focusing on identifying causal relations in text.",
        "Data-D": "Used to evaluate causality detection, specifically comparing performance against other datasets and models."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions several datasets and methods, but only 'Causal-TimeBank' and 'Data-D' are clearly identified as datasets used for evaluation. Other entries like 'KnowDis', 'MasG', and 'BERT' are either methods or models.",
      "processing_time": 31.114176988601685,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "Mirza and Tonelli (2014) annotated the Causal-TimeBank of event causal relations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to annotate event causal relations, focusing on identifying and labeling causal connections between events in text."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions the annotation of the Causal-TimeBank, which is a specific dataset used for event causal relation annotation.",
      "processing_time": 21.597935914993286,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "For ESC, we prefer 1) S-Path (Cheng and Miyao, 2017), a dependency path based sequential method 2 https://github.com/google-research/ bert Methods P R F1 EventStoryLine S-Path (Cheng and Miyao, 2017) 34.0 41.5 37.4 S-Fea (Choubey and Huang, 2017) 32.7 44.9 37.8 LR+ (Gao et al., 2019) 37.0 45.2 40.7 ILP (Gao et al., 2019) 37.4 55.8 44.7 BERT 36.0 56.8 44.1 KnowDis (Zuo et al., 2020) 39.7 66.5 49.7 MasG (Liu et al., 2020) 41.9 62.5 41.9 69.0 52.1 * Causal-TimeBank Rule-B (Mirza and Tonelli, 2014) 36.8 12.3 18.4 Data-D (Mirza and Tonelli, 2014) 67.3 22.6 33.9 VerR-C (Mirza, 2014) 69.0 31.5 43.2 BERT 39.5 44.5 41.9 MasG (Liu et al., 2020) 36.6 55.6 44.1 KnowDis (Zuo et al., 2020) 42 that models the context between events to identify causality; 2) S-Fea (Choubey and Huang, 2017), a sequence model explores complex human designed features for ECI; 3) LR+ and ILP (Gao et al., 2019), document-level models adopt document structures for ECI.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models but does not explicitly refer to any datasets. The names mentioned are primarily models or methods used for event causality identification.",
      "processing_time": 17.642884969711304,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "…al., 2020) 39.7 66.5 49.7 MasG (Liu et al., 2020) 41.9 62.5 41.9 69.0 52.1 * Causal-TimeBank Rule-B (Mirza and Tonelli, 2014) 36.8 12.3 18.4 Data-D (Mirza and Tonelli, 2014) 67.3 22.6 33.9 VerR-C (Mirza, 2014) 69.0 31.5 43.2 BERT 39.5 44.5 41.9 MasG (Liu et al., 2020) 36.6 55.6 44.1 KnowDis (Zuo…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank",
        "Data-D"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate causality annotation systems, focusing on precision, recall, and F1 scores for identifying causal relations in text.",
        "Data-D": "Used to evaluate causality annotation systems, focusing on precision, recall, and F1 scores for identifying causal relations in text."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions 'Causal-TimeBank' and 'Data-D', which are likely datasets used for evaluating causality annotation systems. The context suggests these datasets are used for performance comparison.",
      "processing_time": 30.889567136764526,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "These models are designed by Mirza and Tonelli (2014; 2014) for ECI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models designed for ECI. The cited paper title 'Annotating Causality in the TempEval-3 Corpus' suggests a corpus, but it is not mentioned in the citation context.",
      "processing_time": 21.20162868499756,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "…41.9 62.5 41.9 69.0 52.1 * Causal-TimeBank Rule-B (Mirza and Tonelli, 2014) 36.8 12.3 18.4 Data-D (Mirza and Tonelli, 2014) 67.3 22.6 33.9 VerR-C (Mirza, 2014) 69.0 31.5 43.2 BERT 39.5 44.5 41.9 MasG (Liu et al., 2020) 36.6 55.6 44.1 KnowDis (Zuo et al., 2020) 42 that models the context between…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank",
        "Data-D"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate causality annotation models, focusing on identifying causal relations in text. The dataset is part of the TempEval-3 corpus and is used for benchmarking performance.",
        "Data-D": "Used to evaluate causality annotation models, focusing on identifying causal relations in text. The dataset is part of the TempEval-3 corpus and is used for benchmarking performance."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'Causal-TimeBank' and 'Data-D', which are likely datasets used for evaluating causality annotation models. However, 'VerR-C' and 'MasG' do not appear to be datasets based on the context.",
      "processing_time": 35.79938578605652,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "6) It is worth noting that the improvement on the CTB is higher than that of the ESC, because the amount of labeled data of the former is relatively small, and more need for the help of exter-nal causal statements.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'CTB' and 'ESC', which could be datasets, but they are not clearly identified as such. The citation does not provide enough information to confirm their nature as datasets.",
      "processing_time": 19.80517554283142,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "For CTB, we prefer 1) Rule-B , a rule-based sys-tem; 2) Data-D , a data driven machine learning based system; 3) VerR-C , a verb rule based model with data ﬁltering and causal signals enhancement.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions systems and models (Rule-B, Data-D, VerR-C) but does not reference any specific datasets. The context is about system preferences for annotation tasks, not dataset usage.",
      "processing_time": 20.093700170516968,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "9 (ESC) (Caselli and Vossen, 2017) described above; and (2) Causal-TimeBank (CTB) (Mirza and Tonelli, 2014) which contains 184 documents, 6813 events, and 318 causal event pairs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ESC",
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "ESC": "Used for event extraction and causality annotation, containing annotated documents with events and causal relationships.",
        "Causal-TimeBank": "Used for event extraction and causality annotation, containing 184 documents, 6813 events, and 318 causal event pairs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ESC and Causal-TimeBank, both of which are used for event extraction and causality annotation.",
      "processing_time": 28.12986135482788,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "We conduct 5-fold and 10-fold cross-validation on ESC and CTB respectively, same as previous methods.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ESC",
        "CTB"
      ],
      "dataset_descriptions": {
        "ESC": "Used for 5-fold cross-validation in event extraction experiments, focusing on the robustness of the model across different folds.",
        "CTB": "Used for 10-fold cross-validation in event extraction experiments, focusing on the robustness of the model across different folds."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'ESC' and 'CTB', which are likely datasets used for cross-validation. However, without additional context, it is unclear if these are specific, verifiable datasets or generic placeholders.",
      "processing_time": 30.575708866119385,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "From the results: 1) Our CauSeRL outperforms all baseline meth-ods and achieves the best performance on F1 value, 52.1% on ESC and 53.2% on CTB respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ESC",
        "CTB"
      ],
      "dataset_descriptions": {
        "ESC": "Used to evaluate the performance of CauSeRL on causality detection, achieving an F1 score of 52.1%. The dataset focuses on event causality in text.",
        "CTB": "Used to evaluate the performance of CauSeRL on causality detection, achieving an F1 score of 53.2%. The dataset focuses on event causality in Chinese text."
      },
      "confidence_score": 0.7,
      "reasoning": "The citation mentions 'ESC' and 'CTB', which are likely datasets used for evaluation, but the context does not provide enough detail to confirm their full names or specific usage.",
      "processing_time": 34.16666579246521,
      "citing_paper_id": "235313618",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "Event causality identiﬁcation (ECI) aims to identify causal relations between events in texts, which can provide crucial clues for deep textual understanding (Girju, 2003; Oh et al., 2013, 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of event causality identification. No verifiable resources are named.",
      "processing_time": 16.67803454399109,
      "citing_paper_id": "235313618",
      "cited_paper_id": 8192267
    },
    {
      "context_text": "Caselli and Vossen (2017) annotated the EventStoryLine Corpus for event causality identiﬁcation in 320 short stories based on the temporal and causal relations annotated dataset (Mostafazadeh et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine Corpus",
        "temporal and causal relations annotated dataset"
      ],
      "dataset_descriptions": {
        "EventStoryLine Corpus": "Annotated for event causality identification in 320 short stories, focusing on temporal and causal relations.",
        "temporal and causal relations annotated dataset": "Used as a basis for annotating the EventStoryLine Corpus, providing temporal and causal relation annotations."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions the 'EventStoryLine Corpus' and 'temporal and causal relations annotated dataset'. Both are specific datasets used for annotation and research.",
      "processing_time": 28.136056661605835,
      "citing_paper_id": "235313618",
      "cited_paper_id": 8387007
    },
    {
      "context_text": "To date, most existing methods regard this task as a classiﬁcation problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation context does not mention any specific datasets by name. It only refers to annotated data used for training ECI models, which is too generic.",
      "processing_time": 18.67844009399414,
      "citing_paper_id": "235313618",
      "cited_paper_id": 9130816
    },
    {
      "context_text": "To date, most existing methods regard this task as a classiﬁcation problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation context does not mention any specific datasets by name. It only refers to annotated data used for training ECI models, which is too generic.",
      "processing_time": 18.67844009399414,
      "citing_paper_id": "235313618",
      "cited_paper_id": 14877527
    },
    {
      "context_text": "To date, most existing methods regard this task as a classiﬁcation problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation context does not mention any specific datasets by name. It only refers to annotated data used for training ECI models, which is too generic.",
      "processing_time": 18.67844009399414,
      "citing_paper_id": "235313618",
      "cited_paper_id": 15125226
    },
    {
      "context_text": "To date, most existing methods regard this task as a classiﬁcation problem and usually train ECI models on annotated data (Hashimoto et al., 2014; Riaz and Girju, 2014b; Mirza and Tonelli, 2016; Hu and Walker, 2017b; Gao et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation context does not mention any specific datasets by name. It only refers to annotated data used for training ECI models, which is too generic.",
      "processing_time": 18.67844009399414,
      "citing_paper_id": "235313618",
      "cited_paper_id": 17227879
    },
    {
      "context_text": "Event Causality Identiﬁcation Up to now, identifying the causality implied in the text has at-tracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works. The cited papers also do not provide clear dataset names.",
      "processing_time": 17.249566316604614,
      "citing_paper_id": "235313618",
      "cited_paper_id": 9130816
    },
    {
      "context_text": "Event Causality Identiﬁcation Up to now, identifying the causality implied in the text has at-tracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works. The cited papers also do not provide clear dataset names.",
      "processing_time": 17.249566316604614,
      "citing_paper_id": "235313618",
      "cited_paper_id": 15125226
    },
    {
      "context_text": "For the target network, the parameters δ are an exponential moving average of the parameters θ of the online network (Lillicrap et al., 2016): where, η tea is the learning rate of the online network, and τ ∈ [0 , 1] is the decay rate that determines the degree of the movement of θ to δ .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only parameters and methods related to deep reinforcement learning.",
      "processing_time": 14.815048456192017,
      "citing_paper_id": "235313618",
      "cited_paper_id": 16326763
    },
    {
      "context_text": "…Up to now, identifying the causality implied in the text has at-tracted more and more attention (Hu and Walker, 2017a; Riaz and Girju, 2014b; Hashimoto et al., 2014; Riaz and Girju, 2014a, 2010; Do et al., 2011; Hidey and McKeown, 2016; Beamer and Girju, 2009; Hu et al., 2017; Hu and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The context is about identifying causality in text, which is a methodological focus rather than a dataset.",
      "processing_time": 19.376206636428833,
      "citing_paper_id": "235313618",
      "cited_paper_id": 17227879
    },
    {
      "context_text": "Dunietz et al. (2017) presented BECauSE 2.0, a new version of the BE-CauSE (Dunietz et al., 2015) of causal relation and other seven relations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "BECauSE 2.0"
      ],
      "dataset_descriptions": {
        "BECauSE 2.0": "Used to annotate causal and overlapping relations, enhancing the original BE-CauSE corpus with additional annotations and relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions BECauSE 2.0, which is a specific dataset used for annotating causality and overlapping relations. The cited paper title confirms it is a corpus.",
      "processing_time": 25.4044029712677,
      "citing_paper_id": "235313618",
      "cited_paper_id": 17716605
    },
    {
      "context_text": "In speciﬁc, we iteratively sample two external causal statements, initially encode them by BERT (Devlin et al., 2019), and input them into two networks respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT but does not refer to it as a dataset. It is used as a method for encoding causal statements.",
      "processing_time": 16.99704599380493,
      "citing_paper_id": "235313618",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Speciﬁcally, we design a classiﬁer based on BERT (Devlin et al., 2019) to build our identiﬁer.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT, which is a model, not a dataset. No datasets are explicitly mentioned or used in the described research.",
      "processing_time": 17.23770523071289,
      "citing_paper_id": "235313618",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In this way, the mutual information between the teacher and student models could be maximized (Tian et al., 2020).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for maximizing mutual information between models.",
      "processing_time": 13.748634338378906,
      "citing_paper_id": "235313618",
      "cited_paper_id": 204838340
    },
    {
      "context_text": "The key idea of contrastive transfer is intuitional: maximize the mutual information between the teacher and the student (Tian et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or concept.",
      "processing_time": 13.994941473007202,
      "citing_paper_id": "235313618",
      "cited_paper_id": 204838340
    },
    {
      "context_text": "…and general statements from GLUCOSE respectively. classiﬁcation cross-entropy function: Contrastive Transfer Module As aforementioned, inspired by Tian et al. (2020), we employ a contrastive transfer strategy to transfer the ”knowl-edge” mastered by the teacher (self-supervised representation…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (contrastive transfer strategy) and a model (teacher, self-supervised representation).",
      "processing_time": 18.682016134262085,
      "citing_paper_id": "235313618",
      "cited_paper_id": 204838340
    },
    {
      "context_text": "To handle this problem, inspired by Grill et al. (2020), we iteratively sample two external causal statements, take each of them as a target to learn their common-alities, that is, the causal representations, which reﬂect context-speciﬁc causal patterns.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for learning causal representations. No dataset names are present in the citation context.",
      "processing_time": 16.134503841400146,
      "citing_paper_id": "235313618",
      "cited_paper_id": 219687798
    },
    {
      "context_text": "To resolve this issue, inspired by Grill et al. (2020), we design a self-supervised representation learning framework to learn enhanced causal representations from exter-nal causal statements.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for self-supervised learning.",
      "processing_time": 14.534197092056274,
      "citing_paper_id": "235313618",
      "cited_paper_id": 219687798
    },
    {
      "context_text": "According to the theoretical analysis by Grill et al. (2020), the addition of a predictor on the online network and the usage of a slow-moving average of the online parameters as the target network encourage SelfRL to encode a more informative causal representation of commonalities within the…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only theoretical analysis and methodological approaches.",
      "processing_time": 14.531363010406494,
      "citing_paper_id": "235313618",
      "cited_paper_id": 219687798
    },
    {
      "context_text": "Inﬂuenced by the similar causal statements with the example in Table 1 from ATOMIC, the prediction conﬁdence is improved.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a reference to ATOMIC which is likely a method or model rather than a dataset.",
      "processing_time": 17.2191219329834,
      "citing_paper_id": "235313618",
      "cited_paper_id": null
    },
    {
      "context_text": "To address the insufﬁcient annotated example problem, we employ a large number of external causal statements (Sap et al., 2018; Mostafazadeh et al., 2020) that can support adequate evidence of context-speciﬁc causal patterns (Liu et al., 2020) for understanding event causalities.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'external causal statements' but does not specify a named dataset. The reference is too generic and lacks a clear identifier.",
      "processing_time": 18.28630566596985,
      "citing_paper_id": "235313618",
      "cited_paper_id": null
    },
    {
      "context_text": "There, all the ablation experiments are conducted on GLU-SPE. b) The effects of GLU-GEN and ATOMIC are similar because these two types of statements are abstract causal structures.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'GLU-SPE' but does not provide enough information to determine if it is a dataset, method, or other resource. It is also unclear how it is used in the research context.",
      "processing_time": 20.19335174560547,
      "citing_paper_id": "235313618",
      "cited_paper_id": null
    },
    {
      "context_text": "• ATOMIC (Sap et al., 2018): an atlas of machine commonsense, as a step toward addressing the rich spectrum of inferential knowledge that is crucial for commonsense reasoning.",
      "catation_intent": "reusable resource",
      "resource_type": "knowledge base",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "ATOMIC is described as an atlas of machine commonsense, which is a type of knowledge base rather than a dataset. It is not used as a dataset in the given context.",
      "processing_time": 20.33430004119873,
      "citing_paper_id": "235313618",
      "cited_paper_id": null
    },
    {
      "context_text": "Experiments demonstrate that CMNEE is challenging and event extraction in military domain remains an open issue.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general challenge in the military domain. No clear, verifiable resources are identified.",
      "processing_time": 16.11759066581726,
      "citing_paper_id": "269214164",
      "cited_paper_id": 2563759
    },
    {
      "context_text": "Experiments demonstrate that CMNEE is challenging and event extraction in military domain remains an open issue.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general challenge in the military domain. No clear, verifiable resources are identified.",
      "processing_time": 16.11759066581726,
      "citing_paper_id": "269214164",
      "cited_paper_id": 265659367
    },
    {
      "context_text": "There are also some datasets oriented to other specific domains, such as biomedical domain (Pyysalo et al., 2013), literary domain (Sims et al., 2019), terror-ist attack events (Grishman and Sundheim, 1996), breaking news (Fu et al., 2010), etc.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions several domain-specific datasets but does not provide specific names or identifiers. The titles of the cited papers help disambiguate the types of resources mentioned.",
      "processing_time": 19.738391399383545,
      "citing_paper_id": "269214164",
      "cited_paper_id": 2563759
    },
    {
      "context_text": "There are also some datasets oriented to other specific domains, such as biomedical domain (Pyysalo et al., 2013), literary domain (Sims et al., 2019), terror-ist attack events (Grishman and Sundheim, 1996), breaking news (Fu et al., 2010), etc.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions several domain-specific datasets but does not provide specific names or identifiers. The titles of the cited papers help disambiguate the types of resources mentioned.",
      "processing_time": 19.738391399383545,
      "citing_paper_id": "269214164",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "There are also some datasets oriented to other specific domains, such as biomedical domain (Pyysalo et al., 2013), literary domain (Sims et al., 2019), terror-ist attack events (Grishman and Sundheim, 1996), breaking news (Fu et al., 2010), etc.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions several domain-specific datasets but does not provide specific names or identifiers. The titles of the cited papers help disambiguate the types of resources mentioned.",
      "processing_time": 19.738391399383545,
      "citing_paper_id": "269214164",
      "cited_paper_id": 196201373
    },
    {
      "context_text": "Moreover, most existing event extraction datasets are oriented towards general (Li et al., 2020, 2021a) or financial domains (Han et al., 2022a; Zheng et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'event extraction datasets' but does not specify any particular dataset names. The cited papers provide additional context, but no specific dataset names are mentioned in the citation span.",
      "processing_time": 20.18108606338501,
      "citing_paper_id": "269214164",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Moreover, most existing event extraction datasets are oriented towards general (Li et al., 2020, 2021a) or financial domains (Han et al., 2022a; Zheng et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'event extraction datasets' but does not specify any particular dataset names. The cited papers provide additional context, but no specific dataset names are mentioned in the citation span.",
      "processing_time": 20.18108606338501,
      "citing_paper_id": "269214164",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Moreover, most existing event extraction datasets are oriented towards general (Li et al., 2020, 2021a) or financial domains (Han et al., 2022a; Zheng et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'event extraction datasets' but does not specify any particular dataset names. The cited papers provide additional context, but no specific dataset names are mentioned in the citation span.",
      "processing_time": 20.18108606338501,
      "citing_paper_id": "269214164",
      "cited_paper_id": 252569165
    },
    {
      "context_text": "ChfinAnn (Zheng et al., 2019) is constructed using distant supervision to assist in the construction, with a sizable scale, but it does not contain event trigger information, and can only be used for the event argument extraction task.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChfinAnn"
      ],
      "dataset_descriptions": {
        "ChfinAnn": "Used for Chinese financial event argument extraction, constructed with distant supervision, lacks event trigger information."
      },
      "confidence_score": 1.0,
      "reasoning": "ChfinAnn is identified as a dataset used for Chinese financial event extraction, specifically for the event argument extraction task.",
      "processing_time": 21.756126165390015,
      "citing_paper_id": "269214164",
      "cited_paper_id": 119308902
    },
    {
      "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN",
        "DuEE",
        "MNEE",
        "RAMS",
        "WikiEvents",
        "Duee-fin",
        "ChfinAnn",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models.",
        "DuEE": "Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
        "MNEE": "Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences.",
        "RAMS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance.",
        "WikiEvents": "Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation.",
        "Duee-fin": "Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents.",
        "ChfinAnn": "Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain.",
        "Do-cEE": "Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
      "processing_time": 61.81072020530701,
      "citing_paper_id": "269214164",
      "cited_paper_id": 119308902
    },
    {
      "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN",
        "DuEE",
        "MNEE",
        "RAMS",
        "WikiEvents",
        "Duee-fin",
        "ChfinAnn",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models.",
        "DuEE": "Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
        "MNEE": "Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences.",
        "RAMS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance.",
        "WikiEvents": "Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation.",
        "Duee-fin": "Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents.",
        "ChfinAnn": "Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain.",
        "Do-cEE": "Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
      "processing_time": 61.81072020530701,
      "citing_paper_id": "269214164",
      "cited_paper_id": 207853145
    },
    {
      "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN",
        "DuEE",
        "MNEE",
        "RAMS",
        "WikiEvents",
        "Duee-fin",
        "ChfinAnn",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models.",
        "DuEE": "Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
        "MNEE": "Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences.",
        "RAMS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance.",
        "WikiEvents": "Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation.",
        "Duee-fin": "Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents.",
        "ChfinAnn": "Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain.",
        "Do-cEE": "Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
      "processing_time": 61.81072020530701,
      "citing_paper_id": "269214164",
      "cited_paper_id": 216562779
    },
    {
      "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN",
        "DuEE",
        "MNEE",
        "RAMS",
        "WikiEvents",
        "Duee-fin",
        "ChfinAnn",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models.",
        "DuEE": "Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
        "MNEE": "Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences.",
        "RAMS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance.",
        "WikiEvents": "Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation.",
        "Duee-fin": "Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents.",
        "ChfinAnn": "Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain.",
        "Do-cEE": "Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
      "processing_time": 61.81072020530701,
      "citing_paper_id": "269214164",
      "cited_paper_id": 233219850
    },
    {
      "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN",
        "DuEE",
        "MNEE",
        "RAMS",
        "WikiEvents",
        "Duee-fin",
        "ChfinAnn",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models.",
        "DuEE": "Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
        "MNEE": "Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences.",
        "RAMS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance.",
        "WikiEvents": "Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation.",
        "Duee-fin": "Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents.",
        "ChfinAnn": "Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain.",
        "Do-cEE": "Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
      "processing_time": 61.81072020530701,
      "citing_paper_id": "269214164",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Extraction of military events from documents is crucial to downstream applications such as intelligence analysis (Santucci, 2022; Bang, 2016; Freed-man, 1983; Ivanov, 2011), decision making assistance (Skryabina et al., 2020), and strategic planning (Schrodt, 2012; Sankar, 2023; Lyu, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction in military contexts. No verifiable resources are named.",
      "processing_time": 18.282252073287964,
      "citing_paper_id": "269214164",
      "cited_paper_id": 154230030
    },
    {
      "context_text": "Extraction of military events from documents is crucial to downstream applications such as intelligence analysis (Santucci, 2022; Bang, 2016; Freed-man, 1983; Ivanov, 2011), decision making assistance (Skryabina et al., 2020), and strategic planning (Schrodt, 2012; Sankar, 2023; Lyu, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction in military contexts. No verifiable resources are named.",
      "processing_time": 18.282252073287964,
      "citing_paper_id": "269214164",
      "cited_paper_id": 154992508
    },
    {
      "context_text": "Extraction of military events from documents is crucial to downstream applications such as intelligence analysis (Santucci, 2022; Bang, 2016; Freed-man, 1983; Ivanov, 2011), decision making assistance (Skryabina et al., 2020), and strategic planning (Schrodt, 2012; Sankar, 2023; Lyu, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction in military contexts. No verifiable resources are named.",
      "processing_time": 18.282252073287964,
      "citing_paper_id": "269214164",
      "cited_paper_id": 213428800
    },
    {
      "context_text": "Extraction of military events from documents is crucial to downstream applications such as intelligence analysis (Santucci, 2022; Bang, 2016; Freed-man, 1983; Ivanov, 2011), decision making assistance (Skryabina et al., 2020), and strategic planning (Schrodt, 2012; Sankar, 2023; Lyu, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction in military contexts. No verifiable resources are named.",
      "processing_time": 18.282252073287964,
      "citing_paper_id": "269214164",
      "cited_paper_id": null
    },
    {
      "context_text": "For the document-level event extraction task, the commonly used datasets are RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021a), with a smaller number of documents, 9124 and 246, respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event extraction, containing 9124 documents. It serves as a larger-scale resource for training and evaluating event extraction models.",
        "WikiEvents": "Used for document-level event extraction, containing 246 documents. It provides a smaller, more focused dataset for detailed analysis and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for document-level event extraction. Both have clear identifiers and are directly relevant to the research topic.",
      "processing_time": 32.45723056793213,
      "citing_paper_id": "269214164",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "For the document-level event extraction task, the commonly used datasets are RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021a), with a smaller number of documents, 9124 and 246, respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event extraction, containing 9124 documents. It serves as a larger-scale resource for training and evaluating event extraction models.",
        "WikiEvents": "Used for document-level event extraction, containing 246 documents. It provides a smaller, more focused dataset for detailed analysis and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for document-level event extraction. Both have clear identifiers and are directly relevant to the research topic.",
      "processing_time": 32.45723056793213,
      "citing_paper_id": "269214164",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "(Du and Cardie, 2020) converted the event extraction task into the natural question answering task.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for converting event extraction into a question answering task.",
      "processing_time": 15.20710015296936,
      "citing_paper_id": "269214164",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Evaluation Following the widely-used setting, we report the micro Precision, Recall, and F-1 scores for event detection and event argument extraction as our evaluation metrics (Wang et al., 2020; Tong et al., 2022).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets by name. It only refers to evaluation metrics and cites papers that could potentially contain relevant datasets.",
      "processing_time": 18.600189924240112,
      "citing_paper_id": "269214164",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "Evaluation Following the widely-used setting, we report the micro Precision, Recall, and F-1 scores for event detection and event argument extraction as our evaluation metrics (Wang et al., 2020; Tong et al., 2022).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets by name. It only refers to evaluation metrics and cites papers that could potentially contain relevant datasets.",
      "processing_time": 18.600189924240112,
      "citing_paper_id": "269214164",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Attack” category, while the MAVEN dataset includes categories like “Attack” and “Defending”.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used to train and evaluate event detection models, specifically focusing on general domain events including 'Attack' and 'Defending'. The dataset supports the investigation of document-level event extraction methodologies."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MAVEN dataset, which is a specific, verifiable dataset used for event detection. The dataset is clearly identified and relevant to the topic of document-level event extraction.",
      "processing_time": 25.92805504798889,
      "citing_paper_id": "269214164",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "MAVEN (Wang et al., 2020) is the largest event detection dataset, which defines 168 event types and labels 19,640 events.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used to train and evaluate event detection models, specifically focusing on 168 event types and 19,640 labeled events."
      },
      "confidence_score": 1.0,
      "reasoning": "MAVEN is explicitly identified as a dataset with specific characteristics and is used for event detection.",
      "processing_time": 22.750351428985596,
      "citing_paper_id": "269214164",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "…text, which is typically separated into two subtasks: event detection and event argument extraction (Ahn, 2006; Yang et al., 2019; Xu et al., 2023; Wang et al., 2021b; Shi et al., 2023; Yang et al., 2023; Wan et al., 2023; Liu et al., 2020; Chu et al., 2023; Peng et al., 2023; Wang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only subtasks in event extraction. No dataset names are present in the text.",
      "processing_time": 18.267624855041504,
      "citing_paper_id": "269214164",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "…text, which is typically separated into two subtasks: event detection and event argument extraction (Ahn, 2006; Yang et al., 2019; Xu et al., 2023; Wang et al., 2021b; Shi et al., 2023; Yang et al., 2023; Wan et al., 2023; Liu et al., 2020; Chu et al., 2023; Peng et al., 2023; Wang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only subtasks in event extraction. No dataset names are present in the text.",
      "processing_time": 18.267624855041504,
      "citing_paper_id": "269214164",
      "cited_paper_id": 235254286
    },
    {
      "context_text": "…text, which is typically separated into two subtasks: event detection and event argument extraction (Ahn, 2006; Yang et al., 2019; Xu et al., 2023; Wang et al., 2021b; Shi et al., 2023; Yang et al., 2023; Wan et al., 2023; Liu et al., 2020; Chu et al., 2023; Peng et al., 2023; Wang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only subtasks in event extraction. No dataset names are present in the text.",
      "processing_time": 18.267624855041504,
      "citing_paper_id": "269214164",
      "cited_paper_id": 258378242
    },
    {
      "context_text": "…text, which is typically separated into two subtasks: event detection and event argument extraction (Ahn, 2006; Yang et al., 2019; Xu et al., 2023; Wang et al., 2021b; Shi et al., 2023; Yang et al., 2023; Wan et al., 2023; Liu et al., 2020; Chu et al., 2023; Peng et al., 2023; Wang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only subtasks in event extraction. No dataset names are present in the text.",
      "processing_time": 18.267624855041504,
      "citing_paper_id": "269214164",
      "cited_paper_id": 262825274
    },
    {
      "context_text": "6 ) TEXT2EVENT (Lu et al., 2021) is a sequence-to-structure generation paradigm that can directly extract events from the text in an end-to-end manner.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation describes a method (Text2Event) rather than a dataset. No specific dataset is mentioned or used in the context.",
      "processing_time": 18.291065216064453,
      "citing_paper_id": "269214164",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "Most of these models use sentence-level text for analysis, and while sentence-level event extraction research is relatively mature (Gao, 2021; Hsu et al., 2021; Huang et al., 2023a), this technology struggles when directly applied to document-level event extraction tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only discusses the limitations of sentence-level event extraction models when applied to document-level tasks.",
      "processing_time": 18.263841152191162,
      "citing_paper_id": "269214164",
      "cited_paper_id": 237353175
    },
    {
      "context_text": "Most of these models use sentence-level text for analysis, and while sentence-level event extraction research is relatively mature (Gao, 2021; Hsu et al., 2021; Huang et al., 2023a), this technology struggles when directly applied to document-level event extraction tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only discusses the limitations of sentence-level event extraction models when applied to document-level tasks.",
      "processing_time": 18.263841152191162,
      "citing_paper_id": "269214164",
      "cited_paper_id": null
    },
    {
      "context_text": "Currently, the FewFC dataset is the main dataset used for the study of overlapping events (Sheng et al., 2021; Cao et al., 2022), but the size of this dataset is relatively small, in which only 18% of the instances contain overlapping events, and its annotation is based on sentences.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewFC"
      ],
      "dataset_descriptions": {
        "FewFC": "Used to study overlapping events, but its small size and sentence-based annotation limit its applicability for document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the FewFC dataset, which is used for studying overlapping events. It provides details about the dataset's size and annotation method.",
      "processing_time": 23.54090642929077,
      "citing_paper_id": "269214164",
      "cited_paper_id": 252089843
    },
    {
      "context_text": "Recently, there have been some efforts using ChatGPT for data annotation in areas like Named Entity Recognition and Relation Extraction, as indicated in references (Ding et al., 2022; Goel et al., 2023; Zhang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of ChatGPT for data annotation in NER and Relation Extraction.",
      "processing_time": 18.25879144668579,
      "citing_paper_id": "269214164",
      "cited_paper_id": 254877171
    },
    {
      "context_text": "Recently, there have been some efforts using ChatGPT for data annotation in areas like Named Entity Recognition and Relation Extraction, as indicated in references (Ding et al., 2022; Goel et al., 2023; Zhang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of ChatGPT for data annotation in NER and Relation Extraction.",
      "processing_time": 18.25879144668579,
      "citing_paper_id": "269214164",
      "cited_paper_id": 264814421
    },
    {
      "context_text": "Chen et al. (2015) ﬁrstly propose a neural pipeline model to extract events, while Nguyen et al. (2016) utilize a joint model to mitigate error propagation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on describing different approaches to event extraction.",
      "processing_time": 17.92666244506836,
      "citing_paper_id": "248496614",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Li et al. (2014) and Judea and Strube (2016) use handcrafted features to extract events from the sentence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of handcrafted features for event extraction.",
      "processing_time": 16.355714082717896,
      "citing_paper_id": "248496614",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "In our implementation, we use BERT base (Devlin et al., 2019) and RoBERTa large (Liu et al., 2019) as our backbone encoder for T SAR , with global and local encoders sharing parameters.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and RoBERTa but does not refer to them as datasets. They are models used as backbone encoders.",
      "processing_time": 18.58995532989502,
      "citing_paper_id": "248496614",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In our implementation, we use BERTbase (Devlin et al., 2019) and RoBERTalarge (Liu et al.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERTbase and RoBERTalarge, which are models, not datasets. No datasets are explicitly mentioned or used according to the given context.",
      "processing_time": 19.702199935913086,
      "citing_paper_id": "248496614",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Some studies first identify entities in the document, followed by assigning these entities as specific argument roles (Yang et al., 2018; Zheng et al., 2019; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods or approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 19.29128122329712,
      "citing_paper_id": "248496614",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Some studies ﬁrst identify entities in the document, followed by assigning these entities as speciﬁc argument roles (Yang et al., 2018; Zheng et al., 2019; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches for event extraction. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 17.914457321166992,
      "citing_paper_id": "248496614",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Some studies ﬁrst identify entities in the document, followed by assigning these entities as speciﬁc argument roles (Yang et al., 2018; Zheng et al., 2019; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches for event extraction. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 17.914457321166992,
      "citing_paper_id": "248496614",
      "cited_paper_id": 202539732
    },
    {
      "context_text": "Data augmentation is also considered (Yang et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to data augmentation. No clear, verifiable resource names are present.",
      "processing_time": 18.923320770263672,
      "citing_paper_id": "248496614",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "From the global perspective, we first construct the global AMR graphs by fully connecting the root nodes of AMR graphs of different sentences, since the root nodes contain the core semantics according to the AMR core-semantic principle (Cai and Lam, 2019) 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological approach to constructing global AMR graphs.",
      "processing_time": 16.896806955337524,
      "citing_paper_id": "248496614",
      "cited_paper_id": 202542357
    },
    {
      "context_text": "436 These results suggest that encoding the document 437 in a two-stream way, and introducing AMR graphs 438 to facilitate interactions, is beneficial to capturing 439\n2We use TSARlarge based on RoBERTalarge to compare with BART-Gen based on BARTlarge, as they are pre-trained on the same corpus with the same batch size and training steps.\nintra-sentential and inter-sentential features, and440 thus improves the performance.441 Moreover, we follow Li et al. (2021) to evaluate442 both argument identification and argument classifi-443 cation, and report the Head F1 and Coref F1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the evaluation of argument identification and classification using specific metrics.",
      "processing_time": 19.28008008003235,
      "citing_paper_id": "248496614",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "5) BART-Gen (Li et al., 2021) for- 423 mulate the task as a sequence-to-sequence task and 424 uses BARTlarge (Lewis et al., 2020) to generate 425 corresponding arguments in a predefined format.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the use of BART for generating arguments, which is a methodological approach rather than a dataset.",
      "processing_time": 20.71721339225769,
      "citing_paper_id": "248496614",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "BERT-QA and BERT-QA-Doc extract run on sentence-level and document-level, respectively.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (BERT-QA and BERT-QA-Doc). No verifiable resources are identified.",
      "processing_time": 19.275243043899536,
      "citing_paper_id": "248496614",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "4) BERT-QA (Du and Cardie, 2020c) a QA-based model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT-QA, which is a model, not a dataset. No datasets are explicitly mentioned or used in the given citation context.",
      "processing_time": 19.49576163291931,
      "citing_paper_id": "248496614",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "4) BERT-QA (Du and Cardie, 2020c) is also a QA-based model.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT-QA, which is a model, not a dataset. No datasets are mentioned in the given citation span.",
      "processing_time": 18.565176486968994,
      "citing_paper_id": "248496614",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "with BIO-schema (Du and Cardie, 2020a; Veyseh et al., 2021), while span-based methods predict the argument role for candidate text spans which usually have a maximum length limitation (Ebner et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on comparing BIO-schema and span-based methods for event role filler extraction.",
      "processing_time": 19.843602895736694,
      "citing_paper_id": "248496614",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Tagging-based methods directly conduct se- 162 quence labeling for each token in the document 163 with BIO-schema (Du and Cardie, 2020a; Veyseh 164 et al., 2021), while span-based methods predict the 165 argument role for candidate text spans which usu- 166 ally have a maximum length limitation (Ebner et al., 167\n2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 25.14810609817505,
      "citing_paper_id": "248496614",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "2) Two-Step (Zhang et al., 2020b) is a span-based method, which ﬁrst identiﬁes the head word of possible argument span, and then extends to the full span.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes a method (Two-Step) rather than a dataset. No specific dataset is mentioned or used in the described research.",
      "processing_time": 25.598190784454346,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "2) Two-Step (Zhang et al., 2020b) is a span-based method, which ﬁrst identiﬁes the head word of possible argument span, and then extends to the full span.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes a method (Two-Step) rather than a dataset. No specific dataset is mentioned or used in the described research.",
      "processing_time": 25.598190784454346,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "It helps to transform the unstructured text into structured event knowledge that can be further utilized in recommendation systems (Li et al., 2020), dialogue systems (Zhang et al., 2020a), and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event knowledge transformation. No dataset names are present in the text.",
      "processing_time": 26.031864404678345,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "It helps to transform the unstructured text into structured event knowledge that can be further utilized in recommendation systems (Li et al., 2020), dialogue systems (Zhang et al., 2020a), and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event knowledge transformation. No dataset names are present in the text.",
      "processing_time": 26.031864404678345,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "2) Two-Step (Zhang et al., 2020b) is a span-based method, which first identifies the head word of possible argument span, and then extends to the full span.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event argument detection.",
      "processing_time": 24.64840817451477,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Instead, span-based methods predict argu-ment roles for candidate spans (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 26.518830060958862,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Instead, span-based methods predict argu-ment roles for candidate spans (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 26.518830060958862,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "Instead, span-based methods predict argument roles for candidate spans (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for predicting argument roles for candidate spans.",
      "processing_time": 25.129889249801636,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Although Two-Step and BART-Gen wrongly predict the place as Iraq and Syria , and Two-Step even fails to extract the Attacker , T SAR manage to extract the cross-sentence arguments.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and their performance. No verifiable resources are identified.",
      "processing_time": 25.86383032798767,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Although Two-Step and BART-Gen wrongly predict the place as Iraq and Syria , and Two-Step even fails to extract the Attacker , T SAR manage to extract the cross-sentence arguments.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and their performance. No verifiable resources are identified.",
      "processing_time": 25.86383032798767,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "Following Zhang et al. (2020b), we report the Span F1 and Head F1 for RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate event extraction models, reporting Span F1 and Head F1 metrics to assess performance in identifying and classifying events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for event extraction. The dataset is used to report performance metrics (Span F1 and Head F1) in the research.",
      "processing_time": 35.509453535079956,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Following Zhang et al. (2020b), we report the Span F1 and Head F1 for RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate event extraction models, reporting Span F1 and Head F1 metrics to assess performance in identifying and classifying events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for event extraction. The dataset is used to report performance metrics (Span F1 and Head F1) in the research.",
      "processing_time": 35.509453535079956,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "…directly conduct sequence labeling for each token in the document End: with BIO-schema (Du and Cardie, 2020a; Veyseh et al., 2021), while span-based methods predict the argument role for candidate text spans which usually have a maximum length limitation (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for event argument detection. No verifiable resources are identified.",
      "processing_time": 26.670851945877075,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "…directly conduct sequence labeling for each token in the document End: with BIO-schema (Du and Cardie, 2020a; Veyseh et al., 2021), while span-based methods predict the argument role for candidate text spans which usually have a maximum length limitation (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for event argument detection. No verifiable resources are identified.",
      "processing_time": 26.670851945877075,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": ", 2021), while span-based methods predict the argument role for candidate text spans which usually have a maximum length limitation (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 26.455212593078613,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "BERT-CRF TCD and Two-Step TCD refers to adopting Type-Constraint Decoding mechanism as used in (Ebner et al., 2020).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 14.681067943572998,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "BERT-CRF TCD and Two-Step TCD refers to adopting Type-Constraint Decoding mechanism as used in (Ebner et al., 2020).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 14.681067943572998,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": ", 2020), dialogue systems (Zhang et al., 2020a), and so on.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of application. No dataset names are present in the text.",
      "processing_time": 26.44955015182495,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "Another line of studies reformulate the task as a sequence-to-sequence task (Du et al., 2021a,b; Li et al., 2021), or machine reading comprehension task (Wei et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only reformulations of the task as sequence-to-sequence or machine reading comprehension. No verifiable resources are identified.",
      "processing_time": 28.252376317977905,
      "citing_paper_id": "248496614",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "Another line of studies reformulate the task as a sequence-to-sequence task (Du et al., 2021a,b; Li et al., 2021), or machine reading comprehension task (Wei et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only reformulations of the task as sequence-to-sequence or machine reading comprehension. No verifiable resources are identified.",
      "processing_time": 28.252376317977905,
      "citing_paper_id": "248496614",
      "cited_paper_id": 236460308
    },
    {
      "context_text": ", 2021), or machine reading comprehension task (Wei et al., 2021).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 28.239866018295288,
      "citing_paper_id": "248496614",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "3) FEAE (Wei et al., 2021), Frame-aware Event Argument Extraction, is a concurrent work based on question answering.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a concurrent work and its approach.",
      "processing_time": 25.44490337371826,
      "citing_paper_id": "248496614",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "To better model the interactions among words, Liu et al. (2018); Yan et al. (2019); Ma et al. (2020) make use of the dependency tree, and Wadden et al. (2019) enumer-ates all possible spans and propagate information in the span graph.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets.",
      "processing_time": 26.44028091430664,
      "citing_paper_id": "248496614",
      "cited_paper_id": 269498086
    },
    {
      "context_text": "As791 the number of AMR relation types is large, which792 results in too many demanded parameters, we fol-793 low Zhang and Ji (2021) to cluster the relation types794 into main categories as shown in Table 5.795\nB Statistics of Datasets796\nThe detailed data statistics of RAMS and797 WikiEvents…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to provide detailed data statistics for document-level event extraction, focusing on the distribution and characteristics of events and relations.",
        "WikiEvents": "Used to provide detailed data statistics for document-level event extraction, focusing on the distribution and characteristics of events and relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS' and 'WikiEvents' as datasets, which are multi-word proper nouns and likely refer to specific, verifiable datasets used in the research.",
      "processing_time": 40.09006643295288,
      "citing_paper_id": "248496614",
      "cited_paper_id": null
    },
    {
      "context_text": "ECB+ This dataset (Cybulska and Vossen, 2014), which is an extended version of the EventCorefBank (ECB) (Bejan and Harabagiu, 2010), is the most commonly used dataset for training and testing models for CD event coreference (Choubey and",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+",
        "EventCorefBank (ECB)"
      ],
      "dataset_descriptions": {
        "ECB+": "Used for training and testing models for CD event coreference, extending the original ECB dataset with additional annotations and data.",
        "EventCorefBank (ECB)": "Used for training and testing models for CD event coreference, providing a foundational dataset for event coreference resolution."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions ECB+ and ECB as specific datasets used for training and testing models for CD event coreference. These are multi-word proper nouns and are clearly identified as datasets.",
      "processing_time": 42.08031702041626,
      "citing_paper_id": "233210350",
      "cited_paper_id": 739867
    },
    {
      "context_text": "ECB+ This dataset (Cybulska and Vossen, 2014), which is an extended version of the EventCorefBank (ECB) (Bejan and Harabagiu, 2010), is the most commonly used dataset for training and testing models for CD event coreference (Choubey and",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+",
        "EventCorefBank (ECB)"
      ],
      "dataset_descriptions": {
        "ECB+": "Used for training and testing models for CD event coreference, extending the original ECB dataset with additional annotations and data.",
        "EventCorefBank (ECB)": "Used for training and testing models for CD event coreference, providing a foundational dataset for event coreference resolution."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions ECB+ and ECB as specific datasets used for training and testing models for CD event coreference. These are multi-word proper nouns and are clearly identified as datasets.",
      "processing_time": 42.08031702041626,
      "citing_paper_id": "233210350",
      "cited_paper_id": 1801348
    },
    {
      "context_text": "For\n6We note that this optimization is different than the (linear) antecedent ranking in the model of Lee et al. (2017), since in the CD setting there is no linear order between mentions from different documents.\nthe experiment on ECB+, we follow the recent evaluation setting (Kenyon-Dean et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison to a method from another paper. No verifiable resources are identified.",
      "processing_time": 27.205307722091675,
      "citing_paper_id": "233210350",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "within-document coreference models (Lee et al., 2017; Kantor and Globerson, 2019; Joshi et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods for coreference resolution.",
      "processing_time": 25.986062049865723,
      "citing_paper_id": "233210350",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "within-document coreference models (Lee et al., 2017; Kantor and Globerson, 2019; Joshi et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods for coreference resolution.",
      "processing_time": 25.986062049865723,
      "citing_paper_id": "233210350",
      "cited_paper_id": 201646551
    },
    {
      "context_text": "Applying RoBERTa to this window, we represent each mention by a vector gi, which is the concatenation of three vectors: the contextualized representations of the mention span boundaries (first and last) and the weighted sum of the mention token vectors according to the head-finding attention mechanism in (Lee et al., 2017).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (RoBERTa) and a reference to another paper for a specific mechanism. No verifiable datasets are identified.",
      "processing_time": 28.89157772064209,
      "citing_paper_id": "233210350",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "We therefore developed a new, more scalable, baseline model for the task, while adapting components of recent competitive\nwithin-document coreference models (Lee et al., 2017; Kantor and Globerson, 2019; Joshi et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 27.593449115753174,
      "citing_paper_id": "233210350",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "We therefore developed a new, more scalable, baseline model for the task, while adapting components of recent competitive\nwithin-document coreference models (Lee et al., 2017; Kantor and Globerson, 2019; Joshi et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 27.593449115753174,
      "citing_paper_id": "233210350",
      "cited_paper_id": 201646551
    },
    {
      "context_text": "In addition, we observe that longer spans common in WEC-Eng challenge the span representation model of Lee et al. (2017).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a challenge (WEC-Eng) which is excluded as per instructions. The cited paper title does not help in identifying a dataset.",
      "processing_time": 29.785584211349487,
      "citing_paper_id": "233210350",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "For the pairwise model, we replicate the architecture of mention representation and pairwise scorer from the end-to-end within document coreference model in (Lee et al., 2017), while including the recent incorporation of transformer-based encoders (Joshi et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on replicating architectural components from another paper.",
      "processing_time": 27.5896418094635,
      "citing_paper_id": "233210350",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "For the pairwise model, we replicate the architecture of mention representation and pairwise scorer from the end-to-end within document coreference model in (Lee et al., 2017), while including the recent incorporation of transformer-based encoders (Joshi et al., 2019; Kantor and Globerson, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers are used to describe the architecture and enhancements of the model, not for dataset usage.",
      "processing_time": 29.212400436401367,
      "citing_paper_id": "233210350",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "For the pairwise model, we replicate the architecture of mention representation and pairwise scorer from the end-to-end within document coreference model in (Lee et al., 2017), while including the recent incorporation of transformer-based encoders (Joshi et al., 2019; Kantor and Globerson, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers are used to describe the architecture and enhancements of the model, not for dataset usage.",
      "processing_time": 29.212400436401367,
      "citing_paper_id": "233210350",
      "cited_paper_id": 201646551
    },
    {
      "context_text": "…we represent each mention by a vector gi, which is the concatenation of three vectors: the contextualized representations of the mention span boundaries (first and last) and the weighted sum of the mention token vectors according to the head-finding attention mechanism in (Lee et al., 2017).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for representing mentions using vectors. The cited paper is about a neural coreference resolution method.",
      "processing_time": 27.95698595046997,
      "citing_paper_id": "233210350",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "Notable datasets include ECB+ (Cybulska and Vossen, 2014), MEANTIME (Minard et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+",
        "MEANTIME"
      ],
      "dataset_descriptions": {
        "ECB+": "Used for event coreference resolution, focusing on lexical diversity and event linking in news articles.",
        "MEANTIME": "Applied to study event coreference across multiple languages, enhancing cross-lingual event linking in news texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ECB+ and MEANTIME, which are relevant to document-level event extraction.",
      "processing_time": 37.63678693771362,
      "citing_paper_id": "233210350",
      "cited_paper_id": 1801348
    },
    {
      "context_text": "(Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019), the merging score for two clusters is defined as the average mention pair score s(i, j) over all mention pairs (i, j) across the two candidate clusters to be merged.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a method for calculating merging scores in clustering. The cited papers' titles suggest a focus on event coreference resolution, but do not introduce specific datasets.",
      "processing_time": 31.18460988998413,
      "citing_paper_id": "233210350",
      "cited_paper_id": 2091974
    },
    {
      "context_text": "(Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019), the merging score for two clusters is defined as the average mention pair score s(i, j) over all mention pairs (i, j) across the two candidate clusters to be merged.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a method for calculating merging scores in clustering. The cited papers' titles suggest a focus on event coreference resolution, but do not introduce specific datasets.",
      "processing_time": 31.18460988998413,
      "citing_paper_id": "233210350",
      "cited_paper_id": 174799117
    },
    {
      "context_text": "In its essence, our methodology leverages the coreference relation that often holds between anchor texts of hyperlinks pointing to the same Wikipedia article (see Figure 1), similar to the basic idea introduced in the Wikilinks dataset (Singh et al., 2012).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wikilinks dataset"
      ],
      "dataset_descriptions": {
        "Wikilinks dataset": "Used to leverage coreference relations between anchor texts of hyperlinks pointing to the same Wikipedia article, focusing on cross-document coreference."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'Wikilinks dataset' as a reusable resource, which is a specific, verifiable dataset used for cross-document coreference.",
      "processing_time": 35.80143427848816,
      "citing_paper_id": "233210350",
      "cited_paper_id": 11619517
    },
    {
      "context_text": "coreference relation that often holds between anchor texts of hyperlinks pointing to the same Wikipedia article (see Figure 1), similar to the basic idea introduced in the Wikilinks dataset (Singh et al., 2012).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wikilinks"
      ],
      "dataset_descriptions": {
        "Wikilinks": "Used to study coreference relations in anchor texts of hyperlinks pointing to the same Wikipedia article, focusing on cross-document coreference."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the Wikilinks dataset, which is a specific, verifiable resource used for cross-document coreference. The dataset is clearly identified and referenced in the context.",
      "processing_time": 36.268523931503296,
      "citing_paper_id": "233210350",
      "cited_paper_id": 11619517
    },
    {
      "context_text": "Wikilinks (Singh et al., 2012) is an automaticallycollected large-scale cross-document coreference dataset, focused on entity coreference.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wikilinks"
      ],
      "dataset_descriptions": {
        "Wikilinks": "Used to study entity coreference across documents, focusing on large-scale cross-document coreference resolution using links to Wikipedia."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Wikilinks' as a dataset used for cross-document coreference, specifically focusing on entity coreference.",
      "processing_time": 34.46206879615784,
      "citing_paper_id": "233210350",
      "cited_paper_id": 11619517
    },
    {
      "context_text": "…is no linear order between mentions from different documents.\nthe experiment on ECB+, we follow the recent evaluation setting (Kenyon-Dean et al., 2018; Barhom et al., 2019), clustering gold mentions and concatenating all test documents into one meta-document, as proposed by Upadhyay et al. (2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+"
      ],
      "dataset_descriptions": {
        "ECB+": "Used to evaluate cross-document event coreference, clustering gold mentions and concatenating test documents into a meta-document, following the evaluation setting proposed by Kenyon-Dean et al. (2018) and Barhom et al. (2019)."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ECB+' which is a known dataset for event coreference. The dataset is used for evaluating cross-document event coreference, following a specific experimental setup.",
      "processing_time": 40.36924910545349,
      "citing_paper_id": "233210350",
      "cited_paper_id": 12399949
    },
    {
      "context_text": "…is no linear order between mentions from different documents.\nthe experiment on ECB+, we follow the recent evaluation setting (Kenyon-Dean et al., 2018; Barhom et al., 2019), clustering gold mentions and concatenating all test documents into one meta-document, as proposed by Upadhyay et al. (2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+"
      ],
      "dataset_descriptions": {
        "ECB+": "Used to evaluate cross-document event coreference, clustering gold mentions and concatenating test documents into a meta-document, following the evaluation setting proposed by Kenyon-Dean et al. (2018) and Barhom et al. (2019)."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ECB+' which is a known dataset for event coreference. The dataset is used for evaluating cross-document event coreference, following a specific experimental setup.",
      "processing_time": 40.36924910545349,
      "citing_paper_id": "233210350",
      "cited_paper_id": 174799117
    },
    {
      "context_text": "96 Recall, indicating the high quality of our validated dataset (the Cohen’s Kappa (Cohen, 1960) between the original and consolidated annotations was 0.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a 'validated dataset' but does not provide a specific name or identifier. The citation is used to support the quality of the dataset, not to introduce a reusable resource.",
      "processing_time": 30.389978885650635,
      "citing_paper_id": "233210350",
      "cited_paper_id": 15926286
    },
    {
      "context_text": "Relative to this reliable consolidated annotation, the original annotations scored at 0.95 Precision and 0.96 Recall, indicating the high quality of our validated dataset (the Cohen’s Kappa (Cohen, 1960) between the original and consolidated annotations was 0.75, considered substantial agreement).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'validated dataset' but does not provide a specific name or identifier. It is a generic reference to the dataset used in the study.",
      "processing_time": 28.862061738967896,
      "citing_paper_id": "233210350",
      "cited_paper_id": 15926286
    },
    {
      "context_text": "…of broad general events, consisting of many sub-events is necessary as often Wikipedia authors link to a broad event from anchor texts that refer to a subevent (and should be regarded as non-coreferring by standard definitions of the event coreference task (Hovy et al., 2013; Araki et al., 2014)).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers discussing event coreference resolution and subevent structure.",
      "processing_time": 27.158093452453613,
      "citing_paper_id": "233210350",
      "cited_paper_id": 17510107
    },
    {
      "context_text": "MEANTIME Minard et al. (2016) proposed a dataset that is similar in some respects to ECB+, with documents partitioned into a set of topics.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MEANTIME"
      ],
      "dataset_descriptions": {
        "MEANTIME": "Used to study multilingual event and time annotations in news articles, focusing on document-level event extraction and temporal relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MEANTIME' as a dataset, which is a specific, verifiable resource. The title confirms it is a corpus, making it a valid dataset.",
      "processing_time": 35.93470335006714,
      "citing_paper_id": "233210350",
      "cited_paper_id": 26201484
    },
    {
      "context_text": "Notable datasets include ECB+ (Cybulska and Vossen, 2014), MEANTIME (Minard et al., 2016) and the Gun Violence Corpus (GVC) (Vossen et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+",
        "MEANTIME",
        "GVC"
      ],
      "dataset_descriptions": {
        "ECB+": "Used to train and evaluate models for event coreference resolution, focusing on cross-document event linking and co-reference.",
        "MEANTIME": "Utilized for multilingual event and time annotation, enhancing cross-lingual event extraction and temporal relation analysis.",
        "GVC": "Applied to study gun violence events, specifically extracting and analyzing event mentions and their contexts in news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets relevant to document-level event extraction, including ECB+, MEANTIME, and GVC. These are multi-word proper nouns and are clearly identified as datasets.",
      "processing_time": 47.4758505821228,
      "citing_paper_id": "233210350",
      "cited_paper_id": 26201484
    },
    {
      "context_text": "This section describes the main characteristics of notable datasets for CD event coreference (ECB+, MEANTIME, GVC).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+",
        "MEANTIME",
        "GVC"
      ],
      "dataset_descriptions": {
        "ECB+": "Used to evaluate event coreference systems, focusing on cross-document event linking and coreference resolution in news articles.",
        "MEANTIME": "Used to train and evaluate multilingual event and time annotation systems, providing a richly annotated corpus for event and time expressions in multiple languages.",
        "GVC": "Used to study event coreference in a specific domain, focusing on cross-document event linking and coreference resolution in government and political texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three datasets by name: ECB+, MEANTIME, and GVC. These are specific datasets used for event coreference in the document-level event extraction domain.",
      "processing_time": 49.05382061004639,
      "citing_paper_id": "233210350",
      "cited_paper_id": 26201484
    },
    {
      "context_text": "Notable datasets include ECB+ (Cybulska and Vossen,\n2014), MEANTIME (Minard et al., 2016) and the Gun Violence Corpus (GVC) (Vossen et al., 2018) (described in Section 2), where recent work has been evaluated solely on ECB+.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+",
        "MEANTIME",
        "GVC"
      ],
      "dataset_descriptions": {
        "ECB+": "Used for evaluating document-level event extraction models, focusing on cross-document coreference resolution and event linking.",
        "MEANTIME": "Utilized for multilingual event and time annotation, supporting cross-lingual event extraction and temporal relation analysis.",
        "GVC": "Applied to study gun violence events, focusing on fine-grained event annotation and context extraction in news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three datasets: ECB+, MEANTIME, and GVC. These are all specific, verifiable datasets used in document-level event extraction research.",
      "processing_time": 46.44902038574219,
      "citing_paper_id": "233210350",
      "cited_paper_id": 26201484
    },
    {
      "context_text": "Results are reported by precision, recall, and F1 for the standard coreference metrics MUC, B3, CEAF-e, and the average F1 of the three metrics, using the official CoNLL scorer (Pradhan et al., 2012).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions evaluation metrics and a scorer but does not refer to a specific dataset. The CoNLL-2012 shared task is mentioned, which involves the OntoNotes dataset, but the dataset itself is not directly referenced in the citation context.",
      "processing_time": 33.51891231536865,
      "citing_paper_id": "233210350",
      "cited_paper_id": 41479182
    },
    {
      "context_text": "Results are reported by precision, recall, and F1 for the standard coreference metrics MUC, B3, CEAF-e, and the average F1 of the three metrics, using the official CoNLL scorer (Pradhan et al., 2012).7",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions coreference metrics and the CoNLL scorer, which are evaluation tools rather than datasets. No specific dataset is mentioned.",
      "processing_time": 28.397990226745605,
      "citing_paper_id": "233210350",
      "cited_paper_id": 41479182
    },
    {
      "context_text": "…are gaining increasing interest and need to match and integrate information across documents, such as multidocument summarization (Falke et al., 2017; Liao et al., 2018), multi-hop question answering (Dhingra et al., 2018; Wang et al., 2019) and Knowledge Base Population (KBP) (Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research areas and tasks. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 29.203338861465454,
      "citing_paper_id": "233210350",
      "cited_paper_id": 49210924
    },
    {
      "context_text": "…are gaining increasing interest and need to match and integrate information across documents, such as multidocument summarization (Falke et al., 2017; Liao et al., 2018), multi-hop question answering (Dhingra et al., 2018; Wang et al., 2019) and Knowledge Base Population (KBP) (Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research areas and tasks. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 29.203338861465454,
      "citing_paper_id": "233210350",
      "cited_paper_id": 207756678
    },
    {
      "context_text": "…are gaining increasing interest and need to match and integrate information across documents, such as multidocument summarization (Falke et al., 2017; Liao et al., 2018), multi-hop question answering (Dhingra et al., 2018; Wang et al., 2019) and Knowledge Base Population (KBP) (Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research areas and tasks. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 29.203338861465454,
      "citing_paper_id": "233210350",
      "cited_paper_id": 214641903
    },
    {
      "context_text": "Successful identification of such coreferring mentions is beneficial for a broad range of applications at the multi-text level, which are gaining increasing interest and need to match and integrate information across documents, such as multidocument summarization (Falke et al., 2017; Liao et al., 2018), multi-hop question answering (Dhingra et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only applications and methods. No clear identifiers for datasets are present.",
      "processing_time": 27.362106800079346,
      "citing_paper_id": "233210350",
      "cited_paper_id": 49210924
    },
    {
      "context_text": "Our model outperforms state-of-the-art results for both the JOINT model and the DISJOINT event model of Barhom et al. (2019), with a gain of 1.3 CoNLL F1 points and 2.3 CoNLL F1 points respectively.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and performance metrics. The context focuses on comparing model performance.",
      "processing_time": 27.743431568145752,
      "citing_paper_id": "233210350",
      "cited_paper_id": 174799117
    },
    {
      "context_text": "In addition, the model of Barhom et al. (2019) uses an SRL system to encode the context surrounding verbal event mentions, while WEC-Eng is mostly composed of nominal event mentions (Section 3.4).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model and a system. The term 'WEC-Eng' is mentioned but it is not clear if it is a dataset or a component of the model. Therefore, no datasets are extracted.",
      "processing_time": 33.351797580718994,
      "citing_paper_id": "233210350",
      "cited_paper_id": 174799117
    },
    {
      "context_text": "The current state-of-the-art CD event coreference system (Barhom et al., 2019) cannot be effectively trained on WEC-Eng for two main reasons: (1) computational complexity and (2) reliance on verbal SRL features.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (CD event coreference system) and a limitation regarding training on WEC-Eng. WEC-Eng is not a clear, verifiable dataset name.",
      "processing_time": 32.626760482788086,
      "citing_paper_id": "233210350",
      "cited_paper_id": 174799117
    },
    {
      "context_text": "…(Bejan and Harabagiu, 2010), is the most commonly used dataset for training and testing models for CD event coreference (Choubey and\n1WEC–https://github.com/AlonEirew/ extract-wec\n2Model–https://github.com/AlonEirew/ cross-doc-event-coref\nHuang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'CD event coreference' which likely refers to a dataset, but does not provide a specific name. The context suggests the dataset is widely used but does not specify it.",
      "processing_time": 31.845306158065796,
      "citing_paper_id": "233210350",
      "cited_paper_id": 174799117
    },
    {
      "context_text": "Following the commonly used average-link method (Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019), the merging score for two clusters is defined as the average mention pair score s(i, j) over all mention pairs (i, j) across the two candidate clusters to be merged.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a clustering method. No datasets are referenced or used in the described context.",
      "processing_time": 27.351433992385864,
      "citing_paper_id": "233210350",
      "cited_paper_id": 174799117
    },
    {
      "context_text": "the experiment on ECB+, we follow the recent evaluation setting (Kenyon-Dean et al., 2018; Barhom et al., 2019), clustering gold mentions and concatenating all test documents into one meta-document, as proposed by Upadhyay et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+"
      ],
      "dataset_descriptions": {
        "ECB+": "Used to evaluate cross-document entity and event coreference resolution, clustering gold mentions and concatenating test documents into a meta-document."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ECB+' which is a known dataset for document-level event extraction. The dataset is used for evaluating cross-document entity and event coreference resolution.",
      "processing_time": 35.74910283088684,
      "citing_paper_id": "233210350",
      "cited_paper_id": 174799117
    },
    {
      "context_text": "For a fair comparison, we use the output of pre-processing document clustering obtained by Barhom et al. (2019) and apply our coreference model separately on each predicted document cluster.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using the output of pre-processing document clustering from Barhom et al. (2019), but does not specify a named dataset. The reference is to a method or process rather than a specific, verifiable dataset.",
      "processing_time": 33.34060192108154,
      "citing_paper_id": "233210350",
      "cited_paper_id": 174799117
    },
    {
      "context_text": "Concretely, we first apply a pre-trained RoBERTa (Liu et al., 2019) language model (without finetuning), separately for each mention.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a pre-trained language model (RoBERTa).",
      "processing_time": 14.051735877990723,
      "citing_paper_id": "233210350",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "This suggests that the RoBERTa-based modeling of context may not be sufficient, and that more sophisticated models, injecting argument structure more extensively, may be needed.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only discusses the limitations of RoBERTa-based modeling.",
      "processing_time": 27.33154559135437,
      "citing_paper_id": "233210350",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "Given a mention span i, we include as context, T (set to 250) tokens to the left of i and T tokens to the right of i. Applying RoBERTa to this window, we represent each mention by a vector gi, which is the concatenation of three vectors: the contextualized representations of the mention span boundaries (first and last) and the weighted sum of the mention token vectors according to the head-finding attention mechanism in (Lee et al., 2017).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (RoBERTa) and a technique for representing mentions. No verifiable datasets are referenced.",
      "processing_time": 29.7322940826416,
      "citing_paper_id": "233210350",
      "cited_paper_id": 198953378
    },
    {
      "context_text": ", 2017), while including the recent incorporation of transformer-based encoders (Joshi et al., 2019; Kantor and Globerson, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing transformer-based encoders. No verifiable resources are identified.",
      "processing_time": 29.147587060928345,
      "citing_paper_id": "233210350",
      "cited_paper_id": 201646551
    },
    {
      "context_text": ", 2018), multi-hop question answering (Dhingra et al., 2018; Wang et al., 2019) and Knowledge Base Population (KBP) (Lin et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research areas and methods. No clear identifiers for datasets are present.",
      "processing_time": 28.36628794670105,
      "citing_paper_id": "233210350",
      "cited_paper_id": 207756678
    },
    {
      "context_text": "Successful identification of such coreferring mentions is beneficial for a broad range of applications at the multi-text level, which are gaining increasing interest and need to match and integrate information across documents, such as multidocument summarization (Falke et al., 2017; Liao et al., 2018), multi-hop question answering (Dhingra et al., 2018; Wang et al., 2019) and Knowledge Base Population (KBP) (Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications and tasks. The cited paper title 'KBPearl' does not help in identifying a dataset.",
      "processing_time": 30.621461391448975,
      "citing_paper_id": "233210350",
      "cited_paper_id": 214641903
    },
    {
      "context_text": ", 2019) and Knowledge Base Population (KBP) (Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Knowledge Base Population (KBP)', which is a task or challenge rather than a specific dataset. No specific dataset names are provided in the context.",
      "processing_time": 31.11928391456604,
      "citing_paper_id": "233210350",
      "cited_paper_id": 214641903
    },
    {
      "context_text": "The bridging relations are important for capturing a range of anaphora phenomena that are not strict identity relationships (Clark, 1975; Poesio et al., 1997).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to academic papers discussing bridging relations and anaphora phenomena.",
      "processing_time": 28.55765390396118,
      "citing_paper_id": "15139323",
      "cited_paper_id": 8176139
    },
    {
      "context_text": "…which do annotate causal, temporal, event-structural or coreference relations within limited scopes, such as within the same clause or across adjacent sentences (Banarescu et al., 2013; Carlson et al., 2003; Prasad et al., 2008; Riaz and Girju, 2013; Fillmore and Baker, 2000; Palmer et al., 2005).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions various studies that annotate specific linguistic relations, but does not name any specific datasets. The context is more about referencing prior work rather than using a particular dataset.",
      "processing_time": 31.55750274658203,
      "citing_paper_id": "15139323",
      "cited_paper_id": 15920102
    },
    {
      "context_text": "…which do annotate causal, temporal, event-structural or coreference relations within limited scopes, such as within the same clause or across adjacent sentences (Banarescu et al., 2013; Carlson et al., 2003; Prasad et al., 2008; Riaz and Girju, 2013; Fillmore and Baker, 2000; Palmer et al., 2005).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions various studies that annotate specific linguistic relations, but does not name any specific datasets. The context is more about referencing prior work rather than using a particular dataset.",
      "processing_time": 31.55750274658203,
      "citing_paper_id": "15139323",
      "cited_paper_id": null
    },
    {
      "context_text": "…which do annotate causal, temporal, event-structural or coreference relations within limited scopes, such as within the same clause or across adjacent sentences (Banarescu et al., 2013; Carlson et al., 2003; Prasad et al., 2008; Riaz and Girju, 2013; Fillmore and Baker, 2000; Palmer et al., 2005).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions various studies that annotate specific linguistic relations, but does not name any specific datasets. The context is more about referencing prior work rather than using a particular dataset.",
      "processing_time": 31.55750274658203,
      "citing_paper_id": "15139323",
      "cited_paper_id": 7771402
    },
    {
      "context_text": "This annotation aims towards logical deﬁnitions for cause and preconditions outlined in Ikuta et al (2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a paper discussing causation in event descriptions.",
      "processing_time": 28.14840340614319,
      "citing_paper_id": "15139323",
      "cited_paper_id": 16067820
    },
    {
      "context_text": "This annotation aims towards logical deﬁnitions for cause and preconditions outlined in Ikuta et al (2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a paper discussing causation in event descriptions.",
      "processing_time": 28.14840340614319,
      "citing_paper_id": "15139323",
      "cited_paper_id": null
    },
    {
      "context_text": "RED annotation, based on preliminary studies of causal annotation in (Ikuta et al., 2014), adopted a two-way distinction between C AUSES and P RECONDI - TION similar to the distinction often made between “Cause” and “enable”.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological approach to causal annotation. No verifiable resources are identified.",
      "processing_time": 27.879151582717896,
      "citing_paper_id": "15139323",
      "cited_paper_id": 16067820
    },
    {
      "context_text": "RED annotation, based on preliminary studies of causal annotation in (Ikuta et al., 2014), adopted a two-way distinction between C AUSES and P RECONDI - TION similar to the distinction often made between “Cause” and “enable”.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological approach to causal annotation. No verifiable resources are identified.",
      "processing_time": 27.879151582717896,
      "citing_paper_id": "15139323",
      "cited_paper_id": null
    },
    {
      "context_text": "…and Klein, 2013) in recent systems, and some researchers working on coreference have observed the utility of focusing upon headwords, with (Peng et al., 2015) claiming that “identifying and co-referring mention heads is not only sufﬁcient but is more robust than working with complete…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on coreference resolution and mention head detection, which are methodologies rather than datasets.",
      "processing_time": 31.361053228378296,
      "citing_paper_id": "15139323",
      "cited_paper_id": 17010034
    },
    {
      "context_text": "…in recent systems, and some researchers working on coreference have observed the utility of focusing upon headwords, with (Peng et al., 2015) claiming that “identifying and co-referring mention heads is not only sufﬁcient but is more robust than working with complete mentions” (Peng et al. 2015:1).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach related to coreference resolution and mention head detection.",
      "processing_time": 28.78481960296631,
      "citing_paper_id": "15139323",
      "cited_paper_id": 17010034
    },
    {
      "context_text": "…may be useful for a wide range of goals; Liao and Grishman (2010) found that looking at related events within a document could aid ACE-style event detection, and Vossen et al. (2015) discussed the value of combining time-lines with bridging and causal relations in the construction of storylines.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methodologies and findings.",
      "processing_time": 26.933225870132446,
      "citing_paper_id": "15139323",
      "cited_paper_id": 18203481
    },
    {
      "context_text": "Annotation schemes such as Prop-bank (Palmer et al., 2005), FrameNet (Fillmore and Baker, 2000), Preposition annotation (Litkowski and Hargraves, 2005; Srikumar and Roth, 2013; Schneider et al., 2015) or AMR (Banarescu et al., 2013) have captured large quantities of temporal and causal relationships, but largely do so within very limited distances from a predicate.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several annotation schemes but does not refer to them as datasets. They are described as methods or frameworks for annotation, not as reusable data resources.",
      "processing_time": 30.817830324172974,
      "citing_paper_id": "15139323",
      "cited_paper_id": null
    },
    {
      "context_text": "Annotation schemes such as Prop-bank (Palmer et al., 2005), FrameNet (Fillmore and Baker, 2000), Preposition annotation (Litkowski and Hargraves, 2005; Srikumar and Roth, 2013; Schneider et al., 2015) or AMR (Banarescu et al., 2013) have captured large quantities of temporal and causal relationships, but largely do so within very limited distances from a predicate.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several annotation schemes but does not refer to them as datasets. They are described as methods or frameworks for annotation, not as reusable data resources.",
      "processing_time": 30.817830324172974,
      "citing_paper_id": "15139323",
      "cited_paper_id": 7771402
    },
    {
      "context_text": "Annotation schemes such as Prop-bank (Palmer et al., 2005), FrameNet (Fillmore and Baker, 2000), Preposition annotation (Litkowski and Hargraves, 2005; Srikumar and Roth, 2013; Schneider et al., 2015) or AMR (Banarescu et al., 2013) have captured large quantities of temporal and causal…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several annotation schemes but does not refer to them as datasets. These are methods or frameworks for annotation, not datasets.",
      "processing_time": 29.690348863601685,
      "citing_paper_id": "15139323",
      "cited_paper_id": null
    },
    {
      "context_text": "The second source of “narrative container” annotation is a focus in the annotations on capturing temporal structure using CONTAINS ( INCLUDES , in ISO-TimeML) relations between events and on capturing event-time relationships.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a focus on temporal structure and event-time relationships in annotations. No clear, verifiable dataset names are present.",
      "processing_time": 31.34998345375061,
      "citing_paper_id": "15139323",
      "cited_paper_id": 341734
    },
    {
      "context_text": "Corpora for event-event and event-time relations have also been developed, both for temporal information in the TimeML tradition (Pustejovsky et al., 2003; Styler IV et al., 2014; Minard et al., 2016), and causal structure (Bethard, 2007; Mostafazadeh et al., 2016; Mirza et al., 2014; Hong et al.,…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions corpora for event-event and event-time relations, which are relevant to document-level event extraction. However, specific dataset names are not provided.",
      "processing_time": 31.108752727508545,
      "citing_paper_id": "15139323",
      "cited_paper_id": 341734
    },
    {
      "context_text": "Guidelines for these features largely following the Thyme-TimeML speciﬁcations (Styler IV et al., 2014), a modiﬁcation of the ISO-TimeML (Pustejovsky et al., 2003) guidelines designed for clinical text.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only guidelines and specifications for event and temporal expressions in text.",
      "processing_time": 28.33538818359375,
      "citing_paper_id": "15139323",
      "cited_paper_id": 341734
    },
    {
      "context_text": "Causation has often been divided into CAUSE, EN-ABLE and PREVENT, as outlined in Hobbs (2005) and Wolff (2007), and implemented in Mirza et al. (2014) and Mostafazadeh et al. (2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and categorizations of causation.",
      "processing_time": 14.277674436569214,
      "citing_paper_id": "15139323",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "…event-time relations have also been developed, both for temporal information in the TimeML tradition (Pustejovsky et al., 2003; Styler IV et al., 2014; Minard et al., 2016), and causal structure (Bethard, 2007; Mostafazadeh et al., 2016; Mirza et al., 2014; Hong et al., 2016; Dunietz et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and research works. The context focuses on temporal and causal relations in various studies.",
      "processing_time": 28.779815912246704,
      "citing_paper_id": "15139323",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "This distinction has similarly been suggested in (Mostafazadeh et al., 2016), and bears practical similarity to the decisions in Hong et al. (2016) to allow multiple labels be-tween two events, or the layered annotation of Mirza et al. (2014) on top of temporal structure.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and annotations in other papers.",
      "processing_time": 27.838784217834473,
      "citing_paper_id": "15139323",
      "cited_paper_id": 6364632
    },
    {
      "context_text": "Glavas and Snajder (2014) annotated event coreference and subevent relations, but did not capture temporal or causal structure.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation mentions annotation of event coreference and subevent relations, but does not specify a dataset name. The context does not provide a clear, verifiable dataset.",
      "processing_time": 31.525590181350708,
      "citing_paper_id": "15139323",
      "cited_paper_id": 7000235
    },
    {
      "context_text": "Subevent relations corpora have also been annotated (Glava and najder, 2014; Hong et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'subevent relations corpora' but does not specify any named datasets. The context is too generic to identify specific datasets.",
      "processing_time": 30.797614574432373,
      "citing_paper_id": "15139323",
      "cited_paper_id": 7000235
    },
    {
      "context_text": "…FrameNet (Fillmore and Baker, 2000), Preposition annotation (Litkowski and Hargraves, 2005; Srikumar and Roth, 2013; Schneider et al., 2015) or AMR (Banarescu et al., 2013) have captured large quantities of temporal and causal relationships, but largely do so within very limited distances from a…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several resources but does not indicate their use as datasets for document-level event extraction. FrameNet, Preposition annotation, and AMR are mentioned as capturing relationships, but they are not used as datasets in the given context.",
      "processing_time": 33.75524044036865,
      "citing_paper_id": "15139323",
      "cited_paper_id": 7771402
    },
    {
      "context_text": "Advanced techniques also have been adopted to further improve EE, such as zero-shot learning (Huang et al., 2018), multi-modal integration (Zhang et al., 2017), and weakly supervised methods (Chen et al., 2017; Wang et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only techniques and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 30.56826639175415,
      "citing_paper_id": "202770954",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "Advanced techniques also have been adopted to further improve EE, such as zero-shot learning (Huang et al., 2018), multi-modal integration (Zhang et al., 2017), and weakly supervised methods (Chen et al., 2017; Wang et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only techniques and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 30.56826639175415,
      "citing_paper_id": "202770954",
      "cited_paper_id": 7322681
    },
    {
      "context_text": "Advanced techniques also have been adopted to further improve EE, such as zeroshot learning (Huang et al., 2018), multi-modal integration (Zhang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only techniques and methods. No dataset names are present in the citation span.",
      "processing_time": 29.440935134887695,
      "citing_paper_id": "202770954",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "Li’s Joint (Li et al., 2013) 64.7 44.4 52.7 DMCNN (Chen et al., 2015) 62.2 46.9 53.5 RBPB (Sha et al., 2016) 54.1 53.5 53.8 JRNN (Nguyen et al., 2016) (Ferguson et al., 2016) 32.1 5.0 8.7 CMU CS Event1 (Hsi et al., 2016) 31.2 4.9 8.4 Washington1 (Ferguson et al., 2016) 26.5 6.8 10.8 DMCNN (Chen et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 30.29059600830078,
      "citing_paper_id": "202770954",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Li’s Joint (Li et al., 2013) 64.7 44.4 52.7 DMCNN (Chen et al., 2015) 62.2 46.9 53.5 RBPB (Sha et al., 2016) 54.1 53.5 53.8 JRNN (Nguyen et al., 2016) (Ferguson et al., 2016) 32.1 5.0 8.7 CMU CS Event1 (Hsi et al., 2016) 31.2 4.9 8.4 Washington1 (Ferguson et al., 2016) 26.5 6.8 10.8 DMCNN (Chen et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 30.29059600830078,
      "citing_paper_id": "202770954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "We compare our models with various state-of-theart baselines on ACE 2005: (1) Feature-based methods, including Li’s joint (Li et al., 2013) and RBPB (Sha et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to compare models with state-of-the-art baselines, focusing on feature-based methods and structured prediction with global features."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE 2005' which is a well-known dataset for event extraction. The dataset is used to compare models with state-of-the-art baselines.",
      "processing_time": 38.23493790626526,
      "citing_paper_id": "202770954",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Li’s Joint (Li et al., 2013) 64.7 44.4 52.7 DMCNN (Chen et al., 2015) 62.2 46.9 53.5 RBPB (Sha et al., 2016) 54.1 53.5 53.8 JRNN (Nguyen et al., 2016) (Ferguson et al., 2016) 32.1 5.0 8.7 CMU CS Event1 (Hsi et al., 2016) 31.2 4.9 8.4 Washington1 (Ferguson et al., 2016) 26.5 6.8 10.8 DMCNN (Chen et al., 2015) 17.9 16.0 16.9 The results are shown in Table 3 and Table 4.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 30.784812211990356,
      "citing_paper_id": "202770954",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Li’s Joint (Li et al., 2013) 64.7 44.4 52.7 DMCNN (Chen et al., 2015) 62.2 46.9 53.5 RBPB (Sha et al., 2016) 54.1 53.5 53.8 JRNN (Nguyen et al., 2016) (Ferguson et al., 2016) 32.1 5.0 8.7 CMU CS Event1 (Hsi et al., 2016) 31.2 4.9 8.4 Washington1 (Ferguson et al., 2016) 26.5 6.8 10.8 DMCNN (Chen et al., 2015) 17.9 16.0 16.9 The results are shown in Table 3 and Table 4.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 30.784812211990356,
      "citing_paper_id": "202770954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "We compare our models with various state-of-the-art baselines on ACE 2005: (1) Feature-based methods, including Li’s joint (Li et al., 2013) and RBPB (Sha et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to compare models with state-of-the-art baselines, focusing on feature-based methods for joint event extraction and structured prediction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE 2005' as a dataset used for comparing models with state-of-the-art baselines. The dataset is clearly identified and relevant to document-level event extraction.",
      "processing_time": 38.9269745349884,
      "citing_paper_id": "202770954",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Traditional feature-based methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2010b,a; Huang and Riloff, 2012; Li et al., 2013) rely on hand-crafted features and patterns.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 29.670098543167114,
      "citing_paper_id": "202770954",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Since EE beneﬁts many NLP applications (Yang et al., 2003; Basile et al., 2014; Cheng and Erk, 2018), intensive efforts have been devoted to detecting events and extracting their event arguments.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general efforts in event extraction. No dataset names are present in the text.",
      "processing_time": 30.27966547012329,
      "citing_paper_id": "202770954",
      "cited_paper_id": 3425897
    },
    {
      "context_text": "Since EE beneﬁts many NLP applications (Yang et al., 2003; Basile et al., 2014; Cheng and Erk, 2018), intensive efforts have been devoted to detecting events and extracting their event arguments.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general efforts in event extraction. No dataset names are present in the text.",
      "processing_time": 30.27966547012329,
      "citing_paper_id": "202770954",
      "cited_paper_id": 18183751
    },
    {
      "context_text": ", 2018) and the neural module networks (NMNs) (Andreas et al., 2016), HMEAE adopts the NMNs to enable a flexible network architecture imitating the concept hierarchical structure, which can provide effective inductive bias for better classification performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and architectures. The cited paper 'Neural Module Networks' is referenced for its methodological contribution, not for providing a dataset.",
      "processing_time": 32.5380802154541,
      "citing_paper_id": "202770954",
      "cited_paper_id": 5276660
    },
    {
      "context_text": "…by the previous hierarchical clas-siﬁcation works (Qiu et al., 2011; Shimura et al., 2018; Han et al., 2018) and the neural module networks (NMNs) (Andreas et al., 2016), HMEAE adopts the NMNs to enable a ﬂexible network architecture imitating the concept hierarchical structure, which can…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the use of Neural Module Networks (NMNs) for a flexible network architecture.",
      "processing_time": 31.989955186843872,
      "citing_paper_id": "202770954",
      "cited_paper_id": 5276660
    },
    {
      "context_text": "…networks have been used to automatically represent textual semantics with low-dimensional vectors, and further extract event arguments based on those semantic vectors, including convolutional neural networks (Chen et al., 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 30.01378607749939,
      "citing_paper_id": "202770954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": ", 2015) and recurrent neural networks (Nguyen et al., 2016; Sha et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers and methods. No verifiable resources are identified.",
      "processing_time": 29.997181177139282,
      "citing_paper_id": "202770954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "(2) Vanilla neural network methods, including DMCNN (Chen et al., 2015) and JRNN (Nguyen et al., 2016).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions methods (DMCNN and JRNN) but does not reference any specific datasets. The context is focused on describing the methods used rather than the datasets.",
      "processing_time": 31.75590753555298,
      "citing_paper_id": "202770954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "We adopt Adam (Kingma and Ba, 2015) to minimize L ( θ ) .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions Adam, which is a method for stochastic optimization, not a dataset. No datasets are mentioned.",
      "processing_time": 29.07197594642639,
      "citing_paper_id": "202770954",
      "cited_paper_id": 6628106
    },
    {
      "context_text": ", 2018), multi-modal integration (Zhang et al., 2017), and weakly supervised methods (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets in the text.",
      "processing_time": 30.763493537902832,
      "citing_paper_id": "202770954",
      "cited_paper_id": 7322681
    },
    {
      "context_text": "Following the previous works (Liao and Grishman, 2010b; Chen et al., 2015), we use the same test set containing 40 newswire documents, a development set with 30 randomly selected documents and training set with the remaining 529 documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions specific sets of documents used for testing, development, and training, but does not provide a specific name for the dataset. The reference to 'newswire documents' suggests a domain-specific corpus, but it lacks a clear identifier.",
      "processing_time": 45.93480396270752,
      "citing_paper_id": "202770954",
      "cited_paper_id": 11187670
    },
    {
      "context_text": "Since EE benefits many NLP applications (Yang et al., 2003; Basile et al., 2014; Cheng and Erk, 2018), intensive efforts have been devoted to detecting events and extracting their event arguments.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general efforts towards event detection and argument extraction.",
      "processing_time": 29.40862202644348,
      "citing_paper_id": "202770954",
      "cited_paper_id": 18183751
    },
    {
      "context_text": "Inspired by the previous hierarchical classification works (Qiu et al., 2011; Shimura et al., 2018; Han et al., 2018) and the neural module networks (NMNs) (Andreas et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous works and methods.",
      "processing_time": 28.49401307106018,
      "citing_paper_id": "202770954",
      "cited_paper_id": 18954792
    },
    {
      "context_text": "Inspired by the previous hierarchical clas-siﬁcation works (Qiu et al., 2011; Shimura et al., 2018; Han et al., 2018) and the neural module networks (NMNs) (Andreas et al., 2016), HMEAE adopts the NMNs to enable a ﬂexible network architecture imitating the concept hierarchical structure, which can…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and previous works. The context focuses on the adoption of Neural Module Networks (NMNs) for a flexible network architecture.",
      "processing_time": 31.9603328704834,
      "citing_paper_id": "202770954",
      "cited_paper_id": 18954792
    },
    {
      "context_text": "On TAC KBP 2016, we compare our models with the top systems (Dubbin et al., 2016; Hsi et al., 2016; Ferguson et al., 2016) of the competition as well as DMCNN and DMBERT.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TAC KBP 2016"
      ],
      "dataset_descriptions": {
        "TAC KBP 2016": "Used to compare model performance with top systems from the competition, focusing on document-level event extraction and evaluation methodologies."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions TAC KBP 2016, which is a specific dataset used in a competition. The context indicates that the dataset is used for comparing model performance.",
      "processing_time": 39.71310758590698,
      "citing_paper_id": "202770954",
      "cited_paper_id": 44063424
    },
    {
      "context_text": "(Wang et al., 2021; Du and Cardie, 2020a) utilize the sequence labeling model BiLSTM-CRF (Zhang et al., 2015) for DEE.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BiLSTM-CRF) used for document-level event extraction.",
      "processing_time": 31.047783136367798,
      "citing_paper_id": "259858959",
      "cited_paper_id": 8950084
    },
    {
      "context_text": ", 2021; Du and Cardie, 2020a) utilize the sequence labeling model BiLSTM-CRF (Zhang et al., 2015) for DEE.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BiLSTM-CRF) used for document-level event extraction.",
      "processing_time": 31.28442096710205,
      "citing_paper_id": "259858959",
      "cited_paper_id": 8950084
    },
    {
      "context_text": ", 2015) firstly propose a neural pipeline model for event extraction and (Nguyen et al., 2016; Nguyen and Grishman, 2015; Liu et al., 2017; Zhou et al., 2020) further extend the pipeline model to recurrent neural networks and convolutional neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 31.720425605773926,
      "citing_paper_id": "259858959",
      "cited_paper_id": 10913456
    },
    {
      "context_text": ", 2015) firstly propose a neural pipeline model for event extraction and (Nguyen et al., 2016; Nguyen and Grishman, 2015; Liu et al., 2017; Zhou et al., 2020) further extend the pipeline model to recurrent neural networks and convolutional neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 31.720425605773926,
      "citing_paper_id": "259858959",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "(Chen et al., 2015) firstly propose a neural pipeline model for event extraction and (Nguyen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 29.078607082366943,
      "citing_paper_id": "259858959",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Considering most candidate arguments are negative samples and the imbalanced role distribution, we adopt focal loss (Lin et al., 2017) to make the training process focus more on useful positive samples, where α and γ are hyperparameters.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (focal loss) used to address class imbalance in training.",
      "processing_time": 30.72997736930847,
      "citing_paper_id": "259858959",
      "cited_paper_id": 47252984
    },
    {
      "context_text": "Compared with previous works (Liu et al., 2018; Wadden et al., 2019; Tong et al., 2020) focusing on sentence-level EAE, more and more recent works tend to explore documentlevel EAE (Wang et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous works and their focus on sentence-level or document-level event extraction.",
      "processing_time": 32.35740399360657,
      "citing_paper_id": "259858959",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Compared with previous works (Liu et al., 2018; Wadden et al., 2019; Tong et al., 2020) focusing on sentence-level EAE, more and more recent works tend to explore documentlevel EAE (Wang et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous works and their focus on sentence-level or document-level event extraction.",
      "processing_time": 32.35740399360657,
      "citing_paper_id": "259858959",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Compared with previous works (Liu et al., 2018; Wadden et al., 2019; Tong et al., 2020) focusing on sentence-level EAE, more and more recent works tend to explore documentlevel EAE (Wang et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous works and their focus on sentence-level or document-level event extraction.",
      "processing_time": 32.35740399360657,
      "citing_paper_id": "259858959",
      "cited_paper_id": 220047190
    },
    {
      "context_text": "To model the dependency of words in a sentence, (Liu et al., 2018; Yan et al., 2019; Fernandez Astudillo et al., 2020) leverage dependency trees to model semantic and syntactic relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for modeling dependencies using dependency trees.",
      "processing_time": 31.725666761398315,
      "citing_paper_id": "259858959",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "(Zheng et al., 2019) propose a transformer-based architecture and model",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model architecture. No dataset names are present in the citation context.",
      "processing_time": 32.798909425735474,
      "citing_paper_id": "259858959",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Compared with previous tagging-based and span-based methods like BERT-CRF and Two-Step, our SCPRG equipped with BERTbase yields an improvement of +8.46/+9.64 ∼ +6.36/+7.14 Span F1 and +7.68/+9.00 ∼ +5.38/+6.40 Head F1 on dev/test set, showing that our SCPRG framework has superiority in excluding impossible candidate spans and solving the imbalance of data distribution problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model performance metrics and comparisons. The citation is focused on methodological improvements.",
      "processing_time": 33.575602293014526,
      "citing_paper_id": "259858959",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al., 2020), span-based methods like Two-Step (Zhang et al., 2020b), Two-StepTCD (Ebner et al., 2020), TSAR (Xu et al., 2022), and other generation-based methods such as FEAE (Wei et al., 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al., 2021), EA2E (Zeng et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only various models and methods used for document-level event argument extraction (EAE).",
      "processing_time": 34.572025537490845,
      "citing_paper_id": "259858959",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al., 2020), span-based methods like Two-Step (Zhang et al., 2020b), Two-StepTCD (Ebner et al., 2020), TSAR (Xu et al., 2022), and other generation-based methods such as FEAE (Wei et al., 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al., 2021), EA2E (Zeng et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only various models and methods used for document-level event argument extraction (EAE).",
      "processing_time": 34.572025537490845,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al., 2020), span-based methods like Two-Step (Zhang et al., 2020b), Two-StepTCD (Ebner et al., 2020), TSAR (Xu et al., 2022), and other generation-based methods such as FEAE (Wei et al., 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al., 2021), EA2E (Zeng et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only various models and methods used for document-level event argument extraction (EAE).",
      "processing_time": 34.572025537490845,
      "citing_paper_id": "259858959",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al., 2020), span-based methods like Two-Step (Zhang et al., 2020b), Two-StepTCD (Ebner et al., 2020), TSAR (Xu et al., 2022), and other generation-based methods such as FEAE (Wei et al., 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al., 2021), EA2E (Zeng et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only various models and methods used for document-level event argument extraction (EAE).",
      "processing_time": 34.572025537490845,
      "citing_paper_id": "259858959",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is focused on comparing different tagging-based methods for document-level event argument extraction.",
      "processing_time": 35.41979694366455,
      "citing_paper_id": "259858959",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Some methods using transformer-based pre-trained model (Wadden et al., 2019; Wang et al., 2019; Tong et al., 2020; Lu et al., 2021; Liu et al., 2022b) also achieve remarkable performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 35.41810631752014,
      "citing_paper_id": "259858959",
      "cited_paper_id": 174799895
    },
    {
      "context_text": "Some methods using transformer-based pre-trained model (Wadden et al., 2019; Wang et al., 2019; Tong et al., 2020; Lu et al., 2021; Liu et al., 2022b) also achieve remarkable performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 35.41810631752014,
      "citing_paper_id": "259858959",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Some methods using transformer-based pre-trained model (Wadden et al., 2019; Wang et al., 2019; Tong et al., 2020; Lu et al., 2021; Liu et al., 2022b) also achieve remarkable performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 35.41810631752014,
      "citing_paper_id": "259858959",
      "cited_paper_id": 220047190
    },
    {
      "context_text": "Some methods using transformer-based pre-trained model (Wadden et al., 2019; Wang et al., 2019; Tong et al., 2020; Lu et al., 2021; Liu et al., 2022b) also achieve remarkable performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 35.41810631752014,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248721950
    },
    {
      "context_text": "(Wadden et al., 2019) enumerates all possible spans and construct span graphs with graph neural netpreve nter trans porte r pass enge r origindesti natio n",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for constructing span graphs using graph neural networks.",
      "processing_time": 34.716572761535645,
      "citing_paper_id": "259858959",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "BART-Genlarge is based on BARTlarge (Lewis et al., 2019) which is pre-trained on the same corpus.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BART-Genlarge and BARTlarge, which are models, not datasets. No specific dataset is mentioned or used in the context.",
      "processing_time": 36.340285301208496,
      "citing_paper_id": "259858959",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "First, when we remove span-trigger-based contextual pooling (STCP) module, both Span F1 and\n4BART-Genlarge is based on BARTlarge (Lewis et al., 2019) which is pre-trained on the same corpus.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BARTlarge) and a method (STCP). No verifiable datasets are referenced.",
      "processing_time": 36.458112478256226,
      "citing_paper_id": "259858959",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "In this section, we show the complete cooccurrence frequency matrix which contains all roles in RAMS test set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS test set"
      ],
      "dataset_descriptions": {
        "RAMS test set": "Used to generate and display the cooccurrence frequency matrix of roles, focusing on document-level event extraction and role relationships."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS test set' as a specific dataset used to show the cooccurrence frequency matrix. The dataset is relevant to document-level event extraction.",
      "processing_time": 43.64863181114197,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Other span based methods (Ebner et al., 2020; Zhang et al., 2020b) predict the argument roles for candidate text spans with a maximum length limitation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets in the text.",
      "processing_time": 36.90576982498169,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al., 2020), span-based methods like Two-Step (Zhang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 14.48365831375122,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Additionally, when removing role-based latent information guidance (RLIG) module5, the performance of SCPRGbase/ SCPRGlarge drops sharply by 1.03/1.04 Span F1 and 1.58/1.2 Head F1 on RAMS test set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the performance of SCPRGbase and SCPRGlarge models after removing the RLIG module, focusing on Span F1 and Head F1 metrics."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS test set, which is a specific dataset used for evaluating the performance of the models after removing the RLIG module.",
      "processing_time": 46.29546809196472,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": ", 2022), which needs to solve long-distance dependency (Ebner et al., 2020) and cross-sentence inference (Li et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to solving long-distance dependency and cross-sentence inference. No verifiable resources are identified.",
      "processing_time": 38.519935846328735,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Datasets and Metrics We evaluate the proposed model on two large-scale public document-level\nEAE datasets, RAMSv1.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMSv1"
      ],
      "dataset_descriptions": {
        "RAMSv1": "Used to evaluate the proposed model on document-level event argument extraction, focusing on multi-sentence argument linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMSv1' as a document-level EAE dataset used for evaluation. The name is specific and follows the required format.",
      "processing_time": 46.08581495285034,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "In the main body of the paper, we conduct ablation study on RAMS dataset for SCPRGbase and SCPRGlarge.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for conducting ablation studies on SCPRGbase and SCPRGlarge, focusing on document-level event extraction performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for document-level event extraction.",
      "processing_time": 44.11556529998779,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Figure 7: A t-SNE visualization example from RAMS, where embeddings of arguments and roles are from 5 different documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to visualize embeddings of arguments and roles from multiple documents, focusing on document-level event extraction and argument linking."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'RAMS' as a source of embeddings for a t-SNE visualization, which suggests it is a dataset used for document-level event extraction.",
      "processing_time": 46.288057804107666,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Following (Xu et al., 2022), we report the Span F1 and Head F1 on dev and test sets for RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate document-level event argument extraction, reporting Span F1 and Head F1 on development and test sets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for evaluation. The citation intent is to report performance metrics on this dataset.",
      "processing_time": 46.63254475593567,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Following (Xu et al., 2022), we report the Span F1 and Head F1 on dev and test sets for RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate document-level event argument extraction, reporting Span F1 and Head F1 on development and test sets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for evaluation. The citation intent is to report performance metrics on this dataset.",
      "processing_time": 46.63254475593567,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Moreover, many roles co-occur in multiple events (Ebner et al., 2020; Li et al., 2021), which may have close semantic relevance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to roles co-occurring in multiple events. No verifiable resources are identified.",
      "processing_time": 39.04736948013306,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": ", 2020b), Two-StepTCD (Ebner et al., 2020), TSAR (Xu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods or models. There are no clear identifiers for datasets within the given context.",
      "processing_time": 39.03261733055115,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "To better illustrate the capabilities of our components, we conduct ablation study on RAMS dataset as shown in Table 4.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to conduct an ablation study on document-level event extraction, evaluating the performance of different components in the system."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for document-level event extraction.",
      "processing_time": 45.45637798309326,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Specifically, we count and visualize the frequency of co-occurrence between 15 most frequent roles in RAMS dataset in Figure 2.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS dataset"
      ],
      "dataset_descriptions": {
        "RAMS dataset": "Used to count and visualize the frequency of co-occurrence between the 15 most frequent roles, focusing on event extraction and argument linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'RAMS dataset' which is a specific, verifiable dataset used for event extraction and argument linking.",
      "processing_time": 47.5066032409668,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Figure 1: A document from RAMS (Ebner et al., 2020) dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to provide a document example for argument linking, focusing on multi-sentence structures and their relationships in the context of document-level event extraction."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'RAMS' as a dataset, which is a multi-word proper noun and appears to be a specific, verifiable resource. The cited paper title does not contradict this interpretation.",
      "processing_time": 49.05029821395874,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "• Extensive experiments show that SCPRG outperforms previous start-of-the-art models, with 1.13 F1 and 2.64 F1 improvements on public RAMS and WikiEvents (Li et al., 2021) datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the performance of the SCPRG model, specifically measuring F1 score improvements over previous state-of-the-art models.",
        "WikiEvents": "Used to evaluate the performance of the SCPRG model, specifically measuring F1 score improvements over previous state-of-the-art models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used to evaluate the performance of the SCPRG model.",
      "processing_time": 53.06123423576355,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Table 2 shows the experimental results on both dev and test set in RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate experimental results on document-level event extraction, focusing on performance metrics on both development and test sets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for evaluation in the research.",
      "processing_time": 45.648138999938965,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "63M 48.33 54.04 47.52 55.61 -ASE 372.90M 49.80 56.31 51.73 58.48\nTable 4: Ablation Study on RAMS for SCPRG.\nlarity between latent role representations from two events in RAMS dataset in Fig 6.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for an ablation study on SCPRG, analyzing the clarity between latent role representations from two events in the dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a well-known resource for document-level event extraction. The dataset is used for an ablation study and to analyze the clarity between latent role representations from two events.",
      "processing_time": 49.42801380157471,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We train SCPRG for 50 epochs for RAMS dataset and 100 epochs for WikiEvents dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to train the SCPRG model for 50 epochs, focusing on document-level event extraction and argument linking.",
        "WikiEvents": "Used to train the SCPRG model for 100 epochs, focusing on document-level event extraction and argument linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for training the SCPRG model. These datasets are relevant to document-level event extraction.",
      "processing_time": 53.99215054512024,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": ", 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models or methods. No dataset names are present in the text.",
      "processing_time": 39.02943181991577,
      "citing_paper_id": "259858959",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "(Wang et al., 2021; Du and Cardie, 2020a) utilize the sequence labeling model BiLSTM-CRF (Zhang et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (BiLSTM-CRF). The context is about utilizing a sequence labeling model, which is not a dataset.",
      "processing_time": 41.37102222442627,
      "citing_paper_id": "259858959",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "(Wang et al., 2021; Du and Cardie, 2020a) utilize the sequence labeling model BiLSTM-CRF (Zhang et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (BiLSTM-CRF). The context is about utilizing a sequence labeling model, which is not a dataset.",
      "processing_time": 41.37102222442627,
      "citing_paper_id": "259858959",
      "cited_paper_id": 235254286
    },
    {
      "context_text": "and dialogue systems (Zhang et al., 2020a) for presenting unstructured text containing event information in structured form.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to unstructured text containing event information. No clear, verifiable dataset names are present.",
      "processing_time": 40.49931454658508,
      "citing_paper_id": "259858959",
      "cited_paper_id": 220524732
    },
    {
      "context_text": ", 2021) formulate the problem as conditional generation and (Du et al., 2021) regards the problem as a sequence-to-sequence task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only approaches to the problem of document-level event entity extraction.",
      "processing_time": 39.02391338348389,
      "citing_paper_id": "259858959",
      "cited_paper_id": 231728756
    },
    {
      "context_text": ", 2022) try to construct graphs based on heuristic rules (Xu et al., 2021; Liu et al., 2022a) or syntactic structures (Xu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 40.49505591392517,
      "citing_paper_id": "259858959",
      "cited_paper_id": 235253912
    },
    {
      "context_text": ", 2022) try to construct graphs based on heuristic rules (Xu et al., 2021; Liu et al., 2022a) or syntactic structures (Xu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 40.49505591392517,
      "citing_paper_id": "259858959",
      "cited_paper_id": 252626402
    },
    {
      "context_text": "Base on their architecture, (Xu et al., 2021) construct a heterogeneous graph and a tracker module to capture the interdependency among events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction using a heterogeneous graph and a tracker module.",
      "processing_time": 40.15361475944519,
      "citing_paper_id": "259858959",
      "cited_paper_id": 235253912
    },
    {
      "context_text": ", 2022), and other generation-based methods such as FEAE (Wei et al., 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 14.416618585586548,
      "citing_paper_id": "259858959",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "(Wei et al., 2021) reformulate the task as reading a comprehension task.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reformulation of a task. No verifiable resources are identified.",
      "processing_time": 39.836430311203,
      "citing_paper_id": "259858959",
      "cited_paper_id": 236460308
    },
    {
      "context_text": ", 2022a) or syntactic structures (Xu et al., 2022) and model logical reasoning with Graph Neural Networks (Kipf and Welling, 2016; Zeng et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 39.99797534942627,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Moreover, (Xu et al., 2022) propose a twostream encoder with AMR-guided graph to solve long-distance dependency problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or model. The title confirms the focus on a model rather than a dataset.",
      "processing_time": 40.72642707824707,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "However, many previous works (Li et al., 2021; Xu et al., 2022) only utilize pre-trained transformerar X iv :2 31 0.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous works. There are no clear identifiers for datasets in the given context.",
      "processing_time": 40.72490620613098,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Span-Trigger-based Contextual Pooling For a candidate span ranging from wi to wj , most previous span-based methods(Zhang et al., 2020b; Xu et al., 2022) represent it through the average pooling of the hidden state of tokens within this span:",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers are used to describe previous work on span-based methods, not to introduce or use datasets.",
      "processing_time": 42.76389455795288,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": ", 2020), TSAR (Xu et al., 2022), and other generation-based methods such as FEAE (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 40.720744371414185,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": ", 2020) focusing on sentence-level EAE, more and more recent works tend to explore documentlevel EAE (Wang et al., 2022b; Yang et al., 2021; Xu et al., 2022), which needs to solve long-distance dependency (Ebner et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to document-level event argument extraction (EAE) and the challenge of long-distance dependencies.",
      "processing_time": 41.54207158088684,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Finally, the boundary loss is defined to detect the start and end position following (Xu et al., 2022): Lb = − ∑|D| i=1[y s i logP s i + (1− ys i ) log(1− P s i ) +ye i logP e i + (1− ye i ) log(1− P e i )], (7) where ys i and y e i denote golden labels and P s i = sigmoid(W4h start i ) and P e i = sigmoid(W5h end i ) are the probabilities of the word wi predicted to be the first or last word of a golden argument span.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for defining boundary loss in the context of document-level event argument extraction.",
      "processing_time": 40.717936754226685,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Besides, (Ren et al., 2022) integrate argument roles into document encoding to aware tokens of multiple role information for nested arguments problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for integrating argument roles into document encoding.",
      "processing_time": 39.00121212005615,
      "citing_paper_id": "259858959",
      "cited_paper_id": 252819226
    },
    {
      "context_text": ", 2022c; Chen and Kou, 2023) and Image Semantic Segmentation (Zhang et al., 2022), its impact on Event Argument Extraction in natural language processing has been relatively limited.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to 'Event Argument Extraction' and 'Image Semantic Segmentation'. No specific dataset names are provided.",
      "processing_time": 42.74358415603638,
      "citing_paper_id": "259858959",
      "cited_paper_id": 254043718
    },
    {
      "context_text": "Although deep learning has achieved significant success in many areas of computer vision (Li et al., 2022; Wang et al., 2023, 2022a; Pan et al., 2023; Wang and Chen, 2023) like 3D Scene Graph Generation (Liu et al., 2022c; Chen and Kou, 2023) and Image Semantic Segmentation (Zhang et al., 2022), its impact on Event Argument Extraction in natural language processing has been relatively limited.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research and methods. There are no verifiable resources or datasets mentioned.",
      "processing_time": 41.53622245788574,
      "citing_paper_id": "259858959",
      "cited_paper_id": 254043718
    },
    {
      "context_text": "Although deep learning has achieved significant success in many areas of computer vision (Li et al., 2022; Wang et al., 2023, 2022a; Pan et al., 2023; Wang and Chen, 2023) like 3D Scene Graph Generation (Liu et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to deep learning successes in computer vision and 3D Scene Graph Generation. No verifiable resources are identified.",
      "processing_time": 43.02593111991882,
      "citing_paper_id": "259858959",
      "cited_paper_id": 259716313
    },
    {
      "context_text": "Un-supervised methods can extract large numbers of events without using labeled data (Chambers and Jurafsky, 2011; Cheung et al., 2013; Huang et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only unsupervised methods for event extraction. No verifiable resources are identified.",
      "processing_time": 41.14337968826294,
      "citing_paper_id": "12108307",
      "cited_paper_id": 278288
    },
    {
      "context_text": "Un-supervised methods can extract large numbers of events without using labeled data (Chambers and Jurafsky, 2011; Cheung et al., 2013; Huang et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only unsupervised methods for event extraction. No verifiable resources are identified.",
      "processing_time": 41.14337968826294,
      "citing_paper_id": "12108307",
      "cited_paper_id": 12808163
    },
    {
      "context_text": "Unsupervised methods can extract large numbers of events without using labeled data (Chambers and Jurafsky, 2011; Cheung et al., 2013; Huang et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only unsupervised methods for event extraction. No dataset names are present in the context.",
      "processing_time": 41.530625104904175,
      "citing_paper_id": "12108307",
      "cited_paper_id": 278288
    },
    {
      "context_text": "(Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013, 2014; Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. The titles of the cited papers do not provide additional context about datasets.",
      "processing_time": 42.39094424247742,
      "citing_paper_id": "12108307",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "(Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013, 2014; Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. The titles of the cited papers do not provide additional context about datasets.",
      "processing_time": 42.39094424247742,
      "citing_paper_id": "12108307",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "(Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013, 2014; Chen et al., 2015; Nguyen and Grishman, 2015; Nguyen et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. The titles of the cited papers do not provide additional context about datasets.",
      "processing_time": 42.39094424247742,
      "citing_paper_id": "12108307",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "To this end, so far most methods (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2014; Hong et al., 2011; Ji and Grishman, 2008) usually adopted supervised learning paradigm which relies on elaborate human-annotated data, such as ACE 2005 1 , to train extractors.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to train supervised event extractors, focusing on human-annotated data for improving extraction accuracy."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE 2005' as a human-annotated dataset used for training event extractors, which is relevant to document-level event extraction.",
      "processing_time": 49.760767221450806,
      "citing_paper_id": "12108307",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "To this end, so far most methods (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2014; Hong et al., 2011; Ji and Grishman, 2008) usually adopted supervised learning paradigm which relies on elaborate human-annotated data, such as ACE 2005 1 , to train extractors.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to train supervised event extractors, focusing on human-annotated data for improving extraction accuracy."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE 2005' as a human-annotated dataset used for training event extractors, which is relevant to document-level event extraction.",
      "processing_time": 49.760767221450806,
      "citing_paper_id": "12108307",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "To this end, so far most methods (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2014; Hong et al., 2011; Ji and Grishman, 2008) usually adopted supervised learning paradigm which relies on elaborate human-annotated data, such as ACE 2005 1 , to train extractors.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to train supervised event extractors, focusing on human-annotated data for improving extraction accuracy."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE 2005' as a human-annotated dataset used for training event extractors, which is relevant to document-level event extraction.",
      "processing_time": 49.760767221450806,
      "citing_paper_id": "12108307",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Distant supervision have been used in relation extraction for automatically labeling training data (Mintz et al., 2009; Hinton et al., 2012; Krause et al., 2012; Krishnamurthy and Mitchell, 2012; Berant et al., 2013; Surdeanu et al., 2012; Zeng et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses the use of distant supervision for relation extraction but does not mention any specific datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 43.01733136177063,
      "citing_paper_id": "12108307",
      "cited_paper_id": 2605890
    },
    {
      "context_text": "Distant supervision have been used in relation extraction for automatically labeling training data (Mintz et al., 2009; Hinton et al., 2012; Krause et al., 2012; Krishnamurthy and Mitchell, 2012; Berant et al., 2013; Surdeanu et al., 2012; Zeng et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses the use of distant supervision for relation extraction but does not mention any specific datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 43.01733136177063,
      "citing_paper_id": "12108307",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "Distant supervision have been used in relation extraction for automatically labeling training data (Mintz et al., 2009; Hinton et al., 2012; Krause et al., 2012; Krishnamurthy and Mitchell, 2012; Berant et al., 2013; Surdeanu et al., 2012; Zeng et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses the use of distant supervision for relation extraction but does not mention any specific datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 43.01733136177063,
      "citing_paper_id": "12108307",
      "cited_paper_id": 5633240
    },
    {
      "context_text": "Distant supervision have been used in relation extraction for automatically labeling training data (Mintz et al., 2009; Hinton et al., 2012; Krause et al., 2012; Krishnamurthy and Mitchell, 2012; Berant et al., 2013; Surdeanu et al., 2012; Zeng et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses the use of distant supervision for relation extraction but does not mention any specific datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 43.01733136177063,
      "citing_paper_id": "12108307",
      "cited_paper_id": 5869747
    },
    {
      "context_text": "Distant supervision have been used in relation extraction for automatically labeling training data (Mintz et al., 2009; Hinton et al., 2012; Krause et al., 2012; Krishnamurthy and Mitchell, 2012; Berant et al., 2013; Surdeanu et al., 2012; Zeng et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses the use of distant supervision for relation extraction but does not mention any specific datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 43.01733136177063,
      "citing_paper_id": "12108307",
      "cited_paper_id": 6401679
    },
    {
      "context_text": "Distant supervision have been used in relation extraction for automatically labeling training data (Mintz et al., 2009; Hinton et al., 2012; Krause et al., 2012; Krishnamurthy and Mitchell, 2012; Berant et al., 2013; Surdeanu et al., 2012; Zeng et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses the use of distant supervision for relation extraction but does not mention any specific datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 43.01733136177063,
      "citing_paper_id": "12108307",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "However, our automatically labeled data face a noise problem, which is a intrinsic problem of using DS to construct training data (Hoffmann et al., 2011; Surdeanu et al., 2012).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'automatically labeled data' and 'DS to construct training data', but does not specify a named dataset. The cited papers do not provide additional specific dataset names.",
      "processing_time": 44.03203988075256,
      "citing_paper_id": "12108307",
      "cited_paper_id": 5869747
    },
    {
      "context_text": "However, our automatically labeled data face a noise problem, which is a intrinsic problem of using DS to construct training data (Hoffmann et al., 2011; Surdeanu et al., 2012).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'automatically labeled data' and 'DS to construct training data', but does not specify a named dataset. The cited papers do not provide additional specific dataset names.",
      "processing_time": 44.03203988075256,
      "citing_paper_id": "12108307",
      "cited_paper_id": 16483125
    },
    {
      "context_text": ", 2012; Krishnamurthy and Mitchell, 2012; Berant et al., 2013; Surdeanu et al., 2012; Zeng et al., 2015). But DS for RE cannot directly use for EE. For the reasons that an event is more complicated than a relation and the task of EE is more difficult than RE. The best reported supervised RE and EE system got a F1-score of 88.0% (Wang et al., 2016) and 55.4% (Nguyen et al., 2016) respectively. Reschke et al. (2014) extended the distant supervision approach to fill slots in plane crash.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the challenges and performance metrics of relation extraction (RE) and event extraction (EE) systems.",
      "processing_time": 42.72682785987854,
      "citing_paper_id": "12108307",
      "cited_paper_id": 6401679
    },
    {
      "context_text": "Following (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2013), we used the same test set with 40 newswire articles and the same development set with 30 documents and the rest 529 documents are used for ACE training set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE training set"
      ],
      "dataset_descriptions": {
        "ACE training set": "Used for training event extraction models, consisting of 529 documents. The dataset supports the evaluation of model performance on newswire articles and development documents."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific sets of documents used for testing, development, and training, which are part of the ACE dataset. The dataset is clearly identified and used for evaluating event extraction models.",
      "processing_time": 51.47188425064087,
      "citing_paper_id": "12108307",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Following (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2013), we used the same test set with 40 newswire articles and the same development set with 30 documents and the rest 529 documents are used for ACE training set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE training set"
      ],
      "dataset_descriptions": {
        "ACE training set": "Used for training event extraction models, consisting of 529 documents. The dataset supports the evaluation of model performance on newswire articles and development documents."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific sets of documents used for testing, development, and training, which are part of the ACE dataset. The dataset is clearly identified and used for evaluating event extraction models.",
      "processing_time": 51.47188425064087,
      "citing_paper_id": "12108307",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "4% (Nguyen et al., 2016) respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a percentage and a reference to a paper. The cited paper title suggests a method or model, not a dataset.",
      "processing_time": 43.80197310447693,
      "citing_paper_id": "12108307",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "(3) Nguyen’s JRNN , which is the state-of-the-arts system (Nguyen et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (JRNN) rather than a dataset. There are no specific datasets mentioned in the citation context.",
      "processing_time": 41.801528453826904,
      "citing_paper_id": "12108307",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "And DS for RE assumes that if two entities have a relationship in a known knowledge base, then all sentences that mention these two entities will express that relationship in some way (Mintz et al., 2009).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Distant Supervision) and a concept (knowledge base).",
      "processing_time": 14.784583806991577,
      "citing_paper_id": "12108307",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "Following previous work (Mintz et al., 2009) in distant supervised RE, we evaluate our method in two ways: held-out and manual evaluation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation methods. The cited paper title confirms the focus on methodology rather than a specific dataset.",
      "processing_time": 42.37183451652527,
      "citing_paper_id": "12108307",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "(2) Chen’s DMCNN , which is the best reported CNN-based system (Chen et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (DMCNN) rather than a dataset. No specific dataset is referenced in the citation context.",
      "processing_time": 41.494502544403076,
      "citing_paper_id": "12108307",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "The Dynamic Multi-pooling Convolutional Neural Networks (DMCNNs) is the best reported CNN-based model for event extraction (Chen et al., 2015) by using human-annotated training data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'human-annotated training data' but does not specify a named dataset. The reference is to a method (DMCNNs) rather than a dataset.",
      "processing_time": 44.03258657455444,
      "citing_paper_id": "12108307",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "(2) Chen’s DMCNN, which is the best reported CNN-based system (Chen et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (DMCNN) rather than a dataset. No specific dataset is referenced in the citation context.",
      "processing_time": 40.669559478759766,
      "citing_paper_id": "12108307",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Previous researches focused on sentence-level RE, which predicts the relationship between entities in a single sentence [Zeng et al., 2015; Zhang et al., 2018; Baldini Soares et al., 2019].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous research on sentence-level relation extraction.",
      "processing_time": 40.303101778030396,
      "citing_paper_id": "248300064",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "C L\n] 4\nA ug\n2 02\n2\nTo extract such complex inter-sentence relations, most current approaches constructed a document-level graph based on heuristics, structured attention, or dependency structures [Zeng et al., 2020; Nan et al., 2020; Christopoulou et al., 2019; Wang et al., 2020], and then perform inference with graph convolutional network (GCN) [Guo et al., 2019; Kipf and Welling, 2016] on the document-level graph.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses methods and models for constructing document-level graphs and performing inference using GCNs, but does not mention any specific datasets.",
      "processing_time": 41.306801319122314,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3144218
    },
    {
      "context_text": "C L\n] 4\nA ug\n2 02\n2\nTo extract such complex inter-sentence relations, most current approaches constructed a document-level graph based on heuristics, structured attention, or dependency structures [Zeng et al., 2020; Nan et al., 2020; Christopoulou et al., 2019; Wang et al., 2020], and then perform inference with graph convolutional network (GCN) [Guo et al., 2019; Kipf and Welling, 2016] on the document-level graph.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses methods and models for constructing document-level graphs and performing inference using GCNs, but does not mention any specific datasets.",
      "processing_time": 41.306801319122314,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3292002
    },
    {
      "context_text": "C L\n] 4\nA ug\n2 02\n2\nTo extract such complex inter-sentence relations, most current approaches constructed a document-level graph based on heuristics, structured attention, or dependency structures [Zeng et al., 2020; Nan et al., 2020; Christopoulou et al., 2019; Wang et al., 2020], and then perform inference with graph convolutional network (GCN) [Guo et al., 2019; Kipf and Welling, 2016] on the document-level graph.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses methods and models for constructing document-level graphs and performing inference using GCNs, but does not mention any specific datasets.",
      "processing_time": 41.306801319122314,
      "citing_paper_id": "248300064",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "C L\n] 4\nA ug\n2 02\n2\nTo extract such complex inter-sentence relations, most current approaches constructed a document-level graph based on heuristics, structured attention, or dependency structures [Zeng et al., 2020; Nan et al., 2020; Christopoulou et al., 2019; Wang et al., 2020], and then perform inference with graph convolutional network (GCN) [Guo et al., 2019; Kipf and Welling, 2016] on the document-level graph.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses methods and models for constructing document-level graphs and performing inference using GCNs, but does not mention any specific datasets.",
      "processing_time": 41.306801319122314,
      "citing_paper_id": "248300064",
      "cited_paper_id": 190001673
    },
    {
      "context_text": ", 2020], and then perform inference with graph convolutional network (GCN) [Guo et al., 2019; Kipf and Welling, 2016] on the document-level graph.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The context is focused on the use of graph convolutional networks for inference on document-level graphs.",
      "processing_time": 44.024744510650635,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3144218
    },
    {
      "context_text": ", 2020], and then perform inference with graph convolutional network (GCN) [Guo et al., 2019; Kipf and Welling, 2016] on the document-level graph.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The context is focused on the use of graph convolutional networks for inference on document-level graphs.",
      "processing_time": 44.024744510650635,
      "citing_paper_id": "248300064",
      "cited_paper_id": 190001673
    },
    {
      "context_text": "On the DocRED Dataset, we choose the following two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang et al., 2020], GAIN [Zeng et al., 2020], and HeterGSAN [Xu et al., 2021b].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate graph-based models on document-level relation extraction, focusing on the performance of various graph convolutional network approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the DocRED Dataset, which is used for evaluating graph-based models on document-level relation extraction tasks.",
      "processing_time": 48.5735080242157,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3144218
    },
    {
      "context_text": "On the DocRED Dataset, we choose the following two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang et al., 2020], GAIN [Zeng et al., 2020], and HeterGSAN [Xu et al., 2021b].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate graph-based models on document-level relation extraction, focusing on the performance of various graph convolutional network approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the DocRED Dataset, which is used for evaluating graph-based models on document-level relation extraction tasks.",
      "processing_time": 48.5735080242157,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3292002
    },
    {
      "context_text": "On the DocRED Dataset, we choose the following two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang et al., 2020], GAIN [Zeng et al., 2020], and HeterGSAN [Xu et al., 2021b].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate graph-based models on document-level relation extraction, focusing on the performance of various graph convolutional network approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the DocRED Dataset, which is used for evaluating graph-based models on document-level relation extraction tasks.",
      "processing_time": 48.5735080242157,
      "citing_paper_id": "248300064",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "On the DocRED Dataset, we choose the following two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang et al., 2020], GAIN [Zeng et al., 2020], and HeterGSAN [Xu et al., 2021b].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate graph-based models on document-level relation extraction, focusing on the performance of various graph convolutional network approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the DocRED Dataset, which is used for evaluating graph-based models on document-level relation extraction tasks.",
      "processing_time": 48.5735080242157,
      "citing_paper_id": "248300064",
      "cited_paper_id": 190001673
    },
    {
      "context_text": "On the DocRED Dataset, we choose the following two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang et al., 2020], GAIN [Zeng et al., 2020], and HeterGSAN [Xu et al., 2021b].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate graph-based models on document-level relation extraction, focusing on the performance of various graph convolutional network approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the DocRED Dataset, which is used for evaluating graph-based models on document-level relation extraction tasks.",
      "processing_time": 48.5735080242157,
      "citing_paper_id": "248300064",
      "cited_paper_id": 221836081
    },
    {
      "context_text": "…graph based on heuristics, structured attention, or dependency structures [Zeng et al., 2020; Nan et al., 2020; Christopoulou et al., 2019; Wang et al., 2020], and then perform inference with graph convolutional network (GCN) [Guo et al., 2019; Kipf and Welling, 2016] on the document-level graph.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 42.35814118385315,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3144218
    },
    {
      "context_text": "…graph based on heuristics, structured attention, or dependency structures [Zeng et al., 2020; Nan et al., 2020; Christopoulou et al., 2019; Wang et al., 2020], and then perform inference with graph convolutional network (GCN) [Guo et al., 2019; Kipf and Welling, 2016] on the document-level graph.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 42.35814118385315,
      "citing_paper_id": "248300064",
      "cited_paper_id": 190001673
    },
    {
      "context_text": "…we choose the following two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on describing the types of models used as baselines, particularly graph-based models.",
      "processing_time": 44.019901752471924,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3144218
    },
    {
      "context_text": "• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on describing the use of graph-based models and graph convolutional networks, which are not datasets.",
      "processing_time": 44.72212886810303,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3144218
    },
    {
      "context_text": "• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on describing the use of graph-based models and graph convolutional networks, which are not datasets.",
      "processing_time": 44.72212886810303,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3292002
    },
    {
      "context_text": "• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on describing the use of graph-based models and graph convolutional networks, which are not datasets.",
      "processing_time": 44.72212886810303,
      "citing_paper_id": "248300064",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "Specifically, they first constructed a graph structure from the document, and then applied the GCN [Kipf and Welling, 2016; Huang et al., 2017] to the graph to complete logical reasoning.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes the use of GCN (Graph Convolutional Networks) for constructing a graph structure from documents and applying it for logical reasoning. No specific datasets are mentioned.",
      "processing_time": 44.397618770599365,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3144218
    },
    {
      "context_text": "Specifically, they first constructed a graph structure from the document, and then applied the GCN [Kipf and Welling, 2016; Huang et al., 2017] to the graph to complete logical reasoning.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes the use of GCN (Graph Convolutional Networks) for constructing a graph structure from documents and applying it for logical reasoning. No specific datasets are mentioned.",
      "processing_time": 44.397618770599365,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3292002
    },
    {
      "context_text": "Specifically, they first constructed a graph structure from the document, and then applied the GCN [Kipf and Welling, 2016; Huang et al., 2017] to the graph to complete logical reasoning.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes the use of GCN (Graph Convolutional Networks) for constructing a graph structure from documents and applying it for logical reasoning. No specific datasets are mentioned.",
      "processing_time": 44.397618770599365,
      "citing_paper_id": "248300064",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "Specifically, they first constructed a graph structure from the document, and then applied the GCN [Kipf and Welling, 2016; Huang et al., 2017] to the graph to complete logical reasoning.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes the use of GCN (Graph Convolutional Networks) for constructing a graph structure from documents and applying it for logical reasoning. No specific datasets are mentioned.",
      "processing_time": 44.397618770599365,
      "citing_paper_id": "248300064",
      "cited_paper_id": 190001673
    },
    {
      "context_text": "…two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on describing the types of models used as baselines, particularly graph-based models and their applications.",
      "processing_time": 44.71837329864502,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3292002
    },
    {
      "context_text": "…biomedical datasets, CDR and GDA, we compared our model with a large number of baseline models and recent state-of-the-art models including BRAN [Verga et al., 2018], EoG [Christopoulou et al., 2019], LSR [Nan et al., 2020], DHG [Zhang et al., 2020], GLRE [Wang et al., 2020], SciBERT [Beltagy…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "CDR": "Used to compare model performance in chemical-disease relation extraction, focusing on identifying relations between chemicals and diseases in biomedical texts.",
        "GDA": "Used to evaluate model performance in gene-disease association extraction, specifically assessing the ability to identify associations between genes and diseases in biomedical literature."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'CDR' and 'GDA' as biomedical datasets used for comparing model performance. These are specific, identifiable datasets relevant to the research topic.",
      "processing_time": 57.46771860122681,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3576631
    },
    {
      "context_text": "However, large amounts of relationships are expressed by multiple sentences in real life [Yao et al., 2019; Verga et al., 2018].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about relationships expressed in multiple sentences.",
      "processing_time": 40.64986181259155,
      "citing_paper_id": "248300064",
      "cited_paper_id": 3576631
    },
    {
      "context_text": "…as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on graph-based models and their application in document-level event extraction.",
      "processing_time": 43.75875997543335,
      "citing_paper_id": "248300064",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "Our model is optimized with AdamW [Loshchilov and Hutter, 2017] with a linear warmup [Goyal et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only optimization methods and training strategies.",
      "processing_time": 40.41766905784607,
      "citing_paper_id": "248300064",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "Our model is optimized with AdamW [Loshchilov and Hutter, 2017] with a linear warmup [Goyal et al., 2017] for the first 6% steps followed by a linear decay to 0.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only optimization methods and training strategies.",
      "processing_time": 40.917407512664795,
      "citing_paper_id": "248300064",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "We used cased BERT-base [Devlin et al., 2018] as the encoder on DocRED and SciBERT-base [Beltagy et al., 2019] on CDR and GDA.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate document-level relation extraction, focusing on complex relations across multiple sentences using cased BERT-base as the encoder.",
        "CDR": "Used to evaluate chemical-disease relation extraction, employing SciBERT-base to handle scientific text specificities.",
        "GDA": "Used to evaluate gene-disease association extraction, leveraging SciBERT-base for improved performance in scientific contexts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED', 'CDR', and 'GDA' as datasets used for document-level event extraction. These are specific datasets with clear identifiers.",
      "processing_time": 62.48178267478943,
      "citing_paper_id": "248300064",
      "cited_paper_id": 202558505
    },
    {
      "context_text": ", 2020], SciBERT [Beltagy et al., 2019], ATLOP [Zhou et al.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No dataset names are present in the text.",
      "processing_time": 42.3635835647583,
      "citing_paper_id": "248300064",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "On the two biomedical datasets, CDR and GDA, we compared our model with a large number of baseline models and recent state-of-the-art models including BRAN [Verga et al., 2018], EoG [Christopoulou et al., 2019], LSR [Nan et al., 2020], DHG [Zhang et al., 2020], GLRE [Wang et al., 2020], SciBERT [Beltagy et al., 2019], ATLOP [Zhou et al., 2021b], and DocuNet [Zhang et al., 2021a].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "CDR": "Used to compare model performance on chemical-disease relation extraction, focusing on document-level relations and evaluating against baseline and state-of-the-art models.",
        "GDA": "Used to compare model performance on gene-disease association extraction, focusing on document-level relations and evaluating against baseline and state-of-the-art models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'CDR' and 'GDA' as datasets used for comparing models. These are multi-word proper nouns and appear to be specific datasets.",
      "processing_time": 58.94479179382324,
      "citing_paper_id": "248300064",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "On the two biomedical datasets, CDR and GDA, we compared our model with a large number of baseline models and recent state-of-the-art models including BRAN [Verga et al., 2018], EoG [Christopoulou et al., 2019], LSR [Nan et al., 2020], DHG [Zhang et al., 2020], GLRE [Wang et al., 2020], SciBERT [Beltagy et al., 2019], ATLOP [Zhou et al., 2021b], and DocuNet [Zhang et al., 2021a].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "CDR": "Used to compare model performance on chemical-disease relation extraction, focusing on document-level relations and evaluating against baseline and state-of-the-art models.",
        "GDA": "Used to compare model performance on gene-disease association extraction, focusing on document-level relations and evaluating against baseline and state-of-the-art models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'CDR' and 'GDA' as datasets used for comparing models. These are multi-word proper nouns and appear to be specific datasets.",
      "processing_time": 58.94479179382324,
      "citing_paper_id": "248300064",
      "cited_paper_id": 221836081
    },
    {
      "context_text": "…of baseline models and recent state-of-the-art models including BRAN [Verga et al., 2018], EoG [Christopoulou et al., 2019], LSR [Nan et al., 2020], DHG [Zhang et al., 2020], GLRE [Wang et al., 2020], SciBERT [Beltagy et al., 2019], ATLOP [Zhou et al., 2021b], and DocuNet [Zhang et al., 2021a].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not reference any specific datasets. The context is focused on comparing different models and their performance.",
      "processing_time": 43.74843692779541,
      "citing_paper_id": "248300064",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "…of baseline models and recent state-of-the-art models including BRAN [Verga et al., 2018], EoG [Christopoulou et al., 2019], LSR [Nan et al., 2020], DHG [Zhang et al., 2020], GLRE [Wang et al., 2020], SciBERT [Beltagy et al., 2019], ATLOP [Zhou et al., 2021b], and DocuNet [Zhang et al., 2021a].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not reference any specific datasets. The context is focused on comparing different models and their performance.",
      "processing_time": 43.74843692779541,
      "citing_paper_id": "248300064",
      "cited_paper_id": 221836081
    },
    {
      "context_text": "…of baseline models and recent state-of-the-art models including BRAN [Verga et al., 2018], EoG [Christopoulou et al., 2019], LSR [Nan et al., 2020], DHG [Zhang et al., 2020], GLRE [Wang et al., 2020], SciBERT [Beltagy et al., 2019], ATLOP [Zhou et al., 2021b], and DocuNet [Zhang et al., 2021a].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not reference any specific datasets. The context is focused on comparing different models and their performance.",
      "processing_time": 43.74843692779541,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": ", 2018] as the encoder on DocRED and SciBERT-base [Beltagy et al., 2019] on CDR and GDA.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate document-level relation extraction, focusing on complex relations across multiple sentences using a pre-trained encoder.",
        "CDR": "Used to evaluate chemical-disease relation extraction, applying a scientific text-based pre-trained model for improved performance.",
        "GDA": "Used to evaluate gene-disease association extraction, leveraging a pre-trained model to enhance relation extraction accuracy."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. SciBERT is a model, not a dataset, so it is excluded.",
      "processing_time": 59.32015323638916,
      "citing_paper_id": "248300064",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "To extract such complex inter-sentence relations, most current approaches constructed a document-level graph based on heuristics, structured attention, or dependency structures [Zeng et al., 2020; Nan et al., 2020; Christopoulou et al., 2019; Wang et al., 2020], and then perform inference with graph convolutional network (GCN) [Guo et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for document-level relation extraction.",
      "processing_time": 40.90532660484314,
      "citing_paper_id": "248300064",
      "cited_paper_id": 221836081
    },
    {
      "context_text": "The graph-based method was first introduced by [Quirk and Poon, 2016] and has recently been extended by many works [Christopoulou et al., 2019; Li et al., 2020; Zhang et al., 2020; Zhou et al., 2020; Wang et al., 2020; Nan et al., 2020; Zeng et al., 2020; Wu et al., 2019].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and research works. The context is focused on describing the evolution of graph-based methods in document-level relation extraction.",
      "processing_time": 44.96405339241028,
      "citing_paper_id": "248300064",
      "cited_paper_id": 221836081
    },
    {
      "context_text": "…networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang et al., 2020], GAIN [Zeng et al., 2020], and HeterGSAN [Xu et al., 2021b].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several methods/models (GEDA, LSR, GLRE, GAIN, HeterGSAN) but does not refer to them as datasets. No specific datasets are mentioned.",
      "processing_time": 46.156538009643555,
      "citing_paper_id": "248300064",
      "cited_paper_id": 221836081
    },
    {
      "context_text": "…graph based on heuristics, structured attention, or dependency structures [Zeng et al., 2020; Nan et al., 2020; Christopoulou et al., 2019; Wang et al., 2020], and then perform inference with graph convolutional network (GCN) [Guo et al., 2019; Kipf and Welling, 2016] on the…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The context is focused on the use of graph-based approaches and GCNs for document-level relation extraction.",
      "processing_time": 45.33968734741211,
      "citing_paper_id": "248300064",
      "cited_paper_id": 221836081
    },
    {
      "context_text": ", 2020], GLRE [Wang et al., 2020], SciBERT [Beltagy et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GLRE"
      ],
      "dataset_descriptions": {
        "GLRE": "Used to evaluate document-level relation extraction models, focusing on capturing global context and local interactions between entities."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions 'GLRE' which is a dataset for document-level relation extraction, and 'SciBERT' which is a method. GLRE is included as it fits the criteria for a dataset.",
      "processing_time": 51.738576889038086,
      "citing_paper_id": "248300064",
      "cited_paper_id": 221836081
    },
    {
      "context_text": "The SIRE [Zeng et al., 2021] represents intraand inter-sentential relations in different ways, and design a new and straightforward form of logical reasoning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (SIRE) for document-level relation extraction.",
      "processing_time": 42.67767405509949,
      "citing_paper_id": "248300064",
      "cited_paper_id": 235313883
    },
    {
      "context_text": "Compared with Intra-F1, Inter-F1 can better reflect the reasoning ability of the model. we can observe that our DRE-MIR model improved the Inter-F1 score by 3.28 compared with the SIRE model.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model performance comparisons.",
      "processing_time": 41.069974184036255,
      "citing_paper_id": "248300064",
      "cited_paper_id": 235313883
    },
    {
      "context_text": "To evaluate the inference ability of the models, we follow [Xu et al., 2021b; Zeng et al., 2021] and report Infer-F1 scores in table 5, which only considers relations that engaged in the relational reasoning process.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the evaluation metric (Infer-F1 scores) and the relational reasoning process. No datasets are explicitly named or described.",
      "processing_time": 45.33254098892212,
      "citing_paper_id": "248300064",
      "cited_paper_id": 235313883
    },
    {
      "context_text": ", 2021a] and SIRE [Zeng et al., 2021] in the comparison.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions SIRE, which is a method for document-level relation extraction, not a dataset. No datasets are explicitly mentioned.",
      "processing_time": 43.739802837371826,
      "citing_paper_id": "248300064",
      "cited_paper_id": 235313883
    },
    {
      "context_text": "In addition, we also consider the DocuNet [Zhang et al., 2021a] and SIRE [Zeng et al., 2021] in the comparison.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions DocuNet and SIRE, but neither are datasets. They are methods/models used for document-level relation extraction.",
      "processing_time": 43.97918701171875,
      "citing_paper_id": "248300064",
      "cited_paper_id": 235313883
    },
    {
      "context_text": "While, the SIRE represents intra- and inter-sentential relations in different ways, and design a new form of logical reasoning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (SIRE) for document-level relation extraction.",
      "processing_time": 43.496790409088135,
      "citing_paper_id": "248300064",
      "cited_paper_id": 235313883
    },
    {
      "context_text": "[Zhou et al., 2021b] proposed an ATLOP\nmodel that consists of two parts: adaptive thresholding and localized context pooling, to solve the multi-label and multientity problems.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its components. The context is focused on describing the ATLOP model and its purpose.",
      "processing_time": 45.326127767562866,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": ", 2021] and [Zhou et al., 2021a], we reconstruct the distribution of the pixels of the masked image on the label, p(r|MA,B), instead of reconstructing the raw pixels, MA,B .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for reconstructing the distribution of pixels in a masked image.",
      "processing_time": 43.972803354263306,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": "…due to the pre-trained language model based on the transformer architecture can implicitly model longdistance dependence and complete logical reasoning, some studies [Tang et al., 2020; Zhou et al., 2021b; Wang et al., 2019] directly apply pre-trained model without introducing document graphs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of pre-trained models. The context is about applying pre-trained models without document graphs.",
      "processing_time": 45.15937566757202,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": "Inspired by [Bao et al., 2021] and [Zhou et al., 2021a], we reconstruct the distribution of the pixels of the masked image on the label, p(r|MA,B), instead of reconstructing the raw pixels, MA,B .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for reconstructing the distribution of pixels in masked images.",
      "processing_time": 43.95424818992615,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": "• Transformer-based Models: These models directly use pre-trained language models for document-level RE without using graph structures, including BERT [Xu et al.,\n2021b], BERT-Two-Step [Wang et al., 2019], HIN-BERT [Tang et al., 2020], CorefBERT [Ye et al., 2020], and ATLOP-BERT [Zhou et al., 2021b].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 44.94834589958191,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": "For an entity ei with mentions {mij} Nei j , we follow [Zhou et al., 2021b] and [Zhang et al., 2021a], and leverage logsumexp pooling [Jia et al., 2019], a smooth version of max pooling, to obtain the embedding hei of entity ei:\nhei = log Nei∑ j=1 exp(hmij ).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and mathematical operations. No verifiable resources are identified.",
      "processing_time": 43.96736526489258,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": "Furthermore, our work is inspired by recent pre-training research in the field of machine vision, such as BIET [Bao et al., 2021], IBOT [Zhou et al., 2021a], and MAE [He et al., 2021].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several models (BIET, IBOT, MAE) but does not refer to any specific datasets. The context is about pre-training methods in machine vision.",
      "processing_time": 46.62523937225342,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": "…Transformer-based Models: These models directly use pre-trained language models for document-level RE without using graph structures, including BERT [Xu et al.,\n2021b], BERT-Two-Step [Wang et al., 2019], HIN-BERT [Tang et al., 2020], CorefBERT [Ye et al., 2020], and ATLOP-BERT [Zhou et al., 2021b].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 45.52260994911194,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": "To alleviate the problem of unbalanced relationship distribution, we use adaptive-thresholding loss [Zhou et al., 2021b] as our classification loss function LC , which learns an adaptive threshold for each sample.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (adaptive-thresholding loss) used to address class imbalance in classification.",
      "processing_time": 45.30063319206238,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": "…considering the transformer architecture can implicitly model long-distance dependencies and can be regarded as a tokenlevel fully connected graph, some studies [Tang et al., 2020; Zhou et al., 2021b] implicitly infers through the pre-trained model rather than via the document-level graphs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to studies using pre-trained models. No clear identifiers for datasets are present.",
      "processing_time": 45.50905466079712,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": "Therefore, many recent works have made efforts to extend sentence-level RE to document-level RE [Yao et al., 2019; Zeng et al., 2020; Zhou et al., 2021b; Xu et al., 2021a; Zhang et al., 2021a].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to works that have extended sentence-level RE to document-level RE. No verifiable resources are identified.",
      "processing_time": 46.87362480163574,
      "citing_paper_id": "248300064",
      "cited_paper_id": 244117494
    },
    {
      "context_text": "Tuples of event-type and arguments are one way of inducing script like-structures (Chambers and Jurafsky, 2008).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for inducing script-like structures.",
      "processing_time": 44.928104877471924,
      "citing_paper_id": "222208551",
      "cited_paper_id": 529375
    },
    {
      "context_text": ", 2014) and generating approximate causal paths (Kang et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers. No verifiable resources are identified.",
      "processing_time": 45.72019839286804,
      "citing_paper_id": "222208551",
      "cited_paper_id": 793863
    },
    {
      "context_text": "Some examples are event coreference (Lu and Ng, 2018), detecting event-event temporal (Vashishtha et al., 2019) and causal relations (Dunietz et al., 2017), sub-event structure (Araki et al., 2014) and generating approximate causal paths (Kang et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various types of event-related tasks and studies. The cited paper titles do not introduce any specific datasets either.",
      "processing_time": 47.518646001815796,
      "citing_paper_id": "222208551",
      "cited_paper_id": 793863
    },
    {
      "context_text": "Some examples are event coreference (Lu and Ng, 2018), detecting event-event temporal (Vashishtha et al., 2019) and causal relations (Dunietz et al., 2017), sub-event structure (Araki et al., 2014) and generating approximate causal paths (Kang et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various types of event-related tasks and studies. The cited paper titles do not introduce any specific datasets either.",
      "processing_time": 47.518646001815796,
      "citing_paper_id": "222208551",
      "cited_paper_id": 17510107
    },
    {
      "context_text": "Some examples are event coreference (Lu and Ng, 2018), detecting event-event temporal (Vashishtha et al., 2019) and causal relations (Dunietz et al., 2017), sub-event structure (Araki et al., 2014) and generating approximate causal paths (Kang et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various types of event-related tasks and studies. The cited paper titles do not introduce any specific datasets either.",
      "processing_time": 47.518646001815796,
      "citing_paper_id": "222208551",
      "cited_paper_id": 17716605
    },
    {
      "context_text": "Some examples are event coreference (Lu and Ng, 2018), detecting event-event temporal (Vashishtha et al., 2019) and causal relations (Dunietz et al., 2017), sub-event structure (Araki et al., 2014) and generating approximate causal paths (Kang et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various types of event-related tasks and studies. The cited paper titles do not introduce any specific datasets either.",
      "processing_time": 47.518646001815796,
      "citing_paper_id": "222208551",
      "cited_paper_id": 59599681
    },
    {
      "context_text": "It comes with an associated BPE tokenizer (Sennrich et al., 2015) which tokenizes raw inputs to subwords.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a BPE tokenizer but does not refer to any specific dataset. The tokenizer is a method, not a dataset.",
      "processing_time": 46.60129427909851,
      "citing_paper_id": "222208551",
      "cited_paper_id": 1114678
    },
    {
      "context_text": "We ground these terms more clearly in §2.1\nguistic/task motivated 0-1 feature families to perword-type pretrained vectors (Pennington et al., 2014) to contextual embeddings (Peters et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to methods and models. No verifiable resources are identified.",
      "processing_time": 46.86581563949585,
      "citing_paper_id": "222208551",
      "cited_paper_id": 3626819
    },
    {
      "context_text": "ELMo (Peters et al., 2018) was an early CE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions ELMo, which is a method/model, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 47.5049831867218,
      "citing_paper_id": "222208551",
      "cited_paper_id": 3626819
    },
    {
      "context_text": "This is similar to the approach of (Gulordava et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a methodological approach.",
      "processing_time": 46.311076402664185,
      "citing_paper_id": "222208551",
      "cited_paper_id": 4460159
    },
    {
      "context_text": "Gulordava et al. (2018) evaluate subject-verb agreement but only through “nonce” sentences to con-\n2 trol for both lexical confounding and memorization3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach using 'nonce' sentences.",
      "processing_time": 46.86016607284546,
      "citing_paper_id": "222208551",
      "cited_paper_id": 4460159
    },
    {
      "context_text": ", 2019), sentence-level properties (Adi et al., 2016) and negative polarity items (Warstadt et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. No dataset names are present in the text.",
      "processing_time": 47.97547459602356,
      "citing_paper_id": "222208551",
      "cited_paper_id": 6771196
    },
    {
      "context_text": "Besides those discussed earlier, other aspects studied include filler-gap dependencies (Wilcox et al., 2018), function word comprehension (Kim et al., 2019), sentence-level properties (Adi et al., 2016) and negative polarity items (Warstadt et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research areas and papers. No clear identifiers for datasets are present.",
      "processing_time": 48.129016399383545,
      "citing_paper_id": "222208551",
      "cited_paper_id": 6771196
    },
    {
      "context_text": ", 2017), sub-event structure (Araki et al., 2014) and generating approximate causal paths (Kang et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to research works. The context is too vague to identify any verifiable resources.",
      "processing_time": 48.89539170265198,
      "citing_paper_id": "222208551",
      "cited_paper_id": 17510107
    },
    {
      "context_text": ", 2019) and causal relations (Dunietz et al., 2017), sub-event structure (Araki et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to papers discussing causality and overlapping relations.",
      "processing_time": 48.12544345855713,
      "citing_paper_id": "222208551",
      "cited_paper_id": 17716605
    },
    {
      "context_text": "Some examples are event coreference (Lu and Ng, 2018), detecting event-event temporal (Vashishtha et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a reference to event coreference research.",
      "processing_time": 47.96798086166382,
      "citing_paper_id": "222208551",
      "cited_paper_id": 51606527
    },
    {
      "context_text": "Analysis of cross-sentence performance can be found in §3.3 and §3.4 We note that the dataset is in English (Bender and Friedman, 2018) and observations made may not generalize to other languages.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions a dataset in English but does not provide a specific name. The reference to Bender and Friedman (2018) is likely about the dataset's characteristics rather than introducing a new dataset.",
      "processing_time": 51.83948373794556,
      "citing_paper_id": "222208551",
      "cited_paper_id": 52255687
    },
    {
      "context_text": "We note that the dataset is in English (Bender and Friedman, 2018) and observations made may not generalize to other languages.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context does not provide a specific dataset name, only a general reference to 'the dataset'. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 51.359445095062256,
      "citing_paper_id": "222208551",
      "cited_paper_id": 52255687
    },
    {
      "context_text": "Some examples are event coreference (Lu and Ng, 2018), detecting event-event temporal (Vashishtha et al., 2019) and causal relations (Dunietz et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. No dataset names are present in the text.",
      "processing_time": 48.87833094596863,
      "citing_paper_id": "222208551",
      "cited_paper_id": 59599681
    },
    {
      "context_text": "Hewitt and Manning (2019) find that BERT token representations are linearly projectable into a space where they embed constituency structure.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BERT) and a finding about its token representations. The context is focused on the methodology and findings rather than the use of a dataset.",
      "processing_time": 51.834611892700195,
      "citing_paper_id": "222208551",
      "cited_paper_id": 106402715
    },
    {
      "context_text": "Recent\n5 works have shown that BERT does retain such associations, including for first names (Shwartz et al., 2020), and enough so that it can act as a reasonable knowledge base (Petroni et al., 2019).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to models and methods. The cited papers are used to support findings about BERT retaining associations.",
      "processing_time": 50.06340456008911,
      "citing_paper_id": "222208551",
      "cited_paper_id": 202539551
    },
    {
      "context_text": "We follow the practice of earlier probing works such as (Sorodoc et al., 2020) and (Linzen et al., 2016) of using one of the smaller splits for training.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general practice of using smaller splits for training. No verifiable resource names are provided.",
      "processing_time": 49.62407112121582,
      "citing_paper_id": "222208551",
      "cited_paper_id": 220047937
    },
    {
      "context_text": "We follow the practice of earlier probing works such as (Sorodoc et al., 2020) and (Linzen et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to earlier works. There are no clear identifiers for datasets in the given context.",
      "processing_time": 50.05031752586365,
      "citing_paper_id": "222208551",
      "cited_paper_id": 220047937
    },
    {
      "context_text": "Recently, Sorodoc et al. (2020) probed transformer based language models for coreference.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (transformer-based language models) and a task (probing for coreference).",
      "processing_time": 50.04831886291504,
      "citing_paper_id": "222208551",
      "cited_paper_id": 220047937
    },
    {
      "context_text": "Initially, MIL was introduced by Riedel et al. (2010) in order to reduce noise in distantly supervised corpora (Mintz et al., 2009).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'distantly supervised corpora' but does not specify a named dataset. The term 'corpora' is too generic without a specific identifier.",
      "processing_time": 51.670917987823486,
      "citing_paper_id": "202541610",
      "cited_paper_id": 2386383
    },
    {
      "context_text": "Initially, MIL was introduced by Riedel et al. (2010) in order to reduce noise in distantly supervised corpora (Mintz et al., 2009).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'distantly supervised corpora' but does not specify a named dataset. The term 'corpora' is too generic without a specific identifier.",
      "processing_time": 51.670917987823486,
      "citing_paper_id": "202541610",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "Verga et al. (2018) and Nguyen and Verspoor (2018) consider a single pair per document, while Gu et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 51.185689210891724,
      "citing_paper_id": "202541610",
      "cited_paper_id": 2386383
    },
    {
      "context_text": "They utilise Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al., 2016; Zhou et al., 2018), entity descriptors (Jiang et al., 2016) and graph CNNs (Vashishth et al., 2018) to perform MIL on bags-of-sentences that contain multiple mentions of an entity pair.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 50.83110046386719,
      "citing_paper_id": "202541610",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "They utilise Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al., 2016; Zhou et al., 2018), entity descriptors (Jiang et al., 2016) and graph CNNs (Vashishth et al., 2018) to perform MIL on bags-of-sentences that contain multiple mentions of an entity pair.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 50.83110046386719,
      "citing_paper_id": "202541610",
      "cited_paper_id": 52115592
    },
    {
      "context_text": "They utilise Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al., 2016; Zhou et al., 2018), entity descriptors (Jiang et al., 2016) and graph CNNs (Vashishth et al., 2018) to perform MIL on bags-of-sentences that contain multiple mentions of an…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models used for relation extraction.",
      "processing_time": 49.414661169052124,
      "citing_paper_id": "202541610",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "They utilise Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is focused on the use of PCNN and attention mechanisms.",
      "processing_time": 15.040709733963013,
      "citing_paper_id": "202541610",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "Other approaches extract document-level representations for each candidate entity pair (Zheng et al., 2018; Li et al., 2018; Wu et al., 2019), or use syntactic dependency structures (Zhou et al., 2016; Peng et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 51.82468056678772,
      "citing_paper_id": "202541610",
      "cited_paper_id": 3023415
    },
    {
      "context_text": "Other approaches extract document-level representations for each candidate entity pair (Zheng et al., 2018; Li et al., 2018; Wu et al., 2019), or use syntactic dependency structures (Zhou et al., 2016; Peng et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 51.82468056678772,
      "citing_paper_id": "202541610",
      "cited_paper_id": 13710324
    },
    {
      "context_text": ", 2019), or use syntactic dependency structures (Zhou et al., 2016; Peng et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and papers. No verifiable resources are identified.",
      "processing_time": 51.17596411705017,
      "citing_paper_id": "202541610",
      "cited_paper_id": 3023415
    },
    {
      "context_text": "To deal with document-level RE, recent approaches assume that only two mentions of the target entities reside in the document (Nguyen and Verspoor, 2018; Verga et al., 2018) or utilise different models for intra- and inter-sentence RE (Gu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses methodologies and assumptions in document-level relation extraction.",
      "processing_time": 50.99737739562988,
      "citing_paper_id": "202541610",
      "cited_paper_id": 3576631
    },
    {
      "context_text": "To deal with document-level RE, recent approaches assume that only two mentions of the target entities reside in the document (Nguyen and Verspoor, 2018; Verga et al., 2018) or utilise different models for intra- and inter-sentence RE (Gu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses methodologies and assumptions in document-level relation extraction.",
      "processing_time": 50.99737739562988,
      "citing_paper_id": "202541610",
      "cited_paper_id": 44127108
    },
    {
      "context_text": "Verga et al. (2018) introduced another MIL setting for relation extraction between named entities in a document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for relation extraction.",
      "processing_time": 49.3980233669281,
      "citing_paper_id": "202541610",
      "cited_paper_id": 3576631
    },
    {
      "context_text": "To compare with related work, we followed Verga et al. (2018) and Gu et al. (2016) and ignored nonrelated pairs that correspond to general concepts (MeSH vocabulary hypernym filtering).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for filtering nonrelated pairs using MeSH vocabulary. No clear, verifiable dataset names are provided.",
      "processing_time": 52.70151710510254,
      "citing_paper_id": "202541610",
      "cited_paper_id": 3576631
    },
    {
      "context_text": "To deal with document-level RE, recent approaches assume that only two mentions of the target entities reside in the document (Nguyen and Verspoor, 2018; Verga et al., 2018) or utilise different models for intra- and inter-sentence RE (Gu et al., 2016; Li et al., 2016b; Gu et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is focused on describing different strategies for document-level relation extraction.",
      "processing_time": 51.991796016693115,
      "citing_paper_id": "202541610",
      "cited_paper_id": 3576631
    },
    {
      "context_text": "Verga et al. (2018) proposed a Transformer-based model for documentlevel relation extraction with multi-instance learning, merging multiple mention pairs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level relation extraction.",
      "processing_time": 51.49962019920349,
      "citing_paper_id": "202541610",
      "cited_paper_id": 3576631
    },
    {
      "context_text": "Due to the small size of the CDR dataset, some approaches create a new split from the union of train and development sets (Verga et al., 2018; Zhou et al., 2018).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CDR"
      ],
      "dataset_descriptions": {
        "CDR": "Used to address the challenge of small dataset size in biological relation extraction, specifically by creating a new split from the union of train and development sets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the CDR dataset, which is a specific dataset used in biological relation extraction. The dataset is referenced in the context of its small size and the creation of a new split from the union of train and development sets.",
      "processing_time": 63.857544898986816,
      "citing_paper_id": "202541610",
      "cited_paper_id": 3576631
    },
    {
      "context_text": "Verga et al. (2018) and Nguyen and Verspoor (2018) consider a single pair per document, while Gu et al. (2017) develops separate models for intra- and inter-sentence pairs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses different approaches to handling relation extraction in documents.",
      "processing_time": 51.49656558036804,
      "citing_paper_id": "202541610",
      "cited_paper_id": 3576631
    },
    {
      "context_text": "the contribution of the shorter edge presentation. In general is larger for shorter edges as we expect that the relation between two nodes is better expressed through the shortest path between them (Xu et al., 2015;Borgwardt and Kriegel,2005). The two steps are repeated a ﬁnite number of times N. The number of iterations is correlated with the ﬁnal length of the edge representations. With initial edge length le",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methods and concepts related to edge representation and relation classification.",
      "processing_time": 52.40349268913269,
      "citing_paper_id": "202541610",
      "cited_paper_id": 5403702
    },
    {
      "context_text": "(2010) in order to reduce noise in distantly supervised corpora (Mintz et al., 2009).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'distantly supervised corpora' but does not specify a named dataset. The context is about reducing noise in such corpora, which is a methodological concern rather than a specific dataset.",
      "processing_time": 55.58086538314819,
      "citing_paper_id": "202541610",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "Traditional approaches focus on intra-sentence supervised RE, utilising CNN or RNN, ignoring multiple entities in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal,",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general approaches and methods. No verifiable resources are identified.",
      "processing_time": 52.554744243621826,
      "citing_paper_id": "202541610",
      "cited_paper_id": 12585424
    },
    {
      "context_text": "Traditional approaches focus on intra-sentence supervised RE, utilising CNN or RNN, ignoring multiple entities in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal,",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general approaches and methods. No verifiable resources are identified.",
      "processing_time": 52.554744243621826,
      "citing_paper_id": "202541610",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Traditional approaches focus on intra-sentence supervised RE, utilising CNN or RNN, ignoring multiple entities in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal,\n2016; Zhang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 53.61053729057312,
      "citing_paper_id": "202541610",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Traditional approaches focus on intra-sentence supervised RE, utilising CNN or RNN, ignoring multiple entities in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal,\n2016; Zhang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 53.61053729057312,
      "citing_paper_id": "202541610",
      "cited_paper_id": 49544037
    },
    {
      "context_text": "Traditional approaches focus on intra-sentence supervised RE, utilising CNN or RNN, ignoring multiple entities in a sentence (Zeng et al., 2014; Nguyen and Grishman, 2015) as well as incorporating external syntactic tools (Miwa and Bansal,\n2016; Zhang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 53.61053729057312,
      "citing_paper_id": "202541610",
      "cited_paper_id": 52115592
    },
    {
      "context_text": "Other approaches extract document-level representations for each candidate entity pair (Zheng et al., 2018; Li et al., 2018; Wu et al., 2019), or use syntactic dependency structures (Zhou et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other research works. There are no clear identifiers for datasets, corpora, or similar resources.",
      "processing_time": 54.32555174827576,
      "citing_paper_id": "202541610",
      "cited_paper_id": 13710324
    },
    {
      "context_text": "…Piecewise Convolutional Neural Networks (PCNN) (Zeng et al., 2015), attention mechanisms (Lin et al., 2016; Zhou et al., 2018), entity descriptors (Jiang et al., 2016) and graph CNNs (Vashishth et al., 2018) to perform MIL on bags-of-sentences that contain multiple mentions of an entity pair.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 52.67626404762268,
      "citing_paper_id": "202541610",
      "cited_paper_id": 16389974
    },
    {
      "context_text": "In contrast with approaches that employ sequential models (Nguyen and Verspoor, 2018; Gu et al., 2017; Zhou et al., 2016), graph-based neural approaches have proven useful in encoding longdistance, inter-sentential information (Peng et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other research works and methods. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.69928956031799,
      "citing_paper_id": "202541610",
      "cited_paper_id": 44127108
    },
    {
      "context_text": "Lately, RE has attracted a lot of attention from the field, in an effort to improve the inference capability of current methods (Zeng et al., 2017; Christopoulou et al., 2018; Luan et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to relation extraction methods and their improvements.",
      "processing_time": 52.681222915649414,
      "citing_paper_id": "202541610",
      "cited_paper_id": 51877560
    },
    {
      "context_text": "Lately, RE has attracted a lot of attention from the field, in an effort to improve the inference capability of current methods (Zeng et al., 2017; Christopoulou et al., 2018; Luan et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to relation extraction methods and their improvements.",
      "processing_time": 52.681222915649414,
      "citing_paper_id": "202541610",
      "cited_paper_id": 102352698
    },
    {
      "context_text": "Finally, the performance drop in intra-sentence pairs, as a result of the inference algorithm removal (NoInf), suggests that multiple entity associations exist in sentences (Christopoulou et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context focuses on the performance impact of removing an inference algorithm.",
      "processing_time": 54.11813163757324,
      "citing_paper_id": "202541610",
      "cited_paper_id": 51877560
    },
    {
      "context_text": "For this purpose, we adapt our two-step inference mechanism, proposed in Christopoulou et al. (2018), to encode interactions between nodes and edges in the graph and hence model EE associations.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context focuses on adapting a two-step inference mechanism for encoding interactions in a graph model.",
      "processing_time": 55.11796164512634,
      "citing_paper_id": "202541610",
      "cited_paper_id": 51877560
    },
    {
      "context_text": "Christopoulou et al. (2018) considered intra-sentence entity interactions without domain dependencies by modelling long dependencies between the entities of a sentence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for relation extraction.",
      "processing_time": 51.79329252243042,
      "citing_paper_id": "202541610",
      "cited_paper_id": 51877560
    },
    {
      "context_text": "We build our model as a significant extension of our previously proposed sentence-level model (Christopoulou et al., 2018) for documentlevel RE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a previous model. The context is about extending a sentence-level model to a document-level model.",
      "processing_time": 54.697898387908936,
      "citing_paper_id": "202541610",
      "cited_paper_id": 51877560
    },
    {
      "context_text": "Following this work, other approaches incorporated graphical models for document-level RE such as graph LSTM (Peng et al., 2017), graph CNN (Song et al., 2018) or RNNs on dependency tree structures (Gupta et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 53.77307605743408,
      "citing_paper_id": "202541610",
      "cited_paper_id": 52115592
    },
    {
      "context_text": "Nguyen and Verspoor (2018) used a CNN with additional character-level embeddings.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CNN with character-level embeddings).",
      "processing_time": 53.22932195663452,
      "citing_paper_id": "202541610",
      "cited_paper_id": 52115592
    },
    {
      "context_text": ", 2017), graph CNN (Song et al., 2018) or RNNs on dependency tree structures (Gupta et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets in the text.",
      "processing_time": 54.30921649932861,
      "citing_paper_id": "202541610",
      "cited_paper_id": 52115592
    },
    {
      "context_text": "…tend to lose focus and cover the whole image, as shown in Figure 8. main (Ji and Grishman, 2008; Liao and Grishman, 2011; Huang and Riloff, 2012; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Hong et al., 2018; Liu et al., 2018b; Chen et al., 2018; Zhang et al., 2019; Liu et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. No clear identifiers for datasets are present.",
      "processing_time": 41.345399618148804,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "For text-only event mentions, we follow (Ji and Grishman, 2008; Li et al., 2013): a textual event mention is correct if its event type and trigger offsets match a reference trigger; and a textual event argument is correct if its event type, offsets, and role label match a reference argument.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation criteria for event mentions and arguments.",
      "processing_time": 53.101818561553955,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "main (Ji and Grishman, 2008; Liao and Grishman, 2011; Huang and Riloff, 2012; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Hong et al., 2018; Liu et al., 2018b; Chen et al., 2018; Zhang et al., 2019; Liu et al., 2018a; Wang et al., 2019; Yang et al., 2019; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 55.292691230773926,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2213149
    },
    {
      "context_text": "…attention heatmaps tend to lose focus and cover the whole image, as shown in Figure 8. main (Ji and Grishman, 2008; Liao and Grishman, 2011; Huang and Riloff, 2012; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Hong et al., 2018; Liu et al., 2018b; Chen et al., 2018; Zhang et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 56.254594564437866,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2213149
    },
    {
      "context_text": "We develop two methods to construct situation graphs from images and train them using the im-Situ dataset (Yatskar et al., 2016) as follows.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "im-Situ"
      ],
      "dataset_descriptions": {
        "im-Situ": "Used to train methods for constructing situation graphs from images, focusing on visual semantic role labeling for image understanding."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'im-Situ dataset' which is a specific dataset used for training methods to construct situation graphs from images.",
      "processing_time": 61.41636300086975,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2424223
    },
    {
      "context_text": "The most similar to our work is Situation Recognition (SR) (Yatskar et al., 2016; Mallya and Lazebnik, 2017) which predicts an event and multiple arguments from an input image, but does not localize the arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Situation Recognition) and its application. No verifiable datasets are referenced.",
      "processing_time": 55.27809691429138,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2424223
    },
    {
      "context_text": ", 2019a) • Most related: Situation Recognition (Yatskar et al., 2016) • Classify an image as one of 500+ FrameNet verbs • Identify 192 generic semantic roles via a 1-word description",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a task and a method. The cited paper title confirms that the focus is on a method (Situation Recognition) rather than a dataset.",
      "processing_time": 57.95010542869568,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2424223
    },
    {
      "context_text": "Event and Argument Classiﬁer: We use either the object-based or attention-based formulation and pre-train it on the imSitu dataset (Yatskar et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "imSitu"
      ],
      "dataset_descriptions": {
        "imSitu": "Used to pre-train models for event and argument classification, focusing on visual semantic role labeling for image understanding."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the imSitu dataset, which is a specific dataset used for pre-training a model for event and argument classification.",
      "processing_time": 62.48542046546936,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2424223
    },
    {
      "context_text": "We deﬁne multimedia newsworthy event types by exhaustively mapping between the event ontology in NLP community for the news domain (ACE 2 ) and the event ontology in CV community for general domain (imSitu (Yatskar et al., 2016)).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "imSitu"
      ],
      "dataset_descriptions": {
        "imSitu": "Used to map event ontologies between NLP and CV communities, focusing on visual semantic role labeling for image understanding."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions 'ACE 2' and 'imSitu', both of which are specific resources. However, 'ACE 2' is likely a method or ontology, and 'imSitu' is a dataset used for visual semantic role labeling.",
      "processing_time": 66.71378588676453,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2424223
    },
    {
      "context_text": "Traditional event extraction methods target a single modality, such as text (Wadden et al., 2019), images (Yatskar et al., 2016) or videos (Ye et al., 2015; Caba Heilbron et al., 2015; Soomro et al., 2012).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only modalities and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 55.911492347717285,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2424223
    },
    {
      "context_text": "Traditional event extraction methods target a single modality, such as text (Wadden et al., 2019), images (Yatskar et al., 2016) or videos (Ye et al., 2015; Caba Heilbron et al., 2015; Soomro et al., 2012).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only modalities and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 55.911492347717285,
      "citing_paper_id": "218501728",
      "cited_paper_id": 7197134
    },
    {
      "context_text": "Image Structured Representation: To obtain image structures similar to AMR graphs, and inspired by situation recognition (Yatskar et al., 2016), we represent each image with a situation graph , that is a star-shaped graph as shown in Figure 4, where the central node is labeled as a verb v (e.g.,…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method for representing images using situation graphs, which is not a dataset.",
      "processing_time": 55.92157316207886,
      "citing_paper_id": "218501728",
      "cited_paper_id": 2424223
    },
    {
      "context_text": "Complex event structures have not been covered by existing multimedia representation meth-ods (Wu et al., 2019b; Faghri et al., 2018; Karpa-thy and Fei-Fei, 2015), so we propose to learn a structured multimedia embedding space.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the limitations of existing multimedia representation methods.",
      "processing_time": 55.5476188659668,
      "citing_paper_id": "218501728",
      "cited_paper_id": 6095318
    },
    {
      "context_text": "…whole image, as shown in Figure 8. main (Ji and Grishman, 2008; Liao and Grishman, 2011; Huang and Riloff, 2012; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Hong et al., 2018; Liu et al., 2018b; Chen et al., 2018; Zhang et al., 2019; Liu et al., 2018a; Wang et al., 2019; Yang et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. There are no clear identifiers for datasets, and the context does not indicate the use of any specific dataset.",
      "processing_time": 58.38397216796875,
      "citing_paper_id": "218501728",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Given the AMR graph, we apply a Graph Convolutional Network (GCN) (Kipf and Welling, 2016) to encode the graph contextual information following (Liu et al., 2018a): (1) where N ( i ) is the neighbour nodes of w i in the AMR graph, E ( i, j ) is the edge type between w i and w j , g ij is the gate following (Liu et al., 2018a), k represents GCN layer number, and f is the Sigmoid function.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on the application of a Graph Convolutional Network (GCN) to encode graph contextual information in AMR graphs.",
      "processing_time": 59.42683148384094,
      "citing_paper_id": "218501728",
      "cited_paper_id": 7771402
    },
    {
      "context_text": "To encode each text sentence, we run the CAMR parser (Wang et al., 2015b,a, 2016) to generate an AMR graph, based on the named entity recognition and part-of-speech (POS) tagging results from Stanford CoreNLP (Manning et al., 2014).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions tools and methods (CAMR parser, Stanford CoreNLP) but does not reference any specific datasets. The citation is focused on the process of generating AMR graphs using these tools.",
      "processing_time": 59.15214157104492,
      "citing_paper_id": "218501728",
      "cited_paper_id": 7771402
    },
    {
      "context_text": "Image Structured Representation: To obtain image structures similar to AMR graphs, and inspired by situation recognition (Yatskar et al., 2016), we represent each image with a situation graph , that is a star-shaped graph as shown in Figure 4, where the central node is labeled as a verb v (e.g., destroying ), and the neighbor nodes are arguments labeled as { ( n, r ) } , where n is a noun (e.g., ship ) derived from WordNet synsets (Miller, 1995) to indicate the entity type, and r indicates the role (e.g., item ) played by the entity in the event, based on FrameNet (Fillmore et al., 2003).",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes the construction of image structure representations using concepts from WordNet and FrameNet, but does not mention specific datasets. WordNet and FrameNet are resources, but they are not used as datasets in the described methodology.",
      "processing_time": 60.189467906951904,
      "citing_paper_id": "218501728",
      "cited_paper_id": 7771402
    },
    {
      "context_text": "Image Structured Representation: To obtain image structures similar to AMR graphs, and inspired by situation recognition (Yatskar et al., 2016), we represent each image with a situation graph , that is a star-shaped graph as shown in Figure 4, where the central node is labeled as a verb v (e.g., destroying ), and the neighbor nodes are arguments labeled as { ( n, r ) } , where n is a noun (e.g., ship ) derived from WordNet synsets (Miller, 1995) to indicate the entity type, and r indicates the role (e.g., item ) played by the entity in the event, based on FrameNet (Fillmore et al., 2003).",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes the construction of image structure representations using concepts from WordNet and FrameNet, but does not mention specific datasets. WordNet and FrameNet are resources, but they are not used as datasets in the described methodology.",
      "processing_time": 60.189467906951904,
      "citing_paper_id": "218501728",
      "cited_paper_id": 62167673
    },
    {
      "context_text": "Text Structured Representation: As shown in Figure 4, we choose Abstract Meaning Representation (AMR) (Banarescu et al., 2013) to represent text because it includes a rich set of 150 ﬁne-grained semantic roles.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a representation method (AMR). AMR is used to represent text with fine-grained semantic roles, which is not a dataset.",
      "processing_time": 58.39726972579956,
      "citing_paper_id": "218501728",
      "cited_paper_id": 7771402
    },
    {
      "context_text": "Multimedia Representation Multimedia common representation has attracted much attention recently (Toselli et al., 2007; Weegar et al., 2015; Hewitt et al., 2018; Chen et al., 2019; Liu et al., 2019; Su et al., 2019a; Saraﬁanos et al., 2019; Sun et al., 2019b; Tan and Bansal, 2019; Li et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to multimedia representation and alignment between text images and transcripts. No verifiable datasets are named.",
      "processing_time": 56.65696954727173,
      "citing_paper_id": "218501728",
      "cited_paper_id": 12948924
    },
    {
      "context_text": "Multimedia Representation Multimedia common representation has attracted much attention recently (Toselli et al., 2007; Weegar et al., 2015; Hewitt et al., 2018; Chen et al., 2019; Liu et al., 2019; Su et al., 2019a; Saraﬁanos et al., 2019; Sun et al., 2019b; Tan and Bansal, 2019; Li et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to multimedia representation and alignment between text images and transcripts. No verifiable datasets are named.",
      "processing_time": 56.65696954727173,
      "citing_paper_id": "218501728",
      "cited_paper_id": 21668375
    },
    {
      "context_text": "More speciﬁcally, we use a VGG-16 CNN to extract a 7 × 7 convolutional feature map for each image m , which can be regarded as attention keys k i for 7 × 7 local regions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (VGG-16 CNN) for extracting features from images.",
      "processing_time": 55.897371768951416,
      "citing_paper_id": "218501728",
      "cited_paper_id": 14124313
    },
    {
      "context_text": "Compare to State-of-the-art While WASE att achieves a higher argument recall as it is not limited by the predeﬁned object classes of the Faster R-CNN.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison to a method (WASE) and a model (Faster R-CNN).",
      "processing_time": 56.901458978652954,
      "citing_paper_id": "218501728",
      "cited_paper_id": 14124313
    },
    {
      "context_text": "WASE obj predicts more accurate bounding boxes since it is based on a Faster R-CNN pretrained on bounding box annotations, resulting in a higher argument precision.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Faster R-CNN) and its performance. No verifiable resources are identified.",
      "processing_time": 57.06680607795715,
      "citing_paper_id": "218501728",
      "cited_paper_id": 14124313
    },
    {
      "context_text": "We employ a VGG-16 CNN (Simonyan and Zisserman, 2014) to extract visual features of an image m and and another VGG-16 to encode the bounding boxes {oi}.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions VGG-16 CNN but does not refer to any specific dataset. It focuses on the use of VGG-16 for feature extraction and encoding bounding boxes.",
      "processing_time": 58.780662536621094,
      "citing_paper_id": "218501728",
      "cited_paper_id": 14124313
    },
    {
      "context_text": "There are a few methods that aim to localize the agent (Gu et al., 2018; Li et al., 2018; Duarte et al., 2018), or classify the recipient (Sigurdsson et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 55.250771284103394,
      "citing_paper_id": "218501728",
      "cited_paper_id": 29165964
    },
    {
      "context_text": "There are a few methods that aim to localize the agent (Gu et al., 2018; Li et al., 2018; Duarte et al., 2018), or classify the recipient (Sig-urdsson et al., 2016; Kato et al., 2018; Wu et al., 2019a) of events, but neither detects the complete set of arguments for an event.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for localizing agents or classifying recipients of events.",
      "processing_time": 56.22194242477417,
      "citing_paper_id": "218501728",
      "cited_paper_id": 29165964
    },
    {
      "context_text": "There are a few methods that aim to localize the agent (Gu et al., 2018; Li et al., 2018; Duarte et al., 2018), or classify the recipient (Sig-urdsson et al., 2016; Kato et al., 2018; Wu et al., 2019a) of events, but neither detects the complete set of arguments for an event.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for localizing agents or classifying recipients of events.",
      "processing_time": 56.22194242477417,
      "citing_paper_id": "218501728",
      "cited_paper_id": 52956197
    },
    {
      "context_text": "We also compare to the state-of-the-art cross-media common representation model, Contrastive Visual Semantic Embedding VSE-C (Shi et al., 2018), by training it the same way as WASE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (VSE-C) which is excluded according to the instructions.",
      "processing_time": 56.23232388496399,
      "citing_paper_id": "218501728",
      "cited_paper_id": 49480783
    },
    {
      "context_text": "…in Figure 8. main (Ji and Grishman, 2008; Liao and Grishman, 2011; Huang and Riloff, 2012; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Hong et al., 2018; Liu et al., 2018b; Chen et al., 2018; Zhang et al., 2019; Liu et al., 2018a; Wang et al., 2019; Yang et al., 2019; Wadden et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. There are no clear identifiers for datasets, and the context does not provide enough information to infer the use of any specific datasets.",
      "processing_time": 59.96477389335632,
      "citing_paper_id": "218501728",
      "cited_paper_id": 51882793
    },
    {
      "context_text": "…8. main (Ji and Grishman, 2008; Liao and Grishman, 2011; Huang and Riloff, 2012; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Hong et al., 2018; Liu et al., 2018b; Chen et al., 2018; Zhang et al., 2019; Liu et al., 2018a; Wang et al., 2019; Yang et al., 2019; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 17.350923538208008,
      "citing_paper_id": "218501728",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "…8. main (Ji and Grishman, 2008; Liao and Grishman, 2011; Huang and Riloff, 2012; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Hong et al., 2018; Liu et al., 2018b; Chen et al., 2018; Zhang et al., 2019; Liu et al., 2018a; Wang et al., 2019; Yang et al., 2019; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 17.350923538208008,
      "citing_paper_id": "218501728",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "…8. main (Ji and Grishman, 2008; Liao and Grishman, 2011; Huang and Riloff, 2012; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Hong et al., 2018; Liu et al., 2018b; Chen et al., 2018; Zhang et al., 2019; Liu et al., 2018a; Wang et al., 2019; Yang et al., 2019; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 17.350923538208008,
      "citing_paper_id": "218501728",
      "cited_paper_id": 201665978
    },
    {
      "context_text": "However, the practice of contemporary journalism (Stephens, 1998) distributes news via multimedia.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It refers to a general practice in journalism, which is not a dataset.",
      "processing_time": 56.52725172042847,
      "citing_paper_id": "218501728",
      "cited_paper_id": 60074195
    },
    {
      "context_text": "…destroying ), and the neighbor nodes are arguments labeled as { ( n, r ) } , where n is a noun (e.g., ship ) derived from WordNet synsets (Miller, 1995) to indicate the entity type, and r indicates the role (e.g., item ) played by the entity in the event, based on FrameNet (Fillmore et al., 2003).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions WordNet and FrameNet, but these are not datasets; they are lexical resources and frameworks. No specific datasets are mentioned.",
      "processing_time": 56.924251079559326,
      "citing_paper_id": "218501728",
      "cited_paper_id": 62167673
    },
    {
      "context_text": "…recently (Toselli et al., 2007; Weegar et al., 2015; Hewitt et al., 2018; Chen et al., 2019; Liu et al., 2019; Su et al., 2019a; Saraﬁanos et al., 2019; Sun et al., 2019b; Tan and Bansal, 2019; Li et al., 2019a,b; Lu et al., 2019; Sun et al., 2019a; Rah-man et al., 2019; Su et al., 2019b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. No dataset names are present in the context.",
      "processing_time": 56.50757932662964,
      "citing_paper_id": "218501728",
      "cited_paper_id": 189762371
    },
    {
      "context_text": "…recently (Toselli et al., 2007; Weegar et al., 2015; Hewitt et al., 2018; Chen et al., 2019; Liu et al., 2019; Su et al., 2019a; Saraﬁanos et al., 2019; Sun et al., 2019b; Tan and Bansal, 2019; Li et al., 2019a,b; Lu et al., 2019; Sun et al., 2019a; Rah-man et al., 2019; Su et al., 2019b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. No dataset names are present in the context.",
      "processing_time": 56.50757932662964,
      "citing_paper_id": "218501728",
      "cited_paper_id": 199528533
    },
    {
      "context_text": "…recently (Toselli et al., 2007; Weegar et al., 2015; Hewitt et al., 2018; Chen et al., 2019; Liu et al., 2019; Su et al., 2019a; Saraﬁanos et al., 2019; Sun et al., 2019b; Tan and Bansal, 2019; Li et al., 2019a,b; Lu et al., 2019; Sun et al., 2019a; Rah-man et al., 2019; Su et al., 2019b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. No dataset names are present in the context.",
      "processing_time": 56.50757932662964,
      "citing_paper_id": "218501728",
      "cited_paper_id": 201103729
    },
    {
      "context_text": "…recently (Toselli et al., 2007; Weegar et al., 2015; Hewitt et al., 2018; Chen et al., 2019; Liu et al., 2019; Su et al., 2019a; Saraﬁanos et al., 2019; Sun et al., 2019b; Tan and Bansal, 2019; Li et al., 2019a,b; Lu et al., 2019; Sun et al., 2019a; Rah-man et al., 2019; Su et al., 2019b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. No dataset names are present in the context.",
      "processing_time": 56.50757932662964,
      "citing_paper_id": "218501728",
      "cited_paper_id": 203594078
    },
    {
      "context_text": "…recently (Toselli et al., 2007; Weegar et al., 2015; Hewitt et al., 2018; Chen et al., 2019; Liu et al., 2019; Su et al., 2019a; Saraﬁanos et al., 2019; Sun et al., 2019b; Tan and Bansal, 2019; Li et al., 2019a,b; Lu et al., 2019; Sun et al., 2019a; Rah-man et al., 2019; Su et al., 2019b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. No dataset names are present in the context.",
      "processing_time": 56.50757932662964,
      "citing_paper_id": "218501728",
      "cited_paper_id": 208001853
    },
    {
      "context_text": "…Classiﬁer: We classify each word w into event types y e 6 and classify each entity t into argument role y a : We take ground truth text entity mentions as input following (Ji and Grishman, 2008) during training, and obtain testing entity mentions using a named entity extractor (Lin et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and processes. The context focuses on the classification of words into event types and entities into argument roles, using ground truth text entity mentions and a named entity extractor.",
      "processing_time": 60.722285747528076,
      "citing_paper_id": "218501728",
      "cited_paper_id": 196202217
    },
    {
      "context_text": "We take ground truth text entity mentions as input following (Ji and Grishman, 2008) during training, and obtain testing entity mentions using a named entity extractor (Lin et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and processes. No verifiable resources are identified.",
      "processing_time": 56.09148073196411,
      "citing_paper_id": "218501728",
      "cited_paper_id": 196202217
    },
    {
      "context_text": "Multimedia Representation Multimedia common representation has attracted much attention recently (Toselli et al., 2007; Weegar et al., 2015; Hewitt et al., 2018; Chen et al., 2019; Liu et al., 2019; Su et al., 2019a; Sarafianos et al., 2019; Sun et al., 2019b; Tan and Bansal, 2019; Li et al., 2019a,b; Lu et al., 2019; Sun et al., 2019a; Rahman et al., 2019; Su et al., 2019b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to multimedia representation and cross-modal research. No verifiable resources are identified.",
      "processing_time": 56.90756368637085,
      "citing_paper_id": "218501728",
      "cited_paper_id": 201103729
    },
    {
      "context_text": "Multimedia Representation Multimedia common representation has attracted much attention recently (Toselli et al., 2007; Weegar et al., 2015; Hewitt et al., 2018; Chen et al., 2019; Liu et al., 2019; Su et al., 2019a; Sarafianos et al., 2019; Sun et al., 2019b; Tan and Bansal, 2019; Li et al., 2019a,b; Lu et al., 2019; Sun et al., 2019a; Rahman et al., 2019; Su et al., 2019b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to multimedia representation and cross-modal research. No verifiable resources are identified.",
      "processing_time": 56.90756368637085,
      "citing_paper_id": "218501728",
      "cited_paper_id": 208001853
    },
    {
      "context_text": "We then input the word sequence to a bi-directional long short term memory (Bi-LSTM) (Graves et al., 2013) network to encode the word order and get the representation of each word w .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Bi-LSTM).",
      "processing_time": 54.91607475280762,
      "citing_paper_id": "218501728",
      "cited_paper_id": 206741496
    },
    {
      "context_text": "We then input the word sequence to a bi-directional long short term memory (Bi-LSTM) (Graves et al., 2013) network to encode the word order and get the representation of each word w.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Bi-LSTM).",
      "processing_time": 55.112285137176514,
      "citing_paper_id": "218501728",
      "cited_paper_id": 206741496
    },
    {
      "context_text": "…has attracted much attention recently (Toselli et al., 2007; Weegar et al., 2015; Hewitt et al., 2018; Chen et al., 2019; Liu et al., 2019; Su et al., 2019a; Saraﬁanos et al., 2019; Sun et al., 2019b; Tan and Bansal, 2019; Li et al., 2019a,b; Lu et al., 2019; Sun et al., 2019a; Rah-man et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies. There are no clear identifiers for datasets, models, or methods.",
      "processing_time": 58.21855616569519,
      "citing_paper_id": "218501728",
      "cited_paper_id": 208001853
    },
    {
      "context_text": "We follow the ACE event annotation guidelines (Walker et al., 2006) for textual event and argument annotation, and design an annotation guideline 4 for multimedia events annotation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'ACE event annotation guidelines' but does not refer to a specific dataset. It is a method or set of guidelines rather than a dataset.",
      "processing_time": 57.137770891189575,
      "citing_paper_id": "218501728",
      "cited_paper_id": null
    },
    {
      "context_text": "For instance, (Ren et al., 2017; Zheng et al., 2017; Zeng et al., 2018a; Wang et al., 2018) focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.590686559677124,
      "citing_paper_id": "119308902",
      "cited_paper_id": 1724837
    },
    {
      "context_text": "For instance, (Ren et al., 2017; Zheng et al., 2017; Zeng et al., 2018a; Wang et al., 2018) focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.590686559677124,
      "citing_paper_id": "119308902",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "For instance, (Ren et al., 2017; Zheng et al., 2017; Zeng et al., 2018a; Wang et al., 2018) focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.590686559677124,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51605731
    },
    {
      "context_text": "For instance, (Ren et al., 2017; Zheng et al., 2017; Zeng et al., 2018a; Wang et al., 2018) focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.590686559677124,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51870827
    },
    {
      "context_text": "For instance, [Ren et al. , 2017; Zheng et al. , 2017; Zeng et al. , 2018a; Wang et al. , 2018] focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about specific datasets.",
      "processing_time": 59.81557536125183,
      "citing_paper_id": "119308902",
      "cited_paper_id": 1724837
    },
    {
      "context_text": "For instance, [Ren et al. , 2017; Zheng et al. , 2017; Zeng et al. , 2018a; Wang et al. , 2018] focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about specific datasets.",
      "processing_time": 59.81557536125183,
      "citing_paper_id": "119308902",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "For instance, [Ren et al. , 2017; Zheng et al. , 2017; Zeng et al. , 2018a; Wang et al. , 2018] focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about specific datasets.",
      "processing_time": 59.81557536125183,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51605731
    },
    {
      "context_text": "For instance, [Ren et al. , 2017; Zheng et al. , 2017; Zeng et al. , 2018a; Wang et al. , 2018] focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about specific datasets.",
      "processing_time": 59.81557536125183,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51870827
    },
    {
      "context_text": "To mitigate such problems, we utilize the scheduled sampling (Bengio et al., 2015) to gradually switch the inputs of document-level entity encoding from ground-truth entity mentions to model recognized ones.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (scheduled sampling).",
      "processing_time": 55.55149841308594,
      "citing_paper_id": "119308902",
      "cited_paper_id": 1820089
    },
    {
      "context_text": "Although a great number of efforts [Ahn, 2006; Ji and Gr-ishman, 2008; Liao and Grishman, 2010; Hong et al. , 2011; Riedel and McCallum, 2011; Li et al. , 2013; Li et al. , 2014; Chen et al. , 2015; Yang and Mitchell, 2016; Nguyen et al. , 2016; Liu et al. , 2017; Sha et al. , 2018; Zhang and Ji,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 58.79112148284912,
      "citing_paper_id": "119308902",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Although a great number of efforts [Ahn, 2006; Ji and Gr-ishman, 2008; Liao and Grishman, 2010; Hong et al. , 2011; Riedel and McCallum, 2011; Li et al. , 2013; Li et al. , 2014; Chen et al. , 2015; Yang and Mitchell, 2016; Nguyen et al. , 2016; Liu et al. , 2017; Sha et al. , 2018; Zhang and Ji,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 58.79112148284912,
      "citing_paper_id": "119308902",
      "cited_paper_id": 18198203
    },
    {
      "context_text": "Traditionally, when applying DS to relation extraction, researchers put huge efforts into alleviating labeling noises (Riedel et al., 2010; Lin et al., 2016; Feng et al., 2018; Zheng et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research efforts in relation extraction. No verifiable resources are identified.",
      "processing_time": 58.19731020927429,
      "citing_paper_id": "119308902",
      "cited_paper_id": 2386383
    },
    {
      "context_text": "Traditionally, when applying DS to relation extraction, researchers put huge efforts into alleviating labeling noises (Riedel et al., 2010; Lin et al., 2016; Feng et al., 2018; Zheng et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research efforts in relation extraction. No verifiable resources are identified.",
      "processing_time": 58.19731020927429,
      "citing_paper_id": "119308902",
      "cited_paper_id": 182953200
    },
    {
      "context_text": "Besides, we employ the Adam [ Kingma and Ba, 2015 ] optimizer with the learning rate 1 e − 4 , train for at most 100 epochs and pick the best epoch by the validation score on the development set.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Adam optimizer).",
      "processing_time": 55.7415714263916,
      "citing_paper_id": "119308902",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "…the scaled dot-product attention [Vaswani et al. , 2017] operations: to produce a single embedding ˆ x ∈ R d w , where Q ∈ R d w is a trainable parameter, LayerNorm is the layer normalization [Ba et al. , 2016] and Dropout is an effective technique to avoid overﬁtting [Srivastava et al. , 2014].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 58.481661558151245,
      "citing_paper_id": "119308902",
      "cited_paper_id": 8236317
    },
    {
      "context_text": "Therefore, (Chen et al., 2017; Yang et al., 2018) employed either linguistic resources or predefined dictionaries for trigger-words labeling.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of linguistic resources or predefined dictionaries. No clear, verifiable dataset names are provided.",
      "processing_time": 57.946571350097656,
      "citing_paper_id": "119308902",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Therefore, [Chen et al. , 2017; Yang et al. , 2018] employed either linguistic resources or predeﬁned dictionaries for trigger-words labeling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of linguistic resources or predefined dictionaries. No clear, verifiable dataset names are provided.",
      "processing_time": 57.94559669494629,
      "citing_paper_id": "119308902",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Moreover, for the entity recognition part, we refer readers to [Huang et al. , 2015] for details about stacking the conditional random ﬁeld (CRF) layer over encoded representations.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CRF layer) used in sequence tagging.",
      "processing_time": 57.1333692073822,
      "citing_paper_id": "119308902",
      "cited_paper_id": 12740621
    },
    {
      "context_text": "We conduct this task at the sentence level and follow a classic method, BI-LSTM-CRF (Huang et al., 2015), that first encodes the token sequence and then adds a conditional random field (CRF) layer to facilitate the sequence tagging.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BI-LSTM-CRF) used for sequence tagging.",
      "processing_time": 57.95850372314453,
      "citing_paper_id": "119308902",
      "cited_paper_id": 12740621
    },
    {
      "context_text": "…same to the focus of this paper, a few studies aimed at designing joint models for the entity and event extraction, such as handcrafted-feature-based [Li et al. , 2014; Yang and Mitchell, 2016; Judea and Strube, 2016] and neural-network-based [ Zhang and Ji, 2018; Nguyen and Nguyen, 2019] models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods for entity and event extraction.",
      "processing_time": 58.19985222816467,
      "citing_paper_id": "119308902",
      "cited_paper_id": 14175558
    },
    {
      "context_text": "…same to the focus of this paper, a few studies aimed at designing joint models for the entity and event extraction, such as handcrafted-feature-based [Li et al. , 2014; Yang and Mitchell, 2016; Judea and Strube, 2016] and neural-network-based [ Zhang and Ji, 2018; Nguyen and Nguyen, 2019] models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods for entity and event extraction.",
      "processing_time": 58.19985222816467,
      "citing_paper_id": "119308902",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "…[Ahn, 2006; Ji and Gr-ishman, 2008; Liao and Grishman, 2010; Hong et al. , 2011; Riedel and McCallum, 2011; Li et al. , 2013; Li et al. , 2014; Chen et al. , 2015; Yang and Mitchell, 2016; Nguyen et al. , 2016; Liu et al. , 2017; Sha et al. , 2018; Zhang and Ji, 2018; Nguyen and Nguyen, 2019…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. There are no clear identifiers for datasets within the provided context.",
      "processing_time": 59.584211111068726,
      "citing_paper_id": "119308902",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Although a great number of efforts (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Riedel and McCallum, 2011; Li et al., 2013, 2014; Chen et al., 2015; Yang and Mitchell, 2016; Nguyen et al., 2016; Liu et al., 2017; Sha et al., 2018; Zhang and Ji, 2018; Nguyen and Nguyen, 2019; Wang et al., 2019) have been put on EE, most of them are based on ACE 20052, an expert-annotated benchmark, which only tagged event arguments within the sentence scope.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to tag event arguments within the sentence scope, serving as an expert-annotated benchmark for event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE 2005' as an expert-annotated benchmark used for event extraction, which fits the criteria for a dataset. It is used to tag event arguments within the sentence scope.",
      "processing_time": 68.03539085388184,
      "citing_paper_id": "119308902",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "In the meantime, the same to the focus of this paper, a few studies aimed at designing joint models for the entity and event extraction, such as handcrafted-feature-based (Li et al., 2014; Yang and Mitchell, 2016; Judea and Strube, 2016) and neural-network-based (Zhang and Ji, 2018; Nguyen and Nguyen, 2019) models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the design of joint models for entity and event extraction.",
      "processing_time": 58.98334288597107,
      "citing_paper_id": "119308902",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "…number of efforts [Ahn, 2006; Ji and Gr-ishman, 2008; Liao and Grishman, 2010; Hong et al. , 2011; Riedel and McCallum, 2011; Li et al. , 2013; Li et al. , 2014; Chen et al. , 2015; Yang and Mitchell, 2016; Nguyen et al. , 2016; Liu et al. , 2017; Sha et al. , 2018; Zhang and Ji, 2018; Nguyen…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 60.70128107070923,
      "citing_paper_id": "119308902",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "On the other hand, another recent work [Zeng et al. , 2018b] showed that directly labeling event arguments without trigger words was also feasible.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for labeling event arguments without trigger words.",
      "processing_time": 58.19219255447388,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51870827
    },
    {
      "context_text": "Some previous studies [Zeng et al. , 2018b] attempted to use a similar no-trigger-words design, but they only considered the SEE setting and cannot be directly applied to the DEE setting.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach in a related study.",
      "processing_time": 58.1902220249176,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51870827
    },
    {
      "context_text": "To address this problem, some researches attempted to adapt distant supervision (DS) to the EE setting, since DS has shown promising results by employing knowledge bases to generate training data for relation extraction [Mintz et al., 2009] automatically.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (distant supervision) and its application to event extraction. No verifiable resources are named.",
      "processing_time": 59.77836632728577,
      "citing_paper_id": "119308902",
      "cited_paper_id": null
    },
    {
      "context_text": ", 2018], attempted to explore DEE on ChFinAnn, by employing distant supervision (DS) [Mintz et al., 2009] to generate EE data and performing a two-stage extraction: 1) a sequence tagging model for SEE, and 2) a key-event-sentence detection model to detect the key sentence and an arguments-completion strategy that padded missing arguments from surrounding sentences for DEE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used to explore document-level event extraction (DEE) through distant supervision and a two-stage extraction process involving sequence tagging and key-event-sentence detection."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ChFinAnn' as a specific dataset used for document-level event extraction. The dataset is used to explore DEE using distant supervision and a two-stage extraction process.",
      "processing_time": 68.62664675712585,
      "citing_paper_id": "119308902",
      "cited_paper_id": null
    },
    {
      "context_text": "To address this problem, some researches attempted to adapt distant supervision (DS) to the EE setting, since DS has shown promising results by employing knowledge bases to generate training data for relation extraction [Mintz et al. , 2009] automatically.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (distant supervision) and its application to event extraction. No verifiable resources are named.",
      "processing_time": 59.995781898498535,
      "citing_paper_id": "119308902",
      "cited_paper_id": null
    },
    {
      "context_text": "There are a variety of settings explored, including zero-shot transfer learning (Lyu et al., 2021; Huang et al., 2018), cross-lingual transfer (Subburathinam et al., 2019), inducing event types (Huang et al., 2016; Wang et al., 2021b), keyword-based supervision (Zhang et al., 2021) and few-shot…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methodologies and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.31117916107178,
      "citing_paper_id": "249010869",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "There are a variety of settings explored, including zero-shot transfer learning (Lyu et al., 2021; Huang et al., 2018), cross-lingual trans-",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. No dataset names are present in the text.",
      "processing_time": 59.57019567489624,
      "citing_paper_id": "249010869",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "Prior to this work, there has been some effort in creating schema databases through crowdsourcing (Regneri et al., 2010; Modi et al., 2016; Wanzare et al., 2016; Sak-aguchi et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation mentions 'schema databases' created through crowdsourcing but does not specify any named, verifiable datasets. The context does not provide enough detail to identify specific datasets.",
      "processing_time": 61.368759632110596,
      "citing_paper_id": "249010869",
      "cited_paper_id": 2514272
    },
    {
      "context_text": "Existing link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) or knowledge graph completion methods (Zhang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 59.554943323135376,
      "citing_paper_id": "249010869",
      "cited_paper_id": 3573161
    },
    {
      "context_text": "Existing link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) or knowledge graph completion methods (Zhang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 59.554943323135376,
      "citing_paper_id": "249010869",
      "cited_paper_id": 59316666
    },
    {
      "context_text": "Schema-Guided Event Prediction Our schemaguided event prediction model is also related to link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) and graph completion (Zhang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers are about link prediction and graph completion, which do not introduce specific datasets.",
      "processing_time": 61.3655207157135,
      "citing_paper_id": "249010869",
      "cited_paper_id": 3573161
    },
    {
      "context_text": "Schema-Guided Event Prediction Our schemaguided event prediction model is also related to link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) and graph completion (Zhang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers are about link prediction and graph completion, which do not introduce specific datasets.",
      "processing_time": 61.3655207157135,
      "citing_paper_id": "249010869",
      "cited_paper_id": 59316666
    },
    {
      "context_text": "process, through the use of probabilistic graphical models (Chambers, 2013; Cheung et al., 2013; Nguyen et al., 2015; Weber et al., 2018) and eventbased language models (Pichotta and Mooney, 2016; Modi and Titov, 2014; Rudinger et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 60.684765577316284,
      "citing_paper_id": "249010869",
      "cited_paper_id": 6341459
    },
    {
      "context_text": "Event Schema Induction and Curation Event schemas, or otherwise known as scripts, are structures that represent typical event progressions (Schank and Abelson, 1975).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a theoretical concept. No dataset names are present in the citation span.",
      "processing_time": 59.98571276664734,
      "citing_paper_id": "249010869",
      "cited_paper_id": 18113275
    },
    {
      "context_text": ", 2020); coreference component on ACE05, EDL 2016 (LDC2017E03), EDL 2017 (LDC2017E52), OntoNotes (Pradhan et al., 2012), ERE, CoNLL 2002 (Tjong Kim Sang, 2002), DCEP (Dias, 2016) and SemEval10 (Recasens",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05",
        "EDL 2016 (LDC2017E03)",
        "EDL 2017 (LDC2017E52)",
        "OntoNotes",
        "ERE",
        "CoNLL 2002",
        "DCEP",
        "SemEval10"
      ],
      "dataset_descriptions": {
        "ACE05": "Used for coreference resolution, focusing on identifying and linking entities across documents in various domains.",
        "EDL 2016 (LDC2017E03)": "Used for entity discovery and linking, evaluating the system's ability to identify and link named entities in text.",
        "EDL 2017 (LDC2017E52)": "Used for entity discovery and linking, assessing the performance of systems in identifying and linking entities in diverse texts.",
        "OntoNotes": "Used for coreference resolution, providing a large-scale annotated corpus for training and evaluating coreference models.",
        "ERE": "Used for entity recognition and linking, focusing on identifying and linking entities in multilingual and cross-document contexts.",
        "CoNLL 2002": "Used for named entity recognition, specifically for identifying and classifying named entities in Spanish and Dutch texts.",
        "DCEP": "Used for entity linking, focusing on linking entities to a knowledge base in Portuguese texts.",
        "SemEval10": "Used for semantic evaluation, particularly for tasks involving entity linking and coreference resolution."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions several datasets used for coreference resolution and entity linking tasks. These datasets are specific and have clear identifiers.",
      "processing_time": 114.84262442588806,
      "citing_paper_id": "249010869",
      "cited_paper_id": 41479182
    },
    {
      "context_text": "Existing link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) or knowledge graph completion meth-ods (Zhang et al., 2019; Goel et al., 2020; Wang et al., 2021a) cannot meet this goal because the event instance graphs extracted from news are often incomplete and noisy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 60.681177377700806,
      "citing_paper_id": "249010869",
      "cited_paper_id": 59316666
    },
    {
      "context_text": "Existing link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) or knowledge graph completion meth-ods (Zhang et al., 2019; Goel et al., 2020; Wang et al., 2021a) cannot meet this goal because the event instance graphs extracted from news are often incomplete and noisy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 60.681177377700806,
      "citing_paper_id": "249010869",
      "cited_paper_id": 195833229
    },
    {
      "context_text": "Existing link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) or knowledge graph completion meth-ods (Zhang et al., 2019; Goel et al., 2020; Wang et al., 2021a) cannot meet this goal because the event instance graphs extracted from news are often incomplete and noisy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 60.681177377700806,
      "citing_paper_id": "249010869",
      "cited_paper_id": 202763266
    },
    {
      "context_text": "Existing link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) or knowledge graph completion meth-ods (Zhang et al., 2019; Goel et al., 2020; Wang et al., 2021a) cannot meet this goal because the event instance graphs extracted from news are often incomplete and noisy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 60.681177377700806,
      "citing_paper_id": "249010869",
      "cited_paper_id": 235254286
    },
    {
      "context_text": "Schema-Guided Event Prediction Our schema-guided event prediction model is also related to link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) and graph completion (Zhang et al., 2019; Goel et al., 2020; Wang et al., 2021a) methods.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 61.011505365371704,
      "citing_paper_id": "249010869",
      "cited_paper_id": 59316666
    },
    {
      "context_text": "Schema-Guided Event Prediction Our schema-guided event prediction model is also related to link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) and graph completion (Zhang et al., 2019; Goel et al., 2020; Wang et al., 2021a) methods.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 61.011505365371704,
      "citing_paper_id": "249010869",
      "cited_paper_id": 195833229
    },
    {
      "context_text": "Schema-Guided Event Prediction Our schema-guided event prediction model is also related to link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) and graph completion (Zhang et al., 2019; Goel et al., 2020; Wang et al., 2021a) methods.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 61.011505365371704,
      "citing_paper_id": "249010869",
      "cited_paper_id": 202763266
    },
    {
      "context_text": "Schema-Guided Event Prediction Our schema-guided event prediction model is also related to link prediction (Zhang and Chen, 2018; Wang et al., 2018; Lei et al., 2019) and graph completion (Zhang et al., 2019; Goel et al., 2020; Wang et al., 2021a) methods.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 61.011505365371704,
      "citing_paper_id": "249010869",
      "cited_paper_id": 235254286
    },
    {
      "context_text": ", 2019) or knowledge graph completion methods (Zhang et al., 2019; Goel et al., 2020; Wang et al., 2021a) cannot meet this goal because the event instance graphs extracted from news are often incomplete and noisy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and their limitations. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 61.18836545944214,
      "citing_paper_id": "249010869",
      "cited_paper_id": 195833229
    },
    {
      "context_text": ", 2019) or knowledge graph completion methods (Zhang et al., 2019; Goel et al., 2020; Wang et al., 2021a) cannot meet this goal because the event instance graphs extracted from news are often incomplete and noisy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and their limitations. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 61.18836545944214,
      "citing_paper_id": "249010869",
      "cited_paper_id": 202763266
    },
    {
      "context_text": "…the schema induction process, through the use of probabilistic graphical models (Chambers, 2013; Cheung et al., 2013; Nguyen et al., 2015; Weber et al., 2018) and event-based language models (Pichotta and Mooney, 2016; Modi and Titov, 2014; Rudinger et al., 2015; Li et al., 2020b, 2021a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 61.55694842338562,
      "citing_paper_id": "249010869",
      "cited_paper_id": 215717250
    },
    {
      "context_text": "…the schema induction process, through the use of probabilistic graphical models (Chambers, 2013; Cheung et al., 2013; Nguyen et al., 2015; Weber et al., 2018) and event-based language models (Pichotta and Mooney, 2016; Modi and Titov, 2014; Rudinger et al., 2015; Li et al., 2020b, 2021a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 61.55694842338562,
      "citing_paper_id": "249010869",
      "cited_paper_id": 226262197
    },
    {
      "context_text": "…et al., 2018), cross-lingual transfer (Subburathinam et al., 2019), inducing event types (Huang et al., 2016; Wang et al., 2021b), keyword-based supervision (Zhang et al., 2021) and few-shot learning (Peng et al., 2016; Lai et al., 2020; Shen et al., 2021; Cong et al., 2021; Chen et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches for event detection and few-shot learning. No verifiable resources are identified.",
      "processing_time": 61.72846555709839,
      "citing_paper_id": "249010869",
      "cited_paper_id": 219792780
    },
    {
      "context_text": "…et al., 2018), cross-lingual transfer (Subburathinam et al., 2019), inducing event types (Huang et al., 2016; Wang et al., 2021b), keyword-based supervision (Zhang et al., 2021) and few-shot learning (Peng et al., 2016; Lai et al., 2020; Shen et al., 2021; Cong et al., 2021; Chen et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches for event detection and few-shot learning. No verifiable resources are identified.",
      "processing_time": 61.72846555709839,
      "citing_paper_id": "249010869",
      "cited_paper_id": 227305529
    },
    {
      "context_text": "…et al., 2018), cross-lingual transfer (Subburathinam et al., 2019), inducing event types (Huang et al., 2016; Wang et al., 2021b), keyword-based supervision (Zhang et al., 2021) and few-shot learning (Peng et al., 2016; Lai et al., 2020; Shen et al., 2021; Cong et al., 2021; Chen et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches for event detection and few-shot learning. No verifiable resources are identified.",
      "processing_time": 61.72846555709839,
      "citing_paper_id": "249010869",
      "cited_paper_id": 234790267
    },
    {
      "context_text": "…et al., 2018), cross-lingual transfer (Subburathinam et al., 2019), inducing event types (Huang et al., 2016; Wang et al., 2021b), keyword-based supervision (Zhang et al., 2021) and few-shot learning (Peng et al., 2016; Lai et al., 2020; Shen et al., 2021; Cong et al., 2021; Chen et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches for event detection and few-shot learning. No verifiable resources are identified.",
      "processing_time": 61.72846555709839,
      "citing_paper_id": "249010869",
      "cited_paper_id": 235097376
    },
    {
      "context_text": "…et al., 2018), cross-lingual transfer (Subburathinam et al., 2019), inducing event types (Huang et al., 2016; Wang et al., 2021b), keyword-based supervision (Zhang et al., 2021) and few-shot learning (Peng et al., 2016; Lai et al., 2020; Shen et al., 2021; Cong et al., 2021; Chen et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches for event detection and few-shot learning. No verifiable resources are identified.",
      "processing_time": 61.72846555709839,
      "citing_paper_id": "249010869",
      "cited_paper_id": 236477798
    },
    {
      "context_text": "Here we only show the primitive events under the Onset sub-schema. independent temporal ordering results from two learning-based pairwise event order classification systems (Zhou et al., 2021; Wen and Ji, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods or systems for event order classification.",
      "processing_time": 59.96479868888855,
      "citing_paper_id": "249010869",
      "cited_paper_id": 225066771
    },
    {
      "context_text": "First we provide two independent temporal ordering results from two learning-based pairwise event order classification systems (Zhou et al., 2021; Wen and Ji, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods or systems for event order classification.",
      "processing_time": 60.48975133895874,
      "citing_paper_id": "249010869",
      "cited_paper_id": 225066771
    },
    {
      "context_text": "First we provide two independent temporal ordering results from two learning-based pairwise event order classification systems (Zhou et al., 2021; Wen and Ji, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods or systems for event order classification.",
      "processing_time": 60.48975133895874,
      "citing_paper_id": "249010869",
      "cited_paper_id": 243865639
    },
    {
      "context_text": "…11 scenarios, our information extraction system consists of 3 components: (1) the supervised joint entity, relation and event extraction model OneIE (Lin et al., 2020); (2) weakly supervised keyword-guided event extraction; and (3) zero-shot generation-based argument extraction (Li et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the components of an information extraction system.",
      "processing_time": 61.72427725791931,
      "citing_paper_id": "249010869",
      "cited_paper_id": 226262197
    },
    {
      "context_text": "We train our mention extraction component on ACE05 (Walker et al., 2006) and ERE (Song et al., 2015); document-level argument extraction on ACE05 and RAMS (Ebner et al., 2020) DCEP (Dias, 2016) and SemEval10 (Recasens et al., 2010); temporal ordering component on MA-TRES (Ning et al., 2018); weakly supervised event extraction on ACE05; schema matching and prediction on LDC2022E03; visual event and argument extraction on M2E2 (Li et al., 2020a) and cross-media event coreference on Video M2E2 (Chen et al., 2021a).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05",
        "ERE",
        "RAMS",
        "DCEP",
        "SemEval10",
        "MA-TRES",
        "LDC2022E03",
        "M2E2",
        "Video M2E2"
      ],
      "dataset_descriptions": {
        "ACE05": "Used for training mention extraction and weakly supervised event extraction components, focusing on entity and event recognition in text.",
        "ERE": "Used for training mention extraction components, focusing on entity and relation extraction in text.",
        "RAMS": "Used for document-level argument extraction, focusing on identifying arguments for events in text.",
        "DCEP": "Used for document-level argument extraction, focusing on identifying arguments for events in text.",
        "SemEval10": "Used for document-level argument extraction, focusing on identifying arguments for events in text.",
        "MA-TRES": "Used for training the temporal ordering component, focusing on identifying temporal relations between events.",
        "LDC2022E03": "Used for schema matching and prediction, focusing on aligning event schemas across different sources.",
        "M2E2": "Used for visual event and argument extraction, focusing on identifying events and their arguments in multimedia content.",
        "Video M2E2": "Used for cross-media event coreference, focusing on linking events across different media types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions multiple datasets used for various components of event extraction systems, including mention extraction, argument extraction, temporal ordering, weakly supervised event extraction, schema matching, and visual event extraction.",
      "processing_time": 114.37066316604614,
      "citing_paper_id": "249010869",
      "cited_paper_id": 226262197
    },
    {
      "context_text": "Recent work (Li et al., 2020b, 2021a) proposes to leverage complex event schemas (stereotypical evolution pattern of complex events) for event prediction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only complex event schemas which are not considered datasets.",
      "processing_time": 60.667617082595825,
      "citing_paper_id": "249010869",
      "cited_paper_id": 226262197
    },
    {
      "context_text": "To achieve wide coverage of events types from 11 scenarios, our information extraction system consists of 3 components: (1) the supervised joint entity, relation and event extraction model OneIE (Lin et al., 2020); (2) weakly supervised keyword-guided event extraction; and (3) zero-shot generation-based argument extraction (Li et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the components of an information extraction system.",
      "processing_time": 16.75023651123047,
      "citing_paper_id": "249010869",
      "cited_paper_id": 226262197
    },
    {
      "context_text": "Based on OneIE relations output, we perform rule-based relation enrichment to obtain fine-grained relation subsubtypes.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enriching relations using OneIE relations output.",
      "processing_time": 61.544105052948,
      "citing_paper_id": "249010869",
      "cited_paper_id": 226262197
    },
    {
      "context_text": "…et al., 2010); temporal ordering component on MA-TRES (Ning et al., 2018); weakly supervised event extraction on ACE05; schema matching and prediction on LDC2022E03; visual event and argument extraction on M2E2 (Li et al., 2020a) and cross-media event coreference on Video M2E2 (Chen et al., 2021a).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05",
        "LDC2022E03",
        "M2E2",
        "Video M2E2"
      ],
      "dataset_descriptions": {
        "ACE05": "Used for weakly supervised event extraction, focusing on identifying events and their arguments in text.",
        "LDC2022E03": "Used for schema matching and prediction, enhancing the accuracy of event schema induction in complex documents.",
        "M2E2": "Used for visual event and argument extraction, integrating multimodal information to improve event detection in images and text.",
        "Video M2E2": "Used for cross-media event coreference, linking events across different media types to enhance multimedia event understanding."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions several datasets and resources used for various aspects of event extraction, including temporal ordering, weak supervision, schema matching, and visual event extraction.",
      "processing_time": 88.03959083557129,
      "citing_paper_id": "249010869",
      "cited_paper_id": 226262197
    },
    {
      "context_text": "OneIE is a joint neural model for sentence-level information extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model called OneIE. The context is about a method, not a dataset.",
      "processing_time": 62.8629195690155,
      "citing_paper_id": "249010869",
      "cited_paper_id": 226262197
    },
    {
      "context_text": "…learning (Lyu et al., 2021; Huang et al., 2018), cross-lingual transfer (Subburathinam et al., 2019), inducing event types (Huang et al., 2016; Wang et al., 2021b), keyword-based supervision (Zhang et al., 2021) and few-shot learning (Peng et al., 2016; Lai et al., 2020; Shen et al., 2021;…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches. No verifiable resources are identified.",
      "processing_time": 62.69516730308533,
      "citing_paper_id": "249010869",
      "cited_paper_id": 235254286
    },
    {
      "context_text": ", 2019), inducing event types (Huang et al., 2016; Wang et al., 2021b), keyword-based supervision (Zhang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and papers. There are no clear identifiers for datasets within the given context.",
      "processing_time": 63.69597244262695,
      "citing_paper_id": "249010869",
      "cited_paper_id": 235254286
    },
    {
      "context_text": ", 2021b), keyword-based supervision (Zhang et al., 2021) and few-shot learning (Peng et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets.",
      "processing_time": 62.85885262489319,
      "citing_paper_id": "249010869",
      "cited_paper_id": 236477798
    },
    {
      "context_text": "Both extractive [8, 9, 27, 34, 75, 76, 88, 89, 97, 123] and abstractive summarization [37, 38, 39, 58, 77, 86, 96, 108, 109] can only be used to compress or rewrite the text into a shorter form – neither can create a structured output of the form seen in Table 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only summarization methods and their limitations. No verifiable resources are identified.",
      "processing_time": 63.28542685508728,
      "citing_paper_id": "3519188",
      "cited_paper_id": 1320
    },
    {
      "context_text": "Both extractive [8, 9, 27, 34, 75, 76, 88, 89, 97, 123] and abstractive summarization [37, 38, 39, 58, 77, 86, 96, 108, 109] can only be used to compress or rewrite the text into a shorter form – neither can create a structured output of the form seen in Table 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only summarization methods and their limitations. No verifiable resources are identified.",
      "processing_time": 63.28542685508728,
      "citing_paper_id": "3519188",
      "cited_paper_id": 988010
    },
    {
      "context_text": "Both extractive [8, 9, 27, 34, 75, 76, 88, 89, 97, 123] and abstractive summarization [37, 38, 39, 58, 77, 86, 96, 108, 109] can only be used to compress or rewrite the text into a shorter form – neither can create a structured output of the form seen in Table 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only summarization methods and their limitations. No verifiable resources are identified.",
      "processing_time": 63.28542685508728,
      "citing_paper_id": "3519188",
      "cited_paper_id": 1918428
    },
    {
      "context_text": "Both extractive [8, 9, 27, 34, 75, 76, 88, 89, 97, 123] and abstractive summarization [37, 38, 39, 58, 77, 86, 96, 108, 109] can only be used to compress or rewrite the text into a shorter form – neither can create a structured output of the form seen in Table 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only summarization methods and their limitations. No verifiable resources are identified.",
      "processing_time": 63.28542685508728,
      "citing_paper_id": "3519188",
      "cited_paper_id": 6334682
    },
    {
      "context_text": "Both extractive [8, 9, 27, 34, 75, 76, 88, 89, 97, 123] and abstractive summarization [37, 38, 39, 58, 77, 86, 96, 108, 109] can only be used to compress or rewrite the text into a shorter form – neither can create a structured output of the form seen in Table 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only summarization methods and their limitations. No verifiable resources are identified.",
      "processing_time": 63.28542685508728,
      "citing_paper_id": "3519188",
      "cited_paper_id": 6511191
    },
    {
      "context_text": "Both extractive [8, 9, 27, 34, 75, 76, 88, 89, 97, 123] and abstractive summarization [37, 38, 39, 58, 77, 86, 96, 108, 109] can only be used to compress or rewrite the text into a shorter form – neither can create a structured output of the form seen in Table 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only summarization methods and their limitations. No verifiable resources are identified.",
      "processing_time": 63.28542685508728,
      "citing_paper_id": "3519188",
      "cited_paper_id": 8115414
    },
    {
      "context_text": "Both extractive [8, 9, 27, 34, 75, 76, 88, 89, 97, 123] and abstractive summarization [37, 38, 39, 58, 77, 86, 96, 108, 109] can only be used to compress or rewrite the text into a shorter form – neither can create a structured output of the form seen in Table 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only summarization methods and their limitations. No verifiable resources are identified.",
      "processing_time": 63.28542685508728,
      "citing_paper_id": "3519188",
      "cited_paper_id": 8411711
    },
    {
      "context_text": "Both extractive [8, 9, 27, 34, 75, 76, 88, 89, 97, 123] and abstractive summarization [37, 38, 39, 58, 77, 86, 96, 108, 109] can only be used to compress or rewrite the text into a shorter form – neither can create a structured output of the form seen in Table 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only summarization methods and their limitations. No verifiable resources are identified.",
      "processing_time": 63.28542685508728,
      "citing_paper_id": "3519188",
      "cited_paper_id": 8812081
    },
    {
      "context_text": "Both extractive [8, 9, 27, 34, 75, 76, 88, 89, 97, 123] and abstractive summarization [37, 38, 39, 58, 77, 86, 96, 108, 109] can only be used to compress or rewrite the text into a shorter form – neither can create a structured output of the form seen in Table 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only summarization methods and their limitations. No verifiable resources are identified.",
      "processing_time": 63.28542685508728,
      "citing_paper_id": "3519188",
      "cited_paper_id": 10019526
    },
    {
      "context_text": "Both extractive [8, 9, 27, 34, 75, 76, 88, 89, 97, 123] and abstractive summarization [37, 38, 39, 58, 77, 86, 96, 108, 109] can only be used to compress or rewrite the text into a shorter form – neither can create a structured output of the form seen in Table 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only summarization methods and their limitations. No verifiable resources are identified.",
      "processing_time": 63.28542685508728,
      "citing_paper_id": "3519188",
      "cited_paper_id": null
    },
    {
      "context_text": "Extractive summarization avoids the problem of natural language generation by instead extracting subsets of the original text in order to create a summary [8, 9, 27, 34, 75, 76, 88, 89, 97, 123].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only describes the concept of extractive summarization.",
      "processing_time": 63.005672216415405,
      "citing_paper_id": "3519188",
      "cited_paper_id": 1320
    },
    {
      "context_text": "Extractive summarization avoids the problem of natural language generation by instead extracting subsets of the original text in order to create a summary [8, 9, 27, 34, 75, 76, 88, 89, 97, 123].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only describes the concept of extractive summarization.",
      "processing_time": 63.005672216415405,
      "citing_paper_id": "3519188",
      "cited_paper_id": 6334682
    },
    {
      "context_text": "Extractive summarization avoids the problem of natural language generation by instead extracting subsets of the original text in order to create a summary [8, 9, 27, 34, 75, 76, 88, 89, 97, 123].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only describes the concept of extractive summarization.",
      "processing_time": 63.005672216415405,
      "citing_paper_id": "3519188",
      "cited_paper_id": 6511191
    },
    {
      "context_text": "Extractive summarization avoids the problem of natural language generation by instead extracting subsets of the original text in order to create a summary [8, 9, 27, 34, 75, 76, 88, 89, 97, 123].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only describes the concept of extractive summarization.",
      "processing_time": 63.005672216415405,
      "citing_paper_id": "3519188",
      "cited_paper_id": 8812081
    },
    {
      "context_text": "Extractive summarization avoids the problem of natural language generation by instead extracting subsets of the original text in order to create a summary [8, 9, 27, 34, 75, 76, 88, 89, 97, 123].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only describes the concept of extractive summarization.",
      "processing_time": 63.005672216415405,
      "citing_paper_id": "3519188",
      "cited_paper_id": null
    },
    {
      "context_text": "Sentence-level event extraction has been applied to Chinese and Spanish [13, 14, 18, 19, 48, 49, 50, 69].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only sentence-level event extraction applied to Chinese and Spanish. No verifiable resources are named.",
      "processing_time": 64.03136491775513,
      "citing_paper_id": "3519188",
      "cited_paper_id": 344550
    },
    {
      "context_text": "Sentence-level event extraction has been applied to Chinese and Spanish [13, 14, 18, 19, 48, 49, 50, 69].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only sentence-level event extraction applied to Chinese and Spanish. No verifiable resources are named.",
      "processing_time": 64.03136491775513,
      "citing_paper_id": "3519188",
      "cited_paper_id": 1415632
    },
    {
      "context_text": "Sentence-level event extraction has been applied to Chinese and Spanish [13, 14, 18, 19, 48, 49, 50, 69].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only sentence-level event extraction applied to Chinese and Spanish. No verifiable resources are named.",
      "processing_time": 64.03136491775513,
      "citing_paper_id": "3519188",
      "cited_paper_id": 44185312
    },
    {
      "context_text": "Entries with * represent no significant difference (at α = 0.05) compared to the best method. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 7.6 Results from macro-event extraction on the elections domain, Spanish documents.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only results from macro-event extraction on the elections domain, Spanish documents. No clear dataset names are provided.",
      "processing_time": 64.68280601501465,
      "citing_paper_id": "3519188",
      "cited_paper_id": 344550
    },
    {
      "context_text": "Entries with * represent no significant difference (at α = 0.05) compared to the best method. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 7.6 Results from macro-event extraction on the elections domain, Spanish documents.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only results from macro-event extraction on the elections domain, Spanish documents. No clear dataset names are provided.",
      "processing_time": 64.68280601501465,
      "citing_paper_id": "3519188",
      "cited_paper_id": 1415632
    },
    {
      "context_text": "Entries with * represent no significant difference (at α = 0.05) compared to the best method. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 7.6 Results from macro-event extraction on the elections domain, Spanish documents.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only results from macro-event extraction on the elections domain, Spanish documents. No clear dataset names are provided.",
      "processing_time": 64.68280601501465,
      "citing_paper_id": "3519188",
      "cited_paper_id": 44185312
    },
    {
      "context_text": "For the elections domain, we have additionally collected Spanish language data to demonstrate the effectiveness of our models on non-English texts\n• Experimental results on the attack, election, sporting-event and criminal-trial domains with baseline methods and all three of our proposed algorithms.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions collecting Spanish language data for the elections domain but does not specify a named dataset. The cited papers do not provide additional dataset names.",
      "processing_time": 64.55898332595825,
      "citing_paper_id": "3519188",
      "cited_paper_id": 344550
    },
    {
      "context_text": "For the elections domain, we have additionally collected Spanish language data to demonstrate the effectiveness of our models on non-English texts\n• Experimental results on the attack, election, sporting-event and criminal-trial domains with baseline methods and all three of our proposed algorithms.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions collecting Spanish language data for the elections domain but does not specify a named dataset. The cited papers do not provide additional dataset names.",
      "processing_time": 64.55898332595825,
      "citing_paper_id": "3519188",
      "cited_paper_id": 1415632
    },
    {
      "context_text": "For the elections domain, we have additionally collected Spanish language data to demonstrate the effectiveness of our models on non-English texts\n• Experimental results on the attack, election, sporting-event and criminal-trial domains with baseline methods and all three of our proposed algorithms.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions collecting Spanish language data for the elections domain but does not specify a named dataset. The cited papers do not provide additional dataset names.",
      "processing_time": 64.55898332595825,
      "citing_paper_id": "3519188",
      "cited_paper_id": 44185312
    },
    {
      "context_text": "• Title – the position the election was for (e.g. President, Senator) • Nominees – the candidates nominated for the election • Winner – the candidate who won the election • Losers – the candidates who lost the election\n1For Spanish data, we consider only a subset of these slots, due to lack of available information in Spanish Wikipedia election infoboxes (see Section 3.3.1 for details)\n27\n• Parties – the political parties associated with the election • Party-Winner – the political party of the winner • Party-Loser – the political parties of the losers • Running-Mates – the running mates for the election • Running-Mate-Winner – the winning running mate • Running-Mates-Loser – the losing running mates The hierarchical structure for elections can be seen in Figure 3.2.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only slots and structures used in the data. No clear identifiers for datasets are present.",
      "processing_time": 63.689846992492676,
      "citing_paper_id": "3519188",
      "cited_paper_id": 344550
    },
    {
      "context_text": "• Title – the position the election was for (e.g. President, Senator) • Nominees – the candidates nominated for the election • Winner – the candidate who won the election • Losers – the candidates who lost the election\n1For Spanish data, we consider only a subset of these slots, due to lack of available information in Spanish Wikipedia election infoboxes (see Section 3.3.1 for details)\n27\n• Parties – the political parties associated with the election • Party-Winner – the political party of the winner • Party-Loser – the political parties of the losers • Running-Mates – the running mates for the election • Running-Mate-Winner – the winning running mate • Running-Mates-Loser – the losing running mates The hierarchical structure for elections can be seen in Figure 3.2.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only slots and structures used in the data. No clear identifiers for datasets are present.",
      "processing_time": 63.689846992492676,
      "citing_paper_id": "3519188",
      "cited_paper_id": 1415632
    },
    {
      "context_text": "• Title – the position the election was for (e.g. President, Senator) • Nominees – the candidates nominated for the election • Winner – the candidate who won the election • Losers – the candidates who lost the election\n1For Spanish data, we consider only a subset of these slots, due to lack of available information in Spanish Wikipedia election infoboxes (see Section 3.3.1 for details)\n27\n• Parties – the political parties associated with the election • Party-Winner – the political party of the winner • Party-Loser – the political parties of the losers • Running-Mates – the running mates for the election • Running-Mate-Winner – the winning running mate • Running-Mates-Loser – the losing running mates The hierarchical structure for elections can be seen in Figure 3.2.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only slots and structures used in the data. No clear identifiers for datasets are present.",
      "processing_time": 63.689846992492676,
      "citing_paper_id": "3519188",
      "cited_paper_id": 44185312
    },
    {
      "context_text": "Each year of the MUC program focused on a single type of event template, allowing for the study of complex structure and fillers within the event template (see Table 2.1 for a complete list of event types considered).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MUC program' which is a well-known series of evaluations for information extraction systems. However, it does not specify a particular dataset or data release, only a program. No specific dataset names are provided.",
      "processing_time": 67.2735583782196,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "Each year of the MUC program focused on a single type of event template, allowing for the study of complex structure and fillers within the event template (see Table 2.1 for a complete list of event types considered).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MUC program' which is a well-known series of evaluations for information extraction systems. However, it does not specify a particular dataset or data release, only a program. No specific dataset names are provided.",
      "processing_time": 67.2735583782196,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "Each year of the MUC program focused on a single type of event template, allowing for the study of complex structure and fillers within the event template (see Table 2.1 for a complete list of event types considered).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MUC program' which is a well-known series of evaluations for information extraction systems. However, it does not specify a particular dataset or data release, only a program. No specific dataset names are provided.",
      "processing_time": 67.2735583782196,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "Each year of the MUC program focused on a single type of event template, allowing for the study of complex structure and fillers within the event template (see Table 2.1 for a complete list of event types considered).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MUC program' which is a well-known series of evaluations for information extraction systems. However, it does not specify a particular dataset or data release, only a program. No specific dataset names are provided.",
      "processing_time": 67.2735583782196,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "Each year of the MUC program focused on a single type of event template, allowing for the study of complex structure and fillers within the event template (see Table 2.1 for a complete list of event types considered).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MUC program' which is a well-known series of evaluations for information extraction systems. However, it does not specify a particular dataset or data release, only a program. No specific dataset names are provided.",
      "processing_time": 67.2735583782196,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "Each year of the MUC program focused on a single type of event template, allowing for the study of complex structure and fillers within the event template (see Table 2.1 for a complete list of event types considered).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MUC program' which is a well-known series of evaluations for information extraction systems. However, it does not specify a particular dataset or data release, only a program. No specific dataset names are provided.",
      "processing_time": 67.2735583782196,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "Each year of the MUC program focused on a single type of event template, allowing for the study of complex structure and fillers within the event template (see Table 2.1 for a complete list of event types considered).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MUC program' which is a well-known series of evaluations for information extraction systems. However, it does not specify a particular dataset or data release, only a program. No specific dataset names are provided.",
      "processing_time": 67.2735583782196,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "Each year of the MUC program focused on a single type of event template, allowing for the study of complex structure and fillers within the event template (see Table 2.1 for a complete list of event types considered).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MUC program' which is a well-known series of evaluations for information extraction systems. However, it does not specify a particular dataset or data release, only a program. No specific dataset names are provided.",
      "processing_time": 67.2735583782196,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "Each year of the MUC program focused on a single type of event template, allowing for the study of complex structure and fillers within the event template (see Table 2.1 for a complete list of event types considered).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MUC program' which is a well-known series of evaluations for information extraction systems. However, it does not specify a particular dataset or data release, only a program. No specific dataset names are provided.",
      "processing_time": 67.2735583782196,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "First, the set of event types studied under documentlevel extraction via MUC are highly specific to a small set of focused domains (e.g. terrorist events in Latin America, electronic circuit fabrication, and launches of rockets/missiles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC' which is likely referring to the Message Understanding Conferences, known for their datasets and evaluation frameworks in information extraction. However, no specific dataset name is mentioned.",
      "processing_time": 66.30889105796814,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "First, the set of event types studied under documentlevel extraction via MUC are highly specific to a small set of focused domains (e.g. terrorist events in Latin America, electronic circuit fabrication, and launches of rockets/missiles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC' which is likely referring to the Message Understanding Conferences, known for their datasets and evaluation frameworks in information extraction. However, no specific dataset name is mentioned.",
      "processing_time": 66.30889105796814,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "First, the set of event types studied under documentlevel extraction via MUC are highly specific to a small set of focused domains (e.g. terrorist events in Latin America, electronic circuit fabrication, and launches of rockets/missiles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC' which is likely referring to the Message Understanding Conferences, known for their datasets and evaluation frameworks in information extraction. However, no specific dataset name is mentioned.",
      "processing_time": 66.30889105796814,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "First, the set of event types studied under documentlevel extraction via MUC are highly specific to a small set of focused domains (e.g. terrorist events in Latin America, electronic circuit fabrication, and launches of rockets/missiles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC' which is likely referring to the Message Understanding Conferences, known for their datasets and evaluation frameworks in information extraction. However, no specific dataset name is mentioned.",
      "processing_time": 66.30889105796814,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "First, the set of event types studied under documentlevel extraction via MUC are highly specific to a small set of focused domains (e.g. terrorist events in Latin America, electronic circuit fabrication, and launches of rockets/missiles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC' which is likely referring to the Message Understanding Conferences, known for their datasets and evaluation frameworks in information extraction. However, no specific dataset name is mentioned.",
      "processing_time": 66.30889105796814,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "First, the set of event types studied under documentlevel extraction via MUC are highly specific to a small set of focused domains (e.g. terrorist events in Latin America, electronic circuit fabrication, and launches of rockets/missiles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC' which is likely referring to the Message Understanding Conferences, known for their datasets and evaluation frameworks in information extraction. However, no specific dataset name is mentioned.",
      "processing_time": 66.30889105796814,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "First, the set of event types studied under documentlevel extraction via MUC are highly specific to a small set of focused domains (e.g. terrorist events in Latin America, electronic circuit fabrication, and launches of rockets/missiles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC' which is likely referring to the Message Understanding Conferences, known for their datasets and evaluation frameworks in information extraction. However, no specific dataset name is mentioned.",
      "processing_time": 66.30889105796814,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "First, the set of event types studied under documentlevel extraction via MUC are highly specific to a small set of focused domains (e.g. terrorist events in Latin America, electronic circuit fabrication, and launches of rockets/missiles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC' which is likely referring to the Message Understanding Conferences, known for their datasets and evaluation frameworks in information extraction. However, no specific dataset name is mentioned.",
      "processing_time": 66.30889105796814,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "First, the set of event types studied under documentlevel extraction via MUC are highly specific to a small set of focused domains (e.g. terrorist events in Latin America, electronic circuit fabrication, and launches of rockets/missiles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC' which is likely referring to the Message Understanding Conferences, known for their datasets and evaluation frameworks in information extraction. However, no specific dataset name is mentioned.",
      "processing_time": 66.30889105796814,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "Early methods developed during this time typically focused on handcrafted patterns [2, 68, 119].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and patterns.",
      "processing_time": 62.67907977104187,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "8\nPattern Matching\nThe DARPA MUC program (1987-1997) brought considerable interest to the topic of documentlevel event extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the DARPA MUC program, which is a well-known initiative in the field of information extraction. However, it does not specify any particular dataset used for document-level event extraction.",
      "processing_time": 66.45593738555908,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "8\nPattern Matching\nThe DARPA MUC program (1987-1997) brought considerable interest to the topic of documentlevel event extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the DARPA MUC program, which is a well-known initiative in the field of information extraction. However, it does not specify any particular dataset used for document-level event extraction.",
      "processing_time": 66.45593738555908,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "8\nPattern Matching\nThe DARPA MUC program (1987-1997) brought considerable interest to the topic of documentlevel event extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the DARPA MUC program, which is a well-known initiative in the field of information extraction. However, it does not specify any particular dataset used for document-level event extraction.",
      "processing_time": 66.45593738555908,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "8\nPattern Matching\nThe DARPA MUC program (1987-1997) brought considerable interest to the topic of documentlevel event extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the DARPA MUC program, which is a well-known initiative in the field of information extraction. However, it does not specify any particular dataset used for document-level event extraction.",
      "processing_time": 66.45593738555908,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "8\nPattern Matching\nThe DARPA MUC program (1987-1997) brought considerable interest to the topic of documentlevel event extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the DARPA MUC program, which is a well-known initiative in the field of information extraction. However, it does not specify any particular dataset used for document-level event extraction.",
      "processing_time": 66.45593738555908,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "8\nPattern Matching\nThe DARPA MUC program (1987-1997) brought considerable interest to the topic of documentlevel event extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the DARPA MUC program, which is a well-known initiative in the field of information extraction. However, it does not specify any particular dataset used for document-level event extraction.",
      "processing_time": 66.45593738555908,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "8\nPattern Matching\nThe DARPA MUC program (1987-1997) brought considerable interest to the topic of documentlevel event extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the DARPA MUC program, which is a well-known initiative in the field of information extraction. However, it does not specify any particular dataset used for document-level event extraction.",
      "processing_time": 66.45593738555908,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "8\nPattern Matching\nThe DARPA MUC program (1987-1997) brought considerable interest to the topic of documentlevel event extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the DARPA MUC program, which is a well-known initiative in the field of information extraction. However, it does not specify any particular dataset used for document-level event extraction.",
      "processing_time": 66.45593738555908,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "8\nPattern Matching\nThe DARPA MUC program (1987-1997) brought considerable interest to the topic of documentlevel event extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the DARPA MUC program, which is a well-known initiative in the field of information extraction. However, it does not specify any particular dataset used for document-level event extraction.",
      "processing_time": 66.45593738555908,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "The MUC-5 conference considered event templates in Japanese for both the joint ventures and micro-electronics domains [54, 55].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-5"
      ],
      "dataset_descriptions": {
        "MUC-5": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC-5' which is a specific conference that dealt with event templates in Japanese. The dataset is implied to be part of the MUC-5 conference, which is relevant to document-level event extraction.",
      "processing_time": 75.86189770698547,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "The MUC-5 conference considered event templates in Japanese for both the joint ventures and micro-electronics domains [54, 55].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-5"
      ],
      "dataset_descriptions": {
        "MUC-5": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC-5' which is a specific conference that dealt with event templates in Japanese. The dataset is implied to be part of the MUC-5 conference, which is relevant to document-level event extraction.",
      "processing_time": 75.86189770698547,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "The MUC-5 conference considered event templates in Japanese for both the joint ventures and micro-electronics domains [54, 55].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-5"
      ],
      "dataset_descriptions": {
        "MUC-5": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC-5' which is a specific conference that dealt with event templates in Japanese. The dataset is implied to be part of the MUC-5 conference, which is relevant to document-level event extraction.",
      "processing_time": 75.86189770698547,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "The MUC-5 conference considered event templates in Japanese for both the joint ventures and micro-electronics domains [54, 55].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-5"
      ],
      "dataset_descriptions": {
        "MUC-5": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC-5' which is a specific conference that dealt with event templates in Japanese. The dataset is implied to be part of the MUC-5 conference, which is relevant to document-level event extraction.",
      "processing_time": 75.86189770698547,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "The MUC-5 conference considered event templates in Japanese for both the joint ventures and micro-electronics domains [54, 55].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-5"
      ],
      "dataset_descriptions": {
        "MUC-5": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC-5' which is a specific conference that dealt with event templates in Japanese. The dataset is implied to be part of the MUC-5 conference, which is relevant to document-level event extraction.",
      "processing_time": 75.86189770698547,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "The MUC-5 conference considered event templates in Japanese for both the joint ventures and micro-electronics domains [54, 55].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-5"
      ],
      "dataset_descriptions": {
        "MUC-5": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC-5' which is a specific conference that dealt with event templates in Japanese. The dataset is implied to be part of the MUC-5 conference, which is relevant to document-level event extraction.",
      "processing_time": 75.86189770698547,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "The MUC-5 conference considered event templates in Japanese for both the joint ventures and micro-electronics domains [54, 55].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-5"
      ],
      "dataset_descriptions": {
        "MUC-5": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC-5' which is a specific conference that dealt with event templates in Japanese. The dataset is implied to be part of the MUC-5 conference, which is relevant to document-level event extraction.",
      "processing_time": 75.86189770698547,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "The MUC-5 conference considered event templates in Japanese for both the joint ventures and micro-electronics domains [54, 55].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-5"
      ],
      "dataset_descriptions": {
        "MUC-5": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC-5' which is a specific conference that dealt with event templates in Japanese. The dataset is implied to be part of the MUC-5 conference, which is relevant to document-level event extraction.",
      "processing_time": 75.86189770698547,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "The MUC-5 conference considered event templates in Japanese for both the joint ventures and micro-electronics domains [54, 55].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-5"
      ],
      "dataset_descriptions": {
        "MUC-5": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC-5' which is a specific conference that dealt with event templates in Japanese. The dataset is implied to be part of the MUC-5 conference, which is relevant to document-level event extraction.",
      "processing_time": 75.86189770698547,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "However, work to date on document-level extraction under the MUC definitions suffers from several limitations.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general limitation in document-level extraction under MUC definitions.",
      "processing_time": 64.23508834838867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "However, work to date on document-level extraction under the MUC definitions suffers from several limitations.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general limitation in document-level extraction under MUC definitions.",
      "processing_time": 64.23508834838867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "However, work to date on document-level extraction under the MUC definitions suffers from several limitations.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general limitation in document-level extraction under MUC definitions.",
      "processing_time": 64.23508834838867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "However, work to date on document-level extraction under the MUC definitions suffers from several limitations.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general limitation in document-level extraction under MUC definitions.",
      "processing_time": 64.23508834838867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "However, work to date on document-level extraction under the MUC definitions suffers from several limitations.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general limitation in document-level extraction under MUC definitions.",
      "processing_time": 64.23508834838867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "However, work to date on document-level extraction under the MUC definitions suffers from several limitations.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general limitation in document-level extraction under MUC definitions.",
      "processing_time": 64.23508834838867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "However, work to date on document-level extraction under the MUC definitions suffers from several limitations.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general limitation in document-level extraction under MUC definitions.",
      "processing_time": 64.23508834838867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "However, work to date on document-level extraction under the MUC definitions suffers from several limitations.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general limitation in document-level extraction under MUC definitions.",
      "processing_time": 64.23508834838867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "However, work to date on document-level extraction under the MUC definitions suffers from several limitations.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general limitation in document-level extraction under MUC definitions.",
      "processing_time": 64.23508834838867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "This has allowed sentence-level work to capture a much wider range of event types than has been seen under MUC-centric document-level analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to MUC-centric document-level analysis. No verifiable resources are identified.",
      "processing_time": 65.22670221328735,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "This has allowed sentence-level work to capture a much wider range of event types than has been seen under MUC-centric document-level analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to MUC-centric document-level analysis. No verifiable resources are identified.",
      "processing_time": 65.22670221328735,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "This has allowed sentence-level work to capture a much wider range of event types than has been seen under MUC-centric document-level analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to MUC-centric document-level analysis. No verifiable resources are identified.",
      "processing_time": 65.22670221328735,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "This has allowed sentence-level work to capture a much wider range of event types than has been seen under MUC-centric document-level analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to MUC-centric document-level analysis. No verifiable resources are identified.",
      "processing_time": 65.22670221328735,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "This has allowed sentence-level work to capture a much wider range of event types than has been seen under MUC-centric document-level analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to MUC-centric document-level analysis. No verifiable resources are identified.",
      "processing_time": 65.22670221328735,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "This has allowed sentence-level work to capture a much wider range of event types than has been seen under MUC-centric document-level analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to MUC-centric document-level analysis. No verifiable resources are identified.",
      "processing_time": 65.22670221328735,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "This has allowed sentence-level work to capture a much wider range of event types than has been seen under MUC-centric document-level analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to MUC-centric document-level analysis. No verifiable resources are identified.",
      "processing_time": 65.22670221328735,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "This has allowed sentence-level work to capture a much wider range of event types than has been seen under MUC-centric document-level analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to MUC-centric document-level analysis. No verifiable resources are identified.",
      "processing_time": 65.22670221328735,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "This has allowed sentence-level work to capture a much wider range of event types than has been seen under MUC-centric document-level analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to MUC-centric document-level analysis. No verifiable resources are identified.",
      "processing_time": 65.22670221328735,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "This is notably different from the paradigms studied in MUC and ACE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE"
      ],
      "dataset_descriptions": {
        "MUC": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research.",
        "ACE": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC and ACE, which are known evaluation campaigns and datasets in the field of information extraction. However, the context does not specify how these datasets are used in the current research.",
      "processing_time": 79.32418298721313,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "This is notably different from the paradigms studied in MUC and ACE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE"
      ],
      "dataset_descriptions": {
        "MUC": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research.",
        "ACE": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC and ACE, which are known evaluation campaigns and datasets in the field of information extraction. However, the context does not specify how these datasets are used in the current research.",
      "processing_time": 79.32418298721313,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "This is notably different from the paradigms studied in MUC and ACE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE"
      ],
      "dataset_descriptions": {
        "MUC": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research.",
        "ACE": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC and ACE, which are known evaluation campaigns and datasets in the field of information extraction. However, the context does not specify how these datasets are used in the current research.",
      "processing_time": 79.32418298721313,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "This is notably different from the paradigms studied in MUC and ACE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE"
      ],
      "dataset_descriptions": {
        "MUC": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research.",
        "ACE": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC and ACE, which are known evaluation campaigns and datasets in the field of information extraction. However, the context does not specify how these datasets are used in the current research.",
      "processing_time": 79.32418298721313,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "This is notably different from the paradigms studied in MUC and ACE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE"
      ],
      "dataset_descriptions": {
        "MUC": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research.",
        "ACE": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC and ACE, which are known evaluation campaigns and datasets in the field of information extraction. However, the context does not specify how these datasets are used in the current research.",
      "processing_time": 79.32418298721313,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "This is notably different from the paradigms studied in MUC and ACE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE"
      ],
      "dataset_descriptions": {
        "MUC": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research.",
        "ACE": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC and ACE, which are known evaluation campaigns and datasets in the field of information extraction. However, the context does not specify how these datasets are used in the current research.",
      "processing_time": 79.32418298721313,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "This is notably different from the paradigms studied in MUC and ACE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE"
      ],
      "dataset_descriptions": {
        "MUC": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research.",
        "ACE": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC and ACE, which are known evaluation campaigns and datasets in the field of information extraction. However, the context does not specify how these datasets are used in the current research.",
      "processing_time": 79.32418298721313,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "This is notably different from the paradigms studied in MUC and ACE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE"
      ],
      "dataset_descriptions": {
        "MUC": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research.",
        "ACE": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC and ACE, which are known evaluation campaigns and datasets in the field of information extraction. However, the context does not specify how these datasets are used in the current research.",
      "processing_time": 79.32418298721313,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "This is notably different from the paradigms studied in MUC and ACE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE"
      ],
      "dataset_descriptions": {
        "MUC": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research.",
        "ACE": "Mentioned as a reference for comparison, highlighting differences in paradigms studied. Not used directly in the current research."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MUC and ACE, which are known evaluation campaigns and datasets in the field of information extraction. However, the context does not specify how these datasets are used in the current research.",
      "processing_time": 79.32418298721313,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "An example MUC template from the Latin American Terrorism domain may be seen in Figure 2.3.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC template' and 'Latin American Terrorism domain', which suggests the use of a specific dataset or resource. However, the exact name of the dataset is not provided in the citation span.",
      "processing_time": 59.399202823638916,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "An example MUC template from the Latin American Terrorism domain may be seen in Figure 2.3.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC template' and 'Latin American Terrorism domain', which suggests the use of a specific dataset or resource. However, the exact name of the dataset is not provided in the citation span.",
      "processing_time": 59.399202823638916,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "An example MUC template from the Latin American Terrorism domain may be seen in Figure 2.3.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC template' and 'Latin American Terrorism domain', which suggests the use of a specific dataset or resource. However, the exact name of the dataset is not provided in the citation span.",
      "processing_time": 59.399202823638916,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "An example MUC template from the Latin American Terrorism domain may be seen in Figure 2.3.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC template' and 'Latin American Terrorism domain', which suggests the use of a specific dataset or resource. However, the exact name of the dataset is not provided in the citation span.",
      "processing_time": 59.399202823638916,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "An example MUC template from the Latin American Terrorism domain may be seen in Figure 2.3.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC template' and 'Latin American Terrorism domain', which suggests the use of a specific dataset or resource. However, the exact name of the dataset is not provided in the citation span.",
      "processing_time": 59.399202823638916,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "An example MUC template from the Latin American Terrorism domain may be seen in Figure 2.3.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC template' and 'Latin American Terrorism domain', which suggests the use of a specific dataset or resource. However, the exact name of the dataset is not provided in the citation span.",
      "processing_time": 59.399202823638916,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "An example MUC template from the Latin American Terrorism domain may be seen in Figure 2.3.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC template' and 'Latin American Terrorism domain', which suggests the use of a specific dataset or resource. However, the exact name of the dataset is not provided in the citation span.",
      "processing_time": 59.399202823638916,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "An example MUC template from the Latin American Terrorism domain may be seen in Figure 2.3.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC template' and 'Latin American Terrorism domain', which suggests the use of a specific dataset or resource. However, the exact name of the dataset is not provided in the citation span.",
      "processing_time": 59.399202823638916,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "An example MUC template from the Latin American Terrorism domain may be seen in Figure 2.3.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'MUC template' and 'Latin American Terrorism domain', which suggests the use of a specific dataset or resource. However, the exact name of the dataset is not provided in the citation span.",
      "processing_time": 59.399202823638916,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "However, such models were not able to outperform the results obtained by knowledge-based approaches [4, 68].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between models and knowledge-based approaches.",
      "processing_time": 55.17379331588745,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "However, such models were not able to outperform the results obtained by knowledge-based approaches [4, 68].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between models and knowledge-based approaches.",
      "processing_time": 55.17379331588745,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
      "processing_time": 67.70911145210266,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
      "processing_time": 67.70911145210266,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
      "processing_time": 67.70911145210266,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
      "processing_time": 67.70911145210266,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
      "processing_time": 67.70911145210266,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
      "processing_time": 67.70911145210266,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
      "processing_time": 67.70911145210266,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
      "processing_time": 67.70911145210266,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
      "processing_time": 67.70911145210266,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "More recent document-level event extraction techniques follow the definitions provided by the Message Understanding Conferences2 (MUC) [2, 4, 7, 20, 21, 40, 41, 51, 52, 53, 54, 55, 62, 68, 73, 93, 94, 95, 103, 104, 114, 115, 116, 117, 119, 127, 128].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Message Understanding Conferences' (MUC) but does not specify a particular dataset. It refers to a series of conferences and their definitions, which are not datasets themselves.",
      "processing_time": 58.588093280792236,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "More recent document-level event extraction techniques follow the definitions provided by the Message Understanding Conferences2 (MUC) [2, 4, 7, 20, 21, 40, 41, 51, 52, 53, 54, 55, 62, 68, 73, 93, 94, 95, 103, 104, 114, 115, 116, 117, 119, 127, 128].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Message Understanding Conferences' (MUC) but does not specify a particular dataset. It refers to a series of conferences and their definitions, which are not datasets themselves.",
      "processing_time": 58.588093280792236,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "More recent document-level event extraction techniques follow the definitions provided by the Message Understanding Conferences2 (MUC) [2, 4, 7, 20, 21, 40, 41, 51, 52, 53, 54, 55, 62, 68, 73, 93, 94, 95, 103, 104, 114, 115, 116, 117, 119, 127, 128].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Message Understanding Conferences' (MUC) but does not specify a particular dataset. It refers to a series of conferences and their definitions, which are not datasets themselves.",
      "processing_time": 58.588093280792236,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "More recent document-level event extraction techniques follow the definitions provided by the Message Understanding Conferences2 (MUC) [2, 4, 7, 20, 21, 40, 41, 51, 52, 53, 54, 55, 62, 68, 73, 93, 94, 95, 103, 104, 114, 115, 116, 117, 119, 127, 128].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Message Understanding Conferences' (MUC) but does not specify a particular dataset. It refers to a series of conferences and their definitions, which are not datasets themselves.",
      "processing_time": 58.588093280792236,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "More recent document-level event extraction techniques follow the definitions provided by the Message Understanding Conferences2 (MUC) [2, 4, 7, 20, 21, 40, 41, 51, 52, 53, 54, 55, 62, 68, 73, 93, 94, 95, 103, 104, 114, 115, 116, 117, 119, 127, 128].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Message Understanding Conferences' (MUC) but does not specify a particular dataset. It refers to a series of conferences and their definitions, which are not datasets themselves.",
      "processing_time": 58.588093280792236,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "More recent document-level event extraction techniques follow the definitions provided by the Message Understanding Conferences2 (MUC) [2, 4, 7, 20, 21, 40, 41, 51, 52, 53, 54, 55, 62, 68, 73, 93, 94, 95, 103, 104, 114, 115, 116, 117, 119, 127, 128].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Message Understanding Conferences' (MUC) but does not specify a particular dataset. It refers to a series of conferences and their definitions, which are not datasets themselves.",
      "processing_time": 58.588093280792236,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "More recent document-level event extraction techniques follow the definitions provided by the Message Understanding Conferences2 (MUC) [2, 4, 7, 20, 21, 40, 41, 51, 52, 53, 54, 55, 62, 68, 73, 93, 94, 95, 103, 104, 114, 115, 116, 117, 119, 127, 128].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Message Understanding Conferences' (MUC) but does not specify a particular dataset. It refers to a series of conferences and their definitions, which are not datasets themselves.",
      "processing_time": 58.588093280792236,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "More recent document-level event extraction techniques follow the definitions provided by the Message Understanding Conferences2 (MUC) [2, 4, 7, 20, 21, 40, 41, 51, 52, 53, 54, 55, 62, 68, 73, 93, 94, 95, 103, 104, 114, 115, 116, 117, 119, 127, 128].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Message Understanding Conferences' (MUC) but does not specify a particular dataset. It refers to a series of conferences and their definitions, which are not datasets themselves.",
      "processing_time": 58.588093280792236,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "More recent document-level event extraction techniques follow the definitions provided by the Message Understanding Conferences2 (MUC) [2, 4, 7, 20, 21, 40, 41, 51, 52, 53, 54, 55, 62, 68, 73, 93, 94, 95, 103, 104, 114, 115, 116, 117, 119, 127, 128].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Message Understanding Conferences' (MUC) but does not specify a particular dataset. It refers to a series of conferences and their definitions, which are not datasets themselves.",
      "processing_time": 58.588093280792236,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "In their evaluation results on the MUC-4 dataset, they found that ALICE was able to outperform nearly all pattern-based methods.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of ALICE against other methods.",
      "processing_time": 65.77264857292175,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "In their evaluation results on the MUC-4 dataset, they found that ALICE was able to outperform nearly all pattern-based methods.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of ALICE against other methods.",
      "processing_time": 65.77264857292175,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "In their evaluation results on the MUC-4 dataset, they found that ALICE was able to outperform nearly all pattern-based methods.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of ALICE against other methods.",
      "processing_time": 65.77264857292175,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "In their evaluation results on the MUC-4 dataset, they found that ALICE was able to outperform nearly all pattern-based methods.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of ALICE against other methods.",
      "processing_time": 65.77264857292175,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "In their evaluation results on the MUC-4 dataset, they found that ALICE was able to outperform nearly all pattern-based methods.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of ALICE against other methods.",
      "processing_time": 65.77264857292175,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "In their evaluation results on the MUC-4 dataset, they found that ALICE was able to outperform nearly all pattern-based methods.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of ALICE against other methods.",
      "processing_time": 65.77264857292175,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "In their evaluation results on the MUC-4 dataset, they found that ALICE was able to outperform nearly all pattern-based methods.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of ALICE against other methods.",
      "processing_time": 65.77264857292175,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "In their evaluation results on the MUC-4 dataset, they found that ALICE was able to outperform nearly all pattern-based methods.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of ALICE against other methods.",
      "processing_time": 65.77264857292175,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "In their evaluation results on the MUC-4 dataset, they found that ALICE was able to outperform nearly all pattern-based methods.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of ALICE against other methods.",
      "processing_time": 65.77264857292175,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "In their experiments on the MUC-4 dataset, they found that this gave nearly as good of performance as a fully handcrafted system that required 1500 person hours to construct.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of a system against a handcrafted one.",
      "processing_time": 67.13215613365173,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "In their experiments on the MUC-4 dataset, they found that this gave nearly as good of performance as a fully handcrafted system that required 1500 person hours to construct.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of a system against a handcrafted one.",
      "processing_time": 67.13215613365173,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "In their experiments on the MUC-4 dataset, they found that this gave nearly as good of performance as a fully handcrafted system that required 1500 person hours to construct.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of a system against a handcrafted one.",
      "processing_time": 67.13215613365173,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "In their experiments on the MUC-4 dataset, they found that this gave nearly as good of performance as a fully handcrafted system that required 1500 person hours to construct.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of a system against a handcrafted one.",
      "processing_time": 67.13215613365173,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "In their experiments on the MUC-4 dataset, they found that this gave nearly as good of performance as a fully handcrafted system that required 1500 person hours to construct.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of a system against a handcrafted one.",
      "processing_time": 67.13215613365173,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "In their experiments on the MUC-4 dataset, they found that this gave nearly as good of performance as a fully handcrafted system that required 1500 person hours to construct.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of a system against a handcrafted one.",
      "processing_time": 67.13215613365173,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "In their experiments on the MUC-4 dataset, they found that this gave nearly as good of performance as a fully handcrafted system that required 1500 person hours to construct.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of a system against a handcrafted one.",
      "processing_time": 67.13215613365173,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "In their experiments on the MUC-4 dataset, they found that this gave nearly as good of performance as a fully handcrafted system that required 1500 person hours to construct.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of a system against a handcrafted one.",
      "processing_time": 67.13215613365173,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "In their experiments on the MUC-4 dataset, they found that this gave nearly as good of performance as a fully handcrafted system that required 1500 person hours to construct.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known dataset used for evaluating information extraction systems. The dataset is used to compare the performance of a system against a handcrafted one.",
      "processing_time": 67.13215613365173,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "The first classification-based method shown to achieve competitive performance with patternbased methods on the MUC data was that of Chieu et al. [2003], via a system called ALICE (Automated Learning-based Information Content Extraction).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC data"
      ],
      "dataset_descriptions": {
        "MUC data": "Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC data', which is a known dataset in the field of information extraction. The citation is used to highlight a method's performance on this dataset.",
      "processing_time": 64.81500697135925,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "The first classification-based method shown to achieve competitive performance with patternbased methods on the MUC data was that of Chieu et al. [2003], via a system called ALICE (Automated Learning-based Information Content Extraction).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC data"
      ],
      "dataset_descriptions": {
        "MUC data": "Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC data', which is a known dataset in the field of information extraction. The citation is used to highlight a method's performance on this dataset.",
      "processing_time": 64.81500697135925,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "The first classification-based method shown to achieve competitive performance with patternbased methods on the MUC data was that of Chieu et al. [2003], via a system called ALICE (Automated Learning-based Information Content Extraction).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC data"
      ],
      "dataset_descriptions": {
        "MUC data": "Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC data', which is a known dataset in the field of information extraction. The citation is used to highlight a method's performance on this dataset.",
      "processing_time": 64.81500697135925,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "The first classification-based method shown to achieve competitive performance with patternbased methods on the MUC data was that of Chieu et al. [2003], via a system called ALICE (Automated Learning-based Information Content Extraction).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC data"
      ],
      "dataset_descriptions": {
        "MUC data": "Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC data', which is a known dataset in the field of information extraction. The citation is used to highlight a method's performance on this dataset.",
      "processing_time": 64.81500697135925,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "The first classification-based method shown to achieve competitive performance with patternbased methods on the MUC data was that of Chieu et al. [2003], via a system called ALICE (Automated Learning-based Information Content Extraction).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC data"
      ],
      "dataset_descriptions": {
        "MUC data": "Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC data', which is a known dataset in the field of information extraction. The citation is used to highlight a method's performance on this dataset.",
      "processing_time": 64.81500697135925,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "The first classification-based method shown to achieve competitive performance with patternbased methods on the MUC data was that of Chieu et al. [2003], via a system called ALICE (Automated Learning-based Information Content Extraction).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC data"
      ],
      "dataset_descriptions": {
        "MUC data": "Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC data', which is a known dataset in the field of information extraction. The citation is used to highlight a method's performance on this dataset.",
      "processing_time": 64.81500697135925,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "The first classification-based method shown to achieve competitive performance with patternbased methods on the MUC data was that of Chieu et al. [2003], via a system called ALICE (Automated Learning-based Information Content Extraction).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC data"
      ],
      "dataset_descriptions": {
        "MUC data": "Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC data', which is a known dataset in the field of information extraction. The citation is used to highlight a method's performance on this dataset.",
      "processing_time": 64.81500697135925,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "The first classification-based method shown to achieve competitive performance with patternbased methods on the MUC data was that of Chieu et al. [2003], via a system called ALICE (Automated Learning-based Information Content Extraction).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC data"
      ],
      "dataset_descriptions": {
        "MUC data": "Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC data', which is a known dataset in the field of information extraction. The citation is used to highlight a method's performance on this dataset.",
      "processing_time": 64.81500697135925,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "The first classification-based method shown to achieve competitive performance with patternbased methods on the MUC data was that of Chieu et al. [2003], via a system called ALICE (Automated Learning-based Information Content Extraction).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC data"
      ],
      "dataset_descriptions": {
        "MUC data": "Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC data', which is a known dataset in the field of information extraction. The citation is used to highlight a method's performance on this dataset.",
      "processing_time": 64.81500697135925,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "8 2.2 Output results from FRUMP on Figure 2.1’s text . . . . . . . . . . . . . . . . . . 8 2.3 Example MUC template from the Latin American Terrorism domain . . . . . .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which likely refers to a dataset or evaluation framework used in information extraction, particularly in the domain of terrorism. However, without more specific details, the exact nature of the dataset is unclear.",
      "processing_time": 65.90089583396912,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "8 2.2 Output results from FRUMP on Figure 2.1’s text . . . . . . . . . . . . . . . . . . 8 2.3 Example MUC template from the Latin American Terrorism domain . . . . . .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which likely refers to a dataset or evaluation framework used in information extraction, particularly in the domain of terrorism. However, without more specific details, the exact nature of the dataset is unclear.",
      "processing_time": 65.90089583396912,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "8 2.2 Output results from FRUMP on Figure 2.1’s text . . . . . . . . . . . . . . . . . . 8 2.3 Example MUC template from the Latin American Terrorism domain . . . . . .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which likely refers to a dataset or evaluation framework used in information extraction, particularly in the domain of terrorism. However, without more specific details, the exact nature of the dataset is unclear.",
      "processing_time": 65.90089583396912,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "8 2.2 Output results from FRUMP on Figure 2.1’s text . . . . . . . . . . . . . . . . . . 8 2.3 Example MUC template from the Latin American Terrorism domain . . . . . .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which likely refers to a dataset or evaluation framework used in information extraction, particularly in the domain of terrorism. However, without more specific details, the exact nature of the dataset is unclear.",
      "processing_time": 65.90089583396912,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "8 2.2 Output results from FRUMP on Figure 2.1’s text . . . . . . . . . . . . . . . . . . 8 2.3 Example MUC template from the Latin American Terrorism domain . . . . . .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which likely refers to a dataset or evaluation framework used in information extraction, particularly in the domain of terrorism. However, without more specific details, the exact nature of the dataset is unclear.",
      "processing_time": 65.90089583396912,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "8 2.2 Output results from FRUMP on Figure 2.1’s text . . . . . . . . . . . . . . . . . . 8 2.3 Example MUC template from the Latin American Terrorism domain . . . . . .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which likely refers to a dataset or evaluation framework used in information extraction, particularly in the domain of terrorism. However, without more specific details, the exact nature of the dataset is unclear.",
      "processing_time": 65.90089583396912,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "8 2.2 Output results from FRUMP on Figure 2.1’s text . . . . . . . . . . . . . . . . . . 8 2.3 Example MUC template from the Latin American Terrorism domain . . . . . .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which likely refers to a dataset or evaluation framework used in information extraction, particularly in the domain of terrorism. However, without more specific details, the exact nature of the dataset is unclear.",
      "processing_time": 65.90089583396912,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "8 2.2 Output results from FRUMP on Figure 2.1’s text . . . . . . . . . . . . . . . . . . 8 2.3 Example MUC template from the Latin American Terrorism domain . . . . . .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which likely refers to a dataset or evaluation framework used in information extraction, particularly in the domain of terrorism. However, without more specific details, the exact nature of the dataset is unclear.",
      "processing_time": 65.90089583396912,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "8 2.2 Output results from FRUMP on Figure 2.1’s text . . . . . . . . . . . . . . . . . . 8 2.3 Example MUC template from the Latin American Terrorism domain . . . . . .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC' which likely refers to a dataset or evaluation framework used in information extraction, particularly in the domain of terrorism. However, without more specific details, the exact nature of the dataset is unclear.",
      "processing_time": 65.90089583396912,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "Outside of the MUC and ACE notions of events, other related approaches for summarizing a text include topic models, extractive summarization, and abstractive summarization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches to text summarization. No dataset names are present in the text.",
      "processing_time": 56.164854526519775,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "Outside of the MUC and ACE notions of events, other related approaches for summarizing a text include topic models, extractive summarization, and abstractive summarization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches to text summarization. No dataset names are present in the text.",
      "processing_time": 56.164854526519775,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "Outside of the MUC and ACE notions of events, other related approaches for summarizing a text include topic models, extractive summarization, and abstractive summarization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches to text summarization. No dataset names are present in the text.",
      "processing_time": 56.164854526519775,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "Outside of the MUC and ACE notions of events, other related approaches for summarizing a text include topic models, extractive summarization, and abstractive summarization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches to text summarization. No dataset names are present in the text.",
      "processing_time": 56.164854526519775,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "Outside of the MUC and ACE notions of events, other related approaches for summarizing a text include topic models, extractive summarization, and abstractive summarization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches to text summarization. No dataset names are present in the text.",
      "processing_time": 56.164854526519775,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "Outside of the MUC and ACE notions of events, other related approaches for summarizing a text include topic models, extractive summarization, and abstractive summarization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches to text summarization. No dataset names are present in the text.",
      "processing_time": 56.164854526519775,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "Outside of the MUC and ACE notions of events, other related approaches for summarizing a text include topic models, extractive summarization, and abstractive summarization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches to text summarization. No dataset names are present in the text.",
      "processing_time": 56.164854526519775,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "Outside of the MUC and ACE notions of events, other related approaches for summarizing a text include topic models, extractive summarization, and abstractive summarization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches to text summarization. No dataset names are present in the text.",
      "processing_time": 56.164854526519775,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "Outside of the MUC and ACE notions of events, other related approaches for summarizing a text include topic models, extractive summarization, and abstractive summarization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches to text summarization. No dataset names are present in the text.",
      "processing_time": 56.164854526519775,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "The macro-event structure represents the unification of event ideologies studied in the ACE and MUC programs, focusing on single event per document summaries (like MUC) that are generalizable enough to cover a wide range of event types (like ACE).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE",
        "MUC"
      ],
      "dataset_descriptions": {
        "ACE": "Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents.",
        "MUC": "Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ACE' and 'MUC' programs, which are known datasets in the field of information extraction. These are used to study macro-event structures and event ideologies.",
      "processing_time": 69.4050064086914,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "The macro-event structure represents the unification of event ideologies studied in the ACE and MUC programs, focusing on single event per document summaries (like MUC) that are generalizable enough to cover a wide range of event types (like ACE).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE",
        "MUC"
      ],
      "dataset_descriptions": {
        "ACE": "Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents.",
        "MUC": "Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ACE' and 'MUC' programs, which are known datasets in the field of information extraction. These are used to study macro-event structures and event ideologies.",
      "processing_time": 69.4050064086914,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "The macro-event structure represents the unification of event ideologies studied in the ACE and MUC programs, focusing on single event per document summaries (like MUC) that are generalizable enough to cover a wide range of event types (like ACE).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE",
        "MUC"
      ],
      "dataset_descriptions": {
        "ACE": "Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents.",
        "MUC": "Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ACE' and 'MUC' programs, which are known datasets in the field of information extraction. These are used to study macro-event structures and event ideologies.",
      "processing_time": 69.4050064086914,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "The macro-event structure represents the unification of event ideologies studied in the ACE and MUC programs, focusing on single event per document summaries (like MUC) that are generalizable enough to cover a wide range of event types (like ACE).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE",
        "MUC"
      ],
      "dataset_descriptions": {
        "ACE": "Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents.",
        "MUC": "Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ACE' and 'MUC' programs, which are known datasets in the field of information extraction. These are used to study macro-event structures and event ideologies.",
      "processing_time": 69.4050064086914,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "The macro-event structure represents the unification of event ideologies studied in the ACE and MUC programs, focusing on single event per document summaries (like MUC) that are generalizable enough to cover a wide range of event types (like ACE).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE",
        "MUC"
      ],
      "dataset_descriptions": {
        "ACE": "Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents.",
        "MUC": "Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ACE' and 'MUC' programs, which are known datasets in the field of information extraction. These are used to study macro-event structures and event ideologies.",
      "processing_time": 69.4050064086914,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "The macro-event structure represents the unification of event ideologies studied in the ACE and MUC programs, focusing on single event per document summaries (like MUC) that are generalizable enough to cover a wide range of event types (like ACE).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE",
        "MUC"
      ],
      "dataset_descriptions": {
        "ACE": "Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents.",
        "MUC": "Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ACE' and 'MUC' programs, which are known datasets in the field of information extraction. These are used to study macro-event structures and event ideologies.",
      "processing_time": 69.4050064086914,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "The macro-event structure represents the unification of event ideologies studied in the ACE and MUC programs, focusing on single event per document summaries (like MUC) that are generalizable enough to cover a wide range of event types (like ACE).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE",
        "MUC"
      ],
      "dataset_descriptions": {
        "ACE": "Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents.",
        "MUC": "Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ACE' and 'MUC' programs, which are known datasets in the field of information extraction. These are used to study macro-event structures and event ideologies.",
      "processing_time": 69.4050064086914,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "The macro-event structure represents the unification of event ideologies studied in the ACE and MUC programs, focusing on single event per document summaries (like MUC) that are generalizable enough to cover a wide range of event types (like ACE).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE",
        "MUC"
      ],
      "dataset_descriptions": {
        "ACE": "Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents.",
        "MUC": "Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ACE' and 'MUC' programs, which are known datasets in the field of information extraction. These are used to study macro-event structures and event ideologies.",
      "processing_time": 69.4050064086914,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "The macro-event structure represents the unification of event ideologies studied in the ACE and MUC programs, focusing on single event per document summaries (like MUC) that are generalizable enough to cover a wide range of event types (like ACE).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE",
        "MUC"
      ],
      "dataset_descriptions": {
        "ACE": "Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents.",
        "MUC": "Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ACE' and 'MUC' programs, which are known datasets in the field of information extraction. These are used to study macro-event structures and event ideologies.",
      "processing_time": 69.4050064086914,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "Transfer-Ownership is not important enough for a summary). . . . . 5\n2.1 Event types studied in the MUC program by year . . . . . . . . . . . . . . . .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to event types studied in the MUC program. No clear, verifiable dataset names are provided.",
      "processing_time": 57.26975631713867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "Transfer-Ownership is not important enough for a summary). . . . . 5\n2.1 Event types studied in the MUC program by year . . . . . . . . . . . . . . . .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to event types studied in the MUC program. No clear, verifiable dataset names are provided.",
      "processing_time": 57.26975631713867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "Transfer-Ownership is not important enough for a summary). . . . . 5\n2.1 Event types studied in the MUC program by year . . . . . . . . . . . . . . . .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to event types studied in the MUC program. No clear, verifiable dataset names are provided.",
      "processing_time": 57.26975631713867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "Transfer-Ownership is not important enough for a summary). . . . . 5\n2.1 Event types studied in the MUC program by year . . . . . . . . . . . . . . . .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to event types studied in the MUC program. No clear, verifiable dataset names are provided.",
      "processing_time": 57.26975631713867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "Transfer-Ownership is not important enough for a summary). . . . . 5\n2.1 Event types studied in the MUC program by year . . . . . . . . . . . . . . . .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to event types studied in the MUC program. No clear, verifiable dataset names are provided.",
      "processing_time": 57.26975631713867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "Transfer-Ownership is not important enough for a summary). . . . . 5\n2.1 Event types studied in the MUC program by year . . . . . . . . . . . . . . . .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to event types studied in the MUC program. No clear, verifiable dataset names are provided.",
      "processing_time": 57.26975631713867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "Transfer-Ownership is not important enough for a summary). . . . . 5\n2.1 Event types studied in the MUC program by year . . . . . . . . . . . . . . . .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to event types studied in the MUC program. No clear, verifiable dataset names are provided.",
      "processing_time": 57.26975631713867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "Transfer-Ownership is not important enough for a summary). . . . . 5\n2.1 Event types studied in the MUC program by year . . . . . . . . . . . . . . . .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to event types studied in the MUC program. No clear, verifiable dataset names are provided.",
      "processing_time": 57.26975631713867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "Transfer-Ownership is not important enough for a summary). . . . . 5\n2.1 Event types studied in the MUC program by year . . . . . . . . . . . . . . . .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to event types studied in the MUC program. No clear, verifiable dataset names are provided.",
      "processing_time": 57.26975631713867,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "In MUC, the event type for each year was always given, so there was no need to determine the correct template to use for any particular document.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to MUC (Message Understanding Conferences). No specific dataset names are provided.",
      "processing_time": 56.53131341934204,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "In MUC, the event type for each year was always given, so there was no need to determine the correct template to use for any particular document.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to MUC (Message Understanding Conferences). No specific dataset names are provided.",
      "processing_time": 56.53131341934204,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "In MUC, the event type for each year was always given, so there was no need to determine the correct template to use for any particular document.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to MUC (Message Understanding Conferences). No specific dataset names are provided.",
      "processing_time": 56.53131341934204,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "In MUC, the event type for each year was always given, so there was no need to determine the correct template to use for any particular document.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to MUC (Message Understanding Conferences). No specific dataset names are provided.",
      "processing_time": 56.53131341934204,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "In MUC, the event type for each year was always given, so there was no need to determine the correct template to use for any particular document.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to MUC (Message Understanding Conferences). No specific dataset names are provided.",
      "processing_time": 56.53131341934204,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "In MUC, the event type for each year was always given, so there was no need to determine the correct template to use for any particular document.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to MUC (Message Understanding Conferences). No specific dataset names are provided.",
      "processing_time": 56.53131341934204,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "In MUC, the event type for each year was always given, so there was no need to determine the correct template to use for any particular document.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to MUC (Message Understanding Conferences). No specific dataset names are provided.",
      "processing_time": 56.53131341934204,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "In MUC, the event type for each year was always given, so there was no need to determine the correct template to use for any particular document.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to MUC (Message Understanding Conferences). No specific dataset names are provided.",
      "processing_time": 56.53131341934204,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "In MUC, the event type for each year was always given, so there was no need to determine the correct template to use for any particular document.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to MUC (Message Understanding Conferences). No specific dataset names are provided.",
      "processing_time": 56.53131341934204,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "Early document-level extraction methods under MUC relied strongly on handcrafted rules (similarly to FRUMP) or pattern matching techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and techniques. No dataset names are present in the citation span.",
      "processing_time": 55.88869905471802,
      "citing_paper_id": "3519188",
      "cited_paper_id": 448730
    },
    {
      "context_text": "Early document-level extraction methods under MUC relied strongly on handcrafted rules (similarly to FRUMP) or pattern matching techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and techniques. No dataset names are present in the citation span.",
      "processing_time": 55.88869905471802,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2114002
    },
    {
      "context_text": "Early document-level extraction methods under MUC relied strongly on handcrafted rules (similarly to FRUMP) or pattern matching techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and techniques. No dataset names are present in the citation span.",
      "processing_time": 55.88869905471802,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2364656
    },
    {
      "context_text": "Early document-level extraction methods under MUC relied strongly on handcrafted rules (similarly to FRUMP) or pattern matching techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and techniques. No dataset names are present in the citation span.",
      "processing_time": 55.88869905471802,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5749336
    },
    {
      "context_text": "Early document-level extraction methods under MUC relied strongly on handcrafted rules (similarly to FRUMP) or pattern matching techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and techniques. No dataset names are present in the citation span.",
      "processing_time": 55.88869905471802,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5817011
    },
    {
      "context_text": "Early document-level extraction methods under MUC relied strongly on handcrafted rules (similarly to FRUMP) or pattern matching techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and techniques. No dataset names are present in the citation span.",
      "processing_time": 55.88869905471802,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14282973
    },
    {
      "context_text": "Early document-level extraction methods under MUC relied strongly on handcrafted rules (similarly to FRUMP) or pattern matching techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and techniques. No dataset names are present in the citation span.",
      "processing_time": 55.88869905471802,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14493443
    },
    {
      "context_text": "Early document-level extraction methods under MUC relied strongly on handcrafted rules (similarly to FRUMP) or pattern matching techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and techniques. No dataset names are present in the citation span.",
      "processing_time": 55.88869905471802,
      "citing_paper_id": "3519188",
      "cited_paper_id": 33436811
    },
    {
      "context_text": "Early document-level extraction methods under MUC relied strongly on handcrafted rules (similarly to FRUMP) or pattern matching techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and techniques. No dataset names are present in the citation span.",
      "processing_time": 55.88869905471802,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": "Our independent SVMs and Learning to Search methods are both trained using LIBSVM34 [10].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions LIBSVM but does not indicate it is a dataset. It is a library for support vector machines, which is a method or tool.",
      "processing_time": 56.88246989250183,
      "citing_paper_id": "3519188",
      "cited_paper_id": 961425
    },
    {
      "context_text": "More specifically, we follow the AggreVaTe model of Ross and Bagnell [107], and apply it to",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (AggreVaTe).",
      "processing_time": 54.737210512161255,
      "citing_paper_id": "3519188",
      "cited_paper_id": 1685197
    },
    {
      "context_text": "Recent work has attempted to solve the event coreference problem [3, 5, 66, 79], however such methods are imperfect, and can lead to compounding errors in an NLP pipeline.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous work on event coreference resolution.",
      "processing_time": 55.0569634437561,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2294115
    },
    {
      "context_text": "However, to do so would require near-perfect sentence-level event extraction, near-perfect sentence-level event coreference [3, 5, 66, 79], near-perfect entity",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the requirement for near-perfect performance in various NLP tasks.",
      "processing_time": 55.70733022689819,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2294115
    },
    {
      "context_text": "coreference [66, 67], near-perfect aggregation of sentence-level events to a document-level template, and near perfect information extraction across entities, event triggers, and event arguments, so as to mitigate against compounding errors in the processing pipeline.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only discusses aspects of coreference resolution and information extraction.",
      "processing_time": 55.1091251373291,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2294115
    },
    {
      "context_text": "coreference [66, 67], near-perfect aggregation of sentence-level events to a document-level template, and near perfect information extraction across entities, event triggers, and event arguments, so as to mitigate against compounding errors in the processing pipeline.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only discusses aspects of coreference resolution and information extraction.",
      "processing_time": 55.1091251373291,
      "citing_paper_id": "3519188",
      "cited_paper_id": 13475584
    },
    {
      "context_text": "the above objective function yields (using the log-derivative trick [122]):",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or algorithm. The context is about an objective function and the log-derivative trick, which are not datasets.",
      "processing_time": 57.56804609298706,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2332513
    },
    {
      "context_text": "In this section, we elucidate the connections of our proposed approach to policy gradient and the classic REINFORCE algorithm [122].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a connection to a reinforcement learning algorithm.",
      "processing_time": 54.721940994262695,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2332513
    },
    {
      "context_text": "Most recent work follows sentence-level extraction, and in particular following the standards set by the Automatic Content Extraction (ACE) program1 [17, 42, 56, 71, 72, 74, 90, 126].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Automatic Content Extraction (ACE) program"
      ],
      "dataset_descriptions": {
        "Automatic Content Extraction (ACE) program": "Mentioned as a standard for sentence-level event extraction, but specific usage in this research context is not detailed."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Automatic Content Extraction (ACE) program' which is a known dataset/resource in the field of information extraction. However, it does not specify how it is used in the current research context.",
      "processing_time": 66.93065309524536,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "Most recent work follows sentence-level extraction, and in particular following the standards set by the Automatic Content Extraction (ACE) program1 [17, 42, 56, 71, 72, 74, 90, 126].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Automatic Content Extraction (ACE) program"
      ],
      "dataset_descriptions": {
        "Automatic Content Extraction (ACE) program": "Mentioned as a standard for sentence-level event extraction, but specific usage in this research context is not detailed."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Automatic Content Extraction (ACE) program' which is a known dataset/resource in the field of information extraction. However, it does not specify how it is used in the current research context.",
      "processing_time": 66.93065309524536,
      "citing_paper_id": "3519188",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "Most recent work follows sentence-level extraction, and in particular following the standards set by the Automatic Content Extraction (ACE) program1 [17, 42, 56, 71, 72, 74, 90, 126].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Automatic Content Extraction (ACE) program"
      ],
      "dataset_descriptions": {
        "Automatic Content Extraction (ACE) program": "Mentioned as a standard for sentence-level event extraction, but specific usage in this research context is not detailed."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Automatic Content Extraction (ACE) program' which is a known dataset/resource in the field of information extraction. However, it does not specify how it is used in the current research context.",
      "processing_time": 66.93065309524536,
      "citing_paper_id": "3519188",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "Deep learning has been applied to a wide variety of machine learning and NLP tasks, including part-of-speech tagging [26, 110, 130], parsing [15, 25], named entity recognition [22, 26, 111], machine reading comprehension [16, 28, 31, 43, 59], and computer vision [63, 112, 121] – often resulting in state-of-the-art performance on these tasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general tasks and areas where deep learning has been applied. No verifiable resources are named.",
      "processing_time": 56.85582780838013,
      "citing_paper_id": "3519188",
      "cited_paper_id": 2834402
    },
    {
      "context_text": "Deep learning has been applied to a wide variety of machine learning and NLP tasks, including part-of-speech tagging [26, 110, 130], parsing [15, 25], named entity recognition [22, 26, 111], machine reading comprehension [16, 28, 31, 43, 59], and computer vision [63, 112, 121] – often resulting in state-of-the-art performance on these tasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general tasks and areas where deep learning has been applied. No verifiable resources are named.",
      "processing_time": 56.85582780838013,
      "citing_paper_id": "3519188",
      "cited_paper_id": 6300165
    },
    {
      "context_text": "Deep learning has been applied to a wide variety of machine learning and NLP tasks, including part-of-speech tagging [26, 110, 130], parsing [15, 25], named entity recognition [22, 26, 111], machine reading comprehension [16, 28, 31, 43, 59], and computer vision [63, 112, 121] – often resulting in state-of-the-art performance on these tasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general tasks and areas where deep learning has been applied. No verifiable resources are named.",
      "processing_time": 56.85582780838013,
      "citing_paper_id": "3519188",
      "cited_paper_id": 6360322
    },
    {
      "context_text": "Deep learning has been applied to a wide variety of machine learning and NLP tasks, including part-of-speech tagging [26, 110, 130], parsing [15, 25], named entity recognition [22, 26, 111], machine reading comprehension [16, 28, 31, 43, 59], and computer vision [63, 112, 121] – often resulting in state-of-the-art performance on these tasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general tasks and areas where deep learning has been applied. No verifiable resources are named.",
      "processing_time": 56.85582780838013,
      "citing_paper_id": "3519188",
      "cited_paper_id": 9150889
    },
    {
      "context_text": "Deep learning has been applied to a wide variety of machine learning and NLP tasks, including part-of-speech tagging [26, 110, 130], parsing [15, 25], named entity recognition [22, 26, 111], machine reading comprehension [16, 28, 31, 43, 59], and computer vision [63, 112, 121] – often resulting in state-of-the-art performance on these tasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general tasks and areas where deep learning has been applied. No verifiable resources are named.",
      "processing_time": 56.85582780838013,
      "citing_paper_id": "3519188",
      "cited_paper_id": 11616343
    },
    {
      "context_text": "Deep learning has been applied to a wide variety of machine learning and NLP tasks, including part-of-speech tagging [26, 110, 130], parsing [15, 25], named entity recognition [22, 26, 111], machine reading comprehension [16, 28, 31, 43, 59], and computer vision [63, 112, 121] – often resulting in state-of-the-art performance on these tasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general tasks and areas where deep learning has been applied. No verifiable resources are named.",
      "processing_time": 56.85582780838013,
      "citing_paper_id": "3519188",
      "cited_paper_id": 12586316
    },
    {
      "context_text": "Deep learning has been applied to a wide variety of machine learning and NLP tasks, including part-of-speech tagging [26, 110, 130], parsing [15, 25], named entity recognition [22, 26, 111], machine reading comprehension [16, 28, 31, 43, 59], and computer vision [63, 112, 121] – often resulting in state-of-the-art performance on these tasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general tasks and areas where deep learning has been applied. No verifiable resources are named.",
      "processing_time": 56.85582780838013,
      "citing_paper_id": "3519188",
      "cited_paper_id": 206592484
    },
    {
      "context_text": "This problem can be framed as an integer linear program, and is solved using AD3 [83].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (AD3) used to solve an integer linear program.",
      "processing_time": 54.95312857627869,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5251230
    },
    {
      "context_text": "Since then, numerous advances have been made, both in terms of additional available datasets [44, 91, 98] and more sophisticated deep learning models [16, 28, 31, 59].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets by name, only referring to 'additional available datasets' without providing concrete identifiers.",
      "processing_time": 55.64135670661926,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5761781
    },
    {
      "context_text": "Since then, numerous advances have been made, both in terms of additional available datasets [44, 91, 98] and more sophisticated deep learning models [16, 28, 31, 59].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets by name, only referring to 'additional available datasets' without providing concrete identifiers.",
      "processing_time": 55.64135670661926,
      "citing_paper_id": "3519188",
      "cited_paper_id": 6360322
    },
    {
      "context_text": "A variety of large-scale corpora for machine reading comprehension have been developed in recent years, including the CNN/DailyMail [43], CBT (Children’s Book Test) [45], SQuAD (Stanford Question Answering Dataset) [98], and WDW (Who Did What) datasets [91].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CNN/DailyMail",
        "CBT (Children’s Book Test)",
        "SQuAD (Stanford Question Answering Dataset)",
        "WDW (Who Did What)"
      ],
      "dataset_descriptions": {
        "CNN/DailyMail": "Used for machine reading comprehension, focusing on summarization and cloze tests to evaluate model performance on news articles.",
        "CBT (Children’s Book Test)": "Used for evaluating machine reading comprehension through cloze tests based on children’s books, assessing the ability to understand and predict context.",
        "SQuAD (Stanford Question Answering Dataset)": "Used for question answering tasks, where models are trained to extract answers from Wikipedia articles, focusing on document-level understanding.",
        "WDW (Who Did What)": "Used for person-centered cloze tests, focusing on identifying actions performed by individuals in news articles, enhancing event extraction capabilities."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several corpora used for machine reading comprehension, which are relevant to document-level event extraction. Each is a specific, named dataset.",
      "processing_time": 87.6466019153595,
      "citing_paper_id": "3519188",
      "cited_paper_id": 5761781
    },
    {
      "context_text": "The most well known method for extractive summarization is Maximum Marginal Relevance (MMR) [8].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MMR as a method for extractive summarization, but does not refer to any specific dataset.",
      "processing_time": 55.45821189880371,
      "citing_paper_id": "3519188",
      "cited_paper_id": 6334682
    },
    {
      "context_text": "MMR operates by greedily selecting sentences one at a time, using a scoring function based on a combination of relevancy and redundancy:\nscoreMMR(si) = λrel(si)− (1− λ) max sj∈S sim(si, sj)\nwhere λ is a scalar on the interval [0, 1], rel(si) is the relevance of sentence si, S is the set of sentences selected so far, and sim(si, sj) is the similarity between sentences si and sj (e.g. cosine similarity).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes the MMR algorithm but does not mention any specific datasets. The focus is on the method itself rather than a reusable dataset.",
      "processing_time": 56.62376093864441,
      "citing_paper_id": "3519188",
      "cited_paper_id": 6334682
    },
    {
      "context_text": "The point of transition between models could be determined via approaches similar to DUAL (Dual Strategy Active Learning) [33], or one could use a weighted vote among various models, where the weights for the directly supervised methods start low and increase as annotated data becomes more readily available.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and strategies. The context is about model training and active learning strategies, not dataset usage.",
      "processing_time": 56.781904458999634,
      "citing_paper_id": "3519188",
      "cited_paper_id": 6909306
    },
    {
      "context_text": "In addition to textual event extraction, there exists a large body of work applying event extraction to video [78, 80, 81, 87, 99, 100, 118, 124, 125].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to event extraction applied to video. No verifiable resources are named.",
      "processing_time": 56.608880281448364,
      "citing_paper_id": "3519188",
      "cited_paper_id": 7994659
    },
    {
      "context_text": "In addition to textual event extraction, there exists a large body of work applying event extraction to video [78, 80, 81, 87, 99, 100, 118, 124, 125].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to event extraction applied to video. No verifiable resources are named.",
      "processing_time": 56.608880281448364,
      "citing_paper_id": "3519188",
      "cited_paper_id": 8471433
    },
    {
      "context_text": "In addition to textual event extraction, there exists a large body of work applying event extraction to video [78, 80, 81, 87, 99, 100, 118, 124, 125].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to event extraction applied to video. No verifiable resources are named.",
      "processing_time": 56.608880281448364,
      "citing_paper_id": "3519188",
      "cited_paper_id": 11137261
    },
    {
      "context_text": "Since then, numerous advances have been made, both in terms of additional available datasets [31, 63, 67] and more sophisticated deep learning models [10, 18, 20, 41].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation span mentions 'additional available datasets' but does not specify any dataset names. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 57.30899691581726,
      "citing_paper_id": "3519188",
      "cited_paper_id": 9205021
    },
    {
      "context_text": "The generated language from FUF/SURGE serves as the final constructed summary.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or tool (FUF/SURGE) used for generating summaries.",
      "processing_time": 56.092066287994385,
      "citing_paper_id": "3519188",
      "cited_paper_id": 10256382
    },
    {
      "context_text": "A parser is applied to the sentences containing these phrases to obtain predicate-argument structures, which are then used by FUF/SURGE [33, 106], a tool for natural language generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tools and methods. The context focuses on the use of a parser and FUF/SURGE for generating predicate-argument structures.",
      "processing_time": 58.08597660064697,
      "citing_paper_id": "3519188",
      "cited_paper_id": 10256382
    },
    {
      "context_text": "Filatova and Hatzivassiloglou [36] extracted relationships between entities and frequent nouns to represent events, and used these as features for extractive summarization.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for extracting relationships between entities and frequent nouns for event representation.",
      "processing_time": 55.950878381729126,
      "citing_paper_id": "3519188",
      "cited_paper_id": 10827006
    },
    {
      "context_text": "Nguyen and Grishman [2015] consider the problem of event trigger classification via convolutional neural networks [61, 65].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (convolutional neural networks) and a research problem (event trigger classification).",
      "processing_time": 56.84067893028259,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14542261
    },
    {
      "context_text": "Given the recent success of cross-lingual NLP for a variety of tasks, including part-of-speech tagging [24, 113], dependency parsing [1, 24, 85, 129], and named entity recognition [102], this could be another promising area of development for future research.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general tasks and areas of research. No verifiable resources are identified.",
      "processing_time": 55.95319867134094,
      "citing_paper_id": "3519188",
      "cited_paper_id": 14693554
    },
    {
      "context_text": "a PERSON entity cannot fill the Time argument role) • Most frequent baseline – for each argument role, assigns the most frequently mentioned named entity with valid entity type • Aggregated Sentence-Level Event Extraction – runs ACE-style event extraction using joint inference of event triggers and arguments [70, 71, 72].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on event extraction methodologies and baselines.",
      "processing_time": 56.11844825744629,
      "citing_paper_id": "3519188",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "[57] explored using an information extraction system to identify entities, relations, and events, and utilize these to reweight candidate sentences in an extractive summarization system.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach involving information extraction and summarization.",
      "processing_time": 55.16360640525818,
      "citing_paper_id": "3519188",
      "cited_paper_id": 17131989
    },
    {
      "context_text": "A number of similar systems for automatically learning patterns were also proposed, including PALKA [62], CRYSTAL [114], and LIEP [53].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several systems but does not refer to any specific datasets. The systems are likely methods or tools rather than datasets.",
      "processing_time": 55.86945366859436,
      "citing_paper_id": "3519188",
      "cited_paper_id": 59002598
    },
    {
      "context_text": ", 2013) are also able to model the coreference relations and entities at document-level, but have been proved to perform substantially worse than supervised models (Patwardhan and Riloff, 2009).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance. There are no clear identifiers for datasets in the text.",
      "processing_time": 56.25242638587952,
      "citing_paper_id": "221246218",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Evaluation Metric The metric for past work on document-level role-filler mentions extraction (Patwardhan and Riloff, 2009; Huang and Riloff, 2011; Du and Cardie, 2020) calculates mention-level precision across all alternative mentions for each rolefiller entity.",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and methods. No dataset names are present in the text.",
      "processing_time": 56.235498905181885,
      "citing_paper_id": "221246218",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Evaluation Metric The metric for past work on document-level role-filler mentions extraction (Patwardhan and Riloff, 2009; Huang and Riloff, 2011; Du and Cardie, 2020) calculates mention-level precision across all alternative mentions for each rolefiller entity.",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and methods. No dataset names are present in the text.",
      "processing_time": 56.235498905181885,
      "citing_paper_id": "231728756",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Document-level IE Document-level event rolefiller mention extraction has been explored in recent work, using hand-designed features for both local and additional context (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012), and with end-to-end sequence tagging based models with contextualized pre-trained representations (Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The focus is on the methodologies used for document-level event role filler mention extraction.",
      "processing_time": 56.39829158782959,
      "citing_paper_id": "221246218",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "As a result of these complications, end-to-end sentence-level event extraction models (Chen et al., 2015; Lample et al., 2016), which dominate the literature, are illsuited for the template filling task, which calls for models that encode information and track entities across a longer context.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the limitations of sentence-level event extraction models.",
      "processing_time": 56.56917953491211,
      "citing_paper_id": "221246218",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "We treat document-level template filling as a sequence-to-sequence task (Sutskever et al., 2014) in order to better model the cross-role dependencies and cross-sentence noun phrase coreference structure.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for treating document-level template filling as a sequence-to-sequence task.",
      "processing_time": 56.235069036483765,
      "citing_paper_id": "221246218",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Instead of using a sequence-to-sequence learning architecture with separate modules (Sutskever et al., 2014; Bahdanau et al., 2015), we use a single pretrained transformer model (Devlin et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 56.57040357589722,
      "citing_paper_id": "221246218",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Instead of using a sequence-to-sequence learning architecture with separate modules (Sutskever et al., 2014; Bahdanau et al., 2015), we use a single pretrained transformer model (Devlin et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 56.57040357589722,
      "citing_paper_id": "231728756",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Instead of using a sequence-to-sequence learning architecture with separate modules (Sutskever et al., 2014; Bahdanau et al., 2015), we use a single pretrained transformer model (Devlin et al., 2019) for both parts, and introduce no additional fine-tuned parameters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers are used to reference the models and methods, not datasets.",
      "processing_time": 56.932724714279175,
      "citing_paper_id": "221246218",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Instead of using a sequence-to-sequence learning architecture with separate modules (Sutskever et al., 2014; Bahdanau et al., 2015), we use a single pretrained transformer model (Devlin et al., 2019) for both parts, and introduce no additional fine-tuned parameters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers are used to reference the models and methods, not datasets.",
      "processing_time": 56.932724714279175,
      "citing_paper_id": "221246218",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Duan et al. (2017) and Zhao et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not provide specific details about datasets used. It only mentions authors and a year, which is insufficient to identify a dataset.",
      "processing_time": 56.50364398956299,
      "citing_paper_id": "221246218",
      "cited_paper_id": 9778664
    },
    {
      "context_text": "Duan et al. (2017) and Zhao et al. (2018) leverage document embeddings as additional features to aid event detection.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions leveraging document embeddings for event detection but does not specify any datasets. The cited papers' titles also do not mention specific datasets.",
      "processing_time": 56.66883134841919,
      "citing_paper_id": "221246218",
      "cited_paper_id": 9778664
    },
    {
      "context_text": "Duan et al. (2017) and Zhao et al. (2018) leverage document embeddings as additional features to aid event detection.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions leveraging document embeddings for event detection but does not specify any datasets. The cited papers' titles also do not mention specific datasets.",
      "processing_time": 56.66883134841919,
      "citing_paper_id": "231728756",
      "cited_paper_id": 51871927
    },
    {
      "context_text": "Previous state-of-the-art methods include Li et al. (2013) and Li et al. (2015), which explored a variety of hand-designed features.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods and their exploration of hand-designed features.",
      "processing_time": 55.40113592147827,
      "citing_paper_id": "221246218",
      "cited_paper_id": 14117526
    },
    {
      "context_text": "Previous state-of-the-art methods include Li et al. (2013) and Li et al. (2015), which explored a variety of hand-designed features.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods and their exploration of hand-designed features.",
      "processing_time": 55.40113592147827,
      "citing_paper_id": "231728756",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "We base the event-based template-filling task on the original MUC1 formulation (Sundheim, 1991), but simplify it as done in prior research (Huang and Riloff, 2012; Du and Cardie, 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC1"
      ],
      "dataset_descriptions": {
        "MUC1": "Used to simplify the event-based template-filling task, focusing on message understanding and event extraction methodologies."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions the MUC1 formulation, which is a specific dataset used for message understanding and event extraction tasks.",
      "processing_time": 62.209317207336426,
      "citing_paper_id": "221246218",
      "cited_paper_id": 14365335
    },
    {
      "context_text": "It is of great importance for automating many real-world tasks, such as event extraction from newswire (Sundheim, 1991).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general task of event extraction from newswire. No verifiable resources are identified.",
      "processing_time": 56.651816606521606,
      "citing_paper_id": "221246218",
      "cited_paper_id": 14365335
    },
    {
      "context_text": "It is of great importance for automating many real-world tasks, such as event extraction from newswire (Sundheim, 1991).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general task of event extraction from newswire. No verifiable resources are identified.",
      "processing_time": 56.651816606521606,
      "citing_paper_id": "231728756",
      "cited_paper_id": 14365335
    },
    {
      "context_text": "Du and Cardie (2020), for example, extend standard contextualized representations (Devlin et al., 2019) to produce a documentlevel sequence tagging model for event argument extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BERT) and a research application (document-level sequence tagging for event argument extraction).",
      "processing_time": 57.09800958633423,
      "citing_paper_id": "221246218",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Both the baselines are end-toend and fine-tuned BERT (Devlin et al., 2019) contextualized representations with task-specific data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'task-specific data' but does not provide a specific dataset name. The citation is focused on the method (BERT) rather than a dataset.",
      "processing_time": 57.53029680252075,
      "citing_paper_id": "221246218",
      "cited_paper_id": 52967399
    },
    {
      "context_text": ", 2015), we use a single pretrained transformer model (Devlin et al., 2019) for both parts, and introduce no additional fine-tuned parameters.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a pretrained model (BERT). No datasets are referenced for training or evaluation.",
      "processing_time": 56.1025755405426,
      "citing_paper_id": "221246218",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In the scientiïňĄc domain, Peng et al. (2017); Wang and Poon (2018); Jia et al. (2019) study N -ary cross-sentence RE using distant supervision annotations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'distant supervision annotations' but does not specify a named dataset. The context is about N-ary cross-sentence relation extraction, which is relevant to document-level event extraction.",
      "processing_time": 59.13072848320007,
      "citing_paper_id": "221246218",
      "cited_paper_id": 102353905
    },
    {
      "context_text": "Dong et al. (2019) presents a new unified pre-trained language model that can be fine-tuned for both NLU and NLG tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a pre-trained language model. The context is about the model's capabilities, not the data used.",
      "processing_time": 57.24775719642639,
      "citing_paper_id": "221246218",
      "cited_paper_id": 147704286
    },
    {
      "context_text": "Also on a related note, Chambers and Jurafsky (2011); Chambers (2013); Liu et al. (2019) work on unsupervised event schema induction and open-domain event extraction from documents.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions work on unsupervised event schema induction and open-domain event extraction but does not specify any datasets. The context is too generic and lacks specific dataset names.",
      "processing_time": 57.92475914955139,
      "citing_paper_id": "221246218",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Sentence-level Event Extraction Most work in event extraction has focused on the ACE sentencelevel event task (Walker et al., 2006), which requires the detection of an event trigger and extraction of its arguments from within a single sentence.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.5,
      "reasoning": "The context mentions the ACE sentence-level event task, which is a well-known dataset in the field of event extraction. However, the name 'ACE' does not appear in the context as a specific dataset label.",
      "processing_time": 59.75088167190552,
      "citing_paper_id": "221246218",
      "cited_paper_id": null
    },
    {
      "context_text": "For this reason, the interactive demonstrator is sometimes referred to as a dynamic oracle (Goldberg and Nivre, 2012).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or tool called 'dynamic oracle'.",
      "processing_time": 54.77472996711731,
      "citing_paper_id": "252873525",
      "cited_paper_id": 1195002
    },
    {
      "context_text": "Much recent work in this domain has turned away from the full task, focusing only on REE and assuming a single aggregate template per document (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012; Du et al., 2021a; Huang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works. No dataset names are present in the text.",
      "processing_time": 56.63174390792847,
      "citing_paper_id": "252873525",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Much recent work in this domain has turned away from the full task, focusing only on REE and assuming a single aggregate template per document (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012; Du et al., 2021a; Huang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works. No dataset names are present in the text.",
      "processing_time": 56.63174390792847,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "Beyond SCIREX, PubMed (Quirk and Poon, 2017; Peng et al., 2017) and DocRED (Yao et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PubMed",
        "DocRED"
      ],
      "dataset_descriptions": {
        "PubMed": "Used as a source of biomedical documents for relation extraction, focusing on cross-sentence relations and entity interactions.",
        "DocRED": "Used to evaluate document-level relation extraction models, specifically focusing on multi-sentence relations and complex event structures."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'PubMed' and 'DocRED', both of which are datasets. However, 'PubMed' is a database, and 'DocRED' is a dataset specifically used for document-level relation extraction, making it highly relevant to the topic.",
      "processing_time": 71.7121810913086,
      "citing_paper_id": "252873525",
      "cited_paper_id": 2797612
    },
    {
      "context_text": "Beyond SCIREX, PubMed (Quirk and Poon, 2017; Peng et al., 2017) and DocRED (Yao et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PubMed",
        "DocRED"
      ],
      "dataset_descriptions": {
        "PubMed": "Used as a source of biomedical documents for relation extraction, focusing on cross-sentence relations and entity interactions.",
        "DocRED": "Used to evaluate document-level relation extraction models, specifically focusing on multi-sentence relations and complex event structures."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'PubMed' and 'DocRED', both of which are datasets. However, 'PubMed' is a database, and 'DocRED' is a dataset specifically used for document-level relation extraction, making it highly relevant to the topic.",
      "processing_time": 71.7121810913086,
      "citing_paper_id": "252873525",
      "cited_paper_id": 15359942
    },
    {
      "context_text": "Beyond S CI REX, PubMed (Quirk and Poon, 2017; Peng et al., 2017) and DocRED (Yao et al., 2019) are two other prominent benchmarks in this area.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate document-level relation extraction models, focusing on complex relations across multiple sentences in scientific documents."
      },
      "confidence_score": 0.9,
      "reasoning": "PubMed and DocRED are mentioned as prominent benchmarks in the document-level relation extraction area. However, PubMed is excluded as it is a database of articles, not a dataset. DocRED is included as it is a specific, verifiable dataset.",
      "processing_time": 65.94360256195068,
      "citing_paper_id": "252873525",
      "cited_paper_id": 2797612
    },
    {
      "context_text": "Beyond S CI REX, PubMed (Quirk and Poon, 2017; Peng et al., 2017) and DocRED (Yao et al., 2019) are two other prominent benchmarks in this area.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate document-level relation extraction models, focusing on complex relations across multiple sentences in scientific documents."
      },
      "confidence_score": 0.9,
      "reasoning": "PubMed and DocRED are mentioned as prominent benchmarks in the document-level relation extraction area. However, PubMed is excluded as it is a database of articles, not a dataset. DocRED is included as it is a specific, verifiable dataset.",
      "processing_time": 65.94360256195068,
      "citing_paper_id": "252873525",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "We model state transitions using a single gated recurrent unit (GRU; Cho et al., 2014).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (GRU).",
      "processing_time": 54.65589427947998,
      "citing_paper_id": "252873525",
      "cited_paper_id": 11336213
    },
    {
      "context_text": ", 2020), MUC-4 (Grishman and Sundheim, 1996), and BETTER Phase II English Granular.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "BETTER Phase II English Granular"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate document-level event extraction, focusing on identifying and classifying events in text documents.",
        "BETTER Phase II English Granular": "Used to assess granular event extraction, specifically targeting detailed event structures and relationships in English texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions MUC-4 and BETTER Phase II English Granular, which are specific datasets used in event extraction research.",
      "processing_time": 69.64707469940186,
      "citing_paper_id": "252873525",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "…Transformer encoder, which naturally models interactions both between spans and between a span and the template type via self-attention (Vaswani et al., 2017): We emphasize that the inputs to the Transformer are embeddings of spans (see §3.1) and not tokens, following Chen et al. (2019, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of a Transformer encoder and span embeddings, which are not datasets.",
      "processing_time": 57.92005681991577,
      "citing_paper_id": "252873525",
      "cited_paper_id": 174797908
    },
    {
      "context_text": ", 2017) and DocRED (Yao et al., 2019) are two other prominent benchmarks in this area.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate document-level relation extraction models, focusing on complex relations across multiple sentences within documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions 'DocRED' as a benchmark, which is a specific dataset used for document-level relation extraction. It is included based on the context and the cited paper title.",
      "processing_time": 63.74556851387024,
      "citing_paper_id": "252873525",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "…focus in recent years on problems such as argument linking (Ebner et al., 2020; Li et al., 2021, i.a. ), 𝑁 -ary relation extraction (Quirk and Poon, 2017; Yao et al., 2019; Jain et al., 2020, i.a. ), and — our primary focus — template extraction (Du et al., 2021b; Huang et al., 2021, i.a. ).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only research areas and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 56.87373089790344,
      "citing_paper_id": "252873525",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "…focus in recent years on problems such as argument linking (Ebner et al., 2020; Li et al., 2021, i.a. ), 𝑁 -ary relation extraction (Quirk and Poon, 2017; Yao et al., 2019; Jain et al., 2020, i.a. ), and — our primary focus — template extraction (Du et al., 2021b; Huang et al., 2021, i.a. ).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only research areas and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 56.87373089790344,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "…focus in recent years on problems such as argument linking (Ebner et al., 2020; Li et al., 2021, i.a. ), 𝑁 -ary relation extraction (Quirk and Poon, 2017; Yao et al., 2019; Jain et al., 2020, i.a. ), and — our primary focus — template extraction (Du et al., 2021b; Huang et al., 2021, i.a. ).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only research areas and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 56.87373089790344,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "5 The input document is first embedded using a pretrained Transformer encoder (Devlin et al., 2019; Raffel et al., 2020) that is fine-tuned during model training.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is about using pretrained Transformer encoders, which are not datasets.",
      "processing_time": 56.87136793136597,
      "citing_paper_id": "252873525",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "Moreover, our best performing model under T5 (Raffel et al., 2020) achieves roughly 2 the performance of T EMP G EN 15 (see Table 2).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (T5 and T EMP G EN). The context focuses on model performance comparisons.",
      "processing_time": 56.56539845466614,
      "citing_paper_id": "252873525",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "Moreover, our best performing model under T5enc large (Raffel et al., 2020) achieves roughly 2.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (T5enc large). The context is about model performance, not dataset usage.",
      "processing_time": 57.51666045188904,
      "citing_paper_id": "252873525",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "The input document is first embedded using a pretrained Transformer encoder (Devlin et al., 2019; Raffel et al., 2020) that is fine-tuned during model training.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is about using pretrained Transformer encoders, which are not datasets.",
      "processing_time": 57.11794829368591,
      "citing_paper_id": "252873525",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "Independent Modeling We train a classifier that outputs a slot type (or 𝜀 ) given both the template type embedding t and the slot type embedding s , inspired by a standard practice in binary relation extraction (Ebner et al., 2020; Lin et al., 2020, i.a. ).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for training a classifier. The context is about the methodology and not the data used.",
      "processing_time": 57.11516284942627,
      "citing_paper_id": "252873525",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "5 For all experiments, we use the neural CRF-based span finder employed for FrameNet parsing in Xia et al. (2021) and for the BETTER Abstract task in Yarmohammadi et al. (2021).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and tasks. The context focuses on the use of a neural CRF-based span finder for FrameNet parsing and the BETTER Abstract task.",
      "processing_time": 59.16797614097595,
      "citing_paper_id": "252873525",
      "cited_paper_id": 231719525
    },
    {
      "context_text": "Argument linking — a generalization of semantic role labeling (SRL; Gildea and Jurafsky, 2002) in which a predicate’s extra-sentential arguments must also be labeled — is one notable example, and has attracted recent attention through the RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021) benchmarks.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate argument linking, a generalization of semantic role labeling, focusing on extra-sentential arguments in document-level event extraction.",
        "WikiEvents": "Used to evaluate argument linking, a generalization of semantic role labeling, focusing on extra-sentential arguments in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two benchmarks, RAMS and WikiEvents, which are used for document-level event argument extraction. These are specific datasets used in the research.",
      "processing_time": 70.88280272483826,
      "citing_paper_id": "252873525",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "…— a generalization of semantic role labeling (SRL; Gildea and Jurafsky, 2002) in which a predicate’s extra-sentential arguments must also be labeled — is one notable example, and has attracted recent attention through the RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021) benchmarks.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate document-level event argument extraction, focusing on identifying and labeling extra-sentential arguments in complex documents.",
        "WikiEvents": "Used to assess document-level event extraction, emphasizing the identification of events and their arguments across multiple sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions two benchmarks, RAMS and WikiEvents, which are relevant to document-level event extraction. These are specific datasets used for evaluating models in this domain.",
      "processing_time": 69.27459454536438,
      "citing_paper_id": "252873525",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "…reasoning to IE has been underscored by an intense research focus in recent years on problems such as argument linking (Ebner et al., 2020; Li et al., 2021, i.a. ), 𝑁 -ary relation extraction (Quirk and Poon, 2017; Yao et al., 2019; Jain et al., 2020, i.a. ), and — our primary focus —…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research areas and problems. The context is too generic to identify any verifiable resources.",
      "processing_time": 57.012771129608154,
      "citing_paper_id": "252873525",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "One could conceivably argue that this usage has begun to change with the recent interest in argument linking datasets like RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021), in which arguments may appear in different sentences from the one containing their predicate.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event argument extraction, focusing on linking arguments across sentences, enhancing the understanding of event structures.",
        "WikiEvents": "Utilized for document-level event argument extraction, specifically for linking arguments that appear in different sentences from their predicates, improving event coherence."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for argument linking in document-level event extraction.",
      "processing_time": 67.99592709541321,
      "citing_paper_id": "252873525",
      "cited_paper_id": 233219850
    },
    {
      "context_text": ", 2020) and WikiEvents (Li et al., 2021) benchmarks.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'WikiEvents' which is a benchmark. However, benchmarks are excluded unless they refer to a specific, downloadable dataset. No other datasets are mentioned.",
      "processing_time": 57.875680446624756,
      "citing_paper_id": "252873525",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Du et al. (2021b) reports CEAF-REE for GTT under an optimal template alignment, but this is obtained via brute-force, enumerating and evaluating every possible alignment, including those between templates of different types.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (brute-force enumeration) used to obtain CEAF-REE scores. The context is focused on the evaluation methodology rather than the use of a dataset.",
      "processing_time": 58.99623346328735,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "The CEAF-REE metric, introduced by Du et al. (2021a), has since been adopted as the standard evaluation metric for MUC-4 (Du et al., 2021b; Huang et al., 2021).",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions CEAF-REE as an evaluation metric but does not refer to any specific dataset. The context is about the adoption of a metric, not the use of a dataset.",
      "processing_time": 58.82202410697937,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "The CEAF-REE metric, introduced by Du et al. (2021a), has since been adopted as the standard evaluation metric for MUC-4 (Du et al., 2021b; Huang et al., 2021).",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions CEAF-REE as an evaluation metric but does not refer to any specific dataset. The context is about the adoption of a metric, not the use of a dataset.",
      "processing_time": 58.82202410697937,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "Existing approaches such as Du et al. (2021b) and Huang et al. (2021) rely on a linearization strategy to force models to learn to predict templates in a pre-defined order .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and strategies. The context is about model training approaches, not data sources.",
      "processing_time": 56.75718903541565,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Existing approaches such as Du et al. (2021b) and Huang et al. (2021) rely on a linearization strategy to force models to learn to predict templates in a pre-defined order .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and strategies. The context is about model training approaches, not data sources.",
      "processing_time": 56.75718903541565,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "This setting corresponds to the standard practice of using fixed template linearizations (Du et al., 2021b; Huang et al., 2021).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.79391360282898,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "This setting corresponds to the standard practice of using fixed template linearizations (Du et al., 2021b; Huang et al., 2021).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.79391360282898,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "Much recent work in this domain has turned away from the full task, focusing only on REE, which is tantamount to assuming that there is just a single aggregate template per document (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012; Du et al., 2021a; Huang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works. No dataset names are present in the text.",
      "processing_time": 56.275714635849,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Much recent work in this domain has turned away from the full task, focusing only on REE, which is tantamount to assuming that there is just a single aggregate template per document (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012; Du et al., 2021a; Huang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works. No dataset names are present in the text.",
      "processing_time": 56.275714635849,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "But following renewed interest in document-level IE, researchers (Du et al., 2021b; Huang et al., 2021; Gantt et al., 2022, i.a. ) have begun to revisit MUC and to develop new template extraction datasets (notably, BETTER Granular).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "BETTER Granular"
      ],
      "dataset_descriptions": {
        "MUC": "Revisited for document-level information extraction, focusing on template filling and entity-based extraction using generative transformers.",
        "BETTER Granular": "Developed for template extraction in document-level information extraction, specifically for granular and detailed template generation."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC' and 'BETTER Granular' as datasets used in document-level information extraction. MUC is a well-known dataset, and BETTER Granular is a newer dataset developed for template extraction.",
      "processing_time": 72.35213947296143,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "But following renewed interest in document-level IE, researchers (Du et al., 2021b; Huang et al., 2021; Gantt et al., 2022, i.a. ) have begun to revisit MUC and to develop new template extraction datasets (notably, BETTER Granular).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "BETTER Granular"
      ],
      "dataset_descriptions": {
        "MUC": "Revisited for document-level information extraction, focusing on template filling and entity-based extraction using generative transformers.",
        "BETTER Granular": "Developed for template extraction in document-level information extraction, specifically for granular and detailed template generation."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC' and 'BETTER Granular' as datasets used in document-level information extraction. MUC is a well-known dataset, and BETTER Granular is a newer dataset developed for template extraction.",
      "processing_time": 72.35213947296143,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "21 Here, we discuss CEAF-REE (Du et al., 2021a), the current standard metric for MUC-4 evaluation.",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (CEAF-REE) used for evaluation. The context is focused on the metric and its application in MUC-4 evaluation.",
      "processing_time": 58.988717555999756,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "GTT (Du et al., 2021b) To our knowledge, this is the only prior work to have attempted full template extraction in recent years, and their work is thus our primary baseline for comparison on MUC4.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC4"
      ],
      "dataset_descriptions": {
        "MUC4": "Used for evaluating template extraction methods, specifically comparing the performance of GTT against other approaches in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions MUC4 as a dataset used for comparison, which is a known dataset in the field of information extraction.",
      "processing_time": 62.53282356262207,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Others have instead focused on the simplified problem of role-filler entity extraction (REE), which entails extracting all slot-filling entities but does not involve mapping them to individual templates (Patwardhan and Riloff, 2009; Du et al., 2021a, i.a. ).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works on role-filler entity extraction.",
      "processing_time": 55.82170271873474,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "…a second maximum bipartite matching problem, which requires aligning predicted and reference templates of the same type, and which CEAF-REE (either CEAF-REE def or CEAF-REE impl ) is not natively Figure 6: An example alignment between predicted and reference entities from Du et al. (2021a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses a method (CEAF-REE) and an example alignment from a cited paper, but no dataset names are provided.",
      "processing_time": 58.99104571342468,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "In Du et al. (2021a), CEAF-REE impl uses ⊆ ( 𝑅, 𝑆 = 1 𝑆 ⊆ .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CEAF-REE impl).",
      "processing_time": 55.65050172805786,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Practically, this means that the alignment shown in Figure 6 would receive full credit, whereas it ought to receive a precision score of only 0.75, as Du et al. (2021a) describe.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or finding from Du et al. (2021a).",
      "processing_time": 56.269487619400024,
      "citing_paper_id": "252873525",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Following Huang et al. (2021), we frame this as a template extraction task, treating each 4-tuple as a template with four slots.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The context is too generic to infer any specific dataset usage.",
      "processing_time": 57.314215898513794,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "TEMPGEN (Huang et al., 2021) This is the current state-of-the-art system for REE (the simplified",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or system called TEMPGEN. The title of the cited paper does not provide additional information about datasets.",
      "processing_time": 58.12604069709778,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "S CI REX For T EMP G EN , we report models trained with BART base and BART large , where only BART base was used in Huang et al. (2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (BART base and BART large). The context is about model training and evaluation, not dataset usage.",
      "processing_time": 58.113051652908325,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "The CEAF-REE implementation (henceforth, CEAF-REE impl ) employed in Du et al. (2021a,b) and Huang et al. (2021) unfortunately departs from the stated metric definition (CEAF-REE def ) in two ways: (1) it eliminates the constraint on entity alignments and (2) it treats the template type as an…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CEAF-REE) and its implementation details. No verifiable resources are identified.",
      "processing_time": 57.35504102706909,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "We simply treat the S CI REX 4-tuples as 4-slot templates, following Huang et al. (2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "S CI REX"
      ],
      "dataset_descriptions": {
        "S CI REX": "Used to generate 4-slot templates for document-level entity-based extraction, focusing on structured information extraction from documents."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'S CI REX 4-tuples' which appears to be a specific dataset or resource. However, without more context, it is unclear if it is a dataset or a method. The title of the cited paper suggests it is used for template generation, which aligns with a dataset usage.",
      "processing_time": 69.73554754257202,
      "citing_paper_id": "252873525",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "Researchers later focused more heavily on sentence-level IE, especially after the introduction of the ACE 2005 dataset (Walker et al., 2006).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to advance sentence-level information extraction, focusing on event identification and argument recognition in text."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE 2005 dataset, which is a well-known resource for information extraction tasks, particularly for sentence-level event extraction.",
      "processing_time": 63.53346228599548,
      "citing_paper_id": "252873525",
      "cited_paper_id": null
    },
    {
      "context_text": "Researchers later focused more heavily on sentence-level IE, especially after the release of the ACE 2005 dataset (Walker et al., 2006).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used for sentence-level information extraction, focusing on the development and evaluation of models for identifying and classifying events within sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE 2005 dataset, which is a specific, verifiable dataset used for sentence-level information extraction.",
      "processing_time": 64.05700755119324,
      "citing_paper_id": "252873525",
      "cited_paper_id": null
    },
    {
      "context_text": "…other proposals in the NLP literature that only differentiate between certain and uncertain (e.g., Medlock and Briscoe [2007] and its subsequent work, or Diab et al. [2009b]) and approaches that distinguish among four (e.g., Henriksson and Velupillai 2010) or even five degrees (Rubin 2007, 2010).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to works that discuss levels of certainty in annotations.",
      "processing_time": 55.92219829559326,
      "citing_paper_id": "2239324",
      "cited_paper_id": 522537
    },
    {
      "context_text": "…Language Understanding Annotation Corpus (Diab et al. 2009a) focuses on the author’s committed belief towards what is reported (a notion comparable to the modality axis in event factuality), and the small knowledge-intensive corpus by Henriksson and Velupillai (2010) targets degrees of certainty.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Language Understanding Annotation Corpus",
        "small knowledge-intensive corpus"
      ],
      "dataset_descriptions": {
        "Language Understanding Annotation Corpus": "Used to annotate the author's committed belief towards reported information, focusing on modality in event factuality.",
        "small knowledge-intensive corpus": "Used to annotate degrees of certainty in knowledge-intensive contexts, targeting nuanced levels of belief and confidence."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions two corpora: 'Language Understanding Annotation Corpus' and a 'small knowledge-intensive corpus'. Both are used for annotation studies related to belief and certainty.",
      "processing_time": 70.7624032497406,
      "citing_paper_id": "2239324",
      "cited_paper_id": 522537
    },
    {
      "context_text": "Input documents have been tokenized, POS-tagged, and parsed into dependency trees with the Stanford Parser (version 1.6; de Marneffe, MacCartney, and Manning 2006).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Stanford Parser but does not refer to any specific dataset. It is used as a tool for processing input documents.",
      "processing_time": 56.80133390426636,
      "citing_paper_id": "2239324",
      "cited_paper_id": 3102322
    },
    {
      "context_text": "…linguistics, authors from different traditions converge in analyzing modality as a subjective component of discourse (e.g., Lyons 1977; Chafe 1986; Palmer 1986; Kiefer 1987), a view that is adopted in the present analysis.4 Traditionally, the study of epistemic modality in linguistics has been…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to linguistic studies and theories. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 58.4155547618866,
      "citing_paper_id": "2239324",
      "cited_paper_id": 8975187
    },
    {
      "context_text": "It has generally been observed that, even though modality is a continuous system, a three-fold distinction is commonly adopted by speakers (e.g., Lyons 1977; Palmer 1986; Halliday andMatthiessen 2004).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to linguistic theories and works. No verifiable resources are identified.",
      "processing_time": 56.35860300064087,
      "citing_paper_id": "2239324",
      "cited_paper_id": 8975187
    },
    {
      "context_text": "…is adopted in the present analysis.4 Traditionally, the study of epistemic modality in linguistics has been confined to modal auxiliaries (e.g., Palmer 1986), but more recently a wider view has been adopted which includes other parts of speech as well, such as epistemic adverbs, adjectives,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a shift in the study of epistemic modality in linguistics. No verifiable resources are identified.",
      "processing_time": 57.82919001579285,
      "citing_paper_id": "2239324",
      "cited_paper_id": 8975187
    },
    {
      "context_text": "Moreover, it is at the basis of explorations on hedging and negation cues scope identification, such as Morante and Daelemans (2009a, 2009b), which apply a supervised sequence labeling approach, or Özgür and Radev (2009) and Velldal, Ovrelid, and Oepen (2010), which",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for identifying hedging and negation cues.",
      "processing_time": 55.23706531524658,
      "citing_paper_id": "2239324",
      "cited_paper_id": 15491194
    },
    {
      "context_text": "Here, we embrace the analyses defended by Geurts (1998) and Glanzberg (2003), among others.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only references analyses by Geurts and Glanzberg.",
      "processing_time": 57.063512086868286,
      "citing_paper_id": "2239324",
      "cited_paper_id": 16465979
    },
    {
      "context_text": "This line of research is further explored by Szarvas ( 2008 ).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to further research. No verifiable resources are identified.",
      "processing_time": 55.50087094306946,
      "citing_paper_id": "2239324",
      "cited_paper_id": 18743753
    },
    {
      "context_text": "…with other work also approaching tasks of sub-sentential interpretation by means of linguistically heavy and resource-intensive models, such as Moilanen and Pulman (2007) or Neviarouskaya, Prendinger, and Ishizuka (2009), which address sentiment analysis based on the principle of…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works and their approaches to sentiment analysis.",
      "processing_time": 55.9375364780426,
      "citing_paper_id": "2239324",
      "cited_paper_id": 32599709
    },
    {
      "context_text": "For example, in Moilanen and Pulman (2007) and Moilanen, Pulman, and Zhang (2010) the well-known semantics principle of compositionality is applied for sentiment polarity classification at the (sub)sentence level, and in Neviarouskaya, Prendinger, and Ishizuka (2009), for recognizing emotions such…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for sentiment polarity classification and emotion recognition.",
      "processing_time": 55.70129132270813,
      "citing_paper_id": "2239324",
      "cited_paper_id": 32599709
    },
    {
      "context_text": "Epistemic modality has been studied from both the logical and linguistic traditions.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to epistemic modality being studied from logical and linguistic perspectives.",
      "processing_time": 57.60071301460266,
      "citing_paper_id": "2239324",
      "cited_paper_id": 57995948
    },
    {
      "context_text": "Within linguistics, authors from different traditions converge in analyzing modality as a subjective component of discourse (e.g., Lyons 1977; Chafe 1986; Palmer 1986; Kiefer 1987), a view that is adopted in the present analysis.4 Traditionally, the study of epistemic modality in linguistics has…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to linguistic studies and theories. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 57.584105014801025,
      "citing_paper_id": "2239324",
      "cited_paper_id": 57995948
    },
    {
      "context_text": "It has generally been observed that, even though modality is a continuous system, a three-fold distinction is commonly adopted by speakers (eg, Lyons  1977 ); (Palmer  1986 ); (Halliday and Matthiessen  2004 ).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to literature discussing modalities in language.",
      "processing_time": 55.94552135467529,
      "citing_paper_id": "2239324",
      "cited_paper_id": 62362826
    },
    {
      "context_text": "All these categories display an equivalent gradation of modality (Givón 1993).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to a concept discussed in the cited paper.",
      "processing_time": 56.83099341392517,
      "citing_paper_id": "2239324",
      "cited_paper_id": 120565858
    },
    {
      "context_text": "D ow nloaded from http://direct.m it.edu/coli/article-pdf/38/2/261/1801523/coli_a_00096.pdf by guest on 12 Septem ber 2021\nThis continuum poses a challenge in the setting of a model of factuality with potential cross-linguistic validity.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses a conceptual challenge in modeling factuality.",
      "processing_time": 57.102965354919434,
      "citing_paper_id": "2239324",
      "cited_paper_id": 140428658
    },
    {
      "context_text": "Certainty touches as well on the notion of epistemic stance, developed from a more cognitivist perspective and which is defined as the pragmatic relation between speakers and their knowledge regarding the things they talk about (Biber and Finegan 1989; Mushin 2001).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to epistemic stance and evidentiality, which are concepts rather than resources.",
      "processing_time": 58.13760542869568,
      "citing_paper_id": "2239324",
      "cited_paper_id": 140428658
    },
    {
      "context_text": "Horn (1989) analyzes modality and its interaction with polarity based on both linguistic tests and the logical relations holding at the basis of the Aristotelian Square of Opposition (in particular, the Law of Excluded Middle and the Law of Contradiction).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only theoretical concepts and logical relations. There are no verifiable resources or datasets mentioned.",
      "processing_time": 57.08869433403015,
      "citing_paper_id": "2239324",
      "cited_paper_id": 171035753
    },
    {
      "context_text": "Many linguists agree, however, that speakers are able to map areas of the modality axis into discrete values (Lyons 1977; Horn 1989; de Haan 1997).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only references linguistic theories and concepts.",
      "processing_time": 55.40951895713806,
      "citing_paper_id": "2239324",
      "cited_paper_id": 171035753
    },
    {
      "context_text": "Many linguists agree, however, that speakers are able to map areas of the modality axis into discrete values (Lyons 1977; Horn 1989; de Haan 1997).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only references linguistic theories and concepts.",
      "processing_time": 55.40951895713806,
      "citing_paper_id": "2239324",
      "cited_paper_id": null
    },
    {
      "context_text": "Here, we use the term in its original grammatical sense, that is, as conveying the distinction between affirmative and negative contexts (e.g., Horn 1989).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to a concept discussed in a cited paper.",
      "processing_time": 56.800453662872314,
      "citing_paper_id": "2239324",
      "cited_paper_id": 171035753
    },
    {
      "context_text": "Here, we use the term in its original grammatical sense, that is, as conveying the distinction between affirmative and negative contexts (eg, Horn  1989 ).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to a concept discussed in a cited paper.",
      "processing_time": 57.0873658657074,
      "citing_paper_id": "2239324",
      "cited_paper_id": 171035753
    },
    {
      "context_text": "The details of the system presented here are further elaborated in Saurı́ (2008).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a dissertation. There is no indication of dataset usage.",
      "processing_time": 56.81180191040039,
      "citing_paper_id": "2239324",
      "cited_paper_id": 259945602
    },
    {
      "context_text": "Karttunen and Zaenen (2005) discuss its relevance for information extraction, and in the area of textual entailment, factuality-related information (modality, intensional contexts, etc.) has been taken as a basic feature in some systems participating in the PASCAL RTE challenges (e.g., Hickl and…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts and challenges. The PASCAL RTE challenges are mentioned but not as a dataset, rather as a context for research.",
      "processing_time": 58.92153358459473,
      "citing_paper_id": "2239324",
      "cited_paper_id": 263864800
    },
    {
      "context_text": "Karttunen and Zaenen (2005) discuss its relevance for information extraction, and in the area of textual entailment, factuality-related information (modality, intensional contexts, etc.) has been taken as a basic feature in some systems participating in the PASCAL RTE challenges (e.g., Hickl and…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts and challenges. The PASCAL RTE challenges are mentioned but not as a dataset, rather as a context for research.",
      "processing_time": 58.92153358459473,
      "citing_paper_id": "2239324",
      "cited_paper_id": null
    },
    {
      "context_text": "The GENIA Event corpus (Kim, Ohta, and Tsujii 2008) contains 1,000 abstracts with biological events annotated with polarity and degrees of certainty, in addition to other information such as the lexical cues leading to these values (Ohta, Kim, and Tsuji 2007).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA Event corpus"
      ],
      "dataset_descriptions": {
        "GENIA Event corpus": "Used to annotate biological events in 1,000 abstracts, including polarity, certainty, and lexical cues, supporting research in event extraction methodologies."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENIA Event corpus, which is a specific dataset used for annotating biological events in abstracts. It is clearly identified and described in the citation.",
      "processing_time": 65.7608437538147,
      "citing_paper_id": "2239324",
      "cited_paper_id": null
    },
    {
      "context_text": "These two measures mutually compensate for an over-emphasis present in the other (either on the lesser or greater populated categories), and can therefore be interpreted as the lower and upper bounds of the De Facto’s performance.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It discusses performance measures without referencing any particular resource.",
      "processing_time": 56.50648903846741,
      "citing_paper_id": "2239324",
      "cited_paper_id": null
    },
    {
      "context_text": "Several predicate classes create this effect, for example: volition (e.g., want, wish, hope), commitment (commit, offer, propose), and inclination predicates (willing, ready, eager, reluctant), among others (cf. Asher 1993).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or resources. It only refers to linguistic concepts and examples.",
      "processing_time": 56.48609018325806,
      "citing_paper_id": "2239324",
      "cited_paper_id": null
    },
    {
      "context_text": "Our PTPCG is an end-to-end model with joint training and scheduled sampling [Bengio et al. , 2015] strategy.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (scheduled sampling) and a model (PTPCG).",
      "processing_time": 56.50077700614929,
      "citing_paper_id": "245123950",
      "cited_paper_id": 1820089
    },
    {
      "context_text": "Our PTPCG is an end-to-end model with joint training and scheduled sampling [Bengio et al. , 2015] strategy.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (scheduled sampling) and a model (PTPCG).",
      "processing_time": 56.50077700614929,
      "citing_paper_id": "245123950",
      "cited_paper_id": null
    },
    {
      "context_text": "For a document D , a bidirectional long short-term memory (BiLSTM) network [Hochreiter and Schmidhuber, 1997] is used to encode each sentence s i into token-wise hidden states ( h i , . . . , h ) , where h i and | s i | is the length of i -th sentence.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BiLSTM). The citation is used to reference the method, not a dataset.",
      "processing_time": 57.584580183029175,
      "citing_paper_id": "245123950",
      "cited_paper_id": 1915014
    },
    {
      "context_text": "1 Event Detection For a document D, a bidirectional long short-term memory (BiLSTM) network [Hochreiter and Schmidhuber, 1997] is used to encode each sentence si into token-wise hidden states",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BiLSTM).",
      "processing_time": 55.13451433181763,
      "citing_paper_id": "245123950",
      "cited_paper_id": 4249277
    },
    {
      "context_text": "a low annotation quality since the large-scale datasets are usually generated via distantly supervised (DS) alignment with existing knowledge bases (KB) (Mintz et al. 2009; Chen et al. 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'large-scale datasets' but does not provide specific names. It refers to a general method of generating datasets using distant supervision.",
      "processing_time": 56.53300213813782,
      "citing_paper_id": "245123950",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "Otherwise, Bron-Kerbosch (BK) algo-rithm [Bron and Kerbosch, 1973] is applied ﬁrst to ﬁnd all possible cliques (step 1 in Figure 3).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Bron-Kerbosch algorithm but does not refer to any specific dataset. The context is about the application of the algorithm to find cliques, which is a methodological detail.",
      "processing_time": 59.48762845993042,
      "citing_paper_id": "245123950",
      "cited_paper_id": 13886709
    },
    {
      "context_text": "We believe it is the future direction to improve the similarity calculation and adjacent matrix prediction. et al. , 2019 ] as sentence representations and exploit relations between sentences via graph neural networks [ Veli ˇ ckovi ´ c et al. , 2018 ] to help identify ﬁxed number of combinations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on improving similarity calculation and using graph neural networks for sentence relations.",
      "processing_time": 57.58026385307312,
      "citing_paper_id": "245123950",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "…EE (SEE) which focuses on building trigger-centered trees [Chen et al. , 2015; Nguyen et al. , 2016; Liu et al. , 2018; Wadden et al. , 2019; Lin et al. , 2020], document-level EE (DEE) is to decode ar-gument combinations from abundant entities across multiple sentences and ﬁll these…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses different approaches to event extraction. No verifiable resources are identified.",
      "processing_time": 57.342122316360474,
      "citing_paper_id": "245123950",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Our PTPCG is an end-to-end model with joint training and scheduled sampling [Bengio et al., 2015] strategy.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (scheduled sampling).",
      "processing_time": 55.722771883010864,
      "citing_paper_id": "245123950",
      "cited_paper_id": null
    },
    {
      "context_text": "Du and Ji (2022); Choudhary and Du (2024) leverage end-to-end deep learning-based methods (Du et al., 2017; Du and Cardie, 2018) for generating QA pairs for representing events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for generating QA pairs.",
      "processing_time": 55.90388035774231,
      "citing_paper_id": "273185680",
      "cited_paper_id": 2172129
    },
    {
      "context_text": "Du and Cardie (2020); Liu et al. (2020a) utilize heuristic-based methods for generating questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only heuristic-based methods for generating questions. No clear identifiers for datasets are present.",
      "processing_time": 57.34421229362488,
      "citing_paper_id": "273185680",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Du and Cardie (2020); Liu et al. (2020a) utilize heuristic-based methods for generating questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only heuristic-based methods for generating questions. No clear identifiers for datasets are present.",
      "processing_time": 57.34421229362488,
      "citing_paper_id": "273185680",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "…recent advancements have leveraged PLMs and introduce semantic structures (Tran Phu and Nguyen, 2021; Hu et al., 2023a), external knowledge (Liu et al., 2020b; Cao et al., 2021), and data augmentation (Zuo et al., 2020, 2021) approaches and investigated the potency of ECI with LLMs (Gao et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 58.12644648551941,
      "citing_paper_id": "273185680",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "…recent advancements have leveraged PLMs and introduce semantic structures (Tran Phu and Nguyen, 2021; Hu et al., 2023a), external knowledge (Liu et al., 2020b; Cao et al., 2021), and data augmentation (Zuo et al., 2020, 2021) approaches and investigated the potency of ECI with LLMs (Gao et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 58.12644648551941,
      "citing_paper_id": "273185680",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "Cause Effect language logical/temporal reasoning (Yang et al., 2020, 2023, 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers discussing methods or findings.",
      "processing_time": 55.70460796356201,
      "citing_paper_id": "273185680",
      "cited_paper_id": 226254029
    },
    {
      "context_text": "Afterwards, we follow previous IE toolkits (Wen et al., 2021; Du et al., 2022) to extract the event arguments with BART-Gen (Li et al., 2021), a generative model for document-level event argument extraction (EAE).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the use of BART-Gen for document-level event argument extraction, which is a method, not a dataset.",
      "processing_time": 60.09043645858765,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235097376
    },
    {
      "context_text": "Afterwards, we follow previous IE toolkits (Wen et al., 2021; Du et al., 2022) to extract the event arguments with BART-Gen (Li et al., 2021), a generative model for document-level event argument extraction (EAE).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the use of BART-Gen for document-level event argument extraction, which is a method, not a dataset.",
      "processing_time": 60.09043645858765,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "Afterwards, we follow previous IE toolkits (Wen et al., 2021; Du et al., 2022) to extract the event arguments with BART-Gen (Li et al., 2021), a generative model for document-level event argument extraction (EAE).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the use of BART-Gen for document-level event argument extraction, which is a method, not a dataset.",
      "processing_time": 60.09043645858765,
      "citing_paper_id": "273185680",
      "cited_paper_id": 249010869
    },
    {
      "context_text": "The event arguments and their single-hop relations are obtained from relevant IE models (Peng et al., 2023b; Li et al., 2021; Eberts and Ulges, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models or methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.89975428581238,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "The event arguments and their single-hop relations are obtained from relevant IE models (Peng et al., 2023b; Li et al., 2021; Eberts and Ulges, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models or methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.89975428581238,
      "citing_paper_id": "273185680",
      "cited_paper_id": 262825274
    },
    {
      "context_text": "Event Argument Extraction & Joint Entity and Relation Extraction We adopted the pre-trained models released by BART-Gen 6 (Li et al., 2021) and JEREX 7 (Eberts and Ulges, 2021) to conduct EAE and joint entity and relation extraction on our datasets, separately.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'our datasets' but does not provide specific names. No other datasets are mentioned.",
      "processing_time": 56.234312534332275,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "We adopt the templates defined by Li et al. (2021) to extract arguments for the event mentions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event detection.",
      "processing_time": 55.17804217338562,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "Event Detection We trained an event detection using the OmniEvent toolkit (Peng et al., 2023b) on the WikiEvents dataset (Li et al., 2021), and we selected CLEVE (Wang et al., 2021) as the PLM.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to train an event detection model, focusing on document-level event extraction with the OmniEvent toolkit."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the WikiEvents dataset, which is a specific, verifiable dataset used for training an event detection model. CLEVE is mentioned but is a method, not a dataset.",
      "processing_time": 64.7935061454773,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "Event Detection We trained an event detection using the OmniEvent toolkit (Peng et al., 2023b) on the WikiEvents dataset (Li et al., 2021), and we selected CLEVE (Wang et al., 2021) as the PLM.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to train an event detection model, focusing on document-level event extraction with the OmniEvent toolkit."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the WikiEvents dataset, which is a specific, verifiable dataset used for training an event detection model. CLEVE is mentioned but is a method, not a dataset.",
      "processing_time": 64.7935061454773,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235254286
    },
    {
      "context_text": "Following the previous research in EE (Du and Cardie, 2020; Deng et al., 2021), we define our Event-Event Causal Relation Extraction (ECRE) task as two subtasks: Event Causality Identification (ECI) , which identifies the existence of causal relationships between event mentions, and Causal Relation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only subtasks of the Event-Event Causal Relation Extraction task. No verifiable resources are identified.",
      "processing_time": 58.588977098464966,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "We train an event detection model us-ing the CLEVE (Wang et al., 2021) PLM on the WikiEvents dataset (Li et al., 2021) to classify the event mentions to their most likely belonged event type in the KAIROS ontology.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to train an event detection model using the CLEVE PLM, classifying event mentions to their most likely event type in the KAIROS ontology."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the WikiEvents dataset for training an event detection model. CLEVE is a method, not a dataset, so it is excluded.",
      "processing_time": 66.44014310836792,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "We train an event detection model us-ing the CLEVE (Wang et al., 2021) PLM on the WikiEvents dataset (Li et al., 2021) to classify the event mentions to their most likely belonged event type in the KAIROS ontology.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to train an event detection model using the CLEVE PLM, classifying event mentions to their most likely event type in the KAIROS ontology."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the WikiEvents dataset for training an event detection model. CLEVE is a method, not a dataset, so it is excluded.",
      "processing_time": 66.44014310836792,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235254286
    },
    {
      "context_text": "…advancements have leveraged PLMs and introduce semantic structures (Tran Phu and Nguyen, 2021; Hu et al., 2023a), external knowledge (Liu et al., 2020b; Cao et al., 2021), and data augmentation (Zuo et al., 2020, 2021) approaches and investigated the potency of ECI with LLMs (Gao et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles suggest a focus on methodologies rather than specific datasets.",
      "processing_time": 58.302207469940186,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235313431
    },
    {
      "context_text": "…advancements have leveraged PLMs and introduce semantic structures (Tran Phu and Nguyen, 2021; Hu et al., 2023a), external knowledge (Liu et al., 2020b; Cao et al., 2021), and data augmentation (Zuo et al., 2020, 2021) approaches and investigated the potency of ECI with LLMs (Gao et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles suggest a focus on methodologies rather than specific datasets.",
      "processing_time": 58.302207469940186,
      "citing_paper_id": "273185680",
      "cited_paper_id": 236460024
    },
    {
      "context_text": "We extend the definition proposed by Automatic Content Extraction (ACE), consisting of event mentions and event arguments (Frisoni et al., 2021), with the single-hop relationships of arguments to enrich their information in contexts, as examples shown in Figure 3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Automatic Content Extraction (ACE)' but does not indicate that it is a dataset. It appears to be a framework or project used to define event mentions and arguments.",
      "processing_time": 59.58957600593567,
      "citing_paper_id": "273185680",
      "cited_paper_id": 244678529
    },
    {
      "context_text": "In the single-turn QA strategy, we make use of the prompt proposed by previous work (Man et al., 2022; Gao et al., 2023) and incorporate the event structures of the two event mentions into the prompt.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods or strategies for incorporating event structures into prompts.",
      "processing_time": 56.80661940574646,
      "citing_paper_id": "273185680",
      "cited_paper_id": 250390907
    },
    {
      "context_text": "An intuitive option is to utilize LLMs for this procedure; however, since they have been found to be insufficient for IE (Li et al., 2023; Peng et al., 2023a), we adopt PLM-based approaches to construct event structures, consisting of three steps: Event Detection , Event Argument Extraction , and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the use of PLMs for event structure construction, which is not a dataset.",
      "processing_time": 59.41101884841919,
      "citing_paper_id": "273185680",
      "cited_paper_id": 258297899
    },
    {
      "context_text": "In addition, QA-based methods have also been investigated in temporal relation extraction (Cohen and Bar, 2023) and ECI (Gao et al., 2023), or retrieving useful background knowledge to improve event causality recognition (Kruengkrai et al., 2017; Kad-owaki et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on QA-based methods in temporal relation extraction and event causality recognition.",
      "processing_time": 58.95591640472412,
      "citing_paper_id": "273185680",
      "cited_paper_id": 259858871
    },
    {
      "context_text": "Unlike previous work that relys heavily on semantic structures, we leverage cross-task knowledge to construct document-level event structures to enrich event information, motivated by the effectiveness of cross-task knowledge in IE (Lin et al., 2020; Jin et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to cross-task knowledge and event structures. No clear identifiers for datasets are present.",
      "processing_time": 58.28831672668457,
      "citing_paper_id": "273185680",
      "cited_paper_id": 260063107
    },
    {
      "context_text": "We compared the performance of KnowQA against the following state-of-the-art baselines from existing ECRE research: (1) PLM (Tran Phu and Nguyen, 2021) 6) HOTECI (Man et al., 2024b) leverages optimal transport to select the most important words and sentences from full documents; (7) GIMC (He et al., 2024) constructs a heterogeneous graph interaction network to model long-distance dependencies between events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing the performance of different models, none of which are datasets.",
      "processing_time": 59.11114835739136,
      "citing_paper_id": "273185680",
      "cited_paper_id": 268249143
    },
    {
      "context_text": "…(1) PLM (Tran Phu and Nguyen, 2021) 6) HOTECI (Man et al., 2024b) leverages optimal transport to select the most important words and sentences from full documents; (7) GIMC (He et al., 2024) constructs a heterogeneous graph interaction network to model long-distance dependencies between events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 57.52916860580444,
      "citing_paper_id": "273185680",
      "cited_paper_id": 268249143
    },
    {
      "context_text": "This phenomenon contributes to low precision and high recall of LLMs on this task, which severely hampers their performance in this field (Gao et al., 2023; Liu et al., 2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the performance issues of LLMs in a certain task.",
      "processing_time": 57.92887997627258,
      "citing_paper_id": "273185680",
      "cited_paper_id": 270199894
    },
    {
      "context_text": "To ensure the richness of classification, we adopt the KAIROS 2 ontology, a superset of ACE 2005 (Walker et al., 2006) that consists of 50 event types and 59 argument roles 3 , to classify the event mentions.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'KAIROS 2 ontology' and 'ACE 2005', which are not datasets but ontologies used for classifying event mentions. No datasets are explicitly mentioned.",
      "processing_time": 59.8209490776062,
      "citing_paper_id": "273185680",
      "cited_paper_id": null
    },
    {
      "context_text": "ACE 2005 (Walker et al., 2006) 2010 Task 8 (Hendrickx et al., 2010) created two sentence-level RE datasets by human annotation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005",
        "2010 Task 8"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to create sentence-level relation extraction datasets through human annotation, focusing on semantic relations between nominals.",
        "2010 Task 8": "Used to create sentence-level relation extraction datasets through human annotation, focusing on multi-way classification of semantic relations."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'ACE 2005' and '2010 Task 8', which are known datasets in the field of semantic relation classification. However, the context does not specify their usage in document-level event extraction.",
      "processing_time": 75.91457629203796,
      "citing_paper_id": "253107167",
      "cited_paper_id": 436023
    },
    {
      "context_text": "ACE 2005 (Walker et al., 2006) 2010 Task 8 (Hendrickx et al., 2010) created two sentence-level RE datasets by human annotation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005",
        "2010 Task 8"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to create sentence-level relation extraction datasets through human annotation, focusing on semantic relations between nominals.",
        "2010 Task 8": "Used to create sentence-level relation extraction datasets through human annotation, focusing on multi-way classification of semantic relations."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'ACE 2005' and '2010 Task 8', which are known datasets in the field of semantic relation classification. However, the context does not specify their usage in document-level event extraction.",
      "processing_time": 75.91457629203796,
      "citing_paper_id": "253107167",
      "cited_paper_id": 260557571
    },
    {
      "context_text": "ACE 2005 (Walker et al., 2006) 2010 Task 8 (Hendrickx et al., 2010) created two sentence-level RE datasets by human annotation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005",
        "2010 Task 8"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to create sentence-level relation extraction datasets through human annotation, focusing on semantic relations between nominals.",
        "2010 Task 8": "Used to create sentence-level relation extraction datasets through human annotation, focusing on multi-way classification of semantic relations."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'ACE 2005' and '2010 Task 8', which are known datasets in the field of semantic relation classification. However, the context does not specify their usage in document-level event extraction.",
      "processing_time": 75.91457629203796,
      "citing_paper_id": "253107167",
      "cited_paper_id": null
    },
    {
      "context_text": "Prior work on automatic data generation mainly relies on rulebased pattern matching (Lehmann et al., 2015) and web crawling (Buck et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods for automatic data generation. No verifiable resources are identified.",
      "processing_time": 57.91341042518616,
      "citing_paper_id": "253107167",
      "cited_paper_id": 1181640
    },
    {
      "context_text": "Prior work on automatic data generation mainly relies on rule-based pattern matching (Lehmann et al., 2015) and web crawling (Buck et al., 2014).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for data generation.",
      "processing_time": 56.12171268463135,
      "citing_paper_id": "253107167",
      "cited_paper_id": 1181640
    },
    {
      "context_text": "…development of pre-trained language models (PLMs; Devlin et al., 2019; Liu et al., 2019 ; Brown et al., 2020), many recent works leverage PLMs for automatic data generation (Bing et al., 2013; Anaby-Tavor et al., 2020; Zhou et al., 2022; Yang et al., 2020; Kumar et al., 2020; Liu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only pre-trained language models and their use in data generation. No verifiable datasets are named.",
      "processing_time": 58.73334980010986,
      "citing_paper_id": "253107167",
      "cited_paper_id": 6326575
    },
    {
      "context_text": "…development of pre-trained language models (PLMs; Devlin et al., 2019; Liu et al., 2019 ; Brown et al., 2020), many recent works leverage PLMs for automatic data generation (Bing et al., 2013; Anaby-Tavor et al., 2020; Zhou et al., 2022; Yang et al., 2020; Kumar et al., 2020; Liu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only pre-trained language models and their use in data generation. No verifiable datasets are named.",
      "processing_time": 58.73334980010986,
      "citing_paper_id": "253107167",
      "cited_paper_id": 211987786
    },
    {
      "context_text": "…development of pre-trained language models (PLMs; Devlin et al., 2019; Liu et al., 2019 ; Brown et al., 2020), many recent works leverage PLMs for automatic data generation (Bing et al., 2013; Anaby-Tavor et al., 2020; Zhou et al., 2022; Yang et al., 2020; Kumar et al., 2020; Liu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only pre-trained language models and their use in data generation. No verifiable datasets are named.",
      "processing_time": 58.73334980010986,
      "citing_paper_id": "253107167",
      "cited_paper_id": 247594716
    },
    {
      "context_text": "…development of pre-trained language models (PLMs; Devlin et al., 2019; Liu et al., 2019 ; Brown et al., 2020), many recent works leverage PLMs for automatic data generation (Bing et al., 2013; Anaby-Tavor et al., 2020; Zhou et al., 2022; Yang et al., 2020; Kumar et al., 2020; Liu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only pre-trained language models and their use in data generation. No verifiable datasets are named.",
      "processing_time": 58.73334980010986,
      "citing_paper_id": "253107167",
      "cited_paper_id": 250390686
    },
    {
      "context_text": "FewRel (Han et al., 2018) and FewRel 2.0 (Gao et al., 2019) have been proposed to study the transferability and few-shot capability of RE models.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "FewRel 2.0"
      ],
      "dataset_descriptions": {
        "FewRel": "Used to study the transferability and few-shot capability of relation extraction models, providing a large-scale supervised dataset for evaluation.",
        "FewRel 2.0": "Used to extend the study of few-shot relation classification, enhancing the evaluation of model capabilities with additional challenges."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions FewRel and FewRel 2.0 as datasets used to study the transferability and few-shot capability of relation extraction models.",
      "processing_time": 71.27705073356628,
      "citing_paper_id": "253107167",
      "cited_paper_id": 53080736
    },
    {
      "context_text": "The Fleiss Kappa (Fleiss, 1971) coefficient for round 1 annotation is 0.73, which is considered as substantial agreement.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a statistical measure (Fleiss Kappa) used to assess inter-rater reliability.",
      "processing_time": 57.890992164611816,
      "citing_paper_id": "253107167",
      "cited_paper_id": 143544759
    },
    {
      "context_text": "The Fleiss Kappa (Fleiss, 1971) coefficient for round 1 annotation is 0.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a statistical measure (Fleiss Kappa) used for inter-rater reliability.",
      "processing_time": 57.8886935710907,
      "citing_paper_id": "253107167",
      "cited_paper_id": 143544759
    },
    {
      "context_text": "The Fleiss Kappa coefficient for round 2 annotation is 0.66.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an agreement measure. No datasets are referenced or used.",
      "processing_time": 57.37080907821655,
      "citing_paper_id": "253107167",
      "cited_paper_id": 143544759
    },
    {
      "context_text": "The New York Times corpus (Sandhaus, 2008) is another common relation extraction dataset used in the literature (Riedel et al., 2013; Nayak and Ng, 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "New York Times corpus"
      ],
      "dataset_descriptions": {
        "New York Times corpus": "Used as a common relation extraction dataset, focusing on extracting relations from news articles using various methodologies."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the New York Times corpus as a common relation extraction dataset, which is relevant to document-level event extraction.",
      "processing_time": 63.696834564208984,
      "citing_paper_id": "253107167",
      "cited_paper_id": 185660016
    },
    {
      "context_text": "The NYT10 (Riedel et al., 2013) dataset matched the Freebase Knowledge base (Bollacker et al., 2008) to the New York Times corpus (Sandhaus, 2008).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "NYT10",
        "Freebase Knowledge Base"
      ],
      "dataset_descriptions": {
        "NYT10": "Used to match entities and relations from the New York Times corpus to the Freebase Knowledge Base, focusing on document-level event extraction and relation identification.",
        "Freebase Knowledge Base": "Serves as a structured knowledge base to which entities and relations from the NYT10 dataset are matched, enhancing the semantic understanding of the text."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets: NYT10 and Freebase Knowledge Base, both of which are used in the research. The New York Times corpus is also mentioned but is part of the NYT10 dataset.",
      "processing_time": 76.07027077674866,
      "citing_paper_id": "253107167",
      "cited_paper_id": 185660016
    },
    {
      "context_text": "The NYT10 (Riedel et al., 2013) dataset matched the Freebase Knowledge base (Bollacker et al., 2008) to the New York Times corpus (Sandhaus, 2008).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "NYT10",
        "Freebase Knowledge Base"
      ],
      "dataset_descriptions": {
        "NYT10": "Used to match entities and relations from the New York Times corpus to the Freebase Knowledge Base, focusing on document-level event extraction and relation identification.",
        "Freebase Knowledge Base": "Serves as a structured knowledge base to which entities and relations from the NYT10 dataset are matched, enhancing the semantic understanding of the text."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets: NYT10 and Freebase Knowledge Base, both of which are used in the research. The New York Times corpus is also mentioned but is part of the NYT10 dataset.",
      "processing_time": 76.07027077674866,
      "citing_paper_id": "253107167",
      "cited_paper_id": 207167677
    },
    {
      "context_text": "We use RoBERTa-large as the encoder for DocRED and XLM-R-base (Conneau et al., 2020) for HacRED.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models (RoBERTa-large, XLM-R-base) but does not refer to any specific datasets. The citation is focused on the models used for encoding, not on datasets.",
      "processing_time": 60.668490409851074,
      "citing_paper_id": "253107167",
      "cited_paper_id": 207880568
    },
    {
      "context_text": ", 2020), many recent works leverage PLMs for automatic data generation (Bing et al., 2013; Anaby-Tavor et al., 2020; Zhou et al., 2022; Yang et al., 2020; Kumar et al., 2020; Liu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to works leveraging PLMs for data generation. No verifiable resources are identified.",
      "processing_time": 59.03129005432129,
      "citing_paper_id": "253107167",
      "cited_paper_id": 211987786
    },
    {
      "context_text": ", 2020), many recent works leverage PLMs for automatic data generation (Bing et al., 2013; Anaby-Tavor et al., 2020; Zhou et al., 2022; Yang et al., 2020; Kumar et al., 2020; Liu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to works leveraging PLMs for data generation. No verifiable resources are identified.",
      "processing_time": 59.03129005432129,
      "citing_paper_id": "253107167",
      "cited_paper_id": 250390686
    },
    {
      "context_text": "Alt et al. (2020) re-annotated a small amount of challenging samples in the development and test sets of the TA-CRED dataset (Zhang et al., 2017).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TA-CRED"
      ],
      "dataset_descriptions": {
        "TA-CRED": "Re-annotated to address challenging samples in the development and test sets, focusing on improving relation extraction accuracy."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the re-annotation of the TA-CRED dataset, which is a specific, verifiable dataset used for relation extraction tasks.",
      "processing_time": 65.09201407432556,
      "citing_paper_id": "253107167",
      "cited_paper_id": 216869183
    },
    {
      "context_text": "Recent efforts on addressing the false negative problem are from the model perspective (Chen et al., 2021; Hao et al., 2021), which aim to denoise the false negative data during training.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches to address false negatives in relation extraction.",
      "processing_time": 57.40908098220825,
      "citing_paper_id": "253107167",
      "cited_paper_id": 227342488
    },
    {
      "context_text": "Recent efforts on addressing the false negative problem are from the model perspective (Chen et al., 2021; Hao et al., 2021), which aim to de-noise the false negative data during training.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches to address false negatives in relation extraction.",
      "processing_time": 58.12142062187195,
      "citing_paper_id": "253107167",
      "cited_paper_id": 227342488
    },
    {
      "context_text": "Datasets We compare the preliminary investigation results on two sentence-level RE datasets: TA-CRED (Zhang et al., 2017) and Re-TACRED (Sto-ica et al., 2021), and two document-level RE datasets: DocRED (Yao et al., 2019) and Hac-RED (Cheng et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TA-CRED",
        "Re-TACRED",
        "DocRED",
        "Hac-RED"
      ],
      "dataset_descriptions": {
        "TA-CRED": "Used for sentence-level relation extraction, providing a benchmark for comparing preliminary investigation results.",
        "Re-TACRED": "Used for sentence-level relation extraction, offering refined annotations for more accurate comparisons.",
        "DocRED": "Used for document-level relation extraction, enabling the evaluation of complex relations across multiple sentences.",
        "Hac-RED": "Used for document-level relation extraction, focusing on challenging cases in practical applications."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions four datasets, two at the sentence level and two at the document level, all of which are relevant to the research topic of document-level event extraction.",
      "processing_time": 80.55154752731323,
      "citing_paper_id": "253107167",
      "cited_paper_id": 236478098
    },
    {
      "context_text": "With a similar approach, Cheng et al. (2021) have created a Chinese document-level RE dataset that focuses on hard relation cases.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "HacRED"
      ],
      "dataset_descriptions": {
        "HacRED": "Used to create a Chinese document-level relation extraction dataset focusing on hard relation cases, enhancing practical applications in relation extraction."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions a 'Chinese document-level RE dataset' which is relevant to the topic of document-level event extraction. The dataset is described as focusing on hard relation cases, making it a suitable resource for the research topic.",
      "processing_time": 67.53384160995483,
      "citing_paper_id": "253107167",
      "cited_paper_id": 236478098
    },
    {
      "context_text": "To mitigate noise from the machine-generated data, West et al. (2021) generate a large amount of commonsense knowledge data and employ human an-notators to filter the generated candidates.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'commonsense knowledge data' but does not specify a named dataset. It describes a process rather than a reusable dataset.",
      "processing_time": 59.4755973815918,
      "citing_paper_id": "253107167",
      "cited_paper_id": 238857304
    },
    {
      "context_text": ", 2019) originated from distant supervision from the Wikidata knowledge base (Vrandečić and Krötzsch, 2014) and Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wikidata knowledge base",
        "Wikipedia articles"
      ],
      "dataset_descriptions": {
        "Wikidata knowledge base": "Used as a source for distant supervision to create a dataset for document-level event extraction, providing structured information for entity linking.",
        "Wikipedia articles": "Used as a source for distant supervision to create a dataset for document-level event extraction, providing textual context for events and entities."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'Wikidata knowledge base' and 'Wikipedia articles', which are specific, verifiable resources. However, they are not used as datasets but rather as sources for distant supervision.",
      "processing_time": 74.4259078502655,
      "citing_paper_id": "253107167",
      "cited_paper_id": null
    },
    {
      "context_text": "ACE 2005 (Walker et al., 2006) and SemEval Ross Patterson Alger ( August 20 , 1920 – January 16 , 1992 ) was a politician in the Canadian province of Alberta , who served as mayor of Calgary from 1977 to 1980 .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to train and evaluate document-level event extraction models, focusing on identifying and classifying events within text documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions 'ACE 2005' which is a known dataset for event extraction. However, the rest of the citation is irrelevant and does not mention any other datasets.",
      "processing_time": 68.02830910682678,
      "citing_paper_id": "253107167",
      "cited_paper_id": null
    },
    {
      "context_text": "Wiki20 (Gao et al., 2021) and DocRED (Yao et al., 2019) originated from distant supervision from the Wikidata knowledge base (Vrandeˇci´c and Krötzsch, 2014) and Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wiki20",
        "DocRED"
      ],
      "dataset_descriptions": {
        "Wiki20": "Used for document-level event extraction, derived from Wikidata and Wikipedia, focusing on distant supervision methods.",
        "DocRED": "Used for document-level relation extraction, derived from Wikidata and Wikipedia, focusing on distant supervision methods."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, Wiki20 and DocRED, which are used for document-level event extraction. Both datasets are derived from Wikidata and Wikipedia.",
      "processing_time": 71.0575258731842,
      "citing_paper_id": "253107167",
      "cited_paper_id": null
    },
    {
      "context_text": "One prominent effort making use of BRAT is the BioNLP Shared Task 2011,1 in which the tool was used in the annotation of the EPI and ID main task corpora (Pyysalo et al., 2012).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EPI",
        "ID"
      ],
      "dataset_descriptions": {
        "EPI": "Used for annotating event and interaction data in the BioNLP Shared Task 2011, focusing on protein interactions and modifications.",
        "ID": "Used for annotating event and interaction data in the BioNLP Shared Task 2011, focusing on infectious diseases and their molecular mechanisms."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the EPI and ID corpora, which are specific datasets used in the BioNLP Shared Task 2011. These corpora are clearly identified and used for annotation tasks.",
      "processing_time": 75.35345244407654,
      "citing_paper_id": "2065400",
      "cited_paper_id": 3175781
    },
    {
      "context_text": "n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE"
      ],
      "dataset_descriptions": {
        "MUC": "Used to support the annotation of event structures, specifically targeting n-ary associations of annotations in document-level event extraction.",
        "ACE": "Used to support the annotation of event structures, specifically targeting n-ary associations of annotations in document-level event extraction."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC' and 'ACE', which are known datasets in the field of information extraction. MUC is specifically referenced in the context of event structures, which aligns with the research topic.",
      "processing_time": 73.43969368934631,
      "citing_paper_id": "2065400",
      "cited_paper_id": 6614930
    },
    {
      "context_text": "…annotation\n(Figure 1 middle and bottom). n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE",
        "BioNLP"
      ],
      "dataset_descriptions": {
        "MUC": "Used to support the annotation of event structures in information extraction tasks, focusing on n-ary associations of annotations.",
        "ACE": "Used to support the annotation of event structures in information extraction tasks, focusing on n-ary associations of annotations.",
        "BioNLP": "Used to support the annotation of event structures in information extraction tasks, focusing on n-ary associations of annotations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets: MUC, ACE, and BioNLP, which are relevant to document-level event extraction tasks.",
      "processing_time": 76.994699716568,
      "citing_paper_id": "2065400",
      "cited_paper_id": 6614930
    },
    {
      "context_text": "…annotation\n(Figure 1 middle and bottom). n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE",
        "BioNLP"
      ],
      "dataset_descriptions": {
        "MUC": "Used to support the annotation of event structures in information extraction tasks, focusing on n-ary associations of annotations.",
        "ACE": "Used to support the annotation of event structures in information extraction tasks, focusing on n-ary associations of annotations.",
        "BioNLP": "Used to support the annotation of event structures in information extraction tasks, focusing on n-ary associations of annotations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets: MUC, ACE, and BioNLP, which are relevant to document-level event extraction tasks.",
      "processing_time": 76.994699716568,
      "citing_paper_id": "2065400",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "These base annotations can be connected by binary relations – either directed or undirected – which can be configured for e.g. simple relation extraction, or verb frame annotation\n(Figure 1 middle and bottom). n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "ACE",
        "BioNLP"
      ],
      "dataset_descriptions": {
        "MUC": "Used for event structure annotation in Information Extraction tasks, focusing on binary and n-ary relations between annotations.",
        "ACE": "Used for event structure annotation in Information Extraction tasks, focusing on binary and n-ary relations between annotations.",
        "BioNLP": "Used for event structure annotation in Information Extraction tasks, focusing on binary and n-ary relations between annotations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions MUC, ACE, and BioNLP as specific datasets used for Information Extraction tasks, particularly for event structure annotation.",
      "processing_time": 76.55106711387634,
      "citing_paper_id": "2065400",
      "cited_paper_id": 6614930
    },
    {
      "context_text": "as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and Màrquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and tasks. No dataset names are present in the citation span.",
      "processing_time": 59.530346632003784,
      "citing_paper_id": "2065400",
      "cited_paper_id": 9716882
    },
    {
      "context_text": "as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and Màrquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and tasks. No dataset names are present in the citation span.",
      "processing_time": 59.530346632003784,
      "citing_paper_id": "2065400",
      "cited_paper_id": 16509032
    },
    {
      "context_text": "…addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and Màrquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tasks and methods. BRAT is a tool, not a dataset.",
      "processing_time": 59.131699323654175,
      "citing_paper_id": "2065400",
      "cited_paper_id": 9716882
    },
    {
      "context_text": "…information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and Màrquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tasks and methods. BRAT is a tool, not a dataset.",
      "processing_time": 59.28621864318848,
      "citing_paper_id": "2065400",
      "cited_paper_id": 16509032
    },
    {
      "context_text": "BRAT is based on our previously released opensource STAV text annotation visualiser (Stenetorp et al., 2011b), which was designed to help users gain an understanding of complex annotations involving a large number of different semantic types, dense, partially overlapping text annotations, and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a tool (BRAT) and a previous work (STAV). No verifiable datasets are referenced.",
      "processing_time": 60.29197573661804,
      "citing_paper_id": "2065400",
      "cited_paper_id": 118219099
    },
    {
      "context_text": "…machine learning-based semantic class disambiguation system capable of offering multiple outputs with probability estimates that was shown to be able to reduce ambiguity on average by over 75% while retaining the correct class in on average 99% of cases over six corpora (Stenetorp et al., 2011a).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'six corpora' but does not provide specific names. The cited paper title does not help disambiguate any specific datasets.",
      "processing_time": 60.566410303115845,
      "citing_paper_id": "2065400",
      "cited_paper_id": 118219099
    },
    {
      "context_text": "The reduction in the time spent in selecting the span is explained by the limiting of the number of candidate types exposed to the annotator, which were decreased from the original 54 to an average of 2.88 by the semantic class disambiguation component (Stenetorp et al., 2011a).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for reducing the number of candidate types in annotation. No verifiable resources are identified.",
      "processing_time": 59.796730279922485,
      "citing_paper_id": "2065400",
      "cited_paper_id": 118219099
    },
    {
      "context_text": "MONEY, and may optionally take a PLACE argument of type LOCATION (LDC, 2005).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to a type of argument in a context that appears to be describing a linguistic or annotation framework.",
      "processing_time": 60.773672580718994,
      "citing_paper_id": "2065400",
      "cited_paper_id": null
    },
    {
      "context_text": "BRAT also implements a fully configurable system for checking detailed constraints on annotation semantics, for example specifying that a TRANSFER event must take exactly one of each of GIVER, RECIPIENT and BENEFICIARY arguments, each of which must have one of the types PERSON, ORGANIZATION or GEO-POLITICAL ENTITY, as well as a MONEY argument of type\nMONEY, and may optionally take a PLACE argument of type LOCATION (LDC, 2005).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BRAT and its annotation system but does not refer to any specific dataset. The mention of LDC ( Linguistic Data Consortium) is not specific enough to identify a dataset.",
      "processing_time": 60.989970207214355,
      "citing_paper_id": "2065400",
      "cited_paper_id": null
    },
    {
      "context_text": "Several methods were developed so far but they addressed the problem in domain aspect point of view.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general statement about methods addressing the problem from a domain perspective.",
      "processing_time": 59.512120485305786,
      "citing_paper_id": "13241382",
      "cited_paper_id": 12978973
    },
    {
      "context_text": "Further, the extracted events can be beneficial for IE systems and other applications like QA systems[1], risk analysis applications [2] and implementing tools for decision making process [3].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction. No dataset names are present in the text.",
      "processing_time": 59.485535621643066,
      "citing_paper_id": "13241382",
      "cited_paper_id": 35235502
    },
    {
      "context_text": "Further, the extracted events can be beneficial for IE systems and other applications like QA systems[1], risk analysis applications [2] and implementing tools for decision making process [3].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction. No dataset names are present in the text.",
      "processing_time": 59.485535621643066,
      "citing_paper_id": "13241382",
      "cited_paper_id": null
    },
    {
      "context_text": "ACE[11] (Automatic Content Extraction) Annotation based method Based on slots filling and knowledge based population (KBP) to recognize the events.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE"
      ],
      "dataset_descriptions": {
        "ACE": "Used for event recognition through annotation-based methods, focusing on slot filling and knowledge-based population to identify events in text."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'ACE' which is a known dataset for event extraction, but does not provide specific details on its usage in this research context.",
      "processing_time": 65.52771186828613,
      "citing_paper_id": "13241382",
      "cited_paper_id": 199562431
    },
    {
      "context_text": "Event properties of TIMEML[15] ( like Reporting, Perception, Aspectual, I_State, I_Action State and Occurrence etc.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only event properties of TIMEML. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 60.23498034477234,
      "citing_paper_id": "13241382",
      "cited_paper_id": null
    },
    {
      "context_text": "Event properties of TIMEML[15] ( like Reporting, Perception, Aspectual, I_State, I_Action State and Occurrence etc.), and lexical features of parts of speech (like nouns: NN, NNS, NNP; verbs: VB, VBZ, VBP, VBG, VBN, VBD, MD is adjectives, AUX, AUXG, JJ; adverbs: WP,RB determiners: DT, WDT, CD; RB,; and prepositions: IN, pronouns: PRP) were used to frame the rules to build the structure.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only features and properties used for building rules. No clear, verifiable dataset names are present.",
      "processing_time": 60.23209547996521,
      "citing_paper_id": "13241382",
      "cited_paper_id": null
    },
    {
      "context_text": "For each generated event of te perform event identification with derived rules the rules are te\nbelongs to one of the following rules , { T1= te ∈ VB ∈ [{VB, VBZ, VBP, VBG, VBN, VBD} ] (includes all forms of verb notations of POS and Tense aspect of TIMEML) { T2= te ∈ NN ∈ (NN,NNS,NP,NPS ) { Event consists of triplet notation the rules are derived from that triplet T=triplet, consists of three tuples (W,T1,T2)  where\nW ∈ wt , T1 ∈ VB,T2∈ NN Rules for the word te to classify as an event are:\nBegin if te ∈ T te ∈ T1 U te ∈ T2 then te belongs Event(e) {\nelse if\nte∈ T te ∈ T1 U te ∉T2 then te belongs Event(e) { else if te∈ T te ∈ T1 U te ∈ T2 then te belongs Event(e) {\nClassified\nevents\nText Normalizati\non of text\nRules for\nEvent\nExtractio\nn ( )\n{\n------------ ------------ ------------ ------------ ------------\n---\n}\nDisplays the Events\nelse if te ∈ T te ∈ 1 U te ∉ T2 then te not belongs to Event(e) { else { Consider as non Events (NE)\n4. end if for 5. end if 6. end if 7. end if 8. end Procedure repeat the above steps for each word\nin document d\n9. return RESULT Display events\nFig.2: Rules Based Event Extraction Algorithm\nThis paper aims to address a novel event extraction for Open Domain.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific, verifiable datasets. It describes a rule-based algorithm for event extraction but does not reference any dataset used for training, evaluation, or testing.",
      "processing_time": 62.142597913742065,
      "citing_paper_id": "13241382",
      "cited_paper_id": null
    },
    {
      "context_text": "Kolaya [9] Chinese news extractor[10] Hybrid Event extraction Advantages of data driven, knowledge driven and statistical methods and encodes them into the form of the pattern rules.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It discusses methods and approaches but does not reference any named datasets.",
      "processing_time": 59.74727153778076,
      "citing_paper_id": "13241382",
      "cited_paper_id": null
    },
    {
      "context_text": "Then, researchers resort to a large amount of labeled data to mitigate the efforts of feature engineering and to learn diverse causal expressions (Hu et al., 2017; Hashimoto, 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'a large amount of labeled data' without providing a specific name or identifier.",
      "processing_time": 61.39758110046387,
      "citing_paper_id": "248218685",
      "cited_paper_id": 1162419
    },
    {
      "context_text": "Then, researchers resort to a large amount of labeled data to mitigate the efforts of feature engineering and to learn diverse causal expressions (Hu et al., 2017; Hashimoto, 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'a large amount of labeled data' without providing a specific name or identifier.",
      "processing_time": 61.39758110046387,
      "citing_paper_id": "248218685",
      "cited_paper_id": 202771243
    },
    {
      "context_text": "In the ﬁrst research line, early methods usually design various features tailored for causal expressions, such as lexical and syntactic patterns (Riaz and Girju, 2013, 2014a,b), causality cues or markers (Riaz and Girju, 2010; Do et al., 2011; Hidey and McKeown, 2016), statistical information…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for identifying causation in verb-noun pairs.",
      "processing_time": 59.57232975959778,
      "citing_paper_id": "248218685",
      "cited_paper_id": 9130816
    },
    {
      "context_text": "…as lexical and syntactic patterns (Riaz and Girju, 2013, 2014a,b), causality cues or markers (Riaz and Girju, 2010; Do et al., 2011; Hidey and McKeown, 2016), statistical information (Beamer and Girju, 2009; Hashimoto et al., 2014), and temporal patterns (Riaz and Girju, 2014a; Ning et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 60.63349223136902,
      "citing_paper_id": "248218685",
      "cited_paper_id": 9130816
    },
    {
      "context_text": "…as lexical and syntactic patterns (Riaz and Girju, 2013, 2014a,b), causality cues or markers (Riaz and Girju, 2010; Do et al., 2011; Hidey and McKeown, 2016), statistical information (Beamer and Girju, 2009; Hashimoto et al., 2014), and temporal patterns (Riaz and Girju, 2014a; Ning et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 60.63349223136902,
      "citing_paper_id": "248218685",
      "cited_paper_id": 17227879
    },
    {
      "context_text": "…as lexical and syntactic patterns (Riaz and Girju, 2013, 2014a,b), causality cues or markers (Riaz and Girju, 2010; Do et al., 2011; Hidey and McKeown, 2016), statistical information (Beamer and Girju, 2009; Hashimoto et al., 2014), and temporal patterns (Riaz and Girju, 2014a; Ning et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 60.63349223136902,
      "citing_paper_id": "248218685",
      "cited_paper_id": 31562985
    },
    {
      "context_text": "…as lexical and syntactic patterns (Riaz and Girju, 2013, 2014a,b), causality cues or markers (Riaz and Girju, 2010; Do et al., 2011; Hidey and McKeown, 2016), statistical information (Beamer and Girju, 2009; Hashimoto et al., 2014), and temporal patterns (Riaz and Girju, 2014a; Ning et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 60.63349223136902,
      "citing_paper_id": "248218685",
      "cited_paper_id": 51878335
    },
    {
      "context_text": "…such as lexical and syntactic patterns (Riaz and Girju, 2013, 2014a,b), causality cues or markers (Riaz and Girju, 2010; Do et al., 2011; Hidey and McKeown, 2016), statistical information (Beamer and Girju, 2009; Hashimoto et al., 2014), and temporal patterns (Riaz and Girju, 2014a;…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various types of patterns and cues used in research. No clear, verifiable resource names are provided.",
      "processing_time": 61.05450367927551,
      "citing_paper_id": "248218685",
      "cited_paper_id": 9137624
    },
    {
      "context_text": "Causality can reveal reliable structures of texts, which is beneﬁ-cial to widespread applications, such as machine reading comprehension (Berant et al., 2014), question answering (Oh et al., 2016), and future event forecasting (Hashimoto, 2019).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of causality in NLP tasks. No dataset names are present in the text.",
      "processing_time": 60.84624910354614,
      "citing_paper_id": "248218685",
      "cited_paper_id": 38687082
    },
    {
      "context_text": "Causality can reveal reliable structures of texts, which is beneﬁ-cial to widespread applications, such as machine reading comprehension (Berant et al., 2014), question answering (Oh et al., 2016), and future event forecasting (Hashimoto, 2019).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of causality in NLP tasks. No dataset names are present in the text.",
      "processing_time": 60.84624910354614,
      "citing_paper_id": "248218685",
      "cited_paper_id": 202771243
    },
    {
      "context_text": "To address this problem, we leverage an adaptive loss function for training, following focal loss (Lin et al., 2017).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'focal loss' which is a method, not a dataset. There are no specific datasets mentioned in the citation context.",
      "processing_time": 60.47524428367615,
      "citing_paper_id": "248218685",
      "cited_paper_id": 47252984
    },
    {
      "context_text": "This leads to an imbalanced classiﬁcation problem (Lin et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a classification problem. The cited paper title 'Focal Loss for Dense Object Detection' does not introduce a dataset.",
      "processing_time": 62.04216527938843,
      "citing_paper_id": "248218685",
      "cited_paper_id": 47252984
    },
    {
      "context_text": "We optimize our model with AdamW (Loshchilov and Hutter, 2019) with a linear warm-up.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions AdamW, which is a method, not a dataset. There are no specific datasets mentioned in the citation context.",
      "processing_time": 60.463109493255615,
      "citing_paper_id": "248218685",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "Gao et al. (2019) use Integer Linear Programming (ILP) to model the global causal structures; RichGCN (Tran Phu and Nguyen, 2021) constructs document-level interaction graphs and uses Graph Convolutional Network (GCN, Kipf and Welling (2017)) to capture relevant connections.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The focus is on the methodologies used for modeling document-level causal structures and capturing relevant connections.",
      "processing_time": 61.54258680343628,
      "citing_paper_id": "248218685",
      "cited_paper_id": 109933467
    },
    {
      "context_text": "However, it performs much worse than LIP, RichGCN, and ERGO on inter-sentence settings, which indicates that a document-level structure or graph is helpful to capture the global interactions for prediction.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance on inter-sentence settings.",
      "processing_time": 59.658562898635864,
      "citing_paper_id": "248218685",
      "cited_paper_id": 109933467
    },
    {
      "context_text": "An event graph is typically constructed to assist the global inference, where edges are carefully designed via heuristic rules or NLP tools, such as adjacent sentences and dependency parser (Gao et al., 2019; Tran Phu and Nguyen, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and tools used for constructing event graphs.",
      "processing_time": 59.39054036140442,
      "citing_paper_id": "248218685",
      "cited_paper_id": 109933467
    },
    {
      "context_text": "Following Gao et al. (2019), we group documents according to their topics.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for grouping documents by topics.",
      "processing_time": 59.175050020217896,
      "citing_paper_id": "248218685",
      "cited_paper_id": 109933467
    },
    {
      "context_text": "(2) LR+ and LIP (Gao et al., 2019), feature-based methods that construct document-level structures and use various types of resources.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and resources. The context is about feature-based methods and their use in constructing document-level structures.",
      "processing_time": 61.555880546569824,
      "citing_paper_id": "248218685",
      "cited_paper_id": 109933467
    },
    {
      "context_text": "Evaluation Metrics For evaluation, we adopt Precision (P), Recall (R) and F1-score (F1) as evaluation metrics, same as previous methods (Gao et al., 2019; Tran Phu and Nguyen, 2021) to ensure comparability.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. The context is focused on the methodology and metrics used for evaluation.",
      "processing_time": 60.59670090675354,
      "citing_paper_id": "248218685",
      "cited_paper_id": 109933467
    },
    {
      "context_text": "Following Baldini Soares et al. (2019), we use the embedding of token “<t>” for event representation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event representation using token embeddings.",
      "processing_time": 59.21431088447571,
      "citing_paper_id": "248218685",
      "cited_paper_id": 174801632
    },
    {
      "context_text": "Along with the success of sentence-level natural language understanding, many tasks are extended to the entire document, such as relation extraction (Yao et al., 2019), natural language inference (Yin et al., 2021), and event argument extraction (Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions extending tasks to document-level, including relation extraction, which is relevant to the topic. However, no specific dataset names are mentioned in the citation context.",
      "processing_time": 61.38203763961792,
      "citing_paper_id": "248218685",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "The reason may be: 1) Longformer continues pre-training from Roberta (Liu et al., 2019), which has been found to outperform BERT on many tasks; 2) Longformer leverages an efﬁcient local and global attention pattern, beneﬁcial to capture longer contextual information for inference.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on explaining why Longformer is used, referencing its pre-training from Roberta and its attention mechanism.",
      "processing_time": 62.96836566925049,
      "citing_paper_id": "248218685",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "The reason may be: 1) Longformer continues pre-training from Roberta (Liu et al., 2019), which has been found to outperform BERT on many tasks; 2) Longformer leverages an efﬁcient local and global attention pattern, beneﬁcial to capture longer contextual information for inference.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on explaining why Longformer is used, referencing its pre-training from Roberta and its attention mechanism.",
      "processing_time": 62.96836566925049,
      "citing_paper_id": "248218685",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "Specifically, we use global attention on the “<s>” token (Longformer uses “<s>” and “</s>” as the special start and end tokens, corresponding to BERT’s “[CLS]” and “[SEP]”), and local attention on other tokens, which could build full sequence representations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of global and local attention mechanisms in the Longformer model.",
      "processing_time": 60.267863035202026,
      "citing_paper_id": "248218685",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "In our implementation, we apply the efﬁcient local and global attention pattern of Longformer.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Longformer).",
      "processing_time": 58.81715798377991,
      "citing_paper_id": "248218685",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "In this paper, we choose pre-trained BERT (De-vlin et al., 2019) and Longformer (Beltagy et al., 2020) as encoders for comparison.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and Longformer but does not refer to them as datasets. They are models, not datasets, and thus do not meet the criteria for inclusion.",
      "processing_time": 61.939701557159424,
      "citing_paper_id": "248218685",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "Using Longformer BASE as the encoder, ERGO achieves better results than ERGO-BERT BASE , which also achieves new SOTA.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance comparisons.",
      "processing_time": 58.7708101272583,
      "citing_paper_id": "248218685",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "Longformer for Document Encoder Long-former (Beltagy et al., 2020) introduces a localized sliding window based attention (the default window size is 512) with little global attention to reduce computation and extend BERT for long documents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Longformer) and its application to long documents.",
      "processing_time": 60.18771743774414,
      "citing_paper_id": "248218685",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "The maximum document length allowed by Longformer is 4096, which is suitable for most documents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a limitation of the Longformer model regarding document length.",
      "processing_time": 59.633500814437866,
      "citing_paper_id": "248218685",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "We use uncased BERT-base (Devlin et al., 2019) or Longformser-base (Beltagy et al., 2020) as the document encoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models (BERT-base, Longformer-base) but does not reference any specific datasets. The citation is focused on the use of these models as document encoders.",
      "processing_time": 61.90800976753235,
      "citing_paper_id": "248218685",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "Existing methods mostly focus on sentence-level ECI (SECI) (Liu et al., 2020; Zuo et al., 2021a; Figure 1: Example of DECI.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to existing methods and their focus on sentence-level event causality identification (SECI).",
      "processing_time": 60.90387439727783,
      "citing_paper_id": "248218685",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Existing methods mostly focus on sentence-level ECI (SECI) (Liu et al., 2020; Zuo et al., 2021a; Figure 1: Example of DECI.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to existing methods and their focus on sentence-level event causality identification (SECI).",
      "processing_time": 60.90387439727783,
      "citing_paper_id": "248218685",
      "cited_paper_id": 235313431
    },
    {
      "context_text": "Existing methods mostly focus on sentence-level ECI (SECI) (Liu et al., 2020; Zuo et al., 2021a; Figure 1: Example of DECI.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to existing methods and their focus on sentence-level event causality identification (SECI).",
      "processing_time": 60.90387439727783,
      "citing_paper_id": "248218685",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "Following (Liu et al., 2020) and (Tran Phu and Nguyen, 2021), we employ a 10-fold cross-validation evaluation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a methodological approach (10-fold cross-validation).",
      "processing_time": 59.48952317237854,
      "citing_paper_id": "248218685",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "SECI Baselines (1) KMMG (Liu et al., 2020), which proposes a mention masking generalization method and use extenal knowledge databases.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'external knowledge databases' but does not specify any particular database. The title suggests the use of external knowledge but does not name a specific dataset.",
      "processing_time": 61.17884564399719,
      "citing_paper_id": "248218685",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "To alleviate the annotation cost, recent methods leverage Pre-trained Language Models (PLMs, e.g., BERT (Devlin et al., 2019)) for the ECI task and have achieved SOTA performance (Kadowaki et al., 2019; Liu et al., 2020; Zuo et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on leveraging PLMs for ECI tasks.",
      "processing_time": 59.98472881317139,
      "citing_paper_id": "248218685",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "In terms of text corpus, there are mainly two types of methods: SECI and DECI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods (SECI and DECI). No verifiable resources are identified.",
      "processing_time": 59.6068274974823,
      "citing_paper_id": "248218685",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "We compare our proposed ERGO with various state-of-the-art SECI and DECI methods.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context is focused on comparing the proposed method with other state-of-the-art methods.",
      "processing_time": 60.20744609832764,
      "citing_paper_id": "248218685",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Zuo et al. (2021b) propose a data augmentation method to further solve the data lacking problem.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation mentions a data augmentation method but does not specify a dataset. The context does not provide enough information to identify a specific, verifiable dataset.",
      "processing_time": 59.12295079231262,
      "citing_paper_id": "248218685",
      "cited_paper_id": 235313431
    },
    {
      "context_text": "(5) CauSeRL (Zuo et al., 2021a), which learns context-speciﬁc causal patterns from external causal statements for ECI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'CauSeRL' as a method for learning context-specific causal patterns, which is not a dataset but a method or model. No specific dataset is mentioned.",
      "processing_time": 60.85572862625122,
      "citing_paper_id": "248218685",
      "cited_paper_id": 235313431
    },
    {
      "context_text": "(5) CauSeRL (Zuo et al., 2021a), which learns context-speciﬁc causal patterns from external causal statements for ECI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'CauSeRL' as a method for learning context-specific causal patterns, which is not a dataset but a method or model. No specific dataset is mentioned.",
      "processing_time": 60.85572862625122,
      "citing_paper_id": "248218685",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "Zuo et al. (2021a) learn context-speciﬁc causal patterns from external causal statements and incorporate them into a target ECI model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of external causal statements. No clear, verifiable dataset names are provided.",
      "processing_time": 59.20651316642761,
      "citing_paper_id": "248218685",
      "cited_paper_id": 235313431
    },
    {
      "context_text": "Zuo et al. (2021a) learn context-speciﬁc causal patterns from external causal statements and incorporate them into a target ECI model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of external causal statements. No clear, verifiable dataset names are provided.",
      "processing_time": 59.20651316642761,
      "citing_paper_id": "248218685",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "(4) LearnDA (Zuo et al., 2021b), which uses knowledge bases to augment training data.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'knowledge bases' but does not specify a particular dataset. The cited paper title confirms the use of knowledge bases for data augmentation but does not name a specific dataset.",
      "processing_time": 59.99740767478943,
      "citing_paper_id": "248218685",
      "cited_paper_id": 235313431
    },
    {
      "context_text": "2120 weighting factor in the focal loss to balance two classes’ training, which is not considered in (Tan et al., 2022).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological detail about class balancing in training.",
      "processing_time": 57.19453430175781,
      "citing_paper_id": "248218685",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "The difference is that the focal loss in (Tan et al., 2022) is used to make long-tail (positive) classes contribute more to the overall loss, while the focal loss in our ERGO tackles the imbalance issue of DECI task by focusing more on difficult samples.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the use of focal loss in different contexts.",
      "processing_time": 57.86908268928528,
      "citing_paper_id": "248218685",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "A concurrent and relevant work is (Tan et al., 2022), which also leverages focal loss for entity relation extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (focal loss) and a research area (entity relation extraction).",
      "processing_time": 58.9294056892395,
      "citing_paper_id": "248218685",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "(He et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The title suggests a focus on semantic role labeling using natural language, which is not directly related to document-level event extraction datasets.",
      "processing_time": 60.51690864562988,
      "citing_paper_id": "269362270",
      "cited_paper_id": 1848109
    },
    {
      "context_text": "Early models were based on hand-crafted features (Li et al., 2013; Liao and Grish-man, 2010; Hong et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and models using hand-crafted features.",
      "processing_time": 58.336671113967896,
      "citing_paper_id": "269362270",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Early models were based on hand-crafted features (Li et al., 2013; Liao and Grish-man, 2010; Hong et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and models using hand-crafted features.",
      "processing_time": 58.336671113967896,
      "citing_paper_id": "269362270",
      "cited_paper_id": 2867611
    },
    {
      "context_text": "Like most NLP tasks, models to extract event-argument structures experienced a transformative shift building on word embeddings, RNNs, and CNNs (Chen et al., 2015; Nguyen et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general NLP methods and models. No verifiable resources are identified.",
      "processing_time": 58.53215408325195,
      "citing_paper_id": "269362270",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Like most NLP tasks, models to extract event-argument structures experienced a transformative shift building on word embeddings, RNNs, and CNNs (Chen et al., 2015; Nguyen et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general NLP methods and models. No verifiable resources are identified.",
      "processing_time": 58.53215408325195,
      "citing_paper_id": "269362270",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Regardless of specific events and relations, event-argument structures are beneficial for applications such as news summarization (Li et al., 2016) and coreference (Huang et al., 2019; Zhang et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general applications of event-argument structures. No dataset names are present in the text.",
      "processing_time": 58.93262982368469,
      "citing_paper_id": "269362270",
      "cited_paper_id": 6788641
    },
    {
      "context_text": "Regardless of specific events and relations, event-argument structures are beneficial for applications such as news summarization (Li et al., 2016) and coreference (Huang et al., 2019; Zhang et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general applications of event-argument structures. No dataset names are present in the text.",
      "processing_time": 58.93262982368469,
      "citing_paper_id": "269362270",
      "cited_paper_id": 174800867
    },
    {
      "context_text": "Specifically, we use a version of T5 pre-trained with SQuAD (Rajpurkar et al., 2016) to generate questions (Wang et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions SQuAD but does not indicate it is used as a dataset. It is referenced as part of the pre-training process for T5, which is a method.",
      "processing_time": 60.43243360519409,
      "citing_paper_id": "269362270",
      "cited_paper_id": 11816014
    },
    {
      "context_text": "The task has a long history in the field (Grishman and Sundheim, 1996; Doddington et al., 2004).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to historical work in the field.",
      "processing_time": 57.323501110076904,
      "citing_paper_id": "269362270",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "Inter-sentential arguments are more challenging and have received less attention (Gerber and Chai, 2010; Ruppenhofer et al., 2010).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous studies discussing inter-sentential arguments.",
      "processing_time": 57.17185735702515,
      "citing_paper_id": "269362270",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "Inter-sentential arguments are more challenging and have received less attention (Gerber and Chai, 2010; Ruppenhofer et al., 2010).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous studies discussing inter-sentential arguments.",
      "processing_time": 57.17185735702515,
      "citing_paper_id": "269362270",
      "cited_paper_id": 261226458
    },
    {
      "context_text": "There are also corpora focused on inter-sentential arguments (Gerber and Chai, 2010; Ruppenhofer et al., 2010; Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'corpora focused on inter-sentential arguments' but does not specify any named datasets. The cited papers do not provide additional specific dataset names.",
      "processing_time": 59.26588034629822,
      "citing_paper_id": "269362270",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "There are also corpora focused on inter-sentential arguments (Gerber and Chai, 2010; Ruppenhofer et al., 2010; Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'corpora focused on inter-sentential arguments' but does not specify any named datasets. The cited papers do not provide additional specific dataset names.",
      "processing_time": 59.26588034629822,
      "citing_paper_id": "269362270",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "There are also corpora focused on inter-sentential arguments (Gerber and Chai, 2010; Ruppenhofer et al., 2010; Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'corpora focused on inter-sentential arguments' but does not specify any named datasets. The cited papers do not provide additional specific dataset names.",
      "processing_time": 59.26588034629822,
      "citing_paper_id": "269362270",
      "cited_paper_id": 261226458
    },
    {
      "context_text": "We use Pytorch (Paszke et al., 2019) and HuggingFace transformers (Wolf et al., 2020).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions Pytorch and HuggingFace transformers, which are software libraries, not datasets. No datasets are explicitly mentioned or used.",
      "processing_time": 58.36619782447815,
      "citing_paper_id": "269362270",
      "cited_paper_id": 202786778
    },
    {
      "context_text": "Li et al. (2021), Ma et al. (2022) and Du et al. (2021) leverage generative language models (Raffel et al., 2020; Lewis et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative language models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.896934270858765,
      "citing_paper_id": "269362270",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "Li et al. (2021), Ma et al. (2022) and Du et al. (2021) leverage generative language models (Raffel et al., 2020; Lewis et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative language models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.896934270858765,
      "citing_paper_id": "269362270",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "Li et al. (2021), Ma et al. (2022) and Du et al. (2021) leverage generative language models (Raffel et al., 2020; Lewis et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative language models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.896934270858765,
      "citing_paper_id": "269362270",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "In order to alleviate this issue, we experiment with T5 (Raffel et al., 2020) to generate questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (T5).",
      "processing_time": 55.900461196899414,
      "citing_paper_id": "269362270",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "Some efforts assume event triggers and argument spans are part of the input and present classifiers to identify the argument type (Ebner et al., 2020; Chen et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches for identifying argument types in event extraction.",
      "processing_time": 57.23409843444824,
      "citing_paper_id": "269362270",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Some efforts assume event triggers and argument spans are part of the input and present classifiers to identify the argument type (Ebner et al., 2020; Chen et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches for identifying argument types in event extraction.",
      "processing_time": 57.23409843444824,
      "citing_paper_id": "269362270",
      "cited_paper_id": 226283556
    },
    {
      "context_text": "Figure 1 presents an example from RAMS (Ebner et al., 2020), the largest corpus annotating multi-sentence event-argument structures.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to annotate multi-sentence event-argument structures, focusing on linking arguments across sentences in the largest corpus of its kind."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS', which is identified as a corpus. It is used for annotating multi-sentence event-argument structures, making it highly relevant to document-level event extraction.",
      "processing_time": 65.51421022415161,
      "citing_paper_id": "269362270",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Roles Across Multiple Sentences (RAMS) (Ebner et al., 2020) is a dataset annotating event-argument structures.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Roles Across Multiple Sentences (RAMS)"
      ],
      "dataset_descriptions": {
        "Roles Across Multiple Sentences (RAMS)": "Used to annotate event-argument structures across multiple sentences, enhancing document-level understanding of events and their participants."
      },
      "confidence_score": 1.0,
      "reasoning": "The context directly mentions 'Roles Across Multiple Sentences (RAMS)' as a dataset, which fits the criteria for a specific, verifiable dataset.",
      "processing_time": 65.67818641662598,
      "citing_paper_id": "269362270",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "All our models use RoBERTa (Liu et al., 2019) for extractive question answering, similar to (Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (RoBERTa) and a method (extractive question answering).",
      "processing_time": 57.99145174026489,
      "citing_paper_id": "269362270",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Inspired by previous work (Du and Cardie, 2020; Liu et al., 2021), we generate questions for each ar-gument an event may have according to the AIDA-1 ontology.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the AIDA-1 ontology but does not indicate it is a dataset. It is likely a method or framework used for event extraction.",
      "processing_time": 57.84045481681824,
      "citing_paper_id": "269362270",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Framing the problem in terms of questions and answers is popular (Du and Cardie, 2020; Liu et al., 2020; Li et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach framing event extraction as question answering.",
      "processing_time": 56.81966853141785,
      "citing_paper_id": "269362270",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Framing the problem in terms of questions and answers is popular (Du and Cardie, 2020; Liu et al., 2020; Li et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach framing event extraction as question answering.",
      "processing_time": 56.81966853141785,
      "citing_paper_id": "269362270",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "Doing so enables zero-shot (Lyu et al., 2021) and few-shot (Sainz et al., 2022) predictions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches for zero-shot and few-shot predictions.",
      "processing_time": 56.97182893753052,
      "citing_paper_id": "269362270",
      "cited_paper_id": 236459781
    },
    {
      "context_text": "Doing so enables zero-shot (Lyu et al., 2021) and few-shot (Sainz et al., 2022) predictions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches for zero-shot and few-shot predictions.",
      "processing_time": 56.97182893753052,
      "citing_paper_id": "269362270",
      "cited_paper_id": 248505827
    },
    {
      "context_text": "Previous work has consistently reported worse results with inter-sentential arguments (Wei et al., 2021; Liu et al., 2021), so we designed six novel data augmentation strategies to improve results with inter-sentential arguments.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general data augmentation strategies. No clear, verifiable resource names are provided.",
      "processing_time": 57.47686529159546,
      "citing_paper_id": "269362270",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "Transfer learning has also been explored, including semantic roles (Zhang et al., 2022), abstract meaning representations (Xu et al., 2022), and frame-aware knowledge distillation (Wei et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 57.22704768180847,
      "citing_paper_id": "269362270",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "Specifically, we use PEGA-SUS (Zhang et al., 2020a) fine-tuned for paraphrasing (Zhou and Bhat, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions PEGA-SUS, which is a model, not a dataset. No datasets are explicitly mentioned or used in the given context.",
      "processing_time": 58.063629150390625,
      "citing_paper_id": "269362270",
      "cited_paper_id": 243865349
    },
    {
      "context_text": "Also, the data augmentation strategies helped the base model to achieve better or comparable results to (i.e., within a standard deviation) the top-2 best performing previous works.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses data augmentation strategies and performance comparisons.",
      "processing_time": 56.13551425933838,
      "citing_paper_id": "269362270",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Context-Aware , also proposed by Yao et al. (2019) on DocRED adapted from (Sorokin and Gurevych, 2017), uses an LSTM to encode the text, but further utilizes attention mechanism to absorb the context relational information for predicting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction, specifically to predict relations using context-aware representations and attention mechanisms in an LSTM-based model."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' as a dataset adapted from Sorokin and Gurevych (2017). It is used for document-level relation extraction, which is directly relevant to the research topic.",
      "processing_time": 66.54198122024536,
      "citing_paper_id": "221996144",
      "cited_paper_id": 6263378
    },
    {
      "context_text": "Context-Aware , also proposed by Yao et al. (2019) on DocRED adapted from (Sorokin and Gurevych, 2017), uses an LSTM to encode the text, but further utilizes attention mechanism to absorb the context relational information for predicting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction, specifically to predict relations using context-aware representations and attention mechanisms in an LSTM-based model."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' as a dataset adapted from Sorokin and Gurevych (2017). It is used for document-level relation extraction, which is directly relevant to the research topic.",
      "processing_time": 66.54198122024536,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Previous approaches focus on sentence-level relation extraction (Zeng et al., 2014; Zeng et al., 2015; Wang et al., 2016; Zhou et al., 2016; Xiao and Liu, 2016; Zhang et al., 2017; Feng et al., 2018; Zhu et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous works on sentence-level relation extraction. No verifiable resources are identified.",
      "processing_time": 57.43745803833008,
      "citing_paper_id": "221996144",
      "cited_paper_id": 9870160
    },
    {
      "context_text": "Previous approaches focus on sentence-level relation extraction (Zeng et al., 2014; Zeng et al., 2015; Wang et al., 2016; Zhou et al., 2016; Xiao and Liu, 2016; Zhang et al., 2017; Feng et al., 2018; Zhu et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous works on sentence-level relation extraction. No verifiable resources are identified.",
      "processing_time": 57.43745803833008,
      "citing_paper_id": "221996144",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Previous approaches focus on sentence-level relation extraction (Zeng et al., 2014; Zeng et al., 2015; Wang et al., 2016; Zhou et al., 2016; Xiao and Liu, 2016; Zhang et al., 2017; Feng et al., 2018; Zhu et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous works on sentence-level relation extraction. No verifiable resources are identified.",
      "processing_time": 57.43745803833008,
      "citing_paper_id": "221996144",
      "cited_paper_id": 18795469
    },
    {
      "context_text": "Previous methods (Zeng et al., 2014; Zeng et al., 2015; Xiao and Liu, 2016; Zhang et al., 2017; Zhang et al., 2018; Baldini Soares et al., 2019) focus on sentence-level RE, which predicts relations among entities in a single sentence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods focusing on sentence-level relation extraction.",
      "processing_time": 56.25525879859924,
      "citing_paper_id": "221996144",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Previous methods (Zeng et al., 2014; Zeng et al., 2015; Xiao and Liu, 2016; Zhang et al., 2017; Zhang et al., 2018; Baldini Soares et al., 2019) focus on sentence-level RE, which predicts relations among entities in a single sentence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods focusing on sentence-level relation extraction.",
      "processing_time": 56.25525879859924,
      "citing_paper_id": "221996144",
      "cited_paper_id": 18795469
    },
    {
      "context_text": "Previous methods (Zeng et al., 2014; Zeng et al., 2015; Xiao and Liu, 2016; Zhang et al., 2017; Zhang et al., 2018; Baldini Soares et al., 2019) focus on sentence-level RE, which predicts relations among entities in a single sentence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods focusing on sentence-level relation extraction.",
      "processing_time": 56.25525879859924,
      "citing_paper_id": "221996144",
      "cited_paper_id": 174801632
    },
    {
      "context_text": "Yao et al. (2019) proposed models to encode the document into a sequence of hidden state vector { h i } ni =1 using CNN (Fukushima, 1980), LSTM (Hochreiter and Schmidhuber, 1997), and BiL-STM (Schuster and Paliwal, 1997) as their encoder, and predict relations between entities with their representations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods used for encoding documents and predicting relations between entities.",
      "processing_time": 56.92058730125427,
      "citing_paper_id": "221996144",
      "cited_paper_id": 18375389
    },
    {
      "context_text": "…al. (2019) proposed models to encode the document into a sequence of hidden state vector { h i } ni =1 using CNN (Fukushima, 1980), LSTM (Hochreiter and Schmidhuber, 1997), and BiL-STM (Schuster and Paliwal, 1997) as their encoder, and predict relations between entities with their representations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of CNN, LSTM, and BiLSTM as encoders for predicting relations between entities in documents.",
      "processing_time": 58.731902837753296,
      "citing_paper_id": "221996144",
      "cited_paper_id": 18375389
    },
    {
      "context_text": "Context-Aware, also proposed by Yao et al. (2019) on DocRED adapted from (Sorokin and Gurevych, 2017), uses an LSTM to encode the text, but further utilizes attention mechanism to absorb the context relational information for predicting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to adapt a hierarchical recurrent neural network with attention for semantic relation classification, focusing on document-level relational information."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'DocRED' as a dataset used for adapting a method, which fits the criteria for a specific, verifiable dataset.",
      "processing_time": 63.11976766586304,
      "citing_paper_id": "221996144",
      "cited_paper_id": 18795469
    },
    {
      "context_text": "Several approaches (Quirk and Poon, 2017; Peng et al., 2017; Gupta et al., 2019; Song et al., 2018; Figure 3: The case study of our proposed GAIN and baseline models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various approaches and models. There are no clear identifiers for datasets within the given context.",
      "processing_time": 57.87092638015747,
      "citing_paper_id": "221996144",
      "cited_paper_id": 52960685
    },
    {
      "context_text": "Previous work in document-level RE do not consider reasoning (Gupta et al., 2019; Jia et al., 2019; Yao et al., 2019), or only use graph-based or hierarchical neural network to conduct reasoning in an implicit way (Peng et al., 2017; Sahu et al., 2019; Nan et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles suggest they are about document-level relation extraction, but no specific datasets are named in the citation context.",
      "processing_time": 59.391793727874756,
      "citing_paper_id": "221996144",
      "cited_paper_id": 52960685
    },
    {
      "context_text": "Previous work in document-level RE do not consider reasoning (Gupta et al., 2019; Jia et al., 2019; Yao et al., 2019), or only use graph-based or hierarchical neural network to conduct reasoning in an implicit way (Peng et al., 2017; Sahu et al., 2019; Nan et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles suggest they are about document-level relation extraction, but no specific datasets are named in the citation context.",
      "processing_time": 59.391793727874756,
      "citing_paper_id": "221996144",
      "cited_paper_id": 102353905
    },
    {
      "context_text": "Previous work in document-level RE do not consider reasoning (Gupta et al., 2019; Jia et al., 2019; Yao et al., 2019), or only use graph-based or hierarchical neural network to conduct reasoning in an implicit way (Peng et al., 2017; Sahu et al., 2019; Nan et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles suggest they are about document-level relation extraction, but no specific datasets are named in the citation context.",
      "processing_time": 59.391793727874756,
      "citing_paper_id": "221996144",
      "cited_paper_id": 184487889
    },
    {
      "context_text": "Previous work in document-level RE do not consider reasoning (Gupta et al., 2019; Jia et al., 2019; Yao et al., 2019), or only use graph-based or hierarchical neural network to conduct reasoning in an implicit way (Peng et al., 2017; Sahu et al., 2019; Nan et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles suggest they are about document-level relation extraction, but no specific datasets are named in the citation context.",
      "processing_time": 59.391793727874756,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Previous work in document-level RE do not consider reasoning (Gupta et al., 2019; Jia et al., 2019; Yao et al., 2019), or only use graph-based or hierarchical neural network to conduct reasoning in an implicit way (Peng et al., 2017; Sahu et al., 2019; Nan et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles suggest they are about document-level relation extraction, but no specific datasets are named in the citation context.",
      "processing_time": 59.391793727874756,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "We train GAIN using AdamW (Loshchilov and Hutter, 2019) as optimizer with weight decay 0 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an optimization method (AdamW).",
      "processing_time": 55.81447672843933,
      "citing_paper_id": "221996144",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "Jia et al., 2019) leverage dependency graph to better capture document-speciﬁc features, but they ignore ubiquitous relational inference in document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context focuses on the use of dependency graphs and relational inference in document-level feature extraction.",
      "processing_time": 58.2921838760376,
      "citing_paper_id": "221996144",
      "cited_paper_id": 102353905
    },
    {
      "context_text": "They construct a graph based on the dependency tree and predict relations by latent structure induction and GCN. Nan et al. (2020) also adapted four graph-based state-of-the-art RE models to DocRED, including GAT (Velickovic et al., 2017), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019), and AGGCN (Guo et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to adapt and evaluate graph-based relation extraction models, focusing on document-level relations using graph convolutional neural networks and latent structure induction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions adapting graph-based models to DocRED, which is a document-level relation extraction dataset. No other specific datasets are mentioned.",
      "processing_time": 64.49695944786072,
      "citing_paper_id": "221996144",
      "cited_paper_id": 184487889
    },
    {
      "context_text": "They construct a graph based on the dependency tree and predict relations by latent structure induction and GCN. Nan et al. (2020) also adapted four graph-based state-of-the-art RE models to DocRED, including GAT (Velickovic et al., 2017), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019), and AGGCN (Guo et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to adapt and evaluate graph-based relation extraction models, focusing on document-level relations using graph convolutional neural networks and latent structure induction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions adapting graph-based models to DocRED, which is a document-level relation extraction dataset. No other specific datasets are mentioned.",
      "processing_time": 64.49695944786072,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "They construct a graph based on the dependency tree and predict relations by latent structure induction and GCN. Nan et al. (2020) also adapted four graph-based state-of-the-art RE models to DocRED, including GAT (Velickovic et al., 2017), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019), and AGGCN (Guo et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to adapt and evaluate graph-based relation extraction models, focusing on document-level relations using graph convolutional neural networks and latent structure induction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions adapting graph-based models to DocRED, which is a document-level relation extraction dataset. No other specific datasets are mentioned.",
      "processing_time": 64.49695944786072,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "…the dependency tree and predict relations by latent structure induction and GCN. Nan et al. (2020) also adapted four graph-based state-of-the-art RE models to DocRED, including GAT (Velickovic et al., 2017), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019), and AGGCN (Guo et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Adapted for inter-sentence relation extraction using graph-based models, focusing on document-level graph convolutional neural networks."
      },
      "confidence_score": 0.7,
      "reasoning": "The citation mentions adapting graph-based models to DocRED, which is a document-level relation extraction dataset. However, the citation does not explicitly describe how DocRED is used in the research context.",
      "processing_time": 64.92499494552612,
      "citing_paper_id": "221996144",
      "cited_paper_id": 184487889
    },
    {
      "context_text": "Some other attempts (Verga et al., 2018; Sahu et al., 2019; Christopoulou et al., 2019) study document-level RE in a speciﬁc domain like biomedical RE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to studies in a specific domain. No clear, verifiable datasets are identified.",
      "processing_time": 57.58382821083069,
      "citing_paper_id": "221996144",
      "cited_paper_id": 184487889
    },
    {
      "context_text": "We evaluate GAIN on the public DocRED dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate GAIN on document-level relation extraction, focusing on the performance of the model across various relations in a large-scale dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' as a dataset used for evaluation, which is a specific, verifiable resource.",
      "processing_time": 62.99619817733765,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Following Yao et al. (2019), for each word w i in D , we ﬁrst concatenate its word embedding with entity type embedding and coreference embedding: where E w ( · ) , E t ( · ) and E c ( · ) denote the word embedding layer, entity type embedding layer and coreference embedding layer, respectively. t…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only embedding layers and methods. The cited paper title 'DocRED' suggests a dataset, but it is not mentioned in the citation context.",
      "processing_time": 59.257161140441895,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Yao et al. (2019) proposed models to encode the document into a sequence of hidden state vector { h i } ni =1 using CNN (Fukushima, 1980), LSTM (Hochreiter and Schmidhuber, 1997), and BiL-STM (Schuster and Paliwal, 1997) as their encoder, and predict relations between entities with their…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation does not mention any specific dataset names, only models and methods. The cited paper title 'DocRED' suggests a dataset, but it is not mentioned in the citation context.",
      "processing_time": 58.65739965438843,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "We randomly sample 100 documents from the Do-cRED dev set and manually analyze the bad cases predicted by a BiLSTM-based model proposed by Yao et al. (2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Do-cRED dev set"
      ],
      "dataset_descriptions": {
        "Do-cRED dev set": "Used to manually analyze bad cases predicted by a BiLSTM-based model, focusing on document-level relation extraction errors and their characteristics."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Do-cRED dev set', which is a specific dataset used for document-level relation extraction. The dataset is used for manual analysis of bad cases predicted by a model.",
      "processing_time": 66.35831546783447,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Figure 1 shows an example from DocRED.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to study document-level relation extraction, focusing on complex relations across multiple sentences within documents."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is mentioned as a specific dataset used in the context of document-level relation extraction.",
      "processing_time": 61.59117412567139,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Besides, the identiﬁcation of these two relation instances also 2019) proposed a large-scale human-annotated document-level RE dataset, DocRED, to push sentence-level RE forward to document-level and it contains massive relation facts.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to advance sentence-level relation extraction to document-level, containing a large number of annotated relation facts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' as a large-scale human-annotated document-level relation extraction dataset, which is directly relevant to the research topic.",
      "processing_time": 63.20451092720032,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "For more detailed statistics about DocRED, we recommend readers to refer to the original paper (Yao et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction, providing a large-scale dataset to train and evaluate models on complex relational structures within documents."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is mentioned as a specific, verifiable dataset with a clear reference to the original paper. It is used for document-level relation extraction.",
      "processing_time": 63.808144092559814,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Experimental results on the large-scale human-annotated dataset, DocRED, show GAIN out-performs previous methods, especially in inter-sentence and inferential relations scenarios.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate GAIN's performance in document-level relation extraction, particularly in inter-sentence and inferential relations scenarios."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is explicitly mentioned as a large-scale human-annotated dataset used for evaluating the performance of GAIN in document-level relation extraction.",
      "processing_time": 63.44267129898071,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "We show GAIN’s performance on the DocRED dataset in Table 2, in comparison with other base-lines.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate GAIN’s performance on document-level relation extraction, comparing it with other baselines in a large-scale dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocRED' dataset, which is a specific, verifiable resource used for document-level relation extraction.",
      "processing_time": 63.17052960395813,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Following Yao et al. (2019), we use the widely used metrics F1 and AUC in our experiment.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only metrics (F1 and AUC). The cited paper title 'DocRED' suggests a dataset, but it is not mentioned in the citation context.",
      "processing_time": 59.91866207122803,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "We evaluate our model on DocRED (Yao et al., 2019 (Yao et al., 2019). we follow the standard split of the dataset, 3 , 053 documents for training, 1 , 000 for development and 1 , 000 for test.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate the model on document-level relation extraction, following the standard split into training, development, and test sets."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is explicitly mentioned as a dataset used for evaluation, with details on the split for training, development, and testing.",
      "processing_time": 63.15681600570679,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "BERT-Two-Step base , proposed by Wang et al. (2019a) on DocRED.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate the BERT-Two-Step model for document-level relation extraction, focusing on complex relations across sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED', which is a document-level relation extraction dataset. The cited paper titles confirm that DocRED is indeed a dataset.",
      "processing_time": 64.68129181861877,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "BERT-Two-Step base , proposed by Wang et al. (2019a) on DocRED.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate the BERT-Two-Step model for document-level relation extraction, focusing on complex relations across sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED', which is a document-level relation extraction dataset. The cited paper titles confirm that DocRED is indeed a dataset.",
      "processing_time": 64.68129181861877,
      "citing_paper_id": "221996144",
      "cited_paper_id": 202539732
    },
    {
      "context_text": "BERT-Two-Step base , proposed by Wang et al. (2019a) on DocRED.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate the BERT-Two-Step model for document-level relation extraction, focusing on complex relations across sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED', which is a document-level relation extraction dataset. The cited paper titles confirm that DocRED is indeed a dataset.",
      "processing_time": 64.68129181861877,
      "citing_paper_id": "221996144",
      "cited_paper_id": 202889074
    },
    {
      "context_text": "(Yao et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate document-level relation extraction models, focusing on complex relations across multiple sentences within documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions DocRED, which is a specific, verifiable dataset used for document-level relation extraction.",
      "processing_time": 61.900779008865356,
      "citing_paper_id": "221996144",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Other pre-trained models like BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), and CorefBERT (Ye et al., 2020) are also used as encoder (Wang et al., 2019a; Ye et al., 2020) to document-level RE task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only pre-trained models and encoders. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 57.981629610061646,
      "citing_paper_id": "221996144",
      "cited_paper_id": 202539732
    },
    {
      "context_text": "Other pre-trained models like BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), and CorefBERT (Ye et al., 2020) are also used as encoder (Wang et al., 2019a; Ye et al., 2020) to document-level RE task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only pre-trained models and encoders. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 57.981629610061646,
      "citing_paper_id": "221996144",
      "cited_paper_id": 202889074
    },
    {
      "context_text": "0001 and implement GAIN under PyTorch (Paszke et al., 2017) and DGL (Wang et al., 2019b).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only software frameworks (PyTorch and DGL).",
      "processing_time": 56.71121644973755,
      "citing_paper_id": "221996144",
      "cited_paper_id": 202539732
    },
    {
      "context_text": "0001 and implement GAIN under PyTorch (Paszke et al., 2017) and DGL (Wang et al., 2019b).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only software frameworks (PyTorch and DGL).",
      "processing_time": 56.71121644973755,
      "citing_paper_id": "221996144",
      "cited_paper_id": 202889074
    },
    {
      "context_text": "HIN-GloVe/HIN-BERT base , proposed by Tang et al. (2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods. The context is about proposing HIN-GloVe and HIN-BERT, which are not datasets.",
      "processing_time": 59.28849720954895,
      "citing_paper_id": "221996144",
      "cited_paper_id": 214714027
    },
    {
      "context_text": "Tang et al. (2020) proposed a hierarchical inference network by considering information from entity-level, sentence-level, and document-level.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (hierarchical inference network).",
      "processing_time": 55.71989345550537,
      "citing_paper_id": "221996144",
      "cited_paper_id": 214714027
    },
    {
      "context_text": "When we were writing this paper, (Nan et al., 2020) make their work public as preprints, which adopt the dependency tree to capture the semantic information in the document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method using dependency trees for capturing semantic information.",
      "processing_time": 55.8925404548645,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "Among the models using BERT or BERT variants, GAIN-BERT base yields a great improvement of F1/Ign F1 on dev and test set by (Nan et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and performance metrics. The context is focused on model performance rather than dataset usage.",
      "processing_time": 57.50162482261658,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "The same as Nan et al. (2020), we report Intra-F1/Inter-F1 scores in Table 4, which only consider either intra-or inter-sentence relations respectively.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and scores.",
      "processing_time": 55.88708424568176,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "They construct a graph based on the dependency tree and predict relations by latent structure induction and GCN. Nan et al. (2020) also adapted four graph-based state-of-the-art RE models to DocRED, including GAT (Velickovic et al., 2017), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019),…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate graph-based relation extraction models, focusing on document-level relation extraction using latent structure induction and GCN methodologies."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' as a dataset used for document-level relation extraction, which aligns with the research topic. No other specific datasets are mentioned.",
      "processing_time": 64.94037199020386,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "96 LSR-BERTbase (Nan et al., 2020) 52.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (LSR-BERTbase). The context is focused on the method and its application, not on a dataset.",
      "processing_time": 59.06964373588562,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "LSR-GloVe/LSR-BERT base , proposed by Nan et al. (2020) recently.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods (LSR-GloVe/LSR-BERT).",
      "processing_time": 57.31431818008423,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": ", 2019), or only use graph-based or hierarchical neural network to conduct reasoning in an implicit way (Peng et al., 2017; Sahu et al., 2019; Nan et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches.",
      "processing_time": 55.67383933067322,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "Results with ‡ are performances of graph-based state-of-the-art RE models implemented in (Nan et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to graph-based state-of-the-art RE models. No clear identifiers for datasets are present.",
      "processing_time": 57.90142369270325,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "For example, we take into account the golden relation facts r (Nan et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method or approach. The context is too vague to identify a dataset.",
      "processing_time": 57.288469552993774,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "45 LSR-GloVe∗ (Nan et al., 2020) 48.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (LSR-GloVe) which is not a dataset.",
      "processing_time": 57.133010387420654,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "The same as Nan et al. (2020), we report Intra-F1/Inter-F1 scores in Table 4, which only consider either intra- or inter-sentence relations respectively.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and scores.",
      "processing_time": 55.844642639160156,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "Results with * are reported in (Nan et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only results from a paper. No clear identifiers for datasets are present.",
      "processing_time": 57.12570238113403,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "They put mention and entity nodes in the same graph and conduct inference implicitly by using GCN. Unlike their work, our GAIN presents mention node and entity node in different graphs to better conduct inter-sentence information aggregation and infer relations more explicitly.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological comparison between two approaches to document-level relation extraction.",
      "processing_time": 57.106122970581055,
      "citing_paper_id": "221996144",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "As there are a number of difficult issues in the joint use of annotated corpora relating to differences in coverage and tagging criteria (Wang et al., 2009), we chose to train the system on the GENETAG corpus (Tanabe et al., 2005).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENETAG corpus"
      ],
      "dataset_descriptions": {
        "GENETAG corpus": "Used to train a system for handling annotated corpora, addressing issues of coverage and tagging criteria in protein annotations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENETAG corpus, which is a specific, verifiable dataset used for training a system. The corpus is relevant to the topic of document-level event extraction.",
      "processing_time": 65.72599053382874,
      "citing_paper_id": "17984630",
      "cited_paper_id": 601125
    },
    {
      "context_text": "As there are a number of difficult issues in the joint use of annotated corpora relating to differences in coverage and tagging criteria (Wang et al., 2009), we chose to train the system on the GENETAG corpus (Tanabe et al., 2005).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENETAG corpus"
      ],
      "dataset_descriptions": {
        "GENETAG corpus": "Used to train a system for handling annotated corpora, addressing issues of coverage and tagging criteria in protein annotations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENETAG corpus, which is a specific, verifiable dataset used for training a system. The corpus is relevant to the topic of document-level event extraction.",
      "processing_time": 65.72599053382874,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "…decade of work on automatic information extraction (IE) from biomedical publications, efforts have focused in particular on the basic task of recognizing entity mentions in text, such as gene, protein or disease names (Kim et al., 2004; Smith et al., 2008; Yeh et al., 2005) and on the extraction…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks and entities in the field of biomedical information extraction.",
      "processing_time": 56.467289447784424,
      "citing_paper_id": "17984630",
      "cited_paper_id": 2787789
    },
    {
      "context_text": "…parser are subsequently processed using the Stanford conversion tool (http://nlp .stanford.edu/software/stanford-parser-2008-10-26.tgz; de Marneffe et al., 2006), resulting in the final analyses in the collapsed dependencies with propagation of conjunct dependencies version of the SD…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the Stanford conversion tool but does not refer to a specific dataset. The tool is used for processing parser outputs into a specific dependency format.",
      "processing_time": 58.431663274765015,
      "citing_paper_id": "17984630",
      "cited_paper_id": 3102322
    },
    {
      "context_text": "This parser achieved the highest published parsing accuracy on the GENIA Treebank (Tateisi et al., 2005) and is thus arguably the best parser available for text in PubMed abstracts (McClosky, 2009).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA Treebank"
      ],
      "dataset_descriptions": {
        "GENIA Treebank": "Used to evaluate parsing accuracy in biomedical text, specifically focusing on PubMed abstracts. The dataset serves as a benchmark for comparing parser performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENIA Treebank, which is a specific dataset used for evaluating parsing accuracy in biomedical text. The dataset is clearly identified and used for performance evaluation.",
      "processing_time": 66.72275996208191,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "…of recognizing entity mentions in text, such as gene, protein or disease names (Kim et al., 2004; Smith et al., 2008; Yeh et al., 2005) and on the extraction of simple relations of these entities, such as statements of protein– protein interactions (PPI; Krallinger et al., 2008; Nédellec, 2005).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks and methods. The cited papers are referenced for their contributions to entity recognition and relation extraction, not for providing datasets.",
      "processing_time": 59.72522258758545,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "Note that while the GENIA term corpus used in the JNLPBA task requires differentiation between, e.g. protein and gene entities, GENETAG only marks a single gene/RNA/protein type, contributing to the measured differences.\nconsidered in a wealth of studies, including several shared tasks which have…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA term corpus",
        "GENETAG"
      ],
      "dataset_descriptions": {
        "GENIA term corpus": "Used to differentiate between protein and gene entities in the JNLPBA task, highlighting the complexity of entity annotation in biomedical text.",
        "GENETAG": "Used to mark a single gene/RNA/protein type, contrasting with the more detailed entity differentiation in the GENIA term corpus."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions GENIA term corpus and GENETAG, both of which are specific datasets used in the JNLPBA task and genic interaction extraction challenges. These datasets are used to compare entity annotation differences.",
      "processing_time": 75.17604565620422,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "The task introduced an event representation and extraction task based on the GENIA event corpus annotation (Kim et al., 2008).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA event corpus"
      ],
      "dataset_descriptions": {
        "GENIA event corpus": "Used to introduce and evaluate an event representation and extraction task, focusing on biomedical events and their annotations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENIA event corpus, which is a specific dataset used for event extraction tasks in the biomedical domain.",
      "processing_time": 63.696635007858276,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "The Shared Task data, based on the GENIA corpus, is composed of PubMed citations relevant to biological reactions concerning transcription factors in human blood cells (Kim et al., 2008).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Shared Task data",
        "GENIA corpus"
      ],
      "dataset_descriptions": {
        "Shared Task data": "Used to evaluate systems on extracting biological reactions concerning transcription factors in human blood cells, focusing on the performance of different methods.",
        "GENIA corpus": "Serves as the basis for the Shared Task data, providing PubMed citations relevant to biological reactions in human blood cells, used for training and evaluation."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'Shared Task data' and 'GENIA corpus', both of which are specific datasets used in the research. The GENIA corpus is a well-known resource in the field of biomedical text mining.",
      "processing_time": 74.80451035499573,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "A particular point of interest is the ability of the system to perform on input data that, compared with the GENIA corpus, has far fewer events per sentence and thus deviates from the distribution on which the system was originally trained.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA corpus"
      ],
      "dataset_descriptions": {
        "GENIA corpus": "Used to evaluate the system's performance on data with fewer events per sentence, highlighting deviations from the training distribution."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENIA corpus, which is a well-known dataset in the field of biomedical text mining. The corpus is used to highlight the system's performance on data with fewer events per sentence.",
      "processing_time": 65.78769016265869,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "Several aspects of the event representation differentiate the event extraction task from the body of domain IE studies targeting, e.g. PPI and gene–disease relations, including previous domain shared tasks (Krallinger et al., 2008; Nédellec, 2005).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous domain shared tasks which are not clearly identified as datasets.",
      "processing_time": 57.343257427215576,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "In this study we apply the BANNER NER system of Leaman and Gonzalez (2008), which in its current release achieves results close to the best published on the standard GENETAG dataset (Table 2) and was reported to have the best performance in a recent study comparing publicly available taggers (Kabiljo et al., 2009).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENETAG"
      ],
      "dataset_descriptions": {
        "GENETAG": "Used to evaluate the performance of the BANNER NER system, focusing on named entity recognition in biomedical text, comparing results to other publicly available taggers."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENETAG dataset, which is a well-known benchmark for named entity recognition in biomedical text. It is used to evaluate the performance of the BANNER NER system.",
      "processing_time": 68.02150321006775,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "For example, annotating the GENIA event corpus consisting of 9 372 sentences required 1.5 years with five part-time annotators and two coordinators (Kim et al., 2008).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA event corpus"
      ],
      "dataset_descriptions": {
        "GENIA event corpus": "Used to annotate genic interaction events in biomedical text, focusing on the effort and time required for annotation with multiple part-time annotators and coordinators."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENIA event corpus, which is a specific dataset used for event annotation in the biomedical domain. The corpus is described in terms of its size and the effort required for annotation.",
      "processing_time": 68.3447277545929,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "The GENIA corpus is focused on a particular subdomain and thus not a representative sample of the entire PubMed, the focus of this study.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA corpus"
      ],
      "dataset_descriptions": {
        "GENIA corpus": "Used to highlight the limitations of a domain-specific dataset in representing the broader PubMed corpus, focusing on genic interaction extraction."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions the GENIA corpus, which is a specific dataset used in the field of genic interaction extraction. However, it is noted that the corpus is not representative of the entire PubMed, indicating a limitation in its scope.",
      "processing_time": 68.1105043888092,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "Also in the biomedical domain NER has been\ni383\n[12:17 12/5/2010 Bioinformatics-btq180.tex] Page: i384 i382–i390\nJNLPBA (best) GENIA term 72.6% Kim et al. (2004) BioCreative I (best) GENETAG 83.2% Yeh et al. (2005) BioCreative II (best) GENETAG 87.2% Smith et al. (2008)\nBANNER GENETAG 86.4% Leaman and Gonzalez (2008)\nPerformance shown for the best performing systems at various shared tasks and the BANNER system used in this work.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several datasets and benchmarks, but they are primarily used to report performance metrics rather than for direct analysis or experimentation in the current research.",
      "processing_time": 58.25162863731384,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "A recent collaborative evaluation demonstrated the potential of event extraction systems, yet there have so far been no studies of the generalization ability of the systems nor the feasibility of large-scale extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general lack of studies on system generalization and large-scale extraction.",
      "processing_time": 57.088091135025024,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "In addition to being one of the largest manually annotated resources for gene and protein NER and the reference standard used for the BioCreative evaluations, GENETAG has been specifically constructed to include a heterogeneous set of sentences from PubMed, a property expected to provide good generalization performance to large-scale tagging of documents from various subdomains.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENETAG"
      ],
      "dataset_descriptions": {
        "GENETAG": "Used as a reference standard for gene and protein NER, specifically constructed to include a heterogeneous set of sentences from PubMed, enhancing generalization performance across various subdomains."
      },
      "confidence_score": 1.0,
      "reasoning": "GENETAG is mentioned as a manually annotated resource for gene and protein NER, used in BioCreative evaluations and constructed to include diverse sentences from PubMed.",
      "processing_time": 66.99968194961548,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "Note that while the GENIA term corpus used in the JNLPBA task requires differentiation between, e.g. protein and gene entities, GENETAG only marks a single gene/RNA/protein type, contributing to the measured differences.\nconsidered in a wealth of studies, including several shared tasks which have demonstrated significant recent advances in NER (Table 2).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA term corpus",
        "GENETAG"
      ],
      "dataset_descriptions": {
        "GENIA term corpus": "Used in the JNLPBA task to differentiate between protein and gene entities, highlighting the complexity of NER tasks in biomedical text.",
        "GENETAG": "Marks a single gene/RNA/protein type, contrasting with the more detailed entity differentiation in the GENIA term corpus."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions GENIA term corpus and GENETAG, both of which are specific datasets used in NER tasks. However, the context does not provide detailed usage information for GENIA term corpus, and GENETAG is only mentioned in passing.",
      "processing_time": 76.1525309085846,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "Finally, events following the Shared Task model are given GENIA Event ontology types drawn from the community-standard Gene Ontology, giving each event well-defined semantics.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the GENIA Event ontology and the Gene Ontology, which are not datasets but ontologies. No specific datasets are mentioned.",
      "processing_time": 57.29822039604187,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "Showing wide interest in the approach, 24 teams participated in the first communitywide competitive evaluation of event extraction methods, the BioNLP’09 Shared Task on Event Extraction (http://wwwtsujii.is.s.u-tokyo.ac.jp/GENIA/SharedTask/; Kim et al., 2009).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a shared task but does not specify a dataset name. The reference is to a competition, not a reusable dataset.",
      "processing_time": 57.785579442977905,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "This compares well with BANNER performance on the GENETAG corpus with precision of 89% (for an f -score of 86%).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENETAG"
      ],
      "dataset_descriptions": {
        "GENETAG": "Used to evaluate BANNER performance on genic interaction extraction, focusing on precision and f-score metrics in the context of biomedical text processing."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENETAG corpus, which is a specific dataset used for evaluating BANNER performance. The corpus is used for genic interaction extraction, which is related to document-level event extraction.",
      "processing_time": 67.55975937843323,
      "citing_paper_id": "17984630",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "Most previous efforts have focused on pairwise PPI, with extracted pairs often represented as merged interaction networks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general trend in research. No verifiable resources are identified.",
      "processing_time": 57.27708864212036,
      "citing_paper_id": "17984630",
      "cited_paper_id": 8410430
    },
    {
      "context_text": "The Chilibot system looks for pairwise relationships based on co-occurrence and uses the presence of interaction keywords to type them (Chen and Sharp, 2004).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Chilibot) for extracting relationships from text.",
      "processing_time": 56.864431381225586,
      "citing_paper_id": "17984630",
      "cited_paper_id": 9986453
    },
    {
      "context_text": "Similarly, significant improvement has been made in PPI extraction (Airola et al., 2008; Chowdhary et al., 2009; Miwa et al., 2009) and there is an active collaboration between database curators and method developers to integrate PPI methods into curation pipelines (Chatr-aryamontri et al., 2008).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to improvements in PPI extraction and collaborations between database curators and method developers.",
      "processing_time": 57.83127570152283,
      "citing_paper_id": "17984630",
      "cited_paper_id": 9986453
    },
    {
      "context_text": "The event extraction system is based on supervised machine learning, i.e. it performs predictions for unknown cases based on a model automatically learned from manually annotated training data, here derived from that provided in the BioNLP’09 Shared Task.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'manually annotated training data' but does not specify a named dataset. The reference to 'BioNLP’09 Shared Task' suggests a specific task but not a dataset name.",
      "processing_time": 60.61281156539917,
      "citing_paper_id": "17984630",
      "cited_paper_id": 14468566
    },
    {
      "context_text": "Finally, methods for a variety of biomedical text processing tasks ranging from sentence splitting (Tomanek et al., 2007) to full parsing (McClosky, 2009) have been introduced with performance approaching or matching the performance of similar methods on general English texts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for biomedical text processing tasks. The context is about the performance of these methods compared to those on general English texts.",
      "processing_time": 58.64083695411682,
      "citing_paper_id": "17984630",
      "cited_paper_id": 15327444
    },
    {
      "context_text": "In response to the explosive growth of biomedical scientific literature, there has recently been significant interest in the development of automatic methods for analyzing domain texts (Chapman and Cohen, 2009).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general interest in developing methods for analyzing domain texts in biomedicine.",
      "processing_time": 57.56396698951721,
      "citing_paper_id": "17984630",
      "cited_paper_id": 15935530
    },
    {
      "context_text": "In response to the explosive growth of biomedical scientific literature, there has recently been significant interest in the development of automatic methods for analyzing domain texts (Chapman and Cohen, 2009).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general interest in developing methods for analyzing domain texts in biomedicine.",
      "processing_time": 57.56396698951721,
      "citing_paper_id": "17984630",
      "cited_paper_id": 16451720
    },
    {
      "context_text": "In the previous decade of work on automatic information extraction (IE) from biomedical publications, efforts have focused in particular on the basic task of recognizing entity mentions in text, such as gene, protein or disease names (Kim et al., 2004; Smith et al., 2008; Yeh et al., 2005) and on…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks and entities in the field of biomedical information extraction.",
      "processing_time": 57.10398888587952,
      "citing_paper_id": "17984630",
      "cited_paper_id": 29191365
    },
    {
      "context_text": "Results: This study considers event-based IE at PubMed scale.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general consideration of event-based information extraction at a large scale.",
      "processing_time": 57.10154104232788,
      "citing_paper_id": "17984630",
      "cited_paper_id": 29191365
    },
    {
      "context_text": "Current EE research can be roughly categorized into two groups: 1) Traditional joint methods (Li et al., 2013; Nguyen et al., 2016; Nguyen and Nguyen, 2019; Liu et al., 2018; Sha et al., 2018) that perform trigger extraction and argument extraction simultaneously.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research methods and approaches. The cited papers' titles also do not provide specific dataset names.",
      "processing_time": 58.80405855178833,
      "citing_paper_id": "235732095",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Current EE research can be roughly categorized into two groups: 1) Traditional joint methods (Li et al., 2013; Nguyen et al., 2016; Nguyen and Nguyen, 2019; Liu et al., 2018; Sha et al., 2018) that perform trigger extraction and argument extraction simultaneously.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research methods and approaches. The cited papers' titles also do not provide specific dataset names.",
      "processing_time": 58.80405855178833,
      "citing_paper_id": "235732095",
      "cited_paper_id": 19220240
    },
    {
      "context_text": "Current EE research can be roughly categorized into two groups: 1) Traditional joint methods (Li et al., 2013; Nguyen et al., 2016; Nguyen and Nguyen, 2019; Liu et al., 2018; Sha et al., 2018) that perform trigger extraction and argument extraction simultaneously.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research methods and approaches. The cited papers' titles also do not provide specific dataset names.",
      "processing_time": 58.80405855178833,
      "citing_paper_id": "235732095",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Current EE research can be roughly categorized into two groups: 1) Traditional joint methods (Li et al., 2013; Nguyen et al., 2016; Nguyen and Nguyen, 2019; Liu et al., 2018; Sha et al., 2018) that perform trigger extraction and argument extraction simultaneously.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research methods and approaches. The cited papers' titles also do not provide specific dataset names.",
      "processing_time": 58.80405855178833,
      "citing_paper_id": "235732095",
      "cited_paper_id": 54437926
    },
    {
      "context_text": "Typically, current EE studies can be roughly categorized into two groups: 1) Traditional joint methods (Nguyen et al., 2016; Liu et al., 2018; Nguyen and Nguyen, 2019), which simultaneously extract triggers and arguments by a uniﬁed decoder labeling the sentence only once.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is focused on describing categories of event extraction studies.",
      "processing_time": 57.868019104003906,
      "citing_paper_id": "235732095",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "As BERT has shown performance improvements across multiple NLP tasks, we adopt BERT (Devlin et al., 2019) as our textual encoder.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT but does not refer to it as a dataset. BERT is a model, not a dataset, and thus should not be included.",
      "processing_time": 58.994298696517944,
      "citing_paper_id": "235732095",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "BERT-softmax (Devlin et al., 2019) adopts BERT to learn textual representations and uses hidden states for classifying event triggers and arguments.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BERT-softmax) and its application to classifying event triggers and arguments.",
      "processing_time": 58.3897819519043,
      "citing_paper_id": "235732095",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "165 categorized into two groups: 1) Traditional joint methods (Nguyen et al., 2016; Liu et al., 2018; Nguyen and Nguyen, 2019), which simultaneously extract triggers and arguments by a unified decoder labeling the sentence only once.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is about categorizing joint methods for event extraction, not using specific datasets.",
      "processing_time": 59.13204598426819,
      "citing_paper_id": "235732095",
      "cited_paper_id": 54437926
    },
    {
      "context_text": "Since all subtasks are jointly learned in contrast to previous pipeline methods (Yang et al., 2019; Li et al., 2020), CasEE could capture feature-level dependencies among subtasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous work and a method (CasEE).",
      "processing_time": 57.31968140602112,
      "citing_paper_id": "235732095",
      "cited_paper_id": 174800619
    },
    {
      "context_text": "The results show that CasEE achieves 3.1% and 2.6% improvements on F1 score of TC and AC over PLMEE, indicating the importance of solving the overlapped trigger problem in EE.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance improvements of models. No dataset names are provided in the context.",
      "processing_time": 57.55715894699097,
      "citing_paper_id": "235732095",
      "cited_paper_id": 174800619
    },
    {
      "context_text": "Yang et al. (2019) attempts to tackle the overlapped argu-ment problem in the pipeline manner, but overlooks the overlapped trigger problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological issue in event detection.",
      "processing_time": 55.30319023132324,
      "citing_paper_id": "235732095",
      "cited_paper_id": 174800619
    },
    {
      "context_text": "PLMEE (Yang et al., 2019) solves overlapped argument problem by extracting role-speciﬁc arguments according to the trigger.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (PLMEE) and its application to solving an overlapped argument problem in event detection.",
      "processing_time": 58.80152487754822,
      "citing_paper_id": "235732095",
      "cited_paper_id": 174800619
    },
    {
      "context_text": "Among the researches, Yang et al. (2019) and Xu et al. (2020) solve the overlapped argument problem, but overlook the overlapped trigger problem, thus can not discern correct triggers for argument extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methodological issues in event detection.",
      "processing_time": 55.29757356643677,
      "citing_paper_id": "235732095",
      "cited_paper_id": 174800619
    },
    {
      "context_text": "We adopt source code for PLMEE with its best hyper-parameters reported in the original literature.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only source code and hyper-parameters.",
      "processing_time": 55.899396896362305,
      "citing_paper_id": "235732095",
      "cited_paper_id": 174800619
    },
    {
      "context_text": "2) Pipeline methods (Chen et al., 2015; Yang et al., 2019; Wadden et al., 2019; Li et al., 2020; Du and Cardie, 2020b; Liu et al., 2020; Chen et al., 2020) that perform trigger extraction and argument extraction in separate stages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only pipeline methods for event extraction. No dataset names are present in the text.",
      "processing_time": 57.89374899864197,
      "citing_paper_id": "235732095",
      "cited_paper_id": 174800619
    },
    {
      "context_text": "2) Pipeline methods (Chen et al., 2015; Yang et al., 2019; Wadden et al., 2019; Li et al., 2020; Du and Cardie, 2020b; Liu et al., 2020; Chen et al., 2020) that perform trigger extraction and argument extraction in separate stages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only pipeline methods for event extraction. No dataset names are present in the text.",
      "processing_time": 57.89374899864197,
      "citing_paper_id": "235732095",
      "cited_paper_id": 208547716
    },
    {
      "context_text": "2) Pipeline methods (Chen et al., 2015; Yang et al., 2019; Wadden et al., 2019; Li et al., 2020; Du and Cardie, 2020b; Liu et al., 2020; Chen et al., 2020) that perform trigger extraction and argument extraction in separate stages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only pipeline methods for event extraction. No dataset names are present in the text.",
      "processing_time": 57.89374899864197,
      "citing_paper_id": "235732095",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "2) Pipeline methods (Chen et al., 2015; Yang et al., 2019; Wadden et al., 2019; Li et al., 2020; Du and Cardie, 2020b; Liu et al., 2020; Chen et al., 2020) that perform trigger extraction and argument extraction in separate stages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only pipeline methods for event extraction. No dataset names are present in the text.",
      "processing_time": 57.89374899864197,
      "citing_paper_id": "235732095",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "2) Pipeline methods (Chen et al., 2015; Yang et al., 2019; Du and Cardie, 2020b), which sequentially extract triggers and arguments in separate stages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only pipeline methods for event extraction. No verifiable resources are identified.",
      "processing_time": 57.52975606918335,
      "citing_paper_id": "235732095",
      "cited_paper_id": 174800619
    },
    {
      "context_text": "2) Pipeline methods (Chen et al., 2015; Yang et al., 2019; Du and Cardie, 2020b), which sequentially extract triggers and arguments in separate stages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only pipeline methods for event extraction. No verifiable resources are identified.",
      "processing_time": 57.52975606918335,
      "citing_paper_id": "235732095",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Inspired by event detection without triggers (Liu et al., 2019), we adopt attention mechanism to detect event types, capturing the most relative context for each possible type.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event detection using attention mechanisms.",
      "processing_time": 56.29121232032776,
      "citing_paper_id": "235732095",
      "cited_paper_id": 174800619
    },
    {
      "context_text": "Motivated by current Machine Reading Comprehension (MRC) based EE studies (Li et al., 2020; Du and Cardie, 2020b; Liu et al., 2020; Chen et al., 2020), we train multiple MRC BERTs for overlapping event extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT models for event extraction. No verifiable resources are named.",
      "processing_time": 58.2257080078125,
      "citing_paper_id": "235732095",
      "cited_paper_id": 208547716
    },
    {
      "context_text": "Motivated by current Machine Reading Comprehension (MRC) based EE studies (Li et al., 2020; Du and Cardie, 2020b; Liu et al., 2020; Chen et al., 2020), we train multiple MRC BERTs for overlapping event extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT models for event extraction. No verifiable resources are named.",
      "processing_time": 58.2257080078125,
      "citing_paper_id": "235732095",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Motivated by current Machine Reading Comprehension (MRC) based EE studies (Li et al., 2020; Du and Cardie, 2020b; Liu et al., 2020; Chen et al., 2020), we train multiple MRC BERTs for overlapping event extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT models for event extraction. No verifiable resources are named.",
      "processing_time": 58.2257080078125,
      "citing_paper_id": "235732095",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "For evaluation, we follow the traditional evaluation metrics (Chen et al., 2015; Du and Cardie, 2020b): 1) Trigger Identification (TI): A trigger is correctly identified if the predicted trigger span matches with a golden span; 2) Trigger Classification (TC): A trigger is correctly classified if it is correctly identified and assigned to the correct type; 3) Argument Identification (AI): An argument is correctly identified if its event type is correctly recognized and the predicted argument span matches with a golden span; 4) Argument Classification (AC): an argument is correctly classified if it is",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and tasks. The context is focused on describing the evaluation criteria for event extraction tasks.",
      "processing_time": 58.78029918670654,
      "citing_paper_id": "235732095",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Wei et al. (2020) and Yu et al. (2020) extract overlapped relational triples with a novel cascade tagging strategy, which inspire us to solve overlapping event extraction in the cascade decoding paradigm.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The focus is on the methodological inspiration for solving overlapping event extraction.",
      "processing_time": 58.77767992019653,
      "citing_paper_id": "235732095",
      "cited_paper_id": 216562386
    },
    {
      "context_text": "Given a condition embedding c and a token representation h i , CLN is formulated as: where µ ∈ R and σ ∈ R are the mean and standard variance taken across the elements of h i , and γ c ∈ R d and β c ∈ R d are the conditional gain and bias, respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only a technical description of a method. There are no verifiable resources or datasets mentioned.",
      "processing_time": 58.21719169616699,
      "citing_paper_id": "235732095",
      "cited_paper_id": 235324725
    },
    {
      "context_text": "(4) with function φ achieved by CLN.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, and the context is too vague to infer the use of any particular resource.",
      "processing_time": 57.87652826309204,
      "citing_paper_id": "235732095",
      "cited_paper_id": 235324725
    },
    {
      "context_text": "Besides, empirical results also show that CLN performs better performance than other fusion functions on F1 scores in the two decoders, indicating that CLN can generate better conditional token representations for downstream subtasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses model performance.",
      "processing_time": 55.429198026657104,
      "citing_paper_id": "235732095",
      "cited_paper_id": 235324725
    },
    {
      "context_text": "conditional representations in the statistical aspect, we introduce an effective and general mechanism, conditional layer normalization (CLN) (Su, 2019; Yu et al., 2021), to achieve φ.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called 'conditional layer normalization'.",
      "processing_time": 56.6668746471405,
      "citing_paper_id": "235732095",
      "cited_paper_id": 235324725
    },
    {
      "context_text": "To fully generate conditional representations in the statistical aspect, we introduce an effective and general mechanism, conditional layer normalization (CLN) (Su, 2019; Yu et al., 2021), to achieve φ .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (conditional layer normalization).",
      "processing_time": 56.41472244262695,
      "citing_paper_id": "235732095",
      "cited_paper_id": 235324725
    },
    {
      "context_text": "CLN is mostly based on the well-known layer normalization (Ba et al., 2016), but can dynamically generate gain γ and bias β based on the condition information.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (layer normalization).",
      "processing_time": 56.166911602020264,
      "citing_paper_id": "235732095",
      "cited_paper_id": 235324725
    },
    {
      "context_text": "• TextRank (Mihalcea and Tarau, 2004): We use the graph based ranking algorithm to rank the sentence-level argument phrases for each argument type in a document extracted using (Kar et al., 2021)’s model.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (TextRank) and a model (Kar et al., 2021).",
      "processing_time": 58.92604684829712,
      "citing_paper_id": "235490449",
      "cited_paper_id": 577937
    },
    {
      "context_text": "Some of the classic works related to the task of ranking text snippets are that of PageRank (Page et al., 1998) and TextRank (Mi-halcea and Tarau, 2004).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions PageRank and TextRank, which are methods, not datasets. No datasets are explicitly mentioned or used in the context.",
      "processing_time": 58.66408586502075,
      "citing_paper_id": "235490449",
      "cited_paper_id": 1508503
    },
    {
      "context_text": "Event-Argument Extraction, the IE task most related to the task of aggregation has a number of well-documented and reliable datasets annotated at the sentence level in different languages like ACE 2005 and TAC KBP (Mitamura et al., 2015) datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005",
        "TAC KBP"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used for event-argument extraction, annotated at the sentence level in multiple languages, providing a reliable resource for information extraction tasks.",
        "TAC KBP": "Used for event-argument extraction, annotated at the sentence level in multiple languages, providing a reliable resource for information extraction tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ACE 2005 and TAC KBP, which are used for event-argument extraction, a task related to aggregation. These datasets are well-documented and reliable, and they are annotated at the sentence level in different languages.",
      "processing_time": 77.86830449104309,
      "citing_paper_id": "235490449",
      "cited_paper_id": 3137086
    },
    {
      "context_text": "Based on the ﬁndings reported in (Hu et al., 2018), to avoid bias from the previous epoch, we ﬁne-tune the pre-trained BERT-based classiﬁer on the entire annotated dataset for every run of active learning.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'annotated dataset' but does not provide a specific name or identifier. The term 'annotated dataset' is too generic and lacks the specificity required to be included as a verifiable resource.",
      "processing_time": 60.81756591796875,
      "citing_paper_id": "235490449",
      "cited_paper_id": 3534906
    },
    {
      "context_text": "After each epoch of active learning, 50 most uncertain samples are identiﬁed using the Monte Carlo estimation of error reduction (Roy and McCallum, 2001).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for identifying uncertain samples in active learning.",
      "processing_time": 57.20946478843689,
      "citing_paper_id": "235490449",
      "cited_paper_id": 14293159
    },
    {
      "context_text": "Event argument extraction is a well researched information extraction task which has seen a lot of work at the sentence-level (Wang et al., 2019; Wadden et al., 2019; Nguyen et al., 2016; Luan et al., 2019b; Veyseh et al., 2020) but a scarce amount of research has been carried out at the document level.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. No dataset names are present in the text.",
      "processing_time": 58.42322516441345,
      "citing_paper_id": "235490449",
      "cited_paper_id": 225067984
    },
    {
      "context_text": "Most of the existing event-argument extraction systems (Nguyen et al., 2016; Luan et al., 2019a; Wadden et al., 2019; Veyseh et al., 2020) pertain to a sentence-level focus, Figure 1: Example document excerpt from our corpus highlighting the different challenges of the aggregation task.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'our corpus' but does not provide a specific name or identifier. It is a generic reference and thus does not meet the criteria for inclusion.",
      "processing_time": 59.11146688461304,
      "citing_paper_id": "235490449",
      "cited_paper_id": 225067984
    },
    {
      "context_text": "Most of the existing information extraction frameworks (Wadden et al., 2019; Veyseh et al., 2020) focus on sentence-level tasks and are hardly able to capture the consolidated information from a given document.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general frameworks and their limitations. No verifiable resources are identified.",
      "processing_time": 57.87655758857727,
      "citing_paper_id": "235490449",
      "cited_paper_id": 225067984
    },
    {
      "context_text": "…argument extraction is a well researched information extraction task which has seen a lot of work at the sentence-level (Wang et al., 2019; Wad-den et al., 2019; Nguyen et al., 2016; Luan et al., 2019b; Veyseh et al., 2020) but a scarce amount of research has been carried out at the document level.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general research trends in argument extraction. No verifiable resources are identified.",
      "processing_time": 58.21893072128296,
      "citing_paper_id": "235490449",
      "cited_paper_id": 225067984
    },
    {
      "context_text": "…(iii) Seq (Gao et al., 2019): another dependency path based sequential model that is originally developed for temporal relation prediction from (Choubey and Huang, 2017) and applied to ECI; (iv) BERT : a baseline method that takes the embedding vectors from BERT and performs ECI in (Liu et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Seq' as a model and 'BERT' as a baseline method, but does not mention any specific datasets. The citation is focused on methods rather than datasets.",
      "processing_time": 60.028443574905396,
      "citing_paper_id": "235097277",
      "cited_paper_id": 2216876
    },
    {
      "context_text": "…Seq (Gao et al., 2019): another dependency path based sequential model that is originally developed for temporal relation prediction from (Choubey and Huang, 2017) and applied to ECI; (iv) BERT : a baseline method that takes the embedding vectors from BERT and performs ECI in (Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation intent is to reference other methods used for comparison in the research.",
      "processing_time": 58.60384964942932,
      "citing_paper_id": "235097277",
      "cited_paper_id": 2216876
    },
    {
      "context_text": "…Seq (Gao et al., 2019): another dependency path based sequential model that is originally developed for temporal relation prediction from (Choubey and Huang, 2017) and applied to ECI; (iv) BERT : a baseline method that takes the embedding vectors from BERT and performs ECI in (Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation intent is to reference other methods used for comparison in the research.",
      "processing_time": 58.60384964942932,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "…cues/markers (e.g., “ because ”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b),…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for event causality identification.",
      "processing_time": 57.33692932128906,
      "citing_paper_id": "235097277",
      "cited_paper_id": 3030259
    },
    {
      "context_text": "The early approach for ECI has involved feature-based methods (Do et al., 2011; Hashimoto, 2019; … Nugroho told Agence-France Presse : \"We have recorded 24 people dead and 249 people injured\", adding that more than 300 buildings have been damaged 1 due to the quake 1 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to feature-based methods and a news report about an earthquake. No verifiable resources are identified.",
      "processing_time": 58.77992105484009,
      "citing_paper_id": "235097277",
      "cited_paper_id": 3030259
    },
    {
      "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT and Know (respectively) for EventSto-ryLine (both are based on BERT).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate models for event causality recognition, specifically comparing rule-based, feature-based, and BERT-based approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The other names mentioned (RB, ML, BERT, Know) are models or methods, not datasets.",
      "processing_time": 67.6999089717865,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT and Know (respectively) for EventSto-ryLine (both are based on BERT).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate models for event causality recognition, specifically comparing rule-based, feature-based, and BERT-based approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The other names mentioned (RB, ML, BERT, Know) are models or methods, not datasets.",
      "processing_time": 67.6999089717865,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT and Know (respectively) for EventSto-ryLine (both are based on BERT).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate models for event causality recognition, specifically comparing rule-based, feature-based, and BERT-based approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The other names mentioned (RB, ML, BERT, Know) are models or methods, not datasets.",
      "processing_time": 67.6999089717865,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT and Know (respectively) for EventSto-ryLine (both are based on BERT).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate models for event causality recognition, specifically comparing rule-based, feature-based, and BERT-based approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The other names mentioned (RB, ML, BERT, Know) are models or methods, not datasets.",
      "processing_time": 67.6999089717865,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "…and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), and weakly supervised data (Hashimoto, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.77345538139343,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "…and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), and weakly supervised data (Hashimoto, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.77345538139343,
      "citing_paper_id": "235097277",
      "cited_paper_id": 9130816
    },
    {
      "context_text": "…and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), and weakly supervised data (Hashimoto, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.77345538139343,
      "citing_paper_id": "235097277",
      "cited_paper_id": 15125226
    },
    {
      "context_text": "…and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), and weakly supervised data (Hashimoto, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.77345538139343,
      "citing_paper_id": "235097277",
      "cited_paper_id": 15920102
    },
    {
      "context_text": "…and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), and weakly supervised data (Hashimoto, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.77345538139343,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "…and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), and weakly supervised data (Hashimoto, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.77345538139343,
      "citing_paper_id": "235097277",
      "cited_paper_id": 51878335
    },
    {
      "context_text": "…2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate models for extracting causal and temporal relations between events, comparing rule-based, feature-based, and BERT-based approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating models. It is a multi-word proper noun and fits the criteria for a dataset.",
      "processing_time": 66.75131678581238,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "…2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate models for extracting causal and temporal relations between events, comparing rule-based, feature-based, and BERT-based approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating models. It is a multi-word proper noun and fits the criteria for a dataset.",
      "processing_time": 66.75131678581238,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "For Causal-TimeBank (Mirza, 2014a), this dataset consists of 184 documents, 6813 events, and 318 of 7608 event mention pairs annotated with a causal relations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to extract causal relations between events, consisting of 184 documents, 6813 events, and 318 of 7608 event mention pairs annotated with causal relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly identifies 'Causal-TimeBank' as a dataset with specific characteristics and usage in the research.",
      "processing_time": 67.63654637336731,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "For Causal-TimeBank (Mirza, 2014a), this dataset consists of 184 documents, 6813 events, and 318 of 7608 event mention pairs annotated with a causal relations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to extract causal relations between events, consisting of 184 documents, 6813 events, and 318 of 7608 event mention pairs annotated with causal relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly identifies 'Causal-TimeBank' as a dataset with specific characteristics and usage in the research.",
      "processing_time": 67.63654637336731,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "Note that as in (Liu et al., 2020), we only evaluate the ECI performance for intra-sentence events in Causal-TimeBank as the number of inter-sentence event mention pairs with the causal relation is very small (i.e., only 18 pairs).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate ECI performance for intra-sentence events, focusing on causal relations within sentences due to the scarcity of inter-sentence causal event pairs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a specific dataset used for evaluating ECI performance, focusing on intra-sentence events due to the limited number of inter-sentence causal event pairs.",
      "processing_time": 68.78810214996338,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "Note that as in (Liu et al., 2020), we only evaluate the ECI performance for intra-sentence events in Causal-TimeBank as the number of inter-sentence event mention pairs with the causal relation is very small (i.e., only 18 pairs).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate ECI performance for intra-sentence events, focusing on causal relations within sentences due to the scarcity of inter-sentence causal event pairs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a specific dataset used for evaluating ECI performance, focusing on intra-sentence events due to the limited number of inter-sentence causal event pairs.",
      "processing_time": 68.78810214996338,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "Note that as in (Liu et al., 2020), we only evaluate the ECI performance for intra-sentence events in Causal-TimeBank as the number of inter-sentence event mention pairs with the causal relation is very small (i.e., only 18 pairs).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate ECI performance for intra-sentence events, focusing on causal relations within sentences due to the scarcity of inter-sentence causal event pairs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a specific dataset used for evaluating ECI performance, focusing on intra-sentence events due to the limited number of inter-sentence causal event pairs.",
      "processing_time": 68.78810214996338,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Table 2 presents the performance of these models on Causal-TimeBank.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate model performance on extracting temporal and causal relations between events, focusing on the accuracy of identifying and linking event sequences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' which is a specific dataset used for evaluating models on temporal and causal relations between events.",
      "processing_time": 65.28616166114807,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "Table 2 presents the performance of these models on Causal-TimeBank.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate model performance on extracting temporal and causal relations between events, focusing on the accuracy of identifying and linking event sequences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' which is a specific dataset used for evaluating models on temporal and causal relations between events.",
      "processing_time": 65.28616166114807,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "We tune the hyperparameters for our model on the development data of EventStoryLine and use the chosen parameters to train the models for both EventStoryLine and Causal-TimeBank.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine",
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to tune hyperparameters and train models, focusing on event extraction and storyline construction in documents.",
        "Causal-TimeBank": "Used to train models, focusing on causal and temporal relations between events in documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'EventStoryLine' and 'Causal-TimeBank' as specific datasets used for tuning hyperparameters and training models. These names match the criteria for specific, verifiable datasets.",
      "processing_time": 72.00330829620361,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "We tune the hyperparameters for our model on the development data of EventStoryLine and use the chosen parameters to train the models for both EventStoryLine and Causal-TimeBank.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine",
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to tune hyperparameters and train models, focusing on event extraction and storyline construction in documents.",
        "Causal-TimeBank": "Used to train models, focusing on causal and temporal relations between events in documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'EventStoryLine' and 'Causal-TimeBank' as specific datasets used for tuning hyperparameters and training models. These names match the criteria for specific, verifiable datasets.",
      "processing_time": 72.00330829620361,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "…: We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT and Know (respectively) for EventSto-ryLine (both are based…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers do not provide additional context to identify a dataset.",
      "processing_time": 58.316317319869995,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "…: We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT and Know (respectively) for EventSto-ryLine (both are based…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers do not provide additional context to identify a dataset.",
      "processing_time": 58.316317319869995,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate models for identifying causal relations between events, focusing on performance metrics such as precision, recall, and F1 score."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The dataset is relevant to the topic of document-level event extraction, particularly for causal relations.",
      "processing_time": 67.7748773097992,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate models for identifying causal relations between events, focusing on performance metrics such as precision, recall, and F1 score."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The dataset is relevant to the topic of document-level event extraction, particularly for causal relations.",
      "processing_time": 67.7748773097992,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to evaluate models for identifying causal relations between events, focusing on performance metrics such as precision, recall, and F1 score."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The dataset is relevant to the topic of document-level event extraction, particularly for causal relations.",
      "processing_time": 67.7748773097992,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Following prior work (Gao et al., 2019; Liu et al., 2020), we evaluate our models on two benchmark datasets for ECI, i.e., EventStoryLine and Causal-TimeBank.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine",
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to evaluate models on event causality identification, focusing on the relationship between events in narrative texts.",
        "Causal-TimeBank": "Used to assess the performance of models in identifying causal relations between events, emphasizing temporal and causal connections."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, EventStoryLine and Causal-TimeBank, which are used for evaluating models on Event Causality Identification (ECI). These datasets are clearly named and relevant to the research topic.",
      "processing_time": 73.27646350860596,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "Following prior work (Gao et al., 2019; Liu et al., 2020), we evaluate our models on two benchmark datasets for ECI, i.e., EventStoryLine and Causal-TimeBank.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine",
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to evaluate models on event causality identification, focusing on the relationship between events in narrative texts.",
        "Causal-TimeBank": "Used to assess the performance of models in identifying causal relations between events, emphasizing temporal and causal connections."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, EventStoryLine and Causal-TimeBank, which are used for evaluating models on Event Causality Identification (ECI). These datasets are clearly named and relevant to the research topic.",
      "processing_time": 73.27646350860596,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "Following prior work (Gao et al., 2019; Liu et al., 2020), we evaluate our models on two benchmark datasets for ECI, i.e., EventStoryLine and Causal-TimeBank.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine",
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to evaluate models on event causality identification, focusing on the relationship between events in narrative texts.",
        "Causal-TimeBank": "Used to assess the performance of models in identifying causal relations between events, emphasizing temporal and causal connections."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, EventStoryLine and Causal-TimeBank, which are used for evaluating models on Event Causality Identification (ECI). These datasets are clearly named and relevant to the research topic.",
      "processing_time": 73.27646350860596,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "The most important observation from the tables is that the proposed model RichGCN signiﬁcantly outperforms all the baselines for both intra-and inter-sentence events on both EventStoryLine and Causal-TimeBank ( p   0 .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine",
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to evaluate the performance of RichGCN on intra- and inter-sentence event extraction, focusing on the model's ability to outperform baselines.",
        "Causal-TimeBank": "Used to evaluate the performance of RichGCN on intra- and inter-sentence event extraction, focusing on the model's ability to outperform baselines."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, EventStoryLine and Causal-TimeBank, which are used to evaluate the performance of the proposed model RichGCN.",
      "processing_time": 75.26454210281372,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8052901
    },
    {
      "context_text": "The most important observation from the tables is that the proposed model RichGCN signiﬁcantly outperforms all the baselines for both intra-and inter-sentence events on both EventStoryLine and Causal-TimeBank ( p   0 .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine",
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to evaluate the performance of RichGCN on intra- and inter-sentence event extraction, focusing on the model's ability to outperform baselines.",
        "Causal-TimeBank": "Used to evaluate the performance of RichGCN on intra- and inter-sentence event extraction, focusing on the model's ability to outperform baselines."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, EventStoryLine and Causal-TimeBank, which are used to evaluate the performance of the proposed model RichGCN.",
      "processing_time": 75.26454210281372,
      "citing_paper_id": "235097277",
      "cited_paper_id": 44097522
    },
    {
      "context_text": "ECI ﬁnds its applications for a wide range of problems in natural language processing (NLP), including machine reading comprehension (Berant et al., 2014), future event forecasting (Hashimoto, 2019), and why-question answering (Oh et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of ECI in NLP. No dataset names are present in the text.",
      "processing_time": 59.2595796585083,
      "citing_paper_id": "235097277",
      "cited_paper_id": 8471750
    },
    {
      "context_text": "…to improve the performance, including lexical and syntactic patterns (Hashimoto, 2019; Gao et al., 2019), causality cues/markers (e.g., “ because ”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017),…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers also do not provide additional context to identify datasets.",
      "processing_time": 58.99667024612427,
      "citing_paper_id": "235097277",
      "cited_paper_id": 9130816
    },
    {
      "context_text": "…to improve the performance, including lexical and syntactic patterns (Hashimoto, 2019; Gao et al., 2019), causality cues/markers (e.g., “ because ”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017),…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers also do not provide additional context to identify datasets.",
      "processing_time": 58.99667024612427,
      "citing_paper_id": "235097277",
      "cited_paper_id": 15125226
    },
    {
      "context_text": "…improve the performance, including lexical and syntactic patterns (Hashimoto, 2019; Gao et al., 2019), causality cues/markers (e.g., “ because ”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017),…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 58.05950331687927,
      "citing_paper_id": "235097277",
      "cited_paper_id": 9130816
    },
    {
      "context_text": "…including lexical and syntactic patterns (Hashimoto, 2019; Gao et al., 2019), causality cues/markers (e.g., “ because ”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify a dataset.",
      "processing_time": 59.002360582351685,
      "citing_paper_id": "235097277",
      "cited_paper_id": 9137624
    },
    {
      "context_text": "…including lexical and syntactic patterns (Hashimoto, 2019; Gao et al., 2019), causality cues/markers (e.g., “ because ”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns (Mirza,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.158737897872925,
      "citing_paper_id": "235097277",
      "cited_paper_id": 9137624
    },
    {
      "context_text": "…Gao et al., 2019), causality cues/markers (e.g., “ because ”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 58.23138785362244,
      "citing_paper_id": "235097277",
      "cited_paper_id": 31562985
    },
    {
      "context_text": "…Gao et al., 2019), causality cues/markers (e.g., “ because ”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper title also does not indicate a specific dataset.",
      "processing_time": 58.741410970687866,
      "citing_paper_id": "235097277",
      "cited_paper_id": 31562985
    },
    {
      "context_text": "In particular, EventStoryLine (i.e., version 0.9) is introduced in (Caselli and Vossen, 2017), involving 258 documents, 22 topics, 4316 sentences, 5334 event mentions, 7805 intra-sentence and 46521 inter-sentence event mention pairs (1770 and 3855 of them are annotated with a causal relation…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to introduce a benchmark for causal and temporal relation extraction, involving 258 documents and 4316 sentences, with a focus on event mention pairs and causal relations."
      },
      "confidence_score": 1.0,
      "reasoning": "EventStoryLine is a specific dataset with a clear version number and detailed characteristics, making it a verifiable resource.",
      "processing_time": 66.72210121154785,
      "citing_paper_id": "235097277",
      "cited_paper_id": 38234032
    },
    {
      "context_text": "On the one hand, this assumption fails to cover the inter-sentence scenario where the input pairs of event mentions can appear in different sentences in the documents, e.g., in the recent EventStoryLine dataset for ECI (Caselli and Vossen, 2017).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to address inter-sentence event relations in document-level event extraction, focusing on causal and temporal relations between events across different sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'EventStoryLine dataset' which is a specific dataset used for Event Causality Identification (ECI). The dataset is referenced in the context of addressing inter-sentence event relations.",
      "processing_time": 68.94436454772949,
      "citing_paper_id": "235097277",
      "cited_paper_id": 38234032
    },
    {
      "context_text": "EventStoryLine : For this dataset, the following baselines are chosen for comparison: (i) OP : a dummy model used in (Caselli and Vossen, 2017) that assigns a causal relation to every pair of event mentions; (ii) LSTM (Gao et al., 2019): a dependency path based sequential model that is adopted from…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used as a benchmark for causal and temporal relation extraction, comparing various models including a dummy model and a dependency path-based LSTM."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'EventStoryLine' as a dataset, which is confirmed by the cited paper title. No other specific datasets are mentioned.",
      "processing_time": 66.2909688949585,
      "citing_paper_id": "235097277",
      "cited_paper_id": 38234032
    },
    {
      "context_text": "Ning et al., 2018; Gao et al., 2019) while the recent approach has examined deep learning meth-ods to deliver state-of-the-art performance for this task (Kadowaki et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.69218111038208,
      "citing_paper_id": "235097277",
      "cited_paper_id": 51878335
    },
    {
      "context_text": "Ning et al., 2018; Gao et al., 2019) while the recent approach has examined deep learning meth-ods to deliver state-of-the-art performance for this task (Kadowaki et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.69218111038208,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "Ning et al., 2018; Gao et al., 2019) while the recent approach has examined deep learning meth-ods to deliver state-of-the-art performance for this task (Kadowaki et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.69218111038208,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "…more abstract representations with GCNs. Recently, deep learning has been applied to solve ECI, leveraging advanced language models (e.g., BERT) (Kadowaki et al., 2019; Zuo et al., 2020) and common-sense knowledge resources (i.e., ConceptNet) (Liu et al., 2020) to produce state-of-the-art…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and knowledge resources. The context focuses on the application of deep learning and language models to event causality recognition.",
      "processing_time": 60.44587230682373,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "In particular, as BERT might split w i into several word-pieces, we employ the average of the hidden vectors for the word-pieces of w i in the last layer of BERT as the representation vector x i for w i .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT for word-piece representation. No verifiable resources are identified.",
      "processing_time": 59.09125089645386,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "Although we also apply related features and resource for ECI (e.g., syntax, WordNet), our model employs such resources to build interaction graphs for documents to induce more abstract representations with GCNs. Recently, deep learning has been applied to solve ECI, leveraging advanced language models (e.g., BERT) (Kadowaki et al., 2019; Zuo et al., 2020) and common-sense knowledge resources (i.e., ConceptNet) (Liu et al., 2020) to produce state-of-the-art performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and resources like WordNet, BERT, and ConceptNet. These are excluded as per the instructions.",
      "processing_time": 60.280330657958984,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "EventStoryLine : For this dataset, the following baselines are chosen for comparison: (i) OP : a dummy model used in (Caselli and Vossen, 2017) that assigns a causal relation to every pair of event mentions; (ii) LSTM (Gao et al., 2019): a dependency path based sequential model that is adopted from (Cheng and Miyao, 2017); (iii) Seq (Gao et al., 2019): another dependency path based sequential model that is originally developed for temporal relation prediction from (Choubey and Huang, 2017) and applied to ECI; (iv) BERT : a baseline method that takes the embedding vectors from BERT and performs ECI in (Liu et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only lists models and methods used as baselines for comparison.",
      "processing_time": 59.247915267944336,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "Our reimplemented model for BERT achieves higher performance on intra-sentence ECI than those in (Liu et al., 2020); (v) KnowDis (Zuo et al., 2020): a BERT-based model that leverages additional data from distant supervision; (vi) LR+ and LIP (Gao et al., 2019): document structure-based models that have the current state-of-the-art performance for inter-sentence ECI; and (vii) Know (Liu et al., 2020): a BERT-based model that exploits ConceptNet and achieves the state-of-the-art performance for intra-sentence ECI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several models and methods but does not explicitly refer to any specific datasets. The names 'KnowDis' and 'Know' are mentioned, but they are models, not datasets.",
      "processing_time": 61.41293406486511,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "Our reimplemented model for BERT achieves higher performance on intra-sentence ECI than those in (Liu et al., 2020); (v) KnowDis (Zuo et al., 2020): a BERT-based model that leverages additional data from distant supervision; (vi) LR+ and LIP (Gao et al., 2019): document structure-based models that have the current state-of-the-art performance for inter-sentence ECI; and (vii) Know (Liu et al., 2020): a BERT-based model that exploits ConceptNet and achieves the state-of-the-art performance for intra-sentence ECI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several models and methods but does not explicitly refer to any specific datasets. The names 'KnowDis' and 'Know' are mentioned, but they are models, not datasets.",
      "processing_time": 61.41293406486511,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Our reimplemented model for BERT achieves higher performance on intra-sentence ECI than those in (Liu et al., 2020); (v) KnowDis (Zuo et al., 2020): a BERT-based model that leverages additional data from distant supervision; (vi) LR+ and LIP (Gao et al., 2019): document structure-based models that have the current state-of-the-art performance for inter-sentence ECI; and (vii) Know (Liu et al., 2020): a BERT-based model that exploits ConceptNet and achieves the state-of-the-art performance for intra-sentence ECI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several models and methods but does not explicitly refer to any specific datasets. The names 'KnowDis' and 'Know' are mentioned, but they are models, not datasets.",
      "processing_time": 61.41293406486511,
      "citing_paper_id": "235097277",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "The sequential modeling of the context in BERT is thus not effective for document-level ECI, necessitating better mechanisms to encode document context (e.g., via the interaction graph of relevant objects as we do).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BERT) and a general need for better mechanisms. No verifiable resources are identified.",
      "processing_time": 59.99481987953186,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "In addition, we also see that BERT performs much worse than the document structure-based models LR+ , LIP and RichGCN .",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance. There are no verifiable resources or datasets mentioned.",
      "processing_time": 59.56192421913147,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "Note that the BERT model essentially corresponds to our RichGCN model when the interaction graphs G and G (cid:48) (thus the GCN model) are completely excluded.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BERT) which is not to be included.",
      "processing_time": 59.06633472442627,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "In particular, we employ WordNet 3.0 and the state-of-the-art BERT-based WSD model in (Blevins and Zettlemoyer, 2020) to perform the word-synset mapping in this work.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WordNet 3.0"
      ],
      "dataset_descriptions": {
        "WordNet 3.0": "Used to perform word-synset mapping, leveraging its lexical structure to enhance word sense disambiguation in the context of event causality recognition."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions WordNet 3.0, which is a lexical database, but does not mention any specific dataset used for document-level event extraction. BERT-based WSD model is a method, not a dataset.",
      "processing_time": 71.91817808151245,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "In particular, we employ WordNet 3.0 and the state-of-the-art BERT-based WSD model in (Blevins and Zettlemoyer, 2020) to perform the word-synset mapping in this work.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WordNet 3.0"
      ],
      "dataset_descriptions": {
        "WordNet 3.0": "Used to perform word-synset mapping, leveraging its lexical structure to enhance word sense disambiguation in the context of event causality recognition."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions WordNet 3.0, which is a lexical database, but does not mention any specific dataset used for document-level event extraction. BERT-based WSD model is a method, not a dataset.",
      "processing_time": 71.91817808151245,
      "citing_paper_id": "235097277",
      "cited_paper_id": 218517044
    },
    {
      "context_text": "Finally, as mentioned earlier, we use the BERT base model (of 768 dimensions) for the pre-trained word embeddings (updated during the training) in this work.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT but does not refer to it as a dataset. It is used as a pre-trained model for word embeddings.",
      "processing_time": 59.23753046989441,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "In the ﬁrst step, we transform each word w i ∈ D into a representation vector x i using the contex-tualized embeddings BERT (Devlin et al., 2019) (i.e., the BERT base version).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT embeddings, which is a method/model, not a dataset.",
      "processing_time": 59.64145064353943,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "To handle long documents with BERT, we divide D into segments of 512 word-pieces to be encoded separately.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes a method for handling long documents with BERT.",
      "processing_time": 59.491562843322754,
      "citing_paper_id": "235097277",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "Our reimplemented model for BERT achieves higher performance on intra-sentence ECI than those in (Liu et al., 2020); (v) KnowDis (Zuo et al., 2020): a BERT-based model that leverages additional data from distant supervision; (vi) LR+ and LIP (Gao et al., 2019): document structure-based models that…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "KnowDis"
      ],
      "dataset_descriptions": {
        "KnowDis": "Used for knowledge-enhanced data augmentation in event causality detection, leveraging distant supervision to improve model performance."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'KnowDis' which is a dataset used for knowledge-enhanced data augmentation in event causality detection. No other specific datasets are mentioned.",
      "processing_time": 67.27641129493713,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Our reimplemented model for BERT achieves higher performance on intra-sentence ECI than those in (Liu et al., 2020); (v) KnowDis (Zuo et al., 2020): a BERT-based model that leverages additional data from distant supervision; (vi) LR+ and LIP (Gao et al., 2019): document structure-based models that…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "KnowDis"
      ],
      "dataset_descriptions": {
        "KnowDis": "Used for knowledge-enhanced data augmentation in event causality detection, leveraging distant supervision to improve model performance."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'KnowDis' which is a dataset used for knowledge-enhanced data augmentation in event causality detection. No other specific datasets are mentioned.",
      "processing_time": 67.27641129493713,
      "citing_paper_id": "235097277",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "…(vi) LR+ and LIP (Gao et al., 2019): document structure-based models that have the current state-of-the-art performance for inter-sentence ECI; and (vii) Know (Liu et al., 2020): a BERT-based model that exploits ConceptNet and achieves the state-of-the-art performance for intra-sentence ECI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models and their performance but does not reference any specific datasets. The context is focused on model performance and capabilities rather than dataset usage.",
      "processing_time": 60.49170637130737,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Finally, the signiﬁcant better performance of RichGCN over Know for intra-sentence ECI in different datasets conﬁrms our intuition in the introduction that capturing context beyond sentences (i.e., document context as in RichGCN ) is helpful for causal prediction of intra-sentence event pairs.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets by name. It discusses the performance of models (RichGCN and Know) across different datasets but does not specify which datasets were used.",
      "processing_time": 61.85945105552673,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Knowledge-based Semantic : Instead of using contextual information, this method leverages the external knowledge of the nodes from knowledge bases to capture their semantic for node similarity computation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method that leverages external knowledge from knowledge bases.",
      "processing_time": 58.827223777770996,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "The documents in the last two topics are used for the development data while the remaining 20 documents are employed for a 5-fold cross-validation evaluation, using the same data split in (Gao et al., 2019; Liu et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'development data' and '5-fold cross-validation evaluation' but does not specify a named dataset. The reference to 'the same data split' suggests reusing a specific split, but no dataset name is provided.",
      "processing_time": 64.07946634292603,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Know has the current state-of-the-art performance for this dataset in our 10-fold cross-validation setting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not provide a specific dataset name, only referring to 'this dataset' without further details. The cited paper title does not help in identifying a specific dataset.",
      "processing_time": 61.904747009277344,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Following (Liu et al., 2020), we do a 10-fold cross-validation evaluation using the same data split for this dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'this dataset' but does not provide a specific name. The cited paper title does not help disambiguate a specific dataset.",
      "processing_time": 61.09281921386719,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Note that (Liu et al., 2020) only reports the performance on intra-sentence events of EventStoryLine for this model.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the performance on intra-sentence events of EventStoryLine. No clear, verifiable dataset names are provided.",
      "processing_time": 61.42841053009033,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "It is clear from the table that RichGCN is signiﬁ-cantly better than the baselines LIP and Know over different cross-topic settings, thereby further testifying to the generalization advantages of capturing document-level context via GCN for intra-sentence ECI in the proposed model.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model comparisons. The context focuses on the performance of RichGCN compared to baselines LIP and Know.",
      "processing_time": 61.424585580825806,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Table 4 present the intra-sentence ECI performance (i.e., F1 scores) of LIP , Know (Liu et al., 2020) is the topic similarity score.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and scores. There are no clear identifiers for datasets in the given context.",
      "processing_time": 60.24331712722778,
      "citing_paper_id": "235097277",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "…abstract representations with GCNs. Recently, deep learning has been applied to solve ECI, leveraging advanced language models (e.g., BERT) (Kadowaki et al., 2019; Zuo et al., 2020) and common-sense knowledge resources (i.e., ConceptNet) (Liu et al., 2020) to produce state-of-the-art performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and resources like BERT and ConceptNet, which are excluded according to the rules.",
      "processing_time": 60.89308261871338,
      "citing_paper_id": "235097277",
      "cited_paper_id": 224814117
    },
    {
      "context_text": "vant objects for documents are explicitly generated and consumed by Graph Convolutional Networks (GCN) (Kipf and Welling, 2017; Nguyen and Grishman, 2018) to induce representation vectors for prediction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets in the text.",
      "processing_time": 59.90797257423401,
      "citing_paper_id": "235097277",
      "cited_paper_id": null
    },
    {
      "context_text": "Our work is also related to prior research on joint embedding of words and knowledge graphs (Xu et al., 2014; Wang et al., 2014; Tian et al., 2016; Yang et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and research works.",
      "processing_time": 59.015690088272095,
      "citing_paper_id": "10638526",
      "cited_paper_id": 2177534
    },
    {
      "context_text": "Our work is also related to prior research on joint embedding of words and knowledge graphs (Xu et al., 2014; Wang et al., 2014; Tian et al., 2016; Yang et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and research works.",
      "processing_time": 59.015690088272095,
      "citing_paper_id": "10638526",
      "cited_paper_id": 15262897
    },
    {
      "context_text": "Socher et al. (2013) has shown that previous work (Bordes et al., 2011; Jenatton et al., 2012; Bordes et al., 2012; Sutskever et al., 2009; Collobert and Weston, 2008) are special cases of their model, which is based on a neural tensor network.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the relationship between different models and the neural tensor network.",
      "processing_time": 60.86969184875488,
      "citing_paper_id": "10638526",
      "cited_paper_id": 5555779
    },
    {
      "context_text": "Socher et al. (2013) has shown that previous work (Bordes et al., 2011; Jenatton et al., 2012; Bordes et al., 2012; Sutskever et al., 2009; Collobert and Weston, 2008) are special cases of their model, which is based on a neural tensor network.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the relationship between different models and the neural tensor network.",
      "processing_time": 60.86969184875488,
      "citing_paper_id": "10638526",
      "cited_paper_id": 8429835
    },
    {
      "context_text": "Socher et al. (2013) has shown that previous work (Bordes et al., 2011; Jenatton et al., 2012; Bordes et al., 2012; Sutskever et al., 2009; Collobert and Weston, 2008) are special cases of their model, which is based on a neural tensor network.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the relationship between different models and the neural tensor network.",
      "processing_time": 60.86969184875488,
      "citing_paper_id": "10638526",
      "cited_paper_id": 10854724
    },
    {
      "context_text": "Socher et al. (2013) has shown that previous work (Bordes et al., 2011; Jenatton et al., 2012; Bordes et al., 2012; Sutskever et al., 2009; Collobert and Weston, 2008) are special cases of their model, which is based on a neural tensor network.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the relationship between different models and the neural tensor network.",
      "processing_time": 60.86969184875488,
      "citing_paper_id": "10638526",
      "cited_paper_id": 14474967
    },
    {
      "context_text": "We use publicly available ﬁnancial news from Reuters and Bloomberg over the period from October 2006 to November 2013, released by Ding et al. (2014).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "financial news from Reuters and Bloomberg"
      ],
      "dataset_descriptions": {
        "financial news from Reuters and Bloomberg": "Used to predict stock price movement, focusing on structured events in financial news articles from October 2006 to November 2013."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'financial news from Reuters and Bloomberg' which is a specific, domain-qualified data source. It is used for predicting stock price movement.",
      "processing_time": 69.73258638381958,
      "citing_paper_id": "10638526",
      "cited_paper_id": 5825949
    },
    {
      "context_text": "In most previous work, the accuracies of individual stock prediction are higher when only company-related news are used as inputs, compared with when sector-related news are used (Ding et al., 2014).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between company-related news and sector-related news. No clear, verifiable dataset names are provided.",
      "processing_time": 60.497408628463745,
      "citing_paper_id": "10638526",
      "cited_paper_id": 5825949
    },
    {
      "context_text": "Ding et al. (2014) show that structured events from open information extraction (Yates et al., 2007; Fader et al., 2011) can achieve better performance compared to conventional features, as they can capture structured relations.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and findings. The context focuses on the performance of structured events from open information extraction compared to conventional features.",
      "processing_time": 61.41508746147156,
      "citing_paper_id": "10638526",
      "cited_paper_id": 5825949
    },
    {
      "context_text": "Ding et al. (2014) show that structured events from open information extraction (Yates et al., 2007; Fader et al., 2011) can achieve better performance compared to conventional features, as they can capture structured relations.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and findings. The context focuses on the performance of structured events from open information extraction compared to conventional features.",
      "processing_time": 61.41508746147156,
      "citing_paper_id": "10638526",
      "cited_paper_id": 10318045
    },
    {
      "context_text": "…al. (2012) propose using bags-of-words to represent news documents, and constructing the prediction model by using Support Vector Machines (SVMs); Ding et al. (2014) report a system that uses structured event tuples E = ( A, P, O ) to represent news documents, and investigate the complex hidden…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It focuses on methods and approaches for representing news documents and predicting stock price movements.",
      "processing_time": 60.6723906993866,
      "citing_paper_id": "10638526",
      "cited_paper_id": 5825949
    },
    {
      "context_text": "…et al. (2012) propose using bags-of-words to represent news documents, and constructing the prediction model by using Support Vector Machines (SVMs); Ding et al. (2014) report a system that uses structured event tuples E = ( A, P, O ) to represent news documents, and investigate the complex hidden…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the representation of news documents and prediction models.",
      "processing_time": 60.45471692085266,
      "citing_paper_id": "10638526",
      "cited_paper_id": 5825949
    },
    {
      "context_text": "…event embeddings on stock prediction by comparing KGEB with bag-of-words representations (Luss and d’Aspremont, 2012), structured event representations (Ding et al., 2014), baseline event embedding representations (Ding et al., 2015) and word embedding representations on the test dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It refers to various representation methods and a 'test dataset' but does not provide a name or identifier.",
      "processing_time": 61.80280375480652,
      "citing_paper_id": "10638526",
      "cited_paper_id": 5825949
    },
    {
      "context_text": "We ﬁnd that: (1) Comparison between the word-based models and event-based models (e.g. Luss and d’Aspremont (2012) vs Ding et al. (2014), WB-CNN vs Ding et al. (2015), WB-CNN vs KGEB-CNN) shows that events are more capable for representing news documents for stock prediction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only comparisons between models. The context focuses on model performance rather than dataset usage.",
      "processing_time": 60.01226615905762,
      "citing_paper_id": "10638526",
      "cited_paper_id": 5825949
    },
    {
      "context_text": "Here the deﬁnition of events follows the open information extraction literature (Fader et al., 2011; Yates et al., 2007), which has seen applications in semantic parsing (Berant et al., 2013), information retrieval (Sun et al., 2015) and text mining (Ding et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to literature on open information extraction and its applications.",
      "processing_time": 59.13170647621155,
      "citing_paper_id": "10638526",
      "cited_paper_id": 5825949
    },
    {
      "context_text": "Here the deﬁnition of events follows the open information extraction literature (Fader et al., 2011; Yates et al., 2007), which has seen applications in semantic parsing (Berant et al., 2013), information retrieval (Sun et al., 2015) and text mining (Ding et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to literature on open information extraction and its applications.",
      "processing_time": 59.13170647621155,
      "citing_paper_id": "10638526",
      "cited_paper_id": 6401679
    },
    {
      "context_text": "Here the deﬁnition of events follows the open information extraction literature (Fader et al., 2011; Yates et al., 2007), which has seen applications in semantic parsing (Berant et al., 2013), information retrieval (Sun et al., 2015) and text mining (Ding et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to literature on open information extraction and its applications.",
      "processing_time": 59.13170647621155,
      "citing_paper_id": "10638526",
      "cited_paper_id": 10318045
    },
    {
      "context_text": "We compare our knowledge-driven event embedding (denoted as KGEB) with the baseline method proposed by Ding et al. (2015) (denoted as EB), and discrete event vectors with semantic lexicons based generalization method proposed by Ding et al. (2014) (denoted as DE).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on comparing different approaches to event embedding and does not reference any particular dataset.",
      "processing_time": 61.416248083114624,
      "citing_paper_id": "10638526",
      "cited_paper_id": 5825949
    },
    {
      "context_text": "A neural tensor network is used to learn baseline event embeddings, and we deﬁne a corresponding loss function to incorporate knowledge graph information, by following recent work on multi-relation models (Socher et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (neural tensor network) and a type of model (multi-relation models).",
      "processing_time": 61.27318596839905,
      "citing_paper_id": "10638526",
      "cited_paper_id": 8429835
    },
    {
      "context_text": "Most existing methods learn knowledge embeddings by minimizing a global loss function over all the entities and relations in (Socher et al., 2013).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for learning knowledge embeddings.",
      "processing_time": 58.67854356765747,
      "citing_paper_id": "10638526",
      "cited_paper_id": 8429835
    },
    {
      "context_text": "We follow Socher et al. (2013) and use tensors to represent relations in knowledge graph embeddings.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using tensors for knowledge graph embeddings, which is a method, not a dataset. No specific dataset is mentioned.",
      "processing_time": 59.53097939491272,
      "citing_paper_id": "10638526",
      "cited_paper_id": 8429835
    },
    {
      "context_text": "Inspired by recent studies on learning distributed representations of multi-relational data from knowledge graph (Socher et al., 2013), we use a neural tensor network framework for knowledge graph embedding.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (neural tensor network framework) and a general reference to knowledge graphs.",
      "processing_time": 60.479933738708496,
      "citing_paper_id": "10638526",
      "cited_paper_id": 8429835
    },
    {
      "context_text": "The structured events are extracted from news text using Open IE (Fader et al., 2011) and dependency parsing (Zhang and Clark, 2011), by strictly following the method of Ding et al. (2015).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and tools used for extracting structured events from news text.",
      "processing_time": 59.38587474822998,
      "citing_paper_id": "10638526",
      "cited_paper_id": 10318045
    },
    {
      "context_text": "We also experiment with randomly initialized word vectors as the input of NTN, which are commonly used in previous work on structured embeddings from knowledge graphs (Bordes et al., 2011; Jenatton et al., 2012).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is used to reference previous work on structured embeddings from knowledge graphs.",
      "processing_time": 61.0518753528595,
      "citing_paper_id": "10638526",
      "cited_paper_id": 10854724
    },
    {
      "context_text": "Knowledge Graph Embedding Recently, several methods have been explored to represent and encode knowledge graph (Bordes et al., 2013; Bordes et al., 2014; Chang et al., 2013; Ji et al., 2015; Lin et al., 2015) in distributed vectors.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches for knowledge graph embedding.",
      "processing_time": 58.54011130332947,
      "citing_paper_id": "10638526",
      "cited_paper_id": 11202498
    },
    {
      "context_text": "Knowledge Graph Embedding Recently, several methods have been explored to represent and encode knowledge graph (Bordes et al., 2013; Bordes et al., 2014; Chang et al., 2013; Ji et al., 2015; Lin et al., 2015) in distributed vectors.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches for knowledge graph embedding.",
      "processing_time": 58.54011130332947,
      "citing_paper_id": "10638526",
      "cited_paper_id": 14941970
    },
    {
      "context_text": "Stock Market Prediction There has been a line of work predicting stock markets using text information from daily news (Lavrenko et al., 2000; Schumaker and Chen, 2009; Xie et al., 2013; Peng and Jiang, 2015; Li et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a line of work predicting stock markets using text information from daily news. No verifiable resources are named.",
      "processing_time": 61.27752757072449,
      "citing_paper_id": "10638526",
      "cited_paper_id": 11783987
    },
    {
      "context_text": "Stock Market Prediction There has been a line of work predicting stock markets using text information from daily news (Lavrenko et al., 2000; Schumaker and Chen, 2009; Xie et al., 2013; Peng and Jiang, 2015; Li et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a line of work predicting stock markets using text information from daily news. No verifiable resources are named.",
      "processing_time": 61.27752757072449,
      "citing_paper_id": "10638526",
      "cited_paper_id": 18057184
    },
    {
      "context_text": "We propose to incorporate the external information from knowledge graphs, such as Freebase (Bol-lacker et al., 2008) and YAGO (Suchanek et al., 2007), into the learning process to generate better event representations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Freebase",
        "YAGO"
      ],
      "dataset_descriptions": {
        "Freebase": "Used to incorporate external information into the learning process for generating better event representations, enhancing the model's understanding of structured human knowledge.",
        "YAGO": "Used to incorporate external information into the learning process for generating better event representations, providing additional context from a large-scale knowledge graph."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions knowledge graphs Freebase and YAGO but does not indicate their use as datasets for document-level event extraction. They are referenced as sources of external information to enhance event representations.",
      "processing_time": 74.91063523292542,
      "citing_paper_id": "10638526",
      "cited_paper_id": 207167677
    },
    {
      "context_text": "We propose to incorporate the external information from knowledge graphs, such as Freebase (Bollacker et al., 2008) and YAGO (Suchanek et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Freebase",
        "YAGO"
      ],
      "dataset_descriptions": {
        "Freebase": "Used as a source of external information to enhance document-level event extraction, providing structured human knowledge.",
        "YAGO": "Used as a source of external information to enhance document-level event extraction, providing structured knowledge from Wikipedia and WordNet."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions Freebase and YAGO as knowledge graphs but does not indicate their use as datasets for document-level event extraction. They are mentioned as sources of external information.",
      "processing_time": 72.99940967559814,
      "citing_paper_id": "10638526",
      "cited_paper_id": 207167677
    },
    {
      "context_text": "Collective methods: 1) Li’s Structure : the method that collectively detects events by us-ing human-designed features (Li et al., 2013).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event detection using human-designed features.",
      "processing_time": 58.809847593307495,
      "citing_paper_id": "53081291",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Some works (Li et al., 2013; Yang and Mitchell, 2016; Liu et al., 2016b) rely on a set of elaborately designed features and complicated natural language processing (NLP) tools to capture event interdependency.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of features and NLP tools. No clear identifiers for datasets are present.",
      "processing_time": 60.37336277961731,
      "citing_paper_id": "53081291",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "However, nearly all of these methods are feature-based methods (McClosky et al., 2011; Li et al., 2013; Yang and Mitchell, 2016; Liu et al., 2016b), which rely on elaborately designed features and suffer error propagation from existing NLP tools.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and their limitations. There are no clear identifiers for datasets in the text.",
      "processing_time": 60.19564366340637,
      "citing_paper_id": "53081291",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "For comparison, as the same as previous works (Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2017), we used the same test set with 40 documents and the same development set with 30 documents and the rest 529 documents are used for training.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions specific document counts for training, development, and test sets, but does not name a specific dataset. The usage is clear, but the dataset name is missing.",
      "processing_time": 61.84645938873291,
      "citing_paper_id": "53081291",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "For comparison, as the same as previous works (Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2017), we used the same test set with 40 documents and the same development set with 30 documents and the rest 529 documents are used for training.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions specific document counts for training, development, and test sets, but does not name a specific dataset. The usage is clear, but the dataset name is missing.",
      "processing_time": 61.84645938873291,
      "citing_paper_id": "53081291",
      "cited_paper_id": 11187670
    },
    {
      "context_text": "For comparison, as the same as previous works (Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2017), we used the same test set with 40 documents and the same development set with 30 documents and the rest 529 documents are used for training.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions specific document counts for training, development, and test sets, but does not name a specific dataset. The usage is clear, but the dataset name is missing.",
      "processing_time": 61.84645938873291,
      "citing_paper_id": "53081291",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "We select the following state-of-the-art methods for comparison, which can be classiﬁed as two types: separate and collective methods: Separate methods: 1) Li’s MaxEnt : the method that detects events in one sentence separately by using human-designed features (Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event detection. The context focuses on comparing different methods for event extraction.",
      "processing_time": 60.16557455062866,
      "citing_paper_id": "53081291",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Following previous works (Li et al., 2013; Chen et al., 2015; Liu et al., 2017; Nguyen and Grishman, 2016), we categorize triggers into these 33 subtypes.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous works for categorizing event triggers.",
      "processing_time": 58.598273515701294,
      "citing_paper_id": "53081291",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Following previous works (Li et al., 2013; Chen et al., 2015; Liu et al., 2017; Nguyen and Grishman, 2016), we categorize triggers into these 33 subtypes.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous works for categorizing event triggers.",
      "processing_time": 58.598273515701294,
      "citing_paper_id": "53081291",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "3) Hong’s CrossEntity : the method that uses cross entity information (Hong et al., 2011).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method 'CrossEntity' but does not refer to any specific dataset. The context is focused on describing a method rather than a dataset.",
      "processing_time": 60.470587968826294,
      "citing_paper_id": "53081291",
      "cited_paper_id": 2867611
    },
    {
      "context_text": "To this end, most methods (Ahn, 2006; Hong et al., 2011; Chen et al., 2015; Nguyen and Grish-man, 2016; Liu et al., 2017) model ED as a multi-classiﬁcation task and predict every word in the sentence separately to determine whether it triggers a speciﬁc type of event by using sentence-level…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 60.141438007354736,
      "citing_paper_id": "53081291",
      "cited_paper_id": 2867611
    },
    {
      "context_text": "To this end, most methods (Ahn, 2006; Hong et al., 2011; Chen et al., 2015; Nguyen and Grish-man, 2016; Liu et al., 2017) model ED as a multi-classiﬁcation task and predict every word in the sentence separately to determine whether it triggers a speciﬁc type of event by using sentence-level…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 60.141438007354736,
      "citing_paper_id": "53081291",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "…exploit a diverse set of strategies to convert classiﬁcation clues into feature vectors (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2012), and neural-based methods which use neural networks to automatically capture clues from plain texts (Chen…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various methods and strategies for event extraction. No clear, verifiable datasets are identified.",
      "processing_time": 60.31234884262085,
      "citing_paper_id": "53081291",
      "cited_paper_id": 2867611
    },
    {
      "context_text": "Speciﬁcally, we use the Skip-gram model (Mikolov et al., 2013) to learn word embeddings on the NYT corpus.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "NYT corpus"
      ],
      "dataset_descriptions": {
        "NYT corpus": "Used to learn word embeddings using the Skip-gram model, focusing on the representation of words in vector space."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'NYT corpus' which is a specific, identifiable dataset. The Skip-gram model is a method, not a dataset, so it is excluded.",
      "processing_time": 67.93337512016296,
      "citing_paper_id": "53081291",
      "cited_paper_id": 5959482
    },
    {
      "context_text": "Specifically, we use the Skip-gram model (Mikolov et al., 2013) to learn word embeddings on the NYT corpus.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "NYT corpus"
      ],
      "dataset_descriptions": {
        "NYT corpus": "Used to train word embeddings with the Skip-gram model, focusing on learning vector representations of words for natural language processing tasks."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions the 'NYT corpus' which is a specific, identifiable dataset. However, it is used to train word embeddings, not directly for document-level event extraction.",
      "processing_time": 68.49733519554138,
      "citing_paper_id": "53081291",
      "cited_paper_id": 5959482
    },
    {
      "context_text": "There have been some feature-based studies (Ji and Grishman, 2008; Liao and Grishman, 2010; Huang and Riloff, 2012) that construct rules to capture document-level information for improving sentence-level ED.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to studies that use feature-based approaches for event extraction.",
      "processing_time": 59.12565565109253,
      "citing_paper_id": "53081291",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "There have been some feature-based studies (Ji and Grishman, 2008; Liao and Grishman, 2010; Huang and Riloff, 2012) that construct rules to capture document-level information for improving sentence-level ED.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to studies that use feature-based approaches for event extraction.",
      "processing_time": 59.12565565109253,
      "citing_paper_id": "53081291",
      "cited_paper_id": 11187670
    },
    {
      "context_text": "These methods include feature-based methods which exploit a diverse set of strategies to convert classification clues into feature vectors (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2012), and neural-based methods which use neural networks to automatically capture clues from plain texts (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets within the text.",
      "processing_time": 59.74147081375122,
      "citing_paper_id": "53081291",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "…set of strategies to convert classiﬁcation clues into feature vectors (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2012), and neural-based methods which use neural networks to automatically capture clues from plain texts (Chen et al., 2015;…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets within the text.",
      "processing_time": 59.73862433433533,
      "citing_paper_id": "53081291",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "…methods which exploit a diverse set of strategies to convert classiﬁcation clues into feature vectors (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2012), and neural-based methods which use neural networks to automatically capture…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets within the text.",
      "processing_time": 59.590529918670654,
      "citing_paper_id": "53081291",
      "cited_paper_id": 11187670
    },
    {
      "context_text": "5) Chen’s DMCNN+ : the DMCNN method argumented with automatically labeled data (Chen et al., 2017).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'automatically labeled data' which is domain-qualified but does not provide a specific, identifiable dataset name. The cited paper title confirms the generation of labeled data but does not specify a dataset.",
      "processing_time": 62.829734802246094,
      "citing_paper_id": "53081291",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "…2010; Hong et al., 2011; Huang and Riloff, 2012), and neural-based methods which use neural networks to automatically capture clues from plain texts (Chen et al., 2015; Nguyen and Grishman, 2015; Feng et al., 2016; Nguyen and Grishman, 2016; Chen et al., 2017; Duan et al., 2017; Liu et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 59.54119920730591,
      "citing_paper_id": "53081291",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "…2010; Hong et al., 2011; Huang and Riloff, 2012), and neural-based methods which use neural networks to automatically capture clues from plain texts (Chen et al., 2015; Nguyen and Grishman, 2015; Feng et al., 2016; Nguyen and Grishman, 2016; Chen et al., 2017; Duan et al., 2017; Liu et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 59.54119920730591,
      "citing_paper_id": "53081291",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "In this paper, we use the LSTM unit as described in (Zaremba and Sutskever, 2014).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions an LSTM unit but does not refer to any specific dataset. The context is about using a method, not a dataset.",
      "processing_time": 59.32828116416931,
      "citing_paper_id": "53081291",
      "cited_paper_id": 12730022
    },
    {
      "context_text": "7) Liu’s ANN-Aug : the method that use the annotated argument information via a supervised attention to improve ED (Liu et al., 2017).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a method (ANN-Aug) and does not refer to any specific dataset. The citation is about a method that uses annotated argument information to improve event detection.",
      "processing_time": 60.52490043640137,
      "citing_paper_id": "53081291",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "Recent research considers an event as actions with similar properties, such as disaster event [69], medicine event [22], economic event [75], personal life event (e.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general categories of events. No clear, verifiable datasets are identified.",
      "processing_time": 58.0770628452301,
      "citing_paper_id": "248325339",
      "cited_paper_id": 130216
    },
    {
      "context_text": "At present, numerous efforts have been achieved and contribute to various issues, involving extraction granularity [45, 62, 66, 75], event type [30, 40, 46, 60], the scarcity of data [9, 20], domain event [22, 25, 27, 51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues and aspects of event extraction research. No clear, verifiable resources are identified.",
      "processing_time": 59.62926006317139,
      "citing_paper_id": "248325339",
      "cited_paper_id": 130216
    },
    {
      "context_text": "At present, numerous efforts have been achieved and contribute to various issues, involving extraction granularity [45, 62, 66, 75], event type [30, 40, 46, 60], the scarcity of data [9, 20], domain event [22, 25, 27, 51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues and aspects of event extraction research. No clear, verifiable resources are identified.",
      "processing_time": 59.62926006317139,
      "citing_paper_id": "248325339",
      "cited_paper_id": 18616505
    },
    {
      "context_text": "At present, numerous efforts have been achieved and contribute to various issues, involving extraction granularity [45, 62, 66, 75], event type [30, 40, 46, 60], the scarcity of data [9, 20], domain event [22, 25, 27, 51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues and aspects of event extraction research. No clear, verifiable resources are identified.",
      "processing_time": 59.62926006317139,
      "citing_paper_id": "248325339",
      "cited_paper_id": 19187253
    },
    {
      "context_text": "At present, numerous efforts have been achieved and contribute to various issues, involving extraction granularity [45, 62, 66, 75], event type [30, 40, 46, 60], the scarcity of data [9, 20], domain event [22, 25, 27, 51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues and aspects of event extraction research. No clear, verifiable resources are identified.",
      "processing_time": 59.62926006317139,
      "citing_paper_id": "248325339",
      "cited_paper_id": 201665978
    },
    {
      "context_text": "At present, numerous efforts have been achieved and contribute to various issues, involving extraction granularity [45, 62, 66, 75], event type [30, 40, 46, 60], the scarcity of data [9, 20], domain event [22, 25, 27, 51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues and aspects of event extraction research. No clear, verifiable resources are identified.",
      "processing_time": 59.62926006317139,
      "citing_paper_id": "248325339",
      "cited_paper_id": 204915992
    },
    {
      "context_text": "At present, numerous efforts have been achieved and contribute to various issues, involving extraction granularity [45, 62, 66, 75], event type [30, 40, 46, 60], the scarcity of data [9, 20], domain event [22, 25, 27, 51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues and aspects of event extraction research. No clear, verifiable resources are identified.",
      "processing_time": 59.62926006317139,
      "citing_paper_id": "248325339",
      "cited_paper_id": 207196336
    },
    {
      "context_text": "At present, numerous efforts have been achieved and contribute to various issues, involving extraction granularity [45, 62, 66, 75], event type [30, 40, 46, 60], the scarcity of data [9, 20], domain event [22, 25, 27, 51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues and aspects of event extraction research. No clear, verifiable resources are identified.",
      "processing_time": 59.62926006317139,
      "citing_paper_id": "248325339",
      "cited_paper_id": 218870398
    },
    {
      "context_text": "At present, numerous efforts have been achieved and contribute to various issues, involving extraction granularity [45, 62, 66, 75], event type [30, 40, 46, 60], the scarcity of data [9, 20], domain event [22, 25, 27, 51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues and aspects of event extraction research. No clear, verifiable resources are identified.",
      "processing_time": 59.62926006317139,
      "citing_paper_id": "248325339",
      "cited_paper_id": 227230288
    },
    {
      "context_text": "At present, numerous efforts have been achieved and contribute to various issues, involving extraction granularity [45, 62, 66, 75], event type [30, 40, 46, 60], the scarcity of data [9, 20], domain event [22, 25, 27, 51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues and aspects of event extraction research. No clear, verifiable resources are identified.",
      "processing_time": 59.62926006317139,
      "citing_paper_id": "248325339",
      "cited_paper_id": 235792491
    },
    {
      "context_text": "Effective event extraction will significantly support the implementation of its downstream tasks, such as investment strategy [7, 27], crisis management [3], summarization [37], recommendation [29], legal judgment support [51], and so forth.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction. No dataset names are present in the text.",
      "processing_time": 59.2921199798584,
      "citing_paper_id": "248325339",
      "cited_paper_id": 3424046
    },
    {
      "context_text": "Effective event extraction will significantly support the implementation of its downstream tasks, such as investment strategy [7, 27], crisis management [3], summarization [37], recommendation [29], legal judgment support [51], and so forth.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction. No dataset names are present in the text.",
      "processing_time": 59.2921199798584,
      "citing_paper_id": "248325339",
      "cited_paper_id": 227230288
    },
    {
      "context_text": "Some studies define the event as an action/behavior [21, 33, 66], while others view it as a structured n -tuple [11, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only differing definitions of events. No verifiable resources are identified.",
      "processing_time": 58.74805450439453,
      "citing_paper_id": "248325339",
      "cited_paper_id": 5825949
    },
    {
      "context_text": "Some studies define the event as an action/behavior [21, 33, 66], while others view it as a structured n -tuple [11, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only differing definitions of events. No verifiable resources are identified.",
      "processing_time": 58.74805450439453,
      "citing_paper_id": "248325339",
      "cited_paper_id": 225076222
    },
    {
      "context_text": "A joint model of event extraction based on bidirectional recurrent neural networks, combining the advantages of CNN in learning hidden features and the strength of joint extraction scheme in mitigating the error propagation, was presented in Reference [42].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction using neural networks.",
      "processing_time": 58.33374333381653,
      "citing_paper_id": "248325339",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "A joint model of event extraction based on bidirectional recurrent neural networks, combining the advantages of CNN in learning hidden features and the strength of joint extraction scheme in mitigating the error propagation, was presented in Reference [42].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction using neural networks.",
      "processing_time": 58.33374333381653,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "(2) JRNN [42] employs bidirectional recurrent neural networks and introduces the memory matrix effectively capturing the dependencies between argu-ment roles and trigger subtypes.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (JRNN) and its components. There are no clear identifiers for datasets in the text.",
      "processing_time": 60.086994886398315,
      "citing_paper_id": "248325339",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "We conduct experiments on the CoNLL-20093 [14] Chinese and English datasets and use the same data split as CoNLL-2009 share task for train, dev, and test.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CoNLL-2009 Chinese",
        "CoNLL-2009 English"
      ],
      "dataset_descriptions": {
        "CoNLL-2009 Chinese": "Used for training, development, and testing in experiments on syntactic and semantic dependencies, following the CoNLL-2009 shared task data splits.",
        "CoNLL-2009 English": "Used for training, development, and testing in experiments on syntactic and semantic dependencies, following the CoNLL-2009 shared task data splits."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the CoNLL-2009 Chinese and English datasets, which are specific and verifiable resources used for training, development, and testing in the experiments.",
      "processing_time": 80.29519653320312,
      "citing_paper_id": "248325339",
      "cited_paper_id": 9210201
    },
    {
      "context_text": "[49] exploited a regularization method to model the dependency relation between candidate arguments to improve the performance of argument identification.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving argument identification in event extraction.",
      "processing_time": 58.34456014633179,
      "citing_paper_id": "248325339",
      "cited_paper_id": 18801503
    },
    {
      "context_text": "Following previous studies [41], we convert the open event extraction into a sequence labeling task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The context is too generic to infer any specific dataset usage.",
      "processing_time": 59.903156757354736,
      "citing_paper_id": "248325339",
      "cited_paper_id": 19235598
    },
    {
      "context_text": "The Syntactic Dependency Parsing (DP) tree has been confirmed to be informative and can effectively support event detection [41, 65].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of syntactic dependency parsing trees for event detection.",
      "processing_time": 59.08184480667114,
      "citing_paper_id": "248325339",
      "cited_paper_id": 19235598
    },
    {
      "context_text": "The Syntactic Dependency Parsing (DP) tree has been confirmed to be informative and can effectively support event detection [41, 65].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of syntactic dependency parsing trees for event detection.",
      "processing_time": 59.08184480667114,
      "citing_paper_id": "248325339",
      "cited_paper_id": 202773239
    },
    {
      "context_text": "However, existing studies [8, 33, 41] merely investigate the original dependency structure.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to existing studies. No dataset names are provided in the context.",
      "processing_time": 59.75032711029053,
      "citing_paper_id": "248325339",
      "cited_paper_id": 19235598
    },
    {
      "context_text": "However, existing studies [8, 33, 41] merely investigate the original dependency structure.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to existing studies. No dataset names are provided in the context.",
      "processing_time": 59.75032711029053,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "However, existing studies [8, 33, 41] merely investigate the original dependency structure.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to existing studies. No dataset names are provided in the context.",
      "processing_time": 59.75032711029053,
      "citing_paper_id": "248325339",
      "cited_paper_id": 222008363
    },
    {
      "context_text": "Also, some studies exploiting syntactic dependency relation via the graph structure to improve the performance of event extraction can be found in Reference [21, 41, 54].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies that use syntactic dependency relations in graph structures for event extraction.",
      "processing_time": 59.747172594070435,
      "citing_paper_id": "248325339",
      "cited_paper_id": 19235598
    },
    {
      "context_text": "Also, some studies exploiting syntactic dependency relation via the graph structure to improve the performance of event extraction can be found in Reference [21, 41, 54].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies that use syntactic dependency relations in graph structures for event extraction.",
      "processing_time": 59.747172594070435,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Also, some studies exploiting syntactic dependency relation via the graph structure to improve the performance of event extraction can be found in Reference [21, 41, 54].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies that use syntactic dependency relations in graph structures for event extraction.",
      "processing_time": 59.747172594070435,
      "citing_paper_id": "248325339",
      "cited_paper_id": 225076222
    },
    {
      "context_text": "(5) GCN-ED [41] is the first attempt to explore how to effectively use GCN in event detection.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (GCN-ED) and its application to event detection.",
      "processing_time": 59.41343593597412,
      "citing_paper_id": "248325339",
      "cited_paper_id": 19235598
    },
    {
      "context_text": "(2) JMEE(–GCN) merely removes the GCN feature encoding module to further discuss the impact of GCN. (3) GAT(Single-channel) (GAT(Single)) [53] employs original GAT to model original dependency graph by single channel, of which input features are consistent with this article.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is focused on discussing different model configurations and their impacts.",
      "processing_time": 60.01537871360779,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "JMEE (line 4 in Table 3) shows the worst performance in this experiment, and the uncoded dependency relation should be a reason of the weakness.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a performance issue with a method or model.",
      "processing_time": 58.502172231674194,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "To comprehensively evaluate our proposed DL-OEE framework, following previous works [8, 33, 57], we compare it with a range of baselines and state-of-the-art models, which perform event extraction rather than just event detection.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison with baselines and state-of-the-art models. No verifiable resources are identified.",
      "processing_time": 60.37275838851929,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "To comprehensively evaluate our proposed DL-OEE framework, following previous works [8, 33, 57], we compare it with a range of baselines and state-of-the-art models, which perform event extraction rather than just event detection.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison with baselines and state-of-the-art models. No verifiable resources are identified.",
      "processing_time": 60.37275838851929,
      "citing_paper_id": "248325339",
      "cited_paper_id": 222008363
    },
    {
      "context_text": "Following References [33, 38, 73], the standard cross-entropy loss with weight is used as our objective function to strengthen the influence of event element labels, since the number of “O” tags is much lager than that of event element tags,",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for handling class imbalance in event element labels.",
      "processing_time": 58.62330722808838,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Event extraction can be viewed as a multi-class classification problem deciding whether each word in the sentence is an event trigger and whether each entity in the sentence plays a particular role in the event triggered by the candidate triggers [33].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to event extraction.",
      "processing_time": 58.074944496154785,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "In addition, the entity type is also missing in JMEE, and it leverages POS instead of dependency relation in JRNN. GCN-ED inputs words and their positions; RGAT needs words and dependency types; and edge weight matrix is fed into EE-GCN expect word information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing different approaches to event extraction.",
      "processing_time": 59.30923271179199,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "If removing the two channels give the baseline JMEE, then the process of feature encoding is similar to JMEE (i.e., feature concatenation before training).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model (JMEE). There are no clear identifiers for datasets in the text.",
      "processing_time": 60.00927758216858,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "We report our experimental results on the CoNLL-2009 Chinese and English test data in Tables 3 and 4, where JMEE(–GCN) (line 5) is used to further analyze baseline JMEE and the encoding effect of GCN.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CoNLL-2009 Chinese and English test data"
      ],
      "dataset_descriptions": {
        "CoNLL-2009 Chinese and English test data": "Used to evaluate the performance of the JMEE and JMEE(–GCN) models on document-level event extraction, focusing on the encoding effect of GCN."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'CoNLL-2009 Chinese and English test data' which is a specific dataset used for evaluating the performance of the JMEE model and its variant.",
      "processing_time": 73.07328939437866,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "[33] proposed a jointly multiple event extraction framework to jointly extract multiple event triggers and arguments by introducing syntactic shortcut arcs to enhance information flow and attention-based graph convolution networks to capture the correlation between triggers.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 57.37819147109985,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Some studies define the event as an action/behavior [21, 33, 66], while others view it as a structured n-tuple [11, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only differing definitions of events in various studies.",
      "processing_time": 57.75814938545227,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Besides, some methods were also developed to exploit syntactic features to capture enhanced semantic association between triggers and arguments [8, 33, 50].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.788466691970825,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Besides, some methods were also developed to exploit syntactic features to capture enhanced semantic association between triggers and arguments [8, 33, 50].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.788466691970825,
      "citing_paper_id": "248325339",
      "cited_paper_id": 222008363
    },
    {
      "context_text": "Following References [33, 38, 73], the standard cross-entropy loss with weight is used as our objective function to strengthen the influence of event element labels, since the number of “O” tags is much lager than that of event element tags, where N s is the number of sentences and n j is the number of words in the j th sentence. ω i is the weight of y i label, which can be obtained by where Med( · ) means taking the median operation, N C i is the number of words contained in the i th class in corpus, and C i is the i th class label.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only discusses the loss function and label weighting. No verifiable resources are identified.",
      "processing_time": 59.24032640457153,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Following References [33, 38, 73], the standard cross-entropy loss with weight is used as our objective function to strengthen the influence of event element labels, since the number of “O” tags is much lager than that of event element tags, where N s is the number of sentences and n j is the number of words in the j th sentence. ω i is the weight of y i label, which can be obtained by where Med( · ) means taking the median operation, N C i is the number of words contained in the i th class in corpus, and C i is the i th class label.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only discusses the loss function and label weighting. No verifiable resources are identified.",
      "processing_time": 59.24032640457153,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "(1) JMEE [33] enhances GCN with self-attention and highway network to improve the performance of GCN for event extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving event extraction using GCN with self-attention and highway networks.",
      "processing_time": 59.237128257751465,
      "citing_paper_id": "248325339",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Following the original GAT in Reference [53], we adopt the multi-head attention mechanism, while the average strategy is used for all layer in HGAT.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and architectures.",
      "processing_time": 56.223397970199585,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "An edge-enhanced GCN with syntactic relation was argued in Reference [8] for event detection, and a knowledge graph-based event embedding framework was considered in Reference [7].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'event detection' and 'syntactic relation', which are relevant to document-level event extraction. However, no specific dataset names are mentioned.",
      "processing_time": 60.5712468624115,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "An edge-enhanced GCN with syntactic relation was argued in Reference [8] for event detection, and a knowledge graph-based event embedding framework was considered in Reference [7].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'event detection' and 'syntactic relation', which are relevant to document-level event extraction. However, no specific dataset names are mentioned.",
      "processing_time": 60.5712468624115,
      "citing_paper_id": "248325339",
      "cited_paper_id": 222008363
    },
    {
      "context_text": "A latent variable neural model was developed in Reference [32] to extract unconstraint types of events from news clusters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a method for event extraction from news clusters.",
      "processing_time": 58.12266564369202,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Yang et al. [66] argued a document-level Chinese financial event extraction system, and an end-to-end framework based on it was designed in Reference [75].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a system and framework for Chinese financial event extraction.",
      "processing_time": 57.86438751220703,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Regarding GAT, a shortest path GAT was developed to extend the receptive field of nodes in Reference [67].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (GAT). The context is about extending the receptive field of nodes, which is a methodological detail.",
      "processing_time": 60.55683183670044,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Following Reference [67], we set a fixed layer and do not analyze the influence of different layer numbers on the extraction performance in Section 5.4.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological decision regarding layer numbers in a neural model.",
      "processing_time": 58.5143096446991,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "This is consistent with Reference [67].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not provide any specific information about datasets or their usage. It only states that something is consistent with a reference.",
      "processing_time": 59.047858476638794,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "The connected edges of ellipsis are represented by a blue dashed line with connected horizontally, and the relation types (“POB” and “SBV” in Figure 2) of edges are attained in Reference [57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a paper. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 60.27063179016113,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "On the other hand, related combinations including the influence of dependency parsing errors on extraction performance have already been discussed in Reference [57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a related discussion. No clear, verifiable resource names are present.",
      "processing_time": 59.0927460193634,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Hence, we employ the LSTM unit as described in Reference [77].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of an LSTM unit. No verifiable resources are identified.",
      "processing_time": 58.212823152542114,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Also, a is parametrized by a weight vector φ ∈ R 2 F , and the nonlinearity LeakyReLU serves as the activation function in Reference [53] generating the Equation (5), where · T represents the transposition operation, Hence, the output representation of node i based on multi-head attention mechanism can be written as where K and σ are the number of attention mechanism head and nonlinear function, respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only technical details about a neural network model. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 59.08730721473694,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "A multi-level GCN was studied in Reference [4] for cross-platform anchor link prediction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (multi-level GCN) and a task (cross-platform anchor link prediction).",
      "processing_time": 59.50783729553223,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "For example, a dynamic multi-pooling Convolutional Neural Network (CNN) was introduced to capture lexical semantic and encode sentence semantic in Reference [5].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (dynamic multi-pooling CNN). The context is about the introduction of a model, not the use of a dataset.",
      "processing_time": 60.84544086456299,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "In this section, we present the original building block layer used to construct graph attention network in Reference [53].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context is about constructing a graph attention network, which is a method.",
      "processing_time": 59.48801112174988,
      "citing_paper_id": "248325339",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Also, some studies focus on specific event types [8], while others extract events with open (unspecific) type [60].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general approaches to event extraction. No dataset names are provided.",
      "processing_time": 58.107731342315674,
      "citing_paper_id": "248325339",
      "cited_paper_id": 201665978
    },
    {
      "context_text": "Also, some studies focus on specific event types [8], while others extract events with open (unspecific) type [60].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general approaches to event extraction. No dataset names are provided.",
      "processing_time": 58.107731342315674,
      "citing_paper_id": "248325339",
      "cited_paper_id": 222008363
    },
    {
      "context_text": "[65] used a dependency tree-based GCN with aggregative attention to explicitly model and aggregate multi-order syntactic representations in sentences for event detection.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event detection using a dependency tree-based GCN with aggregative attention.",
      "processing_time": 58.4711709022522,
      "citing_paper_id": "248325339",
      "cited_paper_id": 202773239
    },
    {
      "context_text": "For the extraction form, different granularities (e.g., document level [26, 75] and sentence level [9, 20, 28]) have been considered.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only different granularities of event extraction. No verifiable resources are identified.",
      "processing_time": 58.18569779396057,
      "citing_paper_id": "248325339",
      "cited_paper_id": 204915992
    },
    {
      "context_text": "For the extraction form, different granularities (e.g., document level [26, 75] and sentence level [9, 20, 28]) have been considered.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only different granularities of event extraction. No verifiable resources are identified.",
      "processing_time": 58.18569779396057,
      "citing_paper_id": "248325339",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "For the extraction form, different granularities (e.g., document level [26, 75] and sentence level [9, 20, 28]) have been considered.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only different granularities of event extraction. No verifiable resources are identified.",
      "processing_time": 58.18569779396057,
      "citing_paper_id": "248325339",
      "cited_paper_id": 235792491
    },
    {
      "context_text": "Recent research considers an event as actions with similar properties, such as disaster event [69], medicine event [22], economic event [75], personal life event (e.g., tourism and marriage) [70], and cybersecurity event [48].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only lists categories of events without naming any particular dataset.",
      "processing_time": 58.35350942611694,
      "citing_paper_id": "248325339",
      "cited_paper_id": 207656472
    },
    {
      "context_text": "Moreover, some special events have been defined, such as personal events [17, 18, 70], critical events [36], crisis events [47], abnormal events [13], and scientific interest events [55].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions various types of events but does not specify any datasets. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 59.52150368690491,
      "citing_paper_id": "248325339",
      "cited_paper_id": 207656472
    },
    {
      "context_text": "Moreover, some special events have been defined, such as personal events [17, 18, 70], critical events [36], crisis events [47], abnormal events [13], and scientific interest events [55].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions various types of events but does not specify any datasets. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 59.52150368690491,
      "citing_paper_id": "248325339",
      "cited_paper_id": 218522520
    },
    {
      "context_text": "We evaluate the models using the following metrics: Precision ( P ), Recall ( R ), Micro-F 1( F1 ) [56], and Macro-Avg-F 1 ( Avg-F 1 ), TP denotes the samples that are predicated to be positive and their ground truth is positive.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only evaluation metrics. There are no clear identifiers for datasets in the text.",
      "processing_time": 58.389161109924316,
      "citing_paper_id": "248325339",
      "cited_paper_id": 212419710
    },
    {
      "context_text": "Wu et al. [63] argued a dynamic GCN for entity linking.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (dynamic GCN) for entity linking.",
      "processing_time": 57.65436553955078,
      "citing_paper_id": "248325339",
      "cited_paper_id": 215844979
    },
    {
      "context_text": "(7) EE-GCN [8] implements event detection with edge-enhanced GCN with syntactic dependency.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (EE-GCN) and its application to event detection. No verifiable datasets are referenced.",
      "processing_time": 59.65827989578247,
      "citing_paper_id": "248325339",
      "cited_paper_id": 222008363
    },
    {
      "context_text": "Some recent studies utilized Graph Neural Network (GNN) to encode the graph structure of the DP tree and could further improve the performance of event detection [8, 43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of GNNs for improving event detection performance.",
      "processing_time": 57.95433592796326,
      "citing_paper_id": "248325339",
      "cited_paper_id": 222008363
    },
    {
      "context_text": "FN means the samples are predicated to be negative and their ground truth is positive [74].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to samples and ground truth. No verifiable resource names are present.",
      "processing_time": 59.13173723220825,
      "citing_paper_id": "248325339",
      "cited_paper_id": 224913101
    },
    {
      "context_text": "Generally, the event extraction work of specified types is based on the types defined by ACE, and extensively studied [5, 6, 21, 28, 31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to types defined by ACE. There is no clear indication of a reusable dataset.",
      "processing_time": 59.75520586967468,
      "citing_paper_id": "248325339",
      "cited_paper_id": 225076222
    },
    {
      "context_text": "Li et al. [26] proposed a document-level neural event argument extraction model by formulating the task as conditional generation following event templates.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event argument extraction.",
      "processing_time": 57.944092988967896,
      "citing_paper_id": "248325339",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Therefore, based on the theory of “three aspects” (i.e., grammar, semantics, and pragmatics) in Chinese studies [35, 59], we study the grammatical structure and semantic function of sentences and give our event definition.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only theoretical aspects of Chinese grammar and semantics.",
      "processing_time": 57.92863082885742,
      "citing_paper_id": "248325339",
      "cited_paper_id": 252270071
    },
    {
      "context_text": ", grammar, semantics, and pragmatics) in Chinese studies [35, 59], we study the grammatical structure and semantic function of sentences and give our event definition.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general areas of study such as grammar, semantics, and pragmatics in Chinese studies.",
      "processing_time": 60.08756899833679,
      "citing_paper_id": "248325339",
      "cited_paper_id": null
    },
    {
      "context_text": "Early methods for event temporal relation extraction have been rule-based where syntax, knowledge databases, regular expressions are leveraged to design temporal rules (Hagège and Tannier 2007; Strötgen and Gertz 2010; Llorens, Saquete, and Navarro 2010).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for event temporal relation extraction.",
      "processing_time": 58.3693950176239,
      "citing_paper_id": "250291480",
      "cited_paper_id": 1339234
    },
    {
      "context_text": "The policy-gradient method REINFORCE (Williams 1992) can thus be leveraged to facilitate the selection training.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reinforcement learning method called REINFORCE. No verifiable resources are identified.",
      "processing_time": 59.16508865356445,
      "citing_paper_id": "250291480",
      "cited_paper_id": 2332513
    },
    {
      "context_text": "In addition, another beneﬁt of REINFORCE involves its ﬂexibility that facilitates the incorporation of different information sources from C to enrich the reward function R ( C ) and provide more training signals for the selection model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reinforcement learning algorithm and its flexibility. No verifiable resources are identified.",
      "processing_time": 59.16127896308899,
      "citing_paper_id": "250291480",
      "cited_paper_id": 2332513
    },
    {
      "context_text": "As such, for EERE problems, we propose the following information sources to compute the reward function R ( C ) for REINFORCE training: • Performance-based Reward R per ( C ) : We compute this reward via the relation prediction performance of the model M EERE for the event mentions e 1 and e 2 in D .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reward function and a model. No clear identifiers for datasets are present.",
      "processing_time": 59.15858840942383,
      "citing_paper_id": "250291480",
      "cited_paper_id": 2332513
    },
    {
      "context_text": "…the relation prediction performance of M EERE over e 1 and e 2 as the sentence selection guidance, we propose to utilize the REINFORCE algorithm (Williams 1992) that can treat the prediction performance as the reward function R ( C ) for the selected sentence sequence C to train the selection…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reinforcement learning algorithm. No dataset names are present in the citation span.",
      "processing_time": 58.847028732299805,
      "citing_paper_id": "250291480",
      "cited_paper_id": 2332513
    },
    {
      "context_text": "To employ the relation prediction performance of M EERE over e 1 and e 2 as the sentence selection guidance, we propose to utilize the REINFORCE algorithm (Williams 1992) that can treat the prediction performance as the reward function R ( C ) for the selected sentence sequence C to train the selection processes for input documents.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reinforcement learning algorithm. No dataset names are present in the citation span.",
      "processing_time": 58.83701300621033,
      "citing_paper_id": "250291480",
      "cited_paper_id": 2332513
    },
    {
      "context_text": "We propose three novel reward functions to train our model with REINFORCE.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of REINFORCE for training models.",
      "processing_time": 57.762988567352295,
      "citing_paper_id": "250291480",
      "cited_paper_id": 2332513
    },
    {
      "context_text": "…works have explored deep learning models to induce representations for EERE from data, i.e., representation learning for TRE (Dli-gach et al. 2017; Tourille et al. 2017; Cheng and Miyao 2017; Meng, Rumshisky, and Romanov 2017) and SRE (Nguyen, Meyers, and Grishman 2016; Zhou et al. 2020; Tran,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that explore deep learning models for event extraction. No verifiable resources are identified.",
      "processing_time": 59.75304412841797,
      "citing_paper_id": "250291480",
      "cited_paper_id": 6353806
    },
    {
      "context_text": "…deep learning models to induce representations for EERE from data, i.e., representation learning for TRE (Dli-gach et al. 2017; Tourille et al. 2017; Cheng and Miyao 2017; Meng, Rumshisky, and Romanov 2017) and SRE (Nguyen, Meyers, and Grishman 2016; Zhou et al. 2020; Tran, Phung, and Nguyen 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to deep learning models and methods for event extraction. No verifiable resources are identified.",
      "processing_time": 59.59531593322754,
      "citing_paper_id": "250291480",
      "cited_paper_id": 6987624
    },
    {
      "context_text": "…deep learning models to induce representations for EERE from data, i.e., representation learning for TRE (Dli-gach et al. 2017; Tourille et al. 2017; Cheng and Miyao 2017; Meng, Rumshisky, and Romanov 2017) and SRE (Nguyen, Meyers, and Grishman 2016; Zhou et al. 2020; Tran, Phung, and Nguyen 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to deep learning models and methods for event extraction. No verifiable resources are identified.",
      "processing_time": 59.59531593322754,
      "citing_paper_id": "250291480",
      "cited_paper_id": 34280734
    },
    {
      "context_text": "…the demonstration of event understanding, event structures ﬁnd their applications in different downstream applications, including question answering, event prediction, timeline construction, and text summarization (Do, Lu, and Roth 2012; Chaturvedi, Peng, and Roth 2017; Han, Ning, and Peng 2019a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only applications of event structures. No clear identifiers for datasets are present.",
      "processing_time": 58.29697942733765,
      "citing_paper_id": "250291480",
      "cited_paper_id": 7359050
    },
    {
      "context_text": "Based on the deﬁnition from (Hovy et al. 2013), an event c 2 is a child of the event c 1 if c 1 is a collector event with a sequence of activities where c 2 is one of the activity in the sequence and c 2 is spatially and temporally contained within c 1 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a definition of event relationships. No verifiable resources are identified.",
      "processing_time": 58.655425786972046,
      "citing_paper_id": "250291480",
      "cited_paper_id": 16940766
    },
    {
      "context_text": "For the subevent relation detection task, we follow the label set in prior work with four possible relations, i.e., PARENT-CHILD , CHILD-PARENT , COREF , and NOREL (Hovy et al. 2013; Glavaˇs et al. 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only relations used in a task. No verifiable resources are identified.",
      "processing_time": 57.756672859191895,
      "citing_paper_id": "250291480",
      "cited_paper_id": 16940766
    },
    {
      "context_text": "Afterward, machine learning models have been applied to both event temporal relation extraction (Mani et al. 2006; Ning, Feng, and Roth 2017; Leeuwenberg and Moens 2017; Ning et al. 2018b; Tran, Nguyen, and Nguyen 2021) and subevent relation extraction (Glavaˇs et al. 2014; Araki et al. 2014;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that apply machine learning models to event temporal relation extraction and subevent relation extraction.",
      "processing_time": 60.05111384391785,
      "citing_paper_id": "250291480",
      "cited_paper_id": 18281724
    },
    {
      "context_text": "As such, given two event mentions in the same document, subevent relation extraction (SRE) seeks to determine if an event mention is a subevent (e.g., “ Parent-Child ”) of the other while the goal of temporal relation extraction (TRE) is to identify the temporal order of the two event mentions (e.g., “ Before ”, “ After ”).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only describes the tasks of subevent relation extraction and temporal relation extraction.",
      "processing_time": 57.96185231208801,
      "citing_paper_id": "250291480",
      "cited_paper_id": 34280734
    },
    {
      "context_text": "To alleviate feature engineering, recent works have explored deep learning models to induce representations for EERE from data, i.e., representation learning for TRE (Dli-gach et al. 2017; Tourille et al. 2017; Cheng and Miyao 2017; Meng, Rumshisky, and Romanov 2017) and SRE (Nguyen, Meyers, and Grishman 2016; Zhou et al. 2020; Tran, Phung, and Nguyen 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to deep learning models and approaches for event extraction. No verifiable resources are identified.",
      "processing_time": 59.59808301925659,
      "citing_paper_id": "250291480",
      "cited_paper_id": 34280734
    },
    {
      "context_text": "Datasets : For subevent relation extraction, we evaluate our models on the HiEve dataset (Glavaˇs et al. 2014) to make it consistent with prior work (Wang et al. 2020; Zhou et al. 2020 (Glavaˇs et al. 2014) 52.2 63.4 57.7 TACOLM (Zhou et al. 2020) 48.5 49.4 48.9 Joint Learning (Wang et al. 2020)…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "HiEve"
      ],
      "dataset_descriptions": {
        "HiEve": "Used to evaluate models on subevent relation extraction, ensuring consistency with prior work and comparing performance metrics."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the HiEve dataset, which is used for evaluating models on subevent relation extraction, consistent with prior work.",
      "processing_time": 64.99881291389465,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215548441
    },
    {
      "context_text": "The latest advances present transformer-based language models, e.g., BERT (Devlin et al. 2019), to encode input texts and deliver state-of-the-art performance for EERE problems (Ning, Subramanian, and Roth 2019; Han et al. 2019b; Wang et al. 2020; Ballesteros et al. 2020; Tran and Nguyen 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of transformer-based language models for event extraction.",
      "processing_time": 59.68917179107666,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215548441
    },
    {
      "context_text": "…with prior work (Wang et al. 2020; Zhou et al. 2020 (Glavaˇs et al. 2014) 52.2 63.4 57.7 TACOLM (Zhou et al. 2020) 48.5 49.4 48.9 Joint Learning (Wang et al. 2020) 62.5 56.4 59.5 SCS-EERE (ours) 68.7 63.2 65.9 Table 1: Model performance on test data of HiEve for subevent relation extraction.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "HiEve"
      ],
      "dataset_descriptions": {
        "HiEve": "Used to evaluate model performance on subevent relation extraction, focusing on temporal ordering of events in document-level event extraction."
      },
      "confidence_score": 0.7,
      "reasoning": "The citation context does not mention any specific datasets, only model performances on test data of HiEve. HiEve is likely a dataset, but it is not explicitly named as such in the given context.",
      "processing_time": 68.37245082855225,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215548441
    },
    {
      "context_text": "Datasets : For subevent relation extraction, we evaluate our models on the HiEve dataset (Glavaˇs et al. 2014) to make it consistent with prior work (Wang et al. 2020; Zhou et al. 2020 (Glavaˇs et al. 2014) 52.2 63.4 57.7 TACOLM (Zhou et al. 2020) 48.5 49.4 48.9 Joint Learning (Wang et al. 2020) 62.5 56.4 59.5 SCS-EERE (ours) 68.7 63.2 65.9 Table 1: Model performance on test data of HiEve for subevent relation extraction.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "HiEve"
      ],
      "dataset_descriptions": {
        "HiEve": "Used to evaluate models on subevent relation extraction, maintaining consistency with prior work and comparing performance across different approaches."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the HiEve dataset, which is used for evaluating models on subevent relation extraction. The dataset is referenced to maintain consistency with prior work.",
      "processing_time": 66.30313086509705,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215548441
    },
    {
      "context_text": "The major challenges to achieve this goal involve capturing multi-granular nature of events and their complex connections/relations (i.e., event structures) to deliver a coherent story for an input document (Wang et al. 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses challenges and goals related to event extraction.",
      "processing_time": 57.963196754455566,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215548441
    },
    {
      "context_text": "As such, given an input document, existing models for EERE have only constrained their operations to document context with a set of sentences that can ﬁt into the length limits of transformer-based language models (Han, Ning, and Peng 2019a; Ballesteros et al. 2020; Wang et al. 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to existing models and their limitations regarding document context length.",
      "processing_time": 58.46838641166687,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215548441
    },
    {
      "context_text": "Following (Wang et al. 2020), to build event structures with multi-faceted event-event relations for an input document, we focus on two tasks of EERE, i.e., subevent and temporal relation extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only tasks within the field of event extraction. No clear identifiers for datasets are present.",
      "processing_time": 59.119966983795166,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215548441
    },
    {
      "context_text": "In particular, following prior work (Wang et al. 2020), we employ the RoBERTa model (Liu et al. 2019) (with the limit of 512 sub-tokens for input texts) to encode D 0 in this work.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the RoBERTa model and a token limit. No verifiable datasets are referenced.",
      "processing_time": 59.10400438308716,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215548441
    },
    {
      "context_text": "For temporal event relation extraction (TRE), we use the label set with temporal relations/orders of BEFORE , AFTER , EQUAL , and VAGUE to be consistent with previous work (Ning, Feng, and Roth 2017; Ning, Subramanian, and Roth 2019; Han, Ning, and Peng 2019a; Wang et al. 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a label set for temporal event relation extraction. No verifiable resources are identified.",
      "processing_time": 59.113913774490356,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215548441
    },
    {
      "context_text": "First, in Self-Attention Architecture Modiﬁcation (Zaheer et al. 2020; Beltagy, Peters, and Cohan 2020; Kitaev, Kaiser, and Levskaya 2020), one can replace the vanilla self-attention of transformer networks with some variant architectures, e.g., sparse self-attention (Zaheer et al. 2020), that…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only architectural modifications to transformer models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 60.04285526275635,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "First, in Self-Attention Architecture Modiﬁcation (Zaheer et al. 2020; Beltagy, Peters, and Cohan 2020; Kitaev, Kaiser, and Levskaya 2020), one can replace the vanilla self-attention of transformer networks with some variant architectures, e.g., sparse self-attention (Zaheer et al. 2020), that…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only architectural modifications to transformer models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 60.04285526275635,
      "citing_paper_id": "250291480",
      "cited_paper_id": 220831004
    },
    {
      "context_text": "…of this type: BigBird (Zaheer et al. 2020) (using sparse self-attention), Reformer (Kitaev, Kaiser, and Levskaya 2020) (using locality-sensitive hashing to replace dot-product attention), and Longformer (Beltagy, Peters, and Cohan 2020) (using local self-attention with global task-aware attention).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models and methods, not datasets. No specific datasets are referenced.",
      "processing_time": 56.70321440696716,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "An observation from the tables is that methods with document-level context modeling (i.e., BigBird, Reformer, Longformer, Hierarchical, Neighbor Sentences, SCS-EERE) tend to perform better than those with only event host sentence encoding (i.e., Host Sentence-RoBERTa) across different tasks and datasets.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers also do not provide additional context about datasets.",
      "processing_time": 59.11066794395447,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "An observation from the tables is that methods with document-level context modeling (i.e., BigBird, Reformer, Longformer, Hierarchical, Neighbor Sentences, SCS-EERE) tend to perform better than those with only event host sentence encoding (i.e., Host Sentence-RoBERTa) across different tasks and datasets.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers also do not provide additional context about datasets.",
      "processing_time": 59.11066794395447,
      "citing_paper_id": "250291480",
      "cited_paper_id": 220831004
    },
    {
      "context_text": "Note that for BigBird, Reformer, Longformer, and Neighbor Sentences, the sentences between the event host sentences will be ﬁrst included into the input context for the models.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 58.04497718811035,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "Note that for BigBird, Reformer, Longformer, and Neighbor Sentences, the sentences between the event host sentences will be ﬁrst included into the input context for the models.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 58.04497718811035,
      "citing_paper_id": "250291480",
      "cited_paper_id": 220831004
    },
    {
      "context_text": "In particular, we consider three popular language models of this type: BigBird (Zaheer et al. 2020) (using sparse self-attention), Reformer (Kitaev, Kaiser, and Levskaya 2020) (using locality-sensitive hashing to replace dot-product attention), and Longformer (Beltagy, Peters, and Cohan 2020) (using local self-attention with global task-aware attention).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models (BigBird, Reformer, Longformer) but does not reference any specific datasets. The citation intent is to describe the models used, not datasets.",
      "processing_time": 60.877466917037964,
      "citing_paper_id": "250291480",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "In particular, we consider three popular language models of this type: BigBird (Zaheer et al. 2020) (using sparse self-attention), Reformer (Kitaev, Kaiser, and Levskaya 2020) (using locality-sensitive hashing to replace dot-product attention), and Longformer (Beltagy, Peters, and Cohan 2020) (using local self-attention with global task-aware attention).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models (BigBird, Reformer, Longformer) but does not reference any specific datasets. The citation intent is to describe the models used, not datasets.",
      "processing_time": 60.877466917037964,
      "citing_paper_id": "250291480",
      "cited_paper_id": 220831004
    },
    {
      "context_text": "…work include joint inferring events and temporal relations (Han et al. 2019b; Han, Ning, and Peng 2019a) and leveraging transformer-based language models for input texts (Ning, Subramanian, and Roth 2019; Ross, Cai, and Min 2020; Wang et al. 2020; Phung, Nguyen, and Nguyen 2021; Phung et al. 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.49365282058716,
      "citing_paper_id": "250291480",
      "cited_paper_id": 216914289
    },
    {
      "context_text": "…work include joint inferring events and temporal relations (Han et al. 2019b; Han, Ning, and Peng 2019a) and leveraging transformer-based language models for input texts (Ning, Subramanian, and Roth 2019; Ross, Cai, and Min 2020; Wang et al. 2020; Phung, Nguyen, and Nguyen 2021; Phung et al. 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.49365282058716,
      "citing_paper_id": "250291480",
      "cited_paper_id": 235097468
    },
    {
      "context_text": "First, in Self-Attention Architecture Modiﬁcation (Zaheer et al. 2020; Beltagy, Peters, and Cohan 2020; Kitaev, Kaiser, and Levskaya 2020), one can replace the vanilla self-attention of transformer networks with some variant architectures, e.g., sparse self-attention (Zaheer et al. 2020), that allow the modeling of larger document context while maintaining the same complexity as the original trans-former.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation discusses modifications to transformer architectures, specifically mentioning sparse self-attention, but does not mention any specific datasets.",
      "processing_time": 58.65294814109802,
      "citing_paper_id": "250291480",
      "cited_paper_id": 220831004
    },
    {
      "context_text": "In particular, we consider three popular language models of this type: BigBird (Zaheer et al. 2020) (using sparse self-attention), Reformer (Kitaev, Kaiser, and Levskaya 2020) (using locality-sensitive hashing to replace dot-product attention), and Longformer (Beltagy, Peters, and Cohan 2020)…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models (BigBird, Reformer, Longformer) but does not reference any specific datasets. The context is focused on describing the models and their mechanisms.",
      "processing_time": 60.71734261512756,
      "citing_paper_id": "250291480",
      "cited_paper_id": 220831004
    },
    {
      "context_text": "…Kaiser, and Levskaya 2020), one can replace the vanilla self-attention of transformer networks with some variant architectures, e.g., sparse self-attention (Zaheer et al. 2020), that allow the modeling of larger document context while maintaining the same complexity as the original trans-former.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model architectures and their capabilities. There are no clear identifiers for datasets.",
      "processing_time": 58.86975359916687,
      "citing_paper_id": "250291480",
      "cited_paper_id": 220831004
    },
    {
      "context_text": "Above all, for both Self-Attention Architecture Modiﬁcation and Hierarchical Designs, the transformer-based models are often used to encode a consecutive sequence of sentences in an input document without considering potential contribution of each sentence for the prediction tasks of interest.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only discusses model architectures and their application to document encoding.",
      "processing_time": 57.15358018875122,
      "citing_paper_id": "250291480",
      "cited_paper_id": 220831004
    },
    {
      "context_text": "…2017) 23.8 46.1 BiLSTM (Cheng and Miyao 2017) 24.3 51.8 BiLSTM+MAP (Han et al. 2019a) 41.1 57.1 Deep SSVM (Han et al. 2019b) 41.0 58.8 UCGraph+BERT (Liu et al. 2021) 43.4 61.2 TIMERS (Mathur et al. 2021) 45.5 71.1 SCS-EERE (ours) 51.1 76.7 Table 3: Model performance (F1) on test data of TDDMan and…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TDDMan"
      ],
      "dataset_descriptions": {
        "TDDMan": "Used to evaluate model performance on document-level event extraction, specifically comparing F1 scores across various models. The dataset focuses on temporal ordering of events with uncertainty-guided graph completion."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'test data of TDDMan' which appears to be a specific dataset used for evaluating model performance. No other datasets are mentioned.",
      "processing_time": 67.96577739715576,
      "citing_paper_id": "250291480",
      "cited_paper_id": 237100961
    },
    {
      "context_text": "In particular, the state-of-the-art performance on HiEve is due to the joint constrained learning method in (Wang et al. 2020) (Ning et al. 2017) 23.8 46.1 BiLSTM (Cheng and Miyao 2017) 24.3 51.8 BiLSTM+MAP (Han et al. 2019a) 41.1 57.1 Deep SSVM (Han et al. 2019b) 41.0 58.8 UCGraph+BERT (Liu et al. 2021) 43.4 61.2 TIMERS (Mathur et al. 2021) 45.5 71.1 SCS-EERE (ours) 51.1 76.7 Table 3: Model performance (F1) on test data of TDDMan and TDDAuto. mance for MATRES, TDDMan, and TDDAuto are recently achieved in the TIMERS system (Mathur et al. 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "HiEve",
        "TDDMan",
        "TDDAuto"
      ],
      "dataset_descriptions": {
        "HiEve": "Used to evaluate the joint constrained learning method for document-level event extraction, focusing on state-of-the-art performance metrics.",
        "TDDMan": "Used to assess model performance on document-level event extraction, providing test data for benchmarking.",
        "TDDAuto": "Used to assess model performance on document-level event extraction, providing test data for benchmarking."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets and models, but only 'HiEve', 'TDDMan', and 'TDDAuto' are identified as specific datasets used for evaluation. The other entries are either models or methods.",
      "processing_time": 78.95621538162231,
      "citing_paper_id": "250291480",
      "cited_paper_id": 237100961
    },
    {
      "context_text": "…been applied to both event temporal relation extraction (Mani et al. 2006; Ning, Feng, and Roth 2017; Leeuwenberg and Moens 2017; Ning et al. 2018b; Tran, Nguyen, and Nguyen 2021) and subevent relation extraction (Glavaˇs et al. 2014; Araki et al. 2014; Aldawsari and Finlayson 2019) to exploit…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various works on event temporal relation extraction and subevent relation extraction.",
      "processing_time": 58.83662724494934,
      "citing_paper_id": "250291480",
      "cited_paper_id": 241583479
    },
    {
      "context_text": "Some feature-based document level information aggregation methods were proposed by (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2012; Reichart and Barzilay, 2012; Lu and Roth, 2012).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.93527436256409,
      "citing_paper_id": "234790176",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Some feature-based document level information aggregation methods were proposed by (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2012; Reichart and Barzilay, 2012; Lu and Roth, 2012).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.93527436256409,
      "citing_paper_id": "234790176",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "Some feature-based document level information aggregation methods were proposed by (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2012; Reichart and Barzilay, 2012; Lu and Roth, 2012).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.93527436256409,
      "citing_paper_id": "234790176",
      "cited_paper_id": 14220069
    },
    {
      "context_text": "We apply the attention mechanism proposed by (Luong et al., 2015) with the weights derived by\nαt,j = exp(zt,j)∑ni\nm=1 exp(zt,m)\nzt,m = tanh(h > t Wsahm + bsa)\n(3)\nAnd the contextual representation of wt is hat =∑ni j=1 αt,jhj .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only an attention mechanism and its mathematical formulation. No verifiable resources are identified.",
      "processing_time": 58.87628149986267,
      "citing_paper_id": "234790176",
      "cited_paper_id": 1998416
    },
    {
      "context_text": "The RNN-based encoder-decoder framework (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gu et al., 2016) consists of two components: a) an encoder which converts the source sentence into a fixed length vector c and",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only models and methods. The cited papers' titles also do not indicate the use of specific datasets.",
      "processing_time": 59.77608251571655,
      "citing_paper_id": "234790176",
      "cited_paper_id": 1998416
    },
    {
      "context_text": "The RNN-based encoder-decoder framework (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gu et al., 2016) consists of two components: a) an encoder which converts the source sentence into a fixed length vector c and",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only models and methods. The cited papers' titles also do not indicate the use of specific datasets.",
      "processing_time": 59.77608251571655,
      "citing_paper_id": "234790176",
      "cited_paper_id": 5590763
    },
    {
      "context_text": "The RNN-based encoder-decoder framework (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gu et al., 2016) consists of two components: a) an encoder which converts the source sentence into a fixed length vector c and",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only models and methods. The cited papers' titles also do not indicate the use of specific datasets.",
      "processing_time": 59.77608251571655,
      "citing_paper_id": "234790176",
      "cited_paper_id": 8174613
    },
    {
      "context_text": "The RNN-based encoder-decoder framework (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gu et al., 2016) consists of two components: a) an encoder which converts the source sentence into a fixed length vector c and",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only models and methods. The cited papers' titles also do not indicate the use of specific datasets.",
      "processing_time": 59.77608251571655,
      "citing_paper_id": "234790176",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "Studies (Bahdanau et al., 2015; Luong et al., 2015) have shown that summarizing the entire source sentence into a fixed length vector will limit the performance of the decoder.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses limitations of summarizing source sentences in neural machine translation.",
      "processing_time": 58.25873565673828,
      "citing_paper_id": "234790176",
      "cited_paper_id": 1998416
    },
    {
      "context_text": "Studies (Bahdanau et al., 2015; Luong et al., 2015) have shown that summarizing the entire source sentence into a fixed length vector will limit the performance of the decoder.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses limitations of summarizing source sentences in neural machine translation.",
      "processing_time": 58.25873565673828,
      "citing_paper_id": "234790176",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "The RNN-based encoder-decoder framework (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gu et al., 2016) consists of two components: a) an encoder which converts the source sentence into a fixed length vector c and b) a decoder is to unfold the context vector c…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes a methodological framework (RNN-based encoder-decoder) and does not mention any specific datasets. The cited papers are also focused on methods and do not introduce datasets.",
      "processing_time": 60.826661348342896,
      "citing_paper_id": "234790176",
      "cited_paper_id": 1998416
    },
    {
      "context_text": "The RNN-based encoder-decoder framework (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gu et al., 2016) consists of two components: a) an encoder which converts the source sentence into a fixed length vector c and b) a decoder is to unfold the context vector c…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes a methodological framework (RNN-based encoder-decoder) and does not mention any specific datasets. The cited papers are also focused on methods and do not introduce datasets.",
      "processing_time": 60.826661348342896,
      "citing_paper_id": "234790176",
      "cited_paper_id": 5590763
    },
    {
      "context_text": "The RNN-based encoder-decoder framework (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gu et al., 2016) consists of two components: a) an encoder which converts the source sentence into a fixed length vector c and b) a decoder is to unfold the context vector c…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes a methodological framework (RNN-based encoder-decoder) and does not mention any specific datasets. The cited papers are also focused on methods and do not introduce datasets.",
      "processing_time": 60.826661348342896,
      "citing_paper_id": "234790176",
      "cited_paper_id": 8174613
    },
    {
      "context_text": "The RNN-based encoder-decoder framework (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gu et al., 2016) consists of two components: a) an encoder which converts the source sentence into a fixed length vector c and b) a decoder is to unfold the context vector c…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes a methodological framework (RNN-based encoder-decoder) and does not mention any specific datasets. The cited papers are also focused on methods and do not introduce datasets.",
      "processing_time": 60.826661348342896,
      "citing_paper_id": "234790176",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "We apply the attention mechanism proposed by (Luong et al., 2015) with the weights derived by",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (attention mechanism).",
      "processing_time": 57.136799812316895,
      "citing_paper_id": "234790176",
      "cited_paper_id": 1998416
    },
    {
      "context_text": "As is formalized in (Gu et al., 2016), the source sentence si is converted into a fixed length vector c by the encoder RNN,\nht = f(ht−1, wt), c = φ({h1, . . . ,hni})\nwhere f is the RNN function, {ht} are the RNN states, wt is the t-th token of source sentence, c is the so-called context vector, and…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only describes a method for converting source sentences into vectors using an encoder RNN.",
      "processing_time": 58.68339562416077,
      "citing_paper_id": "234790176",
      "cited_paper_id": 8174613
    },
    {
      "context_text": "As is formalized in (Gu et al., 2016), the source sentence si is converted into a fixed length vector c by the encoder RNN,",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for converting source sentences into vectors using an encoder RNN.",
      "processing_time": 57.69326138496399,
      "citing_paper_id": "234790176",
      "cited_paper_id": 8174613
    },
    {
      "context_text": "The BiLSTM architecture is composed of a forward LSTM and a backward LSTM, i.e.,\n−→ h t =−−−−→\nLSTM( −→ h t−1, et), ←− h t = ←−−−− LSTM( ←− h t+1, et).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model architecture (BiLSTM). There are no verifiable resources or datasets mentioned.",
      "processing_time": 59.21642589569092,
      "citing_paper_id": "234790176",
      "cited_paper_id": 12730022
    },
    {
      "context_text": "We apply the BiLSTM (Zaremba and Sutskever, 2014) model for sentence-level semantic encoding, which can effectively capture sequential and contextual information for each token.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BiLSTM) and its application for sentence-level semantic encoding.",
      "processing_time": 58.9889121055603,
      "citing_paper_id": "234790176",
      "cited_paper_id": 12730022
    },
    {
      "context_text": "In this module, we encode the sentence-level contextual information for each token with Bidirectional LSTM (BiLSTM) and self-attention mechanism.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources or datasets mentioned.",
      "processing_time": 58.985989809036255,
      "citing_paper_id": "234790176",
      "cited_paper_id": 12730022
    },
    {
      "context_text": "The data splitting for training, validation and testing follows (Ji and Grishman, 2008; Chen et al., 2015; Liu et al., 2018; Chen et al., 2018; Huang and Ji, 2020), where the training set contains 529 documents, the validation set contains 30 documents and the remaining 40 documents are used as…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions specific document counts for training, validation, and testing sets, but does not name a specific dataset. The cited papers do not provide additional context to identify a specific dataset.",
      "processing_time": 61.51213598251343,
      "citing_paper_id": "234790176",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "The data splitting for training, validation and testing follows (Ji and Grishman, 2008; Chen et al., 2015; Liu et al., 2018; Chen et al., 2018; Huang and Ji, 2020), where the training set contains 529 documents, the validation set contains 30 documents and the remaining 40 documents are used as…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions specific document counts for training, validation, and testing sets, but does not name a specific dataset. The cited papers do not provide additional context to identify a specific dataset.",
      "processing_time": 61.51213598251343,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "For comparison, we investigated the performance of the following state-of-the-art methods: 1) DMCNN (Chen et al., 2015), which extracts multiple events from one sentence with dynamic multipooling CNN; 2) HBTNGMA (Chen et al., 2018), which models sentence event inter-dependency via a hierarchical…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions methods (DMCNN, HBTNGMA) but does not reference any specific datasets. The context focuses on comparing methods rather than using datasets.",
      "processing_time": 60.24871826171875,
      "citing_paper_id": "234790176",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "The existing event inter-dependency modeling methods (Chen et al., 2015, 2018; Liu et al., 2018) aim to extract multiple events jointly within a sentence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for event extraction and detection.",
      "processing_time": 57.675867795944214,
      "citing_paper_id": "234790176",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "The existing event inter-dependency modeling methods (Chen et al., 2015, 2018; Liu et al., 2018) aim to extract multiple events jointly within a sentence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for event extraction and detection.",
      "processing_time": 57.675867795944214,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "To address those issues, previous approaches (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Yan et al., 2019; Liu et al., 2019; Zhang et al., 2019) mainly focused on sentence-level event de-\ntection, neglecting the document-level event interdependency and semantic information.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only previous approaches and their focus on sentence-level event detection. No verifiable resources are identified.",
      "processing_time": 60.04873704910278,
      "citing_paper_id": "234790176",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "To address those issues, previous approaches (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Yan et al., 2019; Liu et al., 2019; Zhang et al., 2019) mainly focused on sentence-level event de-\ntection, neglecting the document-level event interdependency and semantic information.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only previous approaches and their focus on sentence-level event detection. No verifiable resources are identified.",
      "processing_time": 60.04873704910278,
      "citing_paper_id": "234790176",
      "cited_paper_id": 174799895
    },
    {
      "context_text": "The existing methods (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2017; Nguyen and Grishman, 2018; Deng et al., 2020; Tong et al., 2020; Lai et al., 2020; Liu et al., 2020; Li et al., 2020; Cui et al., 2020; Deng et al., 2021; Shen et al., 2021) mainly focus on sentence-level event…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to existing methods and their focus on sentence-level event extraction.",
      "processing_time": 58.93329358100891,
      "citing_paper_id": "234790176",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "The existing methods (Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2017; Nguyen and Grishman, 2018; Deng et al., 2020; Tong et al., 2020; Lai et al., 2020; Liu et al., 2020; Li et al., 2020; Cui et al., 2020; Deng et al., 2021; Shen et al., 2021) mainly focus on sentence-level event…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to existing methods and their focus on sentence-level event extraction.",
      "processing_time": 58.93329358100891,
      "citing_paper_id": "234790176",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "To address those issues, previous approaches (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Yan et al., 2019; Liu et al., 2019; Zhang et al., 2019) mainly focused on sentence-level event de-",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous approaches and their focus on sentence-level event detection.",
      "processing_time": 59.11221671104431,
      "citing_paper_id": "234790176",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "For comparison, we investigated the performance of the following state-of-the-art methods: 1) DMCNN (Chen et al., 2015), which extracts multiple events from one sentence with dynamic multipooling CNN; 2) HBTNGMA (Chen et al., 2018), which models sentence event inter-dependency via a hierarchical tagging model; 3) JMEE (Liu et al., 2018), which models the sentence-level event interdependency via a graph model of the sentence syntactic parsing graph; 4) DMBERT-Boot (Wang et al., 2019), which augments the training data with external unlabeled data by adversarial mechanism; 5) MOGANED (Yan et al., 2019), which uses graph convolution network with aggregative attention to explicitly model and aggregate multiorder syntactic representations; 6) SS-VQ-VAE (Huang and Ji, 2020), which learns to induct new event type by a semi-supervised vector quantized variational autoencoder framework, and fine-tunes with the pre-trained BERT-large model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models but does not refer to any specific datasets. The focus is on comparing different approaches to event extraction.",
      "processing_time": 59.38905167579651,
      "citing_paper_id": "234790176",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "For comparison, we investigated the performance of the following state-of-the-art methods: 1) DMCNN (Chen et al., 2015), which extracts multiple events from one sentence with dynamic multipooling CNN; 2) HBTNGMA (Chen et al., 2018), which models sentence event inter-dependency via a hierarchical tagging model; 3) JMEE (Liu et al., 2018), which models the sentence-level event interdependency via a graph model of the sentence syntactic parsing graph; 4) DMBERT-Boot (Wang et al., 2019), which augments the training data with external unlabeled data by adversarial mechanism; 5) MOGANED (Yan et al., 2019), which uses graph convolution network with aggregative attention to explicitly model and aggregate multiorder syntactic representations; 6) SS-VQ-VAE (Huang and Ji, 2020), which learns to induct new event type by a semi-supervised vector quantized variational autoencoder framework, and fine-tunes with the pre-trained BERT-large model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models but does not refer to any specific datasets. The focus is on comparing different approaches to event extraction.",
      "processing_time": 59.38905167579651,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "For comparison, we investigated the performance of the following state-of-the-art methods: 1) DMCNN (Chen et al., 2015), which extracts multiple events from one sentence with dynamic multipooling CNN; 2) HBTNGMA (Chen et al., 2018), which models sentence event inter-dependency via a hierarchical tagging model; 3) JMEE (Liu et al., 2018), which models the sentence-level event interdependency via a graph model of the sentence syntactic parsing graph; 4) DMBERT-Boot (Wang et al., 2019), which augments the training data with external unlabeled data by adversarial mechanism; 5) MOGANED (Yan et al., 2019), which uses graph convolution network with aggregative attention to explicitly model and aggregate multiorder syntactic representations; 6) SS-VQ-VAE (Huang and Ji, 2020), which learns to induct new event type by a semi-supervised vector quantized variational autoencoder framework, and fine-tunes with the pre-trained BERT-large model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models but does not refer to any specific datasets. The focus is on comparing different approaches to event extraction.",
      "processing_time": 59.38905167579651,
      "citing_paper_id": "234790176",
      "cited_paper_id": 174799895
    },
    {
      "context_text": "Among them, Chen et al. (2015) used dynamic multi-pooling CNN to preserve information of multiple events; Nguyen et al. (2016) utilized the bidirectional recurrent neural networks to extract events; Liu et al. (2018) introduced syntactic shortcut arcs to enhance information flow and used graph…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models used for event extraction.",
      "processing_time": 58.384570837020874,
      "citing_paper_id": "234790176",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "For comparison, we investigated the performance of the following state-of-the-art methods: 1) DMCNN (Chen et al., 2015), which extracts multiple events from one sentence with dynamic multipooling CNN; 2) HBTNGMA (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions methods (DMCNN, HBTNGMA) but does not reference any specific datasets. The citation is focused on comparing methods rather than using datasets.",
      "processing_time": 60.698747634887695,
      "citing_paper_id": "234790176",
      "cited_paper_id": 14339673
    },
    {
      "context_text": ", 2015), which extracts multiple events from one sentence with dynamic multipooling CNN; 2) HBTNGMA (Chen et al., 2018), which models sentence event inter-dependency via a hierarchical tagging model; 3) JMEE (Liu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No dataset names are present in the text.",
      "processing_time": 59.178226470947266,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "An alternative method modeling the sentencelevel event inter-dependency called hierarchical tagging layer is proposed by (Chen et al., 2018).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for modeling sentence-level event inter-dependency.",
      "processing_time": 58.48035740852356,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "When only information of current sentence is available, the 1-layer MLBiNet outperforms HBTNGMA by 2.9 points.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between two models. There are no verifiable resources or datasets mentioned.",
      "processing_time": 59.551008224487305,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "…events; Liu et al. (2018) introduced syntactic shortcut arcs to enhance information flow and used graph neural networks to model graph information; Chen et al. (2018) proposed a hierarchical tagging LSTM layer and tagging attention mechanism to model the event interdependency within a sentence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on describing various approaches to event detection and modeling.",
      "processing_time": 59.59864091873169,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "Intra-sentence and inter-sentence event inter-dependency modeling (Liao and Grishman, 2010; Chen et al., 2018; Liu et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and research works.",
      "processing_time": 58.15535044670105,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "collectively detecting multiple events (Chen et al., 2018; Liu et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods or approaches for collective event detection.",
      "processing_time": 58.31787395477295,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "Sentence-level contextual representation and document-level information aggregation (Chen et al., 2018; Zhao et al., 2018;\n∗ Equal contribution and shared co-first authorship.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. No dataset names are present in the text.",
      "processing_time": 59.22833466529846,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "…state-of-the-art methods: 1) DMCNN (Chen et al., 2015), which extracts multiple events from one sentence with dynamic multipooling CNN; 2) HBTNGMA (Chen et al., 2018), which models sentence event inter-dependency via a hierarchical tagging model; 3) JMEE (Liu et al., 2018), which models the…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 59.40817928314209,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "For a given sentence, the event tags corresponding to tokens are associated, which is important for collectively detecting multiple events (Chen et al., 2018; Liu et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods or approaches for event detection.",
      "processing_time": 58.1205780506134,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "Some studies (Chen et al., 2018; Zhao et al., 2018) tried to integrate semantic information across sentences via the attention mechanism.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on integrating semantic information across sentences using attention mechanisms.",
      "processing_time": 59.96594023704529,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "Chen et al. (2018) integrated document information by introducing a multi-level attention.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving multi-level attention.",
      "processing_time": 57.960750579833984,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "It proves that the hierarchical tagging mechanism adopted by HBTNGMA is not as effective as the bidirectional decoding mechanism we proposed.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between two mechanisms. No verifiable resources are identified.",
      "processing_time": 58.815128326416016,
      "citing_paper_id": "234790176",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "…graph; 4) DMBERT-Boot (Wang et al., 2019), which augments the training data with external unlabeled data by adversarial mechanism; 5) MOGANED (Yan et al., 2019), which uses graph convolution network with aggregative attention to explicitly model and aggregate multiorder syntactic…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on describing different approaches and models used for event detection.",
      "processing_time": 60.64582371711731,
      "citing_paper_id": "234790176",
      "cited_paper_id": 174799895
    },
    {
      "context_text": "…2015; Liu et al., 2017; Nguyen and Grishman, 2018; Deng et al., 2020; Tong et al., 2020; Lai et al., 2020; Liu et al., 2020; Li et al., 2020; Cui et al., 2020; Deng et al., 2021; Shen et al., 2021) mainly focus on sentence-level event trigger extraction, neglecting the document information.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies focusing on sentence-level event trigger extraction.",
      "processing_time": 59.74481010437012,
      "citing_paper_id": "234790176",
      "cited_paper_id": 222008363
    },
    {
      "context_text": "(Huang and Ji, 2020), which learns to induct new event type by a semi-supervised vector quantized variational autoencoder framework, and fine-tunes with the pre-trained BERT-large model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method and a model. The context focuses on the methodology and the use of BERT-large for fine-tuning.",
      "processing_time": 61.5075204372406,
      "citing_paper_id": "234790176",
      "cited_paper_id": 226262360
    },
    {
      "context_text": "The performance comparison of prompts constructed by the two different strategy on the Strate-gyQA (Geva et al., 2021) and SST-2 (Socher et al., 2013) datasets is illustrated in Figure 4.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "StrategyQA",
        "SST-2"
      ],
      "dataset_descriptions": {
        "StrategyQA": "Used to compare the performance of prompts constructed using different strategies, focusing on implicit reasoning questions.",
        "SST-2": "Used to evaluate sentiment classification performance, comparing different prompting strategies on sentiment analysis tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, StrategyQA and SST-2, which are used for performance comparison of different prompting strategies.",
      "processing_time": 70.04908084869385,
      "citing_paper_id": "265149752",
      "cited_paper_id": 990233
    },
    {
      "context_text": "The performance comparison of prompts constructed by the two different strategy on the Strate-gyQA (Geva et al., 2021) and SST-2 (Socher et al., 2013) datasets is illustrated in Figure 4.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "StrategyQA",
        "SST-2"
      ],
      "dataset_descriptions": {
        "StrategyQA": "Used to compare the performance of prompts constructed using different strategies, focusing on implicit reasoning questions.",
        "SST-2": "Used to evaluate sentiment classification performance, comparing different prompting strategies on sentiment analysis tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, StrategyQA and SST-2, which are used for performance comparison of different prompting strategies.",
      "processing_time": 70.04908084869385,
      "citing_paper_id": "265149752",
      "cited_paper_id": 230799347
    },
    {
      "context_text": "In addressing RQ3 , we have extended our HD-LoA prompting method to sentiment analysis (SA) and natural language inference (NLI) tasks, utilizing the SST-2 (Socher et al., 2013) and SNLI (Bow-man et al., 2015) datasets for evaluation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SST-2",
        "SNLI"
      ],
      "dataset_descriptions": {
        "SST-2": "Used to evaluate the HD-LoA prompting method on sentiment analysis, focusing on fine-grained sentiment classification of movie reviews.",
        "SNLI": "Used to evaluate the HD-LoA prompting method on natural language inference, assessing the ability to determine the relationship between sentence pairs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions SST-2 and SNLI as datasets used for evaluating the HD-LoA prompting method on sentiment analysis and natural language inference tasks.",
      "processing_time": 73.70954084396362,
      "citing_paper_id": "265149752",
      "cited_paper_id": 990233
    },
    {
      "context_text": "Additionally, we utilize the SST-2 (Socher et al., 2013) and SNLI (Bowman et al., 2015) datasets to assess the effectiveness of our HD-LoA prompting strategy on other non-reasoning tasks: sentiment analysis and natural language inference.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SST-2",
        "SNLI"
      ],
      "dataset_descriptions": {
        "SST-2": "Used to evaluate the effectiveness of the HD-LoA prompting strategy on sentiment analysis, assessing model performance on fine-grained sentiment classification.",
        "SNLI": "Used to evaluate the effectiveness of the HD-LoA prompting strategy on natural language inference, assessing model performance on entailment, contradiction, and neutral relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions SST-2 and SNLI datasets, which are used to evaluate the effectiveness of the HD-LoA prompting strategy on sentiment analysis and natural language inference tasks.",
      "processing_time": 76.23361444473267,
      "citing_paper_id": "265149752",
      "cited_paper_id": 990233
    },
    {
      "context_text": "63% on SST-2 and SNLI datasets, respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SST-2",
        "SNLI"
      ],
      "dataset_descriptions": {
        "SST-2": "Used to evaluate sentiment classification performance, focusing on binary sentiment analysis of movie reviews using a treebank structure.",
        "SNLI": "Used to assess natural language inference performance, evaluating the ability to determine the relationship between premise and hypothesis sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions SST-2 and SNLI datasets, which are commonly used for sentiment analysis and natural language inference tasks. These are specific, verifiable datasets.",
      "processing_time": 72.51659345626831,
      "citing_paper_id": "265149752",
      "cited_paper_id": 990233
    },
    {
      "context_text": "Cognitive science studies reveals that humans perform analogical reasoning through a sequence of retrieval , mapping , and evaluation (Gentner and Forbus, 2011; Gentner and Markman, 1997).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only cognitive science studies and computational models. No verifiable resources are identified.",
      "processing_time": 59.9769606590271,
      "citing_paper_id": "265149752",
      "cited_paper_id": 3446415
    },
    {
      "context_text": "Cognitive science studies reveals that humans perform analogical reasoning through a sequence of retrieval , mapping , and evaluation (Gentner and Forbus, 2011; Gentner and Markman, 1997).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only cognitive science studies and computational models. No verifiable resources are identified.",
      "processing_time": 59.9769606590271,
      "citing_paper_id": "265149752",
      "cited_paper_id": 16482483
    },
    {
      "context_text": "Similarly, in supervised machine learning (ML) systems, models also learn task-specific patterns through training (Shachaf et al., 2021; Najafabadi et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts about supervised machine learning.",
      "processing_time": 58.46643948554993,
      "citing_paper_id": "265149752",
      "cited_paper_id": 11392154
    },
    {
      "context_text": "For example, students often solve new problems by mapping solutions from known problems (Ross, 1987).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to a general concept of problem-solving.",
      "processing_time": 59.24376201629639,
      "citing_paper_id": "265149752",
      "cited_paper_id": 144823696
    },
    {
      "context_text": "Document-level Event Argument Extraction (EAE) aims to transform unstructured event information from documents into structured formats encapsulating event arguments, facilitating their interpretation and application in various domains (Grishman, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to the field of information extraction.",
      "processing_time": 59.245760440826416,
      "citing_paper_id": "265149752",
      "cited_paper_id": 203701085
    },
    {
      "context_text": "EEQA (Du and Cardie, 2020b) 19.54 PAIE (Ma et al., 2022) 29.86 TSAR (Xu et al., 2022) - 26.67 - - CRP (Liu et al., 2023a) 30.09 FewDocAE (Yang et al., RQ2 Can HD-LoA prompting effectively mitigate the dependency on extensive labeled data while enhancing accuracy for EAE task?",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models or methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 60.55908203125,
      "citing_paper_id": "265149752",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "EEQA (Du and Cardie, 2020b) 19.54 PAIE (Ma et al., 2022) 29.86 TSAR (Xu et al., 2022) - 26.67 - - CRP (Liu et al., 2023a) 30.09 FewDocAE (Yang et al., RQ2 Can HD-LoA prompting effectively mitigate the dependency on extensive labeled data while enhancing accuracy for EAE task?",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models or methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 60.55908203125,
      "citing_paper_id": "265149752",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Additionally, we compare our method with various supervised learning methods in EAE, such as Few-DocAE (Yang et al., 2023), CRP (Liu et al., 2023a), PAIE (Ma et al., 2022), TSAR (Xu et al., 2022), EEQA (Du and Cardie, 2020b), etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions several methods/models but does not refer to any specific datasets. The context is focused on comparing the performance of different methods in event argument extraction.",
      "processing_time": 61.10875844955444,
      "citing_paper_id": "265149752",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Additionally, we compare our method with various supervised learning methods in EAE, such as Few-DocAE (Yang et al., 2023), CRP (Liu et al., 2023a), PAIE (Ma et al., 2022), TSAR (Xu et al., 2022), EEQA (Du and Cardie, 2020b), etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions several methods/models but does not refer to any specific datasets. The context is focused on comparing the performance of different methods in event argument extraction.",
      "processing_time": 61.10875844955444,
      "citing_paper_id": "265149752",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "The prevalent approach for this task relies on the collection of labeled data and the subsequent model training via supervised learning (Ren et al., 2023; Liu et al., 2023a; Pouran Ben Veyseh et al., 2022; Zhou and Mao, 2022; Du and Cardie, 2020a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach involving labeled data and supervised learning.",
      "processing_time": 59.33595037460327,
      "citing_paper_id": "265149752",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "The prevalent approach for this task relies on the collection of labeled data and the subsequent model training via supervised learning (Ren et al., 2023; Liu et al., 2023a; Pouran Ben Veyseh et al., 2022; Zhou and Mao, 2022; Du and Cardie, 2020a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach involving labeled data and supervised learning.",
      "processing_time": 59.33595037460327,
      "citing_paper_id": "265149752",
      "cited_paper_id": 250390478
    },
    {
      "context_text": "The prevalent approach for this task relies on the collection of labeled data and the subsequent model training via supervised learning (Ren et al., 2023; Liu et al., 2023a; Pouran Ben Veyseh et al., 2022; Zhou and Mao, 2022; Du and Cardie, 2020a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach involving labeled data and supervised learning.",
      "processing_time": 59.33595037460327,
      "citing_paper_id": "265149752",
      "cited_paper_id": 259370571
    },
    {
      "context_text": "The experiments are carried out using three large language models: the publicly available GPT-3 (Brown et al., 2020) in its text-davinci-003 and gpt-3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models but does not refer to any specific datasets. The context is about using language models for experiments, which does not align with the criteria for extracting datasets.",
      "processing_time": 61.54517197608948,
      "citing_paper_id": "265149752",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "In this context, in-context learning (ICL) (Brown et al., 2020; Liu et al., 2022; Zhou et al., 2022), an emergent ability of large language models (LLMs), offers a promising alternative to supervised learning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The focus is on in-context learning and large language models.",
      "processing_time": 60.41359829902649,
      "citing_paper_id": "265149752",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "In this context, in-context learning (ICL) (Brown et al., 2020; Liu et al., 2022; Zhou et al., 2022), an emergent ability of large language models (LLMs), offers a promising alternative to supervised learning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The focus is on in-context learning and large language models.",
      "processing_time": 60.41359829902649,
      "citing_paper_id": "265149752",
      "cited_paper_id": 248986239
    },
    {
      "context_text": "We use 500 test samples from the StrategyQA (Geva et al., 2021) dataset and the prompt from Shum et al. (2023) for evaluation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "StrategyQA"
      ],
      "dataset_descriptions": {
        "StrategyQA": "Used to evaluate 500 test samples, focusing on implicit reasoning strategies in question answering."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the StrategyQA dataset, which is a specific, verifiable resource. It is used for evaluating test samples, and the citation intent is to reference a reusable resource.",
      "processing_time": 66.59056162834167,
      "citing_paper_id": "265149752",
      "cited_paper_id": 230799347
    },
    {
      "context_text": "The WIKIEVENTS dataset (Li et al., 2021) is excluded from our study because it relies on preprocessed entity candidates for annotating event arguments the annotation, which diverges from the direct ar-gument identification of LLMs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKIEVENTS"
      ],
      "dataset_descriptions": {
        "WIKIEVENTS": "Excluded from the study due to reliance on preprocessed entity candidates, which diverges from the direct argument identification approach of LLMs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the WIKIEVENTS dataset and explains why it is excluded from the study, providing a clear reason related to its preprocessing method.",
      "processing_time": 68.24114108085632,
      "citing_paper_id": "265149752",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "The ICL performance is highly sensitive to the design of in-context demonstrations, such as the selection of examples and the formatting of reasoning steps (Zhang et al., 2023, 2022; Fu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the sensitivity of ICL performance to in-context demonstrations. No verifiable resources are identified.",
      "processing_time": 60.485185384750366,
      "citing_paper_id": "265149752",
      "cited_paper_id": 246426909
    },
    {
      "context_text": "For evaluation, we follow the metrics in (Ma et al., 2022), namely the argument identification F1 score (Arg-I), and the argument classification F1 score (Arg-C).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. The context is focused on the metrics used for evaluation rather than the datasets.",
      "processing_time": 60.66182327270508,
      "citing_paper_id": "265149752",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "The example selection process of ICL is often an indiscriminate, manual process (Liu et al., 2023b; Wei et al., 2022; Zhou et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or processes. There are no clear identifiers for datasets in the context.",
      "processing_time": 60.06718397140503,
      "citing_paper_id": "265149752",
      "cited_paper_id": 248986239
    },
    {
      "context_text": "Neverthe-less, HD-LoA prompting demonstrates competitive performance against supervised methods and even outperform these extensively trained models on the DocEE dataset in the cross-domain setting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to evaluate the performance of HD-LoA prompting in a cross-domain setting, specifically comparing it against supervised methods and extensively trained models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocEE dataset' which is a specific dataset used for document-level event extraction. The dataset is used to evaluate the performance of HD-LoA prompting in a cross-domain setting.",
      "processing_time": 69.41856336593628,
      "citing_paper_id": "265149752",
      "cited_paper_id": 250264890
    },
    {
      "context_text": "Therefore, un-derstandings of supervised ML systems (e.g. pattern learning) are not applicable for ICL (Min et al., 2022; Akyürek et al., 2022), which necessitates distinct explorations on the mechanism of ICL.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to supervised ML systems and ICL. No verifiable resources are identified.",
      "processing_time": 60.532628774642944,
      "citing_paper_id": "265149752",
      "cited_paper_id": 254043800
    },
    {
      "context_text": "We consider an argument span to be correctly identiﬁed if its offsets match any of the gold/reference informative arguments of the current event (i.e., argument identiﬁcation); and it is correctly classiﬁed if its semantic role also matches (i.e., argument classiﬁcation) (Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses evaluation criteria for argument identification and classification.",
      "processing_time": 59.137112617492676,
      "citing_paper_id": "248780117",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Apart from event extraction, in the future, it’s worth investigating how to leverage the global memory idea for other document-level IE problems like (N ary) relation extraction (Quirk and Poon, 2017; Yao et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only future research directions and related work.",
      "processing_time": 58.944499015808105,
      "citing_paper_id": "248780117",
      "cited_paper_id": 15359942
    },
    {
      "context_text": ", 2021) and ignores the global context partially because of the pretrained models’ length limit and their lack of attention for distant context (Khandelwal et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses limitations of pretrained models.",
      "processing_time": 58.941022872924805,
      "citing_paper_id": "248780117",
      "cited_paper_id": 21700944
    },
    {
      "context_text": "(Shi and Lin, 2019) is a popular baseline for semantic role labeling (predicate-argument prediction).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (baseline for semantic role labeling).",
      "processing_time": 59.61275362968445,
      "citing_paper_id": "248780117",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Bosselut et al. (2019) use generative language models to generate new event knowledge based on crowdsourced triples.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only generative language models and crowdsourced triples. No clear, verifiable dataset names are provided.",
      "processing_time": 60.313554525375366,
      "citing_paper_id": "248780117",
      "cited_paper_id": 189762527
    },
    {
      "context_text": "Apart from event extraction, in the future, it’s worth investigating how to leverage the global memory idea for other document-level IE problems like ( N -ary) relation extraction (Quirk and Poon, 2017; Yao et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a general reference to document-level relation extraction. No clear, verifiable datasets are identified.",
      "processing_time": 60.75736403465271,
      "citing_paper_id": "248780117",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "To retrieve the most relevant “event” (i.e., a generated sequence) from the memory store m = { m 1 , m 2 , ... } , we use S-BERT (Reimers and Gurevych, 2019) for dense retrieval (i.e., retrieval with dense representations provided by NN).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (S-BERT) for dense retrieval. No datasets are referenced or used.",
      "processing_time": 60.58008360862732,
      "citing_paper_id": "248780117",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "S-BERT is a modiﬁcation of the BERT model (Devlin et al., 2019) that uses siamese and triplet network structures to obtain semantically meaningful embeddings for text sequences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a modification of the BERT model. No verifiable resources are identified.",
      "processing_time": 60.30440425872803,
      "citing_paper_id": "248780117",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "Since we ﬁx the parameters from S-BERT, the retrieval module’s parameters are not updated during training.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (S-BERT) which is not a dataset.",
      "processing_time": 59.91083288192749,
      "citing_paper_id": "248780117",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "Event Extraction has long been studied as a local sentence-level task (Grishman and Sundheim, 1996; Ji and Grishman, 2008b; Grishman, 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies and papers. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 61.78127431869507,
      "citing_paper_id": "248780117",
      "cited_paper_id": 203701085
    },
    {
      "context_text": "• As compared to the raw BART-Gen, with our memory-based training – leveraging previously closest extracted event information substantially helps increase precision (P) and F-1 scores, with smaller but notable improvement in recall especially under Coref Match.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (memory-based training) and a model (BART-Gen).",
      "processing_time": 60.69343185424805,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Our best model with argu-ment pair constrained decoding outperforms substantially both BART-Gen and our memory-based training model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and performance comparisons.",
      "processing_time": 58.82137680053711,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Following Li et al. (2021), the main model of our framework is based on the pretrained encoder-decoder model BART (Lewis et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BART, which is a pretrained model, not a dataset. No datasets are explicitly mentioned or used in the given citation context.",
      "processing_time": 61.54900574684143,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "We observe that: • The neural generation-based models (BART-Gen and our framework) are superior in this document-level informative argument extraction problem, as compared to the sequence labeling-based approaches.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance in a document-level informative argument extraction task.",
      "processing_time": 60.33339524269104,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Li et al. (2021) propose to use conditional neural text generation model for the document-level argument extraction problem, it handles each event in isolation ( BART-Gen ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BART-Gen but does not refer to it as a dataset. It is described as a model or method for document-level argument extraction.",
      "processing_time": 61.54383373260498,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "(2021), the main model of our framework is based on the pretrained encoderdecoder model BART (Lewis et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions BART, which is a pretrained model, not a dataset. No datasets are explicitly mentioned or used in the given context.",
      "processing_time": 60.88499140739441,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "The intuition behind using BART for the extraction task is that it is pre-trained as a denoising autoencoder – reconstruct the original input sequence.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BART, which is a model and not a dataset.",
      "processing_time": 60.500778913497925,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "To support the progress for the problem, Ebner et al. (2020) built RAMS dataset, and it contains annotations for cross-sentence arguments but for each document it contains only one event.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to support document-level event extraction, specifically focusing on cross-sentence argument linking with annotations, but limited to one event per document."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for document-level event extraction. The dataset is described as containing annotations for cross-sentence arguments but limited to one event per document.",
      "processing_time": 70.06706190109253,
      "citing_paper_id": "248780117",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "In recent years, there have been efforts focusing on event extraction beyond sentence boundaries with end-to-end learning (Ebner et al., 2020; Du, 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research efforts in event extraction beyond sentence boundaries.",
      "processing_time": 60.093186140060425,
      "citing_paper_id": "248780117",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "In recent years, there have been efforts focusing on event extraction beyond sentence boundaries with end-to-end learning (Ebner et al., 2020; Du, 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research efforts in event extraction beyond sentence boundaries.",
      "processing_time": 60.093186140060425,
      "citing_paper_id": "248780117",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "In recent years, there have been efforts focusing on event extraction beyond sentence boundaries with end-to-end learning (Ebner et al., 2020; Du, 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research efforts in event extraction beyond sentence boundaries.",
      "processing_time": 60.093186140060425,
      "citing_paper_id": "248780117",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "In recent years, there have been efforts focusing on event extraction beyond sentence boundaries with end-to-end learning (Ebner et al., 2020; Du, 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research efforts in event extraction beyond sentence boundaries.",
      "processing_time": 60.093186140060425,
      "citing_paper_id": "248780117",
      "cited_paper_id": 247797575
    },
    {
      "context_text": ", 2019) and uses Conditional Random Fields (Lafferty et al., 2001) for structured prediction (BERT-CRF).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Conditional Random Fields) and a model (BERT-CRF).",
      "processing_time": 60.69474482536316,
      "citing_paper_id": "248780117",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "It performs sequence labeling based on automatically extracted features from BERT (Devlin et al., 2019) and uses Conditional Random Fields (Lafferty et al., 2001) for structured prediction ( BERT-CRF ).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and CRF but does not refer to any specific dataset. BERT is a model, and CRF is a method, so they are excluded.",
      "processing_time": 62.40177321434021,
      "citing_paper_id": "248780117",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "For example, if one person has been identified as a JAILER in an event, it’s unlikely that the same person is an ATTACKER in another event in the document (Figure 1), according to world event knowledge (Sap et al., 2019; Yao et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to world event knowledge which is not a verifiable dataset.",
      "processing_time": 60.515095472335815,
      "citing_paper_id": "248780117",
      "cited_paper_id": 226262410
    },
    {
      "context_text": "For example, if one person has been identified as a JAILER in an event, it’s unlikely that the same person is an ATTACKER in another event in the document (Figure 1), according to world event knowledge (Sap et al., 2019; Yao et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to world event knowledge which is not a verifiable dataset.",
      "processing_time": 60.515095472335815,
      "citing_paper_id": "248780117",
      "cited_paper_id": null
    },
    {
      "context_text": "Yao et al. (2020) propose a weakly-supervised approach to extract sub-event relation tuples from the text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach.",
      "processing_time": 59.12865352630615,
      "citing_paper_id": "248780117",
      "cited_paper_id": 226262410
    },
    {
      "context_text": "For example, if one person has been identiﬁed as a JAILER in an event, it’s unlikely that the same person is an ATTACKER in another event in the document (Figure 1), according to world event knowledge (Sap et al., 2019; Yao et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to world event knowledge which is not a verifiable resource.",
      "processing_time": 60.51724123954773,
      "citing_paper_id": "248780117",
      "cited_paper_id": 226262410
    },
    {
      "context_text": "For example, if one person has been identiﬁed as a JAILER in an event, it’s unlikely that the same person is an ATTACKER in another event in the document (Figure 1), according to world event knowledge (Sap et al., 2019; Yao et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to world event knowledge which is not a verifiable resource.",
      "processing_time": 60.51724123954773,
      "citing_paper_id": "248780117",
      "cited_paper_id": null
    },
    {
      "context_text": "Sap et al. (2019) propose to use crowdsourcing for obtaining if-then relations be-tween events.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for obtaining if-then relations between events using crowdsourcing.",
      "processing_time": 60.51436233520508,
      "citing_paper_id": "248780117",
      "cited_paper_id": null
    },
    {
      "context_text": "…extraction and veriﬁcation (Thorne et al., 2018), reading comprehension (Nguyen et al., 2016; Joshi et al., 2017; Lai et al., 2017), sentiment classiﬁcation (Pang and Lee, 2004; Pret-tenhofer and Stein, 2010), summarization (Nalla-pati et al., 2016) and machine translation (Zhang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and methods. No dataset names are present in the context.",
      "processing_time": 61.215145111083984,
      "citing_paper_id": "189898081",
      "cited_paper_id": 388
    },
    {
      "context_text": "…extraction and veriﬁcation (Thorne et al., 2018), reading comprehension (Nguyen et al., 2016; Joshi et al., 2017; Lai et al., 2017), sentiment classiﬁcation (Pang and Lee, 2004; Pret-tenhofer and Stein, 2010), summarization (Nalla-pati et al., 2016) and machine translation (Zhang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and methods. No dataset names are present in the context.",
      "processing_time": 61.215145111083984,
      "citing_paper_id": "189898081",
      "cited_paper_id": 52938038
    },
    {
      "context_text": "Many efforts have been devoted to alleviating the wrong labeling problem in sentence-level RE (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012; Lin et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research efforts addressing wrong labeling in sentence-level relation extraction.",
      "processing_time": 60.84064078330994,
      "citing_paper_id": "189898081",
      "cited_paper_id": 397533
    },
    {
      "context_text": "Many efforts have been devoted to alleviating the wrong labeling problem in sentence-level RE (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012; Lin et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research efforts addressing wrong labeling in sentence-level relation extraction.",
      "processing_time": 60.84064078330994,
      "citing_paper_id": "189898081",
      "cited_paper_id": 2386383
    },
    {
      "context_text": "…explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-the-art performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and models used for relation extraction. No verifiable resources are identified.",
      "processing_time": 61.51580739021301,
      "citing_paper_id": "189898081",
      "cited_paper_id": 397533
    },
    {
      "context_text": "…explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-the-art performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and models used for relation extraction. No verifiable resources are identified.",
      "processing_time": 61.51580739021301,
      "citing_paper_id": "189898081",
      "cited_paper_id": 1774259
    },
    {
      "context_text": "…explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-the-art performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and models used for relation extraction. No verifiable resources are identified.",
      "processing_time": 61.51580739021301,
      "citing_paper_id": "189898081",
      "cited_paper_id": 18795469
    },
    {
      "context_text": "…explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-the-art performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and models used for relation extraction. No verifiable resources are identified.",
      "processing_time": 61.51580739021301,
      "citing_paper_id": "189898081",
      "cited_paper_id": 34190303
    },
    {
      "context_text": "…explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-the-art performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and models used for relation extraction. No verifiable resources are identified.",
      "processing_time": 61.51580739021301,
      "citing_paper_id": "189898081",
      "cited_paper_id": 53079972
    },
    {
      "context_text": "…explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-the-art performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and models used for relation extraction. No verifiable resources are identified.",
      "processing_time": 61.51580739021301,
      "citing_paper_id": "189898081",
      "cited_paper_id": 53080736
    },
    {
      "context_text": "…various neural models have been explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-the-art performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various neural models and their performance in sentence-level relation extraction.",
      "processing_time": 60.95509719848633,
      "citing_paper_id": "189898081",
      "cited_paper_id": 806709
    },
    {
      "context_text": "In recent years, various neural models have been explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-theart performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span discusses various neural models and their performance in sentence-level relation extraction but does not mention any specific datasets.",
      "processing_time": 60.580448389053345,
      "citing_paper_id": "189898081",
      "cited_paper_id": 1774259
    },
    {
      "context_text": "In recent years, various neural models have been explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-theart performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span discusses various neural models and their performance in sentence-level relation extraction but does not mention any specific datasets.",
      "processing_time": 60.580448389053345,
      "citing_paper_id": "189898081",
      "cited_paper_id": 18795469
    },
    {
      "context_text": "In recent years, various neural models have been explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-theart performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span discusses various neural models and their performance in sentence-level relation extraction but does not mention any specific datasets.",
      "processing_time": 60.580448389053345,
      "citing_paper_id": "189898081",
      "cited_paper_id": 34190303
    },
    {
      "context_text": "In recent years, various neural models have been explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-theart performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span discusses various neural models and their performance in sentence-level relation extraction but does not mention any specific datasets.",
      "processing_time": 60.580448389053345,
      "citing_paper_id": "189898081",
      "cited_paper_id": 53079972
    },
    {
      "context_text": ", 2014) based model, an LSTM (Hochreiter and Schmidhuber, 1997) based model, a bidirectional LSTM (BiLSTM) (Cai et al., 2016) based model and the Context-Aware model (Sorokin and Gurevych, 2017) originally",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 61.100947856903076,
      "citing_paper_id": "189898081",
      "cited_paper_id": 1774259
    },
    {
      "context_text": "…RE scenario, including a CNN (Zeng et al., 2014) based model, an LSTM (Hochreiter and Schmidhuber, 1997) based model, a bidirectional LSTM (BiLSTM) (Cai et al., 2016) based model and the Context-Aware model (Sorokin and Gurevych, 2017) originally designed for leveraging contextual relations to…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 60.39206600189209,
      "citing_paper_id": "189898081",
      "cited_paper_id": 1774259
    },
    {
      "context_text": "For each word, the features fed to the encoder is the concatenation of its GloVe word embedding (Pennington et al., 2014), entity type embedding and coreference embedding.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions GloVe word embeddings but does not refer to a specific dataset. GloVe is a method for generating word embeddings, not a dataset.",
      "processing_time": 61.39591884613037,
      "citing_paper_id": "189898081",
      "cited_paper_id": 1957433
    },
    {
      "context_text": "…have been explored to encode relational patterns of entities for sentence-level RE, and achieve state-of-the-art performance (Socher et al., 2012; Zeng et al., 2014, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and research works. No verifiable resources are identified.",
      "processing_time": 60.89640712738037,
      "citing_paper_id": "189898081",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "However, these datasets are either constructed via distant supervision (Quirk and Poon, 2017; Peng et al., 2017) with inevitable wrong labeling problem, or limited in specific domain (Li et al., 2016; Peng et al., 2017).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions datasets but does not provide specific names. It only describes their construction methods and limitations.",
      "processing_time": 59.50232005119324,
      "citing_paper_id": "189898081",
      "cited_paper_id": 2797612
    },
    {
      "context_text": "Quirk and Poon (2017) and Peng et al. (2017) build two distantly supervised datasets without human annotation, which may make the evaluation less reliable.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions two distantly supervised datasets but does not provide specific names. The datasets are implied to be part of the works by Quirk and Poon (2017) and Peng et al. (2017).",
      "processing_time": 64.54587697982788,
      "citing_paper_id": "189898081",
      "cited_paper_id": 2797612
    },
    {
      "context_text": "Swampillai and Stevenson (2010) and Verga et al. (2018) have also reported similar observations.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works. There is no indication of dataset usage or specific data sources.",
      "processing_time": 61.039918184280396,
      "citing_paper_id": "189898081",
      "cited_paper_id": 3576631
    },
    {
      "context_text": "…trend for many areas, including document-level event extraction (Walker et al., 2006; Mitamura et al., 2015, 2017), fact extraction and veriﬁcation (Thorne et al., 2018), reading comprehension (Nguyen et al., 2016; Joshi et al., 2017; Lai et al., 2017), sentiment classiﬁcation (Pang and Lee,…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FEVER"
      ],
      "dataset_descriptions": {
        "FEVER": "Used for fact extraction and verification, providing a large-scale dataset to support research in verifying claims against textual evidence."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several research areas but does not specify any particular dataset names. The only potentially relevant dataset is 'FEVER', which is mentioned in the cited paper title. However, the context does not explicitly state that FEVER is used for document-level event extraction.",
      "processing_time": 71.54065918922424,
      "citing_paper_id": "189898081",
      "cited_paper_id": 4711425
    },
    {
      "context_text": "To select documents for human annotation, we align Wikipedia documents with Wikidata under the distant supervision assumption (Mintz et al., 2009).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Wikipedia' and 'Wikidata' but does not refer to them as datasets. The focus is on the method of aligning these sources for distant supervision.",
      "processing_time": 61.82090163230896,
      "citing_paper_id": "189898081",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "…research from sentence level to document level is a popular trend for many areas, including document-level event extraction (Walker et al., 2006; Mitamura et al., 2015, 2017), fact extraction and veriﬁcation (Thorne et al., 2018), reading comprehension (Nguyen et al., 2016; Joshi et al., 2017;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general trends and areas of research. The cited papers' titles do not provide additional information about specific datasets.",
      "processing_time": 62.218931436538696,
      "citing_paper_id": "189898081",
      "cited_paper_id": 43923561
    },
    {
      "context_text": "…research from sentence level to document level is a popular trend for many areas, including document-level event extraction (Walker et al., 2006; Mitamura et al., 2015, 2017), fact extraction and veriﬁcation (Thorne et al., 2018), reading comprehension (Nguyen et al., 2016; Joshi et al., 2017;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general trends and areas of research. The cited papers' titles do not provide additional information about specific datasets.",
      "processing_time": 62.218931436538696,
      "citing_paper_id": "189898081",
      "cited_paper_id": 44123322
    },
    {
      "context_text": "As a result, RE systems that model context information with algorithms of quadratic or even higher computational complexity such as (Sorokin and Gurevych, 2017; Christopoulou et al., 2018) are not efﬁcient enough for document-level RE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and their computational complexity. No verifiable resources are identified.",
      "processing_time": 60.19810247421265,
      "citing_paper_id": "189898081",
      "cited_paper_id": 51877560
    },
    {
      "context_text": "identified using Bidirectional Encoder Representations from Transformers (BERT) (Devlin et al., 2019) that is fine-tuned on the human-annotated data collected in Sec.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'human-annotated data' but does not provide a specific name or identifier for the dataset. The citation is primarily about the method (BERT) rather than a specific dataset.",
      "processing_time": 63.04380655288696,
      "citing_paper_id": "189898081",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Table 1 shows statistics of DocRED and some representative RE datasets, including sentence-level RE datasets SemEval-2010 Task 8 (Hendrickx et al., 2010), ACE 2003-2004 (Dod-dington et al., 2004), TACRED (Zhang et al., 2017), FewRel (Han et al., 2018b) and document-level RE dataset BC5CDR (Li et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "SemEval-2010 Task 8",
        "ACE 2003-2004",
        "TACRED",
        "FewRel",
        "BC5CDR"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to compare document-level relation extraction performance, focusing on complex relations across multiple sentences.",
        "SemEval-2010 Task 8": "Used to evaluate sentence-level relation extraction, providing a benchmark for binary relation classification.",
        "ACE 2003-2004": "Used to assess sentence-level relation extraction, focusing on named entity relations in news articles.",
        "TACRED": "Used to evaluate sentence-level relation extraction, providing a large-scale dataset for relation classification in diverse domains.",
        "FewRel": "Used to test few-shot relation classification, focusing on the ability to generalize from limited labeled examples.",
        "BC5CDR": "Used to evaluate document-level relation extraction, focusing on chemical and disease relations in biomedical texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets used for relation extraction, including document-level and sentence-level datasets. These datasets are clearly identified and used for comparison in the research.",
      "processing_time": 98.11056590080261,
      "citing_paper_id": "189898081",
      "cited_paper_id": 53079972
    },
    {
      "context_text": "Table 1 shows statistics of DocRED and some representative RE datasets, including sentence-level RE datasets SemEval-2010 Task 8 (Hendrickx et al., 2010), ACE 2003-2004 (Dod-dington et al., 2004), TACRED (Zhang et al., 2017), FewRel (Han et al., 2018b) and document-level RE dataset BC5CDR (Li et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "SemEval-2010 Task 8",
        "ACE 2003-2004",
        "TACRED",
        "FewRel",
        "BC5CDR"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to compare document-level relation extraction performance, focusing on complex relations across multiple sentences.",
        "SemEval-2010 Task 8": "Used to evaluate sentence-level relation extraction, providing a benchmark for binary relation classification.",
        "ACE 2003-2004": "Used to assess sentence-level relation extraction, focusing on named entity relations in news articles.",
        "TACRED": "Used to evaluate sentence-level relation extraction, providing a large-scale dataset for relation classification in diverse domains.",
        "FewRel": "Used to test few-shot relation classification, focusing on the ability to generalize from limited labeled examples.",
        "BC5CDR": "Used to evaluate document-level relation extraction, focusing on chemical and disease relations in biomedical texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets used for relation extraction, including document-level and sentence-level datasets. These datasets are clearly identified and used for comparison in the research.",
      "processing_time": 98.11056590080261,
      "citing_paper_id": "189898081",
      "cited_paper_id": 53080736
    },
    {
      "context_text": "…statistics of DocRED and some representative RE datasets, including sentence-level RE datasets SemEval-2010 Task 8 (Hendrickx et al., 2010), ACE 2003-2004 (Dod-dington et al., 2004), TACRED (Zhang et al., 2017), FewRel (Han et al., 2018b) and document-level RE dataset BC5CDR (Li et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "SemEval-2010 Task 8",
        "ACE 2003-2004",
        "TACRED",
        "FewRel",
        "BC5CDR"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to compare statistics and performance with other relation extraction datasets, focusing on document-level relations.",
        "SemEval-2010 Task 8": "Used for sentence-level relation extraction, providing a benchmark for evaluating relation classification models.",
        "ACE 2003-2004": "Used for sentence-level relation extraction, offering a diverse set of annotated texts for relation classification.",
        "TACRED": "Used for sentence-level relation extraction, serving as a large-scale dataset for evaluating relation classification models.",
        "FewRel": "Used for few-shot relation classification, designed to test models' ability to generalize from limited labeled data.",
        "BC5CDR": "Used for document-level relation extraction, focusing on chemical and disease relations in biomedical texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets used for relation extraction, including both sentence-level and document-level datasets. These datasets are clearly identified and used for comparative analysis.",
      "processing_time": 98.3746588230133,
      "citing_paper_id": "189898081",
      "cited_paper_id": 53079972
    },
    {
      "context_text": "…statistics of DocRED and some representative RE datasets, including sentence-level RE datasets SemEval-2010 Task 8 (Hendrickx et al., 2010), ACE 2003-2004 (Dod-dington et al., 2004), TACRED (Zhang et al., 2017), FewRel (Han et al., 2018b) and document-level RE dataset BC5CDR (Li et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "SemEval-2010 Task 8",
        "ACE 2003-2004",
        "TACRED",
        "FewRel",
        "BC5CDR"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to compare statistics and performance with other relation extraction datasets, focusing on document-level relations.",
        "SemEval-2010 Task 8": "Used for sentence-level relation extraction, providing a benchmark for evaluating relation classification models.",
        "ACE 2003-2004": "Used for sentence-level relation extraction, offering a diverse set of annotated texts for relation classification.",
        "TACRED": "Used for sentence-level relation extraction, serving as a large-scale dataset for evaluating relation classification models.",
        "FewRel": "Used for few-shot relation classification, designed to test models' ability to generalize from limited labeled data.",
        "BC5CDR": "Used for document-level relation extraction, focusing on chemical and disease relations in biomedical texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets used for relation extraction, including both sentence-level and document-level datasets. These datasets are clearly identified and used for comparative analysis.",
      "processing_time": 98.3746588230133,
      "citing_paper_id": "189898081",
      "cited_paper_id": 53080736
    },
    {
      "context_text": "Hendrickx et al. (2010), Doddington et al.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not provide any specific dataset names or usage details. It only mentions authors and years, which are insufficient to identify a dataset.",
      "processing_time": 60.824811935424805,
      "citing_paper_id": "189898081",
      "cited_paper_id": 53080736
    },
    {
      "context_text": ", 2017), FewRel (Han et al., 2018b) and document-",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel"
      ],
      "dataset_descriptions": {
        "FewRel": "Used for few-shot relation classification, specifically evaluating models on a large-scale supervised dataset with state-of-the-art evaluation methods."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'FewRel' which is a specific dataset. The title confirms it is a dataset used for few-shot relation classification.",
      "processing_time": 67.89575505256653,
      "citing_paper_id": "189898081",
      "cited_paper_id": 53080736
    },
    {
      "context_text": "There have been great numbers of studies on EAE tasks since an early stage (Chen et al., 2015; Nguyen et al., 2016; Huang et al., 2018; Yang et al., 2018; Sha et al., 2018; Zheng et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies on EAE tasks. No verifiable resources are named.",
      "processing_time": 61.41644215583801,
      "citing_paper_id": "247084444",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "There have been great numbers of studies on EAE tasks since an early stage (Chen et al., 2015; Nguyen et al., 2016; Huang et al., 2018; Yang et al., 2018; Sha et al., 2018; Zheng et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies on EAE tasks. No verifiable resources are named.",
      "processing_time": 61.41644215583801,
      "citing_paper_id": "247084444",
      "cited_paper_id": 19220240
    },
    {
      "context_text": "There have been great numbers of studies on EAE tasks since an early stage (Chen et al., 2015; Nguyen et al., 2016; Huang et al., 2018; Yang et al., 2018; Sha et al., 2018; Zheng et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies on EAE tasks. No verifiable resources are named.",
      "processing_time": 61.41644215583801,
      "citing_paper_id": "247084444",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "We introduce the classical Hungarian algo-rithm (Kuhn, 1955) for efﬁcient optimal assignment.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Hungarian algorithm, which is a method, not a dataset. There are no specific datasets mentioned in the citation context.",
      "processing_time": 61.16467881202698,
      "citing_paper_id": "247084444",
      "cited_paper_id": 9426884
    },
    {
      "context_text": "(2021), we use Hungarian algorithm (Kuhn, 1955) and leave the detail about it in Appendix A.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Hungarian algorithm but does not refer to any specific dataset. The algorithm is a method, not a dataset.",
      "processing_time": 60.80689764022827,
      "citing_paper_id": "247084444",
      "cited_paper_id": 9426884
    },
    {
      "context_text": "Following Carion et al. (2020); Yang et al. (2021), we use Hungarian algorithm (Kuhn, 1955) and leave the detail about it in Appendix A.4.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the Hungarian algorithm which is a method. The cited paper titles do not introduce any datasets either.",
      "processing_time": 61.567055225372314,
      "citing_paper_id": "247084444",
      "cited_paper_id": 9426884
    },
    {
      "context_text": "Following Carion et al. (2020); Yang et al. (2021), we use Hungarian algorithm (Kuhn, 1955) and leave the detail about it in Appendix A.4.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the Hungarian algorithm which is a method. The cited paper titles do not introduce any datasets either.",
      "processing_time": 61.567055225372314,
      "citing_paper_id": "247084444",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "Understanding text by identifying the event and arguments has been a long-standing goal in Natural Language Processing (NLP) (Sundheim, 1992).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to a conference and evaluation. No verifiable resources are identified.",
      "processing_time": 60.42649006843567,
      "citing_paper_id": "247084444",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "We follow the pre-processing procedure of DyGIE++ (Wadden et al., 2019), which keeps 33 event types and 22 argument roles and collects 4859 arguments in the training set, 605 and 576 in the development and test set respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a pre-processing procedure but does not specify a dataset name. The numbers refer to the distribution of arguments across sets, not a dataset name.",
      "processing_time": 61.084107398986816,
      "citing_paper_id": "247084444",
      "cited_paper_id": 202539496
    },
    {
      "context_text": ", 2020) and T5 (Raffel et al., 2020), there are also some recent works converting extraction tasks to generation tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (T5) and a general approach (converting extraction tasks to generation tasks).",
      "processing_time": 61.59898805618286,
      "citing_paper_id": "247084444",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "To extract all arguments in a single pass, Lu et al. (2021) take EAE as a sequential generation problem with the help of the pre-trained Encoder-Decoder Transformer architecture, such as BART (Lewis et al., 2020) and T5 (Raffel et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and architectures. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 61.167115211486816,
      "citing_paper_id": "247084444",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "With the help of the pre-trained Encoder-Decoder Transformer architecture, such as BART (Lewis et al., 2020) and T5 (Raffel et al., 2020), there are also some recent works converting extraction tasks to generation tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and architectures. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 61.17185044288635,
      "citing_paper_id": "247084444",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Here we choose L as BART (Lewis et al., 2020), a standard Transformer-based pre-trained language model consisting both an Encoder and a Decoder : We ﬁrst deﬁne text markers 〈 t 〉 and 〈 /t 〉 as special tokens then insert them into context X before and after the trigger word respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a pre-trained language model (BART). No datasets are referenced for training or evaluation.",
      "processing_time": 61.39988374710083,
      "citing_paper_id": "247084444",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "The EEQA-BART model shows almost the same Arg-C with BART-Gen (Li et al., 2021) on RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the performance of EEQA-BART and BART-Gen models on document-level event argument extraction, focusing on argument classification (Arg-C)."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'RAMS dataset' which is a specific, verifiable dataset used for evaluating event argument extraction models.",
      "processing_time": 68.08171772956848,
      "citing_paper_id": "247084444",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "The EEQA-BART model shows almost the same Arg-C with BART-Gen (Li et al., 2021) on RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the performance of EEQA-BART and BART-Gen models on document-level event argument extraction, focusing on argument classification (Arg-C)."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'RAMS dataset' which is a specific, verifiable dataset used for evaluating event argument extraction models.",
      "processing_time": 68.08171772956848,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "A.1 Dataset statistics We evaluate on three common datasets for Event Argument Extraction: ACE05 (Dodding-ton et al., 2004), RAMS (Ebner et al., 2020) and WIKIEVENTS (Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05",
        "RAMS",
        "WIKIEVENTS"
      ],
      "dataset_descriptions": {
        "ACE05": "Used to evaluate event argument extraction, focusing on identifying and linking arguments to events in text.",
        "RAMS": "Used to evaluate event argument extraction, focusing on identifying and linking arguments to events in text.",
        "WIKIEVENTS": "Used to evaluate event argument extraction, focusing on identifying and linking arguments to events in text."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets used for evaluating event argument extraction systems. These datasets are clearly named and relevant to the research topic.",
      "processing_time": 77.39839673042297,
      "citing_paper_id": "247084444",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "1% in RAMS and 10 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation span does not contain any specific, verifiable dataset names or other resources. The content is too vague and lacks context to identify any datasets.",
      "processing_time": 61.469417572021484,
      "citing_paper_id": "247084444",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "(2) The role-speciﬁc selector further improves Arg-C scores in RAMS and WIKIEVENTS, while taking a slightly negative effect on ACE05.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WIKIEVENTS",
        "ACE05"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the role-specific selector's impact on argument classification scores, focusing on multi-sentence argument linking.",
        "WIKIEVENTS": "Used to assess the role-specific selector's effectiveness in improving argument classification scores, particularly in the context of multi-sentence events.",
        "ACE05": "Used to test the role-specific selector's performance, noting a slight negative effect on argument classification scores in this dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions RAMS, WIKIEVENTS, and ACE05, which are known datasets in the field of document-level event extraction. These datasets are used to evaluate the performance of the role-specific selector.",
      "processing_time": 82.33238172531128,
      "citing_paper_id": "247084444",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Since the former two datasets are document-level and have more role types (65 in RAMS, 59 in WIKIEVENTS, and 36 in ACE05), we speculate that role-speciﬁc selector plays a critical role when identifying and disambiguating roles with complicated ontology structures in long documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WIKIEVENTS",
        "ACE05"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to explore the impact of role-specific selectors in identifying and disambiguating roles within complex ontology structures in long documents, featuring 65 role types.",
        "WIKIEVENTS": "Used to explore the impact of role-specific selectors in identifying and disambiguating roles within complex ontology structures in long documents, featuring 59 role types.",
        "ACE05": "Used to explore the impact of role-specific selectors in identifying and disambiguating roles within complex ontology structures in long documents, featuring 36 role types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three datasets: RAMS, WIKIEVENTS, and ACE05. These are specific, verifiable datasets used for document-level event extraction.",
      "processing_time": 85.86692404747009,
      "citing_paper_id": "247084444",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Datasets We conduct experiments on three common datasets in Event Argument Extraction task: RAMS (Ebner et al., 2020), WIKIEVENTS (Li et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WIKIEVENTS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to conduct experiments on event argument extraction, focusing on identifying and linking arguments to events in multi-sentence contexts.",
        "WIKIEVENTS": "Used to evaluate event argument extraction models, specifically for identifying and linking arguments to events in multi-sentence contexts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WIKIEVENTS, which are used for the Event Argument Extraction task. These datasets are clearly identified and relevant to the research topic.",
      "processing_time": 75.63754749298096,
      "citing_paper_id": "247084444",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "RAMS is a document-level dataset annotated with 139 event types and 65 semantic roles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to train and evaluate models on document-level event extraction, focusing on 139 event types and 65 semantic roles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS as a document-level dataset with specific annotations, which is directly relevant to the research topic of document-level event extraction.",
      "processing_time": 67.42261004447937,
      "citing_paper_id": "247084444",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "A common idea is to ﬁrst identify argument candidates and then ﬁll each with a speciﬁc role via multi-label classiﬁcation (Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No dataset names are present in the citation context.",
      "processing_time": 60.67641615867615,
      "citing_paper_id": "247084444",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "In the second group, recent studies tend to follow the success of Pre-trained Language Models (PLMs) and solve EAE by Question Answering (QA) (Liu et al., 2021a; Wei et al., 2021; Du and Cardie, 2020; Liu et al., 2020; Li et al., 2020) and Text Generation (Lu et al., 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the use of PLMs and QA for event argument extraction.",
      "processing_time": 60.65753746032715,
      "citing_paper_id": "247084444",
      "cited_paper_id": 226283533
    },
    {
      "context_text": "For WIKIEVENTS dataset, we follow (Li et al., 2021) and additionally evaluate Argument Head F1 score (Head-C), which only concerns the matching of the head word of an argument.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKIEVENTS"
      ],
      "dataset_descriptions": {
        "WIKIEVENTS": "Used to evaluate Argument Head F1 score in document-level event argument extraction, focusing on the matching of the head word of an argument."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the WIKIEVENTS dataset, which is a specific, verifiable dataset used for document-level event extraction. The dataset is used to evaluate the Argument Head F1 score.",
      "processing_time": 69.9793119430542,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "…studies tend to follow the success of Pre-trained Language Models (PLMs) and solve EAE by Question Answering (QA)/Machine Reading Comprehension (MRC) (Liu et al., 2021a; Wei et al., 2021; Du and Cardie, 2020; Liu et al., 2020; Li et al., 2020) and Text Generation (Lu et al., 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The context is about solving Event Argument Extraction using various techniques.",
      "processing_time": 60.91731929779053,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "In experiments, we follow the template from Li et al. (2021) for fair comparison.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or template for fair comparison.",
      "processing_time": 59.31629133224487,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "BART-Gen (Li et al., 2021): For BART-large model, We report the results from origin paper.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets used in the research. It only refers to the BART-large model and reports results from the original paper.",
      "processing_time": 61.527968406677246,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "The second row shows a standard description template for event extraction task, it is usually defined in meta file, works such as (Li et al., 2021) modified the definition with exchangeable placeholders for augment the prompts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to event extraction.",
      "processing_time": 59.64890956878662,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "(2) BART-Gen (Li et al., 2021): a conditional generation model generating (rather than recognizing the spans) arguments sequentially via\na sequence-to-sequence model and prompt.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BART-Gen). The context focuses on describing the model and its approach to argument extraction.",
      "processing_time": 61.69256544113159,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "A.1 Dataset statistics\nWe evaluate on three common datasets for Event Argument Extraction: RAMS (Ebner et al., 2020), WIKIEVENTS (Li et al., 2021) and ACE05 (Doddington et al., 2004).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WIKIEVENTS",
        "ACE05"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate event argument extraction systems, focusing on document-level conditional generation for event arguments.",
        "WIKIEVENTS": "Used to evaluate event argument extraction systems, focusing on document-level conditional generation for event arguments.",
        "ACE05": "Used to evaluate event argument extraction systems, focusing on document-level conditional generation for event arguments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets used for evaluating event argument extraction systems. These datasets are clearly named and relevant to the research topic.",
      "processing_time": 76.9598605632782,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": ", 2020), WIKIEVENTS (Li et al., 2021) and ACE05 (Doddington et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKIEVENTS",
        "ACE05"
      ],
      "dataset_descriptions": {
        "WIKIEVENTS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve event argument identification.",
        "ACE05": "Utilized for evaluating event extraction models, specifically assessing performance on document-level event arguments."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions three datasets: WIKIEVENTS, ACE05, and another dataset which is cut off. WIKIEVENTS and ACE05 are multi-word proper nouns and are clearly datasets used in the research.",
      "processing_time": 74.8914783000946,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "For WIKIEVENTS dataset, we follow (Li et al., 2021) and additionally evaluate Argument Head F1 score (Head-C), which only concerns the matching of the headword of an argument.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKIEVENTS"
      ],
      "dataset_descriptions": {
        "WIKIEVENTS": "Used to evaluate Argument Head F1 score, focusing on the matching of the headword of an argument in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the WIKIEVENTS dataset, which is a specific, verifiable dataset used for document-level event extraction. The dataset is used to evaluate the Argument Head F1 score.",
      "processing_time": 69.56748032569885,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": ", 2020) (2) Generation model: BART-Gen (Li et al., 2021) (3) QA-based model: EEQA (Du and Cardie, 2020), DocMRC (Liu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on describing different models used for event argument extraction.",
      "processing_time": 60.72831583023071,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Datasets We conduct experiments on three common datasets in Event Argument Extraction task: RAMS (Ebner et al., 2020), WIKIEVENTS (Li et al., 2021) and ACE05 (Doddington et al., 2004).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WIKIEVENTS",
        "ACE05"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for event argument extraction, focusing on document-level conditional generation to improve model performance.",
        "WIKIEVENTS": "Utilized for evaluating event argument extraction models, emphasizing document-level context in conditional generation.",
        "ACE05": "Employed for benchmarking event argument extraction systems, providing a standard dataset for document-level event extraction tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets used for the Event Argument Extraction task, which are directly relevant to the research topic of Document-level Event Extraction.",
      "processing_time": 76.79293012619019,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Both BART-Gen (Li et al., 2021) and our model PAIE have a relatively stable performance on various document-level EAE datasets, but our model performs better, especially with smaller PLMs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'document-level EAE datasets' but does not specify any particular dataset names. The reference to 'various document-level EAE datasets' is too generic and lacks specific identifiers.",
      "processing_time": 62.8110568523407,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Baselines We compare PAIE with several stateof-the-art models in three categories: (1) Multilabel classification model: ONEIE (Lin et al., 2020) (2) Generation model: BART-Gen (Li et al., 2021) (3) QA-based model: EEQA (Du and Cardie, 2020), DocMRC (Liu et al., 2021a) and FEAE (Wei et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods used for comparison. No verifiable resources are identified.",
      "processing_time": 60.19577479362488,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Li et al. (2021) target generation model by designing specific templates for each event type.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event argument extraction.",
      "processing_time": 58.544825077056885,
      "citing_paper_id": "247084444",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "For example, (Cui et al., 2021) design the prompt for named entity recognition: [candidate span] is [entity type/not a] entity.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for named entity recognition using prompts.",
      "processing_time": 58.74482727050781,
      "citing_paper_id": "247084444",
      "cited_paper_id": 235313658
    },
    {
      "context_text": "To deal with implicit arguments and multiple events, Xu et al. (2021) construct a heterogeneous graph of arguments, while DEFNN (Yang et al., 2021) predicts arguments via Parallel Prediction Networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited paper title confirms that the focus is on a method (Parallel Prediction Networks) rather than a dataset.",
      "processing_time": 61.70243501663208,
      "citing_paper_id": "247084444",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "Prompt-based Learning: Prompt-based learning is a new paradigm emerging in the ﬁeld of pre-trained language models (Liu et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach in the field of pre-trained language models.",
      "processing_time": 59.64262795448303,
      "citing_paper_id": "247084444",
      "cited_paper_id": 236493269
    },
    {
      "context_text": "It is somewhat similar as a concurrent work P-tuning v2 (Liu et al., 2021c).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model (P-tuning v2).",
      "processing_time": 59.144702196121216,
      "citing_paper_id": "247084444",
      "cited_paper_id": 238857040
    },
    {
      "context_text": "For simplicity, we use the SoftMax norm proposed by (Qian et al. 2019) as the metric learning loss function, which can be seen as a smoothed version of triplet loss.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (SoftMax norm) used for metric learning. The cited papers also do not provide additional context about datasets.",
      "processing_time": 60.8511164188385,
      "citing_paper_id": "259261857",
      "cited_paper_id": 911406
    },
    {
      "context_text": "For simplicity, we use the SoftMax norm proposed by (Qian et al. 2019) as the metric learning loss function, which can be seen as a smoothed version of triplet loss.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (SoftMax norm) used for metric learning. The cited papers also do not provide additional context about datasets.",
      "processing_time": 60.8511164188385,
      "citing_paper_id": "259261857",
      "cited_paper_id": 118646482
    },
    {
      "context_text": "In the past, most RE research focused on extracting relations within a single sentence (Miwa and Bansal 2016; Zhang, Qi, and Manning 2018).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general trend in relation extraction research.",
      "processing_time": 58.57367134094238,
      "citing_paper_id": "259261857",
      "cited_paper_id": 2476229
    },
    {
      "context_text": "In the past, most RE research focused on extracting relations within a single sentence (Miwa and Bansal 2016; Zhang, Qi, and Manning 2018).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general trend in relation extraction research.",
      "processing_time": 58.57367134094238,
      "citing_paper_id": "259261857",
      "cited_paper_id": 49544037
    },
    {
      "context_text": "Proxy-based methods like Proxy-NCA (Movshovitz-Attias et al. 2017) and NormFace (Wang et al. 2017) consider the relationships between proxies and samples, and (Qian et al. 2019) unified the relationship between SoftMax loss and triplet loss, and proposed a new SoftTriplet loss.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers are also about methods, not datasets.",
      "processing_time": 59.373106241226196,
      "citing_paper_id": "259261857",
      "cited_paper_id": 7680631
    },
    {
      "context_text": "Proxy-based methods like Proxy-NCA (Movshovitz-Attias et al. 2017) and NormFace (Wang et al. 2017) consider the relationships between proxies and samples, and (Qian et al. 2019) unified the relationship between SoftMax loss and triplet loss, and proposed a new SoftTriplet loss.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers are also about methods, not datasets.",
      "processing_time": 59.373106241226196,
      "citing_paper_id": "259261857",
      "cited_paper_id": 17861456
    },
    {
      "context_text": "In this section, we introduce the details of P 3 M. Firstly, we propose positive-unlabeled metric learning for document-level RE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for document-level relation extraction.",
      "processing_time": 58.39956045150757,
      "citing_paper_id": "259261857",
      "cited_paper_id": 15313053
    },
    {
      "context_text": "On the other hand, proxy-based methods like Proxy-NCA (Movshovitz-Attias et al., 2017) and NormFace (Wang et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (Proxy-NCA and NormFace).",
      "processing_time": 58.623793601989746,
      "citing_paper_id": "259261857",
      "cited_paper_id": 17861456
    },
    {
      "context_text": "In DocRED ext, our method not only improves recall by 14.26 and 15.26 over SSR-PU under the same settings but also raises precision by 1.60 and 1.47, respectively, highlighting its value in label-scarce scenarios.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance improvements of a method. The cited paper title 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding' is a model, not a dataset.",
      "processing_time": 62.92100405693054,
      "citing_paper_id": "259261857",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We conduct experiments on the DocRED (Yao et al. 2019) dataset under incomplete labeling and extreme incomplete labeling settings, as well as the ChemDisGene (Zhang et al. 2022) the F1 score by about 4-10 points compared to the base-line, demonstrating the effectiveness of our proposed P 3 M method.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "ChemDisGene"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction experiments under incomplete labeling and extreme incomplete labeling settings, demonstrating the effectiveness of the P 3 M method.",
        "ChemDisGene": "Used for document-level relation extraction experiments, showing a significant improvement in F1 score by about 4-10 points compared to the baseline."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, DocRED and ChemDisGene, which are used for document-level relation extraction experiments. The usage is clearly described, including the settings and the impact on performance.",
      "processing_time": 76.30793714523315,
      "citing_paper_id": "259261857",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "We conduct experiments on the DocRED (Yao et al. 2019) dataset under incomplete labeling and extreme incomplete labeling settings, as well as the ChemDisGene (Zhang et al. 2022) the F1 score by about 4-10 points compared to the base-line, demonstrating the effectiveness of our proposed P 3 M method.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "ChemDisGene"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction experiments under incomplete labeling and extreme incomplete labeling settings, demonstrating the effectiveness of the P 3 M method.",
        "ChemDisGene": "Used for document-level relation extraction experiments, showing a significant improvement in F1 score by about 4-10 points compared to the baseline."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, DocRED and ChemDisGene, which are used for document-level relation extraction experiments. The usage is clearly described, including the settings and the impact on performance.",
      "processing_time": 76.30793714523315,
      "citing_paper_id": "259261857",
      "cited_paper_id": 248178003
    },
    {
      "context_text": "(Huang et al. 2022) noticed that the popular document-level RE dataset DocRED (Yao et al. 2019) annotated using the recommend-revise scheme contains a large number of unlabeled positive relations, i.e. false negatives.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to highlight issues in document-level relation extraction, specifically the presence of false negatives due to unlabeled positive relations in the dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' as a specific dataset used for document-level relation extraction, which is directly relevant to the research topic.",
      "processing_time": 66.08072710037231,
      "citing_paper_id": "259261857",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "However, more recent work has begun to examine document-level RE, which involves identifying relations be-tween entities across multiple sentences in a document (Yao et al. 2019; Zhou et al. 2021; Xu et al. 2022; Yu, Yang, and Tian 2022; Zhou and Lee 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions document-level relation extraction but does not explicitly name any datasets. The cited papers' titles suggest they are about document-level relation extraction, but no specific dataset names are mentioned in the context.",
      "processing_time": 62.490028858184814,
      "citing_paper_id": "259261857",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "However, more recent work has begun to examine document-level RE, which involves identifying relations be-tween entities across multiple sentences in a document (Yao et al. 2019; Zhou et al. 2021; Xu et al. 2022; Yu, Yang, and Tian 2022; Zhou and Lee 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions document-level relation extraction but does not explicitly name any datasets. The cited papers' titles suggest they are about document-level relation extraction, but no specific dataset names are mentioned in the context.",
      "processing_time": 62.490028858184814,
      "citing_paper_id": "259261857",
      "cited_paper_id": 227230619
    },
    {
      "context_text": "Pair-based methods (Had-sell, Chopra, and LeCun 2006; Schroff, Kalenichenko, and Philbin 2015; Sohn 2016; Wang et al. 2019) focus on the relationships between individual samples, and contrastive learning can be considered a subset of this approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is focused on describing pair-based methods and their application in contrastive learning.",
      "processing_time": 61.04428291320801,
      "citing_paper_id": "259261857",
      "cited_paper_id": 206592766
    },
    {
      "context_text": "…has been widely applied in various tasks, such as text classification (Li and Liu 2003), sentence embedding (Cao et al. 2021), named entity recognition (Peng et al. 2019; Zhou, Li, and Li 2022), knowledge graph completion (Tang et al. 2022), and sentence-level RE (He et al. 2020) in the NLP field.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and applications. No clear identifiers for datasets are present.",
      "processing_time": 59.73347473144531,
      "citing_paper_id": "259261857",
      "cited_paper_id": 208512660
    },
    {
      "context_text": ", 2022) and the PU learning (Chen et al., 2020a; Wei et al., 2020; Li et al., 2021; Zhao et al., 2022) fields.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research fields and papers. There are no clear identifiers for datasets.",
      "processing_time": 59.57084512710571,
      "citing_paper_id": "259261857",
      "cited_paper_id": 215827880
    },
    {
      "context_text": "It is increasingly used and researched in the NLP (Chen, Yang, and Yang 2020; Yin et al. 2021; Wu et al. 2022) and the PU learning (Chen et al. 2020; Wei et al. 2020; Li et al. 2022; Zhao et al. 2022) fields.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general research areas and papers. There are no clear identifiers for datasets.",
      "processing_time": 59.38335108757019,
      "citing_paper_id": "259261857",
      "cited_paper_id": 215827880
    },
    {
      "context_text": "We also use the method of prior shift in the training data to obtain the final p ositive-unlabeled metric learning (PM) expected loss: where mean that the i -th class is labeled or unlabeled, respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for handling labeled and unlabeled data in a semi-supervised setting.",
      "processing_time": 58.79754900932312,
      "citing_paper_id": "259261857",
      "cited_paper_id": 216553182
    },
    {
      "context_text": "(Chuang et al. 2020) used PU learning to address the issue of negative samples potentially carrying the same label in contrastive learning.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (PU learning) used in contrastive learning.",
      "processing_time": 57.87180185317993,
      "citing_paper_id": "259261857",
      "cited_paper_id": 220280371
    },
    {
      "context_text": "P 3 M has more performance improvement compared to P 3 M(ori), which shows that using none-class relation embedding as pseudo-negative samples effectively mitigates the bias of directly using unlabeled samples for mixup.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses model performance improvements.",
      "processing_time": 57.63692617416382,
      "citing_paper_id": "259261857",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "The contributions of this paper can be summarized as follows: 1",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only contributions of the paper. No dataset names are present in the text.",
      "processing_time": 59.16652798652649,
      "citing_paper_id": "259261857",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "The contributions of this paper can be summarized as follows: 1",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only contributions of the paper. No dataset names are present in the text.",
      "processing_time": 59.16652798652649,
      "citing_paper_id": "259261857",
      "cited_paper_id": 227230619
    },
    {
      "context_text": "The contributions of this paper can be summarized as follows: 1",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only contributions of the paper. No dataset names are present in the text.",
      "processing_time": 59.16652798652649,
      "citing_paper_id": "259261857",
      "cited_paper_id": 248227853
    },
    {
      "context_text": "The regular P 3 M(ori) method has a considerable improvement over P 2 M because in document-level RE, the number of negative samples is far greater than that of positive samples.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (P 3 M) and a general problem in document-level relation extraction.",
      "processing_time": 59.85636830329895,
      "citing_paper_id": "259261857",
      "cited_paper_id": 227230619
    },
    {
      "context_text": "For details on prior shift in document-level RE, please refer to (Wang et al. 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to prior shift in document-level relation extraction. No verifiable resources are identified.",
      "processing_time": 59.853960275650024,
      "citing_paper_id": "259261857",
      "cited_paper_id": 227230619
    },
    {
      "context_text": "For details on prior shift in document-level RE, please refer to (Wang et al. 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to prior shift in document-level relation extraction. No verifiable resources are identified.",
      "processing_time": 59.853960275650024,
      "citing_paper_id": "259261857",
      "cited_paper_id": 249951368
    },
    {
      "context_text": "Firstly, for metric learning in document-level RE, we initialize an embedding for each relation and an embedding for the none-class relation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the initialization of embeddings for relations in the context of document-level relation extraction.",
      "processing_time": 59.0978627204895,
      "citing_paper_id": "259261857",
      "cited_paper_id": 227230619
    },
    {
      "context_text": "Following (du Plessis, Niu, and Sugiyama 2014), PU learning assumes that unlabeled data can reflect the true overall distribution, that is, p U i ( x ) = p i ( x ) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological assumption about unlabeled data in PU learning.",
      "processing_time": 58.62043642997742,
      "citing_paper_id": "259261857",
      "cited_paper_id": 233296292
    },
    {
      "context_text": "Following (du Plessis, Niu, and Sugiyama 2014), PU learning assumes that unlabeled data can reflect the true overall distribution, that is, p U i ( x ) = p i ( x ) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological assumption about unlabeled data in PU learning.",
      "processing_time": 58.62043642997742,
      "citing_paper_id": "259261857",
      "cited_paper_id": 233864791
    },
    {
      "context_text": "We also analyze the effectiveness of different components of the method.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the effectiveness of method components.",
      "processing_time": 57.854663610458374,
      "citing_paper_id": "259261857",
      "cited_paper_id": 233296292
    },
    {
      "context_text": "Let X be an instance space and Y = {− 1 , +1 } K be a label space, where K is the number of pre-defined classes.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts about instance and label spaces.",
      "processing_time": 58.16027092933655,
      "citing_paper_id": "259261857",
      "cited_paper_id": 237431035
    },
    {
      "context_text": "Recently, it has been found that there are a large number of false negatives in document-level RE datasets, i.e. incomplete labels (Huang et al. 2022; Tan et al. 2022b).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'document-level RE datasets' but does not specify any particular dataset names. The cited papers do not provide additional specific dataset names either.",
      "processing_time": 59.41912651062012,
      "citing_paper_id": "259261857",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "Recently, it has been found that there are a large number of false negatives in document-level RE datasets, i.e. incomplete labels (Huang et al. 2022; Tan et al. 2022b).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'document-level RE datasets' but does not specify any particular dataset names. The cited papers do not provide additional specific dataset names either.",
      "processing_time": 59.41912651062012,
      "citing_paper_id": "259261857",
      "cited_paper_id": 253107167
    },
    {
      "context_text": "We conduct experiments on Re-DocRED (Tan et al. 2022b) under a fully supervised setting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Re-DocRED"
      ],
      "dataset_descriptions": {
        "Re-DocRED": "Used for document-level relation extraction experiments under a fully supervised setting, addressing false negatives in relation extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Re-DocRED' as a dataset used for experiments in document-level relation extraction. The cited paper titles help confirm that Re-DocRED is indeed a dataset.",
      "processing_time": 66.99361538887024,
      "citing_paper_id": "259261857",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "We conduct experiments on Re-DocRED (Tan et al. 2022b) under a fully supervised setting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Re-DocRED"
      ],
      "dataset_descriptions": {
        "Re-DocRED": "Used for document-level relation extraction experiments under a fully supervised setting, addressing false negatives in relation extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Re-DocRED' as a dataset used for experiments in document-level relation extraction. The cited paper titles help confirm that Re-DocRED is indeed a dataset.",
      "processing_time": 66.99361538887024,
      "citing_paper_id": "259261857",
      "cited_paper_id": 253107167
    },
    {
      "context_text": "(Tan et al. 2022b) obtained a high-quality Re-DocRED dataset by supplementing the large number of missing relations in DocRED.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Re-DocRED"
      ],
      "dataset_descriptions": {
        "Re-DocRED": "Used to enhance document-level relation extraction by supplementing missing relations in the original DocRED dataset, improving the quality and coverage of relational data."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Re-DocRED' as a dataset derived from 'DocRED' by addressing missing relations. This indicates a specific, verifiable dataset used for document-level relation extraction.",
      "processing_time": 68.33814883232117,
      "citing_paper_id": "259261857",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "(Tan et al. 2022b) obtained a high-quality Re-DocRED dataset by supplementing the large number of missing relations in DocRED.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Re-DocRED"
      ],
      "dataset_descriptions": {
        "Re-DocRED": "Used to enhance document-level relation extraction by supplementing missing relations in the original DocRED dataset, improving the quality and coverage of relational data."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Re-DocRED' as a dataset derived from 'DocRED' by addressing missing relations. This indicates a specific, verifiable dataset used for document-level relation extraction.",
      "processing_time": 68.33814883232117,
      "citing_paper_id": "259261857",
      "cited_paper_id": 253107167
    },
    {
      "context_text": ", 2021), KD-DocRE (Tan et al., 2022a), and SSR-PU (Wang et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "KD-DocRE"
      ],
      "dataset_descriptions": {
        "KD-DocRE": "Used for document-level relation extraction, applying adaptive focal loss and knowledge distillation to improve model performance on complex document structures."
      },
      "confidence_score": 0.7,
      "reasoning": "The citation mentions KD-DocRE, which is likely a dataset or method for document-level relation extraction. However, without more context, it is unclear if it is a dataset or a method. SSR-PU is also mentioned but lacks context to determine its nature.",
      "processing_time": 71.08436274528503,
      "citing_paper_id": "259261857",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "As shown in framework with the existing state-of-the-art methods AT-LOP (Zhou et al. 2021), DocuNET (Zhang et al. 2021), KD-DocRE (Tan et al. 2022a), and SSR-PU (Wang et al. 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.630738973617554,
      "citing_paper_id": "259261857",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "As shown in framework with the existing state-of-the-art methods AT-LOP (Zhou et al. 2021), DocuNET (Zhang et al. 2021), KD-DocRE (Tan et al. 2022a), and SSR-PU (Wang et al. 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.630738973617554,
      "citing_paper_id": "259261857",
      "cited_paper_id": 253107167
    },
    {
      "context_text": "…Zeng et al. 2020; Zeng, Wu, and Chang 2021; Xu, Chen, and Zhao 2021) use graph neural networks to gather entity information for relational inference, while transformer-based methods (Zhou et al. 2021; Xu et al. 2021; Zhang et al. 2021; Tan et al. 2022a) capture long-range dependencies implicitly.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 59.628355264663696,
      "citing_paper_id": "259261857",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "…Zeng et al. 2020; Zeng, Wu, and Chang 2021; Xu, Chen, and Zhao 2021) use graph neural networks to gather entity information for relational inference, while transformer-based methods (Zhou et al. 2021; Xu et al. 2021; Zhang et al. 2021; Tan et al. 2022a) capture long-range dependencies implicitly.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 59.628355264663696,
      "citing_paper_id": "259261857",
      "cited_paper_id": 253107167
    },
    {
      "context_text": "For different variations of the method, P 2 M(all) has an obvious performance decrease compared to PM, which may be caused by the larger deviation between the training set and the test set, and this deviation is further amplified by the augmentation of all samples.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between methods and potential reasons for performance differences.",
      "processing_time": 58.39171504974365,
      "citing_paper_id": "259261857",
      "cited_paper_id": 248178003
    },
    {
      "context_text": "0 can be seen as a uniform mixup interpolation between distributions.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, and the context is too generic to infer the use of a particular dataset.",
      "processing_time": 58.89627718925476,
      "citing_paper_id": "259261857",
      "cited_paper_id": 248178003
    },
    {
      "context_text": "This has made the problem of incomplete labeling a common problem in document-level RE and has at-tracted increasing attention from researchers.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general problem in document-level relation extraction.",
      "processing_time": 57.2275505065918,
      "citing_paper_id": "259261857",
      "cited_paper_id": 248227853
    },
    {
      "context_text": "An instance x ∈ X is associated with a subset of labels, identified by a binary vector y ∈ Y = ( y 1 , . . . , y K ) , where y i = +1 if the i -th label is positive for x , and y i = − 1 otherwise.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general description of labeling instances. No verifiable resources are identified.",
      "processing_time": 58.97387957572937,
      "citing_paper_id": "259261857",
      "cited_paper_id": 248496746
    },
    {
      "context_text": "(Tan et al., 2022b) obtained a high-quality Re-DocRED dataset by supplementing the large number of miss-",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Re-DocRED"
      ],
      "dataset_descriptions": {
        "Re-DocRED": "Used to address the false negative problem in relation extraction, enhancing the quality of document-level annotations for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Re-DocRED' as a dataset used for relation extraction, which is relevant to document-level event extraction.",
      "processing_time": 65.20581316947937,
      "citing_paper_id": "259261857",
      "cited_paper_id": 253107167
    },
    {
      "context_text": "However, the original dataset contains a large amount of incomplete labeling phenomena, (Tan et al., 2022b) proposed a high-quality revised version Re-DocRED.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Re-DocRED"
      ],
      "dataset_descriptions": {
        "Re-DocRED": "Used to address false negatives in relation extraction, providing a high-quality revised version of the original dataset with improved labeling."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Re-DocRED' as a revised version of an original dataset, which is relevant to document-level event extraction.",
      "processing_time": 65.35705089569092,
      "citing_paper_id": "259261857",
      "cited_paper_id": 253107167
    },
    {
      "context_text": "We conduct experiments on Re-DocRED (Tan et al., 2022b) under a fully supervised setting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Re-DocRED"
      ],
      "dataset_descriptions": {
        "Re-DocRED": "Used to conduct experiments in a fully supervised setting for relation extraction, addressing false negatives in document-level relation extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Re-DocRED' as a dataset used for experiments in a fully supervised setting. The title confirms it is a dataset for relation extraction.",
      "processing_time": 66.29492282867432,
      "citing_paper_id": "259261857",
      "cited_paper_id": 253107167
    },
    {
      "context_text": "It may be that recall improvement of BEEDS over EVEX is in part because of the newer Gen-NormPlus (Wei et al., 2015) normalization algo-rithm used in BEEDS compared to the older Gen-Norm (Wei and Kao, 2011) used in EVEX.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only algorithms and systems. The context focuses on comparing normalization algorithms used in different systems.",
      "processing_time": 59.32761096954346,
      "citing_paper_id": "248780216",
      "cited_paper_id": 1017365
    },
    {
      "context_text": "A reliable document re-triever is the BM25 model (Robertson and Walker, 1994) which ranks documents based on their cosine similarity between query and document in TF-IDF representation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BM25 model) used for document retrieval.",
      "processing_time": 58.46057748794556,
      "citing_paper_id": "248780216",
      "cited_paper_id": 2218552
    },
    {
      "context_text": "DrQA answers questions posed to a Wikipedia corpus and uses two models, the BM25 algorithm for retrieval (Robertson and Walker, 1994) and a deep learning model consisting of an LSTM (Long short-term memory) for reading.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of a Wikipedia corpus for question answering but does not specify a named dataset. The BM25 algorithm and LSTM model are mentioned as methods, not datasets.",
      "processing_time": 61.12871527671814,
      "citing_paper_id": "248780216",
      "cited_paper_id": 2218552
    },
    {
      "context_text": "DrQA answers questions posed to a Wikipedia corpus and uses two models, the BM25 algorithm for retrieval (Robertson and Walker, 1994) and a deep learning model consisting of an LSTM (Long short-term memory) for reading.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of a Wikipedia corpus for question answering but does not specify a named dataset. The BM25 algorithm and LSTM model are mentioned as methods, not datasets.",
      "processing_time": 61.12871527671814,
      "citing_paper_id": "248780216",
      "cited_paper_id": 3618568
    },
    {
      "context_text": "Similar approaches combining a retriever reader model to pose questions directly to a corpus include DrQA (Chen et al., 2017), REALM (Guu et al., 2020) and Lewis et al. (2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is about comparing different approaches and models, not using a particular dataset.",
      "processing_time": 59.94863820075989,
      "citing_paper_id": "248780216",
      "cited_paper_id": 3618568
    },
    {
      "context_text": "REALM and Lewis et al. follow a similar idea like introduced in DrQA but use dense retrieval methods, i.e., a retriever employing a deep learning model, and unite the retriever and reader components in a joint deep learning model which can be optimized end-to-end.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The focus is on the methodology of using dense retrieval and joint optimization in a deep learning model.",
      "processing_time": 59.46492147445679,
      "citing_paper_id": "248780216",
      "cited_paper_id": 3618568
    },
    {
      "context_text": "Phosphorylation Site EGID 2309 253 (Schwab et al., 2005) False Where is FKHLR1 or FOXO3 phosphorylated? IGF-I induced phosphorylation of FKHR (Ser 253), FKHRL1 (Ser 256) [.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any datasets, only specific phosphorylation sites and proteins. The citation is focused on the findings of the phosphorylation sites.",
      "processing_time": 58.867058992385864,
      "citing_paper_id": "248780216",
      "cited_paper_id": 5756296
    },
    {
      "context_text": "BEEDS uses a data set for training that consists of two portions: The first portion is a distantly supervised, knowledge base data set containing presumable descriptions of events from the union of the following seven pathway databases: KEGG, PID, Reactome, HumanCyc (Romero et al., 2005), INOH (Yamamoto et al., 2011), PANTHER (Mi et al., 2017) and NetPath (Kandasamy et al., 2010).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "KEGG",
        "PID",
        "Reactome",
        "HumanCyc",
        "INOH",
        "PANTHER",
        "NetPath"
      ],
      "dataset_descriptions": {
        "KEGG": "Used to train BEEDS with event descriptions from biological pathways, contributing to the distantly supervised knowledge base data set.",
        "PID": "Used to train BEEDS with event descriptions from biological pathways, contributing to the distantly supervised knowledge base data set.",
        "Reactome": "Used to train BEEDS with event descriptions from biological pathways, contributing to the distantly supervised knowledge base data set.",
        "HumanCyc": "Used to train BEEDS with event descriptions from biological pathways, contributing to the distantly supervised knowledge base data set.",
        "INOH": "Used to train BEEDS with event descriptions from biological pathways, contributing to the distantly supervised knowledge base data set.",
        "PANTHER": "Used to train BEEDS with event descriptions from biological pathways, contributing to the distantly supervised knowledge base data set.",
        "NetPath": "Used to train BEEDS with event descriptions from biological pathways, contributing to the distantly supervised knowledge base data set."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a knowledge base data set composed of event descriptions from seven pathway databases. These databases are specific, verifiable resources.",
      "processing_time": 99.30195665359497,
      "citing_paper_id": "248780216",
      "cited_paper_id": 16139903
    },
    {
      "context_text": "…is a distantly supervised, knowledge base data set containing presumable descriptions of events from the union of the following seven pathway databases: KEGG, PID, Reactome, HumanCyc (Romero et al., 2005), INOH (Yamamoto et al., 2011), PANTHER (Mi et al., 2017) and NetPath (Kandasamy et al., 2010).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "KEGG",
        "PID",
        "Reactome",
        "HumanCyc",
        "INOH",
        "PANTHER",
        "NetPath"
      ],
      "dataset_descriptions": {
        "KEGG": "Used to create a distantly supervised dataset for event descriptions, contributing biological pathway information.",
        "PID": "Used to create a distantly supervised dataset for event descriptions, providing pathway interaction data.",
        "Reactome": "Used to create a distantly supervised dataset for event descriptions, offering detailed pathway annotations.",
        "HumanCyc": "Used to create a distantly supervised dataset for event descriptions, integrating metabolic pathway data.",
        "INOH": "Used to create a distantly supervised dataset for event descriptions, contributing pathway and interaction data.",
        "PANTHER": "Used to create a distantly supervised dataset for event descriptions, providing pathway and gene function annotations.",
        "NetPath": "Used to create a distantly supervised dataset for event descriptions, focusing on signaling pathways."
      },
      "confidence_score": 1.0,
      "reasoning": "The context describes a dataset created from multiple pathway databases, which is relevant to document-level event extraction. The dataset is used for distantly supervised event description.",
      "processing_time": 93.55408143997192,
      "citing_paper_id": "248780216",
      "cited_paper_id": 16139903
    },
    {
      "context_text": "Acetylation Cause EGID 4303 EGID 23411 (Chuang et al., 2011) False What acetylates FOXO4? [.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only gene IDs and a research question about acetylation. There are no clear identifiers for datasets.",
      "processing_time": 59.47598123550415,
      "citing_paper_id": "248780216",
      "cited_paper_id": 17774549
    },
    {
      "context_text": "This is in line with our previous results from (Wang et al., 2020) where the machine reading component of EVEX, TEES (Björne and Salakoski, 2011), achieves a slightly worse precision than the machine reading component in BEEDS on the GENIA11 dataset (Kim et al., 2011, 57.65% to 59.33",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA11"
      ],
      "dataset_descriptions": {
        "GENIA11": "Used to evaluate the precision of machine reading components in biomedical event extraction, comparing TEES and BEEDS systems."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENIA11 dataset, which is a specific biomedical event extraction dataset used for evaluating machine reading components.",
      "processing_time": 65.65367770195007,
      "citing_paper_id": "248780216",
      "cited_paper_id": 18361255
    },
    {
      "context_text": "This is in line with our previous results from (Wang et al., 2020) where the machine reading component of EVEX, TEES (Björne and Salakoski, 2011), achieves a slightly worse precision than the machine reading component in BEEDS on the GENIA11 dataset (Kim et al., 2011, 57.65% to 59.33",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA11"
      ],
      "dataset_descriptions": {
        "GENIA11": "Used to evaluate the precision of machine reading components in biomedical event extraction, comparing TEES and BEEDS systems."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENIA11 dataset, which is a specific biomedical event extraction dataset used for evaluating machine reading components.",
      "processing_time": 65.65367770195007,
      "citing_paper_id": "248780216",
      "cited_paper_id": 263873742
    },
    {
      "context_text": "Phosphorylation Site EGID 84335 S183 (Bönig et al., 1996) True Where is PRAS40 or AKT1S1 phosphorylated? PRAS40(Ser183) phosphorylation was also inhibited [.",
      "catation_intent": "findings",
      "resource_type": "discovery",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any datasets, only a specific phosphorylation site. The citation is not about a dataset but rather a specific biological finding.",
      "processing_time": 58.99997568130493,
      "citing_paper_id": "248780216",
      "cited_paper_id": 29427769
    },
    {
      "context_text": "Acetylation Cause EGID 9126 EGID 850584 (Ben-Shahar et al., 2008) True What acetylates SMC3? [.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only gene IDs and a research question about acetylation. No verifiable resources are identified.",
      "processing_time": 59.298423528671265,
      "citing_paper_id": "248780216",
      "cited_paper_id": 33497004
    },
    {
      "context_text": "For entity normalization, we use the existing nor-malizer PubTator Central 5 from Wei et al. (2019).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions PubTator Central but does not refer to it as a dataset. It is described as a normalizer, which is a tool or method.",
      "processing_time": 60.31484079360962,
      "citing_paper_id": "248780216",
      "cited_paper_id": 162171628
    },
    {
      "context_text": "However, the increase in F1-score performance from GenNorm to GenNormPlus (80.10% to 86.70%, see Wei et al., 2019) does not solely explain the significant discrepancy in recall for the multi-turn questions.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models (GenNorm, GenNormPlus) and performance metrics (F1-score, recall).",
      "processing_time": 60.00886583328247,
      "citing_paper_id": "248780216",
      "cited_paper_id": 162171628
    },
    {
      "context_text": "More specifically we use a pre-trained checkpoint of the model called SciBERT (Beltagy et al., 2019).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a pre-trained model called SciBERT but does not refer to any specific dataset. SciBERT is a model, not a dataset, and thus should not be included.",
      "processing_time": 60.40350937843323,
      "citing_paper_id": "248780216",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "We augment this distantly supervised training set with gold standard text annotations for biomedical event structures from (Kim et al., 2011) and (Ohta et al., 2013).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Genia Event Task"
      ],
      "dataset_descriptions": {
        "Genia Event Task": "Used to provide gold standard text annotations for biomedical event structures, enhancing the distantly supervised training set with high-quality annotations."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'gold standard text annotations for biomedical event structures' from two cited papers, which suggests the use of specific datasets.",
      "processing_time": 65.05317068099976,
      "citing_paper_id": "248780216",
      "cited_paper_id": 263873742
    },
    {
      "context_text": "The second portion is a directly supervised data set containing gold annotations from the GENIA (Kim et al., 2011) and Pathway Curation (Ohta et al., 2013) challenges; in the following, we call the former the KB data set and the latter the BioNLP data set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA",
        "Pathway Curation"
      ],
      "dataset_descriptions": {
        "GENIA": "Used for gold annotations in a supervised setting, focusing on event extraction in biomedical texts. The dataset is part of the BioNLP Shared Task 2011.",
        "Pathway Curation": "Used for gold annotations in a supervised setting, focusing on event extraction in biomedical texts. The dataset is part of the BioNLP Shared Task 2013."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, GENIA and Pathway Curation, which are used for gold annotations in a supervised setting. These datasets are clearly identified and have been used in challenges.",
      "processing_time": 76.96655416488647,
      "citing_paper_id": "248780216",
      "cited_paper_id": 263873742
    },
    {
      "context_text": "Hybrid event-extraction methods combine statistical methods and pattern-based methods together (Jungermann and Morik, 2008), (Bjorne et al., 2010).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.10254168510437,
      "citing_paper_id": "51871198",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Hybrid event-extraction methods combine statistical methods and pattern-based methods together (Jungermann and Morik, 2008), (Bjorne et al., 2010).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.10254168510437,
      "citing_paper_id": "51871198",
      "cited_paper_id": 17984630
    },
    {
      "context_text": "Hybrid event-extraction methods combine statistical methods and pattern-based methods together (Jungermann and Morik, 2008), (Bjorne et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 58.085675954818726,
      "citing_paper_id": "51871198",
      "cited_paper_id": 1942185
    },
    {
      "context_text": "DS has proved its effectiveness in automatically labeling data for Relation Extraction (Zeng et al., 2015) and Event Extraction (Chen et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions 'Relation Extraction' and 'Event Extraction' but does not specify any datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 59.895737171173096,
      "citing_paper_id": "51871198",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "DS has proved its effectiveness in automatically labeling data for Relation Extraction (Zeng et al., 2015) and Event Extraction (Chen et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions 'Relation Extraction' and 'Event Extraction' but does not specify any datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 59.895737171173096,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "DS has proved its effectiveness in automatically labeling data for Relation Extraction (Zeng et al., 2015) and Event Extraction (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the technique of distant supervision. No clear, verifiable resource names are present.",
      "processing_time": 58.592570304870605,
      "citing_paper_id": "51871198",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "The current EE approaches can be mainly classified into statistical methods, pattern-based method and hybrid method (Hogenboom et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general approaches to event extraction.",
      "processing_time": 56.76913785934448,
      "citing_paper_id": "51871198",
      "cited_paper_id": 8174613
    },
    {
      "context_text": "We make use of Distance Supervision (DS) which has been validated to generate labeled data for EE (Chen et al., 2017) to automatically generate large-scaled annotated data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'Distance Supervision' and 'automatically generate large-scaled annotated data', but does not specify a named dataset. The cited paper title suggests the generation of labeled data for event extraction, but no specific dataset name is provided.",
      "processing_time": 62.24251389503479,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Event Extraction (EE), a challenging task in Nature Language Processing (NLP), aims at discovering event mentions 3 and extracting events which contain event triggers 4 and event arguments 5 from texts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only describes the general task of Event Extraction in NLP.",
      "processing_time": 58.11437106132507,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Figure 2 describes the architecture of our proposed DCFEE framework which primarily involves the following two components: (i) Data Generation, which makes use of DS to automatically label event mention from the whole documen-t (document-level data) and annotate triggers and arguments from event mention (sentence-level data); (ii) EE system, which contains Sentence-level Event Extraction (SEE) supported by sentence-level labeled data and Document-level Event Extraction (DEE) supported by document-level labeled data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'document-level data' and 'sentence-level data' but does not provide specific, identifiable dataset names. The terms are too generic and do not meet the criteria for inclusion.",
      "processing_time": 60.30139684677124,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "In order to improve recall, there are two main research directions: build relatively complete pattern library and use a semi-automatic method to build trigger dictionary (Chen et al., 2017), (Gu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only research directions and methods.",
      "processing_time": 56.47890615463257,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "In order to improve recall, there are two main research directions: build relatively complete pattern library and use a semi-automatic method to build trigger dictionary (Chen et al., 2017), (Gu et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only research directions and methods.",
      "processing_time": 56.79736685752869,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Figure 4 depicts the overall architecture of the EE system proposed in this paper which primarily involves the following two components: The sentence-level Event Extraction (SEE) purposes to extract event arguments and event triggers from one sentence; The document-level Event Extraction (DEE) aims to extract event arguments from the whole document based on a key event detection model and an arguments-completion strategy.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only describes the components of an event extraction system. No verifiable resources are named.",
      "processing_time": 58.645575523376465,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Hybrid event-extraction method-s combine statistical methods and pattern-based methods together (Jungermann and Morik, 2008), (Bjorne et al., 2010).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 58.87334108352661,
      "citing_paper_id": "51871198",
      "cited_paper_id": 17984630
    },
    {
      "context_text": "Recurrent neural networks (RNN) has been shown to perform considerably better than standard feed-forward architecture (Hammerton, 2003)(Sutskev-er et al., 2011)(Liu et al., 2014)(Sundermeyer et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research papers comparing RNNs to feed-forward architectures.",
      "processing_time": 58.102877616882324,
      "citing_paper_id": "9778664",
      "cited_paper_id": 704071
    },
    {
      "context_text": "Remarkable researches are cross-document inference (Ji and Grishman, 2008), cross-event inference (Liao and Grishman, 2010), cross-entity inference (Hong et al., 2011) and modeling textual cohesion (Huang and Riloff, 2012).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research works and methods. No dataset names are present in the text.",
      "processing_time": 58.354182720184326,
      "citing_paper_id": "9778664",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Although there have been already some work to capture the clues beyond sentence to improve sentence level event detection (Ji and Grishman, 2008)(Liao and Grishman, 2010)(Hong et al., 2011), they still exist the following disadvantages: (1) inherent defects in feature-based models; (2) document…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous work and their limitations. No clear, verifiable resource names are provided.",
      "processing_time": 59.2184636592865,
      "citing_paper_id": "9778664",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Most of the existing methods either employed feature-based models with cross-sentence level information (Ji and Grishman, 2008)(Liao and Grishman, 2010)(Hong et al., 2011)(Huang and Riloff, 2012) or followed representation-based architectures with sentence level context (Chen et al., 2015)(Nguyen…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 58.354867935180664,
      "citing_paper_id": "9778664",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "For fair comparisons, the same with (Ji and Grishman, 2008) (Chen et al., 2017) to judge the correctness of the predicted event mentions and use Precision ( P ), Recall ( R ), F-measure ( F 1 ) as the evaluation metrics.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and other papers for comparison.",
      "processing_time": 57.07022786140442,
      "citing_paper_id": "9778664",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "…features and semantic features into one-hot vectors by other natural language processing toolkits, and then sended these well-designed features into the classiﬁers (eg: structure perceptron or support vector machine) and eventually completed the event classiﬁcation (Ahn, 2006)(Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general methods and tools. The context focuses on the process of feature extraction and classification.",
      "processing_time": 58.51109838485718,
      "citing_paper_id": "9778664",
      "cited_paper_id": 6540287
    },
    {
      "context_text": "In order to compute the network parameter θ, we minimize the average negative log-likelihood J(θ) via stochastic gradient descent (SGD) over shuffled mimi-batches with Adam update rule (Kingma and Ba, 2014) and the dropout regularization (Zaremba et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and optimization techniques.",
      "processing_time": 56.16825890541077,
      "citing_paper_id": "9778664",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "…and Grishman, 2010)(Hong et al., 2011)(Huang and Riloff, 2012) or followed representation-based architectures with sentence level context (Chen et al., 2015)(Nguyen and Grishman, 2015)(Li-u et al., 2016)(Nguyen and Grishman, 2016)(N-guyen et al., 2016)(Liu et al., 2017)(Chen et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 58.83810639381409,
      "citing_paper_id": "9778664",
      "cited_paper_id": 11331864
    },
    {
      "context_text": "…and Grishman, 2010)(Hong et al., 2011)(Huang and Riloff, 2012) or followed representation-based architectures with sentence level context (Chen et al., 2015)(Nguyen and Grishman, 2015)(Li-u et al., 2016)(Nguyen and Grishman, 2016)(N-guyen et al., 2016)(Liu et al., 2017)(Chen et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 58.83810639381409,
      "citing_paper_id": "9778664",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "…clues and minimize the dependence on supervised tools and resources for features, we introduce a distributed word representation model (Mikolov et al., 2013a), which has been proved very effective for event detection (Chen et al., 2015)(Nguyen and Grishman, 2015)(Nguyen and Grishman, 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (distributed word representation model) and its effectiveness for event detection. No verifiable datasets are referenced.",
      "processing_time": 59.361313343048096,
      "citing_paper_id": "9778664",
      "cited_paper_id": 11331864
    },
    {
      "context_text": "…vector as the input and encoded the word vector into low-dimensional abstractive representation by the neural network to complete event detection (Nguyen and Grishman, 2015)(Chen et al., 2015)(Nguyen et al., 2016)(Nguyen and Grishman, 2016)(Liu et al., 2016)(Liu et al., 2017)(Chen et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 58.47814393043518,
      "citing_paper_id": "9778664",
      "cited_paper_id": 11331864
    },
    {
      "context_text": "…vector as the input and encoded the word vector into low-dimensional abstractive representation by the neural network to complete event detection (Nguyen and Grishman, 2015)(Chen et al., 2015)(Nguyen et al., 2016)(Nguyen and Grishman, 2016)(Liu et al., 2016)(Liu et al., 2017)(Chen et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 58.47814393043518,
      "citing_paper_id": "9778664",
      "cited_paper_id": 16884406
    },
    {
      "context_text": "…vector as the input and encoded the word vector into low-dimensional abstractive representation by the neural network to complete event detection (Nguyen and Grishman, 2015)(Chen et al., 2015)(Nguyen et al., 2016)(Nguyen and Grishman, 2016)(Liu et al., 2016)(Liu et al., 2017)(Chen et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 58.47814393043518,
      "citing_paper_id": "9778664",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "In this paper, we trained document vectors by using the PV-DM model (Le and Mikolov, 2014), which is very similar to the CBOW model that is another word embedding model (Mikolov et al., 2013a).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. No dataset names are present in the citation span.",
      "processing_time": 57.64375686645508,
      "citing_paper_id": "9778664",
      "cited_paper_id": 16447573
    },
    {
      "context_text": "In this paper, we pre-trained word embedding via skip-gram model (Mikolov et al., 2013b) and New York Times corpus 5 .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "New York Times corpus"
      ],
      "dataset_descriptions": {
        "New York Times corpus": "Used to pre-train word embeddings via the skip-gram model, focusing on generating distributed representations of words and phrases."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'New York Times corpus' which is a specific, identifiable dataset. However, it is used for pre-training word embeddings, which is not directly related to document-level event extraction.",
      "processing_time": 67.19177079200745,
      "citing_paper_id": "9778664",
      "cited_paper_id": 16447573
    },
    {
      "context_text": "The representation of the words as continuous vectors (word embedding) are proved more powerful than discrete representation (Bengio et al., 2003)(Mikolov et al., 2013b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only references to word embeddings and their effectiveness compared to discrete representations.",
      "processing_time": 57.18716335296631,
      "citing_paper_id": "9778664",
      "cited_paper_id": 16447573
    },
    {
      "context_text": "…clues and minimize the dependence on supervised tools and resources for features, we introduce a distributed word representation model (Mikolov et al., 2013a), which has been proved very effective for event detection (Chen et al., 2015)(Nguyen and Grishman, 2015)(Nguyen and Grishman,…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (distributed word representation model) and its effectiveness for event detection. No verifiable datasets are referenced.",
      "processing_time": 59.18064212799072,
      "citing_paper_id": "9778664",
      "cited_paper_id": 16447573
    },
    {
      "context_text": "7) ANN + Attention: It is the representation-based approach proposed by (Liu et al., 2017), which exploited argument information explicitly for event detection via supervised attention mechanisms.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event detection using supervised attention mechanisms.",
      "processing_time": 56.945035457611084,
      "citing_paper_id": "9778664",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "In addition, the standard RNN often suf-355 fers from gradient vanishing or gradient exploding problems during training via backpropagation (Bengio et al., 1994).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RNN) and its training issues.",
      "processing_time": 57.17747378349304,
      "citing_paper_id": "9778664",
      "cited_paper_id": 206457500
    },
    {
      "context_text": "fers from gradient vanishing or gradient exploding problems during training via backpropagation (Bengio et al., 1994).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological challenge in training neural networks.",
      "processing_time": 56.93907427787781,
      "citing_paper_id": "9778664",
      "cited_paper_id": 206457500
    },
    {
      "context_text": "Event Extraction (EE) is a fundamental yet challenging task in information extraction research (Miwa and Bansal, 2016; Katiyar and Cardie, 2016; Fei et al., 2020b; Li et al., 2021b; Fei et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works and methods. No verifiable resources are identified.",
      "processing_time": 57.92560076713562,
      "citing_paper_id": "252089843",
      "cited_paper_id": 2476229
    },
    {
      "context_text": "Event Extraction (EE) is a fundamental yet challenging task in information extraction research (Miwa and Bansal, 2016; Katiyar and Cardie, 2016; Fei et al., 2020b; Li et al., 2021b; Fei et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works and methods. No verifiable resources are identified.",
      "processing_time": 57.92560076713562,
      "citing_paper_id": "252089843",
      "cited_paper_id": 236477583
    },
    {
      "context_text": "Event Extraction (EE) is a fundamental yet challenging task in information extraction research (Miwa and Bansal, 2016; Katiyar and Cardie, 2016; Fei et al., 2020b; Li et al., 2021b; Fei et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works and methods. No verifiable resources are identified.",
      "processing_time": 57.92560076713562,
      "citing_paper_id": "252089843",
      "cited_paper_id": 250340876
    },
    {
      "context_text": "Information extraction is one of the key research track in natural language processing (Miwa and Bansal, 2016; Fei et al., 2021c), among which the event extraction is the most complicated task (Chen et al., 2015; Fei et al., 2022c).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to information extraction and event extraction tasks. No verifiable resources are identified.",
      "processing_time": 58.44391918182373,
      "citing_paper_id": "252089843",
      "cited_paper_id": 2476229
    },
    {
      "context_text": "Information extraction is one of the key research track in natural language processing (Miwa and Bansal, 2016; Fei et al., 2021c), among which the event extraction is the most complicated task (Chen et al., 2015; Fei et al., 2022c).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to information extraction and event extraction tasks. No verifiable resources are identified.",
      "processing_time": 58.44391918182373,
      "citing_paper_id": "252089843",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Information extraction is one of the key research track in natural language processing (Miwa and Bansal, 2016; Fei et al., 2021c), among which the event extraction is the most complicated task (Chen et al., 2015; Fei et al., 2022c).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to information extraction and event extraction tasks. No verifiable resources are identified.",
      "processing_time": 58.44391918182373,
      "citing_paper_id": "252089843",
      "cited_paper_id": 250340876
    },
    {
      "context_text": "1 Event Extraction Information extraction is one of the key research track in natural language processing (Miwa and Bansal, 2016; Fei et al., 2021c), among which the event extraction is the most complicated task (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general references to event extraction and information extraction tasks.",
      "processing_time": 57.28063082695007,
      "citing_paper_id": "252089843",
      "cited_paper_id": 2476229
    },
    {
      "context_text": "Several researchers (Zheng et al., 2017) extend the BIO label scheme to adapt to more complex scenarios.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a tagging scheme. No verifiable resources are identified.",
      "processing_time": 57.15854787826538,
      "citing_paper_id": "252089843",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "BERT-CRF-joint extends the BIO tagging scheme to joint labels of type and role as B/I/O-type-role, inspired by joint extraction of entity and relation (Zheng et al., 2017).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BERT-CRF-joint) and a tagging scheme. No verifiable resources are identified.",
      "processing_time": 58.728379249572754,
      "citing_paper_id": "252089843",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "BERT-CRF-joint extends the BIO tagging scheme to joint labels of type and role as B/I/O-type-role , inspired by joint extraction of entity and relation (Zheng et al., 2017).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BERT-CRF-joint) and a tagging scheme. The cited papers do not introduce any datasets either.",
      "processing_time": 59.179776191711426,
      "citing_paper_id": "252089843",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "BERT-CRF-joint extends the BIO tagging scheme to joint labels of type and role as B/I/O-type-role , inspired by joint extraction of entity and relation (Zheng et al., 2017).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BERT-CRF-joint) and a tagging scheme. The cited papers do not introduce any datasets either.",
      "processing_time": 59.179776191711426,
      "citing_paper_id": "252089843",
      "cited_paper_id": 263873742
    },
    {
      "context_text": "EE facilitates the development of practical applications such as knowledge graph construction (Wei et al., 2019c; Bosselut et al., 2021), biological process analysis (Miwa et al., 2013), and ﬁnancial mar-* ket surveillance (Nuij et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of Event Extraction. No dataset names are present in the text.",
      "processing_time": 57.85158896446228,
      "citing_paper_id": "252089843",
      "cited_paper_id": 11777377
    },
    {
      "context_text": ", 2013), and financial market surveillance (Nuij et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of application. The cited paper title suggests a focus on news data, but no specific dataset is named.",
      "processing_time": 59.208170890808105,
      "citing_paper_id": "252089843",
      "cited_paper_id": 11777377
    },
    {
      "context_text": "Traditional methods for EE (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Nguyen and Nguyen, 2019) regard event extraction as a sequence labeling task, assuming that event mentions do not overlap with each other.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in event extraction.",
      "processing_time": 56.990506172180176,
      "citing_paper_id": "252089843",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Traditional methods for EE (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Nguyen and Nguyen, 2019) regard event extraction as a sequence labeling task, assuming that event mentions do not overlap with each other.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in event extraction.",
      "processing_time": 56.990506172180176,
      "citing_paper_id": "252089843",
      "cited_paper_id": 54437926
    },
    {
      "context_text": "For evaluation, we follow the traditional criteria of previous work (Chen et al., 2015; Du and Cardie, 2020; Sheng et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous work for evaluation criteria.",
      "processing_time": 56.639567852020264,
      "citing_paper_id": "252089843",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Table 2 reports the result of all methods on the overlapped EE dataset, FewFC, while Table 3 reports the results of the nested EE datasets, Genia11 and Genia13.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewFC",
        "Genia11",
        "Genia13"
      ],
      "dataset_descriptions": {
        "FewFC": "Used to evaluate event extraction methods on an overlapped dataset, focusing on few-shot learning scenarios.",
        "Genia11": "Used to evaluate nested event extraction methods, focusing on biomedical events in the Genia corpus.",
        "Genia13": "Used to evaluate nested event extraction methods, focusing on biomedical events in the Genia corpus."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions specific datasets used for evaluating event extraction methods, which are relevant to the document-level event extraction topic.",
      "processing_time": 73.71866035461426,
      "citing_paper_id": "252089843",
      "cited_paper_id": 14339673
    },
    {
      "context_text": ", flat or regular EE) (Li et al., 2013; Nguyen et al., 2016; Liu et al., 2018; Sha et al., 2018; Nguyen and Nguyen, 2019) formulates EE into a sequence labeling task, assigning each token with a label (e.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for event extraction. No verifiable resources are identified.",
      "processing_time": 57.6585738658905,
      "citing_paper_id": "252089843",
      "cited_paper_id": 19220240
    },
    {
      "context_text": ", flat or regular EE) (Li et al., 2013; Nguyen et al., 2016; Liu et al., 2018; Sha et al., 2018; Nguyen and Nguyen, 2019) formulates EE into a sequence labeling task, assigning each token with a label (e.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for event extraction. No verifiable resources are identified.",
      "processing_time": 57.6585738658905,
      "citing_paper_id": "252089843",
      "cited_paper_id": 54437926
    },
    {
      "context_text": "Traditional EE (i.e., ﬂat or regular EE) (Li et al., 2013; Nguyen et al., 2016; Liu et al., 2018; Sha et al., 2018; Nguyen and Nguyen, 2019) formulates EE into a sequence labeling task, assigning each token with a label (e.g., BIO tagging scheme).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and formulations for event extraction. No verifiable resources are identified.",
      "processing_time": 57.83035135269165,
      "citing_paper_id": "252089843",
      "cited_paper_id": 19220240
    },
    {
      "context_text": "Traditional EE (i.e., ﬂat or regular EE) (Li et al., 2013; Nguyen et al., 2016; Liu et al., 2018; Sha et al., 2018; Nguyen and Nguyen, 2019) formulates EE into a sequence labeling task, assigning each token with a label (e.g., BIO tagging scheme).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general methods and formulations for event extraction. No verifiable resources are identified.",
      "processing_time": 57.83035135269165,
      "citing_paper_id": "252089843",
      "cited_paper_id": 54437926
    },
    {
      "context_text": "The gate vector g is produced by a fully-connection layer with the sigmoid function, which can adaptively control the ﬂow of the input: where p and q are input vectors, represented by Eq.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only a technical description of a gate mechanism in a neural network.",
      "processing_time": 57.311399936676025,
      "citing_paper_id": "252089843",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We adopt (Loshchilov and Hutter, 2019) optimizer with the learning rate of 2 e − 5 for BERT and 1 e − 3 for the other modules.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an optimizer method. No datasets are referenced or used in the described context.",
      "processing_time": 57.64929485321045,
      "citing_paper_id": "252089843",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "We adopt AdamW (Loshchilov and Hutter, 2019) optimizer with the learning rate of 2e− 5 for BERT and 1e− 3 for the other modules.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only optimization methods and learning rates.",
      "processing_time": 55.929707050323486,
      "citing_paper_id": "252089843",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "We employ the Chinese Bert-base model for FewFC and BioBERT (Lee et al., 2020) for Ge-nia11 and Genia13.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewFC",
        "Ge-nia11",
        "Genia13"
      ],
      "dataset_descriptions": {
        "FewFC": "Used to evaluate few-shot learning performance of the Chinese Bert-base model, focusing on document-level event extraction tasks.",
        "Ge-nia11": "Used to evaluate the performance of BioBERT on document-level event extraction tasks in the biomedical domain.",
        "Genia13": "Used to evaluate the performance of BioBERT on document-level event extraction tasks in the biomedical domain."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions models (Chinese Bert-base, BioBERT) and datasets (FewFC, Ge-nia11, Genia13). However, only the datasets are relevant for extraction.",
      "processing_time": 77.86875438690186,
      "citing_paper_id": "252089843",
      "cited_paper_id": 59291975
    },
    {
      "context_text": "2 Implementation Details We employ the Chinese Bert-base model for FewFC and BioBERT (Lee et al., 2020) for Ge-",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewFC"
      ],
      "dataset_descriptions": {
        "FewFC": "Used to train and evaluate models for few-shot learning tasks in Chinese, focusing on the performance of the Chinese Bert-base model."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'FewFC' and 'BioBERT', but BioBERT is a model, not a dataset. FewFC is likely a dataset, but there is no additional information about its use or characteristics.",
      "processing_time": 67.25783252716064,
      "citing_paper_id": "252089843",
      "cited_paper_id": 59291975
    },
    {
      "context_text": "Finally, we enumerate all event types in the selected event type set E (cid:48) and get the total loss: where S (cid:48) is a subset sampled from S , we detail the sampling strategy in the appendix.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to a subset sampled from a larger set. No verifiable resource names are present.",
      "processing_time": 58.739638328552246,
      "citing_paper_id": "252089843",
      "cited_paper_id": 195786159
    },
    {
      "context_text": "For two vectors p i and p j from a sequence of representations, we combine them with corresponding position embeddings from Su et al. (2021), and then calculate the score by the dot product of them: where R i and R j are position embeddings of p i and p j , R j − i = R i R j .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method involving position embeddings. The cited paper title 'RoFormer: Enhanced Transformer with Rotary Position Embedding' confirms this is about a method, not a dataset.",
      "processing_time": 60.57802152633667,
      "citing_paper_id": "252089843",
      "cited_paper_id": 233307138
    },
    {
      "context_text": "Recently, the grid tagging scheme is used in a lot of information extraction tasks, such as opinion mining (Wu et al., 2020), relation extraction (Wang et al., 2020), and named entity recognition (Wang et al., 2021), due to its characteristic of presenting relations between word pairs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only various tasks where the grid tagging scheme is applied. No clear identifiers for datasets are present.",
      "processing_time": 57.740230560302734,
      "citing_paper_id": "252089843",
      "cited_paper_id": 235266101
    },
    {
      "context_text": ", 2020), and named entity recognition (Wang et al., 2021), due to its characteristic of presenting relations between word pairs.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general tasks such as named entity recognition. No verifiable resources are identified.",
      "processing_time": 57.92596173286438,
      "citing_paper_id": "252089843",
      "cited_paper_id": 235266101
    },
    {
      "context_text": "Liu et al. (2018) jointly extracts multiple event triggers and arguments by introducing attention-based GCN to model the dependency graph information (Fei et al., 2021b; Li et al., 2021a; Fei et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the methodology used for event extraction and relation extraction.",
      "processing_time": 58.198500633239746,
      "citing_paper_id": "252089843",
      "cited_paper_id": 236477583
    },
    {
      "context_text": "Liu et al. (2018) jointly extracts multiple event triggers and arguments by introducing attention-based GCN to model the dependency graph information (Fei et al., 2021b; Li et al., 2021a; Fei et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the methodology used for event extraction and relation extraction.",
      "processing_time": 58.198500633239746,
      "citing_paper_id": "252089843",
      "cited_paper_id": 250340876
    },
    {
      "context_text": "(2018) jointly extracts multiple event triggers and arguments by introducing attention-based GCN to model the dependency graph information (Fei et al., 2021b; Li et al., 2021a; Fei et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the methodology used for event extraction.",
      "processing_time": 57.740336894989014,
      "citing_paper_id": "252089843",
      "cited_paper_id": 250340876
    },
    {
      "context_text": "Yet most are performed with different ontologies such as Nombank ( G&C ) and FrameNet ( SemEval-2010 and 80Days ); on different domains (e.g. novels); and in smaller scales ( G&C and 80Days only cover 10 types of predicates).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Nombank",
        "FrameNet",
        "80Days"
      ],
      "dataset_descriptions": {
        "Nombank": "Used for semantic role labeling of nominal predicates, providing annotations for implicit arguments in a limited set of predicate types.",
        "FrameNet": "Utilized for semantic role labeling across various domains, including novels, with a focus on different ontologies and predicate types.",
        "80Days": "Employed for semantic role labeling in a smaller scale, covering a limited set of predicate types and domains."
      },
      "confidence_score": 0.8,
      "reasoning": "The citation mentions 'Nombank', 'FrameNet', and '80Days' but does not specify their use as datasets. These are likely ontologies or resources used in semantic role labeling, which is related to event extraction.",
      "processing_time": 79.44359922409058,
      "citing_paper_id": "220046861",
      "cited_paper_id": 5806560
    },
    {
      "context_text": "There are several annotation efforts for implicit arguments in SRL, including G&C (Gerber and Chai, 2010, 2012), SemEval-2010 (Ruppenhofer et al., 2009, 2010), and 80Days (Feizabadi and Pad´o, 2014).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "G&C",
        "SemEval-2010",
        "80Days"
      ],
      "dataset_descriptions": {
        "G&C": "Used for semantic role labeling of implicit arguments in nominal predicates, providing annotated data for training and evaluation.",
        "SemEval-2010": "Used for evaluating systems on the task of identifying implicit arguments in semantic role labeling, serving as a benchmark dataset.",
        "80Days": "Used for annotating implicit arguments in semantic role labeling, focusing on a diverse set of texts and contexts."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions three annotation efforts for implicit arguments in SRL, which are likely datasets or annotated corpora. However, the context does not specify how they are used in the current research.",
      "processing_time": 78.70624589920044,
      "citing_paper_id": "220046861",
      "cited_paper_id": 5806560
    },
    {
      "context_text": "There are several annotation efforts for implicit arguments in SRL, including G&C (Gerber and Chai, 2010, 2012), SemEval-2010 (Ruppenhofer et al., 2009, 2010), and 80Days (Feizabadi and Pad´o, 2014).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "G&C",
        "SemEval-2010",
        "80Days"
      ],
      "dataset_descriptions": {
        "G&C": "Used for semantic role labeling of implicit arguments in nominal predicates, providing annotated data for training and evaluation.",
        "SemEval-2010": "Used for evaluating systems on the task of identifying implicit arguments in semantic role labeling, serving as a benchmark dataset.",
        "80Days": "Used for annotating implicit arguments in semantic role labeling, focusing on a diverse set of texts and contexts."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions three annotation efforts for implicit arguments in SRL, which are likely datasets or annotated corpora. However, the context does not specify how they are used in the current research.",
      "processing_time": 78.70624589920044,
      "citing_paper_id": "220046861",
      "cited_paper_id": 6534839
    },
    {
      "context_text": "Most of previous systems (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Wang et al., 2019) only consider local arguments in the same sentence of the event trigger.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses limitations of previous systems in event extraction.",
      "processing_time": 57.18368053436279,
      "citing_paper_id": "220046861",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Most of previous systems (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Wang et al., 2019) only consider local arguments in the same sentence of the event trigger.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses limitations of previous systems in event extraction.",
      "processing_time": 57.18368053436279,
      "citing_paper_id": "220046861",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Recent state-of-the-art solutions for sentence-level SRL perform the detection in an end-to-end setting, such as span-based (He et al., 2018; Ouchi et al., 2018), and sequence labeling models (He et al., 2017; Shi and Lin, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods for semantic role labeling. No verifiable resources are identified.",
      "processing_time": 57.88221836090088,
      "citing_paper_id": "220046861",
      "cited_paper_id": 6534839
    },
    {
      "context_text": "Recent state-of-the-art solutions for sentence-level SRL perform the detection in an end-to-end setting, such as span-based (He et al., 2018; Ouchi et al., 2018), and sequence labeling models (He et al., 2017; Shi and Lin, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods for semantic role labeling. No verifiable resources are identified.",
      "processing_time": 57.88221836090088,
      "citing_paper_id": "220046861",
      "cited_paper_id": 52920257
    },
    {
      "context_text": "It resembles semantic role labeling (SRL) in that the main target is to ﬁnd argument spans to ﬁll the roles of event frames.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison to semantic role labeling (SRL). No verifiable resources are identified.",
      "processing_time": 58.182987451553345,
      "citing_paper_id": "220046861",
      "cited_paper_id": 6534839
    },
    {
      "context_text": "Inspired by dependency-based SRL (Surdeanu et al., 2008; Hajiˇc et al., 2009), we take the syntactical head-words as the proxy for full argument spans, hypothesizing that the head-words can contain enough information to ﬁll the argument roles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological approach inspired by previous work. No verifiable resources are identified.",
      "processing_time": 58.04722547531128,
      "citing_paper_id": "220046861",
      "cited_paper_id": 6534839
    },
    {
      "context_text": "Actually, this type of two-step setup is not uncommon in prior work of information extraction, including entity detection (Lin et al., 2019), coreference resolution (Peng et al., 2015) and document-level pseudo-coreference (Jauhar et al., 2015; Liu et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and prior work. No dataset names are present in the text.",
      "processing_time": 58.0406699180603,
      "citing_paper_id": "220046861",
      "cited_paper_id": 8024511
    },
    {
      "context_text": "Actually, this type of two-step setup is not uncommon in prior work of information extraction, including entity detection (Lin et al., 2019), coreference resolution (Peng et al., 2015) and document-level pseudo-coreference (Jauhar et al., 2015; Liu et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and prior work. No dataset names are present in the text.",
      "processing_time": 58.0406699180603,
      "citing_paper_id": "220046861",
      "cited_paper_id": 17010034
    },
    {
      "context_text": ", 2015) and document-level pseudo-coreference (Jauhar et al., 2015; Liu et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. No verifiable resources are identified.",
      "processing_time": 57.05922555923462,
      "citing_paper_id": "220046861",
      "cited_paper_id": 8024511
    },
    {
      "context_text": "Yet most are performed with different ontologies such as Nombank (G&C) and FrameNet (SemEval-2010 and 80Days); on different domains (e.g. novels); and in smaller scales (G&C and 80Days only cover 10 types of predicates).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Nombank",
        "FrameNet",
        "80Days"
      ],
      "dataset_descriptions": {
        "Nombank": "Used to study implicit arguments for nominal predicates, focusing on a limited set of predicate types in various domains.",
        "FrameNet": "Utilized for semantic role labeling in different domains, including novels, to compare with other ontologies and datasets.",
        "80Days": "Applied to evaluate event extraction systems on a smaller scale, covering a limited set of predicate types."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'Nombank', 'FrameNet', and '80Days' but does not specify their use as datasets. However, given the research topic and the nature of these resources, they are likely to be datasets used for event extraction.",
      "processing_time": 78.90713405609131,
      "citing_paper_id": "220046861",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "Therefore, he bought the cheaper one.\nin SRL, including G&C (Gerber and Chai, 2010, 2012), SemEval-2010 (Ruppenhofer et al., 2009, 2010), and 80Days (Feizabadi and Padó, 2014).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SemEval-2010",
        "80Days"
      ],
      "dataset_descriptions": {
        "SemEval-2010": "Used for evaluating semantic role labeling systems, focusing on implicit arguments for nominal predicates in the context of the SemEval-2010 shared task.",
        "80Days": "Employed to train and evaluate models on document-level event extraction, specifically addressing challenges in cross-sentence event coreference."
      },
      "confidence_score": 0.8,
      "reasoning": "The citation mentions 'G&C', 'SemEval-2010', and '80Days' which are likely datasets or benchmarks. However, 'G&C' is not a clear dataset name. 'SemEval-2010' and '80Days' are included as they are specific and plausibly datasets.",
      "processing_time": 80.33729767799377,
      "citing_paper_id": "220046861",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "resolution (Peng et al., 2015) and document-level pseudo-coreference (Jauhar et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. The context is too vague to identify any verifiable datasets.",
      "processing_time": 58.2097327709198,
      "citing_paper_id": "220046861",
      "cited_paper_id": 17010034
    },
    {
      "context_text": "…representations of the candidate ( e c ) and the predicate ( e p ), which are calculated by BERT as described in § where the normalization is done over the argument candidate set C (or null (cid:15) , whose score is ﬁxed to 0) for each role, following (Ebner et al., 2020; Ouchi et al., 2018).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the use of BERT for calculating representations, which is a method, not a dataset.",
      "processing_time": 59.41801142692566,
      "citing_paper_id": "220046861",
      "cited_paper_id": 52920257
    },
    {
      "context_text": "This line of work is further extended by studies on implicit semantic role labeling (Ruppenhofer et al., 2009; Moor et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to studies on implicit semantic role labeling.",
      "processing_time": 56.97064471244812,
      "citing_paper_id": "243865143",
      "cited_paper_id": 1671874
    },
    {
      "context_text": "Additionally, we show explicit data augmentation can also beneﬁt learning — it leads to +1.7% in F1 for the model based on sequence labeling (Shi and Lin, 2019).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a performance improvement using data augmentation. No verifiable resource is identified.",
      "processing_time": 57.93274426460266,
      "citing_paper_id": "243865143",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "The following state-of-the-art methods are treated as baselines for comparison: • BERT-CRF (Shi and Lin, 2019), which combines BERT with Condition Random Field (Lafferty et al., 2001), achieving state-of-the-art performance on sentence-level SRL task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT-CRF and CRF but does not refer to any specific datasets. The focus is on comparing methods, not using datasets.",
      "processing_time": 58.72466421127319,
      "citing_paper_id": "243865143",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "The following state-of-the-art methods are treated as baselines for comparison: • BERT-CRF (Shi and Lin, 2019), which combines BERT with Condition Random Field (Lafferty et al., 2001), achieving state-of-the-art performance on sentence-level SRL task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT-CRF and CRF but does not refer to any specific datasets. The focus is on comparing methods, not using datasets.",
      "processing_time": 58.72466421127319,
      "citing_paper_id": "243865143",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "…83.5%, 72.1%, and 70.1% in F1 on SQuAD 2.0, FrameNet SRL, and ACE EE respectively, matching the state-of-the-art performance (Devlin et al., 2019; Shi and Lin, 2019; Liu et al., 2020); in the ﬁne-tuning state, we tune parameters on the development set, and ﬁnally the batch size is set as 20,…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SQuAD 2.0",
        "FrameNet SRL",
        "ACE EE"
      ],
      "dataset_descriptions": {
        "SQuAD 2.0": "Used to evaluate model performance on question answering, achieving 83.5% F1 score.",
        "FrameNet SRL": "Used to evaluate model performance on semantic role labeling, achieving 72.1% F1 score.",
        "ACE EE": "Used to evaluate model performance on event extraction, achieving 70.1% F1 score."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions SQuAD 2.0, FrameNet SRL, and ACE EE as evaluation datasets, but does not provide specific details on their usage beyond reporting performance metrics.",
      "processing_time": 78.89642453193665,
      "citing_paper_id": "243865143",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Different from previous methods addressing the task via sequence labeling (Shi and Lin, 2019) or span ranking (Ebner et al., 2020), we propose a new perspective based on MRC. Query Generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on comparing different methodologies for document-level event extraction.",
      "processing_time": 58.377583265304565,
      "citing_paper_id": "243865143",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "BERT-CRF (Shi and Lin, 2019) 40.3 41.5 +1.2 SpanSel (Ebner et al., 2020) 40.7 41.5 +0.8 Head-Expand (Zhang et al., 2020) 41.8 42.9 +1.1 BART-Gen (Li et al., 2021) 42 (2) With the assistance of the god Hermes, Hector’s fa-ther [Priam] participant goes to [Achilles’ tent] place to plead with Achilles…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 58.37019181251526,
      "citing_paper_id": "243865143",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "BERT-CRF (Shi and Lin, 2019) 40.3 41.5 +1.2 SpanSel (Ebner et al., 2020) 40.7 41.5 +0.8 Head-Expand (Zhang et al., 2020) 41.8 42.9 +1.1 BART-Gen (Li et al., 2021) 42 (2) With the assistance of the god Hermes, Hector’s fa-ther [Priam] participant goes to [Achilles’ tent] place to plead with Achilles…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 58.37019181251526,
      "citing_paper_id": "243865143",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Compared with implicit knowledge transfer, explicit data augmentation can generate tangible training examples, which is shown to beneﬁt a wide range of previous models (e.g., that based on sequence labeling (Shi and Lin, 2019)) for the task.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to 'tangible training examples' and 'sequence labeling'. No clear, verifiable resource names are present.",
      "processing_time": 59.46345663070679,
      "citing_paper_id": "243865143",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "BERT-CRF (2020), we adopt two experimental settings, where \"w/ Type Constraint\" and \"w/o Type Constraint\" indicate considering gold event types or not.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only experimental settings and a model (BERT-CRF). No verifiable resources are identified.",
      "processing_time": 58.20805478096008,
      "citing_paper_id": "243865143",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "BERT-CRF (Shi and Lin, 2019) 40.3 41.5 +1.2 SpanSel (Ebner et al., 2020) 40.7 41.5 +0.8 Head-Expand (Zhang et al., 2020) 41.8 42.9 +1.1 BART-Gen (Li et al., 2021) 42 (2) With the assistance of the god Hermes, Hector’s fa-ther [Priam] participant goes to [Achilles’ tent] place to plead with Achilles for the return of Hector’s body so that he can be buried.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and their performance metrics. The context is about comparing different models' performance on a task, likely relation extraction or semantic role labeling.",
      "processing_time": 60.551509141922,
      "citing_paper_id": "243865143",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Moreover, we note the data generated by explicit data augmentation can also help other models, e.g., BERT-CRF and Head-Expand, to address the zero-shot scenario.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to models and methods.",
      "processing_time": 57.020522117614746,
      "citing_paper_id": "243865143",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "…augmentation can be seen as “eliciting” knowledge from a pre-trained MRC model, and as the training set is explicitly expanded, it has the potential to beneﬁt any model (e.g., that based on sequence labeling (Shi and Lin, 2019) or span prediction (Ebner et al., 2020)) proposed for implicit EAE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of data augmentation and its potential benefits for various models.",
      "processing_time": 58.99942660331726,
      "citing_paper_id": "243865143",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "• BART-Gen 5 (Li et al., 2021), a concurrent work to ours, adopts a generative perspective to address implicit EAE, based on the BART architecture (Lewis et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the BART architecture and its application to event argument extraction.",
      "processing_time": 58.844568729400635,
      "citing_paper_id": "243865143",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "• BART-Gen 5 (Li et al., 2021), a concurrent work to ours, adopts a generative perspective to address implicit EAE, based on the BART architecture (Lewis et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the BART architecture and its application to event argument extraction.",
      "processing_time": 58.844568729400635,
      "citing_paper_id": "243865143",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Following the work, Zhang et al. (2020) devise a head-to-region approach, demonstrating very promising results; Gangal and Hovy (2020) investigate to what extent the pre-trained language model can beneﬁt learning.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the extent to which pre-trained language models benefit learning in event argument extraction tasks, focusing on the model's existing knowledge of event arguments."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions the RAMS dataset, which is a well-known resource for event argument extraction. The context indicates its use in evaluating pre-trained language models.",
      "processing_time": 65.8885760307312,
      "citing_paper_id": "243865143",
      "cited_paper_id": 222208551
    },
    {
      "context_text": "Very recently, Li et al. (2021) investigate a generative perspective on the task, achieving state-of-the-art performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a generative approach to document-level event argument extraction.",
      "processing_time": 57.389363050460815,
      "citing_paper_id": "243865143",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "The expensive experiments on two datasets, RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021), have justiﬁed the effectiveness of our approach.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to validate the effectiveness of the document-level event argument extraction approach through conditional generation, focusing on complex event structures.",
        "WikiEvents": "Utilized to evaluate the performance of the proposed method on document-level event extraction, emphasizing the accuracy and robustness of the system."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used to justify the effectiveness of the approach described in the paper.",
      "processing_time": 70.33740377426147,
      "citing_paper_id": "243865143",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We conduct our experiments on two implicit EAE benchmarks RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate implicit event argument extraction, focusing on document-level conditional generation methods.",
        "WikiEvents": "Used to assess performance in implicit event argument extraction, specifically for document-level event extraction tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS' and 'WikiEvents' as benchmarks for implicit EAE. These are specific datasets used for evaluation in the research.",
      "processing_time": 68.721608877182,
      "citing_paper_id": "243865143",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Following Ebner et al. indicates the co-reference relation is considered into evaluation (Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context is too vague to identify a dataset.",
      "processing_time": 57.45548701286316,
      "citing_paper_id": "243865143",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "In our MRC model, we use a BERT-base-uncased encoder (Devlin et al., 2019), to keep consistent with previous studies (Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of BERT for consistency with previous studies.",
      "processing_time": 58.601473569869995,
      "citing_paper_id": "243865143",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "A2: Syria ments appear in texts (Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a paper. No clear identifiers for datasets are present.",
      "processing_time": 57.95484256744385,
      "citing_paper_id": "243865143",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Experience with event annotation for Light ERE and ACE (Doddington et al., 2004) and related tasks suggests that a major challenge for annotation consistency is poor recall – human annotators are not highly consistent in recognizing that a mention has occurred.",
      "catation_intent": "findings",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE"
      ],
      "dataset_descriptions": {
        "ACE": "Used to highlight annotation consistency issues in event recognition, focusing on the challenges of human annotators in identifying event mentions."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'ACE' which is a known dataset in the field of event extraction. However, it is used to discuss annotation challenges rather than as a primary dataset for the research.",
      "processing_time": 65.18741250038147,
      "citing_paper_id": "3137086",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "The data includes both formal newswire text (NW) and informal discussion forums (DF), drawn from a pool of data also labeled for the DARPA DEFT Program’s Light Entities, Relations and Events (Light ERE) task (Song et al., 2015), and/or the NIST TAC KBP Evaluation Event Argument Task (Ellis et al., 2014), with the goal of ultimately being able to take advantage of multiple styles of event annotation on the same data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DARPA DEFT Program’s Light Entities, Relations and Events (Light ERE) task",
        "NIST TAC KBP Evaluation Event Argument Task"
      ],
      "dataset_descriptions": {
        "DARPA DEFT Program’s Light Entities, Relations and Events (Light ERE) task": "Used for event annotation in both formal newswire and informal discussion forum texts, providing a basis for comparing different styles of annotation.",
        "NIST TAC KBP Evaluation Event Argument Task": "Used for event argument annotation in the same text types, enabling the integration of multiple annotation styles for comprehensive event extraction."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific datasets used for event annotation, which are relevant to document-level event extraction.",
      "processing_time": 77.30770659446716,
      "citing_paper_id": "3137086",
      "cited_paper_id": 63410500
    },
    {
      "context_text": "…for the DARPA DEFT Program’s Light Entities, Relations and Events (Light ERE) task (Song et al., 2015), and/or the NIST TAC KBP Evaluation Event Argument Task (Ellis et al., 2014), with the goal of ultimately being able to take advantage of multiple styles of event annotation on the same data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions two specific tasks that involve event annotation, which are likely to have associated datasets. However, the names 'Light ERE' and 'TAC KBP Evaluation Event Argument Task' do not clearly indicate datasets but rather tasks or evaluations.",
      "processing_time": 61.373963594436646,
      "citing_paper_id": "3137086",
      "cited_paper_id": 63410500
    },
    {
      "context_text": "The classic template-ﬁlling task in information extraction involves extracting event-based templates from documents (Grishman and Sundheim, 1996; Jurafsky and Martin, 2009; Grishman, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general task in information extraction. No dataset names are present in the citation span.",
      "processing_time": 57.817742109298706,
      "citing_paper_id": "235097664",
      "cited_paper_id": 5188467
    },
    {
      "context_text": "Note that Chambers (2013) and Cheung et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to authors and their work. There is no clear indication of a reusable resource.",
      "processing_time": 58.20097231864929,
      "citing_paper_id": "235097664",
      "cited_paper_id": 6341459
    },
    {
      "context_text": "Alternative end-to-end event extraction models, even those incorporating pretrained LM representations, only model events in isolation (Wadden et al., 2019; Du and Cardie, 2020), and are mainly evaluated on ACE-style (Doddington et al., 2004) event extraction from single sentences (Yang and Mitchell, 2016; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'ACE-style' event extraction, which refers to the ACE program. However, 'ACE' is not a dataset but a program that defines tasks and evaluation methods.",
      "processing_time": 58.86475348472595,
      "citing_paper_id": "235097664",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "…extraction models, even those incorporating pretrained LM representations, only model events in isolation (Wadden et al., 2019; Du and Cardie, 2020), and are mainly evaluated on ACE-style (Doddington et al., 2004) event extraction from single sentences (Yang and Mitchell, 2016; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'ACE-style' event extraction, which refers to the ACE program. However, 'ACE' is not a dataset but a program that defines tasks and evaluation methods.",
      "processing_time": 58.85856914520264,
      "citing_paper_id": "235097664",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "We assign types by transforming the problem to multi-class classiﬁcation (MCC) (Spolaor et al., 2013).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for transforming the problem to multi-class classification.",
      "processing_time": 56.921557903289795,
      "citing_paper_id": "235097664",
      "cited_paper_id": 14891665
    },
    {
      "context_text": "As there are 6 event types (i.e., kid-napping , attack , bombing , robbery , arson , forced work stoppage ) in MUC-4, we use 2 6 labels for the MCC problem.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate multi-label classification for event extraction, focusing on six specific event types including kidnapping, attack, bombing, robbery, arson, and forced work stoppage."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions MUC-4, which is a known dataset for event extraction, but does not provide details on its usage or the specific research context.",
      "processing_time": 66.82748341560364,
      "citing_paper_id": "235097664",
      "cited_paper_id": 14891665
    },
    {
      "context_text": "BERT as Encoder and Decoder Our model extends upon the G RIT model for REE (Du et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (G RIT) which is not a dataset. The context is about extending a model for document-level event entity extraction.",
      "processing_time": 60.18910264968872,
      "citing_paper_id": "235097664",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "We build our framework upon G RIT (Du et al., 2020), which tackles role-ﬁller entity extraction (REE), but not template/event recognition.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions G RIT but does not refer to it as a dataset. It is described as a framework or method for role-filler entity extraction, not a dataset.",
      "processing_time": 60.01920676231384,
      "citing_paper_id": "235097664",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "Simpliﬁcations of the task (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012; Du et al., 2020) assume that there is one generic template and focus only on role-ﬁller entity extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only simplifications of the task. No dataset names are present in the citation span.",
      "processing_time": 58.386921882629395,
      "citing_paper_id": "235097664",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "To distinguish the encoder / decoder representations, it uses partial causal attention mask on the decoder side (Du et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context focuses on the technical details of the method, not on the use of a dataset.",
      "processing_time": 59.777817726135254,
      "citing_paper_id": "235097664",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "…successfully applied to many NLP tasks, e.g., dialogue response generation (Weston et al., 2018; Wu et al., 2019; Cai et al., 2019a,b), machine translation (Zhang et al., 2018; Xu et al., 2020; He et al., 2021) and information extraction (Lee et al., 2022; Zhang et al., 2022; Chen et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and methods. No verifiable resources are identified.",
      "processing_time": 57.916369676589966,
      "citing_paper_id": "259370571",
      "cited_paper_id": 4698173
    },
    {
      "context_text": "…successfully applied to many NLP tasks, e.g., dialogue response generation (Weston et al., 2018; Wu et al., 2019; Cai et al., 2019a,b), machine translation (Zhang et al., 2018; Xu et al., 2020; He et al., 2021) and information extraction (Lee et al., 2022; Zhang et al., 2022; Chen et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and methods. No verifiable resources are identified.",
      "processing_time": 57.916369676589966,
      "citing_paper_id": "259370571",
      "cited_paper_id": 220045828
    },
    {
      "context_text": "Retrieval-augmented methods have recently been successfully applied to many NLP tasks, e.g., dialogue response generation (Weston et al., 2018; Wu et al., 2019; Cai et al., 2019a,b), machine translation (Zhang et al., 2018; Xu et al., 2020; He et al., 2021) and information extraction (Lee et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 59.23463273048401,
      "citing_paper_id": "259370571",
      "cited_paper_id": 49312395
    },
    {
      "context_text": "We ﬁne-tune the models on each dataset independently using AdamW (Loshchilov and Hutter, 2019) and conducted experiments on 4 NVIDIA-V100-32GB.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the optimization algorithm (AdamW) and hardware used. No verifiable datasets are referenced.",
      "processing_time": 59.23125219345093,
      "citing_paper_id": "259370571",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "…consistent comparison, we divide several state-of-the-art models into three categories: (1) Multi-label classiﬁcation-based model: BERT-CRF (Shi and Lin, 2019), PAIE (Ma et al., 2022); (2) QA-based model: EEQA (Du and Cardie, 2020) and DocMRC (Liu et al., 2021); and (3) Generation-based…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 58.585036277770996,
      "citing_paper_id": "259370571",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "For strictly consistent comparison, we divide several state-of-the-art models into three categories: (1) Multi-label classiﬁcation-based model: BERT-CRF (Shi and Lin, 2019), PAIE (Ma et al., 2022); (2) QA-based model: EEQA (Du and Cardie, 2020) and DocMRC (Liu et al., 2021); and (3) Generation-based model: BART-Gen (Li et al., 2021) and T5-baseline.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models but does not refer to any specific datasets. The context is focused on categorizing models rather than using datasets.",
      "processing_time": 59.226136684417725,
      "citing_paper_id": "259370571",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "For strictly consistent comparison, we divide several state-of-the-art models into three categories: (1) Multi-label classiﬁcation-based model: BERT-CRF (Shi and Lin, 2019), PAIE (Ma et al., 2022); (2) QA-based model: EEQA (Du and Cardie, 2020) and DocMRC (Liu et al., 2021); and (3) Generation-based model: BART-Gen (Li et al., 2021) and T5-baseline.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models but does not refer to any specific datasets. The context is focused on categorizing models rather than using datasets.",
      "processing_time": 59.226136684417725,
      "citing_paper_id": "259370571",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…strictly consistent comparison, we divide several state-of-the-art models into three categories: (1) Multi-label classiﬁcation-based model: BERT-CRF (Shi and Lin, 2019), PAIE (Ma et al., 2022); (2) QA-based model: EEQA (Du and Cardie, 2020) and DocMRC (Liu et al., 2021); and (3) Generation-based…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 59.21876335144043,
      "citing_paper_id": "259370571",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Du and Ji (2022) applied S-BERT (Reimers and Gurevych, 2019) to retrieve the most relevant example for event extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions S-BERT, which is a method, not a dataset. No specific dataset is mentioned or used in the context.",
      "processing_time": 58.582356214523315,
      "citing_paper_id": "259370571",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "First sample a noise variable (cid:2) from N (0 , 1) Then transform it to 9 − W Calculate the current sample: retrieve (also via S-BERT) the instance label y r that is the top-k relevant to the input label from the training corpus D train .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'training corpus D train' but does not provide enough information to determine if it is a specific, verifiable dataset. The name 'D train' is too generic and lacks specific identifiers.",
      "processing_time": 61.06717228889465,
      "citing_paper_id": "259370571",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "For retrieval, we use S-BERT (Reimers and Gurevych, 2019) to retrieve semantically similar documents x r ∈ D train .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions S-BERT for retrieving semantically similar documents but does not mention any specific dataset. S-BERT is a method, not a dataset.",
      "processing_time": 59.36774945259094,
      "citing_paper_id": "259370571",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "We adopt the T5 model (Raffel et al., 2022), an encoder-decoder pre-trained model, as a backbone.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the T5 model but does not refer to any specific dataset. The T5 model is a method, not a dataset.",
      "processing_time": 59.03496956825256,
      "citing_paper_id": "259370571",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "These retrieval-augmented methods use similarity-based retrieval, which is based on a simple hypothesis (Li et al., 2022): the more x r (retrieved demonstration) resembles x (original input), the more likely y r (demonstration label) resembles y (input label), so it will help the generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. There are no clear identifiers for datasets in the text.",
      "processing_time": 58.61709380149841,
      "citing_paper_id": "259370571",
      "cited_paper_id": 246472929
    },
    {
      "context_text": "(Ma et al., 2022), and ‡ denotes the results from our implemented models for a fairer comparison.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a reference to results from implemented models.",
      "processing_time": 57.499815940856934,
      "citing_paper_id": "259370571",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "For BART-base model, we report the results from Ma et al. (2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a paper. No dataset names are present in the citation span.",
      "processing_time": 58.86273384094238,
      "citing_paper_id": "259370571",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…we divide several state-of-the-art models into three categories: (1) Multi-label classiﬁcation-based model: BERT-CRF (Shi and Lin, 2019), PAIE (Ma et al., 2022); (2) QA-based model: EEQA (Du and Cardie, 2020) and DocMRC (Liu et al., 2021); and (3) Generation-based model: BART-Gen (Li et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 58.013734340667725,
      "citing_paper_id": "259370571",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "7 We adopt the scoring function from Lee et al. (2017); He et al. (2018) which decomposes the function into unary and binary scores 8 i.e., l ( a, ˜ a e,r ) = s E ( e ) + s E,R ( e, r ) + s A,R ( a, r ) where φ l ( a, ˜ a e,r ) is an additional feature vector containing information such as document…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only scoring functions and feature vectors. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 59.17946910858154,
      "citing_paper_id": "207853145",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "Similarly, we represent all candidate arguments with a span embedding ˜ a , consistent with Lee et al. (2017).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for representing candidate arguments using span embeddings.",
      "processing_time": 57.553444147109985,
      "citing_paper_id": "207853145",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "Representations To represent spans from within the text, we adopt the convention from Lee et al. (2017) to compute vector representations of each span by independently encoding each sentence with a bidirectional LSTM starting from contextualized encodings (Peters et al., 2018; De-vlin et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on representation techniques and neural architectures.",
      "processing_time": 58.472702980041504,
      "citing_paper_id": "207853145",
      "cited_paper_id": 1222212
    },
    {
      "context_text": "…from Lee et al. (2017) to compute vector representations of each span by independently encoding each sentence with a bidirectional LSTM starting from contextualized encodings (Peters et al., 2018; De-vlin et al., 2018), GloVe embeddings (Pennington et al., 2014), and character-level convolutions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods such as GloVe embeddings and bidirectional LSTM. No verifiable datasets are referenced.",
      "processing_time": 59.407301902770996,
      "citing_paper_id": "207853145",
      "cited_paper_id": 1957433
    },
    {
      "context_text": "Although non-local arguments are a common phenomenon (Gerber and Chai (2012) found that their annotation of non-local arguments added 71% (relative) role coverage to NomBank annotations), these datasets are signiﬁcantly smaller than RAMS: the SemEval shared task training set contains 1,370 frame instantiations over 438 sentences, and the data from Gerber and Chai (2012) It is not surprising that across multiple datasets, a signiﬁcant number of event arguments are observed to be non-local given the analysis of zero anaphora and deﬁnite null complements by Fillmore (1986) and the distinction between “core” and “non-core” frame elements or roles in FrameNet (Baker et al., 1998) and Prop-Bank (Palmer et al., 2005).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "SemEval shared task training set"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to compare the size and coverage of event argument datasets, highlighting its larger scale compared to other datasets.",
        "SemEval shared task training set": "Used to illustrate the smaller scale of event argument datasets, containing 1,370 frame instantiations over 438 sentences."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions multiple datasets but does not provide specific names for all. Only 'RAMS' and 'SemEval shared task training set' are clearly identified and used in the research context.",
      "processing_time": 74.72928738594055,
      "citing_paper_id": "207853145",
      "cited_paper_id": 2486369
    },
    {
      "context_text": "Although non-local arguments are a common phenomenon (Gerber and Chai (2012) found that their annotation of non-local arguments added 71% (relative) role coverage to NomBank annotations), these datasets are signiﬁcantly smaller than RAMS: the SemEval shared task training set contains 1,370 frame instantiations over 438 sentences, and the data from Gerber and Chai (2012) It is not surprising that across multiple datasets, a signiﬁcant number of event arguments are observed to be non-local given the analysis of zero anaphora and deﬁnite null complements by Fillmore (1986) and the distinction between “core” and “non-core” frame elements or roles in FrameNet (Baker et al., 1998) and Prop-Bank (Palmer et al., 2005).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "SemEval shared task training set"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to compare the size and coverage of event argument datasets, highlighting its larger scale compared to other datasets.",
        "SemEval shared task training set": "Used to illustrate the smaller scale of event argument datasets, containing 1,370 frame instantiations over 438 sentences."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions multiple datasets but does not provide specific names for all. Only 'RAMS' and 'SemEval shared task training set' are clearly identified and used in the research context.",
      "processing_time": 74.72928738594055,
      "citing_paper_id": "207853145",
      "cited_paper_id": 2505531
    },
    {
      "context_text": "…a signiﬁcant number of event arguments are observed to be non-local given the analysis of zero anaphora and deﬁnite null complements by Fillmore (1986) and the distinction between “core” and “non-core” frame elements or roles in FrameNet (Baker et al., 1998) and Prop-Bank (Palmer et al., 2005).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FrameNet",
        "PropBank"
      ],
      "dataset_descriptions": {
        "FrameNet": "Used to analyze the distinction between 'core' and 'non-core' frame elements, contributing to the understanding of event arguments in semantic roles.",
        "PropBank": "Used to analyze the distinction between 'core' and 'non-core' frame elements, contributing to the understanding of event arguments in semantic roles."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions FrameNet and PropBank, which are well-known annotated corpora used in semantic role labeling and frame semantics. However, the context does not specify how these resources are used in the current research.",
      "processing_time": 75.46104454994202,
      "citing_paper_id": "207853145",
      "cited_paper_id": 2486369
    },
    {
      "context_text": "…a signiﬁcant number of event arguments are observed to be non-local given the analysis of zero anaphora and deﬁnite null complements by Fillmore (1986) and the distinction between “core” and “non-core” frame elements or roles in FrameNet (Baker et al., 1998) and Prop-Bank (Palmer et al., 2005).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FrameNet",
        "PropBank"
      ],
      "dataset_descriptions": {
        "FrameNet": "Used to analyze the distinction between 'core' and 'non-core' frame elements, contributing to the understanding of event arguments in semantic roles.",
        "PropBank": "Used to analyze the distinction between 'core' and 'non-core' frame elements, contributing to the understanding of event arguments in semantic roles."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions FrameNet and PropBank, which are well-known annotated corpora used in semantic role labeling and frame semantics. However, the context does not specify how these resources are used in the current research.",
      "processing_time": 75.46104454994202,
      "citing_paper_id": "207853145",
      "cited_paper_id": 2505531
    },
    {
      "context_text": "Because the roles in RAMS are semantically grounded and concrete (compared to abstracted roles such as ARG0 in PropBank (Palmer et al., 2005)), determining whether an argument is likely to ﬁll a given role (regardless of the particular event) may provide some signal of implicit entity typing.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison between RAMS and PropBank. PropBank is a method or resource, not a dataset.",
      "processing_time": 59.86066460609436,
      "citing_paper_id": "207853145",
      "cited_paper_id": 2486369
    },
    {
      "context_text": "5 To obtain more training data, Roth and Frank (2013) automatically induce implicit arguments from pairs of comparable texts, but recover only a small set of additional arguments.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for inducing implicit arguments. The context is about obtaining more training data, but no dataset names are provided.",
      "processing_time": 59.70268154144287,
      "citing_paper_id": "207853145",
      "cited_paper_id": 2505531
    },
    {
      "context_text": "We adapt recent span-based models (Lee et al., 2018; He et al., 2018; Ouchi et al., 2018) for the multi-sentence argument linking task for both our annotated dataset, RAMS, and for an existing slot ﬁlling dataset, GVDB (Pavlick et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "GVDB"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to adapt span-based models for multi-sentence argument linking, focusing on the structure and relationships within and across sentences.",
        "GVDB": "Used to adapt span-based models for multi-sentence argument linking, specifically for slot filling tasks, enhancing the model's ability to handle complex event structures."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, RAMS and GVDB, which are used for adapting span-based models for multi-sentence argument linking tasks.",
      "processing_time": 71.84582424163818,
      "citing_paper_id": "207853145",
      "cited_paper_id": 4891749
    },
    {
      "context_text": "Lee et al. (2018) addresses this issue in coreference resolution, a different document-level task, by implementing a coarse pruner to limit the number of candidate spans that are subsequently scored.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for coreference resolution.",
      "processing_time": 56.5793399810791,
      "citing_paper_id": "207853145",
      "cited_paper_id": 4891749
    },
    {
      "context_text": "Our model is inspired by several recent span selection models (He et al., 2018; Lee et al., 2018; Ouchi et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is about model inspiration, not dataset usage.",
      "processing_time": 58.64801740646362,
      "citing_paper_id": "207853145",
      "cited_paper_id": 4891749
    },
    {
      "context_text": "Although non-local arguments are a common phenomenon (Gerber and Chai (2012) found that their annotation of non-local arguments added 71% (relative) role coverage to NomBank annotations), these datasets are signiﬁcantly smaller than RAMS: the SemEval shared task training set contains 1,370 frame…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used as a larger dataset for training or evaluation, providing a significant amount of data for semantic role labeling tasks, particularly for non-local arguments."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'NomBank' and 'RAMS' as datasets, but does not provide specific usage details for 'NomBank'. 'RAMS' is mentioned as a larger dataset compared to others, which suggests it is used for training or evaluation.",
      "processing_time": 70.45607447624207,
      "citing_paper_id": "207853145",
      "cited_paper_id": 5806560
    },
    {
      "context_text": "Much of the effort on non-local arguments, sometimes called implicit SRL, has focused on two datasets, one based on stories that were produced for SemEval-2010 Task 10 (Ruppenhofer et al., 2010) and the other an expansion of Nom-Bank (Meyers et al., 2004) compiled by Gerber and Chai (2010, 2012).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SemEval-2010 Task 10",
        "Nom-Bank"
      ],
      "dataset_descriptions": {
        "SemEval-2010 Task 10": "Used to study non-local arguments in semantic role labeling, focusing on implicit arguments in stories. The dataset supports the investigation of how context influences argument identification.",
        "Nom-Bank": "Expanded and used to explore implicit arguments for nominal predicates, enhancing the original Nom-Bank with additional annotations for non-local arguments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets used for non-local arguments or implicit SRL: one from SemEval-2010 Task 10 and an expansion of Nom-Bank. These are clearly identified and used in the research.",
      "processing_time": 79.09927654266357,
      "citing_paper_id": "207853145",
      "cited_paper_id": 5806560
    },
    {
      "context_text": "Much of the effort on non-local arguments, sometimes called implicit SRL, has focused on two datasets, one based on stories that were produced for SemEval-2010 Task 10 (Ruppenhofer et al., 2010) and the other an expansion of Nom-Bank (Meyers et al., 2004) compiled by Gerber and Chai (2010, 2012).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SemEval-2010 Task 10",
        "Nom-Bank"
      ],
      "dataset_descriptions": {
        "SemEval-2010 Task 10": "Used to study non-local arguments in semantic role labeling, focusing on implicit arguments in stories. The dataset supports the investigation of how context influences argument identification.",
        "Nom-Bank": "Expanded and used to explore implicit arguments for nominal predicates, enhancing the original Nom-Bank with additional annotations for non-local arguments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets used for non-local arguments or implicit SRL: one from SemEval-2010 Task 10 and an expansion of Nom-Bank. These are clearly identified and used in the research.",
      "processing_time": 79.09927654266357,
      "citing_paper_id": "207853145",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "Much of the effort on non-local arguments, sometimes called implicit SRL, has focused on two datasets, one based on stories that were produced for SemEval-2010 Task 10 (Ruppenhofer et al., 2010) and the other an expansion of Nom-Bank (Meyers et al., 2004) compiled by Gerber and Chai (2010, 2012).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SemEval-2010 Task 10",
        "Nom-Bank"
      ],
      "dataset_descriptions": {
        "SemEval-2010 Task 10": "Used to study non-local arguments in semantic role labeling, focusing on implicit arguments in stories. The dataset supports the investigation of how context influences argument identification.",
        "Nom-Bank": "Expanded and used to explore implicit arguments for nominal predicates, enhancing the original Nom-Bank with additional annotations for non-local arguments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets used for non-local arguments or implicit SRL: one from SemEval-2010 Task 10 and an expansion of Nom-Bank. These are clearly identified and used in the research.",
      "processing_time": 79.09927654266357,
      "citing_paper_id": "207853145",
      "cited_paper_id": 16273722
    },
    {
      "context_text": "The Beyond NomBank dataset (“BNB”) collected by Gerber and Chai (2010) and reﬁned by Ger-ber and Chai (2012) contains nominal predicates (event triggers), and multi-sentence arguments, both of which are properties shared with RAMS.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Beyond NomBank"
      ],
      "dataset_descriptions": {
        "Beyond NomBank": "Used to study nominal predicates and multi-sentence arguments, focusing on event triggers and their properties, similar to those in the RAMS dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Beyond NomBank dataset' (BNB) as a specific dataset used for studying nominal predicates and multi-sentence arguments, which aligns with the research topic of document-level event extraction.",
      "processing_time": 68.77251601219177,
      "citing_paper_id": "207853145",
      "cited_paper_id": 5806560
    },
    {
      "context_text": "The Beyond NomBank dataset (“BNB”) collected by Gerber and Chai (2010) and reﬁned by Ger-ber and Chai (2012) contains nominal predicates (event triggers), and multi-sentence arguments, both of which are properties shared with RAMS.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Beyond NomBank"
      ],
      "dataset_descriptions": {
        "Beyond NomBank": "Used to study nominal predicates and multi-sentence arguments, focusing on event triggers and their properties, similar to those in the RAMS dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Beyond NomBank dataset' (BNB) as a specific dataset used for studying nominal predicates and multi-sentence arguments, which aligns with the research topic of document-level event extraction.",
      "processing_time": 68.77251601219177,
      "citing_paper_id": "207853145",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "Existing datasets either focus on a small number of predicate types (Gerber and Chai, 2010, 2012; Feizabadi and Pad´o, 2014) or on a small number of documents (Ruppenhofer et al., 2010).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions existing datasets but does not provide specific names. It only describes their limitations, which are too generic to identify specific datasets.",
      "processing_time": 59.600685834884644,
      "citing_paper_id": "207853145",
      "cited_paper_id": 5806560
    },
    {
      "context_text": "Existing datasets either focus on a small number of predicate types (Gerber and Chai, 2010, 2012; Feizabadi and Pad´o, 2014) or on a small number of documents (Ruppenhofer et al., 2010).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions existing datasets but does not provide specific names. It only describes their limitations, which are too generic to identify specific datasets.",
      "processing_time": 59.600685834884644,
      "citing_paper_id": "207853145",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "By design, Beyond NomBank focuses on only a few predicate types, but we include its statistics for reference.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a reference to statistics from Beyond NomBank, which is not a dataset but a project or method.",
      "processing_time": 59.872511863708496,
      "citing_paper_id": "207853145",
      "cited_paper_id": 5806560
    },
    {
      "context_text": "…are signiﬁcantly smaller than RAMS: the SemEval shared task training set contains 1,370 frame instantiations over 438 sentences, and the data from Gerber and Chai (2012) It is not surprising that across multiple datasets, a signiﬁcant number of event arguments are observed to be non-local given…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "SemEval shared task training set"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to compare the size of event argument datasets, highlighting the smaller scale of other datasets in document-level event extraction.",
        "SemEval shared task training set": "Used to illustrate the limited scale of event argument datasets, containing 1,370 frame instantiations over 438 sentences for semantic role labeling."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'RAMS' and 'SemEval shared task training set', both of which are specific datasets. However, 'data from Gerber and Chai (2012)' is too generic and lacks a specific identifier.",
      "processing_time": 78.00528407096863,
      "citing_paper_id": "207853145",
      "cited_paper_id": 5806560
    },
    {
      "context_text": "For both event and role annotations, RAMS provides larger and broader coverage than the AIDA Phase 1 data and Beyond NomBank.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "AIDA Phase 1 data"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for event and role annotations, providing larger and broader coverage compared to other datasets, enhancing the scope of semantic role labeling.",
        "AIDA Phase 1 data": "Used for event and role annotations, serving as a baseline for comparison with RAMS in terms of coverage and scope."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS' and 'AIDA Phase 1 data' as datasets used for event and role annotations. These are specific datasets with clear identifiers.",
      "processing_time": 73.42058682441711,
      "citing_paper_id": "207853145",
      "cited_paper_id": 5806560
    },
    {
      "context_text": "Datasets Comparisons between RAMS, the AIDA Phase 1 data, and Beyond NomBank (Gerber and Chai, 2010, 2012) are given in Figure 6 and Figure 7.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "AIDA Phase 1 data",
        "Beyond NomBank"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to compare event extraction performance, focusing on implicit arguments for nominal predicates.",
        "AIDA Phase 1 data": "Used to compare event extraction performance, focusing on implicit arguments for nominal predicates.",
        "Beyond NomBank": "Used to extend NomBank for implicit arguments, focusing on nominal predicates in event extraction."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific datasets used for comparisons in document-level event extraction research.",
      "processing_time": 72.98935198783875,
      "citing_paper_id": "207853145",
      "cited_paper_id": 5806560
    },
    {
      "context_text": "Datasets Comparisons between RAMS, the AIDA Phase 1 data, and Beyond NomBank (Gerber and Chai, 2010, 2012) are given in Figure 6 and Figure 7.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "AIDA Phase 1 data",
        "Beyond NomBank"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to compare event extraction performance, focusing on implicit arguments for nominal predicates.",
        "AIDA Phase 1 data": "Used to compare event extraction performance, focusing on implicit arguments for nominal predicates.",
        "Beyond NomBank": "Used to extend NomBank for implicit arguments, focusing on nominal predicates in event extraction."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific datasets used for comparisons in document-level event extraction research.",
      "processing_time": 72.98935198783875,
      "citing_paper_id": "207853145",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "Argument Linking also draws similarities to slot ﬁlling, exempliﬁed by the various MUC datasets (Sundheim, 1992) and the Gun Violence Database (GVDB) (Pavlick et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC datasets",
        "Gun Violence Database (GVDB)"
      ],
      "dataset_descriptions": {
        "MUC datasets": "Used to evaluate information extraction systems, focusing on slot filling tasks in various domains, providing structured data for argument linking research.",
        "Gun Violence Database (GVDB)": "Used to study gun violence incidents, focusing on event extraction and argument linking, providing detailed records of events and participants."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'MUC datasets' and 'Gun Violence Database (GVDB)', both of which are specific datasets used in the research. MUC datasets are part of a series of evaluations for information extraction systems, and GVDB is a specific database focused on gun violence incidents.",
      "processing_time": 78.63293981552124,
      "citing_paper_id": "207853145",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "Similarly, Gerber and Chai (2010) found that, in their data, almost 90% of implicit arguments could be resolved in the two sentences preceding the trigger.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not mention a specific dataset by name, only referring to 'their data'. This is too generic and lacks a clear identifier.",
      "processing_time": 59.25763988494873,
      "citing_paper_id": "207853145",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "We experiment with both feature-based BERT-base 12 (Devlin et al., 2018) and ELMo (Peters et al., 2018).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions BERT and ELMo, which are models, not datasets. No datasets are explicitly mentioned or used in the context.",
      "processing_time": 59.535369873046875,
      "citing_paper_id": "207853145",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "…datasets, a signiﬁcant number of event arguments are observed to be non-local given the analysis of zero anaphora and deﬁnite null complements by Fillmore (1986) and the distinction between “core” and “non-core” frame elements or roles in FrameNet (Baker et al., 1998) and Prop-Bank (Palmer…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions FrameNet and PropBank, which are well-known linguistic resources. However, they are referenced in the context of explaining a concept rather than being directly used in the research.",
      "processing_time": 61.694417238235474,
      "citing_paper_id": "207853145",
      "cited_paper_id": 59759184
    },
    {
      "context_text": "…datasets, a signiﬁcant number of event arguments are observed to be non-local given the analysis of zero anaphora and deﬁnite null complements by Fillmore (1986) and the distinction between “core” and “non-core” frame elements or roles in FrameNet (Baker et al., 1998) and Prop-Bank (Palmer et…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions FrameNet and PropBank, which are well-known linguistic resources. However, they are referenced for their theoretical contributions rather than as datasets used in the current research.",
      "processing_time": 61.47725534439087,
      "citing_paper_id": "207853145",
      "cited_paper_id": 59759184
    },
    {
      "context_text": "In particular, O’Gorman (2019) speculates a joint coreference and SRL model in which implicit discourse referents are generated for each event predicate and subsequently clustered with the discovered referent spans using a model for coreference.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a speculative model for joint coreference and SRL.",
      "processing_time": 58.7407488822937,
      "citing_paper_id": "207853145",
      "cited_paper_id": null
    },
    {
      "context_text": "Here we review prior considerations of non-local arguments and refer to O’Gorman (2019) for further reading.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to further reading on non-local arguments.",
      "processing_time": 59.32797336578369,
      "citing_paper_id": "207853145",
      "cited_paper_id": null
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features [11, 12, 26] or neural-based contextual representation [4, 8, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 60.06627869606018,
      "citing_paper_id": "249579113",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features [11, 12, 26] or neural-based contextual representation [4, 8, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 60.06627869606018,
      "citing_paper_id": "249579113",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features [11, 12, 26] or neural-based contextual representation [4, 8, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 60.06627869606018,
      "citing_paper_id": "249579113",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features [11, 12, 26] or neural-based contextual representation [4, 8, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 60.06627869606018,
      "citing_paper_id": "249579113",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "TIER [11] extracted role fillers from the secondary context that processes the extraction into three stages: classifying narrative document, recognizing event sentence, and noun phrase analysis.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or process called TIER. No verifiable resources are identified.",
      "processing_time": 59.52406644821167,
      "citing_paper_id": "249579113",
      "cited_paper_id": 950755
    },
    {
      "context_text": "GLACIER [26] used a sentential event recognizer to select sentences and then applied a plausible role filler recognizer to extract role fillers as results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset names, only a method (GLACIER) and its components. The citation is about the method used for information extraction.",
      "processing_time": 61.01357054710388,
      "citing_paper_id": "249579113",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "The mainstream MRC models extract text spans from passages given the questions and have achieved good results [6, 29, 30, 32, 39].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general references to MRC models and their performance. No verifiable resources are identified.",
      "processing_time": 60.18334984779358,
      "citing_paper_id": "249579113",
      "cited_paper_id": 6300274
    },
    {
      "context_text": "The mainstream MRC models extract text spans from passages given the questions and have achieved good results [6, 29, 30, 32, 39].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general references to MRC models and their performance. No verifiable resources are identified.",
      "processing_time": 60.18334984779358,
      "citing_paper_id": "249579113",
      "cited_paper_id": 8535316
    },
    {
      "context_text": "Previous works [29, 30, 32, 39] have shown that the MRC framework can learn and infer in a document through the question-context pair.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MRC framework' but does not specify any datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 59.99658942222595,
      "citing_paper_id": "249579113",
      "cited_paper_id": 6300274
    },
    {
      "context_text": "Previous works [29, 30, 32, 39] have shown that the MRC framework can learn and infer in a document through the question-context pair.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MRC framework' but does not specify any datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 59.99658942222595,
      "citing_paper_id": "249579113",
      "cited_paper_id": 8535316
    },
    {
      "context_text": "In recent years, the MRC task has been widely investigated since the release of large-scale corpora [14, 16, 27, 38].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'large-scale corpora' but does not specify any dataset names. The cited paper title 'RACE: Large-scale ReAding Comprehension Dataset From Examinations' suggests a potential dataset, but it is not explicitly mentioned in the citation context.",
      "processing_time": 65.08047604560852,
      "citing_paper_id": "249579113",
      "cited_paper_id": 6826032
    },
    {
      "context_text": "As a fundamental and challenging task in natural language processing (NLP) , EE can produce valuable structured information to facilitate many NLP applications, such as knowledge base construction, question answering, and language understanding [1, 13].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of Event Extraction in NLP.",
      "processing_time": 58.523932695388794,
      "citing_paper_id": "249579113",
      "cited_paper_id": 8471750
    },
    {
      "context_text": "A great number of EE research focuses on SEE, and most are based on the expert-annotated benchmark ACE 2005 [7] dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used as a benchmark for sentence-level event extraction, providing expert-annotated data to train and evaluate models in the field of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE 2005 dataset, which is a well-known benchmark for event extraction. The dataset is explicitly used for SEE (Sentence-level Event Extraction) research.",
      "processing_time": 69.2869803905487,
      "citing_paper_id": "249579113",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "The second one is how to model long texts, as most MRC methods are based on the Transformer [31] architecture, which is limited to a fixed-length (e.g., 512) input.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a limitation of the Transformer architecture. No verifiable resources are identified.",
      "processing_time": 59.522666692733765,
      "citing_paper_id": "249579113",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "For the basic MRC-based method, we adopt Transformer-base [31], which has 12 layers, 768 hidden units, and 12 attention heads, as the local encoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (Transformer-base). The citation is about the model architecture, not a dataset.",
      "processing_time": 60.186920404434204,
      "citing_paper_id": "249579113",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Most of them are based on the Transformer architecture [31] with a multi-layer self-attention mechanism to model long dependencies between tokens with limited sequence length.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model architecture. No dataset names are present in the citation span.",
      "processing_time": 59.392693519592285,
      "citing_paper_id": "249579113",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "In this article, we adopt the Transformer [31], which contains multi-layer self-attention modules, as the local encoder: where h i , j ∈ R d h , d h denotes the hidden size.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Transformer) which is excluded according to the instructions.",
      "processing_time": 59.211610078811646,
      "citing_paper_id": "249579113",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "McCann et al. [23] cast 10 tasks (e.g., machine translation, summarization, relation extraction, etc.) as a question answering paradigm and propose a general model for them with jointly training.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tasks and a model. The context is about a methodological approach to multitask learning.",
      "processing_time": 59.66372895240784,
      "citing_paper_id": "249579113",
      "cited_paper_id": 49393754
    },
    {
      "context_text": "DCFEE [36] proposed a tagging-based model for SEE and a key-event detection model with an arguments-completion strategy for DEE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DCFEE but does not specify a dataset. The cited paper title indicates that DCFEE is a system, not a dataset.",
      "processing_time": 60.76032900810242,
      "citing_paper_id": "249579113",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "To solve the preceding challenges, previous works [36, 40] formulated DEE as a two-step paradigm: from sentence-level candidate argument extraction to document-level event fusion.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The cited paper title suggests a dataset might be involved, but it is not explicitly named in the citation context.",
      "processing_time": 61.259894609451294,
      "citing_paper_id": "249579113",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "For exploring the real challenges (i.e., multi-events and arguments scattering) for DEE, DCFEE [36] proposed a pipeline method that contains a neural-based sequence tagging model for SEE and a key-event detection model with an arguments-completion strategy for DEE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DCFEE) and its components. The context focuses on the methodology and system architecture rather than a particular dataset.",
      "processing_time": 61.62122583389282,
      "citing_paper_id": "249579113",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "In recent years, as neural networks proved the effectiveness for NLP, many approaches [2, 3, 5, 19, 25, 28, 37, 37] have been proposed to improve performance on this task by employing deep learning models, such as recurrent neural networks and convolutional neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches and models. There are no clear identifiers for datasets.",
      "processing_time": 59.68389344215393,
      "citing_paper_id": "249579113",
      "cited_paper_id": 52349712
    },
    {
      "context_text": "2 A straightforward solution for modeling long texts is the sliding window [34], but this method sacrifices the possibility that the distant tokens “pay attention” to each other.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for handling long texts.",
      "processing_time": 58.139241456985474,
      "citing_paper_id": "249579113",
      "cited_paper_id": 201307832
    },
    {
      "context_text": "To this end, a great number of previous works [9, 19, 25, 33, 37] focus on sentence-level event extraction (SEE) ,which aims to detect events and extract arguments from one sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to sentence-level event extraction. No verifiable resources are identified.",
      "processing_time": 60.108964920043945,
      "citing_paper_id": "249579113",
      "cited_paper_id": 202770954
    },
    {
      "context_text": "MGR [8] proposed a tagging-based model to dynamically incorporate paragraph-and sentence-level representations based on contextualized embeddings produced by the pre-trained language model BERT [6].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method and a pre-trained model (BERT).",
      "processing_time": 59.00637459754944,
      "citing_paper_id": "249579113",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Following prior work [8], we adopt head noun phrase match and exact match accuracy to compare the extractions against gold role fillers for evaluation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and methods.",
      "processing_time": 57.97463417053223,
      "citing_paper_id": "249579113",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Du and Cardie [9], Li et al. [18], and Liu et al. [22] introduce an MRC paradigm for EE in an end-to-end manner.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or paradigms for event extraction.",
      "processing_time": 58.287177085876465,
      "citing_paper_id": "249579113",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "In recent years, as neural networks proved the efectiveness for NLP, many approaches [2, 3, 5, 19, 25, 28, 37, 37] have been proposed to improve performance on this task by employing deep learning models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNN).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches and models. There are no clear identifiers for datasets.",
      "processing_time": 59.49700355529785,
      "citing_paper_id": "249579113",
      "cited_paper_id": 239085620
    },
    {
      "context_text": "The first one is the task of document-level event role filler extraction, which is based on the classic MUC-4 dataset [24].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used for document-level event role filler extraction, focusing on identifying and extracting roles within events across multiple sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known resource for event extraction tasks. The dataset is explicitly used for document-level event role filler extraction.",
      "processing_time": 66.79825806617737,
      "citing_paper_id": "249579113",
      "cited_paper_id": null
    },
    {
      "context_text": "Unsupervised event schema induction based approaches (Chambers and Jurafsky, 2011; Chambers, 2013; Cheung et al., 2013) are also able",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to unsupervised event schema induction approaches. No clear identifiers for datasets are present.",
      "processing_time": 60.065885066986084,
      "citing_paper_id": "231728756",
      "cited_paper_id": 278288
    },
    {
      "context_text": "Unsupervised event schema induction based approaches (Chambers and Jurafsky, 2011; Chambers, 2013; Cheung et al., 2013) are also able",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to unsupervised event schema induction approaches. No clear identifiers for datasets are present.",
      "processing_time": 60.065885066986084,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6341459
    },
    {
      "context_text": "Unsupervised event schema induction based approaches (Chambers and Jurafsky, 2011; Cham-bers, 2013; Cheung et al., 2013) to model the coreference relations and entities at document-level, but have been proved to perform substantially worse than supervised models (Pat-wardhan and Riloff, 2009; Huang…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 59.30394506454468,
      "citing_paper_id": "231728756",
      "cited_paper_id": 278288
    },
    {
      "context_text": "Document-level template filling (Sundheim, 1991, 1993; Grishman and Sundheim, 1996) is a classic problem in information extraction (IE) and NLP (Jurafsky and Martin, 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods in information extraction and NLP.",
      "processing_time": 58.60738754272461,
      "citing_paper_id": "231728756",
      "cited_paper_id": 5073927
    },
    {
      "context_text": "Document-level template filling (Sundheim, 1991, 1993; Grishman and Sundheim, 1996) is a classic problem in information extraction (IE) and NLP (Jurafsky and Martin, 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods in information extraction and NLP.",
      "processing_time": 58.60738754272461,
      "citing_paper_id": "231728756",
      "cited_paper_id": 5188467
    },
    {
      "context_text": "Document-level template ﬁlling (Sundheim, 1991, 1993; Grishman and Sundheim, 1996) is a classic problem in information extraction (IE) and NLP (Jurafsky and Martin, 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to document-level template filling as a classic problem in IE and NLP.",
      "processing_time": 59.422011375427246,
      "citing_paper_id": "231728756",
      "cited_paper_id": 5073927
    },
    {
      "context_text": "We base the REE task on the original MUC3 formulation (Sundheim, 1991), but simplify it as done in prior research (Huang and Riloff, 2012; Du and Cardie, 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC3"
      ],
      "dataset_descriptions": {
        "MUC3": "Used as a basis for the REE task, simplifying the original formulation for event extraction, but details on specific usage in this research are not provided."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC3' which is a specific dataset used for event extraction tasks. However, it does not provide details on how the dataset is used in the current research.",
      "processing_time": 68.90640187263489,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "We base the REE task on the original MUC3 formulation (Sundheim, 1991), but simplify it as done in prior research (Huang and Riloff, 2012; Du and Cardie, 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC3"
      ],
      "dataset_descriptions": {
        "MUC3": "Used as a basis for the REE task, simplifying the original formulation for event extraction, but details on specific usage in this research are not provided."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'MUC3' which is a specific dataset used for event extraction tasks. However, it does not provide details on how the dataset is used in the current research.",
      "processing_time": 68.90640187263489,
      "citing_paper_id": "231728756",
      "cited_paper_id": 14365335
    },
    {
      "context_text": "Similar to (Huang and Riloff, 2012; Du and Cardie, 2020), we use the 1300 documents for training, 200 documents (TST1+TST2) as the development set and 200 documents (TST3+TST4) as the test set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions specific document sets used for training, development, and testing, but does not provide a specific name for the dataset. The numbers and splits are described generically.",
      "processing_time": 61.19032430648804,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "CohesionExtract (Huang and Riloff, 2012) is a bottom-up approach for event extraction that first aggressively identifies candidate role-fillers, and prune the candidates located in event-irrelevant sentences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'CohesionExtract' but does not refer to it as a dataset. It is described as a method or approach for event extraction.",
      "processing_time": 60.37181329727173,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "to model the coreference relations and entities at document-level, but have been proved to perform substantially worse than supervised models (Patwardhan and Riloff, 2009; Huang and Riloff, 2012).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses performance comparisons between unsupervised and supervised models.",
      "processing_time": 58.626774072647095,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "These event roles represent the agents, patients, and instruments associated with terrorism events (Huang and Riloff, 2012).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only event roles in the context of terrorism events. No clear, verifiable dataset names are present.",
      "processing_time": 60.02393984794617,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "We treat document-level REE as a sequence-tosequence task (Sutskever et al., 2014) in order to better model the cross-role dependencies and crosssentence noun phrase coreference structure.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for treating document-level REE as a sequence-to-sequence task.",
      "processing_time": 59.15712833404541,
      "citing_paper_id": "231728756",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "We treat document-level REE as a sequence-to-sequence task (Sutskever et al., 2014) in order to better model the cross-role dependencies and cross-sentence noun phrase coreference structure.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for treating document-level REE as a sequence-to-sequence task.",
      "processing_time": 59.36781311035156,
      "citing_paper_id": "231728756",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Instead of using a sequence-to-sequence learning architecture with separate modules (Sutskever et al., 2014; Bahdanau et al., 2015), we use a single pretrained transformer model (Devlin et al., 2019) for both parts, and introduce no additional ﬁne-tuned parameters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the architecture and model usage.",
      "processing_time": 59.152428150177,
      "citing_paper_id": "231728756",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "We use CEAF-REE which is covered in Section 3 as the evaluation metric.",
      "catation_intent": "none",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an evaluation metric (CEAF-REE).",
      "processing_time": 57.85384488105774,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "Finally, we calculate the precision, recall and F-measure for CEAF-REE as follows: We list several cases (Figure 6) and their CEAF-REE scores (Table 8) to facilitate understanding.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics and scores.",
      "processing_time": 57.39547896385193,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "Drawing insights from the entity-based CEAF metric (Luo, 2005) from the coreference resolution literature, we design a metric (CEAF-REE) for measuring models’ performance on this documentlevel role-filler entity extraction task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a metric derived from coreference resolution literature.",
      "processing_time": 58.09081435203552,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "Drawing insights from the entity-based CEAF metric (Luo, 2005) from the coreference resolution literature, we design a metric ( CEAF-REE ) for measuring models’ performance on this document-level role-ﬁller entity extraction task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric from the coreference resolution literature. No datasets are referenced for use in the research.",
      "processing_time": 59.81840443611145,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "We include more details for our CEAF-TF metric in the appendix.",
      "catation_intent": "research work",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric called CEAF-TF. No datasets are referenced for use in the research.",
      "processing_time": 59.674736976623535,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "• To measure the model’s ability to both extract entities for each role, and implicitly recognize coreferent relations between entity mentions, we design a metric (CEAF-REE) based on a maximum bipartite matching algorithm, drawing insights from the CEAF (Luo, 2005) coreference resolution measure.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating coreference resolution.",
      "processing_time": 57.4026563167572,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "More recently, neural network based models such as recurrent neural networks (Nguyen et al., 2016; Feng et al., 2018), convolutional neural networks (Nguyen and Grish-man, 2015; Chen et al., 2015) and attention mechanisms (Liu et al., 2017, 2018) have also been shown to help improve performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 58.69050216674805,
      "citing_paper_id": "231728756",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "More recently, neural network based models such as recurrent neural networks (Nguyen et al., 2016; Feng et al., 2018), convolutional neural networks (Nguyen and Grish-man, 2015; Chen et al., 2015) and attention mechanisms (Liu et al., 2017, 2018) have also been shown to help improve performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 58.69050216674805,
      "citing_paper_id": "231728756",
      "cited_paper_id": 52816033
    },
    {
      "context_text": ", 2018), convolutional neural networks (Nguyen and Grishman, 2015; Chen et al., 2015) and attention mechanisms (Liu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 59.04426383972168,
      "citing_paper_id": "231728756",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "As a result of these complications, end-to-end sentence-level event extraction models (Chen et al., 2015; Lample et al., 2016), which dominate the literature, are ill-suited for the REE task, which calls for models that encode information and track entities across a longer context.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the limitations of sentence-level event extraction models for the REE task.",
      "processing_time": 60.55562400817871,
      "citing_paper_id": "231728756",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "For the machine translation task, He et al. (2018) propose a model which shares the parameters of each layer between the encoder and decoder to regularize and coordinate the learning.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for neural machine translation.",
      "processing_time": 57.63217830657959,
      "citing_paper_id": "231728756",
      "cited_paper_id": 54088698
    },
    {
      "context_text": "Yao et al. (2019) construct an RE dataset of cross-sentence relations on Wikipedia paragraphs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to construct a large-scale document-level relation extraction dataset from Wikipedia paragraphs, focusing on cross-sentence relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the construction of an RE dataset from Wikipedia paragraphs, which is relevant to document-level event extraction.",
      "processing_time": 63.813371658325195,
      "citing_paper_id": "231728756",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Dataset Following previous work (Cybulska and Vossen, 2014 3, 4, 6-11, 13-17,19-20, 22, 24-33; dev: 2, 5, 12, 18, 21, 23, 34, 35; test:36-45.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions a dataset split into training, development, and test sets, but does not provide a specific name for the dataset. The numbers likely refer to document IDs or sections, which are not considered specific, verifiable datasets.",
      "processing_time": 62.834760665893555,
      "citing_paper_id": "266163830",
      "cited_paper_id": 1801348
    },
    {
      "context_text": "Event coreference resolution is useful for many natural language processing (NLP) applications, such as information extraction (Liu et al., 2017), topic detection (Wayne, 1998), and question answering (Weissenborn et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event coreference resolution. No dataset names are present in the text.",
      "processing_time": 59.71442747116089,
      "citing_paper_id": "266163830",
      "cited_paper_id": 2592133
    },
    {
      "context_text": "Event coreference resolution is useful for many natural language processing (NLP) applications, such as information extraction (Liu et al., 2017), topic detection (Wayne, 1998), and question answering (Weissenborn et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event coreference resolution. No dataset names are present in the text.",
      "processing_time": 59.71442747116089,
      "citing_paper_id": "266163830",
      "cited_paper_id": 59830022
    },
    {
      "context_text": "Shortest Dependency Path (SDP) is widely used in various NLP tasks (Xu et al., 2015; Cheng and Miyao, 2017) to capture crucial interaction information between sentences, we combine it with discourse tree for our CD-ECR task, called DT-SDP.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers also do not provide additional context about datasets.",
      "processing_time": 59.11296057701111,
      "citing_paper_id": "266163830",
      "cited_paper_id": 5403702
    },
    {
      "context_text": "Shortest Dependency Path (SDP) is widely used in various NLP tasks (Xu et al., 2015; Cheng and Miyao, 2017) to capture crucial interaction information between sentences, we combine it with discourse tree for our CD-ECR task, called DT-SDP.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers also do not provide additional context about datasets.",
      "processing_time": 59.11296057701111,
      "citing_paper_id": "266163830",
      "cited_paper_id": 32821791
    },
    {
      "context_text": "Research on event coreference resolution mainly draws on the method of entity coreference resolution, which aims to resolve noun phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017; Joshi et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and research works. The focus is on the methodologies used for entity coreference resolution.",
      "processing_time": 59.65591311454773,
      "citing_paper_id": "266163830",
      "cited_paper_id": 7691746
    },
    {
      "context_text": "Research on event coreference resolution mainly draws on the method of entity coreference resolution, which aims to resolve noun phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017; Joshi et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and research works. The focus is on the methodologies used for entity coreference resolution.",
      "processing_time": 59.65591311454773,
      "citing_paper_id": "266163830",
      "cited_paper_id": 16039645
    },
    {
      "context_text": "Barhom et al. (2019) trains entity and event coreference together and takes argument features as f ( m i , m j ) , which outperforms several early CD-ECR models (Cybulska and Vossen, 2015; Kenyon-Dean et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the performance of a model compared to others.",
      "processing_time": 59.650182008743286,
      "citing_paper_id": "266163830",
      "cited_paper_id": 10432942
    },
    {
      "context_text": "Metrics Following the previous work (Barhom et al., 2019; Cattan et al., 2021; Yu et al., 2022), we use MUC (Vilain et al., 1995), B 3 (Bagga, 1998), and CEAF e (Luo, 2005) to evaluate the performance of our model and also report the CoNLL scores, which is the average of the above three metrics.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions evaluation metrics but does not refer to any specific datasets. The focus is on the metrics used to evaluate model performance.",
      "processing_time": 59.151050090789795,
      "citing_paper_id": "266163830",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "Generally, discourse tree is constructed by discourse rhetorical structure (Mann and Thompson, 1998) (DRS) constructor, which aims to represent input text as a tree structure like the example in Figure 1, where the leaf nodes are elementary discourse units (EDU) and it has smaller fine-grained…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for constructing discourse trees using Discourse Rhetorical Structure (DRS).",
      "processing_time": 59.485676765441895,
      "citing_paper_id": "266163830",
      "cited_paper_id": 60514661
    },
    {
      "context_text": "Specifically, we first encode each document using RoBERTa LARGE inspired by Cat-tan et al. (2021), which splits long documents into non-overlapping segments of up to 512 word-piece tokens and encodes them independently.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of RoBERTa LARGE for encoding documents. RoBERTa is a model, not a dataset.",
      "processing_time": 60.244464635849,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "Specifically, we first encode each document using RoBERTa LARGE inspired by Cat-tan et al. (2021), which splits long documents into non-overlapping segments of up to 512 word-piece tokens and encodes them independently.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of RoBERTa LARGE for encoding documents. RoBERTa is a model, not a dataset.",
      "processing_time": 60.244464635849,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "This indo-cates that LongFomer is a stronger encoder than RoBERTa in the CD-ECR task.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (LongFormer and RoBERTa). The citation is comparing the performance of these models in a specific task (CD-ECR).",
      "processing_time": 61.5143358707428,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "This indo-cates that LongFomer is a stronger encoder than RoBERTa in the CD-ECR task.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (LongFormer and RoBERTa). The citation is comparing the performance of these models in a specific task (CD-ECR).",
      "processing_time": 61.5143358707428,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "1) Baseline(RoBERTa), which resolves corefer-ent events using local feature R local ( m i , m j ) only; 2) +WD-LCP, which adds the global feature R global ( m i , m j ) of within-document event mention pairs to baseline 1).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 59.23813438415527,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "1) Baseline(RoBERTa), which resolves corefer-ent events using local feature R local ( m i , m j ) only; 2) +WD-LCP, which adds the global feature R global ( m i , m j ) of within-document event mention pairs to baseline 1).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 59.23813438415527,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "Compared with Cattan et al. (2021), who develop an end-to-end baseline for CD-ECR and only use RoBERTa to encode event mentions without using other features, our model improves the CoNLL score by 4.7.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison with a method described in another paper. The cited papers do not introduce datasets either.",
      "processing_time": 59.526164054870605,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "Compared with Cattan et al. (2021), who develop an end-to-end baseline for CD-ECR and only use RoBERTa to encode event mentions without using other features, our model improves the CoNLL score by 4.7.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison with a method described in another paper. The cited papers do not introduce datasets either.",
      "processing_time": 59.526164054870605,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "1) Barhom et al. (2019 Table 2: Performance comparision of different models on the ECB+ dataset, where “*” indicates that the models use LongFormer as their encoders and the other models use BERT/RoBERTa as their encoders.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+"
      ],
      "dataset_descriptions": {
        "ECB+": "Used to compare the performance of different models, including those using LongFormer and BERT/RoBERTa encoders, focusing on document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ECB+ dataset, which is a specific dataset used for performance comparison of different models. The dataset is clearly identified and used in the research context.",
      "processing_time": 67.89076137542725,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "1) Barhom et al. (2019 Table 2: Performance comparision of different models on the ECB+ dataset, where “*” indicates that the models use LongFormer as their encoders and the other models use BERT/RoBERTa as their encoders.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+"
      ],
      "dataset_descriptions": {
        "ECB+": "Used to compare the performance of different models, including those using LongFormer and BERT/RoBERTa encoders, focusing on document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ECB+ dataset, which is a specific dataset used for performance comparison of different models. The dataset is clearly identified and used in the research context.",
      "processing_time": 67.89076137542725,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "It also shows the effectiveness of global information in the discourse tree, since our baseline is also RoBERTa.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (RoBERTa) which is excluded. There is no clear indication of a reusable resource being used.",
      "processing_time": 60.11369872093201,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "It also shows the effectiveness of global information in the discourse tree, since our baseline is also RoBERTa.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (RoBERTa) which is excluded. There is no clear indication of a reusable resource being used.",
      "processing_time": 60.11369872093201,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "For fair comparison, we replace our text encoder RoBERTa with Longformer and the experimental results shows that our model outperforms Caciularu et al. (2021) attention to extracting event mention features from the global perspective, which uses discourse tree to capture the features of long-distance event mention pairs.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on comparing model performance rather than using a specific dataset.",
      "processing_time": 59.72726559638977,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "For fair comparison, we replace our text encoder RoBERTa with Longformer and the experimental results shows that our model outperforms Caciularu et al. (2021) attention to extracting event mention features from the global perspective, which uses discourse tree to capture the features of long-distance event mention pairs.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on comparing model performance rather than using a specific dataset.",
      "processing_time": 59.72726559638977,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "They obtained the feature vector v ( · ) through encoding the event sentence by a pre-trained language model (e.g., BERT (Xu et al., 2019), RoBERTa (Liu et al., 2019)) and then consider the word embedding of trigger or trigger context tokens as the feature vector v ( · ) .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and RoBERTa as pre-trained language models but does not refer to them as datasets. They are used for encoding event sentences to obtain feature vectors.",
      "processing_time": 60.46160006523132,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "They obtained the feature vector v ( · ) through encoding the event sentence by a pre-trained language model (e.g., BERT (Xu et al., 2019), RoBERTa (Liu et al., 2019)) and then consider the word embedding of trigger or trigger context tokens as the feature vector v ( · ) .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and RoBERTa as pre-trained language models but does not refer to them as datasets. They are used for encoding event sentences to obtain feature vectors.",
      "processing_time": 60.46160006523132,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "After encoded by RoBERTa, we extract the trigger pair feature t ( m i , m j ) and the EDU pair feature e ( m i , m j ) from word embeddings for the event mention pair ( m i , m j ) , the local information representation R local ( i, j ) is obtained as follows. where t i , t j denotes the trigger tokens embeddings of m i , m j , and e i , e j denotes the EDU tokens embeddings of m i , m j .",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of RoBERTa for extracting features from word embeddings. No verifiable datasets are referenced.",
      "processing_time": 59.55349636077881,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "After encoded by RoBERTa, we extract the trigger pair feature t ( m i , m j ) and the EDU pair feature e ( m i , m j ) from word embeddings for the event mention pair ( m i , m j ) , the local information representation R local ( i, j ) is obtained as follows. where t i , t j denotes the trigger tokens embeddings of m i , m j , and e i , e j denotes the EDU tokens embeddings of m i , m j .",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of RoBERTa for extracting features from word embeddings. No verifiable datasets are referenced.",
      "processing_time": 59.55349636077881,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "Comapred with our model Ours(RoBERTa) us-ing RoBERTa as encoder, Ours(Longformer) using Longformer improves CoNLL by 0.7.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (RoBERTa, Longformer) and a metric (CoNLL). No verifiable resources are identified.",
      "processing_time": 60.293662548065186,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "Comapred with our model Ours(RoBERTa) us-ing RoBERTa as encoder, Ours(Longformer) using Longformer improves CoNLL by 0.7.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (RoBERTa, Longformer) and a metric (CoNLL). No verifiable resources are identified.",
      "processing_time": 60.293662548065186,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "Table 2 reports the performance of the above six baselines and our model on ECB+ with encoder RoBERTa and Longformer, and the results show that our model (Longformer) significantly (P<0.01) outperforms the best Held et al. (2021), with the improvement of 0.7 in the average score CoNLL, and our model (RoBERTa) achieve the competitive result with them.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (RoBERTa and Longformer) and a performance metric (CoNLL). The citation is focused on comparing model performance rather than using a specific dataset.",
      "processing_time": 61.848982095718384,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "Table 2 reports the performance of the above six baselines and our model on ECB+ with encoder RoBERTa and Longformer, and the results show that our model (Longformer) significantly (P<0.01) outperforms the best Held et al. (2021), with the improvement of 0.7 in the average score CoNLL, and our model (RoBERTa) achieve the competitive result with them.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (RoBERTa and Longformer) and a performance metric (CoNLL). The citation is focused on comparing model performance rather than using a specific dataset.",
      "processing_time": 61.848982095718384,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "Compared with baseline(RoBERTa), +WD-LCP improves CoNLL by 1.2 on the ECB+ dataset us-ing the within-document LCP.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+"
      ],
      "dataset_descriptions": {
        "ECB+": "Used to evaluate the performance of the +WD-LCP model on document-level event extraction, specifically comparing it to the baseline (RoBERTa) using within-document LCP."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ECB+ dataset, which is a specific, verifiable dataset used for document-level event extraction.",
      "processing_time": 66.33223724365234,
      "citing_paper_id": "266163830",
      "cited_paper_id": 102353837
    },
    {
      "context_text": "Compared with baseline(RoBERTa), +WD-LCP improves CoNLL by 1.2 on the ECB+ dataset us-ing the within-document LCP.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ECB+"
      ],
      "dataset_descriptions": {
        "ECB+": "Used to evaluate the performance of the +WD-LCP model on document-level event extraction, specifically comparing it to the baseline (RoBERTa) using within-document LCP."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ECB+ dataset, which is a specific, verifiable dataset used for document-level event extraction.",
      "processing_time": 66.33223724365234,
      "citing_paper_id": "266163830",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "…applied to both WD-ECR (Nguyen et al., 2016; Choubey and Huang, 2018; Fang et al., 2018; Huang et al., 2019; Cheng et al., 2019; Lu et al., 2020; Choubey et al., 2020; Lu and Ng, 2021) and CD-ECR (Kenyon-Dean et al., 2018; Barhom et al., 2019; Zeng et al., 2020; Cattan et al., 2021; Yu et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.72018623352051,
      "citing_paper_id": "266163830",
      "cited_paper_id": 218515665
    },
    {
      "context_text": "Besides, some studies also focused on data augmentation (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Barhom et al., 2019; Fang and Li, 2020), which boost event coreference resolution on additional raw data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'additional raw data' but does not specify a named dataset. The context is about data augmentation techniques, not a specific dataset.",
      "processing_time": 59.33723473548889,
      "citing_paper_id": "266163830",
      "cited_paper_id": 222210854
    },
    {
      "context_text": "In our work, we utilize the state-of-the-art discourse rhetoric structure parser (DRS) (Zhang et al., 2021) to construct discourse trees for the CD-ECR task-specific corpus.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a 'task-specific corpus' but does not provide a specific name or identifier. The DRS parser is a method, not a dataset.",
      "processing_time": 60.080018043518066,
      "citing_paper_id": "266163830",
      "cited_paper_id": 236459897
    },
    {
      "context_text": "Since these methods relied heavily on manual annotation features, some studies paid more attention to raw text event coreference resolution (Araki and Mi-tamura, 2015; Peng et al., 2016; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and studies. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 59.733689308166504,
      "citing_paper_id": "266163830",
      "cited_paper_id": null
    },
    {
      "context_text": "We converted the optional templates to required templates and removed the subtypes of the incidents as done in previous work (Chambers, 2013; Du et al., 2021b) We use the tuning data as training data and reserve 10% of the test data, i.e. 12 examples, to create a development/validation set.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'tuning data' and 'test data', which are generic placeholders.",
      "processing_time": 60.158337354660034,
      "citing_paper_id": "248780414",
      "cited_paper_id": 6341459
    },
    {
      "context_text": "We converted the optional templates to required templates and removed the subtypes of the incidents as done in previous work (Chambers, 2013; Du et al., 2021b) so that the dataset is transformed into standardized templates.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions transforming a dataset into standardized templates, but does not specify the name of the dataset. The cited papers do not provide additional information to identify a specific dataset.",
      "processing_time": 60.70354509353638,
      "citing_paper_id": "248780414",
      "cited_paper_id": 6341459
    },
    {
      "context_text": "We converted the optional templates to required templates and removed the subtypes of the incidents as done in previous work (Chambers, 2013; Du et al., 2021b) so that the dataset is transformed into standardized templates.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions transforming a dataset into standardized templates, but does not specify the name of the dataset. The cited papers do not provide additional information to identify a specific dataset.",
      "processing_time": 60.70354509353638,
      "citing_paper_id": "248780414",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "…(Vilar et al., 2006; Zhou et al., 2008; Farrús et al., 2010; Kholy and Habash, 2011; Ze-man et al., 2011; Popovi´c and Ney, 2011), coreference resolution (Uryupina, 2008; Kummerfeld and Klein, 2013; Martschat and Strube, 2014; Martschat et al., 2015) and parsing (Kummerfeld et al., 2012).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various research works and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.68733477592468,
      "citing_paper_id": "248780414",
      "cited_paper_id": 14672517
    },
    {
      "context_text": "…(Vilar et al., 2006; Zhou et al., 2008; Farrús et al., 2010; Kholy and Habash, 2011; Zeman et al., 2011; Popović and Ney, 2011), coreference resolution (Uryupina, 2008; Kummerfeld and Klein, 2013; Martschat and Strube, 2014; Martschat et al., 2015) and parsing (Kummerfeld et al., 2012).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various research works and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 59.3679883480072,
      "citing_paper_id": "248780414",
      "cited_paper_id": 16925224
    },
    {
      "context_text": ", 2011; Popović and Ney, 2011), coreference resolution (Uryupina, 2008; Kummerfeld and Klein, 2013; Martschat and Strube, 2014; Martschat et al., 2015) and parsing (Kummerfeld et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 60.173322439193726,
      "citing_paper_id": "248780414",
      "cited_paper_id": 16925224
    },
    {
      "context_text": "Valls-Vargas et al. (2017) proposed a framework for studying how different errors propagate through an IE system; however, the framework can only be used for pipelined systems, not end-to-end ones.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation discusses a framework for error analysis in information extraction systems, but does not mention any specific datasets.",
      "processing_time": 57.52764368057251,
      "citing_paper_id": "248780414",
      "cited_paper_id": 35264612
    },
    {
      "context_text": "testing like Errudite (Wu et al., 2019), CHECKLIST (Ribeiro et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tools or methods. The context is too limited to infer the use of any datasets.",
      "processing_time": 59.0912811756134,
      "citing_paper_id": "248780414",
      "cited_paper_id": 196199409
    },
    {
      "context_text": "Recently, generalized automated error analysis frameworks involving human-in-the-loop testing like Errudite (Wu et al., 2019), CHECK-\nLIST (Ribeiro et al., 2020), CrossCheck (Arendt et al., 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several frameworks but does not refer to any specific datasets. The focus is on methods and tools for error analysis.",
      "processing_time": 58.12844634056091,
      "citing_paper_id": "248780414",
      "cited_paper_id": 196199409
    },
    {
      "context_text": "Recently, generalized automated error analysis frameworks involving human-in-the-loop testing like Errudite (Wu et al., 2019), CHECK-\nLIST (Ribeiro et al., 2020), CrossCheck (Arendt et al., 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several frameworks but does not specify any datasets. The frameworks are tools or methods, not datasets.",
      "processing_time": 58.39889216423035,
      "citing_paper_id": "248780414",
      "cited_paper_id": 196199409
    },
    {
      "context_text": "To date, for example, there has been no attempt to directly compare the error landscape and distribution of\n2See, for example, Zhang et al. (2019), Du and Cardie (2020) and Lin et al. (2020) for within-sentence event extraction; Akbik et al. (2018), and Akbik et al. (2019) for named entity…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.49466395378113,
      "citing_paper_id": "248780414",
      "cited_paper_id": 198118773
    },
    {
      "context_text": "To date, for example, there has been no attempt to directly compare the error landscape and distribution of\n2See, for example, Zhang et al. (2019), Du and Cardie (2020) and Lin et al. (2020) for within-sentence event extraction; Akbik et al. (2018), and Akbik et al. (2019) for named entity…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.49466395378113,
      "citing_paper_id": "248780414",
      "cited_paper_id": 216562330
    },
    {
      "context_text": ", 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tools and frameworks. The context is about applying these tools to tasks like machine comprehension and relation extraction.",
      "processing_time": 59.72755575180054,
      "citing_paper_id": "248780414",
      "cited_paper_id": 202712654
    },
    {
      "context_text": "L IST (Ribeiro et al., 2020), CrossCheck (Arendt et al., 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions tools and frameworks but does not specify any datasets. The context focuses on the application of these tools to tasks like machine comprehension and relation extraction, but no specific datasets are named.",
      "processing_time": 61.21843218803406,
      "citing_paper_id": "248780414",
      "cited_paper_id": 202712654
    },
    {
      "context_text": "L IST (Ribeiro et al., 2020), CrossCheck (Arendt et al., 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions tools and frameworks but does not specify any datasets. The context focuses on the application of these tools to tasks like machine comprehension and relation extraction, but no specific datasets are named.",
      "processing_time": 61.21843218803406,
      "citing_paper_id": "248780414",
      "cited_paper_id": 216869183
    },
    {
      "context_text": "L IST (Ribeiro et al., 2020), CrossCheck (Arendt et al., 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions tools and frameworks but does not specify any datasets. The context focuses on the application of these tools to tasks like machine comprehension and relation extraction, but no specific datasets are named.",
      "processing_time": 61.21843218803406,
      "citing_paper_id": "248780414",
      "cited_paper_id": 218551201
    },
    {
      "context_text": "Although information extraction (IE) research has almost uniformly focused on sentence-level relation and event extraction (Grishman, 2019), the earliest research in the area formulated the task at the document level.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about the focus of IE research.",
      "processing_time": 57.7985577583313,
      "citing_paper_id": "248780414",
      "cited_paper_id": 203701085
    },
    {
      "context_text": ", 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tasks like machine comprehension and relation extraction. No clear, verifiable dataset names are present in the context.",
      "processing_time": 59.777934312820435,
      "citing_paper_id": "248780414",
      "cited_paper_id": 216869183
    },
    {
      "context_text": "…has been no attempt to directly compare the error landscape and distribution of\n2See, for example, Zhang et al. (2019), Du and Cardie (2020) and Lin et al. (2020) for within-sentence event extraction; Akbik et al. (2018), and Akbik et al. (2019) for named entity recognition (NER); and Zhang et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that discuss various NLP tasks. There are no clear identifiers for datasets.",
      "processing_time": 59.59315776824951,
      "citing_paper_id": "248780414",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "In fact, the problem of document-level information extraction has only recently begun to be revisited (Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of end-to-end neural network techniques that have…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only recent works that revisit document-level information extraction. No clear identifiers for datasets are present.",
      "processing_time": 59.23245882987976,
      "citing_paper_id": "248780414",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "All other hyperparameters are set as in Du et al. (2021b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to another paper for hyperparameters.",
      "processing_time": 57.62914156913757,
      "citing_paper_id": "248780414",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Next, we employ the error analysis framework in a comparison of two state-of-the-art documentlevel neural template-filling approaches, DyGIE++ (Wadden et al., 2019) and GTT (Du et al., 2021b), across three template-filling datasets (SciREX, ProMED (Patwardhan and Riloff, 2009)3, and MUC-4).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SciREX",
        "ProMED",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "SciREX": "Used to compare document-level neural template-filling approaches, focusing on scientific document extraction and summarization tasks.",
        "ProMED": "Used to compare document-level neural template-filling approaches, focusing on disease outbreak information extraction from news articles.",
        "MUC-4": "Used to compare document-level neural template-filling approaches, focusing on message understanding and event extraction tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets used for comparing document-level neural template-filling approaches. These datasets are SciREX, ProMED, and MUC-4.",
      "processing_time": 77.31263899803162,
      "citing_paper_id": "248780414",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Thus, we would also like to improve the time complexity of our template (and mention) matching algorithms using an approach like bipartite matching (Yang et al., 2021).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an algorithmic approach. No dataset names are present in the citation context.",
      "processing_time": 58.37789797782898,
      "citing_paper_id": "248780414",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "…extraction has only recently begun to be revisited (Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of end-to-end neural network techniques that have been so successful on their…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to recent research works. There are no clear identifiers for datasets, and the context is focused on the methodologies and approaches rather than specific data sources.",
      "processing_time": 61.27391457557678,
      "citing_paper_id": "248780414",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "(Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of endto-end neural network techniques that have been so successful on their sentence-level counterparts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to other works. The context is about testing end-to-end neural network techniques for document-level event extraction.",
      "processing_time": 59.97374653816223,
      "citing_paper_id": "248780414",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "(Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of endto-end neural network techniques that have been so successful on their sentence-level counterparts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to other works. The context is about testing end-to-end neural network techniques for document-level event extraction.",
      "processing_time": 59.97374653816223,
      "citing_paper_id": "248780414",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "(Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of endto-end neural network techniques that have been so successful on their sentence-level counterparts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to other works. The context is about testing end-to-end neural network techniques for document-level event extraction.",
      "processing_time": 59.97374653816223,
      "citing_paper_id": "248780414",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "…information extraction has only recently begun to be revis-ited (Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of end-to-end neural network techniques that have been so successful on their…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to recent research efforts in information extraction using neural networks.",
      "processing_time": 58.372124910354614,
      "citing_paper_id": "248780414",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "…information extraction has only recently begun to be revis-ited (Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of end-to-end neural network techniques that have been so successful on their…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to recent research efforts in information extraction using neural networks.",
      "processing_time": 58.372124910354614,
      "citing_paper_id": "248780414",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "As in Jurafsky and Martin (2021), we will refer to document-level information extraction tasks as template-ﬁlling tasks and use the term going forward to refer to both event extraction and document-level relation extraction tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to document-level information extraction tasks.",
      "processing_time": 57.05750107765198,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "As in Jurafsky and Martin (2021), we will refer to document-level information extraction tasks as template-ﬁlling tasks and use the term going forward to refer to both event extraction and document-level relation extraction tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to document-level information extraction tasks.",
      "processing_time": 57.05750107765198,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "In this work, we first introduce a framework for automating error analysis for document-level event and relation extraction, casting both as instances of a general role-filling, or template-filling task (Jurafsky and Martin, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a framework for error analysis in document-level event and relation extraction.",
      "processing_time": 58.16833996772766,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "We ﬁrst discuss the results of DyGIE++ and GTT on SciREX, ProMED, and MUC-4; and then examine the performance of these newer neural models on the 1992 MUC-4 dataset vs. a few of the best-performing IE systems at the time.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SciREX",
        "ProMED",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "SciREX": "Used to evaluate DyGIE++ and GTT models, focusing on scientific document information extraction, comparing performance against other systems.",
        "ProMED": "Used to assess the performance of DyGIE++ and GTT models in extracting information from disease outbreak reports, highlighting advancements in neural models.",
        "MUC-4": "Used to compare the performance of newer neural models (DyGIE++, GTT) with older IE systems, specifically focusing on event extraction tasks from 1992."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions specific datasets used for evaluating models, which are relevant to document-level event extraction.",
      "processing_time": 78.27217102050781,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "MUC-4 (MUC-4, 1992) consists of newswire describing terrorist incidents in Latin America provided by the FBIS (Federal Broadcast Information Services).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to extract events from newswire articles describing terrorist incidents in Latin America, focusing on the identification and classification of event types and participants."
      },
      "confidence_score": 1.0,
      "reasoning": "MUC-4 is a well-known dataset in the field of information extraction, specifically designed for event extraction tasks. The context clearly identifies it as a dataset of newswire articles about terrorist incidents.",
      "processing_time": 67.53092098236084,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Table 2 shows the results of evaluating DyGIE++ and GTT on the SciREX, ProMED, and MUC-4 datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SciREX",
        "ProMED",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "SciREX": "Used to evaluate DyGIE++ and GTT, focusing on scientific document event extraction and coreference resolution.",
        "ProMED": "Used to evaluate DyGIE++ and GTT, focusing on disease outbreak event extraction from health-related texts.",
        "MUC-4": "Used to evaluate DyGIE++ and GTT, focusing on message understanding and event extraction from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions specific datasets used for evaluation, which are relevant to document-level event extraction.",
      "processing_time": 75.3113796710968,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "In our experiments, we train and test two neural-based IE models, described brieﬂy below, on the MUC-4, ProMED, and SciREX datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "ProMED",
        "SciREX"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to train and test neural-based information extraction models, focusing on event extraction in news articles.",
        "ProMED": "Used to train and test neural-based information extraction models, focusing on disease outbreak reports.",
        "SciREX": "Used to train and test neural-based information extraction models, focusing on scientific document event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets used for training and testing neural-based information extraction models.",
      "processing_time": 72.37438035011292,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Consider, for example, the ﬁrst large-scale (for the time) evaluations of IE systems — e.g. MUC-3 (1991) and MUC-4 (1992).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-3",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-3": "Used to evaluate Information Extraction systems, focusing on the performance of entity and relation extraction in news articles.",
        "MUC-4": "Used to evaluate Information Extraction systems, focusing on the performance of entity and relation extraction in news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions MUC-3 and MUC-4, which are specific datasets used for evaluating Information Extraction systems. These are relevant to document-level event extraction.",
      "processing_time": 71.31451082229614,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "From the error count results in Figure 4, we see that GTT makes fewer Missing Template errors than DyGIE++ on the MUC-4 dataset (86 vs. 97).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of GTT and DyGIE++ on document-level event extraction, focusing on reducing Missing Template errors."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a specific, verifiable dataset used for evaluating performance on document-level event extraction.",
      "processing_time": 65.67865180969238,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Next, we employ the error analysis framework in a comparison of two state-of-the-art document-level neural template-ﬁlling approaches, DyGIE++ (Wadden et al., 2019) and GTT (Du et al., 2021b), across three template-ﬁlling datasets (SciREX, ProMED (Patwardhan and Riloff, 2009) 3 , and MUC-4).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SciREX",
        "ProMED",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "SciREX": "Used to compare document-level neural template-filling approaches, focusing on scientific document extraction tasks.",
        "ProMED": "Used to compare document-level neural template-filling approaches, focusing on disease outbreak reports.",
        "MUC-4": "Used to compare document-level neural template-filling approaches, focusing on news articles for event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets used for comparing document-level neural template-filling approaches. These datasets are clearly named and relevant to the research topic.",
      "processing_time": 74.50907349586487,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "We can see that all models perform substantially worse on sci-entiﬁc texts (ProMED, SciREX) as compared to news (MUC-4) , likely because the model base is pretrained for general-purpose NLP applications (BERT) or there are not enough examples of scientiﬁc-style text in the pretraining corpus (SciB-ERT).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ProMED",
        "SciREX",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "ProMED": "Used to evaluate model performance on scientific texts, highlighting challenges in handling specialized language.",
        "SciREX": "Used to assess model effectiveness on scientific documents, emphasizing difficulties with technical content.",
        "MUC-4": "Used as a benchmark for news text, demonstrating better model performance on general-purpose language."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions specific datasets used for evaluating model performance across different text types, including scientific and news texts.",
      "processing_time": 71.92616581916809,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "For the MUC-4 and SciREX datasets, GTT is run for 20 epochs, while for ProMED it is run for 36 epochs, to adjust for the smaller size of the dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "SciREX",
        "ProMED"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to train and evaluate the GTT model for 20 epochs, focusing on document-level event extraction.",
        "SciREX": "Used to train and evaluate the GTT model for 20 epochs, focusing on scientific document event extraction.",
        "ProMED": "Used to train and evaluate the GTT model for 36 epochs, adjusted for its smaller size, focusing on medical document event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets: MUC-4, SciREX, and ProMED. These are used to train and evaluate the GTT model, with different epoch settings based on dataset size.",
      "processing_time": 79.17529582977295,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Table 3 presents the precision, recall, and F1 performance on the MUC-4 dataset for early models from 1992 alongside those of the more recent DyGIE++ and GTT models.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of early and recent models, specifically comparing precision, recall, and F1 scores in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a specific, verifiable resource used for evaluating model performance.",
      "processing_time": 65.18623089790344,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Finally, in an attempt to gauge progress in the information extraction ﬁeld over the past 30 years, we employ the framework to compare the performance of four of the original MUC-4 systems with the two newer deep-learning approaches to document-level IE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to compare the performance of original MUC-4 systems with newer deep-learning approaches in document-level information extraction, focusing on progress over 30 years."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4' which is a known dataset in the information extraction field. It is used to compare the performance of older systems with newer deep-learning approaches.",
      "processing_time": 68.06241345405579,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Aside from the original MUC-4 evaluation scoring reports (Chinchor, 1991), which included counts of missing and spurious role ﬁller errors, there have been very few attempts at understanding the types of errors made by IE systems and grounding those errors linguistically.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate Information Extraction systems, focusing on error types such as missing and spurious role filler errors, providing linguistic grounding for performance analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions MUC-4 evaluation scoring reports, which is a specific dataset used for evaluating Information Extraction systems.",
      "processing_time": 65.26628589630127,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Next, we leverage a pointer network (Vinyals et al., 2015): where H r ∈ R N r d is event role representation from H t , W r , W a ∈ R d d , v ∈ R d are trainable parameters, + is the broadcasting plus of two matrices, P r ∈ R N r ( N a +1) is the score of arguments corresponding to roles in the…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (pointer network) and its parameters. There are no clear identifiers for datasets.",
      "processing_time": 58.972015142440796,
      "citing_paper_id": "266163877",
      "cited_paper_id": 5692837
    },
    {
      "context_text": "…(1) named entity : mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc (Nadeau and Sekine, 2007); (2) entity mention : a text span of entity in the document which refers to a named entity; (3) event argument : an entity…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general concepts related to named entity recognition and classification.",
      "processing_time": 57.84669375419617,
      "citing_paper_id": "266163877",
      "cited_paper_id": 8310135
    },
    {
      "context_text": "Then these tokens are encoded by a vanilla transformer encoder (Vaswani et al., 2017) to get the hidden representation: Where H w ∈ R N w d , d is the hidden dimension.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (transformer encoder). The cited paper 'Attention is All you Need' is a method paper, not a dataset.",
      "processing_time": 60.235589027404785,
      "citing_paper_id": "266163877",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "For extracting multiple events without triggers, a trigger-free method is first designed to detect an event in a center sentence and extract the rest of event arguments from surrounding sentences (Yang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction. The context focuses on the methodology rather than a particular dataset.",
      "processing_time": 58.29045653343201,
      "citing_paper_id": "266163877",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "The ChFinAnn dataset (Zheng et al., 2019) is a large dataset focuses on five event types from the financial text, which has 25 , 632 / 3 , 204 / 3 , 204 for the train/dev/test set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used to train and evaluate models on document-level financial event extraction, focusing on five specific event types with a large annotated corpus."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions 'ChFinAnn dataset' with specific details about its content and split, indicating it is a reusable resource.",
      "processing_time": 64.59370923042297,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Following (Zheng et al., 2019), IPGPF finishes the event extraction by handling three sub-tasks: (1) Named Entity Recognition (NER) : extracting entity mentions as argument candidates from the document; (2) Event Detection (ED) : judging whether there exist predefined event types in the document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only sub-tasks in a process. The context is about methodological steps in event extraction.",
      "processing_time": 58.86528301239014,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "…between sentence representation and argument representation by employing a vanilla transformer encoder: For focusing on the comparison of event record generation module, we keep the same feature H a ∈ R ( N a +1) d and H s ∈ R N s d with (Zheng et al., 2019; Yang et al., 2021) in Equation (17).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to feature representations and equations from other works.",
      "processing_time": 57.62617802619934,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "…between sentence representation and argument representation by employing a vanilla transformer encoder: For focusing on the comparison of event record generation module, we keep the same feature H a ∈ R ( N a +1) d and H s ∈ R N s d with (Zheng et al., 2019; Yang et al., 2021) in Equation (17).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to feature representations and equations from other works.",
      "processing_time": 57.62617802619934,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "We implement IPGPF under Pytorch (Paszke et al., 2017) based on codes released by (Zheng et al., 2019) and (Yang et al., 2021).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only software frameworks and code releases. The cited papers' titles suggest document-level event extraction, but no specific datasets are named in the context.",
      "processing_time": 60.36790895462036,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "We implement IPGPF under Pytorch (Paszke et al., 2017) based on codes released by (Zheng et al., 2019) and (Yang et al., 2021).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only software frameworks and code releases. The cited papers' titles suggest document-level event extraction, but no specific datasets are named in the context.",
      "processing_time": 60.36790895462036,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "Doc2EDAG (Zheng et al., 2019) designs an auto-regressive entity-based directed acyclic graph (EDAG) to generate event records.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Doc2EDAG' but does not refer to it as a dataset. It is described as a method or framework for generating event records.",
      "processing_time": 59.578835010528564,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Most trigger-free DEE methods (Zheng et al., 2019; Xu et al., 2021a; Liang et al., 2022) build entity-based directed acyclic graph (EDAG) to auto-regressively generate event arguments with their roles under a predefined order.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is focused on describing the methodology used in document-level event extraction.",
      "processing_time": 58.943952322006226,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Then a widely used entity-based directed acyclic graph (EDAG) generation method is proposed to better deal with multiple events extraction (Zheng et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions an EDAG generation method but does not refer to any specific dataset. The focus is on the method itself rather than a dataset.",
      "processing_time": 58.670329570770264,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Following (Zheng et al., 2019), we use the micro precision, recall, and F1-score over all arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. The context is focused on the methodology and performance metrics rather than data sources.",
      "processing_time": 58.69351649284363,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Due to the space limit, we put the details of NER and ED sub-tasks that are the same with (Zheng et al., 2019) to Appendix A.3 and A.4.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to sub-tasks in another paper. No clear identifiers for datasets are present.",
      "processing_time": 57.86034655570984,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "In the model training, following (Zheng et al., 2019), we generate event records for each event type independently and finally sum the loss of all event types.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating event records and summing losses.",
      "processing_time": 56.734758377075195,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Regarding the pre-trained encoder, we utilize LERT (Cui et al., 2022) for ChFinAnn and ERNIE (Sun et al., 2019) for DuEE-fin.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions pre-trained encoders LERT and ERNIE but does not refer to any specific datasets. The names are models, not datasets.",
      "processing_time": 58.89359664916992,
      "citing_paper_id": "266163877",
      "cited_paper_id": 125977708
    },
    {
      "context_text": "Recently, some works also tried to cast the event extraction task as question answering task (Du and Cardie, 2020b; Zhou et al., 2021), or sequence-to-sequence task (Xi-angyu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches to event extraction.",
      "processing_time": 56.672398805618286,
      "citing_paper_id": "266163877",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Different from sentence-level event extraction (SEE) (Chen et al., 2015; Nguyen et al., 2016; Du and Cardie, 2020b), event arguments of an event record are usually scattered across multiple sentences, while overlapping arguments contained in several event records appear more often.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methodological differences between sentence-level and document-level event extraction.",
      "processing_time": 57.88822674751282,
      "citing_paper_id": "266163877",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Most document-level EE meth-ods are built upon the event triggers, with which they conduct sequence labelling (Du and Cardie, 2020a; Veyseh et al., 2021) or span-based prediction (Ebner et al., 2020; Zhang et al., 2020; Xu et al., 2022) to identify event arguments in the document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 56.99701285362244,
      "citing_paper_id": "266163877",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Sequence-to-sequence (Du et al., 2021a,b; Li et al., 2021; Huang et al., 2021; Huang and Peng, 2021; Hsu et al., 2022), and question answering (Wei et al., 2021; Ma et al., 2022) paradigms are also applied.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only paradigms and approaches. No dataset names are present in the context.",
      "processing_time": 58.29813241958618,
      "citing_paper_id": "266163877",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "Sequence-to-sequence (Du et al., 2021a,b; Li et al., 2021; Huang et al., 2021; Huang and Peng, 2021; Hsu et al., 2022), and question answering (Wei et al., 2021; Ma et al., 2022) paradigms are also applied.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only paradigms and approaches. No dataset names are present in the context.",
      "processing_time": 58.29813241958618,
      "citing_paper_id": "266163877",
      "cited_paper_id": 234358675
    },
    {
      "context_text": "Several variant methods based on EDAG generation are presented by utilizing more meticulous feature engineering, such as heterogeneous graph feature (Xu et al., 2021a; Huang et al., 2021) and entity relation feature (Liang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and features. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.80529856681824,
      "citing_paper_id": "266163877",
      "cited_paper_id": 234358675
    },
    {
      "context_text": "1 Introduction Document-level event extraction (DEE) aims to extract multiple event records from the entire document (Ebner et al., 2020; Du et al., 2021b; Li et al., 2021; Xu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other research works. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 59.22189235687256,
      "citing_paper_id": "266163877",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Different from (Yang et al., 2021) which use a one-stage one-to-one matching to train their parallel model, we design a two-stage many-to-one matching algorithm to first performs multiple iterative refinements on the generated event records, and subsequently filters the best results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological difference in the approach to event extraction.",
      "processing_time": 57.45481252670288,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "Parallel models (Yang et al., 2021) are presented to generate all event records and roles simultaneously to avoid the error broadcasts in a given event role order.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction.",
      "processing_time": 56.987236738204956,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "DE-PPN (Yang et al., 2021) uses the same encoders with Doc2EDAG to obtain the features of arguments and sentences, but generates all event roles in parallel.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on comparing methodologies.",
      "processing_time": 57.6829731464386,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "Additionally, a parallel method is proposed to avoid the error broadcast in EDAG generation (Yang et al., 2021), and an efficient model is designed to lighten the model and accelerates the decoding speed (Zhu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on methodological improvements and does not reference any data sources.",
      "processing_time": 59.01374363899231,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "For the training epochs, we follow (Zheng et al., 2019; Yang et al., 2021; Xu et al., 2021a) to train 100 epochs for all compared models on the ChFi-nAnn dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFi-nAnn"
      ],
      "dataset_descriptions": {
        "ChFi-nAnn": "Used to train models for document-level event extraction, focusing on parallel prediction networks over 100 epochs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'ChFi-nAnn dataset' which is a specific dataset used for training models in document-level event extraction.",
      "processing_time": 65.22343826293945,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "SCDEE (Huang and Jia, 2021) builds an enhanced entity-sentence community graph, then detect event records from the graph and extract entities as arguments corresponding to the event roles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction.",
      "processing_time": 57.079097032547,
      "citing_paper_id": "266163877",
      "cited_paper_id": 244119148
    },
    {
      "context_text": ") [40], which modifies the term logP (â|D̂, q̂) to −(1− P (â|D̂, q̂)) in (3) for model training, and the method based on example re-weighting (Re-Weighting) [41], which uses a model trained with in-domain data to give out-of-domain and",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited paper title confirms that the focus is on a method (example re-weighting) rather than a dataset.",
      "processing_time": 60.11788487434387,
      "citing_paper_id": "252901047",
      "cited_paper_id": 4321928
    },
    {
      "context_text": "In Discussion (Section VI-D), we compare our method to methods based on loss function modification [40] and example re-weighting [41] to assess its effectiveness.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on comparing different methods, not using datasets.",
      "processing_time": 58.62593865394592,
      "citing_paper_id": "252901047",
      "cited_paper_id": 4321928
    },
    {
      "context_text": "In the ﬁne-tuning state, we employ the RAMS development set for hyper-parameter tuning, and ﬁnally, the batch size is set to 20 (selected from [1, 5, 10, 20, 30, 40]) and the learning rate is set to 2e-5 (picked from [1e-5, 2e-5, 3e-5, 4e-5]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for hyper-parameter tuning during the fine-tuning phase, specifically adjusting batch size and learning rate for optimal performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the RAMS development set for hyper-parameter tuning, which is a specific dataset used in the document-level event extraction domain.",
      "processing_time": 65.3656747341156,
      "citing_paper_id": "252901047",
      "cited_paper_id": 6546734
    },
    {
      "context_text": "[40], which modiﬁes the term log P (ˆ a | ˆ D , ˆ q ) to − (1 − P (ˆ a | ˆ D , ˆ q )) in (3) for model training, and the method based on example re-weighting (Re-Weighting) [41], which uses a model trained with in-domain data to give out-of-domain and automatically generated data a weight for…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for handling label noise in deep neural networks.",
      "processing_time": 57.50163912773132,
      "citing_paper_id": "252901047",
      "cited_paper_id": 6546734
    },
    {
      "context_text": "In Discussion (Section VI-D), we compare our method to methods based on loss function modiﬁcation [40] and example re-weighting [41] to assess its effectiveness.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on comparing different methods for handling label noise in deep neural networks.",
      "processing_time": 59.305259466171265,
      "citing_paper_id": "252901047",
      "cited_paper_id": 6546734
    },
    {
      "context_text": "For this MUC-4 task formulation, traditional approaches have proposed feature-based methods [18], [22], [23], while modern approacheshavestudiedusingneuralnetworksbasedmethodsto obtain document-level cues for learning [19], [24], [25].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is about comparing traditional and modern methods for event extraction.",
      "processing_time": 58.756920337677,
      "citing_paper_id": "252901047",
      "cited_paper_id": 6644751
    },
    {
      "context_text": ", VICTIM) regarding an event template [17], [18], [19], [20], [21].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to event templates. No verifiable resources are identified.",
      "processing_time": 57.649386167526245,
      "citing_paper_id": "252901047",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "For the sentence-level event argument extraction task, the existing methods [30], [31] have used distant supervision for data augmentation, leveraging external knowledge bases to generate new training data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'external knowledge bases' but does not specify any particular dataset. The citation is about using distant supervision for data augmentation, which is a method, not a dataset.",
      "processing_time": 59.883546352386475,
      "citing_paper_id": "252901047",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "In the fine-tuning state, we employ the RAMS development set for hyper-parameter tuning, and finally, the batch size is set to 20 (selected from [1, 5, 10, 20, 30, 40])",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS development set"
      ],
      "dataset_descriptions": {
        "RAMS development set": "Used for hyper-parameter tuning during the fine-tuning process, specifically to optimize the batch size for event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS development set, which is a specific dataset used for hyper-parameter tuning in the fine-tuning process.",
      "processing_time": 64.76795268058777,
      "citing_paper_id": "252901047",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "In our MRC model, we use a BERT-base-uncased architecture [12] to maintain consistency with previous studies [2], [5].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using BERT-base-uncased architecture but does not refer to any specific dataset. BERT is a model, not a dataset.",
      "processing_time": 58.95208954811096,
      "citing_paper_id": "252901047",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Furthermore, this collaborative architecture allows us to directly leverage the advanced models in MRC to handle document-level EAE, which have been proved to excel in capturing document-level clues [12].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to models in MRC for document-level event argument extraction. No verifiable dataset names are present.",
      "processing_time": 59.37786102294922,
      "citing_paper_id": "252901047",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In particular, we create a BERT based encoder [12] to jointly encode q r and D , by ﬁrst generating an extended input sequence to concatenate q r and D : where [CLS] and [SEP] are special tokens used in BERT [12].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT for encoding. BERT is a model, not a dataset.",
      "processing_time": 58.59835505485535,
      "citing_paper_id": "252901047",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We prefer the BERT-based MRC model [12], and in addition to the question answering dataset, i.e., SQuAD 2.0 [36], we also use corpora in FrameNet semantic role labeling (SRL) [37] and ACE 2005 event extraction (EE) [38] for pre-training 2 , by framing them in an MRC formulation in a similar fashion.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SQuAD 2.0",
        "FrameNet",
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "SQuAD 2.0": "Used for pre-training a BERT-based MRC model, focusing on question answering tasks by framing them in an MRC formulation.",
        "FrameNet": "Used for pre-training in semantic role labeling, framed in an MRC formulation to enhance the model's understanding of semantic roles.",
        "ACE 2005": "Used for pre-training in event extraction, framed in an MRC formulation to improve the model's ability to identify and classify events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions SQuAD 2.0, FrameNet, and ACE 2005 as corpora used for pre-training. These are specific datasets used in the research.",
      "processing_time": 80.6088342666626,
      "citing_paper_id": "252901047",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We prefer the BERT-based MRC model [12], and in addition to the question answering dataset, i.e., SQuAD 2.0 [36], we also use corpora in FrameNet semantic role labeling (SRL) [37] and ACE 2005 event extraction (EE) [38] for pre-training 2 , by framing them in an MRC formulation in a similar fashion.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SQuAD 2.0",
        "FrameNet",
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "SQuAD 2.0": "Used for pre-training a BERT-based MRC model, focusing on question answering tasks by framing them in an MRC formulation.",
        "FrameNet": "Used for pre-training in semantic role labeling, framed in an MRC formulation to enhance the model's understanding of semantic roles.",
        "ACE 2005": "Used for pre-training in event extraction, framed in an MRC formulation to improve the model's ability to identify and classify events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions SQuAD 2.0, FrameNet, and ACE 2005 as corpora used for pre-training. These are specific datasets used in the research.",
      "processing_time": 80.6088342666626,
      "citing_paper_id": "252901047",
      "cited_paper_id": null
    },
    {
      "context_text": "In the implicit knowledge transfer method, after pre-training, the MRC model scores 83.5%, 72.1%, and 70.1% in F1 on SQuAD 2.0, FrameNet SRL, and ACE 2005 EE datasets, respectively, matching the state-of-the-art performance [11], [12], [13].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SQuAD 2.0",
        "FrameNet SRL",
        "ACE 2005 EE"
      ],
      "dataset_descriptions": {
        "SQuAD 2.0": "Used to evaluate the MRC model's performance after pre-training, focusing on question answering tasks with a focus on F1 score.",
        "FrameNet SRL": "Used to assess the MRC model's semantic role labeling capabilities, specifically measuring F1 score post-pre-training.",
        "ACE 2005 EE": "Used to evaluate the MRC model's event extraction performance, particularly in identifying events and entities, using F1 score."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three datasets used for evaluating the MRC model's performance after pre-training. These datasets are specific and have clear identifiers.",
      "processing_time": 79.79052710533142,
      "citing_paper_id": "252901047",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "To name a few, authors in [9], [33] cast relation",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a vague reference to relations. No clear, verifiable resources are identified.",
      "processing_time": 58.389923334121704,
      "citing_paper_id": "252901047",
      "cited_paper_id": 153312535
    },
    {
      "context_text": "1 (bottom) gives the data statistics of the currently largest document-level benchmark (i.e., RAMS [2]), where we can see that over 63% of roles have less than 100 instances.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to highlight the distribution of role instances in a large document-level event extraction benchmark, focusing on the scarcity of certain roles."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'RAMS' as a document-level benchmark, which fits the criteria for a dataset. However, it does not provide details on how the dataset is used beyond mentioning its size and role instance distribution.",
      "processing_time": 67.88919186592102,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "…can be viewed as eliciting knowledge from a pre-trained MRC model to generate new examples, and as the training set is explicitly expanded, the method has the potential to beneﬁt any model proposed for document-level EAE (e.g., that based on sequence labeling [13] or span prediction [2]).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the methodology for document-level event argument extraction (EAE).",
      "processing_time": 59.3335177898407,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "T EXTUAL event descriptions may span over multiple sentences; therefore to fully understand the semantics of an event we need to gather information from a document context for reasoning [1], [2], [3].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the need for document-level context in event extraction.",
      "processing_time": 57.845134019851685,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "T EXTUAL event descriptions may span over multiple sentences; therefore to fully understand the semantics of an event we need to gather information from a document context for reasoning [1], [2], [3].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the need for document-level context in event extraction.",
      "processing_time": 57.845134019851685,
      "citing_paper_id": "252901047",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Despite its effectiveness, one disadvantage of implicit knowl-edgetransferisthatitcannotcreateexplicittrainingdata,henceit canonlybeneﬁtamodelinanMRCformulationbutnotinother formulations[2],[4].",
      "catation_intent": "research work",
      "resource_type": "limitation",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses a limitation of implicit knowledge transfer.",
      "processing_time": 57.26470446586609,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Despite its effectiveness, one disadvantage of implicit knowl-edgetransferisthatitcannotcreateexplicittrainingdata,henceit canonlybeneﬁtamodelinanMRCformulationbutnotinother formulations[2],[4].",
      "catation_intent": "research work",
      "resource_type": "limitation",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses a limitation of implicit knowledge transfer.",
      "processing_time": 57.26470446586609,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "For example, the state-of-the-art model attains less than 10% in F1 when the argument and trigger are in different sentences [2], [4], [6].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only performance metrics. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 58.67752408981323,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "For example, the state-of-the-art model attains less than 10% in F1 when the argument and trigger are in different sentences [2], [4], [6].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only performance metrics. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 58.67752408981323,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "To validate the effectiveness of our approach, we have conducted extensive tests on three datasets, i.e., RAMS [2], WikiEvents [5], and MUC-4 [14].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to validate the effectiveness of the approach in document-level event extraction, focusing on multi-sentence argument linking.",
        "WikiEvents": "Used to test the approach's performance in identifying and linking events across multiple sentences in Wikipedia articles.",
        "MUC-4": "Used to evaluate the approach's ability to handle complex event structures in news articles, focusing on message understanding."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets used for validating the approach. These datasets are clearly named and relevant to document-level event extraction.",
      "processing_time": 74.31618857383728,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "To address the data sparsity issue, we take a perspective from MRC and aim to use resources in the domain of MRC for learning, as opposed to previous methods viewing the task as a sequence labeling [13] or span ranking [2].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context does not mention any specific datasets, only a general reference to resources in the domain of Machine Reading Comprehension (MRC).",
      "processing_time": 58.54485726356506,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "[2], W IKI E VENTS (W IKI E) [5] AND MUC-4 [14] 0.9) may be too easy for a model to learn new information, while examples with very low predictive probabilities (e.g., < 0.6) may be too noisy; therefore we choose examples with medium difﬁculty and noisy extent and force the model to train on them.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKI EVENTS",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "WIKI EVENTS": "Used to train and evaluate models on document-level event extraction, focusing on linking events across multiple sentences.",
        "MUC-4": "Used to train and evaluate models on document-level event extraction, specifically for identifying and linking events in news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions WIKI EVENTS (WIKI E) and MUC-4, which are known datasets in the field of document-level event extraction. These datasets are used to train and evaluate models on event extraction tasks.",
      "processing_time": 74.15986347198486,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Document-level event argument extraction (EAE) is such a task requiring a model to extract arguments (i.e., participants) of an event at the document level [2], [4].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of document-level event argument extraction. No verifiable resources are named.",
      "processing_time": 58.795172929763794,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Document-level event argument extraction (EAE) is such a task requiring a model to extract arguments (i.e., participants) of an event at the document level [2], [4].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of document-level event argument extraction. No verifiable resources are named.",
      "processing_time": 58.795172929763794,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Unlike theMUC-4formulation,arecentwork[2]proposesanewbench-markthatismoreﬁne-grainedandannotatestriggersintexts.",
      "catation_intent": "reusable resource",
      "resource_type": "benchmark",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context does not provide a clear, specific dataset name. 'MUC-4' is mentioned but it is not clear if it is a dataset or a benchmark. The context focuses on a new benchmark rather than a specific dataset.",
      "processing_time": 62.71752595901489,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "…in the implicit knowledge transfer method, and in the explicit data generation method, we apply our method to a BERT-CRF model and a QAEE model [3], which uses a ﬁne-grained query generation strategy (we directly use the trigger prediction result of QAEE andonot…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the use of models and their methodologies, not on datasets.",
      "processing_time": 59.693087577819824,
      "citing_paper_id": "252901047",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Particularly, we note document-level EAE is strongly related to a machine reading comprehension (MRC) problem [7], [8], if the argument extraction process is viewed as an answer retrieving procedure [3], [9], [10], [11].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a conceptual relationship between document-level event argument extraction and machine reading comprehension.",
      "processing_time": 58.616636753082275,
      "citing_paper_id": "252901047",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "To name a few, authors in [9], [33] cast relation extraction into a question answering problem; authors in [10] address named entity recognition via an MRC formulation; authors in [3], [11] frame sentence-level event extraction as an MRC problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers are used to illustrate different formulations of NLP tasks, not to introduce or use datasets.",
      "processing_time": 60.49609589576721,
      "citing_paper_id": "252901047",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Followingearlierstudies ondocument-levelEAE[2],[3],[4],[25],weuseprecision (P), recall (R), and F1 score (F1) as evaluation metrics and we adopt the exact match (EM) criterion: only when the projected argument span matches exactly a gold one do we consider it a correct prediction.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and criteria. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 59.34633159637451,
      "citing_paper_id": "252901047",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Followingearlierstudies ondocument-levelEAE[2],[3],[4],[25],weuseprecision (P), recall (R), and F1 score (F1) as evaluation metrics and we adopt the exact match (EM) criterion: only when the projected argument span matches exactly a gold one do we consider it a correct prediction.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and criteria. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 59.34633159637451,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "…BART-Gen employs the BART-large architecture, which has many more parameters than the BERT-base architecture used in previous meth-ods [2], [4], to make the parameter set comparable, we change the conﬁguration to BART-based. roles deﬁned by the gold event types and “ w/o Type Constraint”…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model architectures and configurations. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 59.190471172332764,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "On RAMS, for example, when the event argument is two sentences ahead of 5 The results are based on the development set following [4], and we only use the conﬁguration of “ w/ Type Constraint” to simplify discussion.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate implicit event argument detection, focusing on the configuration with type constraints on the development set."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'RAMS' which appears to be a dataset, but there is no explicit mention of how it is used or its specific characteristics. The citation is brief and does not provide enough detail to confidently describe the usage.",
      "processing_time": 67.98327732086182,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Despitemanyadvancesonthistask,theproblemofinadequate training data still limits a model’s performance [29] — for example, even on the largest dataset RAMS, over 63% of the roles have fewer than 100 examples, limiting the performance of the currently best model to less than 50% in F1 [4].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to highlight the challenge of limited training data in event argument detection, specifically noting that over 63% of roles have fewer than 100 examples, impacting model performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS' as a dataset with inadequate training data, which is relevant to the document-level event extraction task.",
      "processing_time": 67.42110848426819,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Despitemanyadvancesonthistask,theproblemofinadequate training data still limits a model’s performance [29] — for example, even on the largest dataset RAMS, over 63% of the roles have fewer than 100 examples, limiting the performance of the currently best model to less than 50% in F1 [4].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to highlight the challenge of limited training data in event argument detection, specifically noting that over 63% of roles have fewer than 100 examples, impacting model performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS' as a dataset with inadequate training data, which is relevant to the document-level event extraction task.",
      "processing_time": 67.42110848426819,
      "citing_paper_id": "252901047",
      "cited_paper_id": 236087324
    },
    {
      "context_text": "Followingthework,awork[4]constructs a head-to-region approach yielding promising results; authors in [26] study the extent to which the pre-trained language model can assist learning; authors in [27] suggests that knowledge from FrameNet [28] be used to aid the reasoning process; authors in [5]…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to other works and methods. FrameNet is mentioned but it is a knowledge base, not a dataset.",
      "processing_time": 59.95543551445007,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "We conduct an error analysis following [4], by randomly selecting 100 error cases from the RAMS development set and determining their commonality.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS development set"
      ],
      "dataset_descriptions": {
        "RAMS development set": "Used for error analysis in implicit event argument detection, focusing on identifying common errors in the development phase of the model."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS development set, which is a specific dataset used for error analysis in the context of event argument detection.",
      "processing_time": 65.10197138786316,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "(cid:2) Head-Expand [4].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not provide enough context to identify specific datasets or their usage. The title suggests a method for event argument detection, but no datasets are mentioned.",
      "processing_time": 59.00740575790405,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "in [26] study the extent to which the pre-trained language model can assist learning; authors in [27] suggests that knowledge from",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to study the extent to which BERT pre-training assists in learning event arguments, focusing on the model's existing knowledge of event structures."
      },
      "confidence_score": 0.7,
      "reasoning": "The context does not provide specific information about the usage of the RAMS dataset, but the title indicates it is used for studying event arguments with BERT.",
      "processing_time": 66.4193172454834,
      "citing_paper_id": "252901047",
      "cited_paper_id": 222208551
    },
    {
      "context_text": "…approach yielding promising results; authors in [26] study the extent to which the pre-trained language model can assist learning; authors in [27] suggests that knowledge from FrameNet [28] be used to aid the reasoning process; authors in [5] investigate a generative perspective on the task,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works and methods. FrameNet is mentioned but it is a knowledge base, not a dataset.",
      "processing_time": 59.78691101074219,
      "citing_paper_id": "252901047",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "CDR (Li et al., 2016) and GDA (Wu et al., 2019) are two biomedical datasets where CDR studies the binary interactions between disease and chemical concepts with 1 , 500 documents and GDA studies the binary relationships between gene and disease with 30 , 192 documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "CDR": "Used to study binary interactions between disease and chemical concepts, specifically analyzing 1,500 documents for chemical-disease relations.",
        "GDA": "Used to study binary relationships between gene and disease, specifically analyzing 30,192 documents for gene-disease associations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, CDR and GDA, with clear identifiers and usage details.",
      "processing_time": 70.99173831939697,
      "citing_paper_id": "237635295",
      "cited_paper_id": 88817
    },
    {
      "context_text": "CDR (Li et al., 2016) and GDA (Wu et al., 2019) are two biomedical datasets where CDR studies the binary interactions between disease and chemical concepts with 1 , 500 documents and GDA studies the binary relationships between gene and disease with 30 , 192 documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "CDR": "Used to study binary interactions between disease and chemical concepts, specifically analyzing 1,500 documents for chemical-disease relations.",
        "GDA": "Used to study binary relationships between gene and disease, specifically analyzing 30,192 documents for gene-disease associations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, CDR and GDA, with clear identifiers and usage details.",
      "processing_time": 70.99173831939697,
      "citing_paper_id": "237635295",
      "cited_paper_id": 92290275
    },
    {
      "context_text": "Altogether, our SAIS method achieves state-of-the-art RE performance on three benchmarks (Do-cRED (Yao et al., 2019), CDR (Li et al., 2016), and GDA (Wu et al., 2019)) due to more effective super-vision and enhances interpretability by improving the evidence retrieval (ER) F1 score on DocRED by 5 .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Do-cRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "Do-cRED": "Used to evaluate relation extraction performance, specifically enhancing interpretability by improving the evidence retrieval F1 score.",
        "CDR": "Used to evaluate relation extraction performance, focusing on chemical-disease relations.",
        "GDA": "Used to evaluate relation extraction performance, focusing on gene-disease associations."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions three benchmarks: Do-cRED, CDR, and GDA. These are likely datasets used for evaluating relation extraction methods. The cited paper titles help confirm that these are indeed datasets.",
      "processing_time": 75.12562966346741,
      "citing_paper_id": "237635295",
      "cited_paper_id": 88817
    },
    {
      "context_text": "Altogether, our SAIS method achieves state-of-the-art RE performance on three benchmarks (Do-cRED (Yao et al., 2019), CDR (Li et al., 2016), and GDA (Wu et al., 2019)) due to more effective super-vision and enhances interpretability by improving the evidence retrieval (ER) F1 score on DocRED by 5 .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Do-cRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "Do-cRED": "Used to evaluate relation extraction performance, specifically enhancing interpretability by improving the evidence retrieval F1 score.",
        "CDR": "Used to evaluate relation extraction performance, focusing on chemical-disease relations.",
        "GDA": "Used to evaluate relation extraction performance, focusing on gene-disease associations."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions three benchmarks: Do-cRED, CDR, and GDA. These are likely datasets used for evaluating relation extraction methods. The cited paper titles help confirm that these are indeed datasets.",
      "processing_time": 75.12562966346741,
      "citing_paper_id": "237635295",
      "cited_paper_id": 92290275
    },
    {
      "context_text": "Altogether, our SAIS method achieves state-of-the-art RE performance on three benchmarks (Do-cRED (Yao et al., 2019), CDR (Li et al., 2016), and GDA (Wu et al., 2019)) due to more effective super-vision and enhances interpretability by improving the evidence retrieval (ER) F1 score on DocRED by 5 .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Do-cRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "Do-cRED": "Used to evaluate relation extraction performance, specifically enhancing interpretability by improving the evidence retrieval F1 score.",
        "CDR": "Used to evaluate relation extraction performance, focusing on chemical-disease relations.",
        "GDA": "Used to evaluate relation extraction performance, focusing on gene-disease associations."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions three benchmarks: Do-cRED, CDR, and GDA. These are likely datasets used for evaluating relation extraction methods. The cited paper titles help confirm that these are indeed datasets.",
      "processing_time": 75.12562966346741,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Based on Huggingface (Wolf et al., 2019), we apply cased BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate cased BERT-base and RoBERTa-large models for document-level relation extraction, focusing on complex relations in scientific documents.",
        "CDR": "Used to evaluate cased SciBERT for chemical-disease relation extraction, focusing on domain-specific language in scientific texts.",
        "GDA": "Used to evaluate cased SciBERT for gene-disease association extraction, focusing on domain-specific language in scientific texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. These datasets are clearly identified and used in the research.",
      "processing_time": 78.2963616847992,
      "citing_paper_id": "237635295",
      "cited_paper_id": 88817
    },
    {
      "context_text": "Based on Huggingface (Wolf et al., 2019), we apply cased BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate cased BERT-base and RoBERTa-large models for document-level relation extraction, focusing on complex relations in scientific documents.",
        "CDR": "Used to evaluate cased SciBERT for chemical-disease relation extraction, focusing on domain-specific language in scientific texts.",
        "GDA": "Used to evaluate cased SciBERT for gene-disease association extraction, focusing on domain-specific language in scientific texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. These datasets are clearly identified and used in the research.",
      "processing_time": 78.2963616847992,
      "citing_paper_id": "237635295",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Based on Huggingface (Wolf et al., 2019), we apply cased BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate cased BERT-base and RoBERTa-large models for document-level relation extraction, focusing on complex relations in scientific documents.",
        "CDR": "Used to evaluate cased SciBERT for chemical-disease relation extraction, focusing on domain-specific language in scientific texts.",
        "GDA": "Used to evaluate cased SciBERT for gene-disease association extraction, focusing on domain-specific language in scientific texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. These datasets are clearly identified and used in the research.",
      "processing_time": 78.2963616847992,
      "citing_paper_id": "237635295",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "Based on Huggingface (Wolf et al., 2019), we apply cased BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate cased BERT-base and RoBERTa-large models for document-level relation extraction, focusing on complex relations in scientific documents.",
        "CDR": "Used to evaluate cased SciBERT for chemical-disease relation extraction, focusing on domain-specific language in scientific texts.",
        "GDA": "Used to evaluate cased SciBERT for gene-disease association extraction, focusing on domain-specific language in scientific texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. These datasets are clearly identified and used in the research.",
      "processing_time": 78.2963616847992,
      "citing_paper_id": "237635295",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "Based on Huggingface (Wolf et al., 2019), we apply cased BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate cased BERT-base and RoBERTa-large models for document-level relation extraction, focusing on complex relations in scientific documents.",
        "CDR": "Used to evaluate cased SciBERT for chemical-disease relation extraction, focusing on domain-specific language in scientific texts.",
        "GDA": "Used to evaluate cased SciBERT for gene-disease association extraction, focusing on domain-specific language in scientific texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. These datasets are clearly identified and used in the research.",
      "processing_time": 78.2963616847992,
      "citing_paper_id": "237635295",
      "cited_paper_id": 277550631
    },
    {
      "context_text": "Nevertheless, since more complicated relations can only be expressed by multiple sentences, there has been a shift of focus lately towards document-level RE (Yao et al. 2019; Li et al. 2016; Cheng et al. 2021; Wu et al. 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a shift towards document-level relation extraction but does not specify any datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 59.18578481674194,
      "citing_paper_id": "237635295",
      "cited_paper_id": 88817
    },
    {
      "context_text": "Nevertheless, since more complicated relations can only be expressed by multiple sentences, there has been a shift of focus lately towards document-level RE (Yao et al. 2019; Li et al. 2016; Cheng et al. 2021; Wu et al. 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a shift towards document-level relation extraction but does not specify any datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 59.18578481674194,
      "citing_paper_id": "237635295",
      "cited_paper_id": 92290275
    },
    {
      "context_text": "Nevertheless, since more complicated relations can only be expressed by multiple sentences, there has been a shift of focus lately towards document-level RE (Yao et al. 2019; Li et al. 2016; Cheng et al. 2021; Wu et al. 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a shift towards document-level relation extraction but does not specify any datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 59.18578481674194,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "When Model CDR GDA LSR (Nan et al., 2020) 64.8 82.2 SciBERT (Beltagy et al., 2019) 65.1 82.5 DHG (Zhang et al., 2020) 65.9 83.1 SSAN-SciBERT (Xu et al., 2021a) 68.7 83.7 ATLOP-SciBERT (Zhou et al., 2021) 69.4 83.9 SIRE-BioBERT (Zeng et al., 2021) 70.8 84.7 DocuNet-SciBERT (Zhang et al., 2021) 76 two tasks are used jointly, the pair of PER and ET, which combines textual contexts and entity type information, delivers the most signiﬁcant improvement.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance metrics. The cited papers do not introduce new datasets either.",
      "processing_time": 58.884032249450684,
      "citing_paper_id": "237635295",
      "cited_paper_id": 88817
    },
    {
      "context_text": "When Model CDR GDA LSR (Nan et al., 2020) 64.8 82.2 SciBERT (Beltagy et al., 2019) 65.1 82.5 DHG (Zhang et al., 2020) 65.9 83.1 SSAN-SciBERT (Xu et al., 2021a) 68.7 83.7 ATLOP-SciBERT (Zhou et al., 2021) 69.4 83.9 SIRE-BioBERT (Zeng et al., 2021) 70.8 84.7 DocuNet-SciBERT (Zhang et al., 2021) 76 two tasks are used jointly, the pair of PER and ET, which combines textual contexts and entity type information, delivers the most signiﬁcant improvement.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance metrics. The cited papers do not introduce new datasets either.",
      "processing_time": 58.884032249450684,
      "citing_paper_id": "237635295",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "When Model CDR GDA LSR (Nan et al., 2020) 64.8 82.2 SciBERT (Beltagy et al., 2019) 65.1 82.5 DHG (Zhang et al., 2020) 65.9 83.1 SSAN-SciBERT (Xu et al., 2021a) 68.7 83.7 ATLOP-SciBERT (Zhou et al., 2021) 69.4 83.9 SIRE-BioBERT (Zeng et al., 2021) 70.8 84.7 DocuNet-SciBERT (Zhang et al., 2021) 76 two tasks are used jointly, the pair of PER and ET, which combines textual contexts and entity type information, delivers the most signiﬁcant improvement.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance metrics. The cited papers do not introduce new datasets either.",
      "processing_time": 58.884032249450684,
      "citing_paper_id": "237635295",
      "cited_paper_id": 229339602
    },
    {
      "context_text": "When Model CDR GDA LSR (Nan et al., 2020) 64.8 82.2 SciBERT (Beltagy et al., 2019) 65.1 82.5 DHG (Zhang et al., 2020) 65.9 83.1 SSAN-SciBERT (Xu et al., 2021a) 68.7 83.7 ATLOP-SciBERT (Zhou et al., 2021) 69.4 83.9 SIRE-BioBERT (Zeng et al., 2021) 70.8 84.7 DocuNet-SciBERT (Zhang et al., 2021) 76 two tasks are used jointly, the pair of PER and ET, which combines textual contexts and entity type information, delivers the most signiﬁcant improvement.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance metrics. The cited papers do not introduce new datasets either.",
      "processing_time": 58.884032249450684,
      "citing_paper_id": "237635295",
      "cited_paper_id": 235421816
    },
    {
      "context_text": "On the other hand, it has been a trend that many recent datasets support the training of more powerful language models by providing multi-task annotations such as coreference and evidence (Yao et al., 2019; Li et al., 2016; Wu et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'recent datasets' but does not specify any particular dataset names. The cited papers do not provide specific dataset names either.",
      "processing_time": 59.02755165100098,
      "citing_paper_id": "237635295",
      "cited_paper_id": 88817
    },
    {
      "context_text": "On the other hand, it has been a trend that many recent datasets support the training of more powerful language models by providing multi-task annotations such as coreference and evidence (Yao et al., 2019; Li et al., 2016; Wu et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'recent datasets' but does not specify any particular dataset names. The cited papers do not provide specific dataset names either.",
      "processing_time": 59.02755165100098,
      "citing_paper_id": "237635295",
      "cited_paper_id": 92290275
    },
    {
      "context_text": "On the other hand, it has been a trend that many recent datasets support the training of more powerful language models by providing multi-task annotations such as coreference and evidence (Yao et al., 2019; Li et al., 2016; Wu et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'recent datasets' but does not specify any particular dataset names. The cited papers do not provide specific dataset names either.",
      "processing_time": 59.02755165100098,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Nevertheless, since more complicated relations can only be expressed by multiple sentences, there has been a shift of focus lately towards document-level RE (Yao et al., 2019; Li et al., 2016; Cheng et al., 2021; Wu et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a shift in focus towards document-level relation extraction. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 60.900063276290894,
      "citing_paper_id": "237635295",
      "cited_paper_id": 88817
    },
    {
      "context_text": "Nevertheless, since more complicated relations can only be expressed by multiple sentences, there has been a shift of focus lately towards document-level RE (Yao et al., 2019; Li et al., 2016; Cheng et al., 2021; Wu et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a shift in focus towards document-level relation extraction. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 60.900063276290894,
      "citing_paper_id": "237635295",
      "cited_paper_id": 92290275
    },
    {
      "context_text": "Nevertheless, since more complicated relations can only be expressed by multiple sentences, there has been a shift of focus lately towards document-level RE (Yao et al., 2019; Li et al., 2016; Cheng et al., 2021; Wu et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a shift in focus towards document-level relation extraction. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 60.900063276290894,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Since neither CDR nor GDA annotates evidence sentences, we apply SAIS O RE+CR+ET here.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods or tools. The cited paper title suggests a dataset, but it is not explicitly used in the given context.",
      "processing_time": 59.853530406951904,
      "citing_paper_id": "237635295",
      "cited_paper_id": 88817
    },
    {
      "context_text": "Similar trends are also recognized on CDR and GDA in Table 2, where SAIS trained with both CR and ET (besides RE) scores higher than its single-task counterpart.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not provide specific dataset names, only acronyms and task types. The cited paper title suggests 'BioCreative V CDR task corpus' is a relevant dataset, but it is not mentioned in the context.",
      "processing_time": 62.23710775375366,
      "citing_paper_id": "237635295",
      "cited_paper_id": 88817
    },
    {
      "context_text": "8% absolutely on CDR and GDA, respectively.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context does not provide enough information to identify specific datasets. The mention of 'CDR and GDA' is likely referring to corpora, but they are not explicitly named as datasets.",
      "processing_time": 60.34628868103027,
      "citing_paper_id": "237635295",
      "cited_paper_id": 88817
    },
    {
      "context_text": "2 Related Work Early research efforts on RE (Bach and Badaskar 2007; Pawar, Palshikar, and Bhattacharyya 2017) center around predicting relations for entity pairs at the sentence level (Zhang et al. 2017; Hendrickx et al. 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous research works and tasks.",
      "processing_time": 57.074931621551514,
      "citing_paper_id": "237635295",
      "cited_paper_id": 436023
    },
    {
      "context_text": "Early research efforts on RE (Bach and Badaskar, 2007; Pawar et al., 2017) center around predicting relations for entity pairs at the sentence level (Zhang et al., 2017; Hendrickx et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only research efforts and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 59.20332980155945,
      "citing_paper_id": "237635295",
      "cited_paper_id": 436023
    },
    {
      "context_text": "Early research efforts on RE (Bach and Badaskar, 2007; Pawar et al., 2017) center around predicting relations for entity pairs at the sentence level (Zhang et al., 2017; Hendrickx et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only research efforts and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 59.20332980155945,
      "citing_paper_id": "237635295",
      "cited_paper_id": 260557571
    },
    {
      "context_text": "Earlier studies mostly pay attention to sentence-level RE (Zhang et al. 2017; Hendrickx et al. 2019) (i.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to earlier studies and sentence-level relation extraction.",
      "processing_time": 58.169750452041626,
      "citing_paper_id": "237635295",
      "cited_paper_id": 436023
    },
    {
      "context_text": "Earlier studies mostly pay attention to sentence-level RE (Zhang et al., 2017; Hendrickx et al., 2019) (i.e., the targeting entity pair co-occur within a sentence) and achieve promising results (Zhang et al., 2019; Zhou et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to earlier studies and their focus on sentence-level relation extraction.",
      "processing_time": 58.450703144073486,
      "citing_paper_id": "237635295",
      "cited_paper_id": 436023
    },
    {
      "context_text": "Earlier studies mostly pay attention to sentence-level RE (Zhang et al., 2017; Hendrickx et al., 2019) (i.e., the targeting entity pair co-occur within a sentence) and achieve promising results (Zhang et al., 2019; Zhou et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to earlier studies and their focus on sentence-level relation extraction.",
      "processing_time": 58.450703144073486,
      "citing_paper_id": "237635295",
      "cited_paper_id": 210718708
    },
    {
      "context_text": "Earlier studies mostly pay attention to sentence-level RE (Zhang et al., 2017; Hendrickx et al., 2019) (i.e., the targeting entity pair co-occur within a sentence) and achieve promising results (Zhang et al., 2019; Zhou et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to earlier studies and their focus on sentence-level relation extraction.",
      "processing_time": 58.450703144073486,
      "citing_paper_id": "237635295",
      "cited_paper_id": 260557571
    },
    {
      "context_text": "A is the average of the attention heads in the last transformer layer (Vaswani et al. 2017) of the PLM.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (attention mechanism in transformers).",
      "processing_time": 57.582988023757935,
      "citing_paper_id": "237635295",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "…document, with alternating segment token indices for each sentence (Liu and Lapata, 2019), into a PLM: to obtain the token embeddings H ∈ N d × H and the cross-token attention A ∈ N d × N d . heads A is the average of the attention in the last trans-former layer (Vaswani et al., 2017) of the PLM.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the use of a pre-trained language model (PLM) and attention mechanisms.",
      "processing_time": 60.3717257976532,
      "citing_paper_id": "237635295",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "…(Wang et al., 2019; Tang et al., 2020; Huang et al., 2020; Xu et al., 2021a; Zhou et al., 2021; Zhang et al., 2021; Xie et al., 2022; Ye et al., 2020) leverage the strength of pre-trained language models (Devlin et al., 2019; Liu et al., 2019) to encode long-range contextual dependencies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only pre-trained language models. The cited papers are about BERT and RoBERTa, which are models, not datasets.",
      "processing_time": 60.62272024154663,
      "citing_paper_id": "237635295",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "…(Wang et al., 2019; Tang et al., 2020; Huang et al., 2020; Xu et al., 2021a; Zhou et al., 2021; Zhang et al., 2021; Xie et al., 2022; Ye et al., 2020) leverage the strength of pre-trained language models (Devlin et al., 2019; Liu et al., 2019) to encode long-range contextual dependencies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only pre-trained language models. The cited papers are about BERT and RoBERTa, which are models, not datasets.",
      "processing_time": 60.62272024154663,
      "citing_paper_id": "237635295",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "2020) leverage the strength of pre-trained language models (Devlin et al. 2019; Liu et al. 2019) to encode long-range contextual dependencies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only pre-trained language models. The cited papers are methods, not datasets.",
      "processing_time": 58.7388277053833,
      "citing_paper_id": "237635295",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "2020) leverage the strength of pre-trained language models (Devlin et al. 2019; Liu et al. 2019) to encode long-range contextual dependencies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only pre-trained language models. The cited papers are methods, not datasets.",
      "processing_time": 58.7388277053833,
      "citing_paper_id": "237635295",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "More specifically, we apply cased BERT-base (Devlin et al. 2019) and RoBERTa-large (Liu et al.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (BERT and RoBERTa).",
      "processing_time": 57.72906160354614,
      "citing_paper_id": "237635295",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "All the trials are optimized by AdamW (Loshchilov and Hutter, 2019) for 20 epochs with early stopping and a linearly decaying scheduler (Goyal et al., 2017) whose warm-up ratio = 6% .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only optimization methods and training strategies.",
      "processing_time": 57.3613166809082,
      "citing_paper_id": "237635295",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "All the trials are optimized with AdamW (Loshchilov and Hutter 2019) for 20 epochs and with a linearly decaying scheduler (Goyal et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only optimization methods and training parameters.",
      "processing_time": 57.13421821594238,
      "citing_paper_id": "237635295",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "2016) and GDA (Wu et al. 2019) are two biomedical datasets where CDG studies the binary interactions between disease and chemical concepts with 1,500 documents and GDA studies the binary relationships between gene and disease with 30,192 documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GDA",
        "CDG"
      ],
      "dataset_descriptions": {
        "GDA": "Used to study binary relationships between gene and disease with 30,192 documents, focusing on extracting gene-disease associations from literature.",
        "CDG": "Used to study binary interactions between disease and chemical concepts with 1,500 documents, focusing on extracting chemical-disease interactions from literature."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, GDA and CDG, with clear document counts and domain-specific content. These are used for studying binary interactions in biomedical contexts.",
      "processing_time": 73.75359869003296,
      "citing_paper_id": "237635295",
      "cited_paper_id": 92290275
    },
    {
      "context_text": "2016), and GDA (Wu et al. 2019)) due to more effective supervision and enhances interpretability by improving the evidence retrieval (ER) F1 score on DocRED by 5.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation does not mention any specific datasets, only improvements on a metric (F1 score) on a dataset called DocRED. However, DocRED is not explicitly mentioned in the citation span.",
      "processing_time": 61.5465407371521,
      "citing_paper_id": "237635295",
      "cited_paper_id": 92290275
    },
    {
      "context_text": "Graph-based approaches (Nan et al. 2020; Wang et al. 2020; Zeng et al. 2020; Li et al. 2020; Zeng, Wu, and Chang 2021; Xu, Chen, and Zhao 2021a,b; Sahu et al. 2019; Guo, Zhang, and Lu 2019) typically infuse contexts into heuristic-based document graphs and perform multi-hop reasoning via advanced neural techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only graph-based approaches and methods. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.68492007255554,
      "citing_paper_id": "237635295",
      "cited_paper_id": 184487889
    },
    {
      "context_text": "Graph-based approaches (Nan et al. 2020; Wang et al. 2020; Zeng et al. 2020; Li et al. 2020; Zeng, Wu, and Chang 2021; Xu, Chen, and Zhao 2021a,b; Sahu et al. 2019; Guo, Zhang, and Lu 2019) typically infuse contexts into heuristic-based document graphs and perform multi-hop reasoning via advanced neural techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only graph-based approaches and methods. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.68492007255554,
      "citing_paper_id": "237635295",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "Graph-based approaches (Nan et al., 2020; Wang et al., 2020; Zeng et al., 2020; Li et al., 2020; Zeng et al., 2021; Xu et al., 2021c,d; Sahu et al., 2019; Guo et al., 2019) typically infuse contexts into heuristic-based document graphs and perform multi-hop reasoning via advanced neural techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only graph-based approaches and methods. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 59.97152066230774,
      "citing_paper_id": "237635295",
      "cited_paper_id": 184487889
    },
    {
      "context_text": "Graph-based approaches (Nan et al., 2020; Wang et al., 2020; Zeng et al., 2020; Li et al., 2020; Zeng et al., 2021; Xu et al., 2021c,d; Sahu et al., 2019; Guo et al., 2019) typically infuse contexts into heuristic-based document graphs and perform multi-hop reasoning via advanced neural techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only graph-based approaches and methods. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 59.97152066230774,
      "citing_paper_id": "237635295",
      "cited_paper_id": 190001673
    },
    {
      "context_text": "Graph-based approaches (Nan et al., 2020; Wang et al., 2020; Zeng et al., 2020; Li et al., 2020; Zeng et al., 2021; Xu et al., 2021c,d; Sahu et al., 2019; Guo et al., 2019) typically infuse contexts into heuristic-based document graphs and perform multi-hop reasoning via advanced neural techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only graph-based approaches and methods. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 59.97152066230774,
      "citing_paper_id": "237635295",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "Graph-based approaches (Nan et al., 2020; Wang et al., 2020; Zeng et al., 2020; Li et al., 2020; Zeng et al., 2021; Xu et al., 2021c,d; Sahu et al., 2019; Guo et al., 2019) typically infuse contexts into heuristic-based document graphs and perform multi-hop reasoning via advanced neural techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only graph-based approaches and methods. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 59.97152066230774,
      "citing_paper_id": "237635295",
      "cited_paper_id": 229339602
    },
    {
      "context_text": "Graph-based approaches (Nan et al., 2020; Wang et al., 2020; Zeng et al., 2020; Li et al., 2020; Zeng et al., 2021; Xu et al., 2021c,d; Sahu et al., 2019; Guo et al., 2019) typically infuse contexts into heuristic-based document graphs and perform multi-hop reasoning via advanced neural techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only graph-based approaches and methods. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 59.97152066230774,
      "citing_paper_id": "237635295",
      "cited_paper_id": 235421816
    },
    {
      "context_text": "Given that more complicated relations are often expressed by multiple sentences, recent focus of RE has been largely shifted to the document level (Yao et al., 2019; Cheng et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to study document-level relation extraction, focusing on complex relations expressed across multiple sentences in a large-scale dataset."
      },
      "confidence_score": 0.85,
      "reasoning": "The citation mentions document-level relation extraction but does not explicitly name a dataset. However, the cited paper title 'DocRED' suggests a specific dataset.",
      "processing_time": 65.29476380348206,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Given that more complicated relations can only be expressed by multiple sentences, the focus of RE has been recently advanced to the document level (Yao et al. 2019; Cheng et al. 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions document-level relation extraction, which is directly relevant to the research topic. However, no specific dataset names are mentioned in the citation span.",
      "processing_time": 59.67404055595398,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "DocRED (Yao et al. 2019) is a large-scale crowd-sourced dataset based on Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate document-level relation extraction models, focusing on complex relations across multiple sentences in Wikipedia articles."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is explicitly mentioned as a dataset and is described as a large-scale crowd-sourced dataset based on Wikipedia articles.",
      "processing_time": 64.43766593933105,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Altogether, our proposed SAIS method achieves stateof-the-art RE performance on three benchmarks (DocRED (Yao et al. 2019), CDG (Li et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate the proposed SAIS method for document-level relation extraction, focusing on achieving state-of-the-art performance on a large-scale dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' as a benchmark, which is confirmed to be a dataset by the cited paper title. No other specific datasets are mentioned.",
      "processing_time": 67.16704154014587,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "As a case study, it is reported by Yao et al. (2019) that around 17 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not mention any specific dataset names or provide enough context to identify a dataset. The reference to 'DocRED' in the title is not sufficient to infer usage details.",
      "processing_time": 60.86725425720215,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "DocRED (Yao et al., 2019) is a large-scale crowd-sourced dataset based on Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction, specifically leveraging crowd-sourced annotations from Wikipedia articles to train and evaluate models."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is explicitly mentioned as a dataset based on Wikipedia articles, used for document-level relation extraction.",
      "processing_time": 63.62229347229004,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "2 Coreference Resolution (CR) As a case study, it is reported in (Yao et al. 2019) that around 17.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a paper about document-level relation extraction.",
      "processing_time": 58.28983807563782,
      "citing_paper_id": "237635295",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "2019) and RoBERTa-large (Liu et al. 2019) for DocRED and cased SciBERT (Beltagy, Lo, and Cohan 2019) for CDR and GDA.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate models trained on document-level relation extraction, focusing on complex relations across multiple sentences."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions 'DocRED', 'CDR', and 'GDA' as datasets used for evaluation. However, only 'DocRED' is clearly identified as a dataset in the context of document-level event extraction.",
      "processing_time": 68.22877407073975,
      "citing_paper_id": "237635295",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "Then we feed the document, with alternating segment token indices for each sentence (Liu and Lapata, 2019), into a PLM: to obtain the token embeddings H ∈ N d × H and the cross-token attention A ∈ N d × N d . heads A is the average of the attention in the last trans-former layer (Vaswani et al.,…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 59.58214592933655,
      "citing_paper_id": "237635295",
      "cited_paper_id": 201304248
    },
    {
      "context_text": "Then we feed the document, with alternating segment token indices for each sentence (Liu and Lapata 2019), into a PLM,",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method involving segment token indices and a pretrained language model.",
      "processing_time": 58.481735944747925,
      "citing_paper_id": "237635295",
      "cited_paper_id": 201304248
    },
    {
      "context_text": "When Model CDR GDA LSR (Nan et al., 2020) 64.8 82.2 SciBERT (Beltagy et al., 2019) 65.1 82.5 DHG (Zhang et al., 2020) 65.9 83.1 SSAN-SciBERT (Xu et al., 2021a) 68.7 83.7 ATLOP-SciBERT (Zhou et al., 2021) 69.4 83.9 SIRE-BioBERT (Zeng et al., 2021) 70.8 84.7 DocuNet-SciBERT (Zhang et al., 2021) 76…",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and their performance metrics. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 60.298619985580444,
      "citing_paper_id": "237635295",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "When Model CDR GDA LSR (Nan et al., 2020) 64.8 82.2 SciBERT (Beltagy et al., 2019) 65.1 82.5 DHG (Zhang et al., 2020) 65.9 83.1 SSAN-SciBERT (Xu et al., 2021a) 68.7 83.7 ATLOP-SciBERT (Zhou et al., 2021) 69.4 83.9 SIRE-BioBERT (Zeng et al., 2021) 70.8 84.7 DocuNet-SciBERT (Zhang et al., 2021) 76…",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and their performance metrics. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 60.298619985580444,
      "citing_paper_id": "237635295",
      "cited_paper_id": 229339602
    },
    {
      "context_text": "When Model CDR GDA LSR (Nan et al., 2020) 64.8 82.2 SciBERT (Beltagy et al., 2019) 65.1 82.5 DHG (Zhang et al., 2020) 65.9 83.1 SSAN-SciBERT (Xu et al., 2021a) 68.7 83.7 ATLOP-SciBERT (Zhou et al., 2021) 69.4 83.9 SIRE-BioBERT (Zeng et al., 2021) 70.8 84.7 DocuNet-SciBERT (Zhang et al., 2021) 76…",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and their performance metrics. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 60.298619985580444,
      "citing_paper_id": "237635295",
      "cited_paper_id": 235421816
    },
    {
      "context_text": "The learning rate for ﬁne-tuning BERT is 5e 5 , that for ﬁne-tuning RoBERTa or SciBERT is 2e 5 , and that for training the other parameters is 1e 4 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and learning rates. There are no verifiable resources that meet the criteria.",
      "processing_time": 59.51449656486511,
      "citing_paper_id": "237635295",
      "cited_paper_id": 202558505
    },
    {
      "context_text": ", 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "CDR",
        "GDA"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate document-level relation extraction, focusing on complex relations across multiple sentences.",
        "CDR": "Used to evaluate chemical-disease relation extraction, focusing on identifying relationships between chemicals and diseases.",
        "GDA": "Used to evaluate gene-disease association extraction, focusing on identifying relationships between genes and diseases."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'DocRED', 'CDR', and 'GDA' as datasets but does not provide enough information about their usage or specific characteristics. The context is primarily focused on the models used for these datasets.",
      "processing_time": 76.79894590377808,
      "citing_paper_id": "237635295",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "The embedding dimension H of BERT or SciBERT is 768 , and that of RoBERTa is 1 , 024 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model dimensions. No verifiable resources are identified.",
      "processing_time": 58.303213119506836,
      "citing_paper_id": "237635295",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "In particular, consider a pair of mentions (mi,mj), we determine the probability of whether mi and mj refer to the same entity by passing their corresponding embeddings mi and mj through a group bilinear layer (Zheng et al. 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for determining entity co-reference using embeddings and a bilinear layer.",
      "processing_time": 59.49704170227051,
      "citing_paper_id": "237635295",
      "cited_paper_id": 202785670
    },
    {
      "context_text": "In particular, consider a pair of mentions ( m i , m j ) , we determine the probability of whether m i and m j refer to the same entity by passing their corresponding embeddings m i and m j through a group bilinear layer (Zheng et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for determining the probability of coreference using embeddings and a bilinear layer.",
      "processing_time": 59.87438440322876,
      "citing_paper_id": "237635295",
      "cited_paper_id": 202785670
    },
    {
      "context_text": ", the targeting entity pair co-occur within a sentence) and achieve promising results (Zhang et al. 2019; Zhou et al. 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 60.330050230026245,
      "citing_paper_id": "237635295",
      "cited_paper_id": 210718708
    },
    {
      "context_text": "Many pattern-based (Califf and Mooney, 1999; Qu et al., 2018; Zhou et al., 2020) and neural network-based (Cai et al., 2016; Feng et al., 2018; Zhang et al., 2019) models have shown impressive results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets in the text.",
      "processing_time": 60.139461040496826,
      "citing_paper_id": "237635295",
      "cited_paper_id": 210718708
    },
    {
      "context_text": "Many patternbased (Califf and Mooney 1999; Qu et al. 2018; Zhou et al. 2020) and neural network-based (Cai, Zhang, and Wang 2016; Feng et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to pattern-based and neural network-based methods. No clear identifiers for datasets are present.",
      "processing_time": 60.65206813812256,
      "citing_paper_id": "237635295",
      "cited_paper_id": 210718708
    },
    {
      "context_text": "Transformer-based approaches (Wang et al. 2019; Tang et al. 2020; Huang et al. 2020; Xu et al. 2021a; Zhou et al. 2021; Zhang et al. 2021; Xie et al. 2021; Ye et al. 2020) leverage the strength of pre-trained language models (Devlin et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to transformer-based approaches and pre-trained language models. No verifiable datasets are identified.",
      "processing_time": 60.31810688972473,
      "citing_paper_id": "237635295",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "…approaches (Wang et al., 2019; Tang et al., 2020; Huang et al., 2020; Xu et al., 2021a; Zhou et al., 2021; Zhang et al., 2021; Xie et al., 2022; Ye et al., 2020) leverage the strength of pre-trained language models (Devlin et al., 2019; Liu et al., 2019) to encode long-range contextual…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to pre-trained language models and approaches. No verifiable resources are identified.",
      "processing_time": 60.3189640045166,
      "citing_paper_id": "237635295",
      "cited_paper_id": 215768766
    },
    {
      "context_text": "…2 for the focal hyper-parameters γ CR and γ PER based on the develop HeterGSAN-BERT base (Xu et al., 2021d) 58.13 60.18 - 57.12 59.45 - GAIN-BERT base (Zeng et al., 2020) 59.14 61.22 - 59.00 61.24 - DRN-BERT base (Xu et al., 2021c) 59.33 61.39 - 59.15 61.37 - SIRE-BERT base (Zeng et al., 2021) 59…",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and their performance metrics. The context is focused on comparing different models for document-level relation extraction.",
      "processing_time": 60.90674948692322,
      "citing_paper_id": "237635295",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "Existing document-level RE methods (Zeng et al., 2020; Zhou et al., 2021) utilize advanced neural architectures such as heterogeneous graph neural networks (Yang et al., 2020) and pre-trained language models (Xu et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 60.56640124320984,
      "citing_paper_id": "237635295",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "Existing document-level RE methods (Zeng et al., 2020; Zhou et al., 2021) utilize advanced neural architectures such as heterogeneous graph neural networks (Yang et al., 2020) and pre-trained language models (Xu et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 60.56640124320984,
      "citing_paper_id": "237635295",
      "cited_paper_id": 229339602
    },
    {
      "context_text": "Existing document-level RE methods (Zeng et al., 2020; Zhou et al., 2021) utilize advanced neural architectures such as heterogeneous graph neural networks (Yang et al., 2020) and pre-trained language models (Xu et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 60.56640124320984,
      "citing_paper_id": "237635295",
      "cited_paper_id": 235421816
    },
    {
      "context_text": "Existing document-level RE methods (Zeng et al. 2020; Zhou et al. 2021; Xu et al. 2021a) utilize",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The context is too generic to infer any specific dataset usage.",
      "processing_time": 60.38360619544983,
      "citing_paper_id": "237635295",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "A recent study (Peng et al., 2020) attributes the success of these models to their ability to capture textual contexts and entity type information.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general discussion about the success of models in capturing textual contexts and entity type information.",
      "processing_time": 60.38375544548035,
      "citing_paper_id": "237635295",
      "cited_paper_id": 222133166
    },
    {
      "context_text": "The pair of PER and FER also performs well, which reﬂects the ﬁnding in (Peng et al., 2020) that context is the most important source of information.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a finding about the importance of context in relation extraction.",
      "processing_time": 59.251270055770874,
      "citing_paper_id": "237635295",
      "cited_paper_id": 222133166
    },
    {
      "context_text": "Based on an extensive empirical analysis, (Peng et al. 2020) reveals that textual contexts and entity types are the major information sources that lead to the success of prior approaches.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general information about textual contexts and entity types. No clear, verifiable resource names are provided.",
      "processing_time": 60.54247832298279,
      "citing_paper_id": "237635295",
      "cited_paper_id": 222133166
    },
    {
      "context_text": "Peng et al. (2020) reveals that textual contexts and entity types are the major information sources that lead to the success of prior approaches.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general information about the success of prior approaches in relation extraction.",
      "processing_time": 59.25416541099548,
      "citing_paper_id": "237635295",
      "cited_paper_id": 222133166
    },
    {
      "context_text": "A recent study (Peng et al. 2020) attributes the success of these models to their ability to capture textual contexts and entity type information.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general discussion about the success of models in capturing textual contexts and entity type information.",
      "processing_time": 60.09112048149109,
      "citing_paper_id": "237635295",
      "cited_paper_id": 222133166
    },
    {
      "context_text": "The pair of PER and FER also performs well, which reflects the finding in (Peng et al. 2020) that context is the most important source of information.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a finding about the importance of context in relation extraction.",
      "processing_time": 59.126519203186035,
      "citing_paper_id": "237635295",
      "cited_paper_id": 222133166
    },
    {
      "context_text": "2020) and pre-trained language models (Xu et al. 2021b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to pre-trained language models and document-level relation extraction.",
      "processing_time": 59.58154225349426,
      "citing_paper_id": "237635295",
      "cited_paper_id": 229339602
    },
    {
      "context_text": "…et al., 2021a) 57.03 59.19 - 56.06 58.41 - ATLOP-BERT base (Zhou et al., 2021) 59.22 61.09 - 59.31 61.30 - DocuNet-BERT base (Zhang et al., 2021) 59 (Xu et al., 2021a) 60.25 62.08 - 59.47 61.42 - E2GRE-RoBERTa large (Huang et al., 2020) - - - 60.30 62.50 50.50 ATLOP-RoBERTa large (Zhou et al.,…",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only model performances. The cited papers' titles do not help in identifying any datasets.",
      "processing_time": 60.41855597496033,
      "citing_paper_id": "237635295",
      "cited_paper_id": 229339602
    },
    {
      "context_text": "…et al., 2021a) 57.03 59.19 - 56.06 58.41 - ATLOP-BERT base (Zhou et al., 2021) 59.22 61.09 - 59.31 61.30 - DocuNet-BERT base (Zhang et al., 2021) 59 (Xu et al., 2021a) 60.25 62.08 - 59.47 61.42 - E2GRE-RoBERTa large (Huang et al., 2020) - - - 60.30 62.50 50.50 ATLOP-RoBERTa large (Zhou et al.,…",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only model performances. The cited papers' titles do not help in identifying any datasets.",
      "processing_time": 60.41855597496033,
      "citing_paper_id": "237635295",
      "cited_paper_id": 235421816
    },
    {
      "context_text": "…develop HeterGSAN-BERT base (Xu et al., 2021d) 58.13 60.18 - 57.12 59.45 - GAIN-BERT base (Zeng et al., 2020) 59.14 61.22 - 59.00 61.24 - DRN-BERT base (Xu et al., 2021c) 59.33 61.39 - 59.15 61.37 - SIRE-BERT base (Zeng et al., 2021) 59 (Huang et al., 2020) 55.22 58.72 47.14 - - - SSAN-BERT base…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only model names and performance metrics. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 60.57068634033203,
      "citing_paper_id": "237635295",
      "cited_paper_id": 229339602
    },
    {
      "context_text": "…develop HeterGSAN-BERT base (Xu et al., 2021d) 58.13 60.18 - 57.12 59.45 - GAIN-BERT base (Zeng et al., 2020) 59.14 61.22 - 59.00 61.24 - DRN-BERT base (Xu et al., 2021c) 59.33 61.39 - 59.15 61.37 - SIRE-BERT base (Zeng et al., 2021) 59 (Huang et al., 2020) 55.22 58.72 47.14 - - - SSAN-BERT base…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only model names and performance metrics. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 60.57068634033203,
      "citing_paper_id": "237635295",
      "cited_paper_id": 235421816
    },
    {
      "context_text": "…base (Xu et al., 2021c) 59.33 61.39 - 59.15 61.37 - SIRE-BERT base (Zeng et al., 2021) 59 (Huang et al., 2020) 55.22 58.72 47.14 - - - SSAN-BERT base (Xu et al., 2021a) 57.03 59.19 - 56.06 58.41 - ATLOP-BERT base (Zhou et al., 2021) 59.22 61.09 - 59.31 61.30 - DocuNet-BERT base (Zhang et al.,…",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and performance metrics. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 61.01189160346985,
      "citing_paper_id": "237635295",
      "cited_paper_id": 229339602
    },
    {
      "context_text": "…base (Xu et al., 2021c) 59.33 61.39 - 59.15 61.37 - SIRE-BERT base (Zeng et al., 2021) 59 (Huang et al., 2020) 55.22 58.72 47.14 - - - SSAN-BERT base (Xu et al., 2021a) 57.03 59.19 - 56.06 58.41 - ATLOP-BERT base (Zhou et al., 2021) 59.22 61.09 - 59.31 61.30 - DocuNet-BERT base (Zhang et al.,…",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and performance metrics. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 61.01189160346985,
      "citing_paper_id": "237635295",
      "cited_paper_id": 235421816
    },
    {
      "context_text": "5 , 2 for the focal hyper-parameters γ CR and γ PER based on the develop HeterGSAN-BERT base (Xu et al., 2021d) 58.13 60.18 - 57.12 59.45 - GAIN-BERT base (Zeng et al., 2020) 59.14 61.22 - 59.00 61.24 - DRN-BERT base (Xu et al., 2021c) 59.33 61.39 - 59.15 61.37 - SIRE-BERT base (Zeng et al., 2021)…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only model names and performance metrics. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 60.56408667564392,
      "citing_paper_id": "237635295",
      "cited_paper_id": 229339602
    },
    {
      "context_text": "5 , 2 for the focal hyper-parameters γ CR and γ PER based on the develop HeterGSAN-BERT base (Xu et al., 2021d) 58.13 60.18 - 57.12 59.45 - GAIN-BERT base (Zeng et al., 2020) 59.14 61.22 - 59.00 61.24 - DRN-BERT base (Xu et al., 2021c) 59.33 61.39 - 59.15 61.37 - SIRE-BERT base (Zeng et al., 2021)…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only model names and performance metrics. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 60.56408667564392,
      "citing_paper_id": "237635295",
      "cited_paper_id": 235421816
    },
    {
      "context_text": "Transformer-based approaches (Wang et al., 2019; Tang et al., 2020; Huang et al., 2020; Xu et al., 2021a; Zhou et al., 2021; Zhang et al., 2021; Xie et al., 2022; Ye et al., 2020) leverage the strength of pre-trained language models (Devlin et al., 2019; Liu et al., 2019) to encode long-range…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only transformer-based approaches and pre-trained language models. No verifiable resources are identified.",
      "processing_time": 60.08192563056946,
      "citing_paper_id": "237635295",
      "cited_paper_id": 229339602
    },
    {
      "context_text": "Transformer-based approaches (Wang et al., 2019; Tang et al., 2020; Huang et al., 2020; Xu et al., 2021a; Zhou et al., 2021; Zhang et al., 2021; Xie et al., 2022; Ye et al., 2020) leverage the strength of pre-trained language models (Devlin et al., 2019; Liu et al., 2019) to encode long-range…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only transformer-based approaches and pre-trained language models. No verifiable resources are identified.",
      "processing_time": 60.08192563056946,
      "citing_paper_id": "237635295",
      "cited_paper_id": 235421816
    },
    {
      "context_text": ", 2017) center around predicting relations for entity pairs at the sentence level (Zhang et al., 2017; Hendrickx et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only sentence-level relation prediction tasks.",
      "processing_time": 58.145888328552246,
      "citing_paper_id": "237635295",
      "cited_paper_id": 260557571
    },
    {
      "context_text": "Earlier studies mostly pay attention to sentence-level RE (Zhang et al., 2017; Hendrickx et al., 2019) (i.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to earlier studies on sentence-level relation extraction.",
      "processing_time": 58.39559888839722,
      "citing_paper_id": "237635295",
      "cited_paper_id": 260557571
    },
    {
      "context_text": "Implementation Details We implement the PLM encoder based on Huggingface (Wolf et al. 2019) and run our experiments on one Tesla A6000 GPU.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the implementation details using Huggingface's Transformers library.",
      "processing_time": 59.04391574859619,
      "citing_paper_id": "237635295",
      "cited_paper_id": 277550631
    },
    {
      "context_text": "First-order logic (FOL) rules can encode declarative knowledge and play a crucial role in symbolic reasoning (Cresswell and Hughes, 1996).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a book about modal logic.",
      "processing_time": 58.13115453720093,
      "citing_paper_id": "259370721",
      "cited_paper_id": 1164487
    },
    {
      "context_text": "Our approach formalizes the reasoning chain as first-order logic (FOL) rules (Cresswell and Hughes, 1996).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach using first-order logic rules.",
      "processing_time": 57.92425775527954,
      "citing_paper_id": "259370721",
      "cited_paper_id": 1164487
    },
    {
      "context_text": "Earlier efforts on this problem explore the MUC-4 benchmark (Chinchor, 1991; Huang and Riloff, 2012), also known as “template filling” because the entire document is about one event.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used for template filling in event extraction, focusing on one event per document to evaluate classifiers."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions the MUC-4 benchmark, which is a specific dataset used for event extraction tasks. The context indicates it is used for template filling, focusing on one event per document.",
      "processing_time": 67.48870635032654,
      "citing_paper_id": "259370721",
      "cited_paper_id": 2213149
    },
    {
      "context_text": "For optimization, we use the Adam optimizer (Kingma and Ba, 2015) with a batch size of 10 from [5, 10, 15, 20] and a learning rate of 1e-4 from [1e-3, 1e-4, 1e-5].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the Adam optimizer and training parameters. No datasets are referenced.",
      "processing_time": 59.33908677101135,
      "citing_paper_id": "259370721",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "We validate this assumption by analyzing its performance in low-resource scenarios and for defending against adversarial attacks (Jia and Liang, 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general scenarios and attacks. No clear, verifiable resource names are provided.",
      "processing_time": 59.510464668273926,
      "citing_paper_id": "259370721",
      "cited_paper_id": 7228830
    },
    {
      "context_text": "Inspired by work that augments neural networks with FOLs (Li and Srikumar, 2019; Ahmed et al., 2022), we present T-Norm fuzzy logic for relaxation (Hajek, 1998), which leads to an end-to-end training regime.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and theoretical work. There are no clear identifiers for datasets in the text.",
      "processing_time": 60.164933919906616,
      "citing_paper_id": "259370721",
      "cited_paper_id": 61701554
    },
    {
      "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate Span-F1 and Head-F1 metrics, focusing on argument extraction in document-level event extraction.",
        "WikiEvents": "Used to evaluate Coref-F1 metric, which considers co-reference linkages between arguments in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the topic.",
      "processing_time": 71.76890087127686,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate Span-F1 and Head-F1 metrics, focusing on argument extraction in document-level event extraction.",
        "WikiEvents": "Used to evaluate Coref-F1 metric, which considers co-reference linkages between arguments in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the topic.",
      "processing_time": 71.76890087127686,
      "citing_paper_id": "259370721",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate Span-F1 and Head-F1 metrics, focusing on argument extraction in document-level event extraction.",
        "WikiEvents": "Used to evaluate Coref-F1 metric, which considers co-reference linkages between arguments in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the topic.",
      "processing_time": 71.76890087127686,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate Span-F1 and Head-F1 metrics, focusing on argument extraction in document-level event extraction.",
        "WikiEvents": "Used to evaluate Coref-F1 metric, which considers co-reference linkages between arguments in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the topic.",
      "processing_time": 71.76890087127686,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate Span-F1 and Head-F1 metrics, focusing on argument extraction in document-level event extraction.",
        "WikiEvents": "Used to evaluate Coref-F1 metric, which considers co-reference linkages between arguments in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the topic.",
      "processing_time": 71.76890087127686,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "BIOlabel (Shi and Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models, but does not explicitly refer to any datasets. The names mentioned are likely models or methods used in the research.",
      "processing_time": 60.823418617248535,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "BIOlabel (Shi and Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models, but does not explicitly refer to any datasets. The names mentioned are likely models or methods used in the research.",
      "processing_time": 60.823418617248535,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "BIOlabel (Shi and Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models, but does not explicitly refer to any datasets. The names mentioned are likely models or methods used in the research.",
      "processing_time": 60.823418617248535,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "…explosion was a sucicde bomber who detonated his belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets in the text.",
      "processing_time": 60.268110275268555,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "2) Global encoding methods, such as QAEE (Du and Cardie, 2020b) and DocMRC (Liu et al., 2021), which form the task as a document-based question-answering problem, and MemNet (Du et al., 2022), which uses a memory to store global event information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions methods and models (QAEE, DocMRC, MemNet) but does not reference any specific datasets. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 62.357582807540894,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "2) Global encoding methods, such as QAEE (Du and Cardie, 2020b) and DocMRC (Liu et al., 2021), which form the task as a document-based question-answering problem, and MemNet (Du et al., 2022), which uses a memory to store global event information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions methods and models (QAEE, DocMRC, MemNet) but does not reference any specific datasets. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 62.357582807540894,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "BIOlabel (Shi and Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is performed by ﬁrst broadcasting the vector to the same dimension as the matrix, followed by an element-wise concatenation operation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models, but does not explicitly refer to any datasets. The names mentioned are likely models or methods used in the research.",
      "processing_time": 60.802780628204346,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "BIOlabel (Shi and Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is performed by ﬁrst broadcasting the vector to the same dimension as the matrix, followed by an element-wise concatenation operation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models, but does not explicitly refer to any datasets. The names mentioned are likely models or methods used in the research.",
      "processing_time": 60.802780628204346,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.78171348571777,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.78171348571777,
      "citing_paper_id": "259370721",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.78171348571777,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247417818
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.78171348571777,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.78171348571777,
      "citing_paper_id": "259370721",
      "cited_paper_id": 252391326
    },
    {
      "context_text": "From the results, we can see that our model maintains a comparable time to earlier methods such as QAEE and is faster than many models such as FEAE and DocMRC, where FEAE has two base models for knowledge distillation and DocMRC uses external data to pretrain the model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets in the text.",
      "processing_time": 59.87524223327637,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. There are no clear identifiers for datasets.",
      "processing_time": 59.695395708084106,
      "citing_paper_id": "259370721",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "In this task, the major challenge is to model long-range dependencies between event triggers and arguments, as an event expression can span multiple sentences (Ebner et al., 2020; Liu et al., 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the challenge of modeling long-range dependencies in document-level event extraction.",
      "processing_time": 58.610283851623535,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "When ground-truth entities are available (such as in WikiEvents (Li et al., 2021)), we consider the candidate set to be the ground-truth entity set; otherwise, we use external toolkits2 to recognize entities.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to define the candidate set for entity recognition in document-level event argument extraction, providing ground-truth entities for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'WikiEvents' as a dataset where ground-truth entities are available. It is used to define the candidate set for entity recognition in document-level event argument extraction.",
      "processing_time": 67.95554780960083,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "(Du et al., 2022) 46.2 47.0 46.6 BART-Gen (Li et al., 2021) 42.1 47.3 44.5 PAIE (Ma et al., 2022) - - 49.5 FEAE (Wei et al., 2021) 53.1 42.7 47.4 TSAR (Xu et al",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and performance metrics. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.553367137908936,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "(Du et al., 2022) 46.2 47.0 46.6 BART-Gen (Li et al., 2021) 42.1 47.3 44.5 PAIE (Ma et al., 2022) - - 49.5 FEAE (Wei et al., 2021) 53.1 42.7 47.4 TSAR (Xu et al",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and performance metrics. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.553367137908936,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "(Du et al., 2022) 46.2 47.0 46.6 BART-Gen (Li et al., 2021) 42.1 47.3 44.5 PAIE (Ma et al., 2022) - - 49.5 FEAE (Wei et al., 2021) 53.1 42.7 47.4 TSAR (Xu et al",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and performance metrics. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.553367137908936,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "(Du et al., 2022) 46.2 47.0 46.6 BART-Gen (Li et al., 2021) 42.1 47.3 44.5 PAIE (Ma et al., 2022) - - 49.5 FEAE (Wei et al., 2021) 53.1 42.7 47.4 TSAR (Xu et al",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and performance metrics. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.553367137908936,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "(Du et al., 2022) 46.2 47.0 46.6 BART-Gen (Li et al., 2021) 42.1 47.3 44.5 PAIE (Ma et al., 2022) - - 49.5 FEAE (Wei et al., 2021) 53.1 42.7 47.4 TSAR (Xu et al",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and performance metrics. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.553367137908936,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "When ground-truth entities are available (such as in WikiEvents (Li et al., 2021)), we consider the candidate set to be the ground-truth entity set; otherwise, we use external toolkits 2 to recognize entities.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to define the candidate set for entity recognition in document-level event argument extraction, providing ground-truth entities for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'WikiEvents' as a dataset where ground-truth entities are available. It is used to define the candidate set for entity recognition in document-level event argument extraction.",
      "processing_time": 67.36293363571167,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "In this task, the major challenge is to model longrange dependencies between event triggers and arguments, as an event expression can span multiple sentences (Ebner et al., 2020; Liu et al., 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the challenge of modeling long-range dependencies in document-level event argument extraction.",
      "processing_time": 59.86677074432373,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 60.67517375946045,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 60.67517375946045,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 60.67517375946045,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "We conduct experiments using two document-level EAE benchmarks: RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event argument extraction experiments, focusing on conditional generation methods to improve extraction accuracy.",
        "WikiEvents": "Used for document-level event argument extraction experiments, focusing on conditional generation methods to improve extraction accuracy."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific benchmarks used for document-level event argument extraction experiments. These are clearly identified as RAMS and WikiEvents.",
      "processing_time": 69.90147805213928,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": ", participants of an event) is a crucial task for document-level event understanding (Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general task related to document-level event understanding.",
      "processing_time": 59.09944558143616,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We verify the effectiveness of our method on two benchmarks (Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'two benchmarks' but does not specify their names. The context does not provide enough information to identify specific datasets.",
      "processing_time": 60.01006102561951,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "For capturing the document context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event extraction.",
      "processing_time": 59.2115740776062,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "For capturing the document context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event extraction.",
      "processing_time": 59.2115740776062,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "For capturing the document context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event extraction.",
      "processing_time": 59.2115740776062,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "…his belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.092873334884644,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "For capturing the document context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methodologies and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 60.483851194381714,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Identifying event arguments (i.e., participants of an event) is a crucial task for document-level event understanding (Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the task of identifying event arguments for document-level event understanding.",
      "processing_time": 59.0470609664917,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "3) Generative methods, such as BART-Gen (Li et al., 2021), which proposes a sequence-to-sequence paradigm for argument extraction, and PAIE (Ma et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only generative methods and models. No dataset names are present in the citation span.",
      "processing_time": 59.85329794883728,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "3) Generative methods, such as BART-Gen (Li et al., 2021), which proposes a sequence-to-sequence paradigm for argument extraction, and PAIE (Ma et al., 2022), which employs a set generation formulation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions generative methods for argument extraction but does not reference any specific datasets. The cited papers are about methods, not datasets.",
      "processing_time": 59.799254417419434,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "3) Generative methods, such as BART-Gen (Li et al., 2021), which proposes a sequence-to-sequence paradigm for argument extraction, and PAIE (Ma et al., 2022), which employs a set generation formulation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions generative methods for argument extraction but does not reference any specific datasets. The cited papers are about methods, not datasets.",
      "processing_time": 59.799254417419434,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": ", 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing document-level inductive bias and implicit event argument extraction.",
      "processing_time": 59.79547452926636,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "4) Methods using extra supervisions, for example, FEAE (Wei et al., 2021), which adopts frame-related knowledge, and TSAR (Xu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 59.858017444610596,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "4) Methods using extra supervisions, for example, FEAE (Wei et al., 2021), which adopts frame-related knowledge, and TSAR (Xu et al., 2022), which utilizes abstract meaning representation (AMR) resources.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions methods and resources but does not specify any datasets. The cited papers' titles suggest the use of frame-related knowledge and AMR resources, but these are not datasets.",
      "processing_time": 61.30423450469971,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "4) Methods using extra supervisions, for example, FEAE (Wei et al., 2021), which adopts frame-related knowledge, and TSAR (Xu et al., 2022), which utilizes abstract meaning representation (AMR) resources.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions methods and resources but does not specify any datasets. The cited papers' titles suggest the use of frame-related knowledge and AMR resources, but these are not datasets.",
      "processing_time": 61.30423450469971,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248496614
    },
    {
      "context_text": ", 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 60.109922885894775,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and research works. No verifiable resources are identified.",
      "processing_time": 59.52403903007507,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "…belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.90097784996033,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "…belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.90097784996033,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.90097784996033,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247417818
    },
    {
      "context_text": "…belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.90097784996033,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "…belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.90097784996033,
      "citing_paper_id": "259370721",
      "cited_paper_id": 252391326
    },
    {
      "context_text": ", 2021), which proposes a sequence-to-sequence paradigm for argument extraction, and PAIE (Ma et al., 2022), which employs a set generation formulation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions PAIE, which is a method for event argument extraction, not a dataset. No datasets are explicitly mentioned.",
      "processing_time": 59.40793442726135,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is performed by ﬁrst…",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The context is focused on comparing performance metrics of various methods, not on the use of datasets.",
      "processing_time": 60.842660903930664,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b;…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 59.401601791381836,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Currently, it still remains an open problem for effectively capturing such dependencies (Liu et al., 2021, 2022c).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only that capturing certain dependencies remains an open problem. No verifiable resources are named.",
      "processing_time": 59.61963868141174,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247417818
    },
    {
      "context_text": "Currently, it still remains an open problem for effectively capturing such dependencies (Liu et al., 2021, 2022c).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only that capturing certain dependencies remains an open problem. No verifiable resources are named.",
      "processing_time": 59.61963868141174,
      "citing_paper_id": "259370721",
      "cited_paper_id": 252391326
    },
    {
      "context_text": ", 2021), which adopts frame-related knowledge, and TSAR (Xu et al., 2022), which utilizes abstract meaning representation (AMR) resources.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions TSAR, which is a method or tool, not a dataset. No specific datasets are mentioned in the citation context.",
      "processing_time": 59.94384741783142,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248496614
    },
    {
      "context_text": ", 2021), which form the task as a document-based question-answering problem, and MemNet (Du et al., 2022), which uses a memory to store global event information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MemNet, which is a method, not a dataset. No specific datasets are mentioned in the citation context.",
      "processing_time": 59.533092737197876,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "…capturing the document context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 59.529391050338745,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "In this case, we do not utilize the broad definition of entity because an event argument is defined to be a noun entity (Walker and Consortium, 2005; Ahn, 2006).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to definitions and concepts.",
      "processing_time": 57.82893967628479,
      "citing_paper_id": "259370721",
      "cited_paper_id": null
    },
    {
      "context_text": "End-to-End Neural IE models With neural networks, a few end-to-end models have been proposed that perform multiple IE tasks jointly (Miwa and Bansal, 2016; Luan et al., 2018; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 59.73736572265625,
      "citing_paper_id": "218470122",
      "cited_paper_id": 2476229
    },
    {
      "context_text": "End-to-End Neural IE models With neural networks, a few end-to-end models have been proposed that perform multiple IE tasks jointly (Miwa and Bansal, 2016; Luan et al., 2018; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 59.73736572265625,
      "citing_paper_id": "218470122",
      "cited_paper_id": 52118895
    },
    {
      "context_text": "End-to-End Neural IE models With neural networks, a few end-to-end models have been proposed that perform multiple IE tasks jointly (Miwa and Bansal, 2016; Luan et al., 2018; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 59.73736572265625,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "All our models were implemented in AllenNLP library(Gardner et al., 2017).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the implementation of models using AllenNLP, which is a library, not a dataset. No specific datasets are mentioned.",
      "processing_time": 59.57631778717041,
      "citing_paper_id": "218470122",
      "cited_paper_id": 3994096
    },
    {
      "context_text": ", 2019, 2017), and unsupervised detection of entities and their coreference information (Tsai et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods or approaches. No verifiable resources are identified.",
      "processing_time": 59.10067176818848,
      "citing_paper_id": "218470122",
      "cited_paper_id": 4129183
    },
    {
      "context_text": "These types of extractions include citation analysis (Jurgens et al., 2018; Cohan et al., 2019), identifying entities and relations (Augenstein et al., 2017; Luan et al., 2019, 2017), and unsupervised detection of entities and their coreference information (Tsai et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only types of extractions and methods. No dataset names are present in the text.",
      "processing_time": 59.458940505981445,
      "citing_paper_id": "218470122",
      "cited_paper_id": 4129183
    },
    {
      "context_text": "These types of extractions include citation analysis (Jurgens et al., 2018; Cohan et al., 2019), identifying entities and relations (Augenstein et al., 2017; Luan et al., 2019, 2017), and unsupervised detection of entities and their coreference information (Tsai et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only types of extractions and methods. No dataset names are present in the text.",
      "processing_time": 59.458940505981445,
      "citing_paper_id": "218470122",
      "cited_paper_id": 10822819
    },
    {
      "context_text": "These types of extractions include citation analysis (Jurgens et al., 2018; Cohan et al., 2019), identifying entities and relations (Augenstein et al., 2017; Luan et al., 2019, 2017), and unsupervised detection of entities and their coreference information (Tsai et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only types of extractions and methods. No dataset names are present in the text.",
      "processing_time": 59.458940505981445,
      "citing_paper_id": "218470122",
      "cited_paper_id": 102352698
    },
    {
      "context_text": "…first token embedding ej1 , last token embedding ejN and attention weighted average of all embeddings in the mention span ∑N k=1 αjkejk , where ejk is the embedding of word wjk and αjk are scalars computed by passing the token embedding through an additive attention layer (Bahdanau et al., 2015).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for computing embeddings using attention mechanisms.",
      "processing_time": 57.823704957962036,
      "citing_paper_id": "218470122",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "The mention embedding is the concatenation of first token embedding ej1 , last token embedding ejN and attention weighted average of all embeddings in the mention span ∑N k=1 αjkejk , where ejk is the embedding of word wjk and αjk are scalars computed by passing the token embedding through an additive attention layer (Bahdanau et al., 2015).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for computing mention embeddings using attention mechanisms.",
      "processing_time": 58.05300974845886,
      "citing_paper_id": "218470122",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "…documents (e.g Rahman et al. (2016)), 2) TAC KBP relations are usually sentence-level binary relations between a query entity and an attribute (e.g Angeli et al. (2015)), while our relations are 4-ary, span the whole document, and can’t be split into multiple binary relations as discussed in…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses the nature of relations in TAC KBP and contrasts them with the relations in the current work, but does not cite any datasets.",
      "processing_time": 61.96370983123779,
      "citing_paper_id": "218470122",
      "cited_paper_id": 18991323
    },
    {
      "context_text": "We generate a coreference score matrix for all pairs and perform agglomerative hierarchical clustering (Ward, 1963) on top of it to get actual clusters.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for hierarchical clustering.",
      "processing_time": 56.87781596183777,
      "citing_paper_id": "218470122",
      "cited_paper_id": 32863022
    },
    {
      "context_text": "g Rahman et al. (2016)), 2) TAC KBP relations are usually sentence-level binary relations between a query entity and an attribute (e.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to TAC KBP relations which are not considered a dataset.",
      "processing_time": 59.24438142776489,
      "citing_paper_id": "218470122",
      "cited_paper_id": 44144625
    },
    {
      "context_text": "…more interesting as it requires to perform entity extraction, coreference resolution, saliency detection in addition to the relation extraction.2\nGeneral IE Most work in general domain IE focus on sentence-level information extraction (Stanovsky et al., 2018; Qin et al., 2018; Jie and Lu, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts and methods in information extraction.",
      "processing_time": 58.23617386817932,
      "citing_paper_id": "218470122",
      "cited_paper_id": 44144625
    },
    {
      "context_text": "…more interesting as it requires to perform entity extraction, coreference resolution, saliency detection in addition to the relation extraction.2\nGeneral IE Most work in general domain IE focus on sentence-level information extraction (Stanovsky et al., 2018; Qin et al., 2018; Jie and Lu, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts and methods in information extraction.",
      "processing_time": 58.23617386817932,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202718944
    },
    {
      "context_text": "IE focus on sentence-level information extraction (Stanovsky et al., 2018; Qin et al., 2018; Jie and Lu, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other research works. The context is about sentence-level information extraction, but no datasets are explicitly named.",
      "processing_time": 60.49018883705139,
      "citing_paper_id": "218470122",
      "cited_paper_id": 44144625
    },
    {
      "context_text": "IE focus on sentence-level information extraction (Stanovsky et al., 2018; Qin et al., 2018; Jie and Lu, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other research works. The context is about sentence-level information extraction, but no datasets are explicitly named.",
      "processing_time": 60.49018883705139,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202718944
    },
    {
      "context_text": ", information extraction from abstracts of scientific articles as in SCIERC (Luan et al., 2018)), or only extracting",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SCIERC"
      ],
      "dataset_descriptions": {
        "SCIERC": "Used for information extraction from abstracts of scientific articles, focusing on entity recognition, relation extraction, and coreference resolution to construct scientific knowledge graphs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'SCIERC' which is a specific dataset used for information extraction from scientific articles. The dataset is relevant to the topic of document-level event extraction.",
      "processing_time": 67.93664479255676,
      "citing_paper_id": "218470122",
      "cited_paper_id": 52118895
    },
    {
      "context_text": "A recent example is SCIERC (Luan et al., 2018), a dataset of 500 richly annotated scientific abstracts containing mention spans and their types, coreference information between mentions, and binary relations annotations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SCIERC"
      ],
      "dataset_descriptions": {
        "SCIERC": "Used to train and evaluate models on identifying entities, relations, and coreference in scientific abstracts, enhancing scientific knowledge graph construction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly identifies SCIERC as a dataset with specific characteristics relevant to document-level event extraction.",
      "processing_time": 64.59542632102966,
      "citing_paper_id": "218470122",
      "cited_paper_id": 52118895
    },
    {
      "context_text": "…development of full IE models and datasets for short paragraphs (e.g., information extraction from abstracts of scientific articles as in SCIERC (Luan et al., 2018)), or only extracting\n∗Work done while at AI2\nmentions ( Dataset , Metric , Task , Method ), coreferences (indicated by arrows),…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SCIERC"
      ],
      "dataset_descriptions": {
        "SCIERC": "Used for information extraction from scientific article abstracts, focusing on identifying entities, relations, and coreferences to construct scientific knowledge graphs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'SCIERC' as a dataset used for information extraction from scientific article abstracts. It is a specific, verifiable dataset with a clear reference to a published work.",
      "processing_time": 68.1153712272644,
      "citing_paper_id": "218470122",
      "cited_paper_id": 52118895
    },
    {
      "context_text": "To that end, we follow (Jia et al., 2019) methodology.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodology from a cited paper.",
      "processing_time": 57.81264543533325,
      "citing_paper_id": "218470122",
      "cited_paper_id": 102353905
    },
    {
      "context_text": "Recent work by Hou et al. (2019); Jia et al. (2019) tried to rectify this by using distant supervision annotations to build datasets for document-level relation extraction.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'datasets for document-level relation extraction' but does not specify any named datasets. The cited papers do not provide additional specific dataset names.",
      "processing_time": 60.466811418533325,
      "citing_paper_id": "218470122",
      "cited_paper_id": 102353905
    },
    {
      "context_text": "Recent work by Hou et al. (2019); Jia et al. (2019) tried to rectify this by using distant supervision annotations to build datasets for document-level relation extraction.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'datasets for document-level relation extraction' but does not specify any named datasets. The cited papers do not provide additional specific dataset names.",
      "processing_time": 60.466811418533325,
      "citing_paper_id": "218470122",
      "cited_paper_id": 195345077
    },
    {
      "context_text": "…), coreferences (indicated by arrows), salient entities (bold), and N -ary relation (SQuaD, Machine Comprehension, BiDAF (ensemble), EM/F1) that can only be extracted by aggregating information across sections.\nrelations (given ground truth entities) on long documents (e.g. Jia et al. (2019)).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'Jia et al. (2019)' but does not specify a dataset name. The mention of 'long documents' suggests a document-level dataset, but no specific dataset is named.",
      "processing_time": 62.363664627075195,
      "citing_paper_id": "218470122",
      "cited_paper_id": 102353905
    },
    {
      "context_text": "Jia et al. (2019)).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not provide any specific dataset names or details about the datasets used. The context is too limited to extract any verifiable resources.",
      "processing_time": 59.12258958816528,
      "citing_paper_id": "218470122",
      "cited_paper_id": 102353905
    },
    {
      "context_text": "Recently, however, Yao et al. (2019) introduced DocRED, a dataset of cross-sentence relation extractions on Wikipedia paragraphs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate models for cross-sentence relation extraction on Wikipedia paragraphs, focusing on document-level understanding and complex relational structures."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' as a dataset introduced for document-level relation extraction, which is directly relevant to the research topic.",
      "processing_time": 65.09638953208923,
      "citing_paper_id": "218470122",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "We compare our model with DYGIE++ (Wadden et al., 2019) and DocTAET (Hou et al., 2019) on subtasks of our SCIREX dataset and on the SCIERC dataset wherever they apply.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SCIREX",
        "SCIERC"
      ],
      "dataset_descriptions": {
        "SCIREX": "Used to compare model performance on document-level event extraction subtasks, focusing on scientific document processing and evaluation metrics.",
        "SCIERC": "Used to evaluate and compare model performance on document-level event extraction, specifically for scientific document tasks and entity relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'SCIREX' and 'SCIERC' datasets, which are specific and relevant to document-level event extraction. These datasets are used for comparing model performance.",
      "processing_time": 71.58992409706116,
      "citing_paper_id": "218470122",
      "cited_paper_id": 195345077
    },
    {
      "context_text": "We compare our model with DYGIE++ (Wadden et al., 2019) and DocTAET (Hou et al., 2019) on subtasks of our SCIREX dataset and on the SCIERC dataset wherever they apply.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SCIREX",
        "SCIERC"
      ],
      "dataset_descriptions": {
        "SCIREX": "Used to compare model performance on document-level event extraction subtasks, focusing on scientific document processing and evaluation metrics.",
        "SCIERC": "Used to evaluate and compare model performance on document-level event extraction, specifically for scientific document tasks and entity relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'SCIREX' and 'SCIERC' datasets, which are specific and relevant to document-level event extraction. These datasets are used for comparing model performance.",
      "processing_time": 71.58992409706116,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Table 3 shows the result on this subtask, and it shows that our relation model gives comparable performance (in terms of positive class F1 score) to that of DocTAET.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a reference to a 'relation model' and a comparison to 'DocTAET'. No clear, verifiable dataset is identified.",
      "processing_time": 61.05282163619995,
      "citing_paper_id": "218470122",
      "cited_paper_id": 195345077
    },
    {
      "context_text": ", 2019) and DocTAET (Hou et al., 2019) on subtasks of our SCIREX dataset and on the SCIERC dataset wherever they apply.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SCIREX",
        "SCIERC"
      ],
      "dataset_descriptions": {
        "SCIREX": "Used to evaluate document-level event extraction, focusing on scientific documents and comparing performance across different subtasks.",
        "SCIERC": "Used to evaluate document-level event extraction, focusing on scientific documents and comparing performance across different subtasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'SCIREX' and 'SCIERC' datasets, which are specific and relevant to document-level event extraction. The citation intent is to compare performance on these datasets.",
      "processing_time": 71.26140999794006,
      "citing_paper_id": "218470122",
      "cited_paper_id": 195345077
    },
    {
      "context_text": "DocTAET (Hou et al., 2019) is a documentlevel relation classification model that is given a document and a relation tuple to classify if it is expressed in the document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions DocTAET as a model, not a dataset. No specific dataset is mentioned in the context.",
      "processing_time": 58.656495809555054,
      "citing_paper_id": "218470122",
      "cited_paper_id": 195345077
    },
    {
      "context_text": "Recent work by Hou et al. (2019); Jia et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works. There is no clear indication of a reusable resource or dataset being used.",
      "processing_time": 59.63207650184631,
      "citing_paper_id": "218470122",
      "cited_paper_id": 195345077
    },
    {
      "context_text": "DYGIE++ (Wadden et al., 2019) is an end-to-",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DYGIE++).",
      "processing_time": 57.91858148574829,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "We compare our model with DYGIE++ (Wadden et al., 2019) and DocTAET (Hou et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (DYGIE++, DocTAET). No verifiable resources are identified.",
      "processing_time": 59.14587116241455,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "The closest to our work is DYGIE++ (Wadden et al., 2019), which does named entity recognition, binary relation extraction, and event extraction in one model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions DYGIE++ but does not refer to it as a dataset. It is described as a model or method for entity, relation, and event extraction.",
      "processing_time": 60.5330970287323,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "DYGIE++ (Wadden et al., 2019) is an end-toend model for entity and binary relation extraction (check Section 2 for details).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DYGIE++, which is a model, not a dataset. No specific dataset is mentioned or used in the given citation.",
      "processing_time": 59.27154994010925,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "For the BERT coreference model, we use SciBERT-base embeddings with two mentions encoded as [CLS] mention 1 [SEP] mention 2 [SEP].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of SciBERT embeddings for a coreference model. SciBERT is a model, not a dataset.",
      "processing_time": 60.04446887969971,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "The base document representation of our model is formed by SciBERT-base (Beltagy et al., 2019) and BiLSTM with 128-d hidden state.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. SciBERT is a pretrained language model, not a dataset.",
      "processing_time": 59.083473920822144,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "We use pretrained contextualized token encodings using SciBERT (Beltagy et al., 2019) over each section separately to get embeddings for tokens in that section.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of SciBERT for token encodings but does not refer to any specific dataset. SciBERT is a model, not a dataset.",
      "processing_time": 59.9168016910553,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "It concatenates the “surface forms” of two spans mi and mj , embed them using SciBERT, then use a linear classification layer on top of [CLS] embedding to compute the pairwise coreference score cij .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method using SciBERT, which is a model, not a dataset.",
      "processing_time": 59.4946825504303,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "5 To allow document-level information flow, we concatenate\n4with the exception of coreference resolution 5If the section is bigger than 512 tokens (SciBERT limit), it is broken into 512 token subsections, and each subsection is encoded separately.\nthe section-level token embeddings and add a BiLSTM on top of them.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (SciBERT) and a general approach to handling document-level information. No verifiable resources are identified.",
      "processing_time": 60.124560832977295,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202558505
    },
    {
      "context_text": ", 2018; Jie and Lu, 2019). Recently, however, Yao et al. (2019) introduced DocRED, a dataset of cross-sentence relation extractions on Wikipedia paragraphs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for cross-sentence relation extraction on Wikipedia paragraphs, focusing on developing methods to handle complex document-level relations."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is mentioned as a specific dataset introduced for cross-sentence relation extraction on Wikipedia paragraphs.",
      "processing_time": 63.170602321624756,
      "citing_paper_id": "218470122",
      "cited_paper_id": 202718944
    },
    {
      "context_text": "Both (Lai et al., 2020) and (Deng et al., 2020) extend upon the prototype network model (Snell et al., 2017) for classiﬁcation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers are about extending a model for classification and few-shot event detection.",
      "processing_time": 59.95902156829834,
      "citing_paper_id": "233219850",
      "cited_paper_id": 309759
    },
    {
      "context_text": "Both (Lai et al., 2020) and (Deng et al., 2020) extend upon the prototype network model (Snell et al., 2017) for classiﬁcation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers are about extending a model for classification and few-shot event detection.",
      "processing_time": 59.95902156829834,
      "citing_paper_id": "233219850",
      "cited_paper_id": 204915992
    },
    {
      "context_text": "In addition to BERT-QA, we also replace our T AP K EY trigger extraction model with a Prototype Network(Snell et al., 2017) 14 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is about replacing a trigger extraction model with a Prototype Network, which is a method.",
      "processing_time": 60.318883657455444,
      "citing_paper_id": "233219850",
      "cited_paper_id": 309759
    },
    {
      "context_text": "In addition to BERT-QA, we also replace our T AP K EY trigger extraction model with a Prototype Network(Snell et al., 2017) 14 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is about replacing a trigger extraction model with a Prototype Network, which is a method.",
      "processing_time": 60.318883657455444,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "For Coref F1, the model is given full credit if the extracted argument is coreferential with the gold-standard argument as used in (Ji and Grishman, 2008).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method for evaluating coreference resolution. No dataset names are present in the citation span.",
      "processing_time": 59.55358004570007,
      "citing_paper_id": "233219850",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Early work on event extraction originally posed the task as document level role ﬁlling (Grishman and Sundheim, 1996) on a set of narrow scenarios Prosecutors say he drove the truck to Geary Lake in Kansas, that 4,000 pounds of ammonium nitrate laced with nitromethane were loaded into the truck…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It describes early work on event extraction and provides an example scenario, but no dataset names are given.",
      "processing_time": 60.30829858779907,
      "citing_paper_id": "233219850",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "An information seeking session (Mai, 2016) can be divided into 6 stages: task initiation, topic selection, pre-focus exploration, focus information, information collection and search closure (Kuhlthau, 1991).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only stages of an information seeking session. No verifiable resources are identified.",
      "processing_time": 58.79811120033264,
      "citing_paper_id": "233219850",
      "cited_paper_id": 14416802
    },
    {
      "context_text": "Since the baseline BERT-CRF model (Shi and Lin, 2019) cannot handle new labels directly, we exclude it from comparison.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (BERT-CRF) which is excluded from comparison. No verifiable resources are discussed.",
      "processing_time": 59.85585427284241,
      "citing_paper_id": "233219850",
      "cited_paper_id": 131773936
    },
    {
      "context_text": ", 2020) and (Deng et al., 2020) extend upon the prototype network model (Snell et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (prototype network).",
      "processing_time": 57.45509719848633,
      "citing_paper_id": "233219850",
      "cited_paper_id": 204915992
    },
    {
      "context_text": "Our base model is an encoder-decoder language model (BART (Lewis et al., 2020), T5 (Raffel et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models (BART, T5) but does not reference any specific datasets. The context is about using these models, not datasets.",
      "processing_time": 59.61243987083435,
      "citing_paper_id": "233219850",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Compared to recent efforts (Du and Cardie, 2020; Feng et al., 2020; Chen et al., 2020) that retarget question answering (QA) models for event extraction, our generationbased model can easily handle the case of missing arguments and multiple arguments in the same role without the need of tuning thresholds and can extract all arguments in a single pass.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only compares different approaches to event extraction. No verifiable resources are identified.",
      "processing_time": 59.050758361816406,
      "citing_paper_id": "233219850",
      "cited_paper_id": 208547716
    },
    {
      "context_text": "Compared to recent efforts (Du and Cardie, 2020; Feng et al., 2020; Chen et al., 2020) that retarget question answering (QA) models for event extraction, our generationbased model can easily handle the case of missing arguments and multiple arguments in the same role without the need of tuning thresholds and can extract all arguments in a single pass.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only compares different approaches to event extraction. No verifiable resources are identified.",
      "processing_time": 59.050758361816406,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Compared to recent efforts (Du and Cardie, 2020; Feng et al., 2020; Chen et al., 2020) that retarget question answering (QA) models for event extraction, our generationbased model can easily handle the case of missing arguments and multiple arguments in the same role without the need of tuning thresholds and can extract all arguments in a single pass.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only compares different approaches to event extraction. No verifiable resources are identified.",
      "processing_time": 59.050758361816406,
      "citing_paper_id": "233219850",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "Compared to recent efforts (Du and Cardie, 2020; Feng et al., 2020; Chen et al., 2020) that retarget question answering (QA) models for event extraction, our generation-based model can easily handle the case of missing arguments and multiple arguments in the same role without the need of tuning…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works and their methodologies. The context focuses on comparing approaches to event extraction using QA models.",
      "processing_time": 60.17943716049194,
      "citing_paper_id": "233219850",
      "cited_paper_id": 208547716
    },
    {
      "context_text": "Compared to recent efforts (Du and Cardie, 2020; Feng et al., 2020; Chen et al., 2020) that retarget question answering (QA) models for event extraction, our generation-based model can easily handle the case of missing arguments and multiple arguments in the same role without the need of tuning…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works and their methodologies. The context focuses on comparing approaches to event extraction using QA models.",
      "processing_time": 60.17943716049194,
      "citing_paper_id": "233219850",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "Recent work on zero-shot event extraction has posed the problem as question answering (Chen et al., 2020; Du and Cardie, 2020; Feng et al., 2020) with different ways of designing the questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 59.58840465545654,
      "citing_paper_id": "233219850",
      "cited_paper_id": 208547716
    },
    {
      "context_text": "Recent work on zero-shot event extraction has posed the problem as question answering (Chen et al., 2020; Du and Cardie, 2020; Feng et al., 2020) with different ways of designing the questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 59.58840465545654,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Recent work on zero-shot event extraction has posed the problem as question answering (Chen et al., 2020; Du and Cardie, 2020; Feng et al., 2020) with different ways of designing the questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 59.58840465545654,
      "citing_paper_id": "233219850",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "Inspired by (Shwartz et al., 2020), we use clariﬁcation statements to add back constraints without breaking the end-to-end property of the model.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context is about using clarification statements in a model, which is not a dataset.",
      "processing_time": 59.22055697441101,
      "citing_paper_id": "233219850",
      "cited_paper_id": 215745286
    },
    {
      "context_text": "ularly used BERT-CRF baseline (Shi and Lin, 2019) that performs trigger extraction on sentencelevel and BERT-QA (Du and Cardie, 2020) ran on sentence-level and document-level.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of BERT-CRF and BERT-QA for trigger extraction and question answering.",
      "processing_time": 61.14782190322876,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "The performance of BERT-QA is greatly limited by the trigger identiﬁcation step.",
      "catation_intent": "limitation",
      "resource_type": "limitation",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a limitation of BERT-QA in trigger identification.",
      "processing_time": 58.54944968223572,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "edu/rams (12)Note that our preprocessing procedure is slightly different from (Du and Cardie, 2020) as we kept pronouns as valid event triggers and arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a difference in preprocessing procedures.",
      "processing_time": 57.49260902404785,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Notably, one template per event type is given in the ontology, and does not require further human curation as opposed to the question designing process in question answering (QA) models (Du and Cardie, 2020; Feng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison between event extraction templates and question answering models. No verifiable resources are identified.",
      "processing_time": 59.568684339523315,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Notably, one template per event type is given in the ontology, and does not require further human curation as opposed to the question designing process in question answering (QA) models (Du and Cardie, 2020; Feng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison between event extraction templates and question answering models. No verifiable resources are identified.",
      "processing_time": 59.568684339523315,
      "citing_paper_id": "233219850",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "There have been a few datasets published speciﬁcally for implicit semantic role labeling, such as the SemEval 2010 Task 10 (Ruppenhofer et al., 2010), the Beyond NomBank dataset (Gerber and Chai, 2010) and ON5V (Moor et al., 2013).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SemEval 2010 Task 10",
        "Beyond NomBank",
        "ON5V"
      ],
      "dataset_descriptions": {
        "SemEval 2010 Task 10": "Used for implicit semantic role labeling, focusing on identifying roles in sentences where the predicate is not explicitly marked.",
        "Beyond NomBank": "Applied to extend semantic role labeling beyond traditional verb-based predicates, including nominal and adjectival predicates.",
        "ON5V": "Utilized for verb valency annotation, specifically designed to capture the argument structure of verbs in German."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets for implicit semantic role labeling, which are relevant to document-level event extraction.",
      "processing_time": 72.52107310295105,
      "citing_paper_id": "233219850",
      "cited_paper_id": 261226458
    },
    {
      "context_text": "There have been a few datasets published specifically for implicit semantic role labeling, such as the SemEval 2010 Task 10 (Ruppenhofer et al., 2010), the Beyond NomBank dataset (Gerber and Chai, 2010) and ON5V (Moor et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SemEval 2010 Task 10",
        "Beyond NomBank",
        "ON5V"
      ],
      "dataset_descriptions": {
        "SemEval 2010 Task 10": "Used for implicit semantic role labeling, focusing on identifying roles in sentences where the predicate is not explicitly mentioned.",
        "Beyond NomBank": "Applied to extend nominal semantic role labeling beyond the NomBank inventory, enhancing coverage of implicit roles.",
        "ON5V": "Utilized for verb valency annotation, specifically addressing overtness and valency in verb argument structures."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets for implicit semantic role labeling, which are relevant to document-level event extraction.",
      "processing_time": 72.5167920589447,
      "citing_paper_id": "233219850",
      "cited_paper_id": 261226458
    },
    {
      "context_text": "We trained all models with the AdamW optimizer (Loshchilov and Hutter, 2018).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the AdamW optimizer, which is a method, not a dataset. No datasets are mentioned in the context.",
      "processing_time": 58.947914600372314,
      "citing_paper_id": "252819226",
      "cited_paper_id": 3312944
    },
    {
      "context_text": "For strictly consistent comparison, we involve the following strong baselines: • BERT-CRF (Loshchilov and Hutter, 2018), which combines BERT with Condition Random Field (Lafferty et al., 2001), is the most popular method in tagging-based event extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BERT-CRF) used for event extraction. No datasets are referenced for training or evaluation.",
      "processing_time": 59.90471601486206,
      "citing_paper_id": "252819226",
      "cited_paper_id": 3312944
    },
    {
      "context_text": "Li et al. (2013, 2015) employ various hand-designed features to extract event; (Nguyen and Grishman, 2015; Nguyen et al., 2016; Chen et al., 2015; Liu et al., 2017, 2018) use neural based models such as recurrent neural networks (Zaremba et al., 2014) and convolutional neural network (Le-Cun et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.67046546936035,
      "citing_paper_id": "252819226",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Li et al. (2013, 2015) employ various hand-designed features to extract event; (Nguyen and Grishman, 2015; Nguyen et al., 2016; Chen et al., 2015; Liu et al., 2017, 2018) use neural based models such as recurrent neural networks (Zaremba et al., 2014) and convolutional neural network (Le-Cun et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.67046546936035,
      "citing_paper_id": "252819226",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "Li et al. (2013, 2015) employ various hand-designed features to extract event; (Nguyen and Grishman, 2015; Nguyen et al., 2016; Chen et al., 2015; Liu et al., 2017, 2018) use neural based models such as recurrent neural networks (Zaremba et al., 2014) and convolutional neural network (Le-Cun et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.67046546936035,
      "citing_paper_id": "252819226",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Li et al. (2013, 2015) employ various hand-designed features to extract event; (Nguyen and Grishman, 2015; Nguyen et al., 2016; Chen et al., 2015; Liu et al., 2017, 2018) use neural based models such as recurrent neural networks (Zaremba et al., 2014) and convolutional neural network (Le-Cun et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 59.67046546936035,
      "citing_paper_id": "252819226",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "Analogy to multi-head attention (Vaswani et al., 2017), we propose a role-intera C tive mu L ti-event head attent I on netw O rk (CLIO) for DEE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (multi-head attention) and a proposed network (CLIO).",
      "processing_time": 59.24545979499817,
      "citing_paper_id": "252819226",
      "cited_paper_id": 13756489
    },
    {
      "context_text": ", 2014) and convolutional neural network (LeCun et al., 1998) to extract event.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (convolutional neural network).",
      "processing_time": 57.720022439956665,
      "citing_paper_id": "252819226",
      "cited_paper_id": 14542261
    },
    {
      "context_text": "Cognitive scientists believe that humans remember and understand reality primarily in terms of events (Shipley and Zacks, 2008).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general belief about human cognition. No verifiable resources are identified.",
      "processing_time": 58.742836713790894,
      "citing_paper_id": "252819226",
      "cited_paper_id": 140925826
    },
    {
      "context_text": "With the recent success of BERT (Devlin et al., 2019), pretrained language models have also been used for SEE (Wang et al., 2019b,c; Yang et al., 2019; Wadden et al., 2019; Tong et al., 2020; Wang et al., 2021; Lu et al., 2021; Liu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of pretrained language models for SEE (Sentence-level Event Extraction) but does not specify any datasets. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 61.27402997016907,
      "citing_paper_id": "252819226",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "With the recent success of BERT (Devlin et al., 2019), pretrained language models have also been used for SEE (Wang et al., 2019b,c; Yang et al., 2019; Wadden et al., 2019; Tong et al., 2020; Wang et al., 2021; Lu et al., 2021; Liu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of pretrained language models for SEE (Sentence-level Event Extraction) but does not specify any datasets. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 61.27402997016907,
      "citing_paper_id": "252819226",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "We apply an approach, proposed by (Hoffmann et al., 2022) based on InfoNCE, to include multiple positives.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method based on InfoNCE. The context focuses on the approach and its application, not on a particular dataset.",
      "processing_time": 60.64287567138672,
      "citing_paper_id": "252819226",
      "cited_paper_id": 245811890
    },
    {
      "context_text": "Obviously, The synonym replacement based on WordNet cannot avoid introducing some words that do not ﬁt the context (e.g “unify” and “DoS”), while the BERT-based word replacement can consider the context better.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods (WordNet and BERT-based word replacement).",
      "processing_time": 58.37080001831055,
      "citing_paper_id": "255522592",
      "cited_paper_id": 1671874
    },
    {
      "context_text": "Obviously, The synonym replacement based on WordNet cannot avoid introducing some words that do not ﬁt the context (e.g “unify” and “DoS”), while the BERT-based word replacement can consider the context better.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods (WordNet and BERT-based word replacement).",
      "processing_time": 58.37080001831055,
      "citing_paper_id": "255522592",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "We compare our proposed data augmentation method Ours (t5-small) with three baselines: (1) Synonym Replacement replaces adjunct tokens with one of their synonyms retrieved from WordNet (Miller, 1992) DA methods on both trigger extraction (F1) and argument extraction (F1).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WordNet"
      ],
      "dataset_descriptions": {
        "WordNet": "Used to retrieve synonyms for data augmentation in trigger and argument extraction tasks, enhancing model performance through synonym replacement."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions WordNet as a lexical database used for synonym replacement in data augmentation methods. No other datasets are explicitly named.",
      "processing_time": 64.50243306159973,
      "citing_paper_id": "255522592",
      "cited_paper_id": 1671874
    },
    {
      "context_text": "We compare our proposed data augmentation method Ours (t5-small) with three baselines: (1) Synonym Replacement replaces adjunct tokens with one of their synonyms retrieved from WordNet (Miller, 1992) DA methods on both trigger extraction (F1) and argument extraction (F1).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WordNet"
      ],
      "dataset_descriptions": {
        "WordNet": "Used to retrieve synonyms for data augmentation in trigger and argument extraction tasks, enhancing model performance through synonym replacement."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions WordNet as a lexical database used for synonym replacement in data augmentation methods. No other datasets are explicitly named.",
      "processing_time": 64.50243306159973,
      "citing_paper_id": "255522592",
      "cited_paper_id": 225041226
    },
    {
      "context_text": "training data by modifying existing examples (Sennrich et al., 2016; Şahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a generative process and sample from it (Anaby-Tavor et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to methods for generating training data.",
      "processing_time": 58.76123094558716,
      "citing_paper_id": "255522592",
      "cited_paper_id": 15600925
    },
    {
      "context_text": "We empirically evaluate our proposed data augmentation method for event extraction on the ACE2005 corpus 1 with the same train-dev-test split and preprocessing step as previous works (Zhang et al., 2019; Wadden et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE2005"
      ],
      "dataset_descriptions": {
        "ACE2005": "Used to evaluate a data augmentation method for event extraction, focusing on the performance improvement with the same train-dev-test split and preprocessing as prior studies."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the ACE2005 corpus for evaluating a data augmentation method for event extraction, which is directly relevant to the topic of document-level event extraction.",
      "processing_time": 67.9075436592102,
      "citing_paper_id": "255522592",
      "cited_paper_id": 135473179
    },
    {
      "context_text": "(1) BackTranslation (2) Synonym Replacement (3) BERT Figure 1: Visualization of three different data augmentation methods applied to a sentence containing a “Transport” event.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions data augmentation methods but does not specify any datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 58.997284173965454,
      "citing_paper_id": "255522592",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "(1) BackTranslation (2) Synonym Replacement (3) BERT Figure 1: Visualization of three different data augmentation methods applied to a sentence containing a “Transport” event.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions data augmentation methods but does not specify any datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 58.997284173965454,
      "citing_paper_id": "255522592",
      "cited_paper_id": 225041226
    },
    {
      "context_text": "The BERT-based method can only replace words and cannot change the syntax, so it cannot generate samples with a wide variety of expressions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a limitation of the BERT-based method. No verifiable resources are identified.",
      "processing_time": 59.43059182167053,
      "citing_paper_id": "255522592",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Synonym Replacement (Dai and Adel, 2020) and BERT (Yang et al., 2019) replace words in the sentence. training data by modifying existing examples (Sen-nrich et al., 2016; ¸Sahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a generative process and sample from it (Anaby-Tavor et al., 2020; Quteineh et al., 2020; Yang et al., 2020; Ye et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches for data augmentation. No clear, verifiable datasets are identified.",
      "processing_time": 59.42622637748718,
      "citing_paper_id": "255522592",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Synonym Replacement (Dai and Adel, 2020) and BERT (Yang et al., 2019) replace words in the sentence. training data by modifying existing examples (Sen-nrich et al., 2016; ¸Sahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a generative process and sample from it (Anaby-Tavor et al., 2020; Quteineh et al., 2020; Yang et al., 2020; Ye et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches for data augmentation. No clear, verifiable datasets are identified.",
      "processing_time": 59.42622637748718,
      "citing_paper_id": "255522592",
      "cited_paper_id": 225041226
    },
    {
      "context_text": "Previous attempts on DA for such tasks typically use heuristic rules such as synonym replacement (Dai and Adel, 2020; Cai et al., 2020) or context-based words substitution with BERT (Yang et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.655393838882446,
      "citing_paper_id": "255522592",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Previous attempts on DA for such tasks typically use heuristic rules such as synonym replacement (Dai and Adel, 2020; Cai et al., 2020) or context-based words substitution with BERT (Yang et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.655393838882446,
      "citing_paper_id": "255522592",
      "cited_paper_id": 225041226
    },
    {
      "context_text": "Synonym Replacement (Dai and Adel, 2020) and BERT (Yang et al., 2019) replace words in the sentence. training data by modifying existing examples (Sen-nrich et al., 2016; ¸Sahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models for data augmentation. No clear identifiers for datasets are present.",
      "processing_time": 59.22946500778198,
      "citing_paper_id": "255522592",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Synonym Replacement (Dai and Adel, 2020) and BERT (Yang et al., 2019) replace words in the sentence. training data by modifying existing examples (Sen-nrich et al., 2016; ¸Sahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models for data augmentation. No clear identifiers for datasets are present.",
      "processing_time": 59.22946500778198,
      "citing_paper_id": "255522592",
      "cited_paper_id": 225041226
    },
    {
      "context_text": "They develop two BERT-based QA models – one for event trigger detection and the other for argument extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their purposes. No verifiable resources are identified.",
      "processing_time": 58.633888959884644,
      "citing_paper_id": "255522592",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Then, we model DA for the EE task as a Mask-then-Fill process: we ﬁrst randomly masks out an adjunct sentence fragment and then inﬁlls a variable-length text span with a ﬁne-tuned inﬁlling model (T5) (Raffel et al., 2020).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (T5) which is excluded according to the rules.",
      "processing_time": 58.78493809700012,
      "citing_paper_id": "255522592",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "To train our inﬁlling model, we ﬁne-tune a pre-trained sequence-to-sequence model T5 (Raffel et al., 2020) on the Gigaword corpus (Graff et al., 2003), which is from similar domains as the event extraction dataset ACE2005 adopted by our work.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Gigaword corpus",
        "ACE2005"
      ],
      "dataset_descriptions": {
        "Gigaword corpus": "Used to fine-tune a pre-trained sequence-to-sequence model T5 for infilling tasks, focusing on domains similar to event extraction.",
        "ACE2005": "Referenced as a similar domain dataset for event extraction, used to contextualize the training data's relevance."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions the Gigaword corpus and the ACE2005 dataset. Gigaword is used for fine-tuning a pre-trained model, while ACE2005 is referenced as a similar domain dataset for event extraction.",
      "processing_time": 71.41271328926086,
      "citing_paper_id": "255522592",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "…existing examples (Sen-nrich et al., 2016; ¸Sahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a generative process and sample from it (Anaby-Tavor et al., 2020; Quteineh et al., 2020; Yang et al., 2020; Ye et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 60.3703830242157,
      "citing_paper_id": "255522592",
      "cited_paper_id": 212821571
    },
    {
      "context_text": "…existing examples (Sen-nrich et al., 2016; ¸Sahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a generative process and sample from it (Anaby-Tavor et al., 2020; Quteineh et al., 2020; Yang et al., 2020; Ye et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 60.3703830242157,
      "citing_paper_id": "255522592",
      "cited_paper_id": 226262334
    },
    {
      "context_text": "…existing examples (Sen-nrich et al., 2016; ¸Sahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a generative process and sample from it (Anaby-Tavor et al., 2020; Quteineh et al., 2020; Yang et al., 2020; Ye et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 60.3703830242157,
      "citing_paper_id": "255522592",
      "cited_paper_id": 267872583
    },
    {
      "context_text": ", 2016; Şahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a generative process and sample from it (Anaby-Tavor et al., 2020; Quteineh et al., 2020; Yang et al., 2020; Ye et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. No verifiable resources are identified.",
      "processing_time": 59.06545329093933,
      "citing_paper_id": "255522592",
      "cited_paper_id": 212821571
    },
    {
      "context_text": "Following the previous works (Du and Cardie, 2020; Lu et al., 2021) on event extraction, we adopt the same evaluation criteria deﬁned in Li et al. (2013): (i) An event trigger is correctly identiﬁed and classiﬁed ( Trig-ID+C ) if its offsets match a gold trigger and its event type is also correct.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation criteria and methods.",
      "processing_time": 56.785454988479614,
      "citing_paper_id": "255522592",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "In recent years, deep learning methods have emerged as one of the most prominent approaches for this task (Nguyen and Nguyen, 2019; Lin et al., 2020; Du and Cardie, 2020; Paolini et al., 2021; Lu et al., 2021; Lou et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to deep learning methods and related research works.",
      "processing_time": 58.557281255722046,
      "citing_paper_id": "255522592",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "In recent years, deep learning methods have emerged as one of the most prominent approaches for this task (Nguyen and Nguyen, 2019; Lin et al., 2020; Du and Cardie, 2020; Paolini et al., 2021; Lu et al., 2021; Lou et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to deep learning methods and related research works.",
      "processing_time": 58.557281255722046,
      "citing_paper_id": "255522592",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "In recent years, deep learning methods have emerged as one of the most prominent approaches for this task (Nguyen and Nguyen, 2019; Lin et al., 2020; Du and Cardie, 2020; Paolini et al., 2021; Lu et al., 2021; Lou et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to deep learning methods and related research works.",
      "processing_time": 58.557281255722046,
      "citing_paper_id": "255522592",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "• EEQA (Du and Cardie, 2020) formulates the event extraction task as a question answering task.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 57.67936134338379,
      "citing_paper_id": "255522592",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "…(Yang et al., 2019) replace words in the sentence. training data by modifying existing examples (Sen-nrich et al., 2016; ¸Sahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a generative process and sample from it (Anaby-Tavor…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methods for data augmentation, which are not datasets themselves.",
      "processing_time": 59.584975242614746,
      "citing_paper_id": "255522592",
      "cited_paper_id": 225041226
    },
    {
      "context_text": "…(Yang et al., 2019) replace words in the sentence. training data by modifying existing examples (Sen-nrich et al., 2016; ¸Sahin and Steedman, 2018; Dai and Adel, 2020; Wei and Zou, 2019), and (2) the second is to generate new data by estimating a generative process and sample from it…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methods for data augmentation, which are not datasets themselves.",
      "processing_time": 59.42157053947449,
      "citing_paper_id": "255522592",
      "cited_paper_id": 225041226
    },
    {
      "context_text": "The Synonym Replacement and BackTranslation methods lack semantic diversity, because they can only produce samples with similar semantics.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (Synonym Replacement and BackTranslation).",
      "processing_time": 58.37578248977661,
      "citing_paper_id": "255522592",
      "cited_paper_id": 225041226
    },
    {
      "context_text": "However, recent studies (Ding et al., 2020; Yang et al., 2020; Ye et al., 2022) ﬁnd that such methods provide limited data diversity.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that certain methods provide limited data diversity. No verifiable resources are identified.",
      "processing_time": 59.63708472251892,
      "citing_paper_id": "255522592",
      "cited_paper_id": 267872583
    },
    {
      "context_text": "However, recent studies (Ding et al., 2020; Yang et al., 2020; Ye et al., 2022) ﬁnd that such methods provide limited data diversity.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that certain methods provide limited data diversity. No verifiable resources are identified.",
      "processing_time": 59.63708472251892,
      "citing_paper_id": "255522592",
      "cited_paper_id": null
    },
    {
      "context_text": "However, recent studies (Ding et al., 2020; Yang et al., 2020; Ye et al., 2022) find that such methods provide limited data diversity.",
      "catation_intent": "findings",
      "resource_type": "limitation",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general limitation of methods providing limited data diversity.",
      "processing_time": 58.57518696784973,
      "citing_paper_id": "255522592",
      "cited_paper_id": null
    },
    {
      "context_text": "However, most of the existing relation extraction methods [1 – 3] focus merely on intra-sentential relations, which is apparently insufficient in capturing inter-sentential ones.",
      "catation_intent": "research work",
      "resource_type": "limitation",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a limitation of existing methods in relation extraction.",
      "processing_time": 58.80662655830383,
      "citing_paper_id": "214673189",
      "cited_paper_id": 3598397
    },
    {
      "context_text": "To alleviate overfitting, we used dropout [27] to randomly drop units and their connections and the dropout rates of the embedding layer and the bottom Bi-LSTM output layer are set as 0.2 and 0.5, respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions dropout as a method to prevent overfitting, but does not mention any specific datasets.",
      "processing_time": 58.80233359336853,
      "citing_paper_id": "214673189",
      "cited_paper_id": 6844431
    },
    {
      "context_text": "By contrast, some works [15, 16] focus on integrating interactions between relations and thus employ sequence labeling methods to address relation extraction problems in which entity offsets are necessary to specify re-lated entity pairs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the integration of interactions between relations and the use of sequence labeling methods.",
      "processing_time": 60.87162399291992,
      "citing_paper_id": "214673189",
      "cited_paper_id": 12101726
    },
    {
      "context_text": "Word embedding maps words into a low-dimensional space to capture semantic information among words [20] and it has been widely used to process the input of the neural networks in NLP tasks [13].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general usage of word embeddings in NLP tasks.",
      "processing_time": 58.891096115112305,
      "citing_paper_id": "214673189",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "3 The architecture of the Bio-seq model entity position features [13] play a significant role in relation extraction tasks, we design an entity detector (EnDet) to emphasize the sentences that contain source and target entities.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context focuses on the architecture and entity position features in relation extraction tasks.",
      "processing_time": 60.56439781188965,
      "citing_paper_id": "214673189",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Hence, the methods which take entity offsets as position features [13] in the general domain are not appropriate for biomedical document-level relation extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method and its applicability to a domain. No verifiable resources are identified.",
      "processing_time": 60.16291832923889,
      "citing_paper_id": "214673189",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "We used the Pytorch library [26] to implement our proposed method.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using Pytorch, which is a software library, not a dataset. No datasets are mentioned.",
      "processing_time": 59.0622832775116,
      "citing_paper_id": "214673189",
      "cited_paper_id": 40027675
    },
    {
      "context_text": "Moreover, prototypical networks (ProtoNet) (Snell et al., 2017) have been proven to be very powerful for solving few-shot problems by representing each category as a prototype in both Vision (Pan et al., 2019; Dong and Xing, 2018) and NLP (Sun et al., 2019; Gao et al., 2019) domains.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers also do not provide additional context about datasets.",
      "processing_time": 59.835432291030884,
      "citing_paper_id": "252090194",
      "cited_paper_id": 309759
    },
    {
      "context_text": "Moreover, prototypical networks (ProtoNet) (Snell et al., 2017) have been proven to be very powerful for solving few-shot problems by representing each category as a prototype in both Vision (Pan et al., 2019; Dong and Xing, 2018) and NLP (Sun et al., 2019; Gao et al., 2019) domains.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers also do not provide additional context about datasets.",
      "processing_time": 59.835432291030884,
      "citing_paper_id": "252090194",
      "cited_paper_id": 131774949
    },
    {
      "context_text": "Moreover, prototypical networks (ProtoNet) (Snell et al., 2017) have been proven to be very powerful for solving few-shot problems by representing each category as a prototype in both Vision (Pan et al., 2019; Dong and Xing, 2018) and NLP (Sun et al., 2019; Gao et al., 2019) domains.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers also do not provide additional context about datasets.",
      "processing_time": 59.835432291030884,
      "citing_paper_id": "252090194",
      "cited_paper_id": 202771953
    },
    {
      "context_text": "In order to adapt to our few-shot setting, inspired by the successful applications of the prototypical network (ProtoNet) (Snell et al., 2017) for meta-learning, we assume there exists one prototypical representation for each argument type.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (ProtoNet) which is not a dataset.",
      "processing_time": 59.28480648994446,
      "citing_paper_id": "252090194",
      "cited_paper_id": 309759
    },
    {
      "context_text": "The ProtoNet approach (Snell et al., 2017) assumes there exists one prototypical representation for each argument class and learns a metric space where categorization is performed by labeling each query term with the value calculated from the distance between prototype representations that are…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (ProtoNet) and its approach to few-shot learning.",
      "processing_time": 59.507997274398804,
      "citing_paper_id": "252090194",
      "cited_paper_id": 309759
    },
    {
      "context_text": "This is opposite to joint extraction where the task is to jointly extract all events and their associated arguments all at once (Sha et al., 2018; Yang and Mitchell, 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to event and entity extraction.",
      "processing_time": 58.75895643234253,
      "citing_paper_id": "252090194",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "Few-shot learning (FSL) (Fei-Fei et al., 2006) is proposed to tackle",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (few-shot learning).",
      "processing_time": 58.59457755088806,
      "citing_paper_id": "252090194",
      "cited_paper_id": 6953475
    },
    {
      "context_text": "Different from FSL for single sentences by traditional N -way- K - Shot sampling, a novel N -Way- D -Doc sampling strategy is proposed for our document-level task, as can be seen from the example in Fig.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes a novel sampling strategy for a document-level task.",
      "processing_time": 59.542885541915894,
      "citing_paper_id": "252090194",
      "cited_paper_id": 6953475
    },
    {
      "context_text": "Few-shot learning (FSL) (Fei-Fei et al., 2006) is proposed to tackle such limitations to make machine learning models more applicable given limited annotated examples and has been used a lot in the IE area (Han et al., 2018; Ding et al., 2021; Lai et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the concept of few-shot learning and its application in information extraction. The cited papers' titles suggest potential datasets, but they are not explicitly mentioned in the context.",
      "processing_time": 61.92301654815674,
      "citing_paper_id": "252090194",
      "cited_paper_id": 6953475
    },
    {
      "context_text": "Few-shot learning (FSL) (Fei-Fei et al., 2006) is proposed to tackle such limitations to make machine learning models more applicable given limited annotated examples and has been used a lot in the IE area (Han et al., 2018; Ding et al., 2021; Lai et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the concept of few-shot learning and its application in information extraction. The cited papers' titles suggest potential datasets, but they are not explicitly mentioned in the context.",
      "processing_time": 61.92301654815674,
      "citing_paper_id": "252090194",
      "cited_paper_id": 53080736
    },
    {
      "context_text": "Few-shot learning (FSL) (Fei-Fei et al., 2006) is proposed to tackle such limitations to make machine learning models more applicable given limited annotated examples and has been used a lot in the IE area (Han et al., 2018; Ding et al., 2021; Lai et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the concept of few-shot learning and its application in information extraction. The cited papers' titles suggest potential datasets, but they are not explicitly mentioned in the context.",
      "processing_time": 61.92301654815674,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "2020) mainly focuses on sentence-level event extraction, such as the popular ACE2005 (Doddington et al. 2004) dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE2005"
      ],
      "dataset_descriptions": {
        "ACE2005": "Used for sentence-level event extraction, focusing on identifying and classifying events within individual sentences. The dataset provides annotated text for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE2005 dataset, which is a well-known resource for event extraction. The dataset is specifically used for sentence-level event extraction.",
      "processing_time": 67.18778586387634,
      "citing_paper_id": "252090194",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "Previous research (Yang et al., 2019; Tong et al., 2020) mainly focuses on sentence-level event extraction, such as the popular ACE2005 (Dodding-ton et al., 2004) dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE2005"
      ],
      "dataset_descriptions": {
        "ACE2005": "Used for sentence-level event extraction, focusing on identifying events within individual sentences. The dataset provides annotated text for training and evaluating event extraction systems."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE2005 dataset, which is a well-known resource for event extraction. The dataset is explicitly named and used for sentence-level event extraction.",
      "processing_time": 66.9566638469696,
      "citing_paper_id": "252090194",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "While other datasets such as WikiEvents (Li et al., 2021) and MUC-4 (Grishman and Sundheim, 1996) only contain extremely limited types and documents, thus not suitable for our settings.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to highlight limitations in document-level event extraction, specifically the limited types and documents, making it unsuitable for the current research settings.",
        "MUC-4": "Used to highlight limitations in document-level event extraction, specifically the limited types and documents, making it unsuitable for the current research settings."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions two datasets, WikiEvents and MUC-4, which are both relevant to document-level event extraction. However, they are described as unsuitable for the current research settings due to limited types and documents.",
      "processing_time": 69.90594506263733,
      "citing_paper_id": "252090194",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "0 (Pradhan et al., 2013) named entity recognition corpora, all focus on single sentence-level semantics.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'named entity recognition corpora' but does not specify any particular dataset names. The title 'Towards Robust Linguistic Analysis using OntoNotes' suggests OntoNotes might be relevant, but it is not explicitly mentioned in the context.",
      "processing_time": 63.885031938552856,
      "citing_paper_id": "252090194",
      "cited_paper_id": 14515377
    },
    {
      "context_text": "Many approaches and datasets (Petroni et al., 2018; Hürriyeto˘glu et al., 2021; Giorgi et al., 2021; Zavarella et al., 2022) across diverse domains have been proposed for document-level argument extraction to go beyond single-sentence inference.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation span mentions 'datasets' but does not specify any particular dataset names. It refers to general approaches and datasets across diverse domains for document-level argument extraction.",
      "processing_time": 60.57656979560852,
      "citing_paper_id": "252090194",
      "cited_paper_id": 50771731
    },
    {
      "context_text": "Many approaches and datasets (Petroni et al., 2018; Hürriyeto˘glu et al., 2021; Giorgi et al., 2021; Zavarella et al., 2022) across diverse domains have been proposed for document-level argument extraction to go beyond single-sentence inference.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation span mentions 'datasets' but does not specify any particular dataset names. It refers to general approaches and datasets across diverse domains for document-level argument extraction.",
      "processing_time": 60.57656979560852,
      "citing_paper_id": "252090194",
      "cited_paper_id": 236486186
    },
    {
      "context_text": "There have been growing interests under few-shot settings for named entity recognition (Ding et al., 2021; Das et al., 2022), and relation extraction (Han et al., 2018; Popovic and Färber, 2022) under single-sentence and document-level scenarios.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "Few-NERD"
      ],
      "dataset_descriptions": {
        "FewRel": "Used for few-shot relation classification, providing a large-scale supervised dataset for evaluating few-shot learning models in relation extraction tasks.",
        "Few-NERD": "Used for few-shot named entity recognition, offering a dataset designed to support few-shot learning scenarios in NER tasks."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions few-shot settings for named entity recognition and relation extraction, but does not explicitly mention any specific datasets. The cited papers' titles suggest the presence of datasets, but they are not directly referenced in the citation span.",
      "processing_time": 69.7483377456665,
      "citing_paper_id": "252090194",
      "cited_paper_id": 53080736
    },
    {
      "context_text": "There have been growing interests under few-shot settings for named entity recognition (Ding et al., 2021; Das et al., 2022), and relation extraction (Han et al., 2018; Popovic and Färber, 2022) under single-sentence and document-level scenarios.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "Few-NERD"
      ],
      "dataset_descriptions": {
        "FewRel": "Used for few-shot relation classification, providing a large-scale supervised dataset for evaluating few-shot learning models in relation extraction tasks.",
        "Few-NERD": "Used for few-shot named entity recognition, offering a dataset designed to support few-shot learning scenarios in NER tasks."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions few-shot settings for named entity recognition and relation extraction, but does not explicitly mention any specific datasets. The cited papers' titles suggest the presence of datasets, but they are not directly referenced in the citation span.",
      "processing_time": 69.7483377456665,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "There have been growing interests under few-shot settings for named entity recognition (Ding et al., 2021; Das et al., 2022), and relation extraction (Han et al., 2018; Popovic and Färber, 2022) under single-sentence and document-level scenarios.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "Few-NERD"
      ],
      "dataset_descriptions": {
        "FewRel": "Used for few-shot relation classification, providing a large-scale supervised dataset for evaluating few-shot learning models in relation extraction tasks.",
        "Few-NERD": "Used for few-shot named entity recognition, offering a dataset designed to support few-shot learning scenarios in NER tasks."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions few-shot settings for named entity recognition and relation extraction, but does not explicitly mention any specific datasets. The cited papers' titles suggest the presence of datasets, but they are not directly referenced in the citation span.",
      "processing_time": 69.7483377456665,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248512966
    },
    {
      "context_text": "This way we ideally reduce the risk of only representing many NOTA token by one vector as also pointed by (Allen et al., 2019), since there might be multiple NOTA Prototypes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or concept related to prototypes and NOTA tokens.",
      "processing_time": 59.01190257072449,
      "citing_paper_id": "252090194",
      "cited_paper_id": 60441361
    },
    {
      "context_text": "Moreover, prototypical networks(ProtoNet) (Snell, Swersky, and Zemel 2017) have been proven to be very powerful for solving few-shot problems by representing each category as a prototype in both CV (Pan et al. 2019; Dong and Xing 2018) and NLP (Sun et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (prototypical networks) and its applications in CV and NLP. No verifiable datasets are named.",
      "processing_time": 60.61812663078308,
      "citing_paper_id": "252090194",
      "cited_paper_id": 131774949
    },
    {
      "context_text": "Event argument extraction (EAE), a sub-task of event extraction, is a fundamental task for many downstream NLP applications in the IE community.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general task in NLP. No dataset names are present in the text.",
      "processing_time": 59.99032640457153,
      "citing_paper_id": "252090194",
      "cited_paper_id": 202771953
    },
    {
      "context_text": "2019; Dong and Xing 2018) and NLP (Sun et al. 2019; Gao et al. 2019) domains.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general domains (NLP and other unspecified domains). There are no specific, verifiable resources mentioned.",
      "processing_time": 60.39316725730896,
      "citing_paper_id": "252090194",
      "cited_paper_id": 202771953
    },
    {
      "context_text": "There has also been research (Deng et al., 2020; Lai et al., 2021; Feng et al., 2020; Lai et al., 2020) for few-shot event extraction within single-sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to research papers. The context is about few-shot event extraction within single-sentence, but no datasets are explicitly named.",
      "processing_time": 61.492072343826294,
      "citing_paper_id": "252090194",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "Instead of initializing the NONA vectors by randomly as by (Sabo et al., 2021) or from sampled support sets as in (Popovic and Färber, 2022) and then gradually update them, we adopt a K-means MNAV strategy.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and strategies. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 59.68717002868652,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "Instead of initializing the NONA vectors by randomly as by (Sabo et al., 2021) or from sampled support sets as in (Popovic and Färber, 2022) and then gradually update them, we adopt a K-means MNAV strategy.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and strategies. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 59.68717002868652,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248512966
    },
    {
      "context_text": "We believe that this is a big challenge for few-shot document-level tasks, which is not only a issue for small language models (Sabo et al., 2021) but also true for large models like GPT-3 (Brown et al., 2020) and leave more exploration for future work.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses challenges in few-shot document-level tasks.",
      "processing_time": 58.54981017112732,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "This extremely unbalanced setting is a good testbed for validating the model ability due to its similar distribution of many real-world few-shot problems, as also pointed by (Sabo et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a general setting. No clear, verifiable resource is identified.",
      "processing_time": 59.10521602630615,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "Here we adjust the Multiple NOTA(None-Of-the-Above) Vectors(MNAV) proposed by (Sabo et al., 2021) for few-shot relation extraction to our Few-DocAE since they both face the same issue that the majority labels belong to NOTA.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (MNAV) and a task (few-shot relation extraction).",
      "processing_time": 59.68012452125549,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "Instead of building a new dataset from scratch, we aim at leveraging the existing supervised dataset for reconstructing the instances by a novel N -Way- D -Doc sampling strategy, inspired by similar work (Sabo et al., 2021; Popovic and Färber, 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions leveraging an existing supervised dataset but does not specify the name of the dataset. The cited papers do not provide additional clarity on the dataset name.",
      "processing_time": 61.050800800323486,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "Instead of building a new dataset from scratch, we aim at leveraging the existing supervised dataset for reconstructing the instances by a novel N -Way- D -Doc sampling strategy, inspired by similar work (Sabo et al., 2021; Popovic and Färber, 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions leveraging an existing supervised dataset but does not specify the name of the dataset. The cited papers do not provide additional clarity on the dataset name.",
      "processing_time": 61.050800800323486,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248512966
    },
    {
      "context_text": "Similar memory issue has also been reported by (Sabo et al., 2021) when handling few-shot learning for relation extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue with few-shot learning for relation extraction.",
      "processing_time": 58.57785511016846,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "Soft sampling methods like N -Way- K ∼ 2 K Shots in (Ding et al., 2021) still do not work for our long documents since K ∼ 2 K Shots are still hard to be satisfied.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (N-Way-K Shots) and a limitation regarding its applicability to long documents.",
      "processing_time": 60.31651020050049,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "The first one masks all arguments in the training set with O if they also appear in the val and test sets as used in (Ding et al. 2021), while in the second strategy, we can mask all the arguments in the val and test sets if they are shared by the training set.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset names, only generic references to training, validation, and test sets. The cited paper title 'Few-NERD' is a dataset but is not mentioned in the context.",
      "processing_time": 62.42269539833069,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "Soft sampling methods like N -Way-K∼2K Shots in (Ding et al. 2021) still do not work for our long documents since K∼2K Shots are still hard to be satisfied.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (N-Way-K∼2K Shots) and a limitation regarding its applicability to long documents.",
      "processing_time": 60.13924956321716,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "Previous research (Yang and Katiyar, 2020) tries to use greedy sampling to guarantee the strict K shots requirements for sentence-level few-shot NER task, but this is not applicable due to the sparse density of arguments in the document as also been observed by (Ding et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets by name, only referring to previous research and methods. The context is about methodological challenges in few-shot NER, not the use of a specific dataset.",
      "processing_time": 61.459670066833496,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "The latest Few-NERD (Ding et al. 2021) named entity recognition dataset also includes information across sentences.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Few-NERD"
      ],
      "dataset_descriptions": {
        "Few-NERD": "Used to train and evaluate few-shot named entity recognition models, focusing on cross-sentence information for improved entity detection."
      },
      "confidence_score": 1.0,
      "reasoning": "Few-NERD is explicitly mentioned as a dataset and is relevant to the topic of document-level event extraction, as it includes information across sentences.",
      "processing_time": 65.62824130058289,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "Previous research (Yang and Katiyar 2020) tries to use greedy sampling to guarantee the strict K shots requirements for sentencelevel few-shot NER task, but this is not applicable due to the sparse density of arguments in the document as also been observed by (Ding et al. 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets by name, only referring to previous research and methods. The context is about methodological challenges in few-shot NER, not the use of specific datasets.",
      "processing_time": 61.63533544540405,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "There have been growing interests under few-shot settings for named entity recognition (Ding et al. 2021; Das et al. 2022), and relation extraction (Han et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Few-NERD"
      ],
      "dataset_descriptions": {
        "Few-NERD": "Used to evaluate few-shot named entity recognition methods, focusing on the performance of models with limited labeled data."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Few-NERD' in the context of few-shot named entity recognition, which is a specific dataset. No other datasets are mentioned.",
      "processing_time": 65.49955606460571,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "And (Ding et al. 2021) lose the K shots requirement to K∼2K shots.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a methodological change in shot requirements. The title 'Few-NERD' suggests a dataset, but it is not mentioned in the citation context.",
      "processing_time": 62.24317216873169,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "The first one masks all arguments in the training set with O if they also appear in the val and test sets as used in (Ding et al., 2021), while in the second strategy, we can mask all the arguments in the val and test sets if they are shared by the training set.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset names, only generic references to training, validation, and test sets. The cited paper title 'Few-NERD' is a dataset but is not mentioned in the context.",
      "processing_time": 61.835485219955444,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "Many approaches and datasets (Petroni et al., 2018; Hürriyetoğlu et al., 2021; Giorgi et al., 2021; Zavarella et al., 2022) across diverse domains have been proposed for document-level argument extraction to go beyond single-sentence inference.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation mentions 'datasets' in plural but does not specify any particular dataset names. It refers to general approaches and datasets across diverse domains, which are not specific enough to meet the criteria.",
      "processing_time": 62.29207158088684,
      "citing_paper_id": "252090194",
      "cited_paper_id": 236486186
    },
    {
      "context_text": "Following these datasets, many novel methods for solving such new challenges brought by the longer context have also been investigated and witness significant progress (Du and Cardie, 2020; Li et al., 2021; Xu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that discuss methods and progress. No clear, verifiable datasets are identified.",
      "processing_time": 60.47607231140137,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Note that (Popovic and Färber, 2022) adopts D -doc sampling for document-level relation extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'D -doc sampling' which is likely a method or technique rather than a dataset. No specific dataset is mentioned in the context.",
      "processing_time": 60.47541785240173,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248512966
    },
    {
      "context_text": "It is notable that (Popovic and Färber, 2022) tackle this problem for few-shot document-level relation extraction by D -Doc setting where both N and K are variables between documents and individual episodes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to few-shot document-level relation extraction.",
      "processing_time": 59.367910623550415,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248512966
    },
    {
      "context_text": "The recent RAMS (Ebner et al., 2020) and DocEE (Tong et al., 2022) corpora focus on multi-sentence event extraction.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "DocEE"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for multi-sentence event extraction, focusing on the identification and classification of events across multiple sentences.",
        "DocEE": "Used for document-level event extraction, emphasizing large-scale and fine-grained event annotation in multi-sentence contexts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two corpora, RAMS and DocEE, both of which are used for document-level event extraction. DocEE is specifically noted for being large-scale and fine-grained.",
      "processing_time": 67.98168516159058,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "On the other hand, the results convince our motivation by extending to document-level argument extraction as a large portion of arguments can only be extracted across sentences, as also confirmed under supervised condition by (Tong et al., 2022).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a general reference to document-level argument extraction. The cited paper title suggests a benchmark, but it is not explicitly used as a dataset in the citation context.",
      "processing_time": 61.80592179298401,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "For Cross domain, we follow the original event splits in DocEE (Tong et al. 2022) where the authors choose the natural disasters events as the target domain, including Floods, Droughts, Earthquakes, Insect Disaster, Famine, Tsunamis, Mudslides, Hurricanes, Fire, and Volcano Eruption, and leave the remaining 49 event types as source domains.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to train and evaluate cross-domain event extraction models, focusing on natural disaster events as the target domain and other event types as source domains."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocEE' as a benchmark for document-level event extraction, which is a specific dataset used for training and evaluation.",
      "processing_time": 65.13807368278503,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "On the other hand, the results convince our motivation by extending to document-level argument extraction as a large portion of arguments can only be extracted across sentences, as also confirmed under supervised condition by (Tong et al. 2022).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a general reference to 'document-level argument extraction'. The cited paper title suggests a benchmark, but it is not explicitly used as a dataset in the citation context.",
      "processing_time": 62.02846956253052,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "traction dataset is the DocEE (Tong et al. 2022), which consists of 27, 000+ events, 180, 000+ arguments over 27, 485 Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used as a benchmark for document-level event extraction, containing 27,000+ events and 180,000+ arguments across 27,485 Wikipedia articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions 'DocEE' as a dataset with specific statistics, and the cited paper title confirms it is a benchmark for document-level event extraction.",
      "processing_time": 66.64629697799683,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Longformer (Beltagy, Peters, and Cohan 2020)) has also been proven to improve the argument extraction task (Tong et al. 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Longformer) and a research finding (improvement in argument extraction).",
      "processing_time": 60.19668197631836,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "EE datasets include RAMS (Ebner et al., 2020) and DocEE (Tong et al., 2022), and their statistics is shown in Table 1.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "DocEE"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event extraction, providing a benchmark for evaluating systems on complex, multi-event documents.",
        "DocEE": "A large-scale and fine-grained benchmark for document-level event extraction, designed to test the ability of systems to identify and classify events in documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and DocEE, which are used for document-level event extraction. Both are clearly identified and relevant to the research topic.",
      "processing_time": 67.67504000663757,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Previous work on document-level EE using BERT Seq(Du and Cardie 2020; Tong et al. 2022) demonstrate the success of using a pre-trained BERT model to sequentially label words in the article.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT for document-level event extraction. The cited paper title suggests a benchmark, but it is not explicitly used as a dataset in the given context.",
      "processing_time": 62.656466484069824,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "In addition, DocEE (Tong et al. 2022) includes 21, 450 documentlevel events with 109, 395 arguments, making it the largest document-level event extraction dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to benchmark document-level event extraction, focusing on large-scale and fine-grained annotations of events and arguments."
      },
      "confidence_score": 1.0,
      "reasoning": "DocEE is explicitly mentioned as a dataset with specific characteristics relevant to document-level event extraction.",
      "processing_time": 63.601630449295044,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Previous work on document-level EE using BERT_Seq (Du and Cardie, 2020; Tong et al., 2022) demonstrate the success of using a pre-trained BERT model to sequentially label words in the article.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BERT_Seq) and a benchmark (DocEE). DocEE is excluded as it is a benchmark, not a dataset.",
      "processing_time": 61.78812646865845,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Since the DocEE dataset (Tong et al. 2022) follows the main event extraction (Hamborg et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used as a benchmark for document-level event extraction, focusing on fine-grained event classification and entity linking in complex documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocEE dataset' which is a specific, verifiable dataset used for document-level event extraction. The title confirms it is a benchmark dataset.",
      "processing_time": 65.05326819419861,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "The largest document-level event extraction dataset is the DocEE (Tong et al., 2022), which consists of 27 , 000+ events, 180 , 000+ arguments over 27 , 485 Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used as a benchmark for document-level event extraction, containing 27,000+ events and 180,000+ arguments across 27,485 Wikipedia articles, focusing on fine-grained event and argument identification."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset, DocEE, which is used for document-level event extraction. The dataset is described with a clear size and source, making it a verifiable resource.",
      "processing_time": 67.36926674842834,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "The authors (Tong et al. 2022) provide Cross domain scenario, where the training and test labels are entirely disjoint, sharing no mutual domain information.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a cross-domain scenario. The cited paper title suggests a benchmark, but it is not explicitly used as a dataset in the given context.",
      "processing_time": 61.5457398891449,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "In the released DocEE (Tong et al. 2022) corpus, there are 31 hard news event types and 28 soft news event types with their corresponding arguments.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to benchmark document-level event extraction, specifically evaluating performance on 31 hard news and 28 soft news event types with their arguments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the DocEE corpus, which is a specific dataset used for document-level event extraction. The corpus is described as containing hard and soft news event types with corresponding arguments.",
      "processing_time": 65.61239695549011,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "The authors (Tong et al., 2022) provide Cross domain scenario, where the training and test labels are entirely disjoint, sharing no mutual domain information.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a cross-domain scenario. The cited paper title suggests a benchmark, but it is not explicitly used as a dataset in the citation context.",
      "processing_time": 61.78651285171509,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "And the superior performance of the long document transformer (e.g. Longformer (Beltagy et al., 2020)) has also been proven to improve the argument extraction task (Tong et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the performance of the Longformer model in improving argument extraction tasks.",
      "processing_time": 60.34809136390686,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "2020) and DocEE (Tong et al. 2022) corpora focus on multisentence event extraction.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to develop and evaluate models for document-level event extraction, focusing on fine-grained and multisentence events in a large-scale benchmark."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two corpora, DocEE and another unnamed corpus, both focused on document-level event extraction. DocEE is a specific, named resource with a clear reference to a published benchmark.",
      "processing_time": 65.78903985023499,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Since the DocEE dataset (Tong et al., 2022) follows the main event extraction (Hamborg et al., 2018) setting where no trigger words exist and the article title t and the article a itself together determine the event type, we follow their setting and assume the event type e is given, then aim at…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to benchmark document-level event extraction, focusing on fine-grained event types determined by the article title and content without trigger words."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocEE dataset' which is a specific, verifiable dataset used for document-level event extraction. The dataset is directly relevant to the research topic.",
      "processing_time": 65.47171521186829,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "For Coref F1, the model is given full credit if the extracted argument is corefer-ential with the reference as used in Ji and Grishman (2008).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (Coref F1) and a method (cross-document inference). No verifiable resources are identified.",
      "processing_time": 61.00793218612671,
      "citing_paper_id": "258967387",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Wang et al. (2021) pre-trains the EAE model with a contrastive loss built on AMR graphs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions pre-training with AMR graphs but does not specify a dataset. The cited paper title does not help in identifying a specific dataset.",
      "processing_time": 59.637086391448975,
      "citing_paper_id": "258967387",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "Xu and Huang (2022) and Wang et al. (2021) utilize AMR graphs to provide training signals via self-training and contrastive learning, respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions AMR graphs but does not specify a dataset. The cited papers do not provide additional context to identify a specific dataset.",
      "processing_time": 59.79173135757446,
      "citing_paper_id": "258967387",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "Xu and Huang (2022) and Wang et al. (2021) utilize AMR graphs to provide training signals via self-training and contrastive learning, respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions AMR graphs but does not specify a dataset. The cited papers do not provide additional context to identify a specific dataset.",
      "processing_time": 59.79173135757446,
      "citing_paper_id": "258967387",
      "cited_paper_id": 249063162
    },
    {
      "context_text": "(1) QA-based models: EEQA (Du and Cardie, 2020b) and FEAE (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (EEQA and FEAE). The context is about using QA-based models for event extraction, which does not indicate the use of a specific dataset.",
      "processing_time": 62.44310021400452,
      "citing_paper_id": "258967387",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Du and Cardie (2020a) chooses the hierarchical method to aggregate information from different granularity.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 57.2756724357605,
      "citing_paper_id": "258967387",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Unlike the well-developed sentence-level event extraction (Xi et al., 2021; Ma et al., 2020), the Doc-level EAE faces more challenges.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to document-level event extraction challenges.",
      "processing_time": 58.64773154258728,
      "citing_paper_id": "258967387",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "To explore the effect of different AMR parsing performance, we compare test results of TARA using transition-based AMR parser and a latest state-of-the-art parser AMRBART (Bai et al., 2022) in Table 9.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions AMR parsers but does not refer to any specific datasets. The focus is on comparing parsing performance rather than using a particular dataset.",
      "processing_time": 59.97756028175354,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "Second, the Smatch score of SOTA AMR parsers is around 85 (Bai et al., 2022), which causes information loss as well.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a performance metric (Smatch score) of state-of-the-art AMR parsers. No dataset names are provided.",
      "processing_time": 60.73100709915161,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "We implement a simple node-to-text aligner and compress the obtained AMR graph as described in Sec-B for AMRBART.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for AMR parsing and generation.",
      "processing_time": 57.63009238243103,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "As shown in the table, though AMRBART brings better AMR parsing performance, it dose not gain more improvements for EAE.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (AMRBART) and its performance on AMR parsing and generation tasks.",
      "processing_time": 59.63591384887695,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "We also show the performance using another state-of-the-art AMR parser, AMRBART (Bai et al., 2022 (3) Span-based models: TSAR (Xu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing performance of different parsers, which are not considered datasets.",
      "processing_time": 60.0767183303833,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "TAG can be built on vanilla AMR graphs generated by an off-the-shelf AMR parser (Bai et al., 2022; Astudillo et al., 2020), which also provides the alignment information between nodes and words.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and tools. The citation is about using an off-the-shelf AMR parser, which is not a dataset.",
      "processing_time": 59.873676776885986,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "Lin et al. (2022) and Xu and Huang (2022) introduce AMR path information as training signals to correct argument predictions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. The context focuses on the introduction of AMR path information as a training signal.",
      "processing_time": 60.09616255760193,
      "citing_paper_id": "258967387",
      "cited_paper_id": 249063162
    },
    {
      "context_text": "Fan et al. (2022) trains a learnable module to add nodes and edges to the AMR graph.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for adding nodes and edges to an AMR graph.",
      "processing_time": 58.88044452667236,
      "citing_paper_id": "258967387",
      "cited_paper_id": 250637739
    },
    {
      "context_text": "Fan et al. (2022) and Xu et al. (2021) construct an entity-based graph to model dependencies among the document.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving an entity-based graph.",
      "processing_time": 57.738276720047,
      "citing_paper_id": "258967387",
      "cited_paper_id": 250637739
    },
    {
      "context_text": "For example, BioCreative aims to support curation of PPI databases such as MINT (Chatr-aryamontri et al., 2007), for a long time one of the primary tasks of bioinformatics.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MINT"
      ],
      "dataset_descriptions": {
        "MINT": "Used to curate protein-protein interaction data, supporting bioinformatics tasks such as database curation and interaction annotation."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions MINT as a database, which is a specific, verifiable resource. However, it is not used for document-level event extraction but rather for curation of PPI interactions.",
      "processing_time": 64.68624520301819,
      "citing_paper_id": "9631585",
      "cited_paper_id": 1355341
    },
    {
      "context_text": "Both the native output of each parser and a representation in the popular Stanford Dependency (SD) format (de Marneffe et al., 2006) were provided.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only formats and parsers. There are no clear identifiers for datasets in the text.",
      "processing_time": 58.17696952819824,
      "citing_paper_id": "9631585",
      "cited_paper_id": 3102322
    },
    {
      "context_text": "The data for the training and development sets were derived from the publicly available event corpus (Kim et al., 2008), and the data for the test set from an unpublished portion of the corpus.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "event corpus"
      ],
      "dataset_descriptions": {
        "event corpus": "Used for training and development of a model to mine biomedical events from literature, focusing on event extraction and annotation."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions a 'publicly available event corpus' which is likely a dataset used for training and development. The test set comes from an unpublished portion of the same corpus.",
      "processing_time": 64.28887104988098,
      "citing_paper_id": "9631585",
      "cited_paper_id": 5261517
    },
    {
      "context_text": "Similarly to LLL and BioCreative, the BioNLP’09 Shared Task (the BioNLP task, hereafter) also addresses bio-IE, but takes a definitive step further toward finer-grained IE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "BioNLP’09 Shared Task"
      ],
      "dataset_descriptions": {
        "BioNLP’09 Shared Task": "Mentioned as a resource addressing bio-IE with finer-grained information extraction, but specific usage in the current research is not detailed."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the BioNLP’09 Shared Task, which is a specific challenge or dataset used for bio-IE tasks. However, it does not provide details on how it is used in the current research context.",
      "processing_time": 66.14096188545227,
      "citing_paper_id": "9631585",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "Examples include the TREC Genomics track (Hersh et al., 2007), JNLPBA (Kim et al., 2004), LLL (Ńedellec, 2005), and BioCreative (Hirschman et al., 2007).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several named challenges/tracks but does not specify their use as datasets. They are likely benchmark suites or competition tracks rather than reusable datasets.",
      "processing_time": 59.98009705543518,
      "citing_paper_id": "9631585",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "The data was developed based on the GENIA event corpus.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENIA event corpus"
      ],
      "dataset_descriptions": {
        "GENIA event corpus": "Used to develop and evaluate document-level event extraction methods, focusing on genic interactions and their linguistic representations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the GENIA event corpus, which is a well-known dataset in the field of biomedical text mining and event extraction.",
      "processing_time": 63.89418148994446,
      "citing_paper_id": "9631585",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "While LLL and BioCreative focus on a rather simple representation of relations of bio-molecules, i.e. protein-protein interactions (PPI), the BioNLP task concerns the detailed behavior of bio-molecules, characterized as bio-molecular events (bio-events).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tasks and challenges which are excluded according to the instructions.",
      "processing_time": 58.343098640441895,
      "citing_paper_id": "9631585",
      "cited_paper_id": 6962537
    },
    {
      "context_text": "We also applied the GDep 5 , native dependency parser trained on the GENIA Treebank (Tateisi et al., 2005), and a version of the C&C CCG deep parser 6 adapted to biomedical text (Rimell and Clark, 2008).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions tools and parsers but does not refer to any specific datasets. The GENIA Treebank is mentioned, but it is used as a training resource for a parser, not as a primary dataset for the research.",
      "processing_time": 62.2671160697937,
      "citing_paper_id": "9631585",
      "cited_paper_id": 38886829
    },
    {
      "context_text": "The SD representation was created using the Stanford tools 7 to convert from the PTB scheme, the custom conversion introduced by (Rimell and Clark, 2008) for the C&C CCG parser, and a simple format-only conversion for GDep.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tools and methods used for conversion. The context is about the process of converting representations, not the use of a dataset.",
      "processing_time": 60.64997434616089,
      "citing_paper_id": "9631585",
      "cited_paper_id": 38886829
    },
    {
      "context_text": "The history of text mining (TM) shows that shared tasks based on carefully curated resources, such as those organized in the MUC (Chinchor, 1998), TREC (Voorhees, 2007) and ACE (Strassel et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC"
      ],
      "dataset_descriptions": {
        "MUC": "Used to organize shared tasks in text mining, focusing on message understanding and information extraction, providing a benchmark for evaluating systems."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions MUC, TREC, and ACE as examples of shared tasks based on curated resources. MUC is specifically referenced with a year, indicating it is a verifiable resource.",
      "processing_time": 64.45272588729858,
      "citing_paper_id": "9631585",
      "cited_paper_id": 60588668
    },
    {
      "context_text": "The history of text mining ( TM ) shows that shared tasks based on carefully curated resources, such as those organized in the MUC (Chinchor, 1998), TREC (Voorhees, 2007) and ACE (Strassel et al., 2008) events, have signiﬁcantly contributed to the progress of their respective ﬁelds.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Expecting ',' delimiter: line 10 column 9 (char 941), response: ```json\n{\n    \"reasoning\": \"The citation mentions MUC, TREC, and ACE as carefully curated resources ",
      "processing_time": 68.91299176216125,
      "citing_paper_id": "9631585",
      "cited_paper_id": 60588668
    },
    {
      "context_text": "The best model uses a BiLSTM (Hochreiter and Schmidhuber, 1997) to encode the whole document, entities are represented by their average word embedding.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BiLSTM) and a general approach to encoding documents and representing entities. No verifiable datasets are referenced.",
      "processing_time": 60.510695457458496,
      "citing_paper_id": "202889074",
      "cited_paper_id": 1915014
    },
    {
      "context_text": "We compare the BERT model with several base-lines presented in (Yao et al., 2019) including a CNN (Zeng et al., 2014b), LSTM (Hochre-iter and Schmidhuber, 1997), bidirectional LSTM (BiLSTM) (Cai et al., 2016) and Context-Aware models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 58.52244210243225,
      "citing_paper_id": "202889074",
      "cited_paper_id": 1915014
    },
    {
      "context_text": "We compare the BERT model with several base-lines presented in (Yao et al., 2019) including a CNN (Zeng et al., 2014b), LSTM (Hochre-iter and Schmidhuber, 1997), bidirectional LSTM (BiLSTM) (Cai et al., 2016) and Context-Aware models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 58.52244210243225,
      "citing_paper_id": "202889074",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "The ﬁrst three models differ from the BERT model in the encoder, i.e., they use CNN, LSTM, and BiLSTM as encoder respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and encoders. There are no verifiable resources that meet the criteria.",
      "processing_time": 59.27540612220764,
      "citing_paper_id": "202889074",
      "cited_paper_id": 1915014
    },
    {
      "context_text": "The ﬁrst three models differ from the BERT model in the encoder, i.e., they use CNN, LSTM, and BiLSTM as encoder respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and encoders. There are no verifiable resources that meet the criteria.",
      "processing_time": 59.27540612220764,
      "citing_paper_id": "202889074",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Previous research (Socher et al., 2012; Zeng et al., 2014a, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018; Wang et al., 2019) on relation extraction mainly focuses on sentence-level, i.e., predicting the…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous research on relation extraction. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 60.11491322517395,
      "citing_paper_id": "202889074",
      "cited_paper_id": 3766076
    },
    {
      "context_text": "Previous research (Socher et al., 2012; Zeng et al., 2014a, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018; Wang et al., 2019) on relation extraction mainly focuses on sentence-level, i.e., predicting the…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous research on relation extraction. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 60.11491322517395,
      "citing_paper_id": "202889074",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "Previous research (Socher et al., 2012; Zeng et al., 2014a, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018; Wang et al., 2019) on relation extraction mainly focuses on sentence-level, i.e., predicting the…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous research on relation extraction. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 60.11491322517395,
      "citing_paper_id": "202889074",
      "cited_paper_id": 15620570
    },
    {
      "context_text": "Previous research (Socher et al., 2012; Zeng et al., 2014a, 2015; dos Santos et al., 2015; Xiao and Liu, 2016; Cai et al., 2016; Lin et al., 2016; Wu et al., 2017; Qin et al., 2018; Han et al., 2018; Wang et al., 2019) on relation extraction mainly focuses on sentence-level, i.e., predicting the…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous research on relation extraction. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 60.11491322517395,
      "citing_paper_id": "202889074",
      "cited_paper_id": 34190303
    },
    {
      "context_text": "a CNN (Zeng et al., 2014b), LSTM (Hochreiter and Schmidhuber, 1997), bidirectional LSTM (BiLSTM) (Cai et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets.",
      "processing_time": 58.63309931755066,
      "citing_paper_id": "202889074",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "However, we argue that a pre-trained language model, such as BERT (Devlin et al., 2019), can provide a further boost in performance, since it already captures important language features and",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a pre-trained language model (BERT). BERT is a method/model, not a dataset.",
      "processing_time": 59.82771372795105,
      "citing_paper_id": "202889074",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "However, we argue that a pre-trained language model, such as BERT (Devlin et al., 2019), can provide a further boost in performance, since it already captures important language features and may capture some common sense knowledge.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a pre-trained language model (BERT). BERT is a method/model, not a dataset.",
      "processing_time": 59.65022301673889,
      "citing_paper_id": "202889074",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In (Levy et al. 2017), sets of crowdsourced paraphrastic questions are written for each relation type in the ontology.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'sets of crowdsourced paraphrastic questions' which could be a dataset, but it lacks a specific name or identifier. The title does not provide additional clarity.",
      "processing_time": 60.31477928161621,
      "citing_paper_id": "208547716",
      "cited_paper_id": 793385
    },
    {
      "context_text": "These include feature-based approaches (Ji and Grishman 2008; Liao and Grishman 2010; McClosky, Surdeanu, and Manning 2011; Huang and Riloff 2012; Li, Ji, and Huang 2013) and neural approaches (Nguyen and Grishman 2015; Chen et al. 2015; Nguyen and Grishman 2016; Nguyen, Cho, and Grishman 2016;…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods for event extraction. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.11922359466553,
      "citing_paper_id": "208547716",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "These include feature-based approaches (Ji and Grishman 2008; Liao and Grishman 2010; McClosky, Surdeanu, and Manning 2011; Huang and Riloff 2012; Li, Ji, and Huang 2013) and neural approaches (Nguyen and Grishman 2015; Chen et al. 2015; Nguyen and Grishman 2016; Nguyen, Cho, and Grishman 2016;…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods for event extraction. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 60.11922359466553,
      "citing_paper_id": "208547716",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "We ﬁrst compute an attentive representation for a place-holder with respect to each text token t j , using the attention mechanism proposed by Luong, Pham, and Manning (2015), since the placeholder is of variable length but we desire a ﬁxed-size vector representation: Then the attentive placeholder…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for computing an attentive representation using an attention mechanism.",
      "processing_time": 58.17846703529358,
      "citing_paper_id": "208547716",
      "cited_paper_id": 1998416
    },
    {
      "context_text": "…data splits as previous work, in which 40 newswire documents are used as the test set, another 30 documents of different genres are selected as the development set, and the remaining 529 documents constitute the training set (Li, Ji, and Huang 2013; Yang and Mitchell 2016; Nguyen and Nguyen 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context describes a specific data split used across multiple studies, but does not mention a named dataset. The splits are described generically, and there is no multi-word proper noun, uppercase acronym, or hyphenated name with digits.",
      "processing_time": 61.86234211921692,
      "citing_paper_id": "208547716",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "…data splits as previous work, in which 40 newswire documents are used as the test set, another 30 documents of different genres are selected as the development set, and the remaining 529 documents constitute the training set (Li, Ji, and Huang 2013; Yang and Mitchell 2016; Nguyen and Nguyen 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context describes a specific data split used across multiple studies, but does not mention a named dataset. The splits are described generically, and there is no multi-word proper noun, uppercase acronym, or hyphenated name with digits.",
      "processing_time": 61.86234211921692,
      "citing_paper_id": "208547716",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "Yang and Mitchell (2016) attempts to jointly model the three components with hand-crafted features, but still need to detect entity mentions and event triggers separately.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for joint extraction of events and entities.",
      "processing_time": 57.30727982521057,
      "citing_paper_id": "208547716",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "The J OINT F EATURE model (Yang and Mitchell 2016) is a feature-based model that exploits document-level information; the J OINT 3EE model (Nguyen and Nguyen 2019) is a neural model that achieves state-of-the-art performance on ACE 2005.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'ACE 2005' which is a well-known dataset in the field of event extraction. However, it is not explicitly stated that the dataset is used in the research described. The context focuses on describing models rather than their application to specific datasets.",
      "processing_time": 62.25675415992737,
      "citing_paper_id": "208547716",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "We evaluate our approach on the ACE 2005 dataset and use the same data splits as previous work, in which 40 newswire documents are used as the test set, another 30 documents of different genres are selected as the development set, and the remaining 529 documents constitute the training set (Li et al., 2013; Yang and Mitchell, 2016; Nguyen and Nguyen, 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to evaluate the approach on document-level event extraction, employing standard data splits for training, development, and testing as per previous work."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions the ACE 2005 dataset, which is a well-known dataset used for event extraction tasks. The dataset is described in detail, including the splits used for training, development, and testing.",
      "processing_time": 64.51686787605286,
      "citing_paper_id": "208547716",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "The JOINTFEATURE model (Yang and Mitchell, 2016) is a feature-based model that ex-",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model called JOINTFEATURE. The title of the cited paper suggests a focus on event and entity extraction, but no datasets are explicitly named.",
      "processing_time": 60.967952251434326,
      "citing_paper_id": "208547716",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "Researchers have introduced large question answering (QA) / machine reading comprehension (MRC) datasets in a cloze style (Hermann et al. 2015; Onishi et al. 2016), where a query sentence contains a placeholder and the model is expected to ﬁll the blank.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'large question answering (QA) / machine reading comprehension (MRC) datasets' but does not provide specific names. The citation is used to describe a type of dataset rather than a specific reusable resource.",
      "processing_time": 61.25670003890991,
      "citing_paper_id": "208547716",
      "cited_paper_id": 6203757
    },
    {
      "context_text": "In contrast, our approach forgoes explicit graph-structured semantic representations such as AMR.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (AMR) which is excluded according to the instructions.",
      "processing_time": 58.57244610786438,
      "citing_paper_id": "208547716",
      "cited_paper_id": 7771402
    },
    {
      "context_text": "Huang et al. (2018) approach zero-shot event extraction by stipulating a graph structure for each event type and ﬁnding the event type graph structure whose learned representation most closely matches the learned representation of the parsed AMR (Banarescu et al. 2013) structure of a text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (AMR) and a research approach. The context focuses on the methodology of using graph structures for event types and matching them with AMR representations.",
      "processing_time": 60.92319321632385,
      "citing_paper_id": "208547716",
      "cited_paper_id": 7771402
    },
    {
      "context_text": "We employ the neural span-based constituency parser (Stern, Andreas, and Klein 2017) in the Al-lenNLP (Gardner et al. 2018) toolkit to parse the SQuAD questions for extracting the wh - phrases.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using a parser and toolkit but does not reference any specific dataset. The focus is on the method and tools used for parsing questions.",
      "processing_time": 59.19016146659851,
      "citing_paper_id": "208547716",
      "cited_paper_id": 8280711
    },
    {
      "context_text": "Conceptually this may also be considered a form of incremental recognizing textual entailment (RTE) (Dagan et al., 2006) where we iteratively refine a hypothesis that is supported by the document context.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or challenge. The cited paper title confirms it is about a challenge, not a dataset.",
      "processing_time": 59.60238027572632,
      "citing_paper_id": "208547716",
      "cited_paper_id": 8587959
    },
    {
      "context_text": "…Grishman 2008; Liao and Grishman 2010; McClosky, Surdeanu, and Manning 2011; Huang and Riloff 2012; Li, Ji, and Huang 2013) and neural approaches (Nguyen and Grishman 2015; Chen et al. 2015; Nguyen and Grishman 2016; Nguyen, Cho, and Grishman 2016; Chen et al. 2017; Liu et al. 2017; Nguyen and…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 60.127357721328735,
      "citing_paper_id": "208547716",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "…Surdeanu, and Manning 2011; Huang and Riloff 2012; Li, Ji, and Huang 2013) and neural approaches (Nguyen and Grishman 2015; Chen et al. 2015; Nguyen and Grishman 2016; Nguyen, Cho, and Grishman 2016; Chen et al. 2017; Liu et al. 2017; Nguyen and Grish-man 2018; Liu et al. 2018; Sha et al. 2018).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.61387228965759,
      "citing_paper_id": "208547716",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "…Surdeanu, and Manning 2011; Huang and Riloff 2012; Li, Ji, and Huang 2013) and neural approaches (Nguyen and Grishman 2015; Chen et al. 2015; Nguyen and Grishman 2016; Nguyen, Cho, and Grishman 2016; Chen et al. 2017; Liu et al. 2017; Nguyen and Grish-man 2018; Liu et al. 2018; Sha et al. 2018).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 59.61387228965759,
      "citing_paper_id": "208547716",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "Given a bleached statement S = ( s 1 , · · · , s n ) with a highlighted placeholder span with indices 2013), where answer spans are tagged using a linear-chain conditional random ﬁeld (CRF) (Lafferty, McCallum, and Pereira 2001).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (linear-chain CRF). The context is about tagging answer spans using a CRF, which is a method, not a dataset.",
      "processing_time": 60.56961011886597,
      "citing_paper_id": "208547716",
      "cited_paper_id": 14644892
    },
    {
      "context_text": "We use BERT for sequence encoding.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT, which is a model, not a dataset. No datasets are mentioned.",
      "processing_time": 57.50470757484436,
      "citing_paper_id": "208547716",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Architecture for MRC In light of recent advancements in NLP from large-scale pre-training, we use BERT (Devlin et al. 2019) as our sequence encoder.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT as a sequence encoder but does not refer to any specific dataset. BERT is a model, not a dataset.",
      "processing_time": 58.96308088302612,
      "citing_paper_id": "208547716",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Under the formulation of MRC, each training data point is of the form ( S , T ) where S is a natural language question with tokens S = ( s 1 , · · · , s n ) and T is the text to extract answers from, with tokens T = ( t 1 , · · · , t m ) .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes the general structure of training data points in the context of MRC.",
      "processing_time": 59.340518951416016,
      "citing_paper_id": "208547716",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "To perform MRC, Devlin et al. (2019) proposed the following architecture.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an architecture (BERT) which is a method/model.",
      "processing_time": 58.13185358047485,
      "citing_paper_id": "208547716",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We ﬁrst review the answer selector architecture for machine reading comprehension (MRC) used in BERT, then extend it for our approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BERT) which is excluded according to the instructions.",
      "processing_time": 58.42908716201782,
      "citing_paper_id": "208547716",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "First the question S and the text T are concatenated with special delimiters and passed through the BERT contextualizer: where (cid:104) CLS (cid:105) is a special sentinel token whose embedding encompasses the whole string, and (cid:104) SEP (cid:105) is a sentence separator.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT for processing text. No verifiable resources are identified.",
      "processing_time": 58.99737596511841,
      "citing_paper_id": "208547716",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Soares et al. (2019) proposes a model for relation extraction by ﬁlling in two blanks given a contextual relation statement.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model for relation extraction. No verifiable resources are identified.",
      "processing_time": 58.43132662773132,
      "citing_paper_id": "208547716",
      "cited_paper_id": 174801632
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event occurrences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to event extraction. No dataset names are provided.",
      "processing_time": 58.638795137405396,
      "citing_paper_id": "249431954",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event occurrences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to event extraction. No dataset names are provided.",
      "processing_time": 58.638795137405396,
      "citing_paper_id": "249431954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event occurrences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to event extraction. No dataset names are provided.",
      "processing_time": 58.638795137405396,
      "citing_paper_id": "249431954",
      "cited_paper_id": 11187670
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event occurrences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to event extraction. No dataset names are provided.",
      "processing_time": 58.638795137405396,
      "citing_paper_id": "249431954",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "To train the above four components, we leverage the multi-task learning method (Collobert and Weston, 2008) and integrate the four corresponding loss functions together as the following:",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for training components using multi-task learning.",
      "processing_time": 57.81657934188843,
      "citing_paper_id": "249431954",
      "cited_paper_id": 2617020
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a methodological approach to event extraction. No dataset names are provided.",
      "processing_time": 58.68146634101868,
      "citing_paper_id": "249431954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a methodological approach to event extraction. No dataset names are provided.",
      "processing_time": 58.68146634101868,
      "citing_paper_id": "249431954",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Most of the previous methods focus on sentencelevel event extraction (SEE) (Ahn, 2006; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Zhao et al., 2018; Sha et al., 2018; Yan et al., 2019; Du and Cardie, 2020; Li\n*These authors contributed equally to this work\net…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to previous methods and works. No verifiable resources are identified.",
      "processing_time": 58.85405492782593,
      "citing_paper_id": "249431954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Most of the previous methods focus on sentencelevel event extraction (SEE) (Ahn, 2006; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Zhao et al., 2018; Sha et al., 2018; Yan et al., 2019; Du and Cardie, 2020; Li\n*These authors contributed equally to this work\net…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to previous methods and works. No verifiable resources are identified.",
      "processing_time": 58.85405492782593,
      "citing_paper_id": "249431954",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Then a joint model is created to extract triggers and arguments simultaneously via multi-task learning (Nguyen et al., 2016; Sha et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 59.210264921188354,
      "citing_paper_id": "249431954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Then a joint model is created to extract triggers and arguments simultaneously via multi-task learning (Nguyen et al., 2016; Sha et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 59.210264921188354,
      "citing_paper_id": "249431954",
      "cited_paper_id": 19220240
    },
    {
      "context_text": "For example, a neural pipeline model is proposed to identify triggers first and then extracts roles and arguments (Chen et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 57.08697009086609,
      "citing_paper_id": "249431954",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "…event extraction (SEE) (Ahn, 2006; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Zhao et al., 2018; Sha et al., 2018; Yan et al., 2019; Du and Cardie, 2020; Li\n*These authors contributed equally to this work\net al., 2020; Paolini et al., 2021; Lu et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works on event extraction. No verifiable resources are identified.",
      "processing_time": 58.898354053497314,
      "citing_paper_id": "249431954",
      "cited_paper_id": 19220240
    },
    {
      "context_text": "Specifically, we use the BERT (Devlin et al., 2019) encoder pre-trained in Roberta setting (Liu et al.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and Roberta, which are models, not datasets. No specific dataset is mentioned.",
      "processing_time": 57.95976543426514,
      "citing_paper_id": "249431954",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Specifically, we use the BERT (Devlin et al., 2019) encoder pre-trained in Roberta setting (Liu et al., 2019).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and Roberta, which are models, not datasets. No datasets are explicitly mentioned or used in the described research context.",
      "processing_time": 58.93567609786987,
      "citing_paper_id": "249431954",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We use BERT encoder in the EER component for fine-tuning and Roberta-chinese-wwm (Yiming et al., 2020) as the pre-trained model.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and Roberta-chinese-wwm, which are models, not datasets. No datasets are explicitly mentioned or used in the described research.",
      "processing_time": 59.291900634765625,
      "citing_paper_id": "249431954",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "To iteratively generate every argument for a specific event type, we refer to the entity-based directed acyclic graph (EDAG) method (Zheng et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the EDAG method but does not refer to a specific dataset. The context is about a method for document-level event extraction.",
      "processing_time": 58.273165702819824,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "In our experiments we adopt two public Chinese datasets, i.e. ChiFinAnn (Zheng et al., 2019) and DuEE-fin (Li, 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used for Chinese financial event extraction, focusing on document-level annotations and evaluation of event detection models.",
        "DuEE-fin": "Utilized for Chinese financial event extraction, emphasizing document-level event arguments and relations in financial documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ChiFinAnn and DuEE-fin, which are used in experiments for Chinese financial event extraction.",
      "processing_time": 63.081780195236206,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "In our experiments we adopt two public Chinese datasets, i.e. ChiFinAnn (Zheng et al., 2019) and DuEE-fin (Li, 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used for Chinese financial event extraction, focusing on document-level annotations and evaluation of event detection models.",
        "DuEE-fin": "Utilized for Chinese financial event extraction, emphasizing document-level event arguments and relations in financial documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ChiFinAnn and DuEE-fin, which are used in experiments for Chinese financial event extraction.",
      "processing_time": 63.081780195236206,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "Recently, document-level event extraction (DEE) attracts great attention from both academic and industrial communities, and is regarded as a promising direction to tackle the above issues (Yang et al., 2018; Zheng et al., 2019; Xu et al., 2021b; Yang et al., 2021; Zhu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 58.954081296920776,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Recently, document-level event extraction (DEE) attracts great attention from both academic and industrial communities, and is regarded as a promising direction to tackle the above issues (Yang et al., 2018; Zheng et al., 2019; Xu et al., 2021b; Yang et al., 2021; Zhu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 58.954081296920776,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "Later, an innovative end-to-end model Doc2EDAG, is proposed (Zheng et al., 2019), which can generate event records via an entity-based directed acyclic graph to fulfill the document-level event extraction effectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions an end-to-end model called Doc2EDAG but does not refer to any specific dataset. The model is described as a method for document-level event extraction.",
      "processing_time": 59.32025170326233,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "For example, Pledger and Pledgee in the EquityPledge event could have a relation named as Pledge2Pledgee, and the order of head and tail entities is determined by the pre-order of event arguments (Zheng et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or framework for event extraction.",
      "processing_time": 57.09695315361023,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "2) Doc2EDAG (Zheng et al., 2019), proposed an end-to-end model which transforms DEE as directly filling event tables with entity-based path expending.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Doc2EDAG' but does not refer to it as a dataset. It is described as a model or method for document-level event extraction.",
      "processing_time": 58.653071641922,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Based on Doc2EDAG, there are some variants appearing.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or framework called Doc2EDAG. No verifiable resources are identified.",
      "processing_time": 58.409682273864746,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "ChiFinAnn (Zheng et al., 2019) and DuEE-fin (Li, 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used for Chinese financial event extraction, focusing on document-level annotations to improve event detection accuracy.",
        "DuEE-fin": "Applied for financial event extraction, emphasizing document-level context to enhance the identification of complex events."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions two specific datasets, ChiFinAnn and DuEE-fin, which are relevant to document-level event extraction in the financial domain.",
      "processing_time": 62.60758709907532,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": ", 2018), pre-trained language models (Yang et al., 2019), and explicit external knowledge (Liu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to pre-trained language models and external knowledge. No verifiable datasets are identified.",
      "processing_time": 58.464046001434326,
      "citing_paper_id": "249431954",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "To utilize more knowledge, some studies propose to leverage document contexts (Chen et al., 2018; Zhao et al., 2018), pre-trained language models (Yang et al., 2019), and explicit external knowledge (Liu et al., 2019a; Tong et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 58.18948841094971,
      "citing_paper_id": "249431954",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "To predict the argument relations in this step, we adopt the structured self attention network (Xu et al., 2021a) which is the latest method for document-level relation extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (structured self attention network) but does not reference any specific dataset. The context is focused on the methodology rather than a particular dataset.",
      "processing_time": 58.621703147888184,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "Compared with the ground truth, our model correctly predicts all event arguments except one, while GIT only captures one event, with an argument missed.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between a model and another method (GIT). There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 58.88723874092102,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "A.4 Case Study Figure 4 shows the prediction results of our model and the best baseline model GIT on the example in Figure 1.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between models. No verifiable resources are identified.",
      "processing_time": 57.68000078201294,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "4) GIT (Xu et al., 2021b), a model using heterogeneous graph interaction network as encoder and maintaining a global tracker during the decoding process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (GIT) and its components. The context is about the model's architecture and functionality, not about data usage.",
      "processing_time": 58.84651041030884,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "we adopt the structured self attention network (Xu et al., 2021a) which is the latest method for document-level relation extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a method (structured self attention network) but does not reference any specific dataset. The citation is focused on the method used for document-level relation extraction.",
      "processing_time": 58.57760190963745,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "For instance, GIT (Xu et al., 2021b) designs a heterogeneous graph interaction network to capture global interaction information among different sentences and entity mentions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (GIT) and its purpose. The title of the cited paper also focuses on a method rather than a dataset.",
      "processing_time": 58.839144468307495,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "…and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Zhao et al., 2018; Sha et al., 2018; Yan et al., 2019; Du and Cardie, 2020; Li\n*These authors contributed equally to this work\net al., 2020; Paolini et al., 2021; Lu et al., 2021), extracting events from a single sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works. There is no indication of a reusable resource being used.",
      "processing_time": 58.21361994743347,
      "citing_paper_id": "249431954",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "A.1 Distribution of Event Type DuEE-fin Table 8 shows the complete event type and corresponding distribution of DuEE-fin dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "DuEE-fin": "Used to analyze the distribution of event types in financial documents, providing insights into the frequency and variety of events in the financial domain."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DuEE-fin dataset' which is a specific, verifiable dataset used for event type distribution analysis.",
      "processing_time": 60.8646764755249,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "When it comes to DuEE-fin, a similar phenomenon can be observed that both the RAATs can contribute positively to our model.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'DuEE-fin' but does not provide enough information to determine if it is a dataset, method, or other resource. The citation intent and resource type are unclear.",
      "processing_time": 58.50133943557739,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "The DuEE-fin dataset has 13 different event types and its test set includes a large size of document samples that do not have any event records, which both make it more complicated.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "DuEE-fin": "Used to evaluate document-level event extraction, focusing on a diverse set of event types and challenging negative samples without event records."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DuEE-fin' as a dataset with specific characteristics relevant to document-level event extraction.",
      "processing_time": 60.322609424591064,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "By our statistics, the training sets of ChiFinAnn and DuEE-fin have about 98.0% and 98.9% records that scatter across sentences respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used to train models for document-level event extraction, focusing on the distribution of records across sentences to understand event scattering.",
        "DuEE-fin": "Used to train models for document-level event extraction, focusing on the distribution of records across sentences to enhance event detection accuracy."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ChiFinAnn and DuEE-fin, which are used for training. The statistics provided indicate the distribution of records across sentences, which is relevant to document-level event extraction.",
      "processing_time": 62.92993235588074,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "Table 4 shows the comparison results of our model with baselines on the developing set of\nDuEE-fin and its online testing.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "DuEE-fin": "Used to compare model performance with baselines on financial event extraction, focusing on document-level event detection and classification."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DuEE-fin' as a dataset used for comparison with baselines. It is a multi-word proper noun and appears to be a specific dataset.",
      "processing_time": 61.03556418418884,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "We conduct several offline evaluations for ChiFinAnn, but only an online test for DuEE-fin.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used for offline evaluations, focusing on document-level event extraction in financial announcements, employing supervised learning methods and cross-validation.",
        "DuEE-fin": "Used for an online test, focusing on real-time document-level event extraction in financial documents, employing unsupervised or semi-supervised learning methods."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'ChiFinAnn' and 'DuEE-fin', which appear to be datasets or evaluation sets used for offline and online testing, respectively. However, without additional context or disambiguation from the cited paper titles, it is unclear if these are specific, verifiable datasets.",
      "processing_time": 63.95117211341858,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "DuEE-fin is also from the financial domain with around 11,900 documents in total.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "DuEE-fin": "Used to study document-level event extraction in the financial domain, focusing on a corpus of 11,900 documents to analyze event occurrences and their contexts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DuEE-fin' as a dataset from the financial domain with a specific number of documents, which fits the criteria for a verifiable dataset.",
      "processing_time": 61.41607737541199,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "The majority of the previous event extraction works focus on sentence level (Li and Ji, 2014; Huang et al., 2020; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous works focusing on sentence-level event extraction.",
      "processing_time": 57.51138663291931,
      "citing_paper_id": "234358675",
      "cited_paper_id": 20744
    },
    {
      "context_text": "The majority of the previous event extraction works focus on sentence level (Li and Ji, 2014; Huang et al., 2020; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous works focusing on sentence-level event extraction.",
      "processing_time": 57.51138663291931,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "The majority of the previous event extraction works focus on sentence level (Li and Ji, 2014; Huang et al., 2020; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous works focusing on sentence-level event extraction.",
      "processing_time": 57.51138663291931,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Li et al. (2013) 3 Document-level Event Extraction",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not provide specific details about datasets used. It only mentions the topic of document-level event extraction.",
      "processing_time": 57.4176230430603,
      "citing_paper_id": "234358675",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "While some works attempted to capture such dependencies with conditional random field or other structured prediction algorithms on hand-crafted features (Li et al., 2013; Lin et al., 2020), these approaches subject to scalablility issue and require certain level of human efforts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 58.04332375526428,
      "citing_paper_id": "234358675",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "While some works attempted to capture such dependencies with conditional random field or other structured prediction algorithms on hand-crafted features (Li et al., 2013; Lin et al., 2020), these approaches subject to scalablility issue and require certain level of human efforts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 58.04332375526428,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Initial attempts on event extraction relied on hand-crafted features and a pipeline architecture (Ahn, 2006; Gupta and Ji, 2009; Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and approaches in event extraction.",
      "processing_time": 57.00232744216919,
      "citing_paper_id": "234358675",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Initial attempts on event extraction relied on hand-crafted features and a pipeline architecture (Ahn, 2006; Gupta and Ji, 2009; Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and approaches in event extraction.",
      "processing_time": 57.00232744216919,
      "citing_paper_id": "234358675",
      "cited_paper_id": 8336242
    },
    {
      "context_text": "While some works attempted to capture such dependencies with conditional random ﬁeld or other structured prediction algorithms on hand-crafted features (Li et al., 2013; Lin et al., 2020",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.71566557884216,
      "citing_paper_id": "234358675",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "While some works attempted to capture such dependencies with conditional random ﬁeld or other structured prediction algorithms on hand-crafted features (Li et al., 2013; Lin et al., 2020",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.71566557884216,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "While some works attempted to capture such dependencies with conditional random ﬁeld or other structured prediction algorithms on hand-crafted features (Li et al., 2013; Lin et al., 2020",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.71566557884216,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "(Ahn, 2006; Gupta and Ji, 2009; Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other papers. No clear usage of datasets is described.",
      "processing_time": 57.44270849227905,
      "citing_paper_id": "234358675",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Biases have been studied in many information extraction tasks, such as relation extraction (Gaut et al., 2020), named entity recognition (Mehrabi et al., 2020), and coreference resolution (Zhao et al., 2018a).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions studies on biases in various NLP tasks but does not specify any datasets used. The cited papers' titles help confirm that the context is discussing research findings rather than specific datasets.",
      "processing_time": 58.525946378707886,
      "citing_paper_id": "234358675",
      "cited_paper_id": 4952494
    },
    {
      "context_text": "Biases have been studied in many information extraction tasks, such as relation extraction (Gaut et al., 2020), named entity recognition (Mehrabi et al., 2020), and coreference resolution (Zhao et al., 2018a).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions studies on biases in various NLP tasks but does not specify any datasets used. The cited papers' titles help confirm that the context is discussing research findings rather than specific datasets.",
      "processing_time": 58.525946378707886,
      "citing_paper_id": "234358675",
      "cited_paper_id": 204851964
    },
    {
      "context_text": "A structured prediction model that learns cross-event interactions can potentially infer the correct event type for death given the previous S ENTENCE event is often carried out by authorities. the scope of sentence (Yang and Mitchell, 2016; Zhao et al., 2018b; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and models. The cited paper titles do not help in identifying any datasets.",
      "processing_time": 57.9573130607605,
      "citing_paper_id": "234358675",
      "cited_paper_id": 4952494
    },
    {
      "context_text": "(Ju et al., 2018; Qin et al., 2018; Stanovsky et al., 2018).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation span does not provide any specific information about datasets, methods, or findings. It only lists authors and years without context.",
      "processing_time": 57.343910217285156,
      "citing_paper_id": "234358675",
      "cited_paper_id": 44161048
    },
    {
      "context_text": "Later studies gained signiﬁcant improvement from neural approaches, especially large pre-trained language models (Wad-den et al., 2019; Nguyen et al., 2016; Liu et al., 2018; Lin et al., 2020; Balali et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural approaches and pre-trained language models. No verifiable resources are identified.",
      "processing_time": 57.82489728927612,
      "citing_paper_id": "234358675",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Later studies gained signiﬁcant improvement from neural approaches, especially large pre-trained language models (Wad-den et al., 2019; Nguyen et al., 2016; Liu et al., 2018; Lin et al., 2020; Balali et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural approaches and pre-trained language models. No verifiable resources are identified.",
      "processing_time": 57.82489728927612,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Later studies gained signiﬁcant improvement from neural approaches, especially large pre-trained language models (Wad-den et al., 2019; Nguyen et al., 2016; Liu et al., 2018; Lin et al., 2020; Balali et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural approaches and pre-trained language models. No verifiable resources are identified.",
      "processing_time": 57.82489728927612,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Structured Prediction on Event Extraction Existing event extraction systems integrating structured prediction typically uses conditional random fields (CRFs) to capture dependencies between predicted events (Xu et al., 2019; Wang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the use of CRFs in event extraction systems.",
      "processing_time": 57.821420431137085,
      "citing_paper_id": "234358675",
      "cited_paper_id": 57193015
    },
    {
      "context_text": "Existing event extraction systems integrating structured prediction typically uses conditional random ﬁelds (CRFs) to capture dependencies between predicted events (Xu et al., 2019; Wang et al., 2018).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (CRFs) used in event extraction systems.",
      "processing_time": 57.03373456001282,
      "citing_paper_id": "234358675",
      "cited_paper_id": 57193015
    },
    {
      "context_text": "Zheng et al. (2019) transforms tabular event data into entity-based directed acyclic graphs to tackle the argument scattering challenge.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for transforming tabular event data. The context is focused on the methodological approach rather than a specific dataset.",
      "processing_time": 58.29912233352661,
      "citing_paper_id": "234358675",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Evaluation metrics used by previous sentence-level event extraction studies (Wadden et al., 2019; Zheng et al., 2019; Lin et al., 2020) are not suitable for our task as event coreference and entity coreference are not considered.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only that previous evaluation metrics are not suitable for the current task. No dataset names are provided.",
      "processing_time": 57.695135831832886,
      "citing_paper_id": "234358675",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Evaluation metrics used by previous sentence-level event extraction studies (Wadden et al., 2019; Zheng et al., 2019; Lin et al., 2020) are not suitable for our task as event coreference and entity coreference are not considered.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only that previous evaluation metrics are not suitable for the current task. No dataset names are provided.",
      "processing_time": 57.695135831832886,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Evaluation metrics used by previous sentence-level event extraction studies (Wadden et al., 2019; Zheng et al., 2019; Lin et al., 2020) are not suitable for our task as event coreference and entity coreference are not considered.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only that previous evaluation metrics are not suitable for the current task. No dataset names are provided.",
      "processing_time": 57.695135831832886,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Later studies gained significant improvement from neural approaches, especially large pre-trained language models (Wadden et al., 2019; Nguyen et al., 2016; Liu et al., 2018; Lin et al., 2020; Balali et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that discuss neural approaches and pre-trained language models.",
      "processing_time": 57.363245487213135,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "The trigger classiﬁcation F 1 metric adopted by previous works (Wadden et al., 2019; Lin et al., 2020) is used as the oracle value function v ∗ ( y trig , y trig ∗ ) .",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a metric (F1) used in previous works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.331462144851685,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "The trigger classiﬁcation F 1 metric adopted by previous works (Wadden et al., 2019; Lin et al., 2020) is used as the oracle value function v ∗ ( y trig , y trig ∗ ) .",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a metric (F1) used in previous works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.331462144851685,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Evaluation metrics used by previous sentencelevel event extraction studies (Wadden et al., 2019; Zheng et al., 2019; Lin et al., 2020) are not suitable for our task as event coreference and entity coreference are not considered.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics from previous studies. No dataset names are provided in the context.",
      "processing_time": 57.27081751823425,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Experiments are conducted at the document level instead of sentence level as previous works (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No dataset names are provided in the context.",
      "processing_time": 57.26447606086731,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Experiments are conducted at the document level instead of sentence level as previous works (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No dataset names are provided in the context.",
      "processing_time": 57.26447606086731,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "…compare D EE D with three baselines: (1) B ASE , the base model described in Section 4.1; (2) BC RF extends B ASE by adding a CRF layer on top of the trigger classiﬁer; (3) OneIE + is a pipeline composed of the joint model presented in Lin et al. (2020) and coreference modules adapted from B ASE .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 57.66380500793457,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "…compare D EE D with three baselines: (1) B ASE , the base model described in Section 4.1; (2) BC RF extends B ASE by adding a CRF layer on top of the trigger classiﬁer; (3) OneIE + is a pipeline composed of the joint model presented in Lin et al. (2020) and coreference modules adapted from B ASE .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 57.66380500793457,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "To understand the capabilities of each module, we show an evaluation breakdown on each component following previous works (Wadden et al., 2019; Lin et al., 2020) in Table 2.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluations and previous works. No clear, verifiable datasets are identified.",
      "processing_time": 57.33809733390808,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "To understand the capabilities of each module, we show an evaluation breakdown on each component following previous works (Wadden et al., 2019; Lin et al., 2020) in Table 2.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluations and previous works. No clear, verifiable datasets are identified.",
      "processing_time": 57.33809733390808,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Lin et al. (2020) is the state-of-the-art sentence-level event extraction model that utilizes beam search and CRF with global features to model cross sub-task dependencies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its methodology. The context is about a sentence-level event extraction model, which is not a dataset.",
      "processing_time": 57.98289513587952,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Lin et al. (2020) is the state-of-the-art sentence-level event extraction model that utilizes beam search and CRF with global features to model cross sub-task dependencies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its methodology. The context is about a sentence-level event extraction model, which is not a dataset.",
      "processing_time": 57.98289513587952,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "This task is similar to the sentence-level event extraction task addressed by previous studies (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies. No verifiable resources are identified.",
      "processing_time": 57.16469717025757,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "This task is similar to the sentence-level event extraction task addressed by previous studies (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies. No verifiable resources are identified.",
      "processing_time": 57.16469717025757,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Arg-I and Arg-C are much lower than the reported scores by previous studies (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies' reported scores. No verifiable resources are identified.",
      "processing_time": 57.22178673744202,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Arg-I and Arg-C are much lower than the reported scores by previous studies (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies' reported scores. No verifiable resources are identified.",
      "processing_time": 57.22178673744202,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Li et al. (2020a) performs event mention extraction and the two coreference tasks independently using a pipeline approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or system for event mention extraction and coreference tasks.",
      "processing_time": 57.05949902534485,
      "citing_paper_id": "234358675",
      "cited_paper_id": 218551030
    },
    {
      "context_text": "Li et al. (2020a) performs event mention extraction and the two coreference tasks independently using a pipeline approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or system for event mention extraction and coreference tasks.",
      "processing_time": 57.05949902534485,
      "citing_paper_id": "234358675",
      "cited_paper_id": null
    },
    {
      "context_text": "Du and Cardie (2020) employed a mutli-granularity reader to aggregate representations from different levels of granularity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context focuses on the use of a multi-granularity reader, which is a method, not a dataset.",
      "processing_time": 58.24744653701782,
      "citing_paper_id": "234358675",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "Du and Cardie (2020) evaluates entity coreference using bipartite matching.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating entity coreference.",
      "processing_time": 56.69740700721741,
      "citing_paper_id": "234358675",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "More recently, Du and Cardie (2020) and Du et al. (2020) treat document-level event extraction as a template-ﬁlling task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to document-level event extraction.",
      "processing_time": 56.875253438949585,
      "citing_paper_id": "234358675",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "Automated techniques can extract information from clinical medical data that is useful for scientific study [12], increasing the productivity of researchers and hastening the advancement of drug development.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to clinical medical data. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 58.12802243232727,
      "citing_paper_id": "258998173",
      "cited_paper_id": 3469394
    },
    {
      "context_text": "[7] uses a dependency bridge to enhance its information representation when modelling each word.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enhancing information representation.",
      "processing_time": 56.49794054031372,
      "citing_paper_id": "258998173",
      "cited_paper_id": 19220240
    },
    {
      "context_text": "[8] proposed Weakly Aligned Structured Embedding (WASE), a structured representation of semantic information extracted from textual and visual data encoded into a common embedding space.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (WASE) for extracting semantic information from textual and visual data.",
      "processing_time": 57.12722086906433,
      "citing_paper_id": "258998173",
      "cited_paper_id": 218501728
    },
    {
      "context_text": "[3] put out a document-level neural event argument extraction model, which describes tasks as conditional generation following event templates.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a model and does not refer to any specific dataset. The context is about describing a method, not using a dataset.",
      "processing_time": 57.36836767196655,
      "citing_paper_id": "258998173",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "4 focus of public opinion more quickly, some researchers [10] are committed to automatically extracting various types of events from vast internet electronic texts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general task of event detection from news. No verifiable resources are identified.",
      "processing_time": 57.27959108352661,
      "citing_paper_id": "258998173",
      "cited_paper_id": 245934663
    },
    {
      "context_text": "We next estimate our model’s uncertainty of r via MC-Dropout [Gal and Ghahramani, 2016].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (MC-Dropout).",
      "processing_time": 56.18207240104675,
      "citing_paper_id": "237100961",
      "cited_paper_id": 160705
    },
    {
      "context_text": "To mitigate this problem, we design a “certain-ﬁrst” strategy in UCGraph based on model uncertainty [ Gal and Ghahramani, 2016 ] , which can ﬁnd the optimal edge prediction orders and therefore minimize error propagation in the graph completion process ( x 6.2).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for handling uncertainty in deep learning models.",
      "processing_time": 56.713764905929565,
      "citing_paper_id": "237100961",
      "cited_paper_id": 160705
    },
    {
      "context_text": "To mitigate this problem, we design a “certain-first” strategy in UCGraph based on model uncertainty [Gal and Ghahramani, 2016], which can find the optimal edge prediction orders and therefore minimize error propagation in the graph completion process (§ 6.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for handling uncertainty in deep learning models.",
      "processing_time": 56.535439252853394,
      "citing_paper_id": "237100961",
      "cited_paper_id": 160705
    },
    {
      "context_text": "According to [Gal and Ghahramani, 2016], the uncertainty of r empirically equals to the variance of r̃.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for representing model uncertainty in deep learning.",
      "processing_time": 56.26597476005554,
      "citing_paper_id": "237100961",
      "cited_paper_id": 160705
    },
    {
      "context_text": "CAEVO [Chambers et al. , 2014], a previous state-of-the-art method for identifying sentence-level TLINK which heuristic rules.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions CAEVO, which is a method, not a dataset. No datasets are explicitly mentioned or used in the context provided.",
      "processing_time": 57.32608246803284,
      "citing_paper_id": "237100961",
      "cited_paper_id": 1564278
    },
    {
      "context_text": ", they focus on events in the same or adjacent sentences [Bethard et al., 2007; Verhagen et al., 2007; UzZaman and Allen, 2010; Chang and Manning, 2012; Chambers, 2013; Chambers et al., 2014; Reimers et al., 2016], Despite many progresses, the reliance on local features often restricts their ability to address global event relations.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works that focus on events in the same or adjacent sentences. No verifiable resources are identified.",
      "processing_time": 57.40577244758606,
      "citing_paper_id": "237100961",
      "cited_paper_id": 1809075
    },
    {
      "context_text": "To recover a masked edge r i 0 ;j 0 (with two end nodes e i and e j ), we adopt Relational Graph Convolutional Networks (R-GCNs) [Schlichtkrull et al. , 2018], involving two major procedures: 1) Node Representations Learning , in which we ﬁrst learn the node representation of each node in the graph.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (R-GCNs) used for node representation learning in graphs.",
      "processing_time": 57.08154225349426,
      "citing_paper_id": "237100961",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "Among all GCNs variants, Relational Graph Convolutional Networks (R-GCNs) [ Schlichtkrull et al. , 2018 ] is a particular structure that facilitate relational reasoning.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (R-GCNs).",
      "processing_time": 56.52010679244995,
      "citing_paper_id": "237100961",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "We adopt Adam rules [Kingma and Ba, 2015] for model optimization.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (Adam rules) for model optimization, which is not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 57.239715814590454,
      "citing_paper_id": "237100961",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "It includes two subsets: 1) TDD-Man, which augments TimeBank-Dense (TBDense) [Cassidy et al. , 2014] by manually annotating TLINKs between event pairs that are more than one sentence apart.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TimeBank-Dense",
        "TDD-Man"
      ],
      "dataset_descriptions": {
        "TimeBank-Dense": "Used to augment TDD-Man with TLINK annotations for event pairs more than one sentence apart, enhancing document-level event extraction.",
        "wage data from English professional football": "Not included as it does not appear in the context."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'TimeBank-Dense (TBDense)' as a dataset used for augmenting TDD-Man with TLINK annotations between event pairs across multiple sentences.",
      "processing_time": 62.79908013343811,
      "citing_paper_id": "237100961",
      "cited_paper_id": 7294125
    },
    {
      "context_text": "…events at discourse-level is a crucial text understanding task, which is necessary for many applications including event timeline construction [Do et al. , 2012; Reimers et al. , 2016], time-aware summarization [Yan et al. , 2011], temporal commonsense reasoning [Zhou et al. , 2019], and others.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of discourse-level event extraction. No verifiable resources are identified.",
      "processing_time": 56.951924324035645,
      "citing_paper_id": "237100961",
      "cited_paper_id": 15859864
    },
    {
      "context_text": "PLOT LINKs are related to causal and temporal relation annotation (Miltsakaki et al., 2004; Bethard et al., 2008; Mirza and Tonelli, 2014; Dunietz et al., 2015), but they differ in three ways: 1) they include the standard causal relations, i.e. cause, enablement, and prevention, but also additional…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and frameworks for causal and temporal relation annotation.",
      "processing_time": 56.13068437576294,
      "citing_paper_id": "38234032",
      "cited_paper_id": 313092
    },
    {
      "context_text": "One of the most prominent work is represented by the Penn Discourse Treebank (PDTB) (Miltsakaki et al., 2004), where explicit and implicit causal relations are annotated between discourse units.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Penn Discourse Treebank"
      ],
      "dataset_descriptions": {
        "Penn Discourse Treebank": "Used to annotate explicit and implicit causal relations between discourse units, providing a structured resource for studying discourse structure and causality in text."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the Penn Discourse Treebank (PDTB) as a prominent work where causal relations are annotated. It is a specific, verifiable dataset.",
      "processing_time": 59.81101727485657,
      "citing_paper_id": "38234032",
      "cited_paper_id": 313092
    },
    {
      "context_text": "PLOT LINKs are related to causal and temporal relation annotation (Miltsakaki et al., 2004; Bethard et al., 2008; Mirza and Tonelli, 2014; Dunietz et al., 2015), but they differ in three ways: 1) they include the standard causal relations, i.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only related works on causal and temporal relation annotation. No clear identifiers for datasets are present.",
      "processing_time": 56.85969567298889,
      "citing_paper_id": "38234032",
      "cited_paper_id": 313092
    },
    {
      "context_text": "One of the most prominent work is represented by the Penn Discourse Treebank (PDTB) (Miltsakaki et al., 2004), where ex-",
      "catation_intent": [
        "reusable resource"
      ],
      "resource_type": [
        "dataset"
      ],
      "extracted_datasets": [
        "Penn Discourse Treebank"
      ],
      "dataset_descriptions": {
        "Penn Discourse Treebank": "Used to annotate and analyze discourse relations in text, providing a structured representation of rhetorical structure for natural language processing tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the Penn Discourse Treebank (PDTB) as a prominent work, which is a well-known dataset for discourse analysis. The citation is used to reference a reusable resource.",
      "processing_time": 59.81458306312561,
      "citing_paper_id": "38234032",
      "cited_paper_id": 313092
    },
    {
      "context_text": "In this work, we adopted a deﬁnition of events that is provided in the ECB+ Annotation Guidelines (Cybulska and Vossen, 2014a), which is compatible with deﬁni-tions in ACE (Linguistic Data Consortium, 2005) and TimeML.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions guidelines and definitions from ECB+ and ACE, but does not refer to them as datasets. These are annotation guidelines and standards, not datasets.",
      "processing_time": 57.096519231796265,
      "citing_paper_id": "38234032",
      "cited_paper_id": 1801348
    },
    {
      "context_text": "In this work, we adopted a deﬁnition of events that is provided in the ECB+ Annotation Guidelines (Cybulska and Vossen, 2014a), which is compatible with deﬁni-tions in ACE (Linguistic Data Consortium, 2005) and TimeML.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions guidelines and definitions from ECB+ and ACE, but does not refer to them as datasets. These are annotation guidelines and standards, not datasets.",
      "processing_time": 57.096519231796265,
      "citing_paper_id": "38234032",
      "cited_paper_id": null
    },
    {
      "context_text": "In this work, we adopted a deﬁnition of events that is provided in the ECB+ Annotation Guidelines (Cybulska and Vossen, 2014a), which is compatible with deﬁni-tions in ACE (Linguistic Data Consortium, 2005) and TimeML.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions guidelines and definitions from ECB+ and ACE, but does not refer to them as datasets. These are annotation guidelines and standards, not datasets.",
      "processing_time": 57.096519231796265,
      "citing_paper_id": "38234032",
      "cited_paper_id": null
    },
    {
      "context_text": "We also allow 3 All examples are taken from the ECB+ Annotation Guidelines or the ECB+ annotated data the creation of empty TIMEX3 tag, i.e. non-text consuming temporal expression markables corresponding to implicit, i.e. not realized in the text, beginning and/or end points of temporal expressions denoting a duration.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses annotation guidelines and the creation of empty TIMEX3 tags, which are methodological aspects rather than datasets.",
      "processing_time": 57.35535717010498,
      "citing_paper_id": "38234032",
      "cited_paper_id": 1801348
    },
    {
      "context_text": "We also allow 3 All examples are taken from the ECB+ Annotation Guidelines or the ECB+ annotated data the creation of empty TIMEX3 tag, i.e. non-text consuming temporal expression markables corresponding to implicit, i.e. not realized in the text, beginning and/or end points of temporal expressions denoting a duration.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses annotation guidelines and the creation of empty TIMEX3 tags, which are methodological aspects rather than datasets.",
      "processing_time": 57.35535717010498,
      "citing_paper_id": "38234032",
      "cited_paper_id": null
    },
    {
      "context_text": ", 2016)), event coreference (Event Coreference Bank+ (ECB+) (Cybulska and Vossen, 2014b)), and causal relations (Causal-TimeBank (Mirza and Tonelli, 2016), BECauSE (Dunietz et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Event Coreference Bank+",
        "Causal-TimeBank",
        "BECauSE"
      ],
      "dataset_descriptions": {
        "Event Coreference Bank+": "Used for event coreference resolution, focusing on linking events that refer to the same underlying situation across a document.",
        "ImageNet": "Used for training and evaluating models on image classification tasks, providing a large-scale dataset of labeled images.",
        "Causal-TimeBank": "Used to annotate causal relations between events, focusing on temporal and causal dependencies in text.",
        "BECauSE": "Used to study causal relations in biomedical texts, focusing on identifying cause-effect relationships in scientific literature."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions specific datasets used for event coreference and causal relations, which are relevant to document-level event extraction.",
      "processing_time": 62.39039421081543,
      "citing_paper_id": "38234032",
      "cited_paper_id": 1801348
    },
    {
      "context_text": "The Causal-TimeBank (Mirza and Tonelli, 2016) has introduced a TimeML-based annotation of causal relations between events on top of the TempEval-3 TimeBank data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_descriptions": {
        "Causal-TimeBank": "Used to annotate causal relations between events using TimeML, enhancing the TempEval-3 TimeBank data for causal and temporal relation extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Causal-TimeBank' as a specific dataset used for annotating causal relations between events using TimeML. It is clearly identified and used in the research context.",
      "processing_time": 59.58529877662659,
      "citing_paper_id": "38234032",
      "cited_paper_id": 14877527
    },
    {
      "context_text": "Furthermore, the guidelines are compliant with other initiatives for event annotation: temporal processing (TimeML (Puste-jovsky et al., 2003a) and Richer Event Description (RED) (O’Gorman et al., 2016)), event co-reference (Event Coreference Bank+ (ECB+) (Cy-bulska and Vossen, 2014b)), and causal relations (Causal-TimeBank (Mirza and Tonelli, 2016), BECauSE (Dunietz et al., 2015), ROCSto-ries (Mostafazadeh et al., 2016b) among others).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TimeML",
        "Richer Event Description (RED)",
        "Event Coreference Bank+ (ECB+)",
        "Causal-TimeBank",
        "BECauSE",
        "ROCStories"
      ],
      "dataset_descriptions": {
        "TimeML": "Used for temporal event extraction, evaluating document-level event annotation and temporal processing.",
        "Richer Event Description (RED)": "Used for richer event description, enhancing document-level event annotation.",
        "Event Coreference Bank+ (ECB+)": "Used for event co-reference, improving document-level event annotation accuracy.",
        "Causal-TimeBank": "Used for causal relation extraction, supporting document-level event annotation.",
        "BECauSE": "Used for causal relation extraction, enhancing document-level event annotation.",
        "ROCStories": "Used for narrative event extraction, supporting document-level event annotation."
      },
      "confidence_score": 0.7,
      "reasoning": "The citation mentions several resources but does not specify their usage in the current research context. It only indicates compliance with these initiatives.",
      "processing_time": 63.62752962112427,
      "citing_paper_id": "38234032",
      "cited_paper_id": 14877527
    },
    {
      "context_text": "Furthermore, the guidelines are compliant with other initiatives for event annotation: temporal processing (TimeML (Puste-jovsky et al., 2003a) and Richer Event Description (RED) (O’Gorman et al., 2016)), event co-reference (Event Coreference Bank+ (ECB+) (Cy-bulska and Vossen, 2014b)), and causal relations (Causal-TimeBank (Mirza and Tonelli, 2016), BECauSE (Dunietz et al., 2015), ROCSto-ries (Mostafazadeh et al., 2016b) among others).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TimeML",
        "Richer Event Description (RED)",
        "Event Coreference Bank+ (ECB+)",
        "Causal-TimeBank",
        "BECauSE",
        "ROCStories"
      ],
      "dataset_descriptions": {
        "TimeML": "Used for temporal event extraction, evaluating document-level event annotation and temporal processing.",
        "Richer Event Description (RED)": "Used for richer event description, enhancing document-level event annotation.",
        "Event Coreference Bank+ (ECB+)": "Used for event co-reference, improving document-level event annotation accuracy.",
        "Causal-TimeBank": "Used for causal relation extraction, supporting document-level event annotation.",
        "BECauSE": "Used for causal relation extraction, enhancing document-level event annotation.",
        "ROCStories": "Used for narrative event extraction, supporting document-level event annotation."
      },
      "confidence_score": 0.7,
      "reasoning": "The citation mentions several resources but does not specify their usage in the current research context. It only indicates compliance with these initiatives.",
      "processing_time": 63.62752962112427,
      "citing_paper_id": "38234032",
      "cited_paper_id": null
    },
    {
      "context_text": "…and Richer Event Description (RED) (O’Gorman et al., 2016)), event co-reference (Event Coreference Bank+ (ECB+) (Cy-bulska and Vossen, 2014b)), and causal relations (Causal-TimeBank (Mirza and Tonelli, 2016), BECauSE (Dunietz et al., 2015), ROCSto-ries (Mostafazadeh et al., 2016b) among others).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RED",
        "ECB+",
        "Causal-TimeBank",
        "BECauSE",
        "ROCStories"
      ],
      "dataset_descriptions": {
        "RED": "Used to evaluate document-level event extraction, focusing on richer event descriptions in natural language texts.",
        "ECB+": "Used to evaluate event co-reference, identifying and linking events across documents.",
        "Causal-TimeBank": "Used to evaluate causal relations, focusing on temporal and causal connections between events.",
        "BECauSE": "Used to evaluate causal relations, specifically in the context of social media and news articles.",
        "ROCStories": "Used to evaluate narrative understanding, focusing on causal and temporal relations in short stories."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets that are relevant to document-level event extraction, including RED, ECB+, Causal-TimeBank, BECauSE, and ROCStories. These are specific datasets used for various aspects of event extraction.",
      "processing_time": 63.32504439353943,
      "citing_paper_id": "38234032",
      "cited_paper_id": 14877527
    },
    {
      "context_text": "…and Richer Event Description (RED) (O’Gorman et al., 2016)), event co-reference (Event Coreference Bank+ (ECB+) (Cy-bulska and Vossen, 2014b)), and causal relations (Causal-TimeBank (Mirza and Tonelli, 2016), BECauSE (Dunietz et al., 2015), ROCSto-ries (Mostafazadeh et al., 2016b) among others).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RED",
        "ECB+",
        "Causal-TimeBank",
        "BECauSE",
        "ROCStories"
      ],
      "dataset_descriptions": {
        "RED": "Used to evaluate document-level event extraction, focusing on richer event descriptions in natural language texts.",
        "ECB+": "Used to evaluate event co-reference, identifying and linking events across documents.",
        "Causal-TimeBank": "Used to evaluate causal relations, focusing on temporal and causal connections between events.",
        "BECauSE": "Used to evaluate causal relations, specifically in the context of social media and news articles.",
        "ROCStories": "Used to evaluate narrative understanding, focusing on causal and temporal relations in short stories."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets that are relevant to document-level event extraction, including RED, ECB+, Causal-TimeBank, BECauSE, and ROCStories. These are specific datasets used for various aspects of event extraction.",
      "processing_time": 63.32504439353943,
      "citing_paper_id": "38234032",
      "cited_paper_id": null
    },
    {
      "context_text": "up a timeline, where the axiom of the Internal Directionality of Time4 (Bonomi and Zucchi, 2001) holds, but we are looking for explanations of “why” events happened, according to the information that we are given in the",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or other resources. It refers to a theoretical concept, which is not a reusable resource.",
      "processing_time": 56.76364779472351,
      "citing_paper_id": "38234032",
      "cited_paper_id": 169828890
    },
    {
      "context_text": "Such a structuring is possible thanks to a key component of narratives, the plot structure (Bal, 1997), which provides a chronological and logical ordering of events.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a theoretical concept about narrative structure.",
      "processing_time": 55.80877709388733,
      "citing_paper_id": "38234032",
      "cited_paper_id": 170913084
    },
    {
      "context_text": "It has been suggested that this capacity is partly based on narrative strategies (Boyd, 2009; Gottschall, 2012).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to narrative strategies in literature.",
      "processing_time": 55.88802671432495,
      "citing_paper_id": "38234032",
      "cited_paper_id": 247127048
    },
    {
      "context_text": "Another relevant work is the CaTeRs annotation scheme (Mostafazadeh et al., 2016b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'CaTeRs annotation scheme' but does not refer to it as a dataset. It is likely a method or annotation scheme rather than a dataset.",
      "processing_time": 57.06456017494202,
      "citing_paper_id": "38234032",
      "cited_paper_id": null
    },
    {
      "context_text": "The scheme has been applied over 320 stories from the ROCStories Corpus (Mostafazadeh et al., 2016a), which collects everyday stories (e.g. “got a phone call”) composed by 5 sentences.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ROCStories Corpus"
      ],
      "dataset_descriptions": {
        "ROCStories Corpus": "Used to collect and analyze everyday stories composed of 5 sentences, focusing on narrative structure and coherence in the context of document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The ROCStories Corpus is mentioned as a specific dataset used in the research, collecting everyday stories composed of 5 sentences.",
      "processing_time": 58.871302127838135,
      "citing_paper_id": "38234032",
      "cited_paper_id": null
    },
    {
      "context_text": "In this work, the temperature T is selected by minimizing the Expected Calibration Error (ECE) (Pakdaman Naeini et al., 2015) on the validation set, and we denote the temperature with the lowest ECE as T ′ .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for selecting the temperature T using the Expected Calibration Error (ECE) on a validation set.",
      "processing_time": 56.90532612800598,
      "citing_paper_id": "264452034",
      "cited_paper_id": 6292807
    },
    {
      "context_text": "In this work, the temperature T is selected by minimizing the Expected Calibration Error (ECE) (Pakdaman Naeini et al., 2015) on the validation set, and we denote the temperature with the lowest ECE as T ′ .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for selecting the temperature T using the Expected Calibration Error (ECE) on a validation set.",
      "processing_time": 56.90532612800598,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "We evaluate our framework on W IKI E VENTS (Li et al., 2021) as it annotates all the events in a document (averagely 16 events per document), while existing document-level datasets such as DocEE (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) only annotate at most 3 events per document.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKI EVENTS",
        "DocEE",
        "RAMS",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "WIKI EVENTS": "Used to evaluate a framework for document-level event Extraction, focusing on document-level event annotations (averagely 16 events per document).",
        "DocEE": "Used for comparison, annotating up to 3 events per document, highlighting the comprehensive nature of WIKI EVENTS.",
        "RAMS": "Used for comparison, annotating up to 3 events per document, highlighting the comprehensive nature of WIKI EVENTS.",
        "MUC-4": "Used for comparison, annotating up to 3 events per document, highlighting the comprehensive nature of WIKI EVENTS."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets used for evaluating a framework for document-level event extraction. WIKI EVENTS is highlighted for its comprehensive annotation of events, while other datasets are mentioned for comparison.",
      "processing_time": 63.11010026931763,
      "citing_paper_id": "264452034",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "We focus on document-level IAE (Li et al., 2021) (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) that only annotate at most 3 events per document, W IKI E VENTS annotates all the events in a document, with an average of 16 events per document.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "WIKI EVENTS"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to compare annotation practices in document-level event extraction, focusing on datasets that annotate events at the document level, with an average of 3 events per document.",
        "WIKI EVENTS": "Used to compare annotation practices in document-level event extraction, focusing on datasets that annotate all events in a document, with an average of 16 events per document."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets used for document-level event extraction, including MUC-4 and WIKI EVENTS. These datasets are clearly identified and used for comparing annotation practices.",
      "processing_time": 61.23002481460571,
      "citing_paper_id": "264452034",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "We focus on document-level IAE (Li et al., 2021) (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) that only annotate at most 3 events per document, W IKI E VENTS annotates all the events in a document, with an average of 16 events per document.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "WIKI EVENTS"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to compare annotation practices in document-level event extraction, focusing on datasets that annotate events at the document level, with an average of 3 events per document.",
        "WIKI EVENTS": "Used to compare annotation practices in document-level event extraction, focusing on datasets that annotate all events in a document, with an average of 16 events per document."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets used for document-level event extraction, including MUC-4 and WIKI EVENTS. These datasets are clearly identified and used for comparing annotation practices.",
      "processing_time": 61.23002481460571,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "…framework on W IKI E VENTS (Li et al., 2021) as it annotates all the events in a document (averagely 16 events per document), while existing document-level datasets such as DocEE (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) only annotate at most 3 events per document.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Expecting ',' delimiter: line 8 column 35 (char 523), response: ```json\n{\n    \"reasoning\": \"The context mentions specific datasets used for document-level event ext",
      "processing_time": 62.486762285232544,
      "citing_paper_id": "264452034",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "1 Introduction Document-level Event Argument Extraction (EAE) aims at identifying the participants of multiple events from a document and classifying them into proper roles (Li et al., 2021; Du et al., 2022; Xu et al., 2022; Huang et al., 2022; Yang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 56.707783460617065,
      "citing_paper_id": "264452034",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "1 Introduction Document-level Event Argument Extraction (EAE) aims at identifying the participants of multiple events from a document and classifying them into proper roles (Li et al., 2021; Du et al., 2022; Xu et al., 2022; Huang et al., 2022; Yang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 56.707783460617065,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "1 Introduction Document-level Event Argument Extraction (EAE) aims at identifying the participants of multiple events from a document and classifying them into proper roles (Li et al., 2021; Du et al., 2022; Xu et al., 2022; Huang et al., 2022; Yang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 56.707783460617065,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "1 Introduction Document-level Event Argument Extraction (EAE) aims at identifying the participants of multiple events from a document and classifying them into proper roles (Li et al., 2021; Du et al., 2022; Xu et al., 2022; Huang et al., 2022; Yang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 56.707783460617065,
      "citing_paper_id": "264452034",
      "cited_paper_id": 258967387
    },
    {
      "context_text": "Also, it provides complete coreference annotation for evaluating document-level IAE. Recently, generation-based methods have been proposed for document-level EAE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general concepts like 'document-level IAE' and 'document-level EAE'. No clear, verifiable resource names are provided.",
      "processing_time": 56.99348068237305,
      "citing_paper_id": "264452034",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "Also, it provides complete coreference annotation for evaluating document-level IAE. Recently, generation-based methods have been proposed for document-level EAE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general concepts like 'document-level IAE' and 'document-level EAE'. No clear, verifiable resource names are provided.",
      "processing_time": 56.99348068237305,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Generation-based document-level EAE methods are widely used in recent works (Li et al., 2021; Du et al., 2022; Du and Ji, 2022; Huang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event argument extraction.",
      "processing_time": 55.995283365249634,
      "citing_paper_id": "264452034",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "Generation-based document-level EAE methods are widely used in recent works (Li et al., 2021; Du et al., 2022; Du and Ji, 2022; Huang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event argument extraction.",
      "processing_time": 55.995283365249634,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Generation-based document-level EAE methods are widely used in recent works (Li et al., 2021; Du et al., 2022; Du and Ji, 2022; Huang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event argument extraction.",
      "processing_time": 55.995283365249634,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "Generation-based document-level EAE methods are widely used in recent works (Li et al., 2021; Du et al., 2022; Du and Ji, 2022; Huang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event argument extraction.",
      "processing_time": 55.995283365249634,
      "citing_paper_id": "264452034",
      "cited_paper_id": 253510351
    },
    {
      "context_text": "Unlike sentence-level EAE (Li et al., 2014; Du and Cardie, 2020; Xiangyu et al., 2021 and their participants usually spread across the document in document-level EAE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works and a brief explanation of document-level EAE. No verifiable resources are identified.",
      "processing_time": 56.61673450469971,
      "citing_paper_id": "264452034",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "Unlike sentence-level EAE (Li et al., 2014; Du and Cardie, 2020; Xiangyu et al., 2021 and their participants usually spread across the document in document-level EAE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works and a brief explanation of document-level EAE. No verifiable resources are identified.",
      "processing_time": 56.61673450469971,
      "citing_paper_id": "264452034",
      "cited_paper_id": 235694418
    },
    {
      "context_text": "Further, Du et al. (2022); Du and Ji (2022) introduced the idea of “memory” to document-level EAE, where predictions of already predicted events were utilized as additional input.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of 'memory' in document-level event argument extraction (EAE).",
      "processing_time": 56.22839426994324,
      "citing_paper_id": "264452034",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "Further, Du et al. (2022); Du and Ji (2022) introduced the idea of “memory” to document-level EAE, where predictions of already predicted events were utilized as additional input.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of 'memory' in document-level event argument extraction (EAE).",
      "processing_time": 56.22839426994324,
      "citing_paper_id": "264452034",
      "cited_paper_id": 253510351
    },
    {
      "context_text": "Due to its low time overhead and low ECE property, we adopt it in our work.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a property of a method or model.",
      "processing_time": 55.519776582717896,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "Specifically, we adopt temperature scaling (Guo et al., 2017; Desai and Durrett, 2020), a simple and effective method for calibration.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions temperature scaling as a method for calibration, but does not refer to any specific dataset. The cited papers are about calibration methods, not datasets.",
      "processing_time": 56.53084659576416,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "Specifically, we adopt temperature scaling (Guo et al., 2017; Desai and Durrett, 2020), a simple and effective method for calibration.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions temperature scaling as a method for calibration, but does not refer to any specific dataset. The cited papers are about calibration methods, not datasets.",
      "processing_time": 56.53084659576416,
      "citing_paper_id": "264452034",
      "cited_paper_id": 212747810
    },
    {
      "context_text": "Modern DNNs are prone to over-confidence, which implies that the model’s confidence is not reliable (Guo et al., 2017).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue with modern neural networks.",
      "processing_time": 55.40054774284363,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "Among modern calibration approaches, temperature scaling is a simple and effective method (Desai and Durrett, 2020) which can produce low ECE (Guo et al., 2017; Chen et al., 2023).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods for model calibration. No dataset names are present in the text.",
      "processing_time": 55.944993019104004,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "Among modern calibration approaches, temperature scaling is a simple and effective method (Desai and Durrett, 2020) which can produce low ECE (Guo et al., 2017; Chen et al., 2023).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods for model calibration. No dataset names are present in the text.",
      "processing_time": 55.944993019104004,
      "citing_paper_id": "264452034",
      "cited_paper_id": 212747810
    },
    {
      "context_text": "However, some studies reveal that current Deep Neural Networks (DNNs) are prone to over-confidence , which implies that the model’s confidence is not reliable (Guo et al., 2017).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue with DNNs. No dataset names are present in the citation span.",
      "processing_time": 56.08395552635193,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "Other works focus on methods such as label smoothing (Pereyra et al., 2017) and data augmentation (Hendrycks* et al., 2020), but these methods cannot produce as low ECE as temperature scaling (Chen et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and their performance comparisons.",
      "processing_time": 55.144729137420654,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "We compare our framework with a series of competitive baselines: (1) BERT-CRF (Shi and Lin, 2019), a simple BERT-based model without incorporating lexical or syntactic features for argument identification and classification.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (BERT-CRF). The context focuses on comparing a framework with a baseline model, not on using a dataset.",
      "processing_time": 56.59359359741211,
      "citing_paper_id": "264452034",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "• All models augmented with retrieval (i.e., w/ M) perform better compared with BERT-CRF and raw BART-Gen, showing the importance of modeling inter-event dependencies.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance. There are no clear identifiers for datasets in the text.",
      "processing_time": 55.921467542648315,
      "citing_paper_id": "264452034",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Here, we plot the process of predicting the arguments of E 2 . similarity between E i ’s context c i and each prediction in m using S-BERT (Reimers and Gurevych, 2019) embeddings, and select the prediction with the highest score as additional input to help the prediction of E i : where SBERT() denotes S-BERT encoding, m Ri denotes the retrieved prediction that E i relies on.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of S-BERT embeddings for a prediction task. S-BERT is a method, not a dataset.",
      "processing_time": 56.184677600860596,
      "citing_paper_id": "264452034",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "Here, we plot the process of predicting the arguments of E 2 . similarity between E i ’s context c i and each prediction in m using S-BERT (Reimers and Gurevych, 2019) embeddings, and select the prediction with the highest score as additional input to help the prediction of E i : where SBERT()…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of S-BERT embeddings for a prediction task. S-BERT is a method, not a dataset.",
      "processing_time": 56.129876375198364,
      "citing_paper_id": "264452034",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "Studies on the calibration of natural language models have been drawing attention recently (Desai and Durrett, 2020; Park and Caragea, 2022; Kim et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies on the calibration of natural language models.",
      "processing_time": 55.36757230758667,
      "citing_paper_id": "264452034",
      "cited_paper_id": 212747810
    },
    {
      "context_text": "Studies on the calibration of natural language models have been drawing attention recently (Desai and Durrett, 2020; Park and Caragea, 2022; Kim et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies on the calibration of natural language models.",
      "processing_time": 55.36757230758667,
      "citing_paper_id": "264452034",
      "cited_paper_id": 247450599
    },
    {
      "context_text": "We formulate document-level IAE as a generative template-filling task following Li et al. (2021) and Du et al. (2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods or approaches in other papers.",
      "processing_time": 55.20585346221924,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We formulate document-level IAE as a generative template-filling task following Li et al. (2021) and Du et al. (2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods or approaches in other papers.",
      "processing_time": 55.20585346221924,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "(2) BART-Gen (Li et al., 2021), a conditional neural text generation model that generates a filled template for each event given the event template and context words.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a model (BART-Gen) rather than a dataset. No specific dataset is referenced in the citation context.",
      "processing_time": 55.7482476234436,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "From the results, we can conclude that: • Our S2C-CD model outperforms all previous methods on W IKI E VENTS as to document-level IAE, with an average gain of 1.4% in F1 on all four settings.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "W IKI E VENTS"
      ],
      "dataset_descriptions": {
        "W IKI E VENTS": "Used to evaluate the S2C-CC model for document-level event argument extraction, focusing on improving F1 scores across multiple settings."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'W IKI E VENTS' as a dataset used to evaluate the performance of the S2C-CD model. The dataset is relevant to document-level event extraction.",
      "processing_time": 58.674243211746216,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Following previous studies on document-level IAE (Li et al., 2021; Du et al., 2022), we adopt Head Word Match (Head F1) (Huang and Riloff, 2021) and Coreferential Match (Coref F1) (Ji and Grish-man, 2008) to judge whether the predicted argu-ment span matches the gold argument span.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics (Head F1 and Coref F1). These metrics are not considered datasets.",
      "processing_time": 56.101439237594604,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Following previous studies on document-level IAE (Li et al., 2021; Du et al., 2022), we adopt Head Word Match (Head F1) (Huang and Riloff, 2021) and Coreferential Match (Coref F1) (Ji and Grish-man, 2008) to judge whether the predicted argu-ment span matches the gold argument span.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics (Head F1 and Coref F1). These metrics are not considered datasets.",
      "processing_time": 56.101439237594604,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "First, we introduce our memory-enhanced IAE model (Section 3.1).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a model. There are no verifiable resources or datasets mentioned.",
      "processing_time": 55.65849256515503,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "The main results for document-level IAE are presented in Table 2.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the presentation of results. No dataset names are provided in the context.",
      "processing_time": 55.80699396133423,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We evaluate our framework on W IKI E VENTS (Li et al., 2021) as it annotates all the events in a document (averagely 16 events per document), while existing document-level datasets such as DocEE (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) only annotate at most 3 events…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKI EVENTS",
        "DocEE",
        "RAMS",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "WIKI EVENTS": "Used to evaluate document-level event extraction, focusing on comprehensive event annotation (averagely 16 events per document) to assess the framework's performance.",
        "DocEE": "Used for comparison, focusing on fewer event annotations (at most 3 events per document) to highlight the comprehensiveness of WIKI EVENTS.",
        "RAMS": "Used for comparison, focusing on fewer event annotations (at most 3 events per document) to highlight the comprehensiveness of WIKI EVENTS.",
        "MUC-4": "Used for comparison, focusing on fewer event annotations (at most 3 events per document) to highlight the comprehensiveness of WIKI EVENTS."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets used for evaluating a framework for document-level event extraction. WIKI EVENTS is highlighted for its comprehensive annotation of events, while other datasets are mentioned for comparison.",
      "processing_time": 62.80360794067383,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We conduct experiments on a widely used benchmark W IKI E VENTS (Li et al., 2021), and our proposed simple-to-complex framework outperforms the previous SOTA by 1.4% in F1, illustrating the effectiveness of our method.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "W IKI E VENTS"
      ],
      "dataset_descriptions": {
        "W IKI E VENTS": "Used to evaluate the proposed method for document-level event extraction, specifically comparing performance metrics against previous state-of-the-art approaches."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'W IKI E VENTS' as a benchmark used for experiments. It is a specific dataset used for document-level event extraction, which aligns with the research topic.",
      "processing_time": 58.39591670036316,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Our memory-enhanced IAE model is based on a generative model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a generative model. No dataset names are present in the context.",
      "processing_time": 55.57028913497925,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Also, it provides complete coreference annotation for document-level IAE.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset names, only a general reference to 'complete coreference annotation'. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 56.32409882545471,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Among them, one line of studies (Li et al., 2021; Huang et al., 2022) treats each event independently and ignores the underlying correlations between events in real-world documents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No dataset names are present in the citation context.",
      "processing_time": 55.459330797195435,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We calculate the cosine Figure 1: Our simple-to-complex progressive framework for document-level IAE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method or framework for document-level event argument extraction.",
      "processing_time": 55.311851501464844,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "It is the SOTA model on document-level IAE, but still extracts events according to their appearance order in the document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model's performance on a task. No dataset names are provided in the context.",
      "processing_time": 55.667434215545654,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Retrieval-Augmented Generation In the input stage (both for training and testing), we augment our model with similarity-based retrieval following Du et al. (2022) to make it capable of finding argument mentions beyond the context of an event, especially informative ones (Li et al., 2021).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for retrieval-augmented generation. No dataset names are provided in the context.",
      "processing_time": 55.51960349082947,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "In this work, we focus on document-level Informa-tive Argument Extraction 1 (IAE) (Li et al., 2021), where informative arguments are far more distant than local/uninformative ones and provide more useful information about an event.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a research focus on document-level Informative Argument Extraction. No clear, verifiable datasets are identified.",
      "processing_time": 55.69257640838623,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Constrained Decoding In the output stage, we introduce argument pair constraints following Du et al. (2022) to constrain the decoding of arguments with conflicting roles.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for constraining argument pairs during decoding.",
      "processing_time": 55.094332456588745,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "Among them, template generation-based approaches (Li et al., 2021; Huang et al., 2022; Du et al., 2022) are widely utilized.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods or approaches. There are no clear identifiers for datasets in the text.",
      "processing_time": 55.51025390625,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "In this section, we first compare our bounded constraints with those presented in Du et al. (2022), then analyze the impact of the lower and upper bounds individually.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of methods and analysis of bounds.",
      "processing_time": 54.702195167541504,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "Other works (Du et al., 2022; Du and Ji, 2022) start to consider inter-event dependencies and model them by introducing the idea of “memory”, where event predictions (e.g., arguments, roles) are cached and can be retrieved to help the prediction of the upcoming events in a document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of using memory to model inter-event dependencies. No verifiable resources are named.",
      "processing_time": 55.56024980545044,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "Other works (Du et al., 2022; Du and Ji, 2022) start to consider inter-event dependencies and model them by introducing the idea of “memory”, where event predictions (e.g., arguments, roles) are cached and can be retrieved to help the prediction of the upcoming events in a document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of using memory to model inter-event dependencies. No verifiable resources are named.",
      "processing_time": 55.56024980545044,
      "citing_paper_id": "264452034",
      "cited_paper_id": 253510351
    },
    {
      "context_text": "However, once an incorrect prediction is used to constrain another, it may cause more errors (Du et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or finding related to error propagation in predictions.",
      "processing_time": 55.03288388252258,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "In Table 5, we observe that when applying the original constraints (Du et al., 2022 performs only comparably with our S2C model.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between models. No verifiable resources are identified.",
      "processing_time": 55.103251934051514,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "However, the SVM-based methods above are developed for structured data and are hardly to integrate with deep neural network-based representation learning to form an end-to-end train-189 ing procedure for natural language processing tasks. where D is the output of the Bi-LSTM encoding layer, ent start",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only discusses methodological limitations and integration challenges.",
      "processing_time": 54.88355302810669,
      "citing_paper_id": "250390478",
      "cited_paper_id": 8291528
    },
    {
      "context_text": "However, the SVM-based methods above are developed for structured data and are hardly to integrate with deep neural network-based representation learning to form an end-to-end train-189 ing procedure for natural language processing tasks. where D is the output of the Bi-LSTM encoding layer, ent start",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only discusses methodological limitations and integration challenges.",
      "processing_time": 54.88355302810669,
      "citing_paper_id": "250390478",
      "cited_paper_id": null
    },
    {
      "context_text": "We found the root cause Research works in universum usually employ ad-180 ditional unlabeled universum data to provide prior knowledge for the task, such as universum support vector machine (SVM) (Weston et al., 2006; Qi et al., 2012; Richhariya and Tanveer, 2020), and semi-supervised learning (Liu et al., 2015; Xiao et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methods and approaches using unlabeled universum data, but does not name any particular dataset.",
      "processing_time": 55.687586307525635,
      "citing_paper_id": "250390478",
      "cited_paper_id": 8291528
    },
    {
      "context_text": "We found the root cause Research works in universum usually employ ad-180 ditional unlabeled universum data to provide prior knowledge for the task, such as universum support vector machine (SVM) (Weston et al., 2006; Qi et al., 2012; Richhariya and Tanveer, 2020), and semi-supervised learning (Liu et al., 2015; Xiao et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methods and approaches using unlabeled universum data, but does not name any particular dataset.",
      "processing_time": 55.687586307525635,
      "citing_paper_id": "250390478",
      "cited_paper_id": null
    },
    {
      "context_text": "…in universum usually employ ad-180 ditional unlabeled universum data to provide prior knowledge for the task, such as universum support vector machine (SVM) (Weston et al., 2006; Qi et al., 2012; Richhariya and Tanveer, 2020), and semi-supervised learning (Liu et al., 2015; Xiao et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methods and approaches using unlabeled universum data, but does not name any particular dataset.",
      "processing_time": 55.632219076156616,
      "citing_paper_id": "250390478",
      "cited_paper_id": 8291528
    },
    {
      "context_text": "…in universum usually employ ad-180 ditional unlabeled universum data to provide prior knowledge for the task, such as universum support vector machine (SVM) (Weston et al., 2006; Qi et al., 2012; Richhariya and Tanveer, 2020), and semi-supervised learning (Liu et al., 2015; Xiao et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methods and approaches using unlabeled universum data, but does not name any particular dataset.",
      "processing_time": 55.632219076156616,
      "citing_paper_id": "250390478",
      "cited_paper_id": null
    },
    {
      "context_text": "Graph structure is used in EAE to produce com-511 prehensive representation for coreference entities (Luan et al., 2019; Qian et al., 2019; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 55.401848793029785,
      "citing_paper_id": "250390478",
      "cited_paper_id": 53109320
    },
    {
      "context_text": "Graph structure is used in EAE to produce com-511 prehensive representation for coreference entities (Luan et al., 2019; Qian et al., 2019; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 55.401848793029785,
      "citing_paper_id": "250390478",
      "cited_paper_id": 235253912
    },
    {
      "context_text": ", 2021), auto-encoder based anomaly detection (Ionescu et al., 2019), OpenMax layer for open set recognition (Bendale and Boult, 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 55.276983976364136,
      "citing_paper_id": "250390478",
      "cited_paper_id": 54475483
    },
    {
      "context_text": "We use SpanBERT (Joshi et al., 2020) to implement coreference resolution on documents during preprocessing.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions SpanBERT, which is a model, not a dataset. No datasets are explicitly mentioned or used in the given context.",
      "processing_time": 55.45447826385498,
      "citing_paper_id": "250390478",
      "cited_paper_id": 198229624
    },
    {
      "context_text": "Most previous event argument extraction models make predictions at sentence-level (Nguyen et al., 2016; Liu et al., 2018; Yang et al., 2019b; Du and Cardie, 2020b; Wei et al., 2021; Wang et al., 2021; Dutta et al., 2021",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous works on event argument extraction models. No verifiable resources are identified.",
      "processing_time": 55.16448259353638,
      "citing_paper_id": "250390478",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Research on document-level event extraction has been focused on tackling challenges such as arguments-scattering and multiple-events (Zheng et al., 2019; Du and Cardie, 2020a; Du et al., 2021; Lou et al., 2021; Li et al., 2021; Huang and Peng,",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 55.501953125,
      "citing_paper_id": "250390478",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Research on document-level event extraction has been focused on tackling challenges such as arguments-scattering and multiple-events (Zheng et al., 2019; Du and Cardie, 2020a; Du et al., 2021; Lou et al., 2021; Li et al., 2021; Huang and Peng,",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 55.501953125,
      "citing_paper_id": "250390478",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Research on document-level event extraction has been focused on tackling challenges such as arguments-scattering and multiple-events (Zheng et al., 2019; Du and Cardie, 2020a; Du et al., 2021; Lou et al., 2021; Li et al., 2021; Huang and Peng,",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 55.501953125,
      "citing_paper_id": "250390478",
      "cited_paper_id": 234790176
    },
    {
      "context_text": "Previous works are mostly focused on sentence level EE (Liao and Grishman, 2010; Nguyen et al., 2016; Liu et al., 2018; Yang et al., 2019b; Du and Cardie, 2020b; Wei et al., 2021; Wang et al., 2021; Lyu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous works focused on sentence-level event extraction.",
      "processing_time": 54.66774272918701,
      "citing_paper_id": "250390478",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Closed boundary classification methods are also developed in anomaly detection and open set recognition, such as deep one-class learning (Ruff et al., 2018; Defard et al., 2021), auto-encoder based anomaly detection (Ionescu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 55.17062211036682,
      "citing_paper_id": "250390478",
      "cited_paper_id": 226976039
    },
    {
      "context_text": "Classification-based event argument extraction models (Huang and Peng, 2021; Xu et al., 2021; Yang et al., 2021) all employ cross entropy loss for classifier training, without considering the characteristics of Universum class: scattered dis-",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only classification-based models and their training methods. No verifiable resources are identified.",
      "processing_time": 55.16716170310974,
      "citing_paper_id": "250390478",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "Classification-based event argument extraction models (Huang and Peng, 2021; Xu et al., 2021; Yang et al., 2021) all employ cross entropy loss for classifier training, without considering the characteristics of Universum class: scattered dis-",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only classification-based models and their training methods. No verifiable resources are identified.",
      "processing_time": 55.16716170310974,
      "citing_paper_id": "250390478",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "3) An entity may appear multiple times in the document, directly averaging them as the entity’s feature representation (Xu et al., 2021) may introduce noise.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for handling entity representations in document-level event extraction.",
      "processing_time": 54.987165451049805,
      "citing_paper_id": "250390478",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "Research works in event extraction (Xu et al., 2021; Luan et al., 2019; Qian et al., 2019) consider the first observation but neglect the second one.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to research works. The context does not provide information about the use of datasets.",
      "processing_time": 55.26889753341675,
      "citing_paper_id": "250390478",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "Graph structure is used in EAE to produce a comprehensive representation of coreference entities (Luan et al., 2019; Qian et al., 2019; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the use of graph structures in event argument extraction.",
      "processing_time": 55.431620836257935,
      "citing_paper_id": "250390478",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "Cross entropy loss is usually employed in classifier training (Zheng et al., 2019; Huang and Peng, 2021; Xu et al., 2021; Yang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the use of cross entropy loss in classifier training. The cited papers' titles suggest a focus on document-level event extraction, but do not introduce specific datasets.",
      "processing_time": 56.134406089782715,
      "citing_paper_id": "250390478",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "Cross entropy loss is usually employed in classifier training (Zheng et al., 2019; Huang and Peng, 2021; Xu et al., 2021; Yang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the use of cross entropy loss in classifier training. The cited papers' titles suggest a focus on document-level event extraction, but do not introduce specific datasets.",
      "processing_time": 56.134406089782715,
      "citing_paper_id": "250390478",
      "cited_paper_id": 236460259
    },
    {
      "context_text": ", 136 2016; Liu et al., 2018; Yang et al., 2019b; Du 137 and Cardie, 2020b; Wei et al., 2021; Wang et al., 138 2021; Dutta et al., 2021). Considering that real 139 world events are often distributed across sentences, 140 document-level event extraction has attracted more 141 attentions recently. Zheng et al. (2019) propose 142 the Doc2EDAG model to overcome the argument 143 scattering problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies and a model (Doc2EDAG). No verifiable resources are identified.",
      "processing_time": 55.53682994842529,
      "citing_paper_id": "250390478",
      "cited_paper_id": null
    },
    {
      "context_text": "AD3 has been shown to be orders of magnitude faster than a general purpose ILP solver in practice (Das et al., 2012).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (AD3) and its performance compared to a general purpose ILP solver.",
      "processing_time": 55.089667558670044,
      "citing_paper_id": "2367456",
      "cited_paper_id": 1071069
    },
    {
      "context_text": ", 2013), Markov Logic (Poon and Vanderwende, 2010), or dependency parsing algorithms (McClosky et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and algorithms. There are no clear identifiers for datasets in the text.",
      "processing_time": 55.05259084701538,
      "citing_paper_id": "2367456",
      "cited_paper_id": 1160159
    },
    {
      "context_text": "As pipeline approaches suffer from error propagation, researchers have proposed methods for joint extraction of event triggers and arguments, using either structured perceptron (Li et al., 2013), Markov Logic (Poon and Vanderwende, 2010), or dependency parsing algorithms (McClosky et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for joint extraction of event triggers and arguments.",
      "processing_time": 54.937034368515015,
      "citing_paper_id": "2367456",
      "cited_paper_id": 1160159
    },
    {
      "context_text": "As pipeline approaches suffer from error propagation, researchers have proposed methods for joint extraction of event triggers and arguments, using either structured perceptron (Li et al., 2013), Markov Logic (Poon and Vanderwende, 2010), or dependency parsing algorithms (McClosky et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for joint extraction of event triggers and arguments.",
      "processing_time": 54.937034368515015,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "As pipeline approaches suffer from error propagation, researchers have proposed methods for joint extraction of event triggers and arguments, using either structured perceptron (Li et al., 2013), Markov Logic (Poon and Vanderwende, 2010), or dependency parsing algorithms (McClosky et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for joint extraction of event triggers and arguments.",
      "processing_time": 54.937034368515015,
      "citing_paper_id": "2367456",
      "cited_paper_id": 3201232
    },
    {
      "context_text": "We use the same event trigger candidates and entity mention candidates as input to all the comparing models except for J OINT B EAM , because J OINT B EAM only extracts event mentions and assumes entity mentions are given.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their inputs. No verifiable resources are identified.",
      "processing_time": 54.52540707588196,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Second, most existing work extracts events independently from each individual sentence, ignoring the rest of the document (Li et al., 2013; Judea and Strube, 2015; Nguyen and Grishman, 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 55.184831857681274,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Second, most existing work extracts events independently from each individual sentence, ignoring the rest of the document (Li et al., 2013; Judea and Strube, 2015; Nguyen and Grishman, 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 55.184831857681274,
      "citing_paper_id": "2367456",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "Second, most existing work extracts events independently from each individual sentence, ignoring the rest of the document (Li et al., 2013; Judea and Strube, 2015; Nguyen and Grishman, 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 55.184831857681274,
      "citing_paper_id": "2367456",
      "cited_paper_id": 18911648
    },
    {
      "context_text": "Comparing to the state-of-the-art event extractor J OINT B EAM , the improvements introduced by W ITHIN E VENT are substantial in both event triggers and event arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model comparisons. No verifiable resources are identified.",
      "processing_time": 54.6923930644989,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "First, they extract events and entities in separate stages: entities such as people, organization, and locations are ﬁrst extracted by a named entity tagger, and then these extracted entities are used as inputs for extracting events and their arguments (Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event and entity extraction.",
      "processing_time": 54.43027853965759,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "One is J OINT B EAM (Li et al., 2013), a state-of-the-art event extractor that uses a structured perceptron with beam search for sentence-level joint extraction of event triggers and arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (J OINT B EAM) rather than a dataset. No specific dataset is referenced in the citation context.",
      "processing_time": 54.85848665237427,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "We believe there are two main reasons: (1) W ITHIN E VENT considers all possible joint trigger/argument label assignments, whereas J OINT B EAM considers only a subset of the possible assignments based on a heuristic beam search.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methodological differences between two approaches.",
      "processing_time": 54.12279176712036,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "We use the same data split as in Li et al. (2013).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset name, only a reference to a data split used in another paper. No verifiable resource is identified.",
      "processing_time": 54.69355130195618,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "To obtain results from J OINT B EAM , we ran the actual system 8 used in Li et al. (2013) using the entity mentions output by our CRF-based entity extractor.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (J OINT B EAM) and a tool (CRF-based entity extractor).",
      "processing_time": 55.026618003845215,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "We adopt the evaluation metrics for events as de-ﬁned in Li et al. (2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics from a cited paper.",
      "processing_time": 54.209672689437866,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "In fact, previous work (Li et al., 2013) observes that using previously extracted entities in event extraction results in a r X i v : 1609 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about using previously extracted entities in event extraction.",
      "processing_time": 54.27372932434082,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Many of these features overlap with those used in previous work (Li et al., 2013; Li et al., 2014), except for the word embedding features for triggers and the features for entities which are derived from multiple entity resources. f 3 and f 5 are pairwise feature functions that depend on…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only features and methods. No clear identifiers for datasets are present.",
      "processing_time": 54.27001142501831,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "IN E VENT models argument-role-entity-type dependencies, whereas J OINT B EAM assumes the entity types are given.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their methodologies.",
      "processing_time": 53.87160301208496,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2114517
    },
    {
      "context_text": ", 2013), Markov Logic (Poon and Vanderwende, 2010), or dependency parsing algorithms (McClosky et al., 2011).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and algorithms. No dataset names are present in the text.",
      "processing_time": 54.32124710083008,
      "citing_paper_id": "2367456",
      "cited_paper_id": 2941631
    },
    {
      "context_text": "To reduce task complexity, early work employs a pipeline of classiﬁers that extracts event triggers ﬁrst, and then determines their arguments (Ahn, 2006; Bj¨orne et al., 2009).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the methodology of using a pipeline of classifiers for event extraction.",
      "processing_time": 54.74078059196472,
      "citing_paper_id": "2367456",
      "cited_paper_id": 6540287
    },
    {
      "context_text": "For general texts most work focuses on exploiting temporal event relations (Chambers and Ju-rafsky, 2008; Do et al., 2012; McClosky and Man-ning, 2012).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that discuss methods or findings. No verifiable resources are identified.",
      "processing_time": 54.579720973968506,
      "citing_paper_id": "2367456",
      "cited_paper_id": 7359050
    },
    {
      "context_text": "Event extraction has been mainly studied using the ACE data (Doddington et al., 2004) and biomedical data for the BioNLP shared tasks (Kim et al., 2009).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE data",
        "BioNLP shared task data"
      ],
      "dataset_descriptions": {
        "ACE data": "Used to study event extraction, focusing on identifying and classifying events in text, employing a well-established benchmark for evaluation.",
        "BioNLP shared task data": "Utilized to explore event extraction in the biomedical domain, specifically for identifying molecular events and interactions, enhancing precision and recall in specialized contexts."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions two specific datasets: 'ACE data' and 'biomedical data for the BioNLP shared tasks'. Both are relevant to event extraction and are used in the research context.",
      "processing_time": 58.146666526794434,
      "citing_paper_id": "2367456",
      "cited_paper_id": 9631585
    },
    {
      "context_text": ".g., a DIE event tends to co-occur with ATTACK events and TRANSPORT events). It can be extended to handle other types of event relations (e.g., causal and temporal) by designing appropriate features. Chambers and Jurafsky (2009; 2011) learn narrative schemas by linking event verbs that have coreferring syntactic arguments. Our model also adopts this intuition to relate event triggers across sentences. In addition, each even",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers are used to describe the methodology, not to introduce datasets.",
      "processing_time": 54.47101092338562,
      "citing_paper_id": "2367456",
      "cited_paper_id": 10299779
    },
    {
      "context_text": "Chambers and\nJurafsky (2009; 2011) learn narrative schemas by linking event verbs that have coreferring syntactic arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for learning narrative schemas. No verifiable resources are identified.",
      "processing_time": 54.2552809715271,
      "citing_paper_id": "2367456",
      "cited_paper_id": 10299779
    },
    {
      "context_text": "Recently, Convolutional Neural Networks have been used to improve the pipeline classifiers (Nguyen and Grishman, 2015; Chen et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of Convolutional Neural Networks for improving pipeline classifiers. No verifiable resources are identified.",
      "processing_time": 54.5750412940979,
      "citing_paper_id": "2367456",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "Recently, Convolutional Neural Networks have been used to improve the pipeline classifiers (Nguyen and Grishman, 2015; Chen et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of Convolutional Neural Networks for improving pipeline classifiers. No verifiable resources are identified.",
      "processing_time": 54.5750412940979,
      "citing_paper_id": "2367456",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "CROSS-DOC (Ji and Grishman, 2008) performs cross-document inference of events using document clustering information, and CNN (Nguyen and Grishman, 2015) is a convolutional neural network for extracting event triggers at the sentence level.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions methods (CROSS-DOC and CNN) but does not refer to any specific datasets. The context is about methodologies and their applications, not the datasets used.",
      "processing_time": 54.654340982437134,
      "citing_paper_id": "2367456",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "We demonstrate that our approach substantially outperforms the stateof-the-art methods for event extraction as well as a strong baseline for entity extraction.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison to state-of-the-art methods and a baseline. No verifiable resources are identified.",
      "processing_time": 54.359339475631714,
      "citing_paper_id": "2367456",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "ormance compared to using gold-standard entity information. Second, most existing work extracts events independently from each individual sentence, ignoring the rest of the document (Li et al., 2013; Judea and Strube, 2015; Nguyen and Grishman, 2015). Very few attempts have been made to incorporate document context for event extraction. Ji and Grishman (2008) model the information ﬂow in two stages: the ﬁrst stage trai",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous work and methodologies.",
      "processing_time": 53.88345670700073,
      "citing_paper_id": "2367456",
      "cited_paper_id": 18911648
    },
    {
      "context_text": "We use features that are similar to those from previous work (Ratinov and Roth, 2009): (1) current words and part-of-speech tags; (2) context words in a window of size 2; (3) word type such as all-capitalized, is-capitalized, and all-digits; (4) Gazetteer-based entity type if the current word matches an entry in the gazetteers collected from Wikipedia (Ratinov and Roth, 2009).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes features and methods used in the research, but no dataset names are provided.",
      "processing_time": 54.184470891952515,
      "citing_paper_id": "2367456",
      "cited_paper_id": 218835077
    },
    {
      "context_text": "We use features that are similar to those from previous work (Ratinov and Roth, 2009): (1) current words and part-of-speech tags; (2) context words in a window of size 2; (3) word type such as all-capitalized, is-capitalized, and all-digits; (4) Gazetteer-based entity type if the current word…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only features and methods. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 54.07561111450195,
      "citing_paper_id": "2367456",
      "cited_paper_id": 218835077
    },
    {
      "context_text": "…2009): (1) current words and part-of-speech tags; (2) context words in a window of size 2; (3) word type such as all-capitalized, is-capitalized, and all-digits; (4) Gazetteer-based entity type if the current word matches an entry in the gazetteers collected from Wikipedia (Ratinov and Roth, 2009).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only features and methods used in a model. The reference to Wikipedia is for gazetteers, not a dataset.",
      "processing_time": 54.26814579963684,
      "citing_paper_id": "2367456",
      "cited_paper_id": 218835077
    },
    {
      "context_text": "…EAE models mostly focus on problem reformulation and prompt design without incorporating auxiliary syntactic and semantic information that is shown to be effective in classification-based methods (Huang et al., 2016; Xu and Huang, 2022; Huang et al., 2018; Ahmad et al., 2021; Veyseh et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and approaches in event extraction.",
      "processing_time": 53.66080904006958,
      "citing_paper_id": "258947053",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "However, existing generation-based EAE models mostly focus on problem reformulation and prompt design without incorporating auxiliary syntactic and semantic information that is shown to be effective in classification-based methods (Huang et al., 2016; Xu and Huang, 2022; Huang et al., 2018; Ahmad et al., 2021; Veyseh et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and approaches in event extraction.",
      "processing_time": 53.28417086601257,
      "citing_paper_id": "258947053",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "Hence, the AMR graph could provide important clues for models to figure out event arguments, resulting in performance improvements (Zhang and Ji, 2021) and better generalizability (Huang et al., 2018) for classification-based methods.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not mention any specific datasets, only references to models and methods. The context focuses on the benefits of using AMR graphs for event argument identification.",
      "processing_time": 54.14439868927002,
      "citing_paper_id": "258947053",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "Huang et al. (2016, 2018) uses the similarity between AMR and event structures to perform zero-shot event extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or approach using AMR and event structures.",
      "processing_time": 53.441715717315674,
      "citing_paper_id": "258947053",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "(Xu and Huang, 2022; Liu et al., 2019a; Huang et al., 2018; Veyseh et al., 2020) Liu et al. (2019a); Ahmad et al. (2021) leverages dependency syntactic structures of the input sentence to help cross-lingual event predictions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 53.907474517822266,
      "citing_paper_id": "258947053",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "(Xu and Huang, 2022; Liu et al., 2019a; Huang et al., 2018; Veyseh et al., 2020) Liu et al. (2019a); Ahmad et al. (2021) leverages dependency syntactic structures of the input sentence to help cross-lingual event predictions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 53.907474517822266,
      "citing_paper_id": "258947053",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "To encode the AMR graph, we follow Konstas et al. (2017) to adopt a depth-first-search algorithm to linearize the AMR graph into a sequence, as shown in the example in Figure 1.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for linearizing AMR graphs. No dataset names are present in the citation span.",
      "processing_time": 53.94857430458069,
      "citing_paper_id": "258947053",
      "cited_paper_id": 8066499
    },
    {
      "context_text": "It is an important task for various downstream applications (Zhang et al., 2020; Berant et al., 2014; Hogenboom et al., 2016; Wen et al., 2021; Wu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various downstream applications. No verifiable resources are identified.",
      "processing_time": 53.807968616485596,
      "citing_paper_id": "258947053",
      "cited_paper_id": 8471750
    },
    {
      "context_text": "It is an important task for various downstream applications (Zhang et al., 2020; Berant et al., 2014; Hogenboom et al., 2016; Wen et al., 2021; Wu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various downstream applications. No verifiable resources are identified.",
      "processing_time": 53.807968616485596,
      "citing_paper_id": "258947053",
      "cited_paper_id": 235097376
    },
    {
      "context_text": ", 2004) and ERE (Song et al., 2015) datasets using different ratios of training data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ERE"
      ],
      "dataset_descriptions": {
        "ERE": "Used to train and evaluate models on entity, relation, and event extraction tasks, focusing on different ratios of training data to assess performance."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ERE' as a dataset, which is likely a specific, verifiable resource given the cited paper title. The context also mentions 'different ratios of training data', indicating the dataset is used for training and evaluation.",
      "processing_time": 55.89807081222534,
      "citing_paper_id": "258947053",
      "cited_paper_id": 9700115
    },
    {
      "context_text": "We conduct experiments on ACE 2005 (Dod-dington et al., 2004) and ERE (Song et al., 2015) datasets using different ratios of training data.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 12 column 1 (char 509), response: {\n    \"reasoning\": \"The context mentions two specific datasets, ACE 2005 and ERE, which are used for",
      "processing_time": 61.454052686691284,
      "citing_paper_id": "258947053",
      "cited_paper_id": 9700115
    },
    {
      "context_text": "We adopt the event annotation in ACE 2005 dataset (Doddington et al., 2004) ( ACE05-E ) 6 , and the English split in ERE Evaluation metrics.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to adopt event annotation standards, focusing on the English split in ERE Evaluation metrics for consistent event labeling."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE 2005 dataset, which is a well-known dataset for event annotation. The dataset is used for adopting event annotation standards.",
      "processing_time": 55.27748227119446,
      "citing_paper_id": "258947053",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "Their original model is built us-ing BERT (Devlin et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT, which is a model, not a dataset. No datasets are mentioned in the citation span.",
      "processing_time": 53.45887064933777,
      "citing_paper_id": "258947053",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Their original model is built using BERT (Devlin et al., 2019).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT, which is a model, not a dataset. No datasets are mentioned in the citation span.",
      "processing_time": 53.26241588592529,
      "citing_paper_id": "258947053",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Different from the official code, we used RoBERTa-large for pre-trained language model to ensure a fair comparison.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using RoBERTa-large for pre-training, but RoBERTa is a model, not a dataset. No datasets are mentioned.",
      "processing_time": 53.35796499252319,
      "citing_paper_id": "258947053",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "Particularly, A MPERE ( RoBERTa) , which employs a pre-trained RoBERTa-large as the AMR Encoder still achieves competitive results to A MPERE ( AMRBART) , which uses AMR-to-Text data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on comparing different model configurations rather than using a specific dataset.",
      "processing_time": 53.45914649963379,
      "citing_paper_id": "258947053",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "For all the classification-based methods, we use RoBERTa-large , and for all the generation-based methods, we use BART-large as the pre-trained language models.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions pre-trained language models RoBERTa-large and BART-large but does not refer to them as datasets. They are models, not datasets.",
      "processing_time": 53.451369285583496,
      "citing_paper_id": "258947053",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "For all the classification-based methods, we use RoBERTa-large , and for all the generation-based methods, we use BART-large as the pre-trained language models.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions pre-trained language models RoBERTa-large and BART-large but does not refer to them as datasets. They are models, not datasets.",
      "processing_time": 53.451369285583496,
      "citing_paper_id": "258947053",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "As we mentioned in Section 3.1, we replace the used pre-trained language model into RoBERTa-large and tune with learning rates = { 1 e − 5 , 2 e − 5 , 3 e − 5 } .",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a pre-trained language model (RoBERTa-large).",
      "processing_time": 53.008559465408325,
      "citing_paper_id": "258947053",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "• A MPERE ( RoBERTa) : RoBERTa-large (Liu et al., 2019b) is also considered as our AMR encoder as pre-trained masked language models are typical choices to perform encoding tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions RoBERTa but does not refer to it as a dataset. It is described as a pre-trained model used for encoding tasks.",
      "processing_time": 53.40220332145691,
      "citing_paper_id": "258947053",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "We compare A MPERE with the following classification-based models: (1) Dy-GIE++ (Wadden et al., 2019), which extracts information by scoring spans with contextualized representations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is focused on comparing A MPERE with Dy-GIE++, which is a method for event extraction.",
      "processing_time": 53.520885944366455,
      "citing_paper_id": "258947053",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "4 The model is based on BART-large and its vocabulary is enlarged by adding all relations and semantic concepts in AMR as additional tokens.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BART) and a method (AMR).",
      "processing_time": 52.9943151473999,
      "citing_paper_id": "258947053",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Although this setting is more similar to how BART-large is pre-trained and thus better leverages the power of pre-training, the loose constraints on the final prediction could generate hallucinated texts (Ji et al., 2022) or outputs not following the template.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a potential issue with BART-large's pre-training and prediction constraints.",
      "processing_time": 52.80087685585022,
      "citing_paper_id": "258947053",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "We follow D EGREE ’s setting to use BART-large (Lewis et al., 2020) as the pre-trained generative model, and the training objective of our generation-based EAE model is to maximize the conditional probability of generating a ground-truth token given the previously generated ones and the input context in the encoder x 1 , x 2 , ..x m : where y i is the output of the decoder at step i .",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a pre-trained model (BART-large). No verifiable datasets are referenced.",
      "processing_time": 53.03384804725647,
      "citing_paper_id": "258947053",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "We follow DEGREE’s setting to use BART-large (Lewis et al., 2020) as the pretrained generative model, and the training objective of our generation-based EAE model is to maximize the conditional probability of generating a groundtruth token given the previously generated ones and the input context in the encoder x1, x2, .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BART-large as a pretrained generative model but does not refer to any specific dataset. The focus is on the model and its training objective.",
      "processing_time": 53.28046202659607,
      "citing_paper_id": "258947053",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "• PAIE : we use their official code 16 to train the model with the default parameters for BART-large .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using 'PAIE' and 'BART-large', but neither are datasets. PAIE is a method, and BART-large is a model. No specific datasets are mentioned.",
      "processing_time": 53.51523017883301,
      "citing_paper_id": "258947053",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "• PAIE : we use their official code 16 to train the model with the default parameters for BART-large .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using 'PAIE' and 'BART-large', but neither are datasets. PAIE is a method, and BART-large is a model. No specific datasets are mentioned.",
      "processing_time": 53.51523017883301,
      "citing_paper_id": "258947053",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "We follow D EGREE ’s setting to use BART-large (Lewis et al., 2020) as the pre-trained generative model, and the training objective of our generation-based EAE model is to maximize the conditional probability of generating a ground-truth token given the previously generated ones and the input…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BART-large as a pre-trained generative model but does not refer to any specific dataset. The focus is on the model and its training objective.",
      "processing_time": 53.40310454368591,
      "citing_paper_id": "258947053",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "• DEGREE : we use their official code 17 to train the model with the default parameters for BART-large .",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BART-large model and its training code. No verifiable dataset names are present.",
      "processing_time": 52.99655199050903,
      "citing_paper_id": "258947053",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "We report the F1-score for argument predictions following prior works (Wad-den et al., 2019; Lin et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not mention any specific datasets, only F1-scores for argument predictions. No verifiable resources are identified.",
      "processing_time": 52.86435008049011,
      "citing_paper_id": "258947053",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "• OneIE : we use their official code 13 to train the model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a model or method. The citation is about using code to train a model, not a dataset.",
      "processing_time": 52.8838210105896,
      "citing_paper_id": "258947053",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "We report the F1-score for argument predictions following prior works (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only F1-scores for argument predictions. No verifiable resources are identified.",
      "processing_time": 52.671818017959595,
      "citing_paper_id": "258947053",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "We follow prior works (Wadden et al., 2019; Lin et al., 2020) to preprocess each dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to preprocessing datasets. No clear, verifiable resource names are provided.",
      "processing_time": 52.68381476402283,
      "citing_paper_id": "258947053",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "(2) OneIE (Lin et al., 2020), a joint IE framework that incorporates global features.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions OneIE, which is a method or framework, not a dataset. There are no specific datasets mentioned in the citation context.",
      "processing_time": 52.67832660675049,
      "citing_paper_id": "258947053",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Recently, generation-based EAE models (Hsu et al., 2022a; Lu et al., 2021; Li et al., 2021; Paolini et al., 2021; Parekh et al., 2022) are proposed and have shown great generalizability and competitive performance compared to traditional classification-based methods (Chen et al., 2015; Ma et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods. No verifiable resources are identified.",
      "processing_time": 52.507424116134644,
      "citing_paper_id": "258947053",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "Recently, generation-based EAE models (Hsu et al., 2022a; Lu et al., 2021; Li et al., 2021; Paolini et al., 2021; Parekh et al., 2022) are proposed and have shown great generalizability and competitive performance compared to traditional classification-based methods (Chen et al., 2015; Ma et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods. No verifiable resources are identified.",
      "processing_time": 52.507424116134644,
      "citing_paper_id": "258947053",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "Recently, generation-based EAE models (Hsu et al., 2022a; Lu et al., 2021; Li et al., 2021; Paolini et al., 2021) become more and more popular due to their flexibility to present different output structures (Yan et al., 2021), to be unified considered with similar tasks (Lu et al., 2022), and their…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context focuses on the popularity and benefits of generation-based EAE models.",
      "processing_time": 52.75066113471985,
      "citing_paper_id": "258947053",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "Recently, generation-based EAE models (Hsu et al., 2022a; Lu et al., 2021; Li et al., 2021; Paolini et al., 2021) become more and more popular due to their flexibility to present different output structures (Yan et al., 2021), to be unified considered with similar tasks (Lu et al., 2022), and their…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context focuses on the popularity and benefits of generation-based EAE models.",
      "processing_time": 52.75066113471985,
      "citing_paper_id": "258947053",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "…et al., 2021; Li et al., 2021; Paolini et al., 2021) become more and more popular due to their flexibility to present different output structures (Yan et al., 2021), to be unified considered with similar tasks (Lu et al., 2022), and their competitive performance (Hsu et al., 2022a; Liu et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing methods and performance. No verifiable resources are identified.",
      "processing_time": 52.43665528297424,
      "citing_paper_id": "258947053",
      "cited_paper_id": 235294002
    },
    {
      "context_text": ", 2021) become more and more popular due to their flexibility to present different output structures (Yan et al., 2021), to be unified considered with similar tasks (Lu et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing generative frameworks and NER subtasks.",
      "processing_time": 52.34524607658386,
      "citing_paper_id": "258947053",
      "cited_paper_id": 235294002
    },
    {
      "context_text": "Recently, generation-based EAE models (Hsu et al., 2022a; Lu et al., 2021; Li et al., 2021; Paolini et al., 2021; Parekh et al., 2022) are proposed and have shown great generalizability and competitive performance compared to traditional classificationbased methods (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 52.36556696891785,
      "citing_paper_id": "258947053",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "Recently, generation-based EAE models (Hsu et al., 2022a; Lu et al., 2021; Li et al., 2021; Paolini et al., 2021) become more and more popular due to their flexibility to present different output structures (Yan et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 52.35203003883362,
      "citing_paper_id": "258947053",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "To enhance the control, one commonly-used technique is to apply copy mechanism (See et al., 2017) to generation-based event models (Huang et al., 2022, 2021).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and techniques. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 52.2219123840332,
      "citing_paper_id": "258947053",
      "cited_paper_id": 237485215
    },
    {
      "context_text": "(Ma et al., 2022; Yao et al., 2022; Hsu et al., 2022a) More recently, researchers start to improve this series of work by designing different model architectures (Du et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to model architectures and methods. No clear identifiers for datasets are present.",
      "processing_time": 52.31287741661072,
      "citing_paper_id": "258947053",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "In the meanwhile, A MPERE ( RoBERTa) achieves 4.4 points of performance gain compared with PAIE.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context does not mention any specific datasets, only a performance comparison between two models. No verifiable resources are identified.",
      "processing_time": 52.219407081604004,
      "citing_paper_id": "258947053",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "A MPERE outperforms both D EGREE and PAIE, and the gap is more obvious under low-resource settings.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model comparisons. No dataset names are present in the citation span.",
      "processing_time": 51.98542141914368,
      "citing_paper_id": "258947053",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "(Ma et al., 2022; Yao et al., 2022; Hsu et al., 2022a) More recently, researchers start to improve this series of work by designing different model architectures (Du et al., 2022; Zhu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to model architectures and research works.",
      "processing_time": 51.80189752578735,
      "citing_paper_id": "258947053",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "We also consider the following generation-based models: (5) PAIE (Ma et al., 2022), a framework that integrated prompt tuning, and generates span selectors for each role.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions PAIE as a model, not a dataset. No datasets are explicitly mentioned or used in the given citation.",
      "processing_time": 51.95592999458313,
      "citing_paper_id": "258947053",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "EAE has long been a challenging task in NLP, especially when training data is limited (Wang et al., 2019; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the challenge of limited training data for EAE.",
      "processing_time": 51.74291181564331,
      "citing_paper_id": "258947053",
      "cited_paper_id": 247084444
    },
    {
      "context_text": ", 2021), to be unified considered with similar tasks (Lu et al., 2022), and their competitive performance (Hsu et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers and tasks. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 52.15352725982666,
      "citing_paper_id": "258947053",
      "cited_paper_id": 247619149
    },
    {
      "context_text": "…al., 2021; Li et al., 2021; Paolini et al., 2021) become more and more popular due to their flexibility to present different output structures (Yan et al., 2021), to be unified considered with similar tasks (Lu et al., 2022), and their competitive performance (Hsu et al., 2022a; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and findings. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.02945590019226,
      "citing_paper_id": "258947053",
      "cited_paper_id": 247619149
    },
    {
      "context_text": "…al., 2021; Li et al., 2021; Paolini et al., 2021) become more and more popular due to their flexibility to present different output structures (Yan et al., 2021), to be unified considered with similar tasks (Lu et al., 2022), and their competitive performance (Hsu et al., 2022a; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and findings. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.02945590019226,
      "citing_paper_id": "258947053",
      "cited_paper_id": 248780177
    },
    {
      "context_text": "Empirical studies on layer-wise versus single-layer control can be found in Liu et al. (2022b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to empirical studies. The context does not provide enough information to identify a verifiable dataset.",
      "processing_time": 52.02326202392578,
      "citing_paper_id": "258947053",
      "cited_paper_id": 248780177
    }
  ],
  "filtering_stats": {
    "original_papers_count": 614,
    "filtered_papers_count": 100,
    "filtered_percentage": "16.3%"
  },
  "extraction_stats": {
    "unique_contexts_processed": 2562,
    "total_citation_instances": 3489,
    "successful_extractions": 572,
    "failed_extractions": 2917,
    "total_processing_time": 164.98618078231812
  }
}