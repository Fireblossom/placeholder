{
  "summary": {
    "total_unique_datasets": 81,
    "total_dataset_mentions": 223,
    "unique_dataset_names": 81,
    "extraction_successful": 572,
    "extraction_failed": 2917,
    "unique_contexts_processed": 2562,
    "total_citation_instances": 3489,
    "total_processing_time": 164.98618078231812
  },
  "datasets_sorted_by_citation_count": [
    {
      "cited_paper_id": "52967399",
      "citation_count": 0,
      "total_dataset_mentions": 32,
      "unique_datasets": [
        "DocRED"
      ],
      "dataset_details": [
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate gene-disease association extraction, leveraging SciBERT-base for improved performance in scientific contexts. | Used to compare model performance on chemical-disease relation extraction, focusing on document-level relations and evaluating against baseline and state-of-the-art models. | Used to evaluate document-level relation extraction, focusing on complex relations across multiple sentences using cased BERT-base as the encoder. | Used to evaluate document-level relation extraction, focusing on complex relations across multiple sentences using a pre-trained encoder. | Used to compare model performance on gene-disease association extraction, focusing on document-level relations and evaluating against baseline and state-of-the-art models.",
          "citing_paper_id": "248300064",
          "cited_paper_id": 202558505,
          "context_text": ", 2018] as the encoder on DocRED and SciBERT-base [Beltagy et al., 2019] on CDR and GDA.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. SciBERT is a model, not a dataset, so it is excluded.",
          "citing_paper_doi": "10.48550/arXiv.2204.09851",
          "cited_paper_doi": "10.18653/v1/D19-1371",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33b9945129171b1cbcded4a5f4ba122dbb6c0528",
          "cited_paper_url": "https://www.semanticscholar.org/paper/156d217b0a911af97fa1b5a71dc909ccef7a8028",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to illustrate document-level relation extraction, specifically showing an example document and the corresponding predictions from a state-of-the-art method.",
          "citing_paper_id": "271923564",
          "cited_paper_id": 225039888,
          "context_text": "Figure 1 illustrates such an example, where sub-figure (a) in Figure 1 shows an example of a document in the DocRED dataset, and sub-figure (b) shows the corresponding predictions yielded by ATLOP, a state-of-the-art (SOTA) method for DocRE.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the 'DocRED dataset' as a specific dataset used to illustrate an example in the figure. The dataset is clearly identified and used for document-level relation extraction.",
          "citing_paper_doi": "10.18653/v1/2024.acl-long.391",
          "cited_paper_doi": "10.1609/aaai.v35i16.17717",
          "citing_paper_url": "https://www.semanticscholar.org/paper/2aa38877c2210d5e881826f4cd1c6fb026a81942",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3ac08d8c8210252cef12787539a81b0c8280ee3d",
          "citing_paper_year": 2024,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to construct a large-scale document-level relation extraction dataset from Wikipedia paragraphs, focusing on cross-sentence relations.",
          "citing_paper_id": "231728756",
          "cited_paper_id": 189898081,
          "context_text": "Yao et al. (2019) construct an RE dataset of cross-sentence relations on Wikipedia paragraphs.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the construction of an RE dataset from Wikipedia paragraphs, which is relevant to document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/2021.eacl-main.52",
          "cited_paper_doi": "10.18653/v1/P19-1074",
          "citing_paper_url": "https://www.semanticscholar.org/paper/eb54c33b170782eb3c16f206a263abfc551b9c51",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2745fc72e1dd53d1c30f17cf05841b163c2f63c9",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate cased BERT-base and RoBERTa-large models for document-level relation extraction, focusing on complex relations in scientific documents. | Used to evaluate relation extraction performance, focusing on chemical-disease relations. | Used to evaluate relation extraction performance, specifically enhancing interpretability by improving the evidence retrieval F1 score.",
          "citing_paper_id": "237635295",
          "cited_paper_id": 88817,
          "context_text": "Based on Huggingface (Wolf et al., 2019), we apply cased BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. These datasets are clearly identified and used in the research.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-main.171",
          "cited_paper_doi": "10.1093/database/baw068",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f6055cf63e4d24c75f8ff4c3c7e2fbd7a2695119",
          "cited_paper_url": "https://www.semanticscholar.org/paper/61322ec6cfc54fe9723d4637239b8fb9938dc501",
          "citing_paper_year": 2021,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate relation extraction performance, specifically enhancing interpretability by improving the evidence retrieval F1 score. | Used for document-level relation extraction, specifically leveraging crowd-sourced annotations from Wikipedia articles to train and evaluate models. | Used to train and evaluate document-level relation extraction models, focusing on complex relations across multiple sentences in Wikipedia articles. | Used to study document-level relation extraction, focusing on complex relations expressed across multiple sentences in a large-scale dataset. | Used to evaluate relation extraction performance, focusing on chemical-disease relations. | Used to evaluate the proposed SAIS method for document-level relation extraction, focusing on achieving state-of-the-art performance on a large-scale dataset.",
          "citing_paper_id": "237635295",
          "cited_paper_id": 189898081,
          "context_text": "DocRED (Yao et al. 2019) is a large-scale crowd-sourced dataset based on Wikipedia articles.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "DocRED is explicitly mentioned as a dataset and is described as a large-scale crowd-sourced dataset based on Wikipedia articles.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-main.171",
          "cited_paper_doi": "10.18653/v1/P19-1074",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f6055cf63e4d24c75f8ff4c3c7e2fbd7a2695119",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2745fc72e1dd53d1c30f17cf05841b163c2f63c9",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate cased BERT-base and RoBERTa-large models for document-level relation extraction, focusing on complex relations in scientific documents.",
          "citing_paper_id": "237635295",
          "cited_paper_id": 52967399,
          "context_text": "Based on Huggingface (Wolf et al., 2019), we apply cased BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. These datasets are clearly identified and used in the research.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-main.171",
          "cited_paper_doi": "10.18653/v1/N19-1423",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f6055cf63e4d24c75f8ff4c3c7e2fbd7a2695119",
          "cited_paper_url": "https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate cased BERT-base and RoBERTa-large models for document-level relation extraction, focusing on complex relations in scientific documents. | Used to evaluate models trained on document-level relation extraction, focusing on complex relations across multiple sentences.",
          "citing_paper_id": "237635295",
          "cited_paper_id": 198953378,
          "context_text": "Based on Huggingface (Wolf et al., 2019), we apply cased BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. These datasets are clearly identified and used in the research.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-main.171",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/f6055cf63e4d24c75f8ff4c3c7e2fbd7a2695119",
          "cited_paper_url": "https://www.semanticscholar.org/paper/077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate cased BERT-base and RoBERTa-large models for document-level relation extraction, focusing on complex relations in scientific documents. | Used to evaluate document-level relation extraction, focusing on complex relations across multiple sentences.",
          "citing_paper_id": "237635295",
          "cited_paper_id": 202558505,
          "context_text": "Based on Huggingface (Wolf et al., 2019), we apply cased BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. These datasets are clearly identified and used in the research.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-main.171",
          "cited_paper_doi": "10.18653/v1/D19-1371",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f6055cf63e4d24c75f8ff4c3c7e2fbd7a2695119",
          "cited_paper_url": "https://www.semanticscholar.org/paper/156d217b0a911af97fa1b5a71dc909ccef7a8028",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate cased BERT-base and RoBERTa-large models for document-level relation extraction, focusing on complex relations in scientific documents.",
          "citing_paper_id": "237635295",
          "cited_paper_id": 277550631,
          "context_text": "Based on Huggingface (Wolf et al., 2019), we apply cased BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) for DocRED and cased SciBERT (Beltagy et al., 2019) for CDR and GDA.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions specific datasets (DocRED, CDR, GDA) used for document-level event extraction. These datasets are clearly identified and used in the research.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-main.171",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/f6055cf63e4d24c75f8ff4c3c7e2fbd7a2695119",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c95383f251a62c63217586059c67f63507c3e839",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate graph-based models on document-level relation extraction, focusing on the performance of various graph convolutional network approaches.",
          "citing_paper_id": "248300064",
          "cited_paper_id": 3144218,
          "context_text": "On the DocRED Dataset, we choose the following two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang et al., 2020], GAIN [Zeng et al., 2020], and HeterGSAN [Xu et al., 2021b].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the DocRED Dataset, which is used for evaluating graph-based models on document-level relation extraction tasks.",
          "citing_paper_doi": "10.48550/arXiv.2204.09851",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/33b9945129171b1cbcded4a5f4ba122dbb6c0528",
          "cited_paper_url": "https://www.semanticscholar.org/paper/36eff562f65125511b5dfab68ce7f7a943c27478",
          "citing_paper_year": 2022,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate graph-based models on document-level relation extraction, focusing on the performance of various graph convolutional network approaches.",
          "citing_paper_id": "248300064",
          "cited_paper_id": 3292002,
          "context_text": "On the DocRED Dataset, we choose the following two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang et al., 2020], GAIN [Zeng et al., 2020], and HeterGSAN [Xu et al., 2021b].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the DocRED Dataset, which is used for evaluating graph-based models on document-level relation extraction tasks.",
          "citing_paper_doi": "10.48550/arXiv.2204.09851",
          "cited_paper_doi": "10.17863/CAM.48429",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33b9945129171b1cbcded4a5f4ba122dbb6c0528",
          "cited_paper_url": "https://www.semanticscholar.org/paper/33998aff64ce51df8dee45989cdca4b6b1329ec4",
          "citing_paper_year": 2022,
          "cited_paper_year": 2017
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate graph-based models on document-level relation extraction, focusing on the performance of various graph convolutional network approaches.",
          "citing_paper_id": "248300064",
          "cited_paper_id": 5458500,
          "context_text": "On the DocRED Dataset, we choose the following two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang et al., 2020], GAIN [Zeng et al., 2020], and HeterGSAN [Xu et al., 2021b].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the DocRED Dataset, which is used for evaluating graph-based models on document-level relation extraction tasks.",
          "citing_paper_doi": "10.48550/arXiv.2204.09851",
          "cited_paper_doi": "10.1007/978-3-319-93417-4_38",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33b9945129171b1cbcded4a5f4ba122dbb6c0528",
          "cited_paper_url": "https://www.semanticscholar.org/paper/cd8a9914d50b0ac63315872530274d158d6aff09",
          "citing_paper_year": 2022,
          "cited_paper_year": 2017
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate graph-based models on document-level relation extraction, focusing on the performance of various graph convolutional network approaches.",
          "citing_paper_id": "248300064",
          "cited_paper_id": 190001673,
          "context_text": "On the DocRED Dataset, we choose the following two types of models as the baseline:\n• Graph-based Models: This type of method uses graph convolutional networks (GCN) [Kipf and Welling, 2016; Veličković et al., 2017; Schlichtkrull et al., 2018] to complete inference on document-level graphs, including GEDA [Li et al., 2020], LSR [Nan et al., 2020], GLRE [Wang et al., 2020], GAIN [Zeng et al., 2020], and HeterGSAN [Xu et al., 2021b].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the DocRED Dataset, which is used for evaluating graph-based models on document-level relation extraction tasks.",
          "citing_paper_doi": "10.48550/arXiv.2204.09851",
          "cited_paper_doi": "10.18653/v1/P19-1024",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33b9945129171b1cbcded4a5f4ba122dbb6c0528",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e4363d077a890c8d5c5e66b82fe69a1bbbdd5c80",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate document-level relation extraction models, focusing on complex relations across multiple sentences in scientific documents. | Used to evaluate document-level relation extraction models, focusing on complex relations across multiple sentences within documents.",
          "citing_paper_id": "252873525",
          "cited_paper_id": 189898081,
          "context_text": ", 2017) and DocRED (Yao et al., 2019) are two other prominent benchmarks in this area.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions 'DocRED' as a benchmark, which is a specific dataset used for document-level relation extraction. It is included based on the context and the cited paper title.",
          "citing_paper_doi": "10.48550/arXiv.2210.06600",
          "cited_paper_doi": "10.18653/v1/P19-1074",
          "citing_paper_url": "https://www.semanticscholar.org/paper/67e82404e2c4d57d018fa64a4974b459a7fe7d84",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2745fc72e1dd53d1c30f17cf05841b163c2f63c9",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to train and evaluate models for cross-sentence relation extraction on Wikipedia paragraphs, focusing on document-level understanding and complex relational structures.",
          "citing_paper_id": "218470122",
          "cited_paper_id": 189898081,
          "context_text": "Recently, however, Yao et al. (2019) introduced DocRED, a dataset of cross-sentence relation extractions on Wikipedia paragraphs.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'DocRED' as a dataset introduced for document-level relation extraction, which is directly relevant to the research topic.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.670",
          "cited_paper_doi": "10.18653/v1/P19-1074",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e99a259299d4d555ee4c354f2095ab4401369c82",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2745fc72e1dd53d1c30f17cf05841b163c2f63c9",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used for cross-sentence relation extraction on Wikipedia paragraphs, focusing on developing methods to handle complex document-level relations.",
          "citing_paper_id": "218470122",
          "cited_paper_id": 202718944,
          "context_text": ", 2018; Jie and Lu, 2019). Recently, however, Yao et al. (2019) introduced DocRED, a dataset of cross-sentence relation extractions on Wikipedia paragraphs.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "DocRED is mentioned as a specific dataset introduced for cross-sentence relation extraction on Wikipedia paragraphs.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.670",
          "cited_paper_doi": "10.18653/v1/D19-1399",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e99a259299d4d555ee4c354f2095ab4401369c82",
          "cited_paper_url": "https://www.semanticscholar.org/paper/ab4862a273f37176a47ecce30b995ffa563838d6",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate document-level relation extraction, focusing on chemical and disease relations in biomedical texts. | Used to compare document-level relation extraction performance, focusing on complex relations across multiple sentences. | Used for document-level relation extraction, focusing on chemical and disease relations in biomedical texts. | Used to compare statistics and performance with other relation extraction datasets, focusing on document-level relations.",
          "citing_paper_id": "189898081",
          "cited_paper_id": 53079972,
          "context_text": "Table 1 shows statistics of DocRED and some representative RE datasets, including sentence-level RE datasets SemEval-2010 Task 8 (Hendrickx et al., 2010), ACE 2003-2004 (Dod-dington et al., 2004), TACRED (Zhang et al., 2017), FewRel (Han et al., 2018b) and document-level RE dataset BC5CDR (Li et al., 2016).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets used for relation extraction, including document-level and sentence-level datasets. These datasets are clearly identified and used for comparison in the research.",
          "citing_paper_doi": "10.18653/v1/P19-1074",
          "cited_paper_doi": "10.18653/v1/D18-1247",
          "citing_paper_url": "https://www.semanticscholar.org/paper/2745fc72e1dd53d1c30f17cf05841b163c2f63c9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2394bbc609f8b58482166a25afa476c347d41bb1",
          "citing_paper_year": 2019,
          "cited_paper_year": 2018
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate document-level relation extraction, focusing on chemical and disease relations in biomedical texts. | Used to compare document-level relation extraction performance, focusing on complex relations across multiple sentences. | Used for document-level relation extraction, focusing on chemical and disease relations in biomedical texts. | Used to compare statistics and performance with other relation extraction datasets, focusing on document-level relations.",
          "citing_paper_id": "189898081",
          "cited_paper_id": 53080736,
          "context_text": "Table 1 shows statistics of DocRED and some representative RE datasets, including sentence-level RE datasets SemEval-2010 Task 8 (Hendrickx et al., 2010), ACE 2003-2004 (Dod-dington et al., 2004), TACRED (Zhang et al., 2017), FewRel (Han et al., 2018b) and document-level RE dataset BC5CDR (Li et al., 2016).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets used for relation extraction, including document-level and sentence-level datasets. These datasets are clearly identified and used for comparison in the research.",
          "citing_paper_doi": "10.18653/v1/P19-1074",
          "cited_paper_doi": "10.18653/v1/D18-1514",
          "citing_paper_url": "https://www.semanticscholar.org/paper/2745fc72e1dd53d1c30f17cf05841b163c2f63c9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/274b4ad4840b0a8a70c5bac3fe4b4861ce5fbb95",
          "citing_paper_year": 2019,
          "cited_paper_year": 2018
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to train and evaluate document-level relation extraction models, focusing on complex relations across multiple sentences in large-scale documents. | Used to study the distribution of relations in document-level relation extraction, focusing on the prevalence of long-tailed relations with fewer than 200 training triplets. | Used to measure the correlation of relations by counting the frequency of co-occurrence between every two relations, applying positive point-wise mutual information values. | Used for conducting statistical analysis on document-level relation extraction, focusing on identifying relations within and across sentences in long documents. | Used to demonstrate the challenge of extracting relational facts across multiple sentences, highlighting the need for document-level processing in relation extraction.",
          "citing_paper_id": "254877738",
          "cited_paper_id": 189898081,
          "context_text": "For example, on DocRED dataset (Yao et al., 2019), about 60 of the 96 non-NA relations are long-tailed, with less than 200 training triplets.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'DocRED' dataset, which is a specific, verifiable resource used for document-level relation extraction. The dataset is described as having many long-tailed relations, which is relevant to the research topic.",
          "citing_paper_doi": "10.48550/arXiv.2212.10171",
          "cited_paper_doi": "10.18653/v1/P19-1074",
          "citing_paper_url": "https://www.semanticscholar.org/paper/2fef34f2a3c793bd17b13f04d11d4494d945a282",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2745fc72e1dd53d1c30f17cf05841b163c2f63c9",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to create a Chinese document-level relation extraction dataset focusing on hard relation cases, enhancing practical applications in relation extraction. | Used for document-level relation extraction, enabling the evaluation of complex relations across multiple sentences. | Used for document-level relation extraction, focusing on challenging cases in practical applications.",
          "citing_paper_id": "253107167",
          "cited_paper_id": 236478098,
          "context_text": "Datasets We compare the preliminary investigation results on two sentence-level RE datasets: TA-CRED (Zhang et al., 2017) and Re-TACRED (Sto-ica et al., 2021), and two document-level RE datasets: DocRED (Yao et al., 2019) and Hac-RED (Cheng et al., 2021).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions four datasets, two at the sentence level and two at the document level, all of which are relevant to the research topic of document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/2022.emnlp-main.580",
          "cited_paper_doi": "10.18653/v1/2021.findings-acl.249",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c86754c01fc64a8e8b445f530fe95c1dbab4eb03",
          "cited_paper_url": "https://www.semanticscholar.org/paper/31fb3586cab89c1314bb9863d00222aeaa77d7d3",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to train and evaluate document-level relation extraction models, focusing on complex relations across multiple sentences in large-scale documents.",
          "citing_paper_id": "254877738",
          "cited_paper_id": 234762787,
          "context_text": "Yuan et al., 2019; Han et al., 2022).",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation context does not provide specific information about the datasets used. However, the cited paper titles suggest the use of document-level relation extraction datasets.",
          "citing_paper_doi": "10.48550/arXiv.2212.10171",
          "cited_paper_doi": "10.1016/j.neunet.2022.04.019",
          "citing_paper_url": "https://www.semanticscholar.org/paper/2fef34f2a3c793bd17b13f04d11d4494d945a282",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b3484ba12b843ee8a994f03c7d8a0152405f63a9",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate model performance on document-level relation extraction, focusing on coreference resolution and entity linking. | Used to conduct experiments on long-tailed relations and multi-label entity pairs, focusing on document-level event extraction using a base model. | Used to evaluate the performance of BERT-Correl BASE compared to BERT BASE, focusing on document-level information extraction and entity linking. | Used to assess model performance on document-level information extraction, emphasizing the identification of complex events and relations. | Used to evaluate the performance of BERT-Correl BASE compared to BERT BASE, focusing on document-level relation extraction and coreference resolution.",
          "citing_paper_id": "254877738",
          "cited_paper_id": 215768766,
          "context_text": "Further, our model BERT-Correl BASE improves the performance of BERT BASE by 1.30%, 1.24%, 1.09%, 1.12% for each column on DocRED dataset and 1.70%, 2.35%, 2.72%, 2.44% for each column on DWIE dataset.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, DocRED and DWIE, which are used to evaluate the performance of the BERT-Correl BASE model against BERT BASE.",
          "citing_paper_doi": "10.48550/arXiv.2212.10171",
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.582",
          "citing_paper_url": "https://www.semanticscholar.org/paper/2fef34f2a3c793bd17b13f04d11d4494d945a282",
          "cited_paper_url": "https://www.semanticscholar.org/paper/5066c41ef26ac9876ba797a7c7f49548cf713f9b",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate document-level relation extraction, focusing on complex relations across multiple sentences in scientific articles. | Used to assess document-level information extraction, specifically for identifying and linking entities and relations within Wikipedia articles.",
          "citing_paper_id": "254877738",
          "cited_paper_id": 249191749,
          "context_text": "For DocRED, the results are from their original paper, while for DWIE, we use the results reported in Yu et al. (2022).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two datasets, DocRED and DWIE, which are used for document-level relation extraction. The citation intent is to report results from these datasets.",
          "citing_paper_doi": "10.48550/arXiv.2212.10171",
          "cited_paper_doi": "10.48550/arXiv.2205.14393",
          "citing_paper_url": "https://www.semanticscholar.org/paper/2fef34f2a3c793bd17b13f04d11d4494d945a282",
          "cited_paper_url": "https://www.semanticscholar.org/paper/321f23bee0159ebc564d7bd9123838c3eb40e144",
          "citing_paper_year": 2022,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used for document-level relation extraction, specifically to predict relations using context-aware representations and attention mechanisms in an LSTM-based model.",
          "citing_paper_id": "221996144",
          "cited_paper_id": 6263378,
          "context_text": "Context-Aware , also proposed by Yao et al. (2019) on DocRED adapted from (Sorokin and Gurevych, 2017), uses an LSTM to encode the text, but further utilizes attention mechanism to absorb the context relational information for predicting.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'DocRED' as a dataset adapted from Sorokin and Gurevych (2017). It is used for document-level relation extraction, which is directly relevant to the research topic.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.127",
          "cited_paper_doi": "10.18653/v1/D17-1188",
          "citing_paper_url": "https://www.semanticscholar.org/paper/fe9ff8daee1356463d1dc363249f504e8e6809b9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f03ff33bbc473c4e3efc62cced53ff16b172d9d8",
          "citing_paper_year": 2020,
          "cited_paper_year": 2017
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to adapt a hierarchical recurrent neural network with attention for semantic relation classification, focusing on document-level relational information.",
          "citing_paper_id": "221996144",
          "cited_paper_id": 18795469,
          "context_text": "Context-Aware, also proposed by Yao et al. (2019) on DocRED adapted from (Sorokin and Gurevych, 2017), uses an LSTM to encode the text, but further utilizes attention mechanism to absorb the context relational information for predicting.",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'DocRED' as a dataset used for adapting a method, which fits the criteria for a specific, verifiable dataset.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.127",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/fe9ff8daee1356463d1dc363249f504e8e6809b9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/bd64afdf9b26de4c460c19dea17ddf043c26e61c",
          "citing_paper_year": 2020,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate GAIN’s performance on document-level relation extraction, comparing it with other baselines in a large-scale dataset. | Used to advance sentence-level relation extraction to document-level, containing a large number of annotated relation facts. | Used to evaluate the model on document-level relation extraction, following the standard split into training, development, and test sets. | Used for document-level relation extraction, specifically to predict relations using context-aware representations and attention mechanisms in an LSTM-based model. | Used to train and evaluate document-level relation extraction models, focusing on complex relations across multiple sentences within documents. | Used for document-level relation extraction, providing a large-scale dataset to train and evaluate models on complex relational structures within documents. | Used to train and evaluate the BERT-Two-Step model for document-level relation extraction, focusing on complex relations across sentences. | Used to manually analyze bad cases predicted by a BiLSTM-based model, focusing on document-level relation extraction errors and their characteristics. | Used to adapt and evaluate graph-based relation extraction models, focusing on document-level relations using graph convolutional neural networks and latent structure induction. | Used to evaluate GAIN's performance in document-level relation extraction, particularly in inter-sentence and inferential relations scenarios. | Used to evaluate GAIN on document-level relation extraction, focusing on the performance of the model across various relations in a large-scale dataset. | Used to study document-level relation extraction, focusing on complex relations across multiple sentences within documents.",
          "citing_paper_id": "221996144",
          "cited_paper_id": 189898081,
          "context_text": "Context-Aware , also proposed by Yao et al. (2019) on DocRED adapted from (Sorokin and Gurevych, 2017), uses an LSTM to encode the text, but further utilizes attention mechanism to absorb the context relational information for predicting.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'DocRED' as a dataset adapted from Sorokin and Gurevych (2017). It is used for document-level relation extraction, which is directly relevant to the research topic.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.127",
          "cited_paper_doi": "10.18653/v1/P19-1074",
          "citing_paper_url": "https://www.semanticscholar.org/paper/fe9ff8daee1356463d1dc363249f504e8e6809b9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2745fc72e1dd53d1c30f17cf05841b163c2f63c9",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to adapt and evaluate graph-based relation extraction models, focusing on document-level relations using graph convolutional neural networks and latent structure induction. | Adapted for inter-sentence relation extraction using graph-based models, focusing on document-level graph convolutional neural networks.",
          "citing_paper_id": "221996144",
          "cited_paper_id": 184487889,
          "context_text": "They construct a graph based on the dependency tree and predict relations by latent structure induction and GCN. Nan et al. (2020) also adapted four graph-based state-of-the-art RE models to DocRED, including GAT (Velickovic et al., 2017), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019), and AGGCN (Guo et al., 2019).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions adapting graph-based models to DocRED, which is a document-level relation extraction dataset. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.127",
          "cited_paper_doi": "10.18653/v1/P19-1423",
          "citing_paper_url": "https://www.semanticscholar.org/paper/fe9ff8daee1356463d1dc363249f504e8e6809b9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/358ca777d9992bdc06fdcc1940e3b18a8da68878",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to evaluate graph-based relation extraction models, focusing on document-level relation extraction using latent structure induction and GCN methodologies. | Used to adapt and evaluate graph-based relation extraction models, focusing on document-level relations using graph convolutional neural networks and latent structure induction.",
          "citing_paper_id": "221996144",
          "cited_paper_id": 218613850,
          "context_text": "They construct a graph based on the dependency tree and predict relations by latent structure induction and GCN. Nan et al. (2020) also adapted four graph-based state-of-the-art RE models to DocRED, including GAT (Velickovic et al., 2017), GCNN (Sahu et al., 2019), EoG (Christopoulou et al., 2019), and AGGCN (Guo et al., 2019).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions adapting graph-based models to DocRED, which is a document-level relation extraction dataset. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.127",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.141",
          "citing_paper_url": "https://www.semanticscholar.org/paper/fe9ff8daee1356463d1dc363249f504e8e6809b9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/013faec0400d315935e71a2bdfeb22cc83752b3e",
          "citing_paper_year": 2020,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used for document-level relation extraction experiments under incomplete labeling and extreme incomplete labeling settings, demonstrating the effectiveness of the P 3 M method. | Used to highlight issues in document-level relation extraction, specifically the presence of false negatives due to unlabeled positive relations in the dataset. | Used for document-level relation extraction experiments, showing a significant improvement in F1 score by about 4-10 points compared to the baseline.",
          "citing_paper_id": "259261857",
          "cited_paper_id": 189898081,
          "context_text": "We conduct experiments on the DocRED (Yao et al. 2019) dataset under incomplete labeling and extreme incomplete labeling settings, as well as the ChemDisGene (Zhang et al. 2022) the F1 score by about 4-10 points compared to the base-line, demonstrating the effectiveness of our proposed P 3 M method.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, DocRED and ChemDisGene, which are used for document-level relation extraction experiments. The usage is clearly described, including the settings and the impact on performance.",
          "citing_paper_doi": "10.48550/arXiv.2306.14806",
          "cited_paper_doi": "10.18653/v1/P19-1074",
          "citing_paper_url": "https://www.semanticscholar.org/paper/9adb93ae05d08d3e5ec275d9881ea7d496dd1c8a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2745fc72e1dd53d1c30f17cf05841b163c2f63c9",
          "citing_paper_year": 2023,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used for document-level relation extraction experiments under incomplete labeling and extreme incomplete labeling settings, demonstrating the effectiveness of the P 3 M method. | Used for document-level relation extraction experiments, showing a significant improvement in F1 score by about 4-10 points compared to the baseline.",
          "citing_paper_id": "259261857",
          "cited_paper_id": 248178003,
          "context_text": "We conduct experiments on the DocRED (Yao et al. 2019) dataset under incomplete labeling and extreme incomplete labeling settings, as well as the ChemDisGene (Zhang et al. 2022) the F1 score by about 4-10 points compared to the base-line, demonstrating the effectiveness of our proposed P 3 M method.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, DocRED and ChemDisGene, which are used for document-level relation extraction experiments. The usage is clearly described, including the settings and the impact on performance.",
          "citing_paper_doi": "10.48550/arXiv.2306.14806",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/9adb93ae05d08d3e5ec275d9881ea7d496dd1c8a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/d91f66bc5dc644d5e29ad291afe2c950747aaaa1",
          "citing_paper_year": 2023,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to train and evaluate the BERT-Two-Step model for document-level relation extraction, focusing on complex relations across sentences.",
          "citing_paper_id": "221996144",
          "cited_paper_id": 202539732,
          "context_text": "BERT-Two-Step base , proposed by Wang et al. (2019a) on DocRED.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'DocRED', which is a document-level relation extraction dataset. The cited paper titles confirm that DocRED is indeed a dataset.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.127",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/fe9ff8daee1356463d1dc363249f504e8e6809b9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/fd075bcdf2d7e13d23f7c249a8eded343d5bbe3b",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "DocRED",
          "dataset_description": "Used to train and evaluate the BERT-Two-Step model for document-level relation extraction, focusing on complex relations across sentences.",
          "citing_paper_id": "221996144",
          "cited_paper_id": 202889074,
          "context_text": "BERT-Two-Step base , proposed by Wang et al. (2019a) on DocRED.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'DocRED', which is a document-level relation extraction dataset. The cited paper titles confirm that DocRED is indeed a dataset.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.127",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/fe9ff8daee1356463d1dc363249f504e8e6809b9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/cccd1e6fead0a0a0689d8dd53a0b235b3c27b2c4",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "220524732",
      "citation_count": 0,
      "total_dataset_mentions": 29,
      "unique_datasets": [
        "RAMS"
      ],
      "dataset_details": [
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to study document-level event extraction, focusing on argument linking across multiple sentences with a limited set of argument types.",
          "citing_paper_id": "250390839",
          "cited_paper_id": 207853145,
          "context_text": ", 2021) and RAMS(Ebner et al., 2020) consist of 246/9,124 documents with only 59/65 argument types, and most of the arguments in the two datasets are shared among",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions two datasets, RAMS and another unnamed dataset, which are used for document-level event extraction. The datasets are described in terms of their size and argument types.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-main.291",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c8e30e459ad7769528ac7eae051134d245ca16ee",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used for document-level event extraction, emphasizing large-scale and fine-grained event annotation in multi-sentence contexts. | Used to train and evaluate cross-domain event extraction models, focusing on natural disaster events as the target domain and other event types as source domains. | Used as a benchmark for document-level event extraction, focusing on fine-grained event classification and entity linking in complex documents. | Used as a benchmark for document-level event extraction, containing 27,000+ events and 180,000+ arguments across 27,485 Wikipedia articles. | Used for document-level event extraction, providing a benchmark for evaluating systems on complex, multi-event documents. | Used to develop and evaluate models for document-level event extraction, focusing on fine-grained and multisentence events in a large-scale benchmark. | A large-scale and fine-grained benchmark for document-level event extraction, designed to test the ability of systems to identify and classify events in documents. | Used for multi-sentence event extraction, focusing on the identification and classification of events across multiple sentences. | Used to benchmark document-level event extraction, focusing on fine-grained event types determined by the article title and content without trigger words. | Used to benchmark document-level event extraction, focusing on large-scale and fine-grained annotations of events and arguments. | Used to benchmark document-level event extraction, specifically evaluating performance on 31 hard news and 28 soft news event types with their arguments. | Used as a benchmark for document-level event extraction, containing 27,000+ events and 180,000+ arguments across 27,485 Wikipedia articles, focusing on fine-grained event and argument identification.",
          "citing_paper_id": "252090194",
          "cited_paper_id": 250390839,
          "context_text": "The recent RAMS (Ebner et al., 2020) and DocEE (Tong et al., 2022) corpora focus on multi-sentence event extraction.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two corpora, RAMS and DocEE, both of which are used for document-level event extraction. DocEE is specifically noted for being large-scale and fine-grained.",
          "citing_paper_doi": "10.48550/arXiv.2209.02203",
          "cited_paper_doi": "10.18653/v1/2022.naacl-main.291",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1ed23d77d0b80e36ebe8833eb92c363d65356307",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c8e30e459ad7769528ac7eae051134d245ca16ee",
          "citing_paper_year": 2022,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used for hyper-parameter tuning during the fine-tuning phase, specifically adjusting batch size and learning rate for optimal performance.",
          "citing_paper_id": "252901047",
          "cited_paper_id": 6546734,
          "context_text": "In the ﬁne-tuning state, we employ the RAMS development set for hyper-parameter tuning, and ﬁnally, the batch size is set to 20 (selected from [1, 5, 10, 20, 30, 40]) and the learning rate is set to 2e-5 (picked from [1e-5, 2e-5, 3e-5, 4e-5]).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the use of the RAMS development set for hyper-parameter tuning, which is a specific dataset used in the document-level event extraction domain.",
          "citing_paper_doi": "10.1109/TASLP.2022.3210442",
          "cited_paper_doi": "10.1609/aaai.v31i1.10894",
          "citing_paper_url": "https://www.semanticscholar.org/paper/46de1ace70891306ca2dcc06a974d1d23ba77c7f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/33d6aa6c41ce3000161d9b5eea910a5b78e14330",
          "citing_paper_year": 2022,
          "cited_paper_year": 2017
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to validate the effectiveness of the approach in document-level event extraction, focusing on multi-sentence argument linking. | Used to evaluate the approach's ability to handle complex event structures in news articles, focusing on message understanding. | Used to test the approach's performance in identifying and linking events across multiple sentences in Wikipedia articles. | Used to train and evaluate models on document-level event extraction, specifically for identifying and linking events in news articles. | Used to highlight the distribution of role instances in a large document-level event extraction benchmark, focusing on the scarcity of certain roles. | Used to train and evaluate models on document-level event extraction, focusing on linking events across multiple sentences.",
          "citing_paper_id": "252901047",
          "cited_paper_id": 207853145,
          "context_text": "To validate the effectiveness of our approach, we have conducted extensive tests on three datasets, i.e., RAMS [2], WikiEvents [5], and MUC-4 [14].",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions three specific datasets used for validating the approach. These datasets are clearly named and relevant to document-level event extraction.",
          "citing_paper_doi": "10.1109/TASLP.2022.3210442",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/46de1ace70891306ca2dcc06a974d1d23ba77c7f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to highlight the challenge of limited training data in event argument detection, specifically noting that over 63% of roles have fewer than 100 examples, impacting model performance. | Used for error analysis in implicit event argument detection, focusing on identifying common errors in the development phase of the model. | Used to evaluate implicit event argument detection, focusing on the configuration with type constraints on the development set.",
          "citing_paper_id": "252901047",
          "cited_paper_id": 220046861,
          "context_text": "Despitemanyadvancesonthistask,theproblemofinadequate training data still limits a model’s performance [29] — for example, even on the largest dataset RAMS, over 63% of the roles have fewer than 100 examples, limiting the performance of the currently best model to less than 50% in F1 [4].",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'RAMS' as a dataset with inadequate training data, which is relevant to the document-level event extraction task.",
          "citing_paper_doi": "10.1109/TASLP.2022.3210442",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.667",
          "citing_paper_url": "https://www.semanticscholar.org/paper/46de1ace70891306ca2dcc06a974d1d23ba77c7f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/65bf813891b05c26d1cb3608c281d36a641ef366",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to highlight the challenge of limited training data in event argument detection, specifically noting that over 63% of roles have fewer than 100 examples, impacting model performance.",
          "citing_paper_id": "252901047",
          "cited_paper_id": 236087324,
          "context_text": "Despitemanyadvancesonthistask,theproblemofinadequate training data still limits a model’s performance [29] — for example, even on the largest dataset RAMS, over 63% of the roles have fewer than 100 examples, limiting the performance of the currently best model to less than 50% in F1 [4].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'RAMS' as a dataset with inadequate training data, which is relevant to the document-level event extraction task.",
          "citing_paper_doi": "10.1109/TASLP.2022.3210442",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/46de1ace70891306ca2dcc06a974d1d23ba77c7f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/38eb771e1336b74be5af6dd3fbe9fd77649ccb0c",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to study the extent to which BERT pre-training assists in learning event arguments, focusing on the model's existing knowledge of event structures.",
          "citing_paper_id": "252901047",
          "cited_paper_id": 222208551,
          "context_text": "in [26] study the extent to which the pre-trained language model can assist learning; authors in [27] suggests that knowledge from",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context does not provide specific information about the usage of the RAMS dataset, but the title indicates it is used for studying event arguments with BERT.",
          "citing_paper_doi": "10.1109/TASLP.2022.3210442",
          "cited_paper_doi": "10.18653/v1/2020.blackboxnlp-1.1",
          "citing_paper_url": "https://www.semanticscholar.org/paper/46de1ace70891306ca2dcc06a974d1d23ba77c7f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/069498dea2abf78bc15d3e82ba23268d46d8fba2",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to evaluate event extraction models, reporting Span F1 and Head F1 metrics to assess performance in identifying and classifying events.",
          "citing_paper_id": "248496614",
          "cited_paper_id": 220046861,
          "context_text": "Following Zhang et al. (2020b), we report the Span F1 and Head F1 for RAMS dataset.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for event extraction. The dataset is used to report performance metrics (Span F1 and Head F1) in the research.",
          "citing_paper_doi": "10.48550/arXiv.2205.00241",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.667",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5037621e03bafa4a069eafe3561af16e08338680",
          "cited_paper_url": "https://www.semanticscholar.org/paper/65bf813891b05c26d1cb3608c281d36a641ef366",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to evaluate event extraction models, reporting Span F1 and Head F1 metrics to assess performance in identifying and classifying events.",
          "citing_paper_id": "248496614",
          "cited_paper_id": 220524732,
          "context_text": "Following Zhang et al. (2020b), we report the Span F1 and Head F1 for RAMS dataset.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for event extraction. The dataset is used to report performance metrics (Span F1 and Head F1) in the research.",
          "citing_paper_doi": "10.48550/arXiv.2205.00241",
          "cited_paper_doi": "10.1101/2020.08.03.20167569",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5037621e03bafa4a069eafe3561af16e08338680",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2718b77060c73f8e9006e76ab05bc33ac4d0ae51",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to provide detailed data statistics for document-level event extraction, focusing on the distribution and characteristics of events and relations.",
          "citing_paper_id": "248496614",
          "cited_paper_id": null,
          "context_text": "As791 the number of AMR relation types is large, which792 results in too many demanded parameters, we fol-793 low Zhang and Ji (2021) to cluster the relation types794 into main categories as shown in Table 5.795\nB Statistics of Datasets796\nThe detailed data statistics of RAMS and797 WikiEvents…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'RAMS' and 'WikiEvents' as datasets, which are multi-word proper nouns and likely refer to specific, verifiable datasets used in the research.",
          "citing_paper_doi": "10.48550/arXiv.2205.00241",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/5037621e03bafa4a069eafe3561af16e08338680",
          "cited_paper_url": null,
          "citing_paper_year": 2022,
          "cited_paper_year": null
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used for conducting ablation studies on SCPRGbase and SCPRGlarge, focusing on document-level event extraction performance. | Used to evaluate the performance of SCPRGbase and SCPRGlarge models after removing the RLIG module, focusing on Span F1 and Head F1 metrics. | Used to evaluate document-level event argument extraction, reporting Span F1 and Head F1 on development and test sets. | Used to train the SCPRG model for 50 epochs, focusing on document-level event extraction and argument linking. | Used for an ablation study on SCPRG, analyzing the clarity between latent role representations from two events in the dataset. | Used to train the SCPRG model for 100 epochs, focusing on document-level event extraction and argument linking. | Used to provide a document example for argument linking, focusing on multi-sentence structures and their relationships in the context of document-level event extraction. | Used to count and visualize the frequency of co-occurrence between the 15 most frequent roles, focusing on event extraction and argument linking. | Used to generate and display the cooccurrence frequency matrix of roles, focusing on document-level event extraction and role relationships. | Used to evaluate experimental results on document-level event extraction, focusing on performance metrics on both development and test sets. | Used to evaluate the proposed model on document-level event argument extraction, focusing on multi-sentence argument linking. | Used to visualize embeddings of arguments and roles from multiple documents, focusing on document-level event extraction and argument linking. | Used to evaluate the performance of the SCPRG model, specifically measuring F1 score improvements over previous state-of-the-art models. | Used to conduct an ablation study on document-level event extraction, evaluating the performance of different components in the system.",
          "citing_paper_id": "259858959",
          "cited_paper_id": 207853145,
          "context_text": "In this section, we show the complete cooccurrence frequency matrix which contains all roles in RAMS test set.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'RAMS test set' as a specific dataset used to show the cooccurrence frequency matrix. The dataset is relevant to document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/2023.findings-acl.817",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/9cbd7f7c942e09abdece12a12fad34e20aa60a8a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2023,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to evaluate document-level event argument extraction, reporting Span F1 and Head F1 on development and test sets.",
          "citing_paper_id": "259858959",
          "cited_paper_id": 248496614,
          "context_text": "Following (Xu et al., 2022), we report the Span F1 and Head F1 on dev and test sets for RAMS dataset.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for evaluation. The citation intent is to report performance metrics on this dataset.",
          "citing_paper_doi": "10.18653/v1/2023.findings-acl.817",
          "cited_paper_doi": "10.48550/arXiv.2205.00241",
          "citing_paper_url": "https://www.semanticscholar.org/paper/9cbd7f7c942e09abdece12a12fad34e20aa60a8a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/5037621e03bafa4a069eafe3561af16e08338680",
          "citing_paper_year": 2023,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to evaluate Span-F1 and Head-F1 metrics, focusing on argument extraction in document-level event extraction. | Used to evaluate Coref-F1 metric, which considers co-reference linkages between arguments in document-level event extraction.",
          "citing_paper_id": "259370721",
          "cited_paper_id": 216562330,
          "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the topic.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.532",
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.49",
          "citing_paper_url": "https://www.semanticscholar.org/paper/70cb23e280893105cbf582affe439e858916765f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/37e3ebc322895dd9348f080c45600dca737ff60f",
          "citing_paper_year": 2023,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to evaluate Span-F1 and Head-F1 metrics, focusing on argument extraction in document-level event extraction. | Used to evaluate Coref-F1 metric, which considers co-reference linkages between arguments in document-level event extraction.",
          "citing_paper_id": "259370721",
          "cited_paper_id": 218630327,
          "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the topic.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.532",
          "cited_paper_doi": "10.18653/V1/2020.ACL-MAIN.714",
          "citing_paper_url": "https://www.semanticscholar.org/paper/70cb23e280893105cbf582affe439e858916765f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6c1244d21cf1f6a490495f155ced8802b489ee4e",
          "citing_paper_year": 2023,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to define the candidate set for entity recognition in document-level event argument extraction, providing ground-truth entities for training and evaluation. | Used to evaluate Span-F1 and Head-F1 metrics, focusing on argument extraction in document-level event extraction. | Used to evaluate Coref-F1 metric, which considers co-reference linkages between arguments in document-level event extraction. | Used for document-level event argument extraction experiments, focusing on conditional generation methods to improve extraction accuracy.",
          "citing_paper_id": "259370721",
          "cited_paper_id": 233219850,
          "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the topic.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.532",
          "cited_paper_doi": "10.18653/V1/2021.NAACL-MAIN.69",
          "citing_paper_url": "https://www.semanticscholar.org/paper/70cb23e280893105cbf582affe439e858916765f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2a15f541a8216782a7579f01f56762448e48b582",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to evaluate Span-F1 and Head-F1 metrics, focusing on argument extraction in document-level event extraction. | Used to evaluate Coref-F1 metric, which considers co-reference linkages between arguments in document-level event extraction.",
          "citing_paper_id": "259370721",
          "cited_paper_id": 247084444,
          "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the topic.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.532",
          "cited_paper_doi": "10.18653/v1/2022.acl-long.466",
          "citing_paper_url": "https://www.semanticscholar.org/paper/70cb23e280893105cbf582affe439e858916765f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3fbe7f9a0ca640c915d1b4e2cca6e49a15ad710a",
          "citing_paper_year": 2023,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to assess document-level event extraction, emphasizing the identification of events and their arguments across multiple sentences. | Used to evaluate document-level event argument extraction, focusing on identifying and labeling extra-sentential arguments in complex documents. | Used to evaluate argument linking, a generalization of semantic role labeling, focusing on extra-sentential arguments in document-level event extraction. | Utilized for document-level event argument extraction, specifically for linking arguments that appear in different sentences from their predicates, improving event coherence. | Used for document-level event argument extraction, focusing on linking arguments across sentences, enhancing the understanding of event structures.",
          "citing_paper_id": "252873525",
          "cited_paper_id": 233219850,
          "context_text": "Argument linking — a generalization of semantic role labeling (SRL; Gildea and Jurafsky, 2002) in which a predicate’s extra-sentential arguments must also be labeled — is one notable example, and has attracted recent attention through the RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021) benchmarks.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two benchmarks, RAMS and WikiEvents, which are used for document-level event argument extraction. These are specific datasets used in the research.",
          "citing_paper_doi": "10.48550/arXiv.2210.06600",
          "cited_paper_doi": "10.18653/V1/2021.NAACL-MAIN.69",
          "citing_paper_url": "https://www.semanticscholar.org/paper/67e82404e2c4d57d018fa64a4974b459a7fe7d84",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2a15f541a8216782a7579f01f56762448e48b582",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to support document-level event extraction, specifically focusing on cross-sentence argument linking with annotations, but limited to one event per document.",
          "citing_paper_id": "248780117",
          "cited_paper_id": 207853145,
          "context_text": "To support the progress for the problem, Ebner et al. (2020) built RAMS dataset, and it contains annotations for cross-sentence arguments but for each document it contains only one event.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for document-level event extraction. The dataset is described as containing annotations for cross-sentence arguments but limited to one event per document.",
          "citing_paper_doi": "10.18653/v1/2022.acl-long.361",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5f266a559337ffc886e0eed6a1d08c0302ce3f03",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to train and evaluate models on document-level event extraction, focusing on 139 event types and 65 semantic roles. | Used to evaluate event argument extraction, focusing on identifying and linking arguments to events in text. | Used to evaluate the role-specific selector's impact on argument classification scores, focusing on multi-sentence argument linking. | Used to evaluate event argument extraction models, specifically for identifying and linking arguments to events in multi-sentence contexts. | Used to test the role-specific selector's performance, noting a slight negative effect on argument classification scores in this dataset. | Used to assess the role-specific selector's effectiveness in improving argument classification scores, particularly in the context of multi-sentence events. | Used to explore the impact of role-specific selectors in identifying and disambiguating roles within complex ontology structures in long documents, featuring 59 role types. | Used to explore the impact of role-specific selectors in identifying and disambiguating roles within complex ontology structures in long documents, featuring 36 role types. | Used to conduct experiments on event argument extraction, focusing on identifying and linking arguments to events in multi-sentence contexts. | Used to explore the impact of role-specific selectors in identifying and disambiguating roles within complex ontology structures in long documents, featuring 65 role types. | Used to evaluate the performance of EEQA-BART and BART-Gen models on document-level event argument extraction, focusing on argument classification (Arg-C).",
          "citing_paper_id": "247084444",
          "cited_paper_id": 207853145,
          "context_text": "The EEQA-BART model shows almost the same Arg-C with BART-Gen (Li et al., 2021) on RAMS dataset.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'RAMS dataset' which is a specific, verifiable dataset used for evaluating event argument extraction models.",
          "citing_paper_doi": "10.18653/v1/2022.acl-long.466",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/3fbe7f9a0ca640c915d1b4e2cca6e49a15ad710a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used for event argument extraction, focusing on document-level conditional generation to improve model performance. | Employed for benchmarking event argument extraction systems, providing a standard dataset for document-level event extraction tasks. | Used for document-level event argument extraction, focusing on conditional generation methods to improve event argument identification. | Used to evaluate the performance of EEQA-BART and BART-Gen models on document-level event argument extraction, focusing on argument classification (Arg-C). | Utilized for evaluating event argument extraction models, emphasizing document-level context in conditional generation. | Used to evaluate Argument Head F1 score in document-level event argument extraction, focusing on the matching of the head word of an argument. | Utilized for evaluating event extraction models, specifically assessing performance on document-level event arguments. | Used to evaluate Argument Head F1 score, focusing on the matching of the headword of an argument in document-level event extraction. | Used to evaluate event argument extraction systems, focusing on document-level conditional generation for event arguments.",
          "citing_paper_id": "247084444",
          "cited_paper_id": 233219850,
          "context_text": "The EEQA-BART model shows almost the same Arg-C with BART-Gen (Li et al., 2021) on RAMS dataset.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'RAMS dataset' which is a specific, verifiable dataset used for evaluating event argument extraction models.",
          "citing_paper_doi": "10.18653/v1/2022.acl-long.466",
          "cited_paper_doi": "10.18653/V1/2021.NAACL-MAIN.69",
          "citing_paper_url": "https://www.semanticscholar.org/paper/3fbe7f9a0ca640c915d1b4e2cca6e49a15ad710a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2a15f541a8216782a7579f01f56762448e48b582",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to highlight the entity-centric nature and limited event coverage in document-level event extraction, focusing on specific abstract event types.",
          "citing_paper_id": "258865260",
          "cited_paper_id": 250390839,
          "context_text": "Recent works have introduced document-level EAE datasets like RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021), and Do-cEE (Tong et al., 2022); but their ontologies are also entity-centric, and their event coverage is limited to specific abstract event types (Figure 1).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions three specific datasets relevant to document-level event extraction, which are used to highlight the limitations in their ontologies and event coverage.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.203",
          "cited_paper_doi": "10.18653/v1/2022.naacl-main.291",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33c3eb62f55b4f46d812723fd3a053fc8c17fd21",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c8e30e459ad7769528ac7eae051134d245ca16ee",
          "citing_paper_year": 2022,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used for conducting experiments on implicit event argument extraction, focusing on identifying arguments in complex, multi-sentence contexts. | Used for evaluating implicit event argument extraction models, providing a rich set of annotated documents for training and testing. | Used to assess the performance of the proposed method in document-level event extraction, emphasizing the identification and linking of events across multiple sentences. | Used to evaluate the effectiveness of the proposed approach in document-level event extraction, focusing on multi-sentence argument linking.",
          "citing_paper_id": "248496246",
          "cited_paper_id": 207853145,
          "context_text": "We conduct extensive experiments on two implicit EAE datasets, namely RAMS [ Ebner et al. , 2020 ] and WikiEvents [ Li et al. , 2021 ] , which have been widely used in previous studies [ Li et al. , 2021; Liu et al. , 2021a ] .",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for conducting experiments on implicit EAE (Event Argument Extraction). These datasets are widely used in previous studies, indicating their relevance and reusability.",
          "citing_paper_doi": "10.48550/arXiv.2205.00498",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/65d88194a902332b78dd5a7b919fa577bfa7ee9f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used for conducting experiments on implicit event argument extraction, focusing on identifying arguments in complex, multi-sentence contexts. | Used for evaluating implicit event argument extraction models, providing a rich set of annotated documents for training and testing. | Used to assess the performance of the proposed method in document-level event extraction, emphasizing the identification and linking of events across multiple sentences. | Used to evaluate the effectiveness of the proposed approach in document-level event extraction, focusing on multi-sentence argument linking.",
          "citing_paper_id": "248496246",
          "cited_paper_id": 230433941,
          "context_text": "We conduct extensive experiments on two implicit EAE datasets, namely RAMS [ Ebner et al. , 2020 ] and WikiEvents [ Li et al. , 2021 ] , which have been widely used in previous studies [ Li et al. , 2021; Liu et al. , 2021a ] .",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for conducting experiments on implicit EAE (Event Argument Extraction). These datasets are widely used in previous studies, indicating their relevance and reusability.",
          "citing_paper_doi": "10.48550/arXiv.2205.00498",
          "cited_paper_doi": "10.18653/v1/2021.acl-long.353",
          "citing_paper_url": "https://www.semanticscholar.org/paper/65d88194a902332b78dd5a7b919fa577bfa7ee9f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/53d8b356551a2361020a948f64454a6d599af69f",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to assess the performance of the proposed method in document-level event extraction, emphasizing the identification and linking of events across multiple sentences. | Used to evaluate the effectiveness of the proposed approach in document-level event extraction, focusing on multi-sentence argument linking. | Used for conducting experiments on implicit event argument extraction, focusing on identifying arguments in complex, multi-sentence contexts. | Used to evaluate the effectiveness of the proposed approach in document-level event extraction, focusing on multi-event documents and their temporal and causal relationships. | Used to train and evaluate document-level event extraction models, focusing on identifying and classifying events within documents. | Utilized for evaluating document-level event extraction systems, emphasizing the identification of complex event structures and relations. | Used for evaluating implicit event argument extraction models, providing a rich set of annotated documents for training and testing.",
          "citing_paper_id": "248496246",
          "cited_paper_id": null,
          "context_text": "We conduct extensive experiments on two implicit EAE datasets, namely RAMS [ Ebner et al. , 2020 ] and WikiEvents [ Li et al. , 2021 ] , which have been widely used in previous studies [ Li et al. , 2021; Liu et al. , 2021a ] .",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for conducting experiments on implicit EAE (Event Argument Extraction). These datasets are widely used in previous studies, indicating their relevance and reusability.",
          "citing_paper_doi": "10.48550/arXiv.2205.00498",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/65d88194a902332b78dd5a7b919fa577bfa7ee9f",
          "cited_paper_url": null,
          "citing_paper_year": 2022,
          "cited_paper_year": null
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to evaluate the extent to which pre-trained language models benefit learning in event argument extraction tasks, focusing on the model's existing knowledge of event arguments.",
          "citing_paper_id": "243865143",
          "cited_paper_id": 222208551,
          "context_text": "Following the work, Zhang et al. (2020) devise a head-to-region approach, demonstrating very promising results; Gangal and Hovy (2020) investigate to what extent the pre-trained language model can beneﬁt learning.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions the RAMS dataset, which is a well-known resource for event argument extraction. The context indicates its use in evaluating pre-trained language models.",
          "citing_paper_doi": "10.18653/v1/2021.emnlp-main.214",
          "cited_paper_doi": "10.18653/v1/2020.blackboxnlp-1.1",
          "citing_paper_url": "https://www.semanticscholar.org/paper/648a53e10c8caf276c8bc2e6777ba4baec76fac6",
          "cited_paper_url": "https://www.semanticscholar.org/paper/069498dea2abf78bc15d3e82ba23268d46d8fba2",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Utilized to evaluate the performance of the proposed method on document-level event extraction, emphasizing the accuracy and robustness of the system. | Used to assess performance in implicit event argument extraction, specifically for document-level event extraction tasks. | Used to validate the effectiveness of the document-level event argument extraction approach through conditional generation, focusing on complex event structures. | Used to evaluate implicit event argument extraction, focusing on document-level conditional generation methods.",
          "citing_paper_id": "243865143",
          "cited_paper_id": 233219850,
          "context_text": "The expensive experiments on two datasets, RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021), have justiﬁed the effectiveness of our approach.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used to justify the effectiveness of the approach described in the paper.",
          "citing_paper_doi": "10.18653/v1/2021.emnlp-main.214",
          "cited_paper_doi": "10.18653/V1/2021.NAACL-MAIN.69",
          "citing_paper_url": "https://www.semanticscholar.org/paper/648a53e10c8caf276c8bc2e6777ba4baec76fac6",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2a15f541a8216782a7579f01f56762448e48b582",
          "citing_paper_year": 2021,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to illustrate the smaller scale of event argument datasets, containing 1,370 frame instantiations over 438 sentences. | Used to compare the size and coverage of event argument datasets, highlighting its larger scale compared to other datasets. | Used to analyze the distinction between 'core' and 'non-core' frame elements, contributing to the understanding of event arguments in semantic roles.",
          "citing_paper_id": "207853145",
          "cited_paper_id": 2486369,
          "context_text": "Although non-local arguments are a common phenomenon (Gerber and Chai (2012) found that their annotation of non-local arguments added 71% (relative) role coverage to NomBank annotations), these datasets are signiﬁcantly smaller than RAMS: the SemEval shared task training set contains 1,370 frame instantiations over 438 sentences, and the data from Gerber and Chai (2012) It is not surprising that across multiple datasets, a signiﬁcant number of event arguments are observed to be non-local given the analysis of zero anaphora and deﬁnite null complements by Fillmore (1986) and the distinction between “core” and “non-core” frame elements or roles in FrameNet (Baker et al., 1998) and Prop-Bank (Palmer et al., 2005).",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions multiple datasets but does not provide specific names for all. Only 'RAMS' and 'SemEval shared task training set' are clearly identified and used in the research context.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.718",
          "cited_paper_doi": "10.1162/0891201053630264",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "cited_paper_url": "https://www.semanticscholar.org/paper/99d2dcdcf4cf05facaa101a48c7e31d140b4736d",
          "citing_paper_year": 2019,
          "cited_paper_year": 2005
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to illustrate the smaller scale of event argument datasets, containing 1,370 frame instantiations over 438 sentences. | Used to compare the size and coverage of event argument datasets, highlighting its larger scale compared to other datasets. | Used to analyze the distinction between 'core' and 'non-core' frame elements, contributing to the understanding of event arguments in semantic roles.",
          "citing_paper_id": "207853145",
          "cited_paper_id": 2505531,
          "context_text": "Although non-local arguments are a common phenomenon (Gerber and Chai (2012) found that their annotation of non-local arguments added 71% (relative) role coverage to NomBank annotations), these datasets are signiﬁcantly smaller than RAMS: the SemEval shared task training set contains 1,370 frame instantiations over 438 sentences, and the data from Gerber and Chai (2012) It is not surprising that across multiple datasets, a signiﬁcant number of event arguments are observed to be non-local given the analysis of zero anaphora and deﬁnite null complements by Fillmore (1986) and the distinction between “core” and “non-core” frame elements or roles in FrameNet (Baker et al., 1998) and Prop-Bank (Palmer et al., 2005).",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions multiple datasets but does not provide specific names for all. Only 'RAMS' and 'SemEval shared task training set' are clearly identified and used in the research context.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.718",
          "cited_paper_doi": "10.3115/980845.980860",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "cited_paper_url": "https://www.semanticscholar.org/paper/547f23597f9ec8a93f66cedaa6fbfb73960426b1",
          "citing_paper_year": 2019,
          "cited_paper_year": 1998
        },
        {
          "dataset_name": "RAMS",
          "dataset_description": "Used to adapt span-based models for multi-sentence argument linking, specifically for slot filling tasks, enhancing the model's ability to handle complex event structures. | Used to adapt span-based models for multi-sentence argument linking, focusing on the structure and relationships within and across sentences.",
          "citing_paper_id": "207853145",
          "cited_paper_id": 4891749,
          "context_text": "We adapt recent span-based models (Lee et al., 2018; He et al., 2018; Ouchi et al., 2018) for the multi-sentence argument linking task for both our annotated dataset, RAMS, and for an existing slot ﬁlling dataset, GVDB (Pavlick et al., 2016).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two datasets, RAMS and GVDB, which are used for adapting span-based models for multi-sentence argument linking tasks.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.718",
          "cited_paper_doi": "10.18653/v1/N18-2108",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e6566ece21f6637c515fe9969f9d1ec6cca6d36c",
          "citing_paper_year": 2019,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "59002598",
      "citation_count": 0,
      "total_dataset_mentions": 16,
      "unique_datasets": [
        "MUC-4"
      ],
      "dataset_details": [
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used for document-level event role filler extraction, focusing on identifying and extracting roles within events across multiple sentences.",
          "citing_paper_id": "249579113",
          "cited_paper_id": null,
          "context_text": "The first one is the task of document-level event role filler extraction, which is based on the classic MUC-4 dataset [24].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the MUC-4 dataset, which is a well-known resource for event extraction tasks. The dataset is explicitly used for document-level event role filler extraction.",
          "citing_paper_doi": "10.1145/3542925",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/78de896701cf3a1bbaa7b209ec23bb40747085d8",
          "cited_paper_url": null,
          "citing_paper_year": 2022,
          "cited_paper_year": null
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling. | Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods. | Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents. | Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction. | Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct. | Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable. | Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics. | Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles.",
          "citing_paper_id": "3519188",
          "cited_paper_id": 448730,
          "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
          "citing_paper_doi": "10.1184/r1/21610728.v1",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/a66fba6c74576516de7db042b738c60d8654c332",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1d7c366ff41bc3917a0144cd3aac3647066792ab",
          "citing_paper_year": 2022,
          "cited_paper_year": 1991
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling. | Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods. | Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents. | Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction. | Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct. | Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable. | Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics. | Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles.",
          "citing_paper_id": "3519188",
          "cited_paper_id": 2114002,
          "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
          "citing_paper_doi": "10.1184/r1/21610728.v1",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/a66fba6c74576516de7db042b738c60d8654c332",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9e06ae0ced29ba71ff7160c5b8ceb99c8668e66e",
          "citing_paper_year": 2022,
          "cited_paper_year": 2010
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling. | Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods. | Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents. | Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction. | Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct. | Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable. | Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics. | Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles.",
          "citing_paper_id": "3519188",
          "cited_paper_id": 2364656,
          "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
          "citing_paper_doi": "10.1184/r1/21610728.v1",
          "cited_paper_doi": "10.3115/1641408.1641416",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a66fba6c74576516de7db042b738c60d8654c332",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3bbade87a734057bb055741d598427953f152270",
          "citing_paper_year": 2022,
          "cited_paper_year": 2006
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling. | Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods. | Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents. | Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction. | Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct. | Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable. | Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics. | Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles.",
          "citing_paper_id": "3519188",
          "cited_paper_id": 5749336,
          "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
          "citing_paper_doi": "10.1184/r1/21610728.v1",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/a66fba6c74576516de7db042b738c60d8654c332",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c6c7f37fae4376473cc9502a7ee094a4bd7437c1",
          "citing_paper_year": 2022,
          "cited_paper_year": 2007
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling. | Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods. | Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents. | Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction. | Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct. | Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable. | Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics. | Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles.",
          "citing_paper_id": "3519188",
          "cited_paper_id": 5817011,
          "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
          "citing_paper_doi": "10.1184/r1/21610728.v1",
          "cited_paper_doi": "10.3115/1072017.1072031",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a66fba6c74576516de7db042b738c60d8654c332",
          "cited_paper_url": "https://www.semanticscholar.org/paper/fd30edc8e4ff367c3f3191895208101f2779ea49",
          "citing_paper_year": 2022,
          "cited_paper_year": 1993
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling. | Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods. | Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents. | Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction. | Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct. | Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable. | Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics. | Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles.",
          "citing_paper_id": "3519188",
          "cited_paper_id": 14282973,
          "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
          "citing_paper_doi": "10.1184/r1/21610728.v1",
          "cited_paper_doi": "10.3115/1075096.1075124",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a66fba6c74576516de7db042b738c60d8654c332",
          "cited_paper_url": "https://www.semanticscholar.org/paper/544a0fa1107df1423db05070182f213053003040",
          "citing_paper_year": 2022,
          "cited_paper_year": 2003
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling. | Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods. | Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents. | Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction. | Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct. | Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable. | Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics. | Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles.",
          "citing_paper_id": "3519188",
          "cited_paper_id": 14493443,
          "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
          "citing_paper_doi": "10.1184/r1/21610728.v1",
          "cited_paper_doi": "10.3115/v1/D14-1199",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a66fba6c74576516de7db042b738c60d8654c332",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1ab25ab709537462660e47d5a92ed1d71142d333",
          "citing_paper_year": 2022,
          "cited_paper_year": 2014
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling. | Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods. | Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents. | Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction. | Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct. | Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable. | Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics. | Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles.",
          "citing_paper_id": "3519188",
          "cited_paper_id": 33436811,
          "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
          "citing_paper_doi": "10.1184/r1/21610728.v1",
          "cited_paper_doi": "10.3115/1072064.1072076",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a66fba6c74576516de7db042b738c60d8654c332",
          "cited_paper_url": "https://www.semanticscholar.org/paper/ee6a312fa82d38e0aa54823487a72490496a1ac4",
          "citing_paper_year": 2022,
          "cited_paper_year": 1992
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to develop and evaluate event templates in Japanese for the joint ventures and micro-electronics domains, focusing on information extraction and template filling. | Used to evaluate the performance of the ALICE system in information extraction, specifically comparing classification-based methods with pattern-based methods. | Used to study macro-event structures and event ideologies, focusing on generalizable event types across a wide range of documents. | Used to evaluate performance metrics (precision, F1, recall) of text-analysis technologies, specifically comparing against AutoSlog in the context of event extraction. | Used to evaluate the performance of an information extraction system, comparing it to a fully handcrafted system that required 1500 person hours to construct. | Used to study macro-event structures and event ideologies, focusing on single event per document summaries that are generalizable. | Used to evaluate event extraction systems in the Latin American Terrorism domain, focusing on domain-specific information extraction patterns and performance metrics. | Used to evaluate the performance of ALICE in event extraction, comparing it against pattern-based methods. The dataset focuses on extracting events from news articles.",
          "citing_paper_id": "3519188",
          "cited_paper_id": 59002598,
          "context_text": "Evaluation on MUC-4 documents against AutoSlog showed improved performance on precision and F1, but lower recall.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC-4 documents' which is a specific dataset used for evaluation. The dataset is used to compare performance metrics (precision, F1, recall) against another system (AutoSlog).",
          "citing_paper_doi": "10.1184/r1/21610728.v1",
          "cited_paper_doi": "10.1109/CAIA.1993.366645",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a66fba6c74576516de7db042b738c60d8654c332",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e80b34a55aa56578f9a4f27ea207f8c42c93a378",
          "citing_paper_year": 2022,
          "cited_paper_year": 1993
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to evaluate the proposed method for document-level event extraction, specifically comparing performance metrics against previous state-of-the-art approaches. | Used to evaluate the S2C-CC model for document-level event argument extraction, focusing on improving F1 scores across multiple settings. | Used to compare annotation practices in document-level event extraction, focusing on datasets that annotate all events in a document, with an average of 16 events per document. | Used for comparison, focusing on fewer event annotations (at most 3 events per document) to highlight the comprehensiveness of WIKI EVENTS. | Used to evaluate document-level event extraction, focusing on comprehensive event annotation (averagely 16 events per document) to assess the framework's performance. | Used to compare annotation practices in document-level event extraction, focusing on datasets that annotate events at the document level, with an average of 3 events per document.",
          "citing_paper_id": "264452034",
          "cited_paper_id": 233219850,
          "context_text": "We focus on document-level IAE (Li et al., 2021) (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) that only annotate at most 3 events per document, W IKI E VENTS annotates all the events in a document, with an average of 16 events per document.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used for document-level event extraction, including MUC-4 and WIKI EVENTS. These datasets are clearly identified and used for comparing annotation practices.",
          "citing_paper_doi": "10.48550/arXiv.2310.16358",
          "cited_paper_doi": "10.18653/V1/2021.NAACL-MAIN.69",
          "citing_paper_url": "https://www.semanticscholar.org/paper/795716ffc0e22a013bf196cb7fd65dceb95b286c",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2a15f541a8216782a7579f01f56762448e48b582",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used for template filling in event extraction, focusing on one event per document to evaluate classifiers.",
          "citing_paper_id": "259370721",
          "cited_paper_id": 2213149,
          "context_text": "Earlier efforts on this problem explore the MUC-4 benchmark (Chinchor, 1991; Huang and Riloff, 2012), also known as “template filling” because the entire document is about one event.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions the MUC-4 benchmark, which is a specific dataset used for event extraction tasks. The context indicates it is used for template filling, focusing on one event per document.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.532",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/70cb23e280893105cbf582affe439e858916765f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/aec878ecba20af946a61f4d3bc4193338d35887e",
          "citing_paper_year": 2023,
          "cited_paper_year": 2012
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to assess granular event extraction, specifically targeting detailed event structures and relationships in English texts. | Used to evaluate document-level event extraction, focusing on identifying and classifying events in text documents.",
          "citing_paper_id": "252873525",
          "cited_paper_id": 11986411,
          "context_text": ", 2020), MUC-4 (Grishman and Sundheim, 1996), and BETTER Phase II English Granular.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions MUC-4 and BETTER Phase II English Granular, which are specific datasets used in event extraction research.",
          "citing_paper_doi": "10.48550/arXiv.2210.06600",
          "cited_paper_doi": "10.3115/992628.992709",
          "citing_paper_url": "https://www.semanticscholar.org/paper/67e82404e2c4d57d018fa64a4974b459a7fe7d84",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6723dda58e5e09089ec78ba42827b65859f030e2",
          "citing_paper_year": 2022,
          "cited_paper_year": 1996
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Developed for template extraction in document-level information extraction, specifically for granular and detailed template generation. | Used for evaluating template extraction methods, specifically comparing the performance of GTT against other approaches in document-level event extraction. | Revisited for document-level information extraction, focusing on template filling and entity-based extraction using generative transformers.",
          "citing_paper_id": "252873525",
          "cited_paper_id": 235097664,
          "context_text": "GTT (Du et al., 2021b) To our knowledge, this is the only prior work to have attempted full template extraction in recent years, and their work is thus our primary baseline for comparison on MUC4.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions MUC4 as a dataset used for comparison, which is a known dataset in the field of information extraction.",
          "citing_paper_doi": "10.48550/arXiv.2210.06600",
          "cited_paper_doi": "10.18653/V1/2021.NAACL-MAIN.70",
          "citing_paper_url": "https://www.semanticscholar.org/paper/67e82404e2c4d57d018fa64a4974b459a7fe7d84",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e9b3fed266dff06d44be861cce8bd9c247b7d42a",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used for experiments involving entity-based arguments, formulated as a table-filling task to handle single event records of single event types. | Used for experiments involving entity-based arguments with 1,700 documents, formulated as a table-filling task to handle single event records.",
          "citing_paper_id": "235253912",
          "cited_paper_id": 9946972,
          "context_text": "They conduct experiments on MUC-4 (Sundheim, 1992) dataset with 1, 700 documents and 5 kinds of entity-based arguments, and it is formulated as a table-filling task, coping with single event record of single event",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the MUC-4 dataset, which is a specific, verifiable dataset used in the research. The dataset is used for experiments involving entity-based arguments and is formulated as a table-filling task.",
          "citing_paper_doi": "10.18653/v1/2021.acl-long.274",
          "cited_paper_doi": "10.3115/1072064.1072066",
          "citing_paper_url": "https://www.semanticscholar.org/paper/67615300b2bd2aa0f0566ee1e3a5e7d5bd6450b3",
          "cited_paper_url": "https://www.semanticscholar.org/paper/310d432ce7de84de2a54eedde18ee0423a232253",
          "citing_paper_year": 2021,
          "cited_paper_year": 1992
        },
        {
          "dataset_name": "MUC-4",
          "dataset_description": "Used to evaluate multi-label classification for event extraction, focusing on six specific event types including kidnapping, attack, bombing, robbery, arson, and forced work stoppage.",
          "citing_paper_id": "235097664",
          "cited_paper_id": 14891665,
          "context_text": "As there are 6 event types (i.e., kid-napping , attack , bombing , robbery , arson , forced work stoppage ) in MUC-4, we use 2 6 labels for the MCC problem.",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions MUC-4, which is a known dataset for event extraction, but does not provide details on its usage or the specific research context.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.70",
          "cited_paper_doi": "10.1016/J.ENTCS.2013.02.010",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e9b3fed266dff06d44be861cce8bd9c247b7d42a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/d4ad1f1c7328f2bd0d3da1ffa13789829fbb4bcf",
          "citing_paper_year": 2021,
          "cited_paper_year": 2013
        }
      ]
    },
    {
      "cited_paper_id": "3137086",
      "citation_count": 0,
      "total_dataset_mentions": 15,
      "unique_datasets": [
        "ACE 2005"
      ],
      "dataset_details": [
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to conduct experiments on document-level event extraction, focusing on identifying and linking events within documents.",
          "citing_paper_id": "269900068",
          "cited_paper_id": 207853145,
          "context_text": "We conduct our experiments on the widely used dataset ACE 2005 (Doddington et al., 2004) and RAMS (Ebner et al., 2020).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, ACE 2005 and RAMS, which are used for conducting experiments in document-level event extraction.",
          "citing_paper_doi": "10.48550/arXiv.2405.10517",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/8ed919b9f4dccefe962f06181764a5df78313b83",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2024,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to conduct experiments on document-level event extraction, focusing on identifying and linking events within documents.",
          "citing_paper_id": "269900068",
          "cited_paper_id": 259950998,
          "context_text": "We conduct our experiments on the widely used dataset ACE 2005 (Doddington et al., 2004) and RAMS (Ebner et al., 2020).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, ACE 2005 and RAMS, which are used for conducting experiments in document-level event extraction.",
          "citing_paper_doi": "10.48550/arXiv.2405.10517",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/8ed919b9f4dccefe962f06181764a5df78313b83",
          "cited_paper_url": "https://www.semanticscholar.org/paper/104b0bb1da562d53cbda87aec79ef6a2827d191a",
          "citing_paper_year": 2024,
          "cited_paper_year": 2023
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to evaluate a data augmentation method for event extraction, focusing on the performance improvement with the same train-dev-test split and preprocessing as prior studies.",
          "citing_paper_id": "255522592",
          "cited_paper_id": 135473179,
          "context_text": "We empirically evaluate our proposed data augmentation method for event extraction on the ACE2005 corpus 1 with the same train-dev-test split and preprocessing step as previous works (Zhang et al., 2019; Wadden et al., 2019).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the use of the ACE2005 corpus for evaluating a data augmentation method for event extraction, which is directly relevant to the topic of document-level event extraction.",
          "citing_paper_doi": "10.48550/arXiv.2301.02427",
          "cited_paper_doi": "10.1162/dint_a_00014",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a955a5a6d2fd7740375b6f22d2ac9719ce02d17f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/ea00a63c2acd145839eb6f6bbc01a5cfb4930d43",
          "citing_paper_year": 2023,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to tag event arguments within the sentence scope, serving as an expert-annotated benchmark for event extraction.",
          "citing_paper_id": "119308902",
          "cited_paper_id": 14339673,
          "context_text": "Although a great number of efforts (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Riedel and McCallum, 2011; Li et al., 2013, 2014; Chen et al., 2015; Yang and Mitchell, 2016; Nguyen et al., 2016; Liu et al., 2017; Sha et al., 2018; Zhang and Ji, 2018; Nguyen and Nguyen, 2019; Wang et al., 2019) have been put on EE, most of them are based on ACE 20052, an expert-annotated benchmark, which only tagged event arguments within the sentence scope.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ACE 2005' as an expert-annotated benchmark used for event extraction, which fits the criteria for a dataset. It is used to tag event arguments within the sentence scope.",
          "citing_paper_doi": "10.18653/v1/D19-1032",
          "cited_paper_doi": "10.3115/v1/P15-1017",
          "citing_paper_url": "https://www.semanticscholar.org/paper/9e2fd661a172749a739fc146301d3636e4a9c4dc",
          "cited_paper_url": "https://www.semanticscholar.org/paper/98a6b07d51261df9418981c1dddf09ad4a9c48e4",
          "citing_paper_year": 2019,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used as a benchmark for sentence-level event extraction, providing expert-annotated data to train and evaluate models in the field of event extraction.",
          "citing_paper_id": "249579113",
          "cited_paper_id": 9776219,
          "context_text": "A great number of EE research focuses on SEE, and most are based on the expert-annotated benchmark ACE 2005 [7] dataset.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the ACE 2005 dataset, which is a well-known benchmark for event extraction. The dataset is explicitly used for SEE (Sentence-level Event Extraction) research.",
          "citing_paper_doi": "10.1145/3542925",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/78de896701cf3a1bbaa7b209ec23bb40747085d8",
          "cited_paper_url": "https://www.semanticscholar.org/paper/0617dd6924df7a3491c299772b70e90507b195dc",
          "citing_paper_year": 2022,
          "cited_paper_year": 2004
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to evaluate the approach on document-level event extraction, employing standard data splits for training, development, and testing as per previous work.",
          "citing_paper_id": "208547716",
          "cited_paper_id": 2367456,
          "context_text": "We evaluate our approach on the ACE 2005 dataset and use the same data splits as previous work, in which 40 newswire documents are used as the test set, another 30 documents of different genres are selected as the development set, and the remaining 529 documents constitute the training set (Li et al., 2013; Yang and Mitchell, 2016; Nguyen and Nguyen, 2019).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context clearly mentions the ACE 2005 dataset, which is a well-known dataset used for event extraction tasks. The dataset is described in detail, including the splits used for training, development, and testing.",
          "citing_paper_doi": "10.18653/v1/2020.spnlp-1.9",
          "cited_paper_doi": "10.18653/v1/N16-1033",
          "citing_paper_url": "https://www.semanticscholar.org/paper/80e797968a59e1281be95ddb02ba53d653880c90",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c558e2b5dcab8d89f957f3045a9bbd43fd6a28ed",
          "citing_paper_year": 2019,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to adopt event annotation standards, focusing on the English split in ERE Evaluation metrics for consistent event labeling.",
          "citing_paper_id": "258947053",
          "cited_paper_id": 9776219,
          "context_text": "We adopt the event annotation in ACE 2005 dataset (Doddington et al., 2004) ( ACE05-E ) 6 , and the English split in ERE Evaluation metrics.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the ACE 2005 dataset, which is a well-known dataset for event annotation. The dataset is used for adopting event annotation standards.",
          "citing_paper_doi": "10.48550/arXiv.2305.16734",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/b7c676d7b14af6090bf247db2d538e33de8ccd58",
          "cited_paper_url": "https://www.semanticscholar.org/paper/0617dd6924df7a3491c299772b70e90507b195dc",
          "citing_paper_year": 2023,
          "cited_paper_year": 2004
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to compare models with state-of-the-art baselines, focusing on feature-based methods and structured prediction with global features. | Used to compare models with state-of-the-art baselines, focusing on feature-based methods for joint event extraction and structured prediction.",
          "citing_paper_id": "202770954",
          "cited_paper_id": 2114517,
          "context_text": "We compare our models with various state-of-theart baselines on ACE 2005: (1) Feature-based methods, including Li’s joint (Li et al., 2013) and RBPB (Sha et al.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'ACE 2005' which is a well-known dataset for event extraction. The dataset is used to compare models with state-of-the-art baselines.",
          "citing_paper_doi": "10.18653/v1/D19-1584",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/788bf8a74bc0d81215a58ab2ffdc46e12c189f43",
          "cited_paper_url": "https://www.semanticscholar.org/paper/7c9b205b9f1f57b868cfac4ce83deda633c2fc22",
          "citing_paper_year": 2019,
          "cited_paper_year": 2013
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to train supervised event extractors, focusing on human-annotated data for improving extraction accuracy.",
          "citing_paper_id": "12108307",
          "cited_paper_id": 1320606,
          "context_text": "To this end, so far most methods (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2014; Hong et al., 2011; Ji and Grishman, 2008) usually adopted supervised learning paradigm which relies on elaborate human-annotated data, such as ACE 2005 1 , to train extractors.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ACE 2005' as a human-annotated dataset used for training event extractors, which is relevant to document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/P17-1038",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/232537a9d3042a703a624b20fabd50d390a96ce6",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f98ebc10ce8c48020d21cca041de2a3346ce31d9",
          "citing_paper_year": 2017,
          "cited_paper_year": 2008
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to train supervised event extractors, focusing on human-annotated data for improving extraction accuracy. | Used for training event extraction models, consisting of 529 documents. The dataset supports the evaluation of model performance on newswire articles and development documents.",
          "citing_paper_id": "12108307",
          "cited_paper_id": 6452487,
          "context_text": "To this end, so far most methods (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2014; Hong et al., 2011; Ji and Grishman, 2008) usually adopted supervised learning paradigm which relies on elaborate human-annotated data, such as ACE 2005 1 , to train extractors.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'ACE 2005' as a human-annotated dataset used for training event extractors, which is relevant to document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/P17-1038",
          "cited_paper_doi": "10.18653/v1/N16-1034",
          "citing_paper_url": "https://www.semanticscholar.org/paper/232537a9d3042a703a624b20fabd50d390a96ce6",
          "cited_paper_url": "https://www.semanticscholar.org/paper/7afc4b1b89081d118700801064e251870d05617b",
          "citing_paper_year": 2017,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to train supervised event extractors, focusing on human-annotated data for improving extraction accuracy. | Used for training event extraction models, consisting of 529 documents. The dataset supports the evaluation of model performance on newswire articles and development documents.",
          "citing_paper_id": "12108307",
          "cited_paper_id": 14339673,
          "context_text": "To this end, so far most methods (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2014; Hong et al., 2011; Ji and Grishman, 2008) usually adopted supervised learning paradigm which relies on elaborate human-annotated data, such as ACE 2005 1 , to train extractors.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'ACE 2005' as a human-annotated dataset used for training event extractors, which is relevant to document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/P17-1038",
          "cited_paper_doi": "10.3115/v1/P15-1017",
          "citing_paper_url": "https://www.semanticscholar.org/paper/232537a9d3042a703a624b20fabd50d390a96ce6",
          "cited_paper_url": "https://www.semanticscholar.org/paper/98a6b07d51261df9418981c1dddf09ad4a9c48e4",
          "citing_paper_year": 2017,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to advance sentence-level information extraction, focusing on event identification and argument recognition in text.",
          "citing_paper_id": "252873525",
          "cited_paper_id": null,
          "context_text": "Researchers later focused more heavily on sentence-level IE, especially after the introduction of the ACE 2005 dataset (Walker et al., 2006).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the ACE 2005 dataset, which is a well-known resource for information extraction tasks, particularly for sentence-level event extraction.",
          "citing_paper_doi": "10.48550/arXiv.2210.06600",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/67e82404e2c4d57d018fa64a4974b459a7fe7d84",
          "cited_paper_url": null,
          "citing_paper_year": 2022,
          "cited_paper_year": null
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used to verify model performance in event understanding, comparing results to prior work in the field of event extraction.",
          "citing_paper_id": "226283556",
          "cited_paper_id": null,
          "context_text": "First however we look at a more established dataset, ACE 2005 (Walker et al., 2006)7, to verify if our model can reasonable performance compared to prior work in event understanding.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ACE 2005' as a dataset used to verify model performance in event understanding, which aligns with the research topic of document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/2020.codi-1.10",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/366285d6b8e9360709641e1467b3e3bbb26b6d75",
          "cited_paper_url": null,
          "citing_paper_year": 2020,
          "cited_paper_year": null
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used for document-level relation extraction, derived from Wikidata and Wikipedia, focusing on distant supervision methods. | Used as a source for distant supervision to create a dataset for document-level event extraction, providing textual context for events and entities. | Used as a source for distant supervision to create a dataset for document-level event extraction, providing structured information for entity linking. | Used for document-level event extraction, derived from Wikidata and Wikipedia, focusing on distant supervision methods. | Used to train and evaluate document-level event extraction models, focusing on identifying and classifying events within text documents.",
          "citing_paper_id": "253107167",
          "cited_paper_id": null,
          "context_text": "ACE 2005 (Walker et al., 2006) and SemEval Ross Patterson Alger ( August 20 , 1920 – January 16 , 1992 ) was a politician in the Canadian province of Alberta , who served as mayor of Calgary from 1977 to 1980 .",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions 'ACE 2005' which is a known dataset for event extraction. However, the rest of the citation is irrelevant and does not mention any other datasets.",
          "citing_paper_doi": "10.18653/v1/2022.emnlp-main.580",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/c86754c01fc64a8e8b445f530fe95c1dbab4eb03",
          "cited_paper_url": null,
          "citing_paper_year": 2022,
          "cited_paper_year": null
        },
        {
          "dataset_name": "ACE 2005",
          "dataset_description": "Used for event-argument extraction, annotated at the sentence level in multiple languages, providing a reliable resource for information extraction tasks.",
          "citing_paper_id": "235490449",
          "cited_paper_id": 3137086,
          "context_text": "Event-Argument Extraction, the IE task most related to the task of aggregation has a number of well-documented and reliable datasets annotated at the sentence level in different languages like ACE 2005 and TAC KBP (Mitamura et al., 2015) datasets.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, ACE 2005 and TAC KBP, which are used for event-argument extraction, a task related to aggregation. These datasets are well-documented and reliable, and they are annotated at the sentence level in different languages.",
          "citing_paper_doi": "10.18653/v1/2021.case-1.5",
          "cited_paper_doi": "10.3115/v1/W15-0809",
          "citing_paper_url": "https://www.semanticscholar.org/paper/427d52b3d5f5d1c4c1ec8fa436c254fd3a91a579",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9c34bf7bdb5a4247772c5c6d4982aa4d41e67be9",
          "citing_paper_year": 2021,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "60588668",
      "citation_count": 0,
      "total_dataset_mentions": 6,
      "unique_datasets": [
        "MUC"
      ],
      "dataset_details": [
        {
          "dataset_name": "MUC",
          "dataset_description": "Used to study gun violence incidents, focusing on event extraction and argument linking, providing detailed records of events and participants. | Used to evaluate information extraction systems, focusing on slot filling tasks in various domains, providing structured data for argument linking research.",
          "citing_paper_id": "207853145",
          "cited_paper_id": 9946972,
          "context_text": "Argument Linking also draws similarities to slot ﬁlling, exempliﬁed by the various MUC datasets (Sundheim, 1992) and the Gun Violence Database (GVDB) (Pavlick et al., 2016).",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC datasets' and 'Gun Violence Database (GVDB)', both of which are specific datasets used in the research. MUC datasets are part of a series of evaluations for information extraction systems, and GVDB is a specific database focused on gun violence incidents.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.718",
          "cited_paper_doi": "10.3115/1072064.1072066",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "cited_paper_url": "https://www.semanticscholar.org/paper/310d432ce7de84de2a54eedde18ee0423a232253",
          "citing_paper_year": 2019,
          "cited_paper_year": 1992
        },
        {
          "dataset_name": "MUC",
          "dataset_description": "Used to organize shared tasks in text mining, focusing on message understanding and information extraction, providing a benchmark for evaluating systems.",
          "citing_paper_id": "9631585",
          "cited_paper_id": 60588668,
          "context_text": "The history of text mining (TM) shows that shared tasks based on carefully curated resources, such as those organized in the MUC (Chinchor, 1998), TREC (Voorhees, 2007) and ACE (Strassel et al.",
          "confidence_score": 0.85,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions MUC, TREC, and ACE as examples of shared tasks based on curated resources. MUC is specifically referenced with a year, indicating it is a verifiable resource.",
          "citing_paper_doi": "10.3115/1572340.1572342",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/d461edc4de7d4c1398f76c08b54310cd017b963d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/07ebbe478946c18862c9926b96f5e1fd7d994cd3",
          "citing_paper_year": 2009,
          "cited_paper_year": 1998
        },
        {
          "dataset_name": "MUC",
          "dataset_description": "Developed for template extraction in document-level information extraction, specifically for granular and detailed template generation. | Revisited for document-level information extraction, focusing on template filling and entity-based extraction using generative transformers. | Used to generate 4-slot templates for document-level entity-based extraction, focusing on structured information extraction from documents.",
          "citing_paper_id": "252873525",
          "cited_paper_id": 237485215,
          "context_text": "But following renewed interest in document-level IE, researchers (Du et al., 2021b; Huang et al., 2021; Gantt et al., 2022, i.a. ) have begun to revisit MUC and to develop new template extraction datasets (notably, BETTER Granular).",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC' and 'BETTER Granular' as datasets used in document-level information extraction. MUC is a well-known dataset, and BETTER Granular is a newer dataset developed for template extraction.",
          "citing_paper_doi": "10.48550/arXiv.2210.06600",
          "cited_paper_doi": "10.18653/v1/2021.emnlp-main.426",
          "citing_paper_url": "https://www.semanticscholar.org/paper/67e82404e2c4d57d018fa64a4974b459a7fe7d84",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6f7e3a6ecc8464b9edb54b863b8a745d3b4b5766",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "MUC",
          "dataset_description": "Used to support the annotation of event structures, specifically targeting n-ary associations of annotations in document-level event extraction. | Used for event structure annotation in Information Extraction tasks, focusing on binary and n-ary relations between annotations. | Used to support the annotation of event structures in information extraction tasks, focusing on n-ary associations of annotations.",
          "citing_paper_id": "2065400",
          "cited_paper_id": 6614930,
          "context_text": "…annotation\n(Figure 1 middle and bottom). n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions three specific datasets: MUC, ACE, and BioNLP, which are relevant to document-level event extraction tasks.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.3115/1072399.1072402",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a97c7876ebf9ae6c468db92c3c6dc1c0be832192",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f10967fa1863089553067b2413ca0af26d35081d",
          "citing_paper_year": 2012,
          "cited_paper_year": 1995
        },
        {
          "dataset_name": "MUC",
          "dataset_description": "Used to support the annotation of event structures in information extraction tasks, focusing on n-ary associations of annotations.",
          "citing_paper_id": "2065400",
          "cited_paper_id": 9776219,
          "context_text": "…annotation\n(Figure 1 middle and bottom). n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions three specific datasets: MUC, ACE, and BioNLP, which are relevant to document-level event extraction tasks.",
          "citing_paper_doi": null,
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/a97c7876ebf9ae6c468db92c3c6dc1c0be832192",
          "cited_paper_url": "https://www.semanticscholar.org/paper/0617dd6924df7a3491c299772b70e90507b195dc",
          "citing_paper_year": 2012,
          "cited_paper_year": 2004
        },
        {
          "dataset_name": "MUC",
          "dataset_description": "Used to trace the history of event extraction datasets, focusing on the early development of annotated corpora for information extraction tasks. | Used to develop and evaluate early event extraction systems, focusing on named entity recognition and relation extraction tasks.",
          "citing_paper_id": "258865260",
          "cited_paper_id": 11986411,
          "context_text": "Through extensive human expert annotations, we design mappings 2 Related Work Event Extraction Datasets and Ontologies: The earliest datasets in event extraction date back to MUC (Sundheim, 1992; Grishman and Sundheim, 1996).",
          "confidence_score": 0.7,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MUC' which is a well-known series of conferences that produced datasets for event extraction. However, the specific dataset name is not clearly identified beyond the conference acronym.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.203",
          "cited_paper_doi": "10.3115/992628.992709",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33c3eb62f55b4f46d812723fd3a053fc8c17fd21",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6723dda58e5e09089ec78ba42827b65859f030e2",
          "citing_paper_year": 2022,
          "cited_paper_year": 1996
        }
      ]
    },
    {
      "cited_paper_id": "12399949",
      "citation_count": 0,
      "total_dataset_mentions": 6,
      "unique_datasets": [
        "ECB+"
      ],
      "dataset_details": [
        {
          "dataset_name": "ECB+",
          "dataset_description": "Used to compare the performance of different models, including those using LongFormer and BERT/RoBERTa encoders, focusing on document-level event extraction. | Used to evaluate the performance of the +WD-LCP model on document-level event extraction, specifically comparing it to the baseline (RoBERTa) using within-document LCP.",
          "citing_paper_id": "266163830",
          "cited_paper_id": 102353837,
          "context_text": "1) Barhom et al. (2019 Table 2: Performance comparision of different models on the ECB+ dataset, where “*” indicates that the models use LongFormer as their encoders and the other models use BERT/RoBERTa as their encoders.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the ECB+ dataset, which is a specific dataset used for performance comparison of different models. The dataset is clearly identified and used in the research context.",
          "citing_paper_doi": "10.18653/v1/2023.emnlp-main.294",
          "cited_paper_doi": "10.18653/v1/N19-1242",
          "citing_paper_url": "https://www.semanticscholar.org/paper/46d0161a67e8e1694479ee2722600738d8b614bd",
          "cited_paper_url": "https://www.semanticscholar.org/paper/a4bc4b98a917174ac2ab14bd5e66d64306079ab5",
          "citing_paper_year": 2023,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "ECB+",
          "dataset_description": "Used to compare the performance of different models, including those using LongFormer and BERT/RoBERTa encoders, focusing on document-level event extraction. | Used to evaluate the performance of the +WD-LCP model on document-level event extraction, specifically comparing it to the baseline (RoBERTa) using within-document LCP.",
          "citing_paper_id": "266163830",
          "cited_paper_id": 198953378,
          "context_text": "1) Barhom et al. (2019 Table 2: Performance comparision of different models on the ECB+ dataset, where “*” indicates that the models use LongFormer as their encoders and the other models use BERT/RoBERTa as their encoders.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the ECB+ dataset, which is a specific dataset used for performance comparison of different models. The dataset is clearly identified and used in the research context.",
          "citing_paper_doi": "10.18653/v1/2023.emnlp-main.294",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/46d0161a67e8e1694479ee2722600738d8b614bd",
          "cited_paper_url": "https://www.semanticscholar.org/paper/077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
          "citing_paper_year": 2023,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "ECB+",
          "dataset_description": "Used for training and testing models for CD event coreference, providing a foundational dataset for event coreference resolution. | Used for training and testing models for CD event coreference, extending the original ECB dataset with additional annotations and data.",
          "citing_paper_id": "233210350",
          "cited_paper_id": 739867,
          "context_text": "ECB+ This dataset (Cybulska and Vossen, 2014), which is an extended version of the EventCorefBank (ECB) (Bejan and Harabagiu, 2010), is the most commonly used dataset for training and testing models for CD event coreference (Choubey and",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions ECB+ and ECB as specific datasets used for training and testing models for CD event coreference. These are multi-word proper nouns and are clearly identified as datasets.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.198",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/a814f3773b6482b7f5c8ba8c3edfedb726999574",
          "cited_paper_url": "https://www.semanticscholar.org/paper/791198ab24bea86944265887136843e00352e13f",
          "citing_paper_year": 2021,
          "cited_paper_year": 2010
        },
        {
          "dataset_name": "ECB+",
          "dataset_description": "Applied to study event coreference across multiple languages, enhancing cross-lingual event linking in news texts. | Used for event coreference resolution, focusing on lexical diversity and event linking in news articles. | Used for training and testing models for CD event coreference, providing a foundational dataset for event coreference resolution. | Used for training and testing models for CD event coreference, extending the original ECB dataset with additional annotations and data.",
          "citing_paper_id": "233210350",
          "cited_paper_id": 1801348,
          "context_text": "ECB+ This dataset (Cybulska and Vossen, 2014), which is an extended version of the EventCorefBank (ECB) (Bejan and Harabagiu, 2010), is the most commonly used dataset for training and testing models for CD event coreference (Choubey and",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions ECB+ and ECB as specific datasets used for training and testing models for CD event coreference. These are multi-word proper nouns and are clearly identified as datasets.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.198",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/a814f3773b6482b7f5c8ba8c3edfedb726999574",
          "cited_paper_url": "https://www.semanticscholar.org/paper/0fabeb29eee19ca80b6f424d8cd86ac52ac96eb0",
          "citing_paper_year": 2021,
          "cited_paper_year": 2014
        },
        {
          "dataset_name": "ECB+",
          "dataset_description": "Used to evaluate cross-document event coreference, clustering gold mentions and concatenating test documents into a meta-document, following the evaluation setting proposed by Kenyon-Dean et al. (2018) and Barhom et al. (2019).",
          "citing_paper_id": "233210350",
          "cited_paper_id": 12399949,
          "context_text": "…is no linear order between mentions from different documents.\nthe experiment on ECB+, we follow the recent evaluation setting (Kenyon-Dean et al., 2018; Barhom et al., 2019), clustering gold mentions and concatenating all test documents into one meta-document, as proposed by Upadhyay et al. (2016).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ECB+' which is a known dataset for event coreference. The dataset is used for evaluating cross-document event coreference, following a specific experimental setup.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.198",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/a814f3773b6482b7f5c8ba8c3edfedb726999574",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b145717745b433ee8a9daf12188e5d31dab4eec3",
          "citing_paper_year": 2021,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "ECB+",
          "dataset_description": "Used to evaluate cross-document entity and event coreference resolution, clustering gold mentions and concatenating test documents into a meta-document. | Used to evaluate cross-document event coreference, clustering gold mentions and concatenating test documents into a meta-document, following the evaluation setting proposed by Kenyon-Dean et al. (2018) and Barhom et al. (2019).",
          "citing_paper_id": "233210350",
          "cited_paper_id": 174799117,
          "context_text": "…is no linear order between mentions from different documents.\nthe experiment on ECB+, we follow the recent evaluation setting (Kenyon-Dean et al., 2018; Barhom et al., 2019), clustering gold mentions and concatenating all test documents into one meta-document, as proposed by Upadhyay et al. (2016).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'ECB+' which is a known dataset for event coreference. The dataset is used for evaluating cross-document event coreference, following a specific experimental setup.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.198",
          "cited_paper_doi": "10.18653/v1/P19-1409",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a814f3773b6482b7f5c8ba8c3edfedb726999574",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6cd9c11017595a2194cacfedb3ec4ecb30462287",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "119308902",
      "citation_count": 0,
      "total_dataset_mentions": 5,
      "unique_datasets": [
        "ChFinAnn"
      ],
      "dataset_details": [
        {
          "dataset_name": "ChFinAnn",
          "dataset_description": "Used to explore document-level event extraction (DEE) through distant supervision and a two-stage extraction process involving sequence tagging and key-event-sentence detection.",
          "citing_paper_id": "119308902",
          "cited_paper_id": null,
          "context_text": ", 2018], attempted to explore DEE on ChFinAnn, by employing distant supervision (DS) [Mintz et al., 2009] to generate EE data and performing a two-stage extraction: 1) a sequence tagging model for SEE, and 2) a key-event-sentence detection model to detect the key sentence and an arguments-completion strategy that padded missing arguments from surrounding sentences for DEE.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ChFinAnn' as a specific dataset used for document-level event extraction. The dataset is used to explore DEE using distant supervision and a two-stage extraction process.",
          "citing_paper_doi": "10.18653/v1/D19-1032",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/9e2fd661a172749a739fc146301d3636e4a9c4dc",
          "cited_paper_url": null,
          "citing_paper_year": 2019,
          "cited_paper_year": null
        },
        {
          "dataset_name": "ChFinAnn",
          "dataset_description": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models. | Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences. | Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation. | Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain. | Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance. | Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents. | Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents. | Used for Chinese financial event argument extraction, constructed with distant supervision, lacks event trigger information. | Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
          "citing_paper_id": "269214164",
          "cited_paper_id": 119308902,
          "context_text": "ChfinAnn (Zheng et al., 2019) is constructed using distant supervision to assist in the construction, with a sizable scale, but it does not contain event trigger information, and can only be used for the event argument extraction task.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "ChfinAnn is identified as a dataset used for Chinese financial event extraction, specifically for the event argument extraction task.",
          "citing_paper_doi": "10.48550/arXiv.2404.12242",
          "cited_paper_doi": "10.18653/v1/D19-1032",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1f862b3fe4cd9c02bc9f1551c07cc8d626421a25",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9e2fd661a172749a739fc146301d3636e4a9c4dc",
          "citing_paper_year": 2024,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "ChFinAnn",
          "dataset_description": "Used to train and evaluate models on document-level financial event extraction, focusing on five specific event types with a large annotated corpus.",
          "citing_paper_id": "266163877",
          "cited_paper_id": 119308902,
          "context_text": "The ChFinAnn dataset (Zheng et al., 2019) is a large dataset focuses on five event types from the financial text, which has 25 , 632 / 3 , 204 / 3 , 204 for the train/dev/test set.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context clearly mentions 'ChFinAnn dataset' with specific details about its content and split, indicating it is a reusable resource.",
          "citing_paper_doi": "10.18653/v1/2023.emnlp-main.668",
          "cited_paper_doi": "10.18653/v1/D19-1032",
          "citing_paper_url": "https://www.semanticscholar.org/paper/6f722d0e769c59d28098328e6e28040b5cea35ac",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9e2fd661a172749a739fc146301d3636e4a9c4dc",
          "citing_paper_year": 2023,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "ChFinAnn",
          "dataset_description": "Used to train models for document-level event extraction, focusing on parallel prediction networks over 100 epochs.",
          "citing_paper_id": "266163877",
          "cited_paper_id": 236460259,
          "context_text": "For the training epochs, we follow (Zheng et al., 2019; Yang et al., 2021; Xu et al., 2021a) to train 100 epochs for all compared models on the ChFi-nAnn dataset.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the 'ChFi-nAnn dataset' which is a specific dataset used for training models in document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/2023.emnlp-main.668",
          "cited_paper_doi": "10.18653/v1/2021.acl-long.492",
          "citing_paper_url": "https://www.semanticscholar.org/paper/6f722d0e769c59d28098328e6e28040b5cea35ac",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c952b73fd8ac6a7d4ad00d78f6b3b8d1caed6a8f",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "ChFinAnn",
          "dataset_description": "Used for document-level event extraction, serving as a benchmark for evaluating baseline models in financial document processing.",
          "citing_paper_id": "258967833",
          "cited_paper_id": 245123950,
          "context_text": "For ChFinAnn, the base-line results are reported in (Zheng et al., 2019; Yang et al., 2021; Xu et al., 2021; Zhu et al., 2022; Liang et al., 2022).",
          "confidence_score": 0.6,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions 'ChFinAnn' which appears to be a dataset name. However, there is no explicit description of how the dataset is used or its specific characteristics in the given context.",
          "citing_paper_doi": "10.48550/arXiv.2305.18926",
          "cited_paper_doi": "10.24963/ijcai.2022/632",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5313b6d528a5aa640d884548dc025620e79a45ff",
          "cited_paper_url": "https://www.semanticscholar.org/paper/08c626ca0a7868d59e0a68f3d22d4d34cd4315db",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "216562779",
      "citation_count": 0,
      "total_dataset_mentions": 5,
      "unique_datasets": [
        "MAVEN"
      ],
      "dataset_details": [
        {
          "dataset_name": "MAVEN",
          "dataset_description": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models. | Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences. | Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation. | Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain. | Used for document-level event extraction, containing 9124 documents. It serves as a larger-scale resource for training and evaluating event extraction models. | Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance. | Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents. | Used for document-level event extraction, containing 246 documents. It provides a smaller, more focused dataset for detailed analysis and evaluation. | Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents. | Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
          "citing_paper_id": "269214164",
          "cited_paper_id": 207853145,
          "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
          "citing_paper_doi": "10.48550/arXiv.2404.12242",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1f862b3fe4cd9c02bc9f1551c07cc8d626421a25",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2024,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "MAVEN",
          "dataset_description": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models. | Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences. | Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation. | Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain. | Used to train and evaluate event detection models, specifically focusing on general domain events including 'Attack' and 'Defending'. The dataset supports the investigation of document-level event extraction methodologies. | Used to train and evaluate event detection models, specifically focusing on 168 event types and 19,640 labeled events. | Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance. | Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents. | Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents. | Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
          "citing_paper_id": "269214164",
          "cited_paper_id": 216562779,
          "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
          "citing_paper_doi": "10.48550/arXiv.2404.12242",
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.129",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1f862b3fe4cd9c02bc9f1551c07cc8d626421a25",
          "cited_paper_url": "https://www.semanticscholar.org/paper/46e84b0a7b3761d1a3c1577c66225453ab2cbc1c",
          "citing_paper_year": 2024,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "MAVEN",
          "dataset_description": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models. | Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences. | Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation. | Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain. | Used for document-level event extraction, containing 9124 documents. It serves as a larger-scale resource for training and evaluating event extraction models. | Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance. | Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents. | Used for document-level event extraction, containing 246 documents. It provides a smaller, more focused dataset for detailed analysis and evaluation. | Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents. | Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
          "citing_paper_id": "269214164",
          "cited_paper_id": 233219850,
          "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
          "citing_paper_doi": "10.48550/arXiv.2404.12242",
          "cited_paper_doi": "10.18653/V1/2021.NAACL-MAIN.69",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1f862b3fe4cd9c02bc9f1551c07cc8d626421a25",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2a15f541a8216782a7579f01f56762448e48b582",
          "citing_paper_year": 2024,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "MAVEN",
          "dataset_description": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models. | Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences. | Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation. | Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain. | Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance. | Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents. | Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents. | Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
          "citing_paper_id": "269214164",
          "cited_paper_id": 250390839,
          "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
          "citing_paper_doi": "10.48550/arXiv.2404.12242",
          "cited_paper_doi": "10.18653/v1/2022.naacl-main.291",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1f862b3fe4cd9c02bc9f1551c07cc8d626421a25",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c8e30e459ad7769528ac7eae051134d245ca16ee",
          "citing_paper_year": 2024,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "MAVEN",
          "dataset_description": "Used to define abstract event types as top nodes of an event ontology, focusing on general domain event detection and classification. | Used to define abstract event types as top nodes of an ontology tree, demonstrating diversity across 5 different types in a general domain event detection context. | Used to build the event ontology by utilizing its event mapping, focusing on general domain event detection and providing a large-scale dataset for training and evaluation. | MAVEN is used to train and evaluate models for detecting a wide range of event types across general domains, enhancing the robustness of event extraction systems. | Utilized for event detection in general domain texts, focusing on identifying and categorizing events across diverse topics and contexts.",
          "citing_paper_id": "258865260",
          "cited_paper_id": 216562779,
          "context_text": "Abstract event types are defined as the top nodes of the event ontology created by MAVEN (Wang et al., 2020).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions MAVEN as a dataset used for defining abstract event types in an event ontology. The cited paper title confirms MAVEN is a dataset.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.203",
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.129",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33c3eb62f55b4f46d812723fd3a053fc8c17fd21",
          "cited_paper_url": "https://www.semanticscholar.org/paper/46e84b0a7b3761d1a3c1577c66225453ab2cbc1c",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "44097522",
      "citation_count": 0,
      "total_dataset_mentions": 5,
      "unique_datasets": [
        "Causal-TimeBank"
      ],
      "dataset_details": [
        {
          "dataset_name": "Causal-TimeBank",
          "dataset_description": "Used for narrative event extraction, supporting document-level event annotation. | Used to evaluate document-level event extraction, focusing on richer event descriptions in natural language texts. | Used to annotate causal relations between events using TimeML, enhancing the TempEval-3 TimeBank data for causal and temporal relation extraction. | Used for causal relation extraction, enhancing document-level event annotation. | Used for temporal event extraction, evaluating document-level event annotation and temporal processing. | Used for event co-reference, improving document-level event annotation accuracy. | Used to evaluate causal relations, focusing on temporal and causal connections between events. | Used to evaluate narrative understanding, focusing on causal and temporal relations in short stories. | Used to evaluate event co-reference, identifying and linking events across documents. | Used to evaluate causal relations, specifically in the context of social media and news articles. | Used for causal relation extraction, supporting document-level event annotation. | Used for richer event description, enhancing document-level event annotation.",
          "citing_paper_id": "38234032",
          "cited_paper_id": 14877527,
          "context_text": "The Causal-TimeBank (Mirza and Tonelli, 2016) has introduced a TimeML-based annotation of causal relations between events on top of the TempEval-3 TimeBank data.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Causal-TimeBank' as a specific dataset used for annotating causal relations between events using TimeML. It is clearly identified and used in the research context.",
          "citing_paper_doi": "10.18653/v1/W17-2711",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/210998cf25778b5e07018a34c441e671e034fb1e",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3aed6bb014e8179303bd8d30c9386d60e5fbb254",
          "citing_paper_year": 2017,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "Causal-TimeBank",
          "dataset_description": "Used to evaluate model performance on extracting temporal and causal relations between events, focusing on the accuracy of identifying and linking event sequences. | Used to evaluate models for event causality recognition, specifically comparing rule-based, feature-based, and BERT-based approaches. | Used to evaluate ECI performance for intra-sentence events, focusing on causal relations within sentences due to the scarcity of inter-sentence causal event pairs. | Used to evaluate models on event causality identification, focusing on the relationship between events in narrative texts. | Used to assess the performance of models in identifying causal relations between events, emphasizing temporal and causal connections. | Used to tune hyperparameters and train models, focusing on event extraction and storyline construction in documents. | Used to train models, focusing on causal and temporal relations between events in documents. | Used to extract causal relations between events, consisting of 184 documents, 6813 events, and 318 of 7608 event mention pairs annotated with causal relations. | Used to evaluate models for identifying causal relations between events, focusing on performance metrics such as precision, recall, and F1 score. | Used to evaluate the performance of RichGCN on intra- and inter-sentence event extraction, focusing on the model's ability to outperform baselines. | Used to evaluate models for extracting causal and temporal relations between events, comparing rule-based, feature-based, and BERT-based approaches.",
          "citing_paper_id": "235097277",
          "cited_paper_id": 8052901,
          "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT and Know (respectively) for EventSto-ryLine (both are based on BERT).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The other names mentioned (RB, ML, BERT, Know) are models or methods, not datasets.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.273",
          "cited_paper_doi": "10.3115/v1/P14-3002",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5649d1a202e523d0653fbba3cc9017cee539dc19",
          "cited_paper_url": "https://www.semanticscholar.org/paper/db6a385e90f14fd974683d0c49cb56f60be08c72",
          "citing_paper_year": 2021,
          "cited_paper_year": 2014
        },
        {
          "dataset_name": "Causal-TimeBank",
          "dataset_description": "Used to evaluate models for event causality recognition, specifically comparing rule-based, feature-based, and BERT-based approaches. | Used to perform word-synset mapping, leveraging its lexical structure to enhance word sense disambiguation in the context of event causality recognition.",
          "citing_paper_id": "235097277",
          "cited_paper_id": 202782267,
          "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT and Know (respectively) for EventSto-ryLine (both are based on BERT).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The other names mentioned (RB, ML, BERT, Know) are models or methods, not datasets.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.273",
          "cited_paper_doi": "10.18653/v1/D19-1590",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5649d1a202e523d0653fbba3cc9017cee539dc19",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3c09611a91f526e4b30c759f50625a54d4d36cfc",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "Causal-TimeBank",
          "dataset_description": "Used to evaluate model performance on extracting temporal and causal relations between events, focusing on the accuracy of identifying and linking event sequences. | Used to evaluate models for event causality recognition, specifically comparing rule-based, feature-based, and BERT-based approaches. | Used to evaluate ECI performance for intra-sentence events, focusing on causal relations within sentences due to the scarcity of inter-sentence causal event pairs. | Used to evaluate models on event causality identification, focusing on the relationship between events in narrative texts. | Used to assess the performance of models in identifying causal relations between events, emphasizing temporal and causal connections. | Used to tune hyperparameters and train models, focusing on event extraction and storyline construction in documents. | Used to train models, focusing on causal and temporal relations between events in documents. | Used to extract causal relations between events, consisting of 184 documents, 6813 events, and 318 of 7608 event mention pairs annotated with causal relations. | Used to evaluate models for identifying causal relations between events, focusing on performance metrics such as precision, recall, and F1 score. | Used to evaluate the performance of RichGCN on intra- and inter-sentence event extraction, focusing on the model's ability to outperform baselines. | Used to evaluate models for extracting causal and temporal relations between events, comparing rule-based, feature-based, and BERT-based approaches.",
          "citing_paper_id": "235097277",
          "cited_paper_id": 44097522,
          "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT and Know (respectively) for EventSto-ryLine (both are based on BERT).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The other names mentioned (RB, ML, BERT, Know) are models or methods, not datasets.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.273",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/5649d1a202e523d0653fbba3cc9017cee539dc19",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b769d966f012dbbf013ac308aa5caba76c3fa817",
          "citing_paper_year": 2021,
          "cited_paper_year": 2014
        },
        {
          "dataset_name": "Causal-TimeBank",
          "dataset_description": "Used to evaluate models for event causality recognition, specifically comparing rule-based, feature-based, and BERT-based approaches. | Used to evaluate ECI performance for intra-sentence events, focusing on causal relations within sentences due to the scarcity of inter-sentence causal event pairs. | Used to evaluate models on event causality identification, focusing on the relationship between events in narrative texts. | Used for knowledge-enhanced data augmentation in event causality detection, leveraging distant supervision to improve model performance. | Used to evaluate models for identifying causal relations between events, focusing on performance metrics such as precision, recall, and F1 score. | Used to assess the performance of models in identifying causal relations between events, emphasizing temporal and causal connections.",
          "citing_paper_id": "235097277",
          "cited_paper_id": 220484653,
          "context_text": "Model P R F1 RB (Mirza, 2014b) 36.8 12.3 18.4 ML (Mirza, 2014a) 67.3 22.6 33.9 BERT* (Liu et al., 2020) 30.3 41.1 34.9 Know* (Liu et al., 2020) Causal-TimeBank : We use the following base-lines for this dataset: (i) RB : a rule-based system in (Mirza, 2014b); (ii) ML : a feature-based model for ECI in (Mirza, 2014a); and (iii) BERT and Know (Liu et al., 2020): These are the same models BERT and Know (respectively) for EventSto-ryLine (both are based on BERT).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Causal-TimeBank' as a dataset used for evaluating different models. The other names mentioned (RB, ML, BERT, Know) are models or methods, not datasets.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.273",
          "cited_paper_doi": "10.24963/ijcai.2020/495",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5649d1a202e523d0653fbba3cc9017cee539dc19",
          "cited_paper_url": "https://www.semanticscholar.org/paper/a50bf4fa36aa62ef48300baabb4d26f29eff14a2",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "16273722",
      "citation_count": 0,
      "total_dataset_mentions": 4,
      "unique_datasets": [
        "Nom-Bank"
      ],
      "dataset_details": [
        {
          "dataset_name": "Nom-Bank",
          "dataset_description": "Used as a larger dataset for training or evaluation, providing a significant amount of data for semantic role labeling tasks, particularly for non-local arguments. | Used to extend NomBank for implicit arguments, focusing on nominal predicates in event extraction. | Used to illustrate the limited scale of event argument datasets, containing 1,370 frame instantiations over 438 sentences for semantic role labeling. | Used to study non-local arguments in semantic role labeling, focusing on implicit arguments in stories. The dataset supports the investigation of how context influences argument identification. | Used to compare event extraction performance, focusing on implicit arguments for nominal predicates. | Used to compare the size of event argument datasets, highlighting the smaller scale of other datasets in document-level event extraction. | Used to study nominal predicates and multi-sentence arguments, focusing on event triggers and their properties, similar to those in the RAMS dataset. | Expanded and used to explore implicit arguments for nominal predicates, enhancing the original Nom-Bank with additional annotations for non-local arguments. | Used for event and role annotations, serving as a baseline for comparison with RAMS in terms of coverage and scope. | Used for event and role annotations, providing larger and broader coverage compared to other datasets, enhancing the scope of semantic role labeling.",
          "citing_paper_id": "207853145",
          "cited_paper_id": 5806560,
          "context_text": "Much of the effort on non-local arguments, sometimes called implicit SRL, has focused on two datasets, one based on stories that were produced for SemEval-2010 Task 10 (Ruppenhofer et al., 2010) and the other an expansion of Nom-Bank (Meyers et al., 2004) compiled by Gerber and Chai (2010, 2012).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets used for non-local arguments or implicit SRL: one from SemEval-2010 Task 10 and an expansion of Nom-Bank. These are clearly identified and used in the research.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.718",
          "cited_paper_doi": "10.1162/COLI_a_00110",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "cited_paper_url": "https://www.semanticscholar.org/paper/acbac8a75b25384bcc10953b2becc8278b9240c9",
          "citing_paper_year": 2019,
          "cited_paper_year": 2012
        },
        {
          "dataset_name": "Nom-Bank",
          "dataset_description": "Expanded and used to explore implicit arguments for nominal predicates, enhancing the original Nom-Bank with additional annotations for non-local arguments. | Used to study non-local arguments in semantic role labeling, focusing on implicit arguments in stories. The dataset supports the investigation of how context influences argument identification.",
          "citing_paper_id": "207853145",
          "cited_paper_id": 16273722,
          "context_text": "Much of the effort on non-local arguments, sometimes called implicit SRL, has focused on two datasets, one based on stories that were produced for SemEval-2010 Task 10 (Ruppenhofer et al., 2010) and the other an expansion of Nom-Bank (Meyers et al., 2004) compiled by Gerber and Chai (2010, 2012).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets used for non-local arguments or implicit SRL: one from SemEval-2010 Task 10 and an expansion of Nom-Bank. These are clearly identified and used in the research.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.718",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "cited_paper_url": "https://www.semanticscholar.org/paper/255d6867cb5c57810c909d5e488c9ae86e0d6d3e",
          "citing_paper_year": 2019,
          "cited_paper_year": 2004
        },
        {
          "dataset_name": "Nom-Bank",
          "dataset_description": "Utilized for semantic role labeling across various domains, including novels, with a focus on different ontologies and predicate types. | Employed for semantic role labeling in a smaller scale, covering a limited set of predicate types and domains. | Used for annotating implicit arguments in semantic role labeling, focusing on a diverse set of texts and contexts. | Used for semantic role labeling of nominal predicates, providing annotations for implicit arguments in a limited set of predicate types.",
          "citing_paper_id": "220046861",
          "cited_paper_id": 5806560,
          "context_text": "Yet most are performed with different ontologies such as Nombank ( G&C ) and FrameNet ( SemEval-2010 and 80Days ); on different domains (e.g. novels); and in smaller scales ( G&C and 80Days only cover 10 types of predicates).",
          "confidence_score": 0.8,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions 'Nombank', 'FrameNet', and '80Days' but does not specify their use as datasets. These are likely ontologies or resources used in semantic role labeling, which is related to event extraction.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.667",
          "cited_paper_doi": "10.1162/COLI_a_00110",
          "citing_paper_url": "https://www.semanticscholar.org/paper/65bf813891b05c26d1cb3608c281d36a641ef366",
          "cited_paper_url": "https://www.semanticscholar.org/paper/acbac8a75b25384bcc10953b2becc8278b9240c9",
          "citing_paper_year": 2020,
          "cited_paper_year": 2012
        },
        {
          "dataset_name": "Nom-Bank",
          "dataset_description": "Employed to train and evaluate models on document-level event extraction, specifically addressing challenges in cross-sentence event coreference. | Used to study implicit arguments for nominal predicates, focusing on a limited set of predicate types in various domains. | Applied to evaluate event extraction systems on a smaller scale, covering a limited set of predicate types. | Utilized for semantic role labeling in different domains, including novels, to compare with other ontologies and datasets.",
          "citing_paper_id": "220046861",
          "cited_paper_id": 13804679,
          "context_text": "Yet most are performed with different ontologies such as Nombank (G&C) and FrameNet (SemEval-2010 and 80Days); on different domains (e.g. novels); and in smaller scales (G&C and 80Days only cover 10 types of predicates).",
          "confidence_score": 0.8,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Nombank', 'FrameNet', and '80Days' but does not specify their use as datasets. However, given the research topic and the nature of these resources, they are likely to be datasets used for event extraction.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.667",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/65bf813891b05c26d1cb3608c281d36a641ef366",
          "cited_paper_url": "https://www.semanticscholar.org/paper/d8259bcbe9cb0cf5bad6ea25645f4407fc544a1c",
          "citing_paper_year": 2020,
          "cited_paper_year": 2010
        }
      ]
    },
    {
      "cited_paper_id": "9776219",
      "citation_count": 0,
      "total_dataset_mentions": 4,
      "unique_datasets": [
        "ACE"
      ],
      "dataset_details": [
        {
          "dataset_name": "ACE",
          "dataset_description": "Used to evaluate the performance of relation extraction methods, focusing on the accuracy of identifying relations in text without labeled training data.",
          "citing_paper_id": "246241684",
          "cited_paper_id": 10910955,
          "context_text": "These methods have achieved the promising performance on ACE dataset [20].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the 'ACE dataset' which is a well-known dataset in the field of information extraction, particularly for event and relation extraction tasks.",
          "citing_paper_doi": "10.1145/3502223.3502229",
          "cited_paper_doi": "10.3115/1690219.1690287",
          "citing_paper_url": "https://www.semanticscholar.org/paper/13a32988ccdda02bca2e2ec11902b0834baaeadb",
          "cited_paper_url": "https://www.semanticscholar.org/paper/d84b57362e2010f6f65357267df7e0157af30684",
          "citing_paper_year": 2021,
          "cited_paper_year": 2009
        },
        {
          "dataset_name": "ACE",
          "dataset_description": "Utilized to explore event extraction in the biomedical domain, specifically for identifying molecular events and interactions, enhancing precision and recall in specialized contexts. | Used to study event extraction, focusing on identifying and classifying events in text, employing a well-established benchmark for evaluation.",
          "citing_paper_id": "2367456",
          "cited_paper_id": 9631585,
          "context_text": "Event extraction has been mainly studied using the ACE data (Doddington et al., 2004) and biomedical data for the BioNLP shared tasks (Kim et al., 2009).",
          "confidence_score": 0.85,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets: 'ACE data' and 'biomedical data for the BioNLP shared tasks'. Both are relevant to event extraction and are used in the research context.",
          "citing_paper_doi": "10.18653/v1/N16-1033",
          "cited_paper_doi": "10.3115/1572340.1572342",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c558e2b5dcab8d89f957f3045a9bbd43fd6a28ed",
          "cited_paper_url": "https://www.semanticscholar.org/paper/d461edc4de7d4c1398f76c08b54310cd017b963d",
          "citing_paper_year": 2016,
          "cited_paper_year": 2009
        },
        {
          "dataset_name": "ACE",
          "dataset_description": "Used for event recognition through annotation-based methods, focusing on slot filling and knowledge-based population to identify events in text.",
          "citing_paper_id": "13241382",
          "cited_paper_id": 199562431,
          "context_text": "ACE[11] (Automatic Content Extraction) Annotation based method Based on slots filling and knowledge based population (KBP) to recognize the events.",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ACE' which is a known dataset for event extraction, but does not provide specific details on its usage in this research context.",
          "citing_paper_doi": "10.1109/RTEICT.2016.7807771",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/604bb995898792c42402504eea43ef65ee3f050a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/63184bd44dcf66212184a47c59b0c91be9cda369",
          "citing_paper_year": 2016,
          "cited_paper_year": 2005
        },
        {
          "dataset_name": "ACE",
          "dataset_description": "Used to highlight annotation consistency issues in event recognition, focusing on the challenges of human annotators in identifying event mentions.",
          "citing_paper_id": "3137086",
          "cited_paper_id": 9776219,
          "context_text": "Experience with event annotation for Light ERE and ACE (Doddington et al., 2004) and related tasks suggests that a major challenge for annotation consistency is poor recall – human annotators are not highly consistent in recognizing that a mention has occurred.",
          "confidence_score": 0.8,
          "citation_intent": "findings",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ACE' which is a known dataset in the field of event extraction. However, it is used to discuss annotation challenges rather than as a primary dataset for the research.",
          "citing_paper_doi": "10.3115/v1/W15-0809",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/9c34bf7bdb5a4247772c5c6d4982aa4d41e67be9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/0617dd6924df7a3491c299772b70e90507b195dc",
          "citing_paper_year": 2015,
          "cited_paper_year": 2004
        }
      ]
    },
    {
      "cited_paper_id": "195345077",
      "citation_count": 0,
      "total_dataset_mentions": 4,
      "unique_datasets": [
        "SCIREX"
      ],
      "dataset_details": [
        {
          "dataset_name": "SCIREX",
          "dataset_description": "Used to compare document-level neural template-filling approaches, focusing on scientific document extraction and summarization tasks. | Used to compare document-level neural template-filling approaches, focusing on message understanding and event extraction tasks. | Used to compare document-level neural template-filling approaches, focusing on disease outbreak information extraction from news articles.",
          "citing_paper_id": "248780414",
          "cited_paper_id": 235097664,
          "context_text": "Next, we employ the error analysis framework in a comparison of two state-of-the-art documentlevel neural template-filling approaches, DyGIE++ (Wadden et al., 2019) and GTT (Du et al., 2021b), across three template-filling datasets (SciREX, ProMED (Patwardhan and Riloff, 2009)3, and MUC-4).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions three specific datasets used for comparing document-level neural template-filling approaches. These datasets are SciREX, ProMED, and MUC-4.",
          "citing_paper_doi": "10.18653/v1/2022.acl-long.274",
          "cited_paper_doi": "10.18653/V1/2021.NAACL-MAIN.70",
          "citing_paper_url": "https://www.semanticscholar.org/paper/0b21349acbef40735f64f6660271aef8faea886f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e9b3fed266dff06d44be861cce8bd9c247b7d42a",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "SCIREX",
          "dataset_description": "Used to train and evaluate the GTT model for 20 epochs, focusing on scientific document event extraction. | Used to evaluate Information Extraction systems, focusing on error types such as missing and spurious role filler errors, providing linguistic grounding for performance analysis. | Used to compare the performance of newer neural models (DyGIE++, GTT) with older IE systems, specifically focusing on event extraction tasks from 1992. | Used to evaluate Information Extraction systems, focusing on the performance of entity and relation extraction in news articles. | Used to train and test neural-based information extraction models, focusing on disease outbreak reports. | Used to train and test neural-based information extraction models, focusing on event extraction in news articles. | Used to train and evaluate the GTT model for 20 epochs, focusing on document-level event extraction. | Used to evaluate model performance on scientific texts, highlighting challenges in handling specialized language. | Used to compare document-level neural template-filling approaches, focusing on disease outbreak reports. | Used to compare the performance of original MUC-4 systems with newer deep-learning approaches in document-level information extraction, focusing on progress over 30 years. | Used to train and evaluate the GTT model for 36 epochs, adjusted for its smaller size, focusing on medical document event extraction. | Used to assess model effectiveness on scientific documents, emphasizing difficulties with technical content. | Used to extract events from newswire articles describing terrorist incidents in Latin America, focusing on the identification and classification of event types and participants. | Used to evaluate DyGIE++ and GTT, focusing on scientific document event extraction and coreference resolution. | Used as a benchmark for news text, demonstrating better model performance on general-purpose language. | Used to compare document-level neural template-filling approaches, focusing on news articles for event extraction. | Used to evaluate DyGIE++ and GTT models, focusing on scientific document information extraction, comparing performance against other systems. | Used to evaluate the performance of early and recent models, specifically comparing precision, recall, and F1 scores in document-level event extraction. | Used to evaluate DyGIE++ and GTT, focusing on message understanding and event extraction from news articles. | Used to compare document-level neural template-filling approaches, focusing on scientific document extraction tasks. | Used to evaluate the performance of GTT and DyGIE++ on document-level event extraction, focusing on reducing Missing Template errors. | Used to train and test neural-based information extraction models, focusing on scientific document event extraction. | Used to assess the performance of DyGIE++ and GTT models in extracting information from disease outbreak reports, highlighting advancements in neural models. | Used to evaluate DyGIE++ and GTT, focusing on disease outbreak event extraction from health-related texts.",
          "citing_paper_id": "248780414",
          "cited_paper_id": null,
          "context_text": "We ﬁrst discuss the results of DyGIE++ and GTT on SciREX, ProMED, and MUC-4; and then examine the performance of these newer neural models on the 1992 MUC-4 dataset vs. a few of the best-performing IE systems at the time.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions specific datasets used for evaluating models, which are relevant to document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/2022.acl-long.274",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/0b21349acbef40735f64f6660271aef8faea886f",
          "cited_paper_url": null,
          "citing_paper_year": 2022,
          "cited_paper_year": null
        },
        {
          "dataset_name": "SCIREX",
          "dataset_description": "Used to compare model performance on document-level event extraction subtasks, focusing on scientific document processing and evaluation metrics. | Used to evaluate document-level event extraction, focusing on scientific documents and comparing performance across different subtasks. | Used to evaluate and compare model performance on document-level event extraction, specifically for scientific document tasks and entity relations.",
          "citing_paper_id": "218470122",
          "cited_paper_id": 195345077,
          "context_text": "We compare our model with DYGIE++ (Wadden et al., 2019) and DocTAET (Hou et al., 2019) on subtasks of our SCIREX dataset and on the SCIERC dataset wherever they apply.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'SCIREX' and 'SCIERC' datasets, which are specific and relevant to document-level event extraction. These datasets are used for comparing model performance.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.670",
          "cited_paper_doi": "10.18653/v1/P19-1513",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e99a259299d4d555ee4c354f2095ab4401369c82",
          "cited_paper_url": "https://www.semanticscholar.org/paper/115617d09807325bd18c42deedd6cab435f90563",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "SCIREX",
          "dataset_description": "Used to compare model performance on document-level event extraction subtasks, focusing on scientific document processing and evaluation metrics. | Used to evaluate and compare model performance on document-level event extraction, specifically for scientific document tasks and entity relations.",
          "citing_paper_id": "218470122",
          "cited_paper_id": 202539496,
          "context_text": "We compare our model with DYGIE++ (Wadden et al., 2019) and DocTAET (Hou et al., 2019) on subtasks of our SCIREX dataset and on the SCIERC dataset wherever they apply.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'SCIREX' and 'SCIERC' datasets, which are specific and relevant to document-level event extraction. These datasets are used for comparing model performance.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.670",
          "cited_paper_doi": "10.18653/v1/D19-1585",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e99a259299d4d555ee4c354f2095ab4401369c82",
          "cited_paper_url": "https://www.semanticscholar.org/paper/fac2368c2ec81ef82fd168d49a0def2f8d1ec7d8",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "235254286",
      "citation_count": 0,
      "total_dataset_mentions": 4,
      "unique_datasets": [
        "WikiEvents"
      ],
      "dataset_details": [
        {
          "dataset_name": "WikiEvents",
          "dataset_description": "Used to evaluate Span-F1 and Head-F1 metrics, focusing on argument extraction in document-level event extraction. | Used to evaluate Coref-F1 metric, which considers co-reference linkages between arguments in document-level event extraction.",
          "citing_paper_id": "259370721",
          "cited_paper_id": 236460308,
          "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the topic.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.532",
          "cited_paper_doi": "10.18653/v1/2021.acl-long.360",
          "citing_paper_url": "https://www.semanticscholar.org/paper/70cb23e280893105cbf582affe439e858916765f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/89c32bb4da87815564081be435e54dbd09b4a426",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "WikiEvents",
          "dataset_description": "Used to train an event detection model, focusing on document-level event extraction with the OmniEvent toolkit. | Used to train an event detection model using the CLEVE PLM, classifying event mentions to their most likely event type in the KAIROS ontology.",
          "citing_paper_id": "273185680",
          "cited_paper_id": 235166504,
          "context_text": "Event Detection We trained an event detection using the OmniEvent toolkit (Peng et al., 2023b) on the WikiEvents dataset (Li et al., 2021), and we selected CLEVE (Wang et al., 2021) as the PLM.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the WikiEvents dataset, which is a specific, verifiable dataset used for training an event detection model. CLEVE is mentioned but is a method, not a dataset.",
          "citing_paper_doi": "10.48550/arXiv.2410.04752",
          "cited_paper_doi": "10.18653/v1/2021.acl-long.220",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c568decc196679e98826dca827bd0814ba59037d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f674b75ce8159759c42aa1bf93e08903934af29e",
          "citing_paper_year": 2024,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "WikiEvents",
          "dataset_description": "Used to train an event detection model, focusing on document-level event extraction with the OmniEvent toolkit. | Used to train an event detection model using the CLEVE PLM, classifying event mentions to their most likely event type in the KAIROS ontology.",
          "citing_paper_id": "273185680",
          "cited_paper_id": 235254286,
          "context_text": "Event Detection We trained an event detection using the OmniEvent toolkit (Peng et al., 2023b) on the WikiEvents dataset (Li et al., 2021), and we selected CLEVE (Wang et al., 2021) as the PLM.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the WikiEvents dataset, which is a specific, verifiable dataset used for training an event detection model. CLEVE is mentioned but is a method, not a dataset.",
          "citing_paper_doi": "10.48550/arXiv.2410.04752",
          "cited_paper_doi": "10.18653/v1/2021.acl-long.491",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c568decc196679e98826dca827bd0814ba59037d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2580aed3ac10d971f86d21f4c06db2de0cfb3c22",
          "citing_paper_year": 2024,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "WikiEvents",
          "dataset_description": "Used to highlight the entity-centric nature and limited event coverage in document-level event extraction, focusing on specific abstract event types. | Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories. | Referenced for its definitions of events, which differ from those used in the current research. | Used to evaluate document-level event argument extraction, focusing on complex events and their arguments across multiple sentences. | Applied to study document-level event extraction, specifically addressing the challenge of identifying and linking events within and across sentences.",
          "citing_paper_id": "258865260",
          "cited_paper_id": 207853145,
          "context_text": "Recent works have introduced document-level EAE datasets like RAMS (Ebner et al., 2020), WikiEvents (Li et al.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are relevant to document-level event argument extraction.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.203",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33c3eb62f55b4f46d812723fd3a053fc8c17fd21",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "41089825",
      "citation_count": 0,
      "total_dataset_mentions": 4,
      "unique_datasets": [
        "GENEVA"
      ],
      "dataset_details": [
        {
          "dataset_name": "GENEVA",
          "dataset_description": "Mentioned as being more diverse than other datasets, but no specific usage details are provided in the citation context.",
          "citing_paper_id": "258865260",
          "cited_paper_id": 8471750,
          "context_text": "We observe that GENEVA is relatively more diverse than the other datasets. question answering (Berant et al., 2014), and others (Hogenboom et al., 2016; Wen et al., 2021; Yang et al., 2019b).",
          "confidence_score": 0.6,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'GENEVA' as a dataset and compares its diversity to other datasets. However, no specific usage details are provided in the citation context.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.203",
          "cited_paper_doi": "10.3115/v1/D14-1159",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33c3eb62f55b4f46d812723fd3a053fc8c17fd21",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6396ab37641d36be4c26420e58adeb8665914c3b",
          "citing_paper_year": 2022,
          "cited_paper_year": 2014
        },
        {
          "dataset_name": "GENEVA",
          "dataset_description": "Mentioned as being more diverse than other datasets, but no specific usage details are provided in the citation context.",
          "citing_paper_id": "258865260",
          "cited_paper_id": 41089825,
          "context_text": "We observe that GENEVA is relatively more diverse than the other datasets. question answering (Berant et al., 2014), and others (Hogenboom et al., 2016; Wen et al., 2021; Yang et al., 2019b).",
          "confidence_score": 0.6,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'GENEVA' as a dataset and compares its diversity to other datasets. However, no specific usage details are provided in the citation context.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.203",
          "cited_paper_doi": "10.1016/j.dss.2016.02.006",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33c3eb62f55b4f46d812723fd3a053fc8c17fd21",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2ff9e6b1a03f968bd96943f38ef184aabd272e9d",
          "citing_paper_year": 2022,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "GENEVA",
          "dataset_description": "Mentioned as being more diverse than other datasets, but no specific usage details are provided in the citation context.",
          "citing_paper_id": "258865260",
          "cited_paper_id": 196178503,
          "context_text": "We observe that GENEVA is relatively more diverse than the other datasets. question answering (Berant et al., 2014), and others (Hogenboom et al., 2016; Wen et al., 2021; Yang et al., 2019b).",
          "confidence_score": 0.6,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'GENEVA' as a dataset and compares its diversity to other datasets. However, no specific usage details are provided in the citation context.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.203",
          "cited_paper_doi": "10.18653/v1/P19-1522",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33c3eb62f55b4f46d812723fd3a053fc8c17fd21",
          "cited_paper_url": "https://www.semanticscholar.org/paper/36b79362d2927824e0daa864dd32cf0de7ca35f9",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "GENEVA",
          "dataset_description": "Used to analyze event types and build knowledge graphs, focusing on the distribution of event types across various abstract categories. | Used to analyze distribution of event types, focusing on abstract event categories for document-level event extraction.",
          "citing_paper_id": "258865260",
          "cited_paper_id": null,
          "context_text": "EAE is a classic topic (Sundheim, 1992) and elemental for a wide range of applications like building knowledge graphs (Zhang et al., 2020), Figure 1: Distribution of event types into various abstract event types 1 for GENEVA, ACE, ERE, RAMS, and WikiEvents datasets.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets by name, which are relevant to document-level event extraction. These datasets are used for building knowledge graphs and analyzing event types.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.203",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/33c3eb62f55b4f46d812723fd3a053fc8c17fd21",
          "cited_paper_url": null,
          "citing_paper_year": 2022,
          "cited_paper_year": null
        }
      ]
    },
    {
      "cited_paper_id": "6962537",
      "citation_count": 0,
      "total_dataset_mentions": 3,
      "unique_datasets": [
        "GENIA event corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "GENIA event corpus",
          "dataset_description": "Mentioned as a resource addressing bio-IE with finer-grained information extraction, but specific usage in the current research is not detailed. | Used to develop and evaluate document-level event extraction methods, focusing on genic interactions and their linguistic representations.",
          "citing_paper_id": "9631585",
          "cited_paper_id": 6962537,
          "context_text": "The data was developed based on the GENIA event corpus.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the GENIA event corpus, which is a well-known dataset in the field of biomedical text mining and event extraction.",
          "citing_paper_doi": "10.3115/1572340.1572342",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/d461edc4de7d4c1398f76c08b54310cd017b963d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/91e0ce446530b62c78495cdfcfd9190efb974fce",
          "citing_paper_year": 2009,
          "cited_paper_year": 2005
        },
        {
          "dataset_name": "GENIA event corpus",
          "dataset_description": "Used to annotate biological events in 1,000 abstracts, including polarity, certainty, and lexical cues, supporting research in event extraction methodologies.",
          "citing_paper_id": "2239324",
          "cited_paper_id": null,
          "context_text": "The GENIA Event corpus (Kim, Ohta, and Tsujii 2008) contains 1,000 abstracts with biological events annotated with polarity and degrees of certainty, in addition to other information such as the lexical cues leading to these values (Ohta, Kim, and Tsuji 2007).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the GENIA Event corpus, which is a specific dataset used for annotating biological events in abstracts. It is clearly identified and described in the citation.",
          "citing_paper_doi": "10.1162/COLI_a_00096",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/fec2e117185dbc0e69008872934d84ed5c0209a7",
          "cited_paper_url": null,
          "citing_paper_year": 2012,
          "cited_paper_year": null
        },
        {
          "dataset_name": "GENIA event corpus",
          "dataset_description": "Used to introduce and evaluate an event representation and extraction task, focusing on biomedical events and their annotations. | Serves as the basis for the Shared Task data, providing PubMed citations relevant to biological reactions in human blood cells, used for training and evaluation. | Used to evaluate systems on extracting biological reactions concerning transcription factors in human blood cells, focusing on the performance of different methods. | Used to annotate genic interaction events in biomedical text, focusing on the effort and time required for annotation with multiple part-time annotators and coordinators. | Used to evaluate the system's performance on data with fewer events per sentence, highlighting deviations from the training distribution.",
          "citing_paper_id": "17984630",
          "cited_paper_id": 6962537,
          "context_text": "The task introduced an event representation and extraction task based on the GENIA event corpus annotation (Kim et al., 2008).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the GENIA event corpus, which is a specific dataset used for event extraction tasks in the biomedical domain.",
          "citing_paper_doi": "10.1093/bioinformatics/btq180",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/f1ae781dfe425c8026a20dbb474770b696cfb172",
          "cited_paper_url": "https://www.semanticscholar.org/paper/91e0ce446530b62c78495cdfcfd9190efb974fce",
          "citing_paper_year": 2010,
          "cited_paper_year": 2005
        }
      ]
    },
    {
      "cited_paper_id": "12793034",
      "citation_count": 0,
      "total_dataset_mentions": 3,
      "unique_datasets": [
        "FrameNet"
      ],
      "dataset_details": [
        {
          "dataset_name": "FrameNet",
          "dataset_description": "Used for pre-training in event extraction, framed in an MRC formulation to improve the model's ability to identify and classify events. | Used for pre-training in semantic role labeling, framed in an MRC formulation to enhance the model's understanding of semantic roles. | Used to assess the MRC model's semantic role labeling capabilities, specifically measuring F1 score post-pre-training. | Used to evaluate the MRC model's event extraction performance, particularly in identifying events and entities, using F1 score.",
          "citing_paper_id": "252901047",
          "cited_paper_id": 52967399,
          "context_text": "We prefer the BERT-based MRC model [12], and in addition to the question answering dataset, i.e., SQuAD 2.0 [36], we also use corpora in FrameNet semantic role labeling (SRL) [37] and ACE 2005 event extraction (EE) [38] for pre-training 2 , by framing them in an MRC formulation in a similar fashion.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions SQuAD 2.0, FrameNet, and ACE 2005 as corpora used for pre-training. These are specific datasets used in the research.",
          "citing_paper_doi": "10.1109/TASLP.2022.3210442",
          "cited_paper_doi": "10.18653/v1/N19-1423",
          "citing_paper_url": "https://www.semanticscholar.org/paper/46de1ace70891306ca2dcc06a974d1d23ba77c7f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "FrameNet",
          "dataset_description": "Used for pre-training in event extraction, framed in an MRC formulation to improve the model's ability to identify and classify events. | Used for pre-training in semantic role labeling, framed in an MRC formulation to enhance the model's understanding of semantic roles.",
          "citing_paper_id": "252901047",
          "cited_paper_id": null,
          "context_text": "We prefer the BERT-based MRC model [12], and in addition to the question answering dataset, i.e., SQuAD 2.0 [36], we also use corpora in FrameNet semantic role labeling (SRL) [37] and ACE 2005 event extraction (EE) [38] for pre-training 2 , by framing them in an MRC formulation in a similar fashion.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions SQuAD 2.0, FrameNet, and ACE 2005 as corpora used for pre-training. These are specific datasets used in the research.",
          "citing_paper_doi": "10.1109/TASLP.2022.3210442",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/46de1ace70891306ca2dcc06a974d1d23ba77c7f",
          "cited_paper_url": null,
          "citing_paper_year": 2022,
          "cited_paper_year": null
        },
        {
          "dataset_name": "FrameNet",
          "dataset_description": "Utilized to design the ontology for event argument extraction, leveraging shared properties with semantic role labeling to reduce human effort while maintaining high quality. | Leveraged to build the ontology, exploiting shared properties with semantic role labeling and event argument extraction, providing a diverse and exhaustive resource. | Leveraged as a diverse and exhaustive SRL dataset to exploit shared properties with event argument extraction, reducing human effort in annotation.",
          "citing_paper_id": "258865260",
          "cited_paper_id": 12793034,
          "context_text": "To reduce human effort, we exploit the shared properties between semantic role labeling (SRL) and EAE (Aguilar et al., 2014) and leverage a diverse and exhaustive SRL dataset, FrameNet (Baker et al.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "FrameNet is mentioned as a dataset used for semantic role labeling (SRL), which shares properties with event argument extraction (EAE). It is described as diverse and exhaustive.",
          "citing_paper_doi": "10.18653/v1/2023.acl-long.203",
          "cited_paper_doi": "10.3115/v1/W14-2907",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33c3eb62f55b4f46d812723fd3a053fc8c17fd21",
          "cited_paper_url": "https://www.semanticscholar.org/paper/7fa072aaecb006e7d4435814ea469af6baded9f9",
          "citing_paper_year": 2022,
          "cited_paper_year": 2014
        }
      ]
    },
    {
      "cited_paper_id": "16250626",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "EPI"
      ],
      "dataset_details": [
        {
          "dataset_name": "EPI",
          "dataset_description": "Used to assess EventMine's effectiveness in identifying interaction detection events, showing high F scores. | Used to test EventMine's capabilities in extracting protein-protein interactions, achieving competitive results. | Used to evaluate EventMine's performance on gene expression events, demonstrating superior F scores compared to other systems.",
          "citing_paper_id": "13981987",
          "cited_paper_id": 16250626,
          "context_text": "EventMine outperforms the best systems participating in the original BioNLP Shared Task 2011 on the GE and ID data sets (with F scores 58.0% and 57.6%, respectively) and is competitive with the best systems on the EPI data set (Kim et al., 2011b; Miwa et al., 2012).",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used in the BioNLP Shared Task 2011, which are relevant to document-level event extraction.",
          "citing_paper_doi": "10.1093/bioinformatics/bts407",
          "cited_paper_doi": "10.1093/bioinformatics/bts237",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a8dff94485a16320e1ef980420bc74b2882babee",
          "cited_paper_url": "https://www.semanticscholar.org/paper/67382d16cefd5b3f707597e94df14ff996bebe69",
          "citing_paper_year": 2012,
          "cited_paper_year": 2012
        },
        {
          "dataset_name": "EPI",
          "dataset_description": "Used for annotating event and interaction data in the BioNLP Shared Task 2011, focusing on protein interactions and modifications. | Used for annotating event and interaction data in the BioNLP Shared Task 2011, focusing on infectious diseases and their molecular mechanisms.",
          "citing_paper_id": "2065400",
          "cited_paper_id": 3175781,
          "context_text": "One prominent effort making use of BRAT is the BioNLP Shared Task 2011,1 in which the tool was used in the annotation of the EPI and ID main task corpora (Pyysalo et al., 2012).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the EPI and ID corpora, which are specific datasets used in the BioNLP Shared Task 2011. These corpora are clearly identified and used for annotation tasks.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.1186/1471-2105-13-S11-S2",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a97c7876ebf9ae6c468db92c3c6dc1c0be832192",
          "cited_paper_url": "https://www.semanticscholar.org/paper/44107a021d2e6b8ee35b761417734f09d633c571",
          "citing_paper_year": 2012,
          "cited_paper_year": 2012
        }
      ]
    },
    {
      "cited_paper_id": "1671874",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "WordNet"
      ],
      "dataset_details": [
        {
          "dataset_name": "WordNet",
          "dataset_description": "Used to retrieve synonyms for data augmentation in trigger and argument extraction tasks, enhancing model performance through synonym replacement.",
          "citing_paper_id": "255522592",
          "cited_paper_id": 1671874,
          "context_text": "We compare our proposed data augmentation method Ours (t5-small) with three baselines: (1) Synonym Replacement replaces adjunct tokens with one of their synonyms retrieved from WordNet (Miller, 1992) DA methods on both trigger extraction (F1) and argument extraction (F1).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions WordNet as a lexical database used for synonym replacement in data augmentation methods. No other datasets are explicitly named.",
          "citing_paper_doi": "10.48550/arXiv.2301.02427",
          "cited_paper_doi": "10.1145/219717.219748",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a955a5a6d2fd7740375b6f22d2ac9719ce02d17f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/68c03788224000794d5491ab459be0b2a2c38677",
          "citing_paper_year": 2023,
          "cited_paper_year": 1995
        },
        {
          "dataset_name": "WordNet",
          "dataset_description": "Used to retrieve synonyms for data augmentation in trigger and argument extraction tasks, enhancing model performance through synonym replacement.",
          "citing_paper_id": "255522592",
          "cited_paper_id": 225041226,
          "context_text": "We compare our proposed data augmentation method Ours (t5-small) with three baselines: (1) Synonym Replacement replaces adjunct tokens with one of their synonyms retrieved from WordNet (Miller, 1992) DA methods on both trigger extraction (F1) and argument extraction (F1).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions WordNet as a lexical database used for synonym replacement in data augmentation methods. No other datasets are explicitly named.",
          "citing_paper_doi": "10.48550/arXiv.2301.02427",
          "cited_paper_doi": "10.18653/V1/2020.COLING-MAIN.343",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a955a5a6d2fd7740375b6f22d2ac9719ce02d17f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/bdbb944a84b8cdec8d120d2d2535995e335d0174",
          "citing_paper_year": 2023,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "9700115",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "ERE"
      ],
      "dataset_details": [
        {
          "dataset_name": "ERE",
          "dataset_description": "Used for entity recognition and linking, focusing on identifying and linking entities in multilingual and cross-document contexts.",
          "citing_paper_id": "249010869",
          "cited_paper_id": 41479182,
          "context_text": ", 2020); coreference component on ACE05, EDL 2016 (LDC2017E03), EDL 2017 (LDC2017E52), OntoNotes (Pradhan et al., 2012), ERE, CoNLL 2002 (Tjong Kim Sang, 2002), DCEP (Dias, 2016) and SemEval10 (Recasens",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions several datasets used for coreference resolution and entity linking tasks. These datasets are specific and have clear identifiers.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-demo.7",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/396833983f6d7d77957e12c3839e5da05feb053a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f8cdf754fb7c08caf6e2f82b176819230910be5b",
          "citing_paper_year": 2022,
          "cited_paper_year": 2012
        },
        {
          "dataset_name": "ERE",
          "dataset_description": "Used to train and evaluate models on entity, relation, and event extraction tasks, focusing on different ratios of training data to assess performance.",
          "citing_paper_id": "258947053",
          "cited_paper_id": 9700115,
          "context_text": ", 2004) and ERE (Song et al., 2015) datasets using different ratios of training data.",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ERE' as a dataset, which is likely a specific, verifiable resource given the cited paper title. The context also mentions 'different ratios of training data', indicating the dataset is used for training and evaluation.",
          "citing_paper_doi": "10.48550/arXiv.2305.16734",
          "cited_paper_doi": "10.3115/v1/W15-0812",
          "citing_paper_url": "https://www.semanticscholar.org/paper/b7c676d7b14af6090bf247db2d538e33de8ccd58",
          "cited_paper_url": "https://www.semanticscholar.org/paper/17793213e53c6358e336822da851f22d04cd4e7a",
          "citing_paper_year": 2023,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "6364632",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "TempEval-3 Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "TempEval-3 Corpus",
          "dataset_description": "Used to annotate event causal relations, focusing on identifying and labeling causal connections between events in text. | Used to evaluate the performance of CauSeRL on causality detection, achieving an F1 score of 53.2%. The dataset focuses on event causality in Chinese text. | Used to annotate causal relations in texts, focusing on event temporal relations using a rule-based multi-sieve approach. | Used for event extraction and causality annotation, containing 184 documents, 6813 events, and 318 causal event pairs. | Used to evaluate causality annotation in the TempEval-3 corpus, focusing on identifying causal relations in text. | Used for 10-fold cross-validation in event extraction experiments, focusing on the robustness of the model across different folds. | Used for event extraction and causality annotation, containing annotated documents with events and causal relationships. | Used for 5-fold cross-validation in event extraction experiments, focusing on the robustness of the model across different folds. | Used to evaluate causality detection, specifically comparing performance against other datasets and models. | Used to evaluate causality annotation models, focusing on identifying causal relations in text. The dataset is part of the TempEval-3 corpus and is used for benchmarking performance. | Used to evaluate the performance of CauSeRL on causality detection, achieving an F1 score of 52.1%. The dataset focuses on event causality in text. | Used to evaluate causality annotation systems, focusing on precision, recall, and F1 scores for identifying causal relations in text.",
          "citing_paper_id": "235313618",
          "cited_paper_id": 6364632,
          "context_text": "Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'TempEval-3 Corpus' which is a specific dataset used for temporal and causal relation annotation. No other datasets are mentioned.",
          "citing_paper_doi": "10.18653/v1/2021.findings-acl.190",
          "cited_paper_doi": "10.3115/v1/W14-0702",
          "citing_paper_url": "https://www.semanticscholar.org/paper/47ea802a1fed0f735a9a61a7c9b63062f02a5f5d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/801cb56e4abef192407926ef9e06847962f8dc01",
          "citing_paper_year": 2021,
          "cited_paper_year": 2014
        },
        {
          "dataset_name": "TempEval-3 Corpus",
          "dataset_description": "Used to annotate causal relations in texts, focusing on event temporal relations using a rule-based multi-sieve approach.",
          "citing_paper_id": "235313618",
          "cited_paper_id": 14877527,
          "context_text": "Mirza et al. (2014), Mirza and Tonelli (2016) extracted causal relation of events with a rule-based multi-sieve approach incorporating with event temporal relation.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'TempEval-3 Corpus' which is a specific dataset used for temporal and causal relation annotation. No other datasets are mentioned.",
          "citing_paper_doi": "10.18653/v1/2021.findings-acl.190",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/47ea802a1fed0f735a9a61a7c9b63062f02a5f5d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3aed6bb014e8179303bd8d30c9386d60e5fbb254",
          "citing_paper_year": 2021,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "14365335",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "MUC3"
      ],
      "dataset_details": [
        {
          "dataset_name": "MUC3",
          "dataset_description": "Used as a basis for the REE task, simplifying the original formulation for event extraction, but details on specific usage in this research are not provided.",
          "citing_paper_id": "231728756",
          "cited_paper_id": 6644751,
          "context_text": "We base the REE task on the original MUC3 formulation (Sundheim, 1991), but simplify it as done in prior research (Huang and Riloff, 2012; Du and Cardie, 2020).",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'MUC3' which is a specific dataset used for event extraction tasks. However, it does not provide details on how the dataset is used in the current research.",
          "citing_paper_doi": "10.18653/v1/2021.eacl-main.52",
          "cited_paper_doi": "10.1609/aaai.v26i1.8354",
          "citing_paper_url": "https://www.semanticscholar.org/paper/eb54c33b170782eb3c16f206a263abfc551b9c51",
          "cited_paper_url": "https://www.semanticscholar.org/paper/53b181cfb07a1b29e9dd30a86442c10c00a0148b",
          "citing_paper_year": 2021,
          "cited_paper_year": 2012
        },
        {
          "dataset_name": "MUC3",
          "dataset_description": "Used as a basis for the REE task, simplifying the original formulation for event extraction, but details on specific usage in this research are not provided.",
          "citing_paper_id": "231728756",
          "cited_paper_id": 14365335,
          "context_text": "We base the REE task on the original MUC3 formulation (Sundheim, 1991), but simplify it as done in prior research (Huang and Riloff, 2012; Du and Cardie, 2020).",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'MUC3' which is a specific dataset used for event extraction tasks. However, it does not provide details on how the dataset is used in the current research.",
          "citing_paper_doi": "10.18653/v1/2021.eacl-main.52",
          "cited_paper_doi": "10.3115/1071958.1071960",
          "citing_paper_url": "https://www.semanticscholar.org/paper/eb54c33b170782eb3c16f206a263abfc551b9c51",
          "cited_paper_url": "https://www.semanticscholar.org/paper/987f7071b08e8cf82132fc268c28baecc50500c4",
          "citing_paper_year": 2021,
          "cited_paper_year": 1991
        }
      ]
    },
    {
      "cited_paper_id": "119308902",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "ChiFinAnn"
      ],
      "dataset_details": [
        {
          "dataset_name": "ChiFinAnn",
          "dataset_description": "Utilized for Chinese financial event extraction, emphasizing document-level event arguments and relations in financial documents. | Used for Chinese financial event extraction, focusing on document-level annotations to improve event detection accuracy. | Used for Chinese financial event extraction, focusing on document-level annotations and evaluation of event detection models. | Applied for financial event extraction, emphasizing document-level context to enhance the identification of complex events.",
          "citing_paper_id": "249431954",
          "cited_paper_id": 119308902,
          "context_text": "In our experiments we adopt two public Chinese datasets, i.e. ChiFinAnn (Zheng et al., 2019) and DuEE-fin (Li, 2021).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, ChiFinAnn and DuEE-fin, which are used in experiments for Chinese financial event extraction.",
          "citing_paper_doi": "10.48550/arXiv.2206.03377",
          "cited_paper_doi": "10.18653/v1/D19-1032",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c9e0f9ac2c7ad1518a100faca0c2da9577b915fd",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9e2fd661a172749a739fc146301d3636e4a9c4dc",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "ChiFinAnn",
          "dataset_description": "Used to evaluate document-level event extraction, focusing on a diverse set of event types and challenging negative samples without event records. | Used for offline evaluations, focusing on document-level event extraction in financial announcements, employing supervised learning methods and cross-validation. | Used to analyze the distribution of event types in financial documents, providing insights into the frequency and variety of events in the financial domain. | Used for an online test, focusing on real-time document-level event extraction in financial documents, employing unsupervised or semi-supervised learning methods. | Used to train models for document-level event extraction, focusing on the distribution of records across sentences to enhance event detection accuracy. | Used to study document-level event extraction in the financial domain, focusing on a corpus of 11,900 documents to analyze event occurrences and their contexts. | Utilized for Chinese financial event extraction, emphasizing document-level event arguments and relations in financial documents. | Used to train models for document-level event extraction, focusing on the distribution of records across sentences to understand event scattering. | Used to compare model performance with baselines on financial event extraction, focusing on document-level event detection and classification. | Used for Chinese financial event extraction, focusing on document-level annotations and evaluation of event detection models.",
          "citing_paper_id": "249431954",
          "cited_paper_id": null,
          "context_text": "In our experiments we adopt two public Chinese datasets, i.e. ChiFinAnn (Zheng et al., 2019) and DuEE-fin (Li, 2021).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, ChiFinAnn and DuEE-fin, which are used in experiments for Chinese financial event extraction.",
          "citing_paper_doi": "10.48550/arXiv.2206.03377",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/c9e0f9ac2c7ad1518a100faca0c2da9577b915fd",
          "cited_paper_url": null,
          "citing_paper_year": 2022,
          "cited_paper_year": null
        }
      ]
    },
    {
      "cited_paper_id": "9946972",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "DocEE"
      ],
      "dataset_details": [
        {
          "dataset_name": "DocEE",
          "dataset_description": "Used to evaluate a framework for document-level event Extraction, focusing on document-level event annotations (averagely 16 events per document). | Used to compare annotation practices in document-level event extraction, focusing on datasets that annotate events at the document level, with an average of 3 events per document. | Used to compare annotation practices in document-level event extraction, focusing on datasets that annotate all events in a document, with an average of 16 events per document. | Used for comparison, annotating up to 3 events per document, highlighting the comprehensive nature of WIKI EVENTS.",
          "citing_paper_id": "264452034",
          "cited_paper_id": 9946972,
          "context_text": "We evaluate our framework on W IKI E VENTS (Li et al., 2021) as it annotates all the events in a document (averagely 16 events per document), while existing document-level datasets such as DocEE (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) only annotate at most 3 events per document.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used for evaluating a framework for document-level event extraction. WIKI EVENTS is highlighted for its comprehensive annotation of events, while other datasets are mentioned for comparison.",
          "citing_paper_doi": "10.48550/arXiv.2310.16358",
          "cited_paper_doi": "10.3115/1072064.1072066",
          "citing_paper_url": "https://www.semanticscholar.org/paper/795716ffc0e22a013bf196cb7fd65dceb95b286c",
          "cited_paper_url": "https://www.semanticscholar.org/paper/310d432ce7de84de2a54eedde18ee0423a232253",
          "citing_paper_year": 2023,
          "cited_paper_year": 1992
        },
        {
          "dataset_name": "DocEE",
          "dataset_description": "Used to evaluate the performance of HD-LoA prompting in a cross-domain setting, specifically comparing it against supervised methods and extensively trained models.",
          "citing_paper_id": "265149752",
          "cited_paper_id": 250264890,
          "context_text": "Neverthe-less, HD-LoA prompting demonstrates competitive performance against supervised methods and even outperform these extensively trained models on the DocEE dataset in the cross-domain setting.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the 'DocEE dataset' which is a specific dataset used for document-level event extraction. The dataset is used to evaluate the performance of HD-LoA prompting in a cross-domain setting.",
          "citing_paper_doi": "10.18653/v1/2024.acl-long.647",
          "cited_paper_doi": "10.48550/arXiv.2207.00747",
          "citing_paper_url": "https://www.semanticscholar.org/paper/6fb36c2d53ce4554b71473984a27fb961ffaafbf",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b17cc18e4130505b939f7d527082eb6be2a7fd5b",
          "citing_paper_year": 2023,
          "cited_paper_year": 2022
        }
      ]
    },
    {
      "cited_paper_id": "2797612",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "PubMed"
      ],
      "dataset_details": [
        {
          "dataset_name": "PubMed",
          "dataset_description": "Used to evaluate document-level relation extraction models, focusing on complex relations across multiple sentences in scientific documents. | Used to evaluate document-level relation extraction models, specifically focusing on multi-sentence relations and complex event structures. | Used as a source of biomedical documents for relation extraction, focusing on cross-sentence relations and entity interactions.",
          "citing_paper_id": "252873525",
          "cited_paper_id": 2797612,
          "context_text": "Beyond SCIREX, PubMed (Quirk and Poon, 2017; Peng et al., 2017) and DocRED (Yao et al.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'PubMed' and 'DocRED', both of which are datasets. However, 'PubMed' is a database, and 'DocRED' is a dataset specifically used for document-level relation extraction, making it highly relevant to the topic.",
          "citing_paper_doi": "10.48550/arXiv.2210.06600",
          "cited_paper_doi": "10.1162/tacl_a_00049",
          "citing_paper_url": "https://www.semanticscholar.org/paper/67e82404e2c4d57d018fa64a4974b459a7fe7d84",
          "cited_paper_url": "https://www.semanticscholar.org/paper/54b8aadb7c2576665ce26caf59464b6449ac9ccf",
          "citing_paper_year": 2022,
          "cited_paper_year": 2017
        },
        {
          "dataset_name": "PubMed",
          "dataset_description": "Used to evaluate document-level relation extraction models, specifically focusing on multi-sentence relations and complex event structures. | Used as a source of biomedical documents for relation extraction, focusing on cross-sentence relations and entity interactions.",
          "citing_paper_id": "252873525",
          "cited_paper_id": 15359942,
          "context_text": "Beyond SCIREX, PubMed (Quirk and Poon, 2017; Peng et al., 2017) and DocRED (Yao et al.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'PubMed' and 'DocRED', both of which are datasets. However, 'PubMed' is a database, and 'DocRED' is a dataset specifically used for document-level relation extraction, making it highly relevant to the topic.",
          "citing_paper_doi": "10.48550/arXiv.2210.06600",
          "cited_paper_doi": "10.18653/V1/E17-1110",
          "citing_paper_url": "https://www.semanticscholar.org/paper/67e82404e2c4d57d018fa64a4974b459a7fe7d84",
          "cited_paper_url": "https://www.semanticscholar.org/paper/0bd50cb6e58c09923ecab00ac252dc7e60eb5cc8",
          "citing_paper_year": 2022,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "207853145",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "Roles Across Multiple Sentences (RAMS)"
      ],
      "dataset_details": [
        {
          "dataset_name": "Roles Across Multiple Sentences (RAMS)",
          "dataset_description": "Used to annotate multi-sentence event-argument structures, focusing on linking arguments across sentences in the largest corpus of its kind. | Used to annotate event-argument structures across multiple sentences, enhancing document-level understanding of events and their participants.",
          "citing_paper_id": "269362270",
          "cited_paper_id": 207853145,
          "context_text": "Roles Across Multiple Sentences (RAMS) (Ebner et al., 2020) is a dataset annotating event-argument structures.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context directly mentions 'Roles Across Multiple Sentences (RAMS)' as a dataset, which fits the criteria for a specific, verifiable dataset.",
          "citing_paper_doi": "10.48550/arXiv.2404.16413",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/6a5abb17944918569281fb2bf1bc2ec0a64f45ed",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2024,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "Roles Across Multiple Sentences (RAMS)",
          "dataset_description": "Used to annotate and link arguments across multiple sentences, supporting the development of models for document-level event extraction.",
          "citing_paper_id": "236460259",
          "cited_paper_id": 207853145,
          "context_text": "Recently, Ebner et al. (2020) published the Roles Across Multiple Sentences (RAMS) dataset, which contains annotation for the task of multi-sentence argument linking.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for multi-sentence argument linking.",
          "citing_paper_doi": "10.18653/v1/2021.acl-long.492",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c952b73fd8ac6a7d4ad00d78f6b3b8d1caed6a8f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "253107167",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "Re-DocRED"
      ],
      "dataset_details": [
        {
          "dataset_name": "Re-DocRED",
          "dataset_description": "Used to enhance document-level relation extraction by supplementing missing relations in the original DocRED dataset, improving the quality and coverage of relational data. | Used for document-level relation extraction, applying adaptive focal loss and knowledge distillation to improve model performance on complex document structures. | Used for document-level relation extraction experiments under a fully supervised setting, addressing false negatives in relation extraction.",
          "citing_paper_id": "259261857",
          "cited_paper_id": 247594480,
          "context_text": "We conduct experiments on Re-DocRED (Tan et al. 2022b) under a fully supervised setting.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Re-DocRED' as a dataset used for experiments in document-level relation extraction. The cited paper titles help confirm that Re-DocRED is indeed a dataset.",
          "citing_paper_doi": "10.48550/arXiv.2306.14806",
          "cited_paper_doi": "10.48550/arXiv.2203.10900",
          "citing_paper_url": "https://www.semanticscholar.org/paper/9adb93ae05d08d3e5ec275d9881ea7d496dd1c8a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1ce8ea725add95062e82222ae2f273f570d185fb",
          "citing_paper_year": 2023,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "Re-DocRED",
          "dataset_description": "Used to conduct experiments in a fully supervised setting for relation extraction, addressing false negatives in document-level relation extraction. | Used to address false negatives in relation extraction, providing a high-quality revised version of the original dataset with improved labeling. | Used to enhance document-level relation extraction by supplementing missing relations in the original DocRED dataset, improving the quality and coverage of relational data. | Used for document-level relation extraction experiments under a fully supervised setting, addressing false negatives in relation extraction. | Used to address the false negative problem in relation extraction, enhancing the quality of document-level annotations for training and evaluation.",
          "citing_paper_id": "259261857",
          "cited_paper_id": 253107167,
          "context_text": "We conduct experiments on Re-DocRED (Tan et al. 2022b) under a fully supervised setting.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Re-DocRED' as a dataset used for experiments in document-level relation extraction. The cited paper titles help confirm that Re-DocRED is indeed a dataset.",
          "citing_paper_doi": "10.48550/arXiv.2306.14806",
          "cited_paper_doi": "10.18653/v1/2022.emnlp-main.580",
          "citing_paper_url": "https://www.semanticscholar.org/paper/9adb93ae05d08d3e5ec275d9881ea7d496dd1c8a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c86754c01fc64a8e8b445f530fe95c1dbab4eb03",
          "citing_paper_year": 2023,
          "cited_paper_year": 2022
        }
      ]
    },
    {
      "cited_paper_id": "263873742",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "GENIA11"
      ],
      "dataset_details": [
        {
          "dataset_name": "GENIA11",
          "dataset_description": "Used to evaluate the precision of machine reading components in biomedical event extraction, comparing TEES and BEEDS systems.",
          "citing_paper_id": "248780216",
          "cited_paper_id": 18361255,
          "context_text": "This is in line with our previous results from (Wang et al., 2020) where the machine reading component of EVEX, TEES (Björne and Salakoski, 2011), achieves a slightly worse precision than the machine reading component in BEEDS on the GENIA11 dataset (Kim et al., 2011, 57.65% to 59.33",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the GENIA11 dataset, which is a specific biomedical event extraction dataset used for evaluating machine reading components.",
          "citing_paper_doi": "10.18653/v1/2022.bionlp-1.28",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/f2e5d260503074638e6e9849bdd1945b3dac7aad",
          "cited_paper_url": "https://www.semanticscholar.org/paper/97c9b4ef33af9d084996c7a93c8dc520d56fc925",
          "citing_paper_year": 2022,
          "cited_paper_year": 2011
        },
        {
          "dataset_name": "GENIA11",
          "dataset_description": "Used for gold annotations in a supervised setting, focusing on event extraction in biomedical texts. The dataset is part of the BioNLP Shared Task 2011. | Used to provide gold standard text annotations for biomedical event structures, enhancing the distantly supervised training set with high-quality annotations. | Used to evaluate the precision of machine reading components in biomedical event extraction, comparing TEES and BEEDS systems. | Used for gold annotations in a supervised setting, focusing on event extraction in biomedical texts. The dataset is part of the BioNLP Shared Task 2013.",
          "citing_paper_id": "248780216",
          "cited_paper_id": 263873742,
          "context_text": "This is in line with our previous results from (Wang et al., 2020) where the machine reading component of EVEX, TEES (Björne and Salakoski, 2011), achieves a slightly worse precision than the machine reading component in BEEDS on the GENIA11 dataset (Kim et al., 2011, 57.65% to 59.33",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the GENIA11 dataset, which is a specific biomedical event extraction dataset used for evaluating machine reading components.",
          "citing_paper_doi": "10.18653/v1/2022.bionlp-1.28",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/f2e5d260503074638e6e9849bdd1945b3dac7aad",
          "cited_paper_url": "https://www.semanticscholar.org/paper/00248a60f905f49c451e106ee6647823e9359e6c",
          "citing_paper_year": 2022,
          "cited_paper_year": 2011
        }
      ]
    },
    {
      "cited_paper_id": "59291975",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "FewFC"
      ],
      "dataset_details": [
        {
          "dataset_name": "FewFC",
          "dataset_description": "Used to evaluate nested event extraction methods, focusing on biomedical events in the Genia corpus. | Used to evaluate event extraction methods on an overlapped dataset, focusing on few-shot learning scenarios.",
          "citing_paper_id": "252089843",
          "cited_paper_id": 14339673,
          "context_text": "Table 2 reports the result of all methods on the overlapped EE dataset, FewFC, while Table 3 reports the results of the nested EE datasets, Genia11 and Genia13.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions specific datasets used for evaluating event extraction methods, which are relevant to the document-level event extraction topic.",
          "citing_paper_doi": "10.48550/arXiv.2209.02693",
          "cited_paper_doi": "10.3115/v1/P15-1017",
          "citing_paper_url": "https://www.semanticscholar.org/paper/d36c0b5f67bce9afccc8bdd8b68fafa8097d9dee",
          "cited_paper_url": "https://www.semanticscholar.org/paper/98a6b07d51261df9418981c1dddf09ad4a9c48e4",
          "citing_paper_year": 2022,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "FewFC",
          "dataset_description": "Used to evaluate the performance of BioBERT on document-level event extraction tasks in the biomedical domain. | Used to evaluate few-shot learning performance of the Chinese Bert-base model, focusing on document-level event extraction tasks. | Used to train and evaluate models for few-shot learning tasks in Chinese, focusing on the performance of the Chinese Bert-base model.",
          "citing_paper_id": "252089843",
          "cited_paper_id": 59291975,
          "context_text": "We employ the Chinese Bert-base model for FewFC and BioBERT (Lee et al., 2020) for Ge-nia11 and Genia13.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions models (Chinese Bert-base, BioBERT) and datasets (FewFC, Ge-nia11, Genia13). However, only the datasets are relevant for extraction.",
          "citing_paper_doi": "10.48550/arXiv.2209.02693",
          "cited_paper_doi": "10.1093/bioinformatics/btz682",
          "citing_paper_url": "https://www.semanticscholar.org/paper/d36c0b5f67bce9afccc8bdd8b68fafa8097d9dee",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1e43c7084bdcb6b3102afaf301cce10faead2702",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "13374927",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "Penn Discourse Treebank (PDTB)"
      ],
      "dataset_details": [
        {
          "dataset_name": "Penn Discourse Treebank (PDTB)",
          "dataset_description": "Used to annotate semantic relations between clauses, including causal relations, both explicit and implicit, enhancing discourse analysis in natural language processing.",
          "citing_paper_id": "248377560",
          "cited_paper_id": 13374927,
          "context_text": "Penn Discourse Treebank (PDTB) (Prasad et al., 2008; Webber et al., 2019; Prasad et al., 2006) is a corpus that annotates semantic relations (including causal relations) between clauses, expressed either explicitly or implicitly.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the Penn Discourse Treebank (PDTB) as a corpus that annotates semantic relations between clauses. It is clearly identified as a reusable resource.",
          "citing_paper_doi": "10.48550/arXiv.2204.11714",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/140e29941a4f38ab00ad9f671473f3e036602b39",
          "cited_paper_url": "https://www.semanticscholar.org/paper/a6c26e574d74346a2b5ade5412aee2138075463e",
          "citing_paper_year": 2022,
          "cited_paper_year": 2008
        },
        {
          "dataset_name": "Penn Discourse Treebank (PDTB)",
          "dataset_description": "Used to annotate semantic relations between clauses, including causal relations, both explicit and implicit, enhancing discourse analysis in natural language processing. | Used to define the 'contingency' label for causality, where one argument provides the reason, explanation, or justification for the situation described by the other. | Used for causal sentence classification, evaluating the effectiveness of baseline models in detecting causal relationships in English news articles.",
          "citing_paper_id": "248377560",
          "cited_paper_id": 263864984,
          "context_text": "Penn Discourse Treebank (PDTB) (Prasad et al., 2008; Webber et al., 2019; Prasad et al., 2006) is a corpus that annotates semantic relations (including causal relations) between clauses, expressed either explicitly or implicitly.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the Penn Discourse Treebank (PDTB) as a corpus that annotates semantic relations between clauses. It is clearly identified as a reusable resource.",
          "citing_paper_doi": "10.48550/arXiv.2204.11714",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/140e29941a4f38ab00ad9f671473f3e036602b39",
          "cited_paper_url": "https://www.semanticscholar.org/paper/531b5f071c0c7e75108684d9896dba49f5917a7a",
          "citing_paper_year": 2022,
          "cited_paper_year": 2007
        }
      ]
    },
    {
      "cited_paper_id": "261226458",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Beyond NomBank"
      ],
      "dataset_details": [
        {
          "dataset_name": "Beyond NomBank",
          "dataset_description": "Applied to extend nominal semantic role labeling beyond the NomBank inventory, enhancing coverage of implicit roles. | Applied to extend semantic role labeling beyond traditional verb-based predicates, including nominal and adjectival predicates. | Utilized for verb valency annotation, specifically addressing overtness and valency in verb argument structures.",
          "citing_paper_id": "233219850",
          "cited_paper_id": 261226458,
          "context_text": "There have been a few datasets published speciﬁcally for implicit semantic role labeling, such as the SemEval 2010 Task 10 (Ruppenhofer et al., 2010), the Beyond NomBank dataset (Gerber and Chai, 2010) and ON5V (Moor et al., 2013).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions three specific datasets for implicit semantic role labeling, which are relevant to document-level event extraction.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.69",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/2a15f541a8216782a7579f01f56762448e48b582",
          "cited_paper_url": null,
          "citing_paper_year": 2021,
          "cited_paper_year": null
        }
      ]
    },
    {
      "cited_paper_id": "221836081",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "GDA"
      ],
      "dataset_details": [
        {
          "dataset_name": "GDA",
          "dataset_description": "Used to evaluate graph-based models on document-level relation extraction, focusing on the performance of various graph convolutional network approaches. | Used to evaluate document-level relation extraction models, focusing on capturing global context and local interactions between entities. | Used to compare model performance on gene-disease association extraction, focusing on document-level relations and evaluating against baseline and state-of-the-art models. | Used to compare model performance on chemical-disease relation extraction, focusing on document-level relations and evaluating against baseline and state-of-the-art models.",
          "citing_paper_id": "248300064",
          "cited_paper_id": 221836081,
          "context_text": "On the two biomedical datasets, CDR and GDA, we compared our model with a large number of baseline models and recent state-of-the-art models including BRAN [Verga et al., 2018], EoG [Christopoulou et al., 2019], LSR [Nan et al., 2020], DHG [Zhang et al., 2020], GLRE [Wang et al., 2020], SciBERT [Beltagy et al., 2019], ATLOP [Zhou et al., 2021b], and DocuNet [Zhang et al., 2021a].",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'CDR' and 'GDA' as datasets used for comparing models. These are multi-word proper nouns and appear to be specific datasets.",
          "citing_paper_doi": "10.48550/arXiv.2204.09851",
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.303",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33b9945129171b1cbcded4a5f4ba122dbb6c0528",
          "cited_paper_url": "https://www.semanticscholar.org/paper/cb00cf22920d317e1e8b886dd19fd005a1b65111",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "6446644",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "BioNLP Shared Task 2011 GE data set"
      ],
      "dataset_details": [
        {
          "dataset_name": "BioNLP Shared Task 2011 GE data set",
          "dataset_description": "Used to assess EventMine's effectiveness in identifying interaction detection events, showing high F scores. | Used to test EventMine's capabilities in extracting protein-protein interactions, achieving competitive results. | Used to evaluate EventMine's performance on gene expression events, demonstrating superior F scores compared to other systems. | Used to train a model for event extraction, specifically incorporating predictions from this dataset into a stacking approach to enhance the base model's performance.",
          "citing_paper_id": "13981987",
          "cited_paper_id": 6446644,
          "context_text": "We performed event extraction experiments in two settings: training only on the newly introduced data (base model) and training using stacking, incorporating predictions from a model trained on the BioNLP Shared Task 2011 GE data set (Kim et al., 2011b) as the source corpus.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'BioNLP Shared Task 2011 GE data set' which is a specific dataset used for training a model in the research.",
          "citing_paper_doi": "10.1093/bioinformatics/bts407",
          "cited_paper_doi": "10.1111/j.1467-8640.2011.00398.x",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a8dff94485a16320e1ef980420bc74b2882babee",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b6410c634a5a3ccd1935b9b2e3703412a2a54e19",
          "citing_paper_year": 2012,
          "cited_paper_year": 2011
        }
      ]
    },
    {
      "cited_paper_id": "13804679",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "SemEval-2010 Task 10"
      ],
      "dataset_details": [
        {
          "dataset_name": "SemEval-2010 Task 10",
          "dataset_description": "Used to extend NomBank for implicit arguments, focusing on nominal predicates in event extraction. | Used to study non-local arguments in semantic role labeling, focusing on implicit arguments in stories. The dataset supports the investigation of how context influences argument identification. | Used to compare event extraction performance, focusing on implicit arguments for nominal predicates. | Used to study nominal predicates and multi-sentence arguments, focusing on event triggers and their properties, similar to those in the RAMS dataset. | Expanded and used to explore implicit arguments for nominal predicates, enhancing the original Nom-Bank with additional annotations for non-local arguments.",
          "citing_paper_id": "207853145",
          "cited_paper_id": 13804679,
          "context_text": "Much of the effort on non-local arguments, sometimes called implicit SRL, has focused on two datasets, one based on stories that were produced for SemEval-2010 Task 10 (Ruppenhofer et al., 2010) and the other an expansion of Nom-Bank (Meyers et al., 2004) compiled by Gerber and Chai (2010, 2012).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets used for non-local arguments or implicit SRL: one from SemEval-2010 Task 10 and an expansion of Nom-Bank. These are clearly identified and used in the research.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.718",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "cited_paper_url": "https://www.semanticscholar.org/paper/d8259bcbe9cb0cf5bad6ea25645f4407fc544a1c",
          "citing_paper_year": 2019,
          "cited_paper_year": 2010
        }
      ]
    },
    {
      "cited_paper_id": "4803246",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "EventKG"
      ],
      "dataset_details": [
        {
          "dataset_name": "EventKG",
          "dataset_description": "Used to construct a multilingual event-centric temporal knowledge graph, focusing on integrating and representing events across multiple languages and sources.",
          "citing_paper_id": "250390839",
          "cited_paper_id": 4803246,
          "context_text": "tive works are EventKG (Gottschalk and Demidova, 2018), Event Wiki (Ge et al.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'EventKG' and 'Event Wiki', but only 'EventKG' is a specific, verifiable dataset as indicated by the cited paper title.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-main.291",
          "cited_paper_doi": "10.1007/978-3-319-93417-4_18",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c8e30e459ad7769528ac7eae051134d245ca16ee",
          "cited_paper_url": "https://www.semanticscholar.org/paper/78c8f2a8a5d6a9be351875908f765424534c64c7",
          "citing_paper_year": 2022,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "204838007",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Gigaword corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "Gigaword corpus",
          "dataset_description": "Referenced as a similar domain dataset for event extraction, used to contextualize the training data's relevance. | Used to fine-tune a pre-trained sequence-to-sequence model T5 for infilling tasks, focusing on domains similar to event extraction.",
          "citing_paper_id": "255522592",
          "cited_paper_id": 204838007,
          "context_text": "To train our inﬁlling model, we ﬁne-tune a pre-trained sequence-to-sequence model T5 (Raffel et al., 2020) on the Gigaword corpus (Graff et al., 2003), which is from similar domains as the event extraction dataset ACE2005 adopted by our work.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the Gigaword corpus and the ACE2005 dataset. Gigaword is used for fine-tuning a pre-trained model, while ACE2005 is referenced as a similar domain dataset for event extraction.",
          "citing_paper_doi": "10.48550/arXiv.2301.02427",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/a955a5a6d2fd7740375b6f22d2ac9719ce02d17f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6c4b76232bb72897685d19b3d264c6ee3005bc2b",
          "citing_paper_year": 2023,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "8729417",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "SemEval-2010 Task 8"
      ],
      "dataset_details": [
        {
          "dataset_name": "SemEval-2010 Task 8",
          "dataset_description": "Used as a basis for proposing new tasks in event extraction, focusing on relation classification using recurrent neural networks.",
          "citing_paper_id": "246241684",
          "cited_paper_id": 8729417,
          "context_text": "Based on SemEval-2010 Task 8, some new tasks about extraction were proposed [8, 13].",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions SemEval-2010 Task 8, which is a known dataset for relation classification in the context of event extraction. However, the citation does not provide specific details on how this dataset is used in the current research.",
          "citing_paper_doi": "10.1145/3502223.3502229",
          "cited_paper_doi": "10.1109/BIGCOMP.2016.7425968",
          "citing_paper_url": "https://www.semanticscholar.org/paper/13a32988ccdda02bca2e2ec11902b0834baaeadb",
          "cited_paper_url": "https://www.semanticscholar.org/paper/7ae41f61be85ea112a2c0d16c3f10dae4e7e4c0e",
          "citing_paper_year": 2021,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "119308902",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "FEED"
      ],
      "dataset_details": [
        {
          "dataset_name": "FEED",
          "dataset_description": "Utilized to provide event knowledge for DS-based event labeling, enhancing the accuracy of event extraction in financial documents. | Used to evaluate the performance of the Doc2EDAG model on Chinese financial event extraction, focusing on document-level event detection and the distinguishability between different models. | Used to construct datasets for document-level event labeling, focusing on Chinese financial documents over a decade (2008-2018).",
          "citing_paper_id": "246241684",
          "cited_paper_id": 119308902,
          "context_text": "Note that Doc2EDAG as a state-of-the-art model, performs much better than its counter-part on FEED, indicating the distinguishability between them.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'FEED' as a dataset used to evaluate the performance of the Doc2EDAG model. The dataset is relevant to document-level event extraction, particularly in the financial domain.",
          "citing_paper_doi": "10.1145/3502223.3502229",
          "cited_paper_doi": "10.18653/v1/D19-1032",
          "citing_paper_url": "https://www.semanticscholar.org/paper/13a32988ccdda02bca2e2ec11902b0834baaeadb",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9e2fd661a172749a739fc146301d3636e4a9c4dc",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "781199",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Darpa corpus from 2009"
      ],
      "dataset_details": [
        {
          "dataset_name": "Darpa corpus from 2009",
          "dataset_description": "Used to evaluate event extraction systems, specifically focusing on performance metrics like F-score. The dataset is noted for its historical significance but lacks current public availability. | Used to evaluate a system's performance in news event extraction, specifically measuring F-score to assess the system's accuracy and robustness.",
          "citing_paper_id": "3867049",
          "cited_paper_id": 781199,
          "context_text": "While the evaluations of the reviewed papers generally indicate sufficient quality to be usable for news event extraction, e.g., the system from [36] achieved F ’ =0.85 on the Darpa corpus from 2009, they lack comparability for two reasons: (1) There is no gold standard for journalistic 5W QA on…",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'Darpa corpus from 2009' as a dataset used for evaluating a system's performance in news event extraction. The dataset is specific and has a clear identifier.",
          "citing_paper_doi": "10.1007/978-3-319-78105-1_39",
          "cited_paper_doi": "10.21437/Interspeech.2009-692",
          "citing_paper_url": "https://www.semanticscholar.org/paper/8dae3db208475e0da5376213615cef23b288abe4",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2eb1a3475f068090ff74274a1440f61ed295f6ce",
          "citing_paper_year": 2018,
          "cited_paper_year": 2009
        }
      ]
    },
    {
      "cited_paper_id": "234742165",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Few-NERD"
      ],
      "dataset_details": [
        {
          "dataset_name": "Few-NERD",
          "dataset_description": "Used to train and evaluate few-shot named entity recognition models, focusing on cross-sentence information for improved entity detection.",
          "citing_paper_id": "252090194",
          "cited_paper_id": 234742165,
          "context_text": "The latest Few-NERD (Ding et al. 2021) named entity recognition dataset also includes information across sentences.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "Few-NERD is explicitly mentioned as a dataset and is relevant to the topic of document-level event extraction, as it includes information across sentences.",
          "citing_paper_doi": "10.48550/arXiv.2209.02203",
          "cited_paper_doi": "10.18653/v1/2021.acl-long.248",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1ed23d77d0b80e36ebe8833eb92c363d65356307",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e1cb1ff6965525380b41b9971aed71edbb393703",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "226262197",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "ACE05"
      ],
      "dataset_details": [
        {
          "dataset_name": "ACE05",
          "dataset_description": "Used for training the temporal ordering component, focusing on identifying temporal relations between events. | Used for visual event and argument extraction, integrating multimodal information to improve event detection in images and text. | Used for cross-media event coreference, linking events across different media types to enhance multimedia event understanding. | Used for weakly supervised event extraction, focusing on identifying events and their arguments in text. | Used for document-level argument extraction, focusing on identifying arguments for events in text. | Used for training mention extraction and weakly supervised event extraction components, focusing on entity and event recognition in text. | Used for visual event and argument extraction, focusing on identifying events and their arguments in multimedia content. | Used for schema matching and prediction, enhancing the accuracy of event schema induction in complex documents. | Used for training mention extraction components, focusing on entity and relation extraction in text. | Used for cross-media event coreference, focusing on linking events across different media types. | Used for schema matching and prediction, focusing on aligning event schemas across different sources.",
          "citing_paper_id": "249010869",
          "cited_paper_id": 226262197,
          "context_text": "We train our mention extraction component on ACE05 (Walker et al., 2006) and ERE (Song et al., 2015); document-level argument extraction on ACE05 and RAMS (Ebner et al., 2020) DCEP (Dias, 2016) and SemEval10 (Recasens et al., 2010); temporal ordering component on MA-TRES (Ning et al., 2018); weakly supervised event extraction on ACE05; schema matching and prediction on LDC2022E03; visual event and argument extraction on M2E2 (Li et al., 2020a) and cross-media event coreference on Video M2E2 (Chen et al., 2021a).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions multiple datasets used for various components of event extraction systems, including mention extraction, argument extraction, temporal ordering, weakly supervised event extraction, schema matching, and visual event extraction.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-demo.7",
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.50",
          "citing_paper_url": "https://www.semanticscholar.org/paper/396833983f6d7d77957e12c3839e5da05feb053a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/89588d38424c85dbe7bd705302b5252e6b79ab78",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "8387007",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "EventStoryLine Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "EventStoryLine Corpus",
          "dataset_description": "Annotated for event causality identification in 320 short stories, focusing on temporal and causal relations. | Used as a basis for annotating the EventStoryLine Corpus, providing temporal and causal relation annotations.",
          "citing_paper_id": "235313618",
          "cited_paper_id": 8387007,
          "context_text": "Caselli and Vossen (2017) annotated the EventStoryLine Corpus for event causality identiﬁcation in 320 short stories based on the temporal and causal relations annotated dataset (Mostafazadeh et al., 2016).",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'EventStoryLine Corpus' and 'temporal and causal relations annotated dataset'. Both are specific datasets used for annotation and research.",
          "citing_paper_doi": "10.18653/v1/2021.findings-acl.190",
          "cited_paper_doi": "10.18653/v1/W16-1007",
          "citing_paper_url": "https://www.semanticscholar.org/paper/47ea802a1fed0f735a9a61a7c9b63062f02a5f5d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/04041a04ede58a464c843f95608e813a7686f6eb",
          "citing_paper_year": 2021,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "17716605",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "BECauSE 2.0"
      ],
      "dataset_details": [
        {
          "dataset_name": "BECauSE 2.0",
          "dataset_description": "Used to annotate causal and overlapping relations, enhancing the original BE-CauSE corpus with additional annotations and relations.",
          "citing_paper_id": "235313618",
          "cited_paper_id": 17716605,
          "context_text": "Dunietz et al. (2017) presented BECauSE 2.0, a new version of the BE-CauSE (Dunietz et al., 2015) of causal relation and other seven relations.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions BECauSE 2.0, which is a specific dataset used for annotating causality and overlapping relations. The cited paper title confirms it is a corpus.",
          "citing_paper_doi": "10.18653/v1/2021.findings-acl.190",
          "cited_paper_doi": "10.18653/v1/W17-0812",
          "citing_paper_url": "https://www.semanticscholar.org/paper/47ea802a1fed0f735a9a61a7c9b63062f02a5f5d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/31f9e4a26870b48c5c254fd42c812cd2742d21f5",
          "citing_paper_year": 2021,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "5261517",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "event corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "event corpus",
          "dataset_description": "Used for training and development of a model to mine biomedical events from literature, focusing on event extraction and annotation.",
          "citing_paper_id": "9631585",
          "cited_paper_id": 5261517,
          "context_text": "The data for the training and development sets were derived from the publicly available event corpus (Kim et al., 2008), and the data for the test set from an unpublished portion of the corpus.",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a 'publicly available event corpus' which is likely a dataset used for training and development. The test set comes from an unpublished portion of the same corpus.",
          "citing_paper_doi": "10.3115/1572340.1572342",
          "cited_paper_doi": "10.1186/1471-2105-9-10",
          "citing_paper_url": "https://www.semanticscholar.org/paper/d461edc4de7d4c1398f76c08b54310cd017b963d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f1a989f56056c9d6893d6cc3cd36e773845f1b3f",
          "citing_paper_year": 2009,
          "cited_paper_year": 2008
        }
      ]
    },
    {
      "cited_paper_id": "7294125",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "TimeBank-Dense"
      ],
      "dataset_details": [
        {
          "dataset_name": "TimeBank-Dense",
          "dataset_description": "This dataset 'TDD-Man' was mentioned in the citation context but no detailed description was generated. | Used to augment TDD-Man with TLINK annotations for event pairs more than one sentence apart, enhancing document-level event extraction.",
          "citing_paper_id": "237100961",
          "cited_paper_id": 7294125,
          "context_text": "It includes two subsets: 1) TDD-Man, which augments TimeBank-Dense (TBDense) [Cassidy et al. , 2014] by manually annotating TLINKs between event pairs that are more than one sentence apart.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'TimeBank-Dense (TBDense)' as a dataset used for augmenting TDD-Man with TLINK annotations between event pairs across multiple sentences.",
          "citing_paper_doi": "10.24963/ijcai.2021/533",
          "cited_paper_doi": "10.3115/v1/P14-2082",
          "citing_paper_url": "https://www.semanticscholar.org/paper/32c1767b956dec644f8bfc1f009fc5a1af47f0cc",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1f78e47c67c0ed3e5e3293337fa8c240dafa8b52",
          "citing_paper_year": 2021,
          "cited_paper_year": 2014
        }
      ]
    },
    {
      "cited_paper_id": "313092",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Penn Discourse Treebank"
      ],
      "dataset_details": [
        {
          "dataset_name": "Penn Discourse Treebank",
          "dataset_description": "Used to annotate explicit and implicit causal relations between discourse units, providing a structured resource for studying discourse structure and causality in text. | Used to annotate and analyze discourse relations in text, providing a structured representation of rhetorical structure for natural language processing tasks.",
          "citing_paper_id": "38234032",
          "cited_paper_id": 313092,
          "context_text": "One of the most prominent work is represented by the Penn Discourse Treebank (PDTB) (Miltsakaki et al., 2004), where explicit and implicit causal relations are annotated between discourse units.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            "reusable resource",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "dataset",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the Penn Discourse Treebank (PDTB) as a prominent work where causal relations are annotated. It is a specific, verifiable dataset.",
          "citing_paper_doi": "10.18653/v1/W17-2711",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/210998cf25778b5e07018a34c441e671e034fb1e",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b349b855f47a3000062e1b08ec48651b28ce10f4",
          "citing_paper_year": 2017,
          "cited_paper_year": 2004
        }
      ]
    },
    {
      "cited_paper_id": "1801348",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Event Coreference Bank+"
      ],
      "dataset_details": [
        {
          "dataset_name": "Event Coreference Bank+",
          "dataset_description": "Used to annotate causal relations between events, focusing on temporal and causal dependencies in text. | Used for event coreference resolution, focusing on linking events that refer to the same underlying situation across a document. | Used to study causal relations in biomedical texts, focusing on identifying cause-effect relationships in scientific literature.",
          "citing_paper_id": "38234032",
          "cited_paper_id": 1801348,
          "context_text": ", 2016)), event coreference (Event Coreference Bank+ (ECB+) (Cybulska and Vossen, 2014b)), and causal relations (Causal-TimeBank (Mirza and Tonelli, 2016), BECauSE (Dunietz et al.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions specific datasets used for event coreference and causal relations, which are relevant to document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/W17-2711",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/210998cf25778b5e07018a34c441e671e034fb1e",
          "cited_paper_url": "https://www.semanticscholar.org/paper/0fabeb29eee19ca80b6f424d8cd86ac52ac96eb0",
          "citing_paper_year": 2017,
          "cited_paper_year": 2014
        }
      ]
    },
    {
      "cited_paper_id": "12108307",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "RAMS development set"
      ],
      "dataset_details": [
        {
          "dataset_name": "RAMS development set",
          "dataset_description": "Used for hyper-parameter tuning during the fine-tuning process, specifically to optimize the batch size for event extraction.",
          "citing_paper_id": "252901047",
          "cited_paper_id": 12108307,
          "context_text": "In the fine-tuning state, we employ the RAMS development set for hyper-parameter tuning, and finally, the batch size is set to 20 (selected from [1, 5, 10, 20, 30, 40])",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the RAMS development set, which is a specific dataset used for hyper-parameter tuning in the fine-tuning process.",
          "citing_paper_doi": "10.1109/TASLP.2022.3210442",
          "cited_paper_doi": "10.18653/v1/P17-1038",
          "citing_paper_url": "https://www.semanticscholar.org/paper/46de1ace70891306ca2dcc06a974d1d23ba77c7f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/232537a9d3042a703a624b20fabd50d390a96ce6",
          "citing_paper_year": 2022,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "unknown",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "RED"
      ],
      "dataset_details": [
        {
          "dataset_name": "RED",
          "dataset_description": "Used for narrative event extraction, supporting document-level event annotation. | Used to evaluate document-level event extraction, focusing on richer event descriptions in natural language texts. | Used for causal relation extraction, enhancing document-level event annotation. | Used for temporal event extraction, evaluating document-level event annotation and temporal processing. | Used for event co-reference, improving document-level event annotation accuracy. | Used to evaluate causal relations, focusing on temporal and causal connections between events. | Used to evaluate narrative understanding, focusing on causal and temporal relations in short stories. | Used to evaluate event co-reference, identifying and linking events across documents. | Used to evaluate causal relations, specifically in the context of social media and news articles. | Used to collect and analyze everyday stories composed of 5 sentences, focusing on narrative structure and coherence in the context of document-level event extraction. | Used for causal relation extraction, supporting document-level event annotation. | Used for richer event description, enhancing document-level event annotation.",
          "citing_paper_id": "38234032",
          "cited_paper_id": null,
          "context_text": "…and Richer Event Description (RED) (O’Gorman et al., 2016)), event co-reference (Event Coreference Bank+ (ECB+) (Cy-bulska and Vossen, 2014b)), and causal relations (Causal-TimeBank (Mirza and Tonelli, 2016), BECauSE (Dunietz et al., 2015), ROCSto-ries (Mostafazadeh et al., 2016b) among others).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets that are relevant to document-level event extraction, including RED, ECB+, Causal-TimeBank, BECauSE, and ROCStories. These are specific datasets used for various aspects of event extraction.",
          "citing_paper_doi": "10.18653/v1/W17-2711",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/210998cf25778b5e07018a34c441e671e034fb1e",
          "cited_paper_url": null,
          "citing_paper_year": 2017,
          "cited_paper_year": null
        }
      ]
    },
    {
      "cited_paper_id": "92290275",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "CDG"
      ],
      "dataset_details": [
        {
          "dataset_name": "CDG",
          "dataset_description": "Used to evaluate relation extraction performance, specifically enhancing interpretability by improving the evidence retrieval F1 score. | Used to study binary interactions between disease and chemical concepts with 1,500 documents, focusing on extracting chemical-disease interactions from literature. | Used to study binary relationships between gene and disease with 30,192 documents, focusing on extracting gene-disease associations from literature. | Used to evaluate relation extraction performance, focusing on chemical-disease relations.",
          "citing_paper_id": "237635295",
          "cited_paper_id": 92290275,
          "context_text": "2016) and GDA (Wu et al. 2019) are two biomedical datasets where CDG studies the binary interactions between disease and chemical concepts with 1,500 documents and GDA studies the binary relationships between gene and disease with 30,192 documents.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, GDA and CDG, with clear document counts and domain-specific content. These are used for studying binary interactions in biomedical contexts.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-main.171",
          "cited_paper_doi": "10.1007/978-3-030-17083-7_17",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f6055cf63e4d24c75f8ff4c3c7e2fbd7a2695119",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6304c47b3eccf19aa066372c3e71e06b88d0e7a6",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "26201484",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "MEANTIME"
      ],
      "dataset_details": [
        {
          "dataset_name": "MEANTIME",
          "dataset_description": "Used to evaluate event coreference systems, focusing on cross-document event linking and coreference resolution in news articles. | Utilized for multilingual event and time annotation, supporting cross-lingual event extraction and temporal relation analysis. | Applied to study gun violence events, specifically extracting and analyzing event mentions and their contexts in news articles. | Used to study multilingual event and time annotations in news articles, focusing on document-level event extraction and temporal relations. | Used to study event coreference in a specific domain, focusing on cross-document event linking and coreference resolution in government and political texts. | Used for evaluating document-level event extraction models, focusing on cross-document coreference resolution and event linking. | Used to train and evaluate models for event coreference resolution, focusing on cross-document event linking and co-reference. | Applied to study gun violence events, focusing on fine-grained event annotation and context extraction in news articles. | Used to train and evaluate multilingual event and time annotation systems, providing a richly annotated corpus for event and time expressions in multiple languages. | Utilized for multilingual event and time annotation, enhancing cross-lingual event extraction and temporal relation analysis.",
          "citing_paper_id": "233210350",
          "cited_paper_id": 26201484,
          "context_text": "MEANTIME Minard et al. (2016) proposed a dataset that is similar in some respects to ECB+, with documents partitioned into a set of topics.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'MEANTIME' as a dataset, which is a specific, verifiable resource. The title confirms it is a corpus, making it a valid dataset.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.198",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/a814f3773b6482b7f5c8ba8c3edfedb726999574",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e8177476a3c62278d3b5dd3a99b9bb417c7d449a",
          "citing_paper_year": 2021,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "44063424",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "TAC KBP 2016"
      ],
      "dataset_details": [
        {
          "dataset_name": "TAC KBP 2016",
          "dataset_description": "Used to compare model performance with top systems from the competition, focusing on document-level event extraction and evaluation methodologies.",
          "citing_paper_id": "202770954",
          "cited_paper_id": 44063424,
          "context_text": "On TAC KBP 2016, we compare our models with the top systems (Dubbin et al., 2016; Hsi et al., 2016; Ferguson et al., 2016) of the competition as well as DMCNN and DMBERT.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions TAC KBP 2016, which is a specific dataset used in a competition. The context indicates that the dataset is used for comparing model performance.",
          "citing_paper_doi": "10.18653/v1/D19-1584",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/788bf8a74bc0d81215a58ab2ffdc46e12c189f43",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9f289ecc2a9e207dc71cea24f6802ad6b41c943e",
          "citing_paper_year": 2019,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "14365335",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "MUC1"
      ],
      "dataset_details": [
        {
          "dataset_name": "MUC1",
          "dataset_description": "Used to simplify the event-based template-filling task, focusing on message understanding and event extraction methodologies.",
          "citing_paper_id": "221246218",
          "cited_paper_id": 14365335,
          "context_text": "We base the event-based template-filling task on the original MUC1 formulation (Sundheim, 1991), but simplify it as done in prior research (Huang and Riloff, 2012; Du and Cardie, 2020).",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the MUC1 formulation, which is a specific dataset used for message understanding and event extraction tasks.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.3115/1071958.1071960",
          "citing_paper_url": "https://www.semanticscholar.org/paper/0fb0595be9400709a79040a1a7ef5346d331e28e",
          "cited_paper_url": "https://www.semanticscholar.org/paper/987f7071b08e8cf82132fc268c28baecc50500c4",
          "citing_paper_year": 2020,
          "cited_paper_year": 1991
        }
      ]
    },
    {
      "cited_paper_id": "5761781",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "WDW (Who Did What)"
      ],
      "dataset_details": [
        {
          "dataset_name": "WDW (Who Did What)",
          "dataset_description": "Used for person-centered cloze tests, focusing on identifying actions performed by individuals in news articles, enhancing event extraction capabilities.",
          "citing_paper_id": "3519188",
          "cited_paper_id": 5761781,
          "context_text": "A variety of large-scale corpora for machine reading comprehension have been developed in recent years, including the CNN/DailyMail [43], CBT (Children’s Book Test) [45], SQuAD (Stanford Question Answering Dataset) [98], and WDW (Who Did What) datasets [91].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions several corpora used for machine reading comprehension, which are relevant to document-level event extraction. Each is a specific, named dataset.",
          "citing_paper_doi": "10.1184/r1/21610728.v1",
          "cited_paper_doi": "10.18653/v1/D16-1241",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a66fba6c74576516de7db042b738c60d8654c332",
          "cited_paper_url": "https://www.semanticscholar.org/paper/a39ffa57ef8e538b3c6a6c2bbc0b641f7cdc60dc",
          "citing_paper_year": 2022,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "52118895",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "SCIERC"
      ],
      "dataset_details": [
        {
          "dataset_name": "SCIERC",
          "dataset_description": "Used to train and evaluate models on identifying entities, relations, and coreference in scientific abstracts, enhancing scientific knowledge graph construction. | Used for information extraction from scientific article abstracts, focusing on identifying entities, relations, and coreferences to construct scientific knowledge graphs. | Used for information extraction from abstracts of scientific articles, focusing on entity recognition, relation extraction, and coreference resolution to construct scientific knowledge graphs.",
          "citing_paper_id": "218470122",
          "cited_paper_id": 52118895,
          "context_text": ", information extraction from abstracts of scientific articles as in SCIERC (Luan et al., 2018)), or only extracting",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'SCIERC' which is a specific dataset used for information extraction from scientific articles. The dataset is relevant to the topic of document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.670",
          "cited_paper_doi": "10.18653/v1/D18-1360",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e99a259299d4d555ee4c354f2095ab4401369c82",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b21b927c251c415b601b6d7f785a42cc5c292635",
          "citing_paper_year": 2020,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "237100961",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "TDDMan"
      ],
      "dataset_details": [
        {
          "dataset_name": "TDDMan",
          "dataset_description": "Used to evaluate the joint constrained learning method for document-level event extraction, focusing on state-of-the-art performance metrics. | Used to evaluate model performance on document-level event extraction, specifically comparing F1 scores across various models. The dataset focuses on temporal ordering of events with uncertainty-guided graph completion. | Used to assess model performance on document-level event extraction, providing test data for benchmarking.",
          "citing_paper_id": "250291480",
          "cited_paper_id": 237100961,
          "context_text": "In particular, the state-of-the-art performance on HiEve is due to the joint constrained learning method in (Wang et al. 2020) (Ning et al. 2017) 23.8 46.1 BiLSTM (Cheng and Miyao 2017) 24.3 51.8 BiLSTM+MAP (Han et al. 2019a) 41.1 57.1 Deep SSVM (Han et al. 2019b) 41.0 58.8 UCGraph+BERT (Liu et al. 2021) 43.4 61.2 TIMERS (Mathur et al. 2021) 45.5 71.1 SCS-EERE (ours) 51.1 76.7 Table 3: Model performance (F1) on test data of TDDMan and TDDAuto. mance for MATRES, TDDMan, and TDDAuto are recently achieved in the TIMERS system (Mathur et al. 2021).",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets and models, but only 'HiEve', 'TDDMan', and 'TDDAuto' are identified as specific datasets used for evaluation. The other entries are either models or methods.",
          "citing_paper_doi": "10.1609/aaai.v36i10.21354",
          "cited_paper_doi": "10.24963/ijcai.2021/533",
          "citing_paper_url": "https://www.semanticscholar.org/paper/caf084d6f1f46f1aad60691efbb1b9bb0a77d257",
          "cited_paper_url": "https://www.semanticscholar.org/paper/32c1767b956dec644f8bfc1f009fc5a1af47f0cc",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "522537",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Language Understanding Annotation Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "Language Understanding Annotation Corpus",
          "dataset_description": "Used to annotate the author's committed belief towards reported information, focusing on modality in event factuality. | Used to annotate degrees of certainty in knowledge-intensive contexts, targeting nuanced levels of belief and confidence.",
          "citing_paper_id": "2239324",
          "cited_paper_id": 522537,
          "context_text": "…Language Understanding Annotation Corpus (Diab et al. 2009a) focuses on the author’s committed belief towards what is reported (a notion comparable to the modality axis in event factuality), and the small knowledge-intensive corpus by Henriksson and Velupillai (2010) targets degrees of certainty.",
          "confidence_score": 0.85,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two corpora: 'Language Understanding Annotation Corpus' and a 'small knowledge-intensive corpus'. Both are used for annotation studies related to belief and certainty.",
          "citing_paper_doi": "10.1162/COLI_a_00096",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/fec2e117185dbc0e69008872934d84ed5c0209a7",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3139d0ce491ee606a166e3e981fb254d24a1850f",
          "citing_paper_year": 2012,
          "cited_paper_year": 2010
        }
      ]
    },
    {
      "cited_paper_id": "4711425",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "FEVER"
      ],
      "dataset_details": [
        {
          "dataset_name": "FEVER",
          "dataset_description": "Used for fact extraction and verification, providing a large-scale dataset to support research in verifying claims against textual evidence.",
          "citing_paper_id": "189898081",
          "cited_paper_id": 4711425,
          "context_text": "…trend for many areas, including document-level event extraction (Walker et al., 2006; Mitamura et al., 2015, 2017), fact extraction and veriﬁcation (Thorne et al., 2018), reading comprehension (Nguyen et al., 2016; Joshi et al., 2017; Lai et al., 2017), sentiment classiﬁcation (Pang and Lee,…",
          "confidence_score": 0.6,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions several research areas but does not specify any particular dataset names. The only potentially relevant dataset is 'FEVER', which is mentioned in the cited paper title. However, the context does not explicitly state that FEVER is used for document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/P19-1074",
          "cited_paper_doi": "10.18653/v1/N18-1074",
          "citing_paper_url": "https://www.semanticscholar.org/paper/2745fc72e1dd53d1c30f17cf05841b163c2f63c9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b1d24e8e08435b7c52335485a0d635abf9bc604c",
          "citing_paper_year": 2019,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "207853145",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "RAMS argument linking dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "RAMS argument linking dataset",
          "dataset_description": "Used for document-level event extraction, focusing on identifying and linking argument structures across multiple sentences. | Used to evaluate the model on discourse-level tasks, focusing on joint modeling of arguments and ablation studies to assess performance. | Used to evaluate the model on discourse-level event extraction, focusing on multi-sentence argument linking and the relationships between events and arguments. | Used to evaluate the model on discourse-level argument linking, focusing on the joint modeling of arguments and comparing it with an independent model in ablation studies. | Used to consider discourse-level, non-local arguments in document-level context for event extraction, enhancing the understanding of complex event structures. | Used to evaluate the performance of the proposed model on argument linking tasks, demonstrating the benefits of joint modeling in linking arguments to event roles. | Used to explore non-local argument linking in the context of anaphora resolution, providing a new resource for document-level event extraction.",
          "citing_paper_id": "226283556",
          "cited_paper_id": 207853145,
          "context_text": "We demonstrate this leads to state-of-the-art performance on the RAMS argument linking dataset introduced by Ebner et al. (2020), 3 showing the beneﬁts of joint modeling when linking arguments to roles of events.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'RAMS argument linking dataset' which is a specific dataset used for evaluating the performance of the model described in the paper.",
          "citing_paper_doi": "10.18653/v1/2020.codi-1.10",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.718",
          "citing_paper_url": "https://www.semanticscholar.org/paper/366285d6b8e9360709641e1467b3e3bbb26b6d75",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e424abd301379ac627add38366ec962db21dce71",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "185660016",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "New York Times corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "New York Times corpus",
          "dataset_description": "Serves as a structured knowledge base to which entities and relations from the NYT10 dataset are matched, enhancing the semantic understanding of the text. | Used as a common relation extraction dataset, focusing on extracting relations from news articles using various methodologies. | Used to match entities and relations from the New York Times corpus to the Freebase Knowledge Base, focusing on document-level event extraction and relation identification.",
          "citing_paper_id": "253107167",
          "cited_paper_id": 185660016,
          "context_text": "The New York Times corpus (Sandhaus, 2008) is another common relation extraction dataset used in the literature (Riedel et al., 2013; Nayak and Ng, 2019).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the New York Times corpus as a common relation extraction dataset, which is relevant to document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/2022.emnlp-main.580",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/c86754c01fc64a8e8b445f530fe95c1dbab4eb03",
          "cited_paper_url": "https://www.semanticscholar.org/paper/adcfef04625c2763028815759750d47c7c3fe689",
          "citing_paper_year": 2022,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "5066019",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "TimeBank"
      ],
      "dataset_details": [
        {
          "dataset_name": "TimeBank",
          "dataset_description": "Used to refine annotations for event temporal relations, specifically focusing on improving the accuracy and consistency of temporal annotations in the MATRES project. | Used to conduct experiments on event temporal relations, specifically focusing on multi-axis annotation schemes for improving temporal relation identification.",
          "citing_paper_id": "243865639",
          "cited_paper_id": 5066019,
          "context_text": "MATRES contains reﬁned annotations on TimeBank (Pustejovsky et al., 2003 1.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'TimeBank' as a dataset used for refined annotations in the MATRES project. TimeBank is a well-known dataset in the field of temporal relations and event extraction.",
          "citing_paper_doi": "10.18653/v1/2021.emnlp-main.815",
          "cited_paper_doi": "10.18653/v1/P18-1122",
          "citing_paper_url": "https://www.semanticscholar.org/paper/9055d0c286811b1a4f68804805cf440f2d687931",
          "cited_paper_url": "https://www.semanticscholar.org/paper/bff8ae9e28323d217b9ad5a7321e58f79607f557",
          "citing_paper_year": 2021,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "207167677",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "NYT10"
      ],
      "dataset_details": [
        {
          "dataset_name": "NYT10",
          "dataset_description": "Serves as a structured knowledge base to which entities and relations from the NYT10 dataset are matched, enhancing the semantic understanding of the text. | Used to match entities and relations from the New York Times corpus to the Freebase Knowledge Base, focusing on document-level event extraction and relation identification.",
          "citing_paper_id": "253107167",
          "cited_paper_id": 207167677,
          "context_text": "The NYT10 (Riedel et al., 2013) dataset matched the Freebase Knowledge base (Bollacker et al., 2008) to the New York Times corpus (Sandhaus, 2008).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets: NYT10 and Freebase Knowledge Base, both of which are used in the research. The New York Times corpus is also mentioned but is part of the NYT10 dataset.",
          "citing_paper_doi": "10.18653/v1/2022.emnlp-main.580",
          "cited_paper_doi": "10.1145/1376616.1376746",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c86754c01fc64a8e8b445f530fe95c1dbab4eb03",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1976c9eeccc7115d18a04f1e7fb5145db6b96002",
          "citing_paper_year": 2022,
          "cited_paper_year": 2008
        }
      ]
    },
    {
      "cited_paper_id": "216869183",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "TA-CRED"
      ],
      "dataset_details": [
        {
          "dataset_name": "TA-CRED",
          "dataset_description": "Re-annotated to address challenging samples in the development and test sets, focusing on improving relation extraction accuracy.",
          "citing_paper_id": "253107167",
          "cited_paper_id": 216869183,
          "context_text": "Alt et al. (2020) re-annotated a small amount of challenging samples in the development and test sets of the TA-CRED dataset (Zhang et al., 2017).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the re-annotation of the TA-CRED dataset, which is a specific, verifiable dataset used for relation extraction tasks.",
          "citing_paper_doi": "10.18653/v1/2022.emnlp-main.580",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.142",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c86754c01fc64a8e8b445f530fe95c1dbab4eb03",
          "cited_paper_url": "https://www.semanticscholar.org/paper/85bbec78eb692d78020f3fbcca70d34f279485af",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "9776219",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "ACE Challenge dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "ACE Challenge dataset",
          "dataset_description": "Used for document-level event extraction, specifically for identifying and classifying events and entities in text. | Used for comparison with an automatically generated dataset, highlighting the size and construction time differences. The research investigates the efficiency of automatic dataset generation for event extraction. | Used to extract positive instances for document-level event extraction, focusing on identifying sentences that contain events. The dataset is utilized to cover 64.7% of the original content. | Used as a benchmark for comparison, containing significantly fewer sentences and events, highlighting the scalability of the IMP&TIME + DIS dataset. | Used to evaluate the system's performance in handling pronouns as key arguments, highlighting issues with current strategies in argument extraction. | Used as a benchmark to compare the size and construction time of the automatically generated dataset, highlighting the efficiency and scale of the new approach. | Used for document-level event extraction, emphasizing cross-document coreference and event argument linking. | Used to compute importance values for arguments and select key arguments for each event type, enhancing document-level event extraction accuracy. | Used for evaluating document-level event extraction, focusing on named entity recognition and relation extraction tasks. | Used to automatically collect quality training data for event extraction, containing 46735 sentences with 50109 events, demonstrating feasibility without human-designed event schemas or extra annotations. | Used to test the proposed strategy on document-level event extraction, focusing on the performance and accuracy of the method in identifying events within documents.",
          "citing_paper_id": "19224644",
          "cited_paper_id": 9776219,
          "context_text": "Using the structured tables from FreeBase and Wikipedia, we are able to automatically generate a large number of training instances – resulting in a training dataset that is 14x greater than the widely used ACE Challenge dataset(Doddington et al. 2004), and our dataset was automatically constructed within hours instead of costing years of linguists and annotators’ time.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'ACE Challenge dataset' which is a specific, verifiable dataset. It is used for comparison with the automatically generated dataset described in the current research.",
          "citing_paper_doi": "10.1609/aaai.v32i1.12030",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/e44b6963297d2c65bcc422a52cf16a0275820550",
          "cited_paper_url": "https://www.semanticscholar.org/paper/0617dd6924df7a3491c299772b70e90507b195dc",
          "citing_paper_year": 2017,
          "cited_paper_year": 2004
        }
      ]
    },
    {
      "cited_paper_id": "16139903",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "KEGG"
      ],
      "dataset_details": [
        {
          "dataset_name": "KEGG",
          "dataset_description": "Used to create a distantly supervised dataset for event descriptions, providing pathway interaction data. | Used to create a distantly supervised dataset for event descriptions, contributing biological pathway information. | Used to create a distantly supervised dataset for event descriptions, offering detailed pathway annotations. | Used to create a distantly supervised dataset for event descriptions, contributing pathway and interaction data. | Used to train BEEDS with event descriptions from biological pathways, contributing to the distantly supervised knowledge base data set. | Used to create a distantly supervised dataset for event descriptions, focusing on signaling pathways.",
          "citing_paper_id": "248780216",
          "cited_paper_id": 16139903,
          "context_text": "BEEDS uses a data set for training that consists of two portions: The first portion is a distantly supervised, knowledge base data set containing presumable descriptions of events from the union of the following seven pathway databases: KEGG, PID, Reactome, HumanCyc (Romero et al., 2005), INOH (Yamamoto et al., 2011), PANTHER (Mi et al., 2017) and NetPath (Kandasamy et al., 2010).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions a knowledge base data set composed of event descriptions from seven pathway databases. These databases are specific, verifiable resources.",
          "citing_paper_doi": "10.18653/v1/2022.bionlp-1.28",
          "cited_paper_doi": "10.1093/nar/gkw1138",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f2e5d260503074638e6e9849bdd1945b3dac7aad",
          "cited_paper_url": "https://www.semanticscholar.org/paper/767557b5d54467fd6051db172cdb729d2cfd8932",
          "citing_paper_year": 2022,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "2524712",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "GLACIER"
      ],
      "dataset_details": [
        {
          "dataset_name": "GLACIER",
          "dataset_description": "Used to jointly consider phrasal and sentential evidence for information extraction, enhancing the model's ability to capture contextual information.",
          "citing_paper_id": "218630327",
          "cited_paper_id": 2524712,
          "context_text": "GLACIER (Patwardhan and Riloff, 2009) jointly considers cross-",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions 'GLACIER' which is a specific dataset used for information extraction, particularly for joint consideration of phrasal and sentential evidence.",
          "citing_paper_doi": "10.18653/V1/2020.ACL-MAIN.714",
          "cited_paper_doi": "10.3115/1699510.1699530",
          "citing_paper_url": "https://www.semanticscholar.org/paper/6c1244d21cf1f6a490495f155ced8802b489ee4e",
          "cited_paper_url": "https://www.semanticscholar.org/paper/8ff2052500f5f020411fdaeb1c77be482c014689",
          "citing_paper_year": 2020,
          "cited_paper_year": 2009
        }
      ]
    },
    {
      "cited_paper_id": "8387007",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "CausalTimeBank (CTB)"
      ],
      "dataset_details": [
        {
          "dataset_name": "CausalTimeBank (CTB)",
          "dataset_description": "Used to annotate causal and temporal relations in short stories, enhancing the understanding of event structures and their relationships. | Utilized to analyze event causality in online news articles, offering a rich resource for studying event chains and their temporal dynamics. | Used to study causal event pairs, providing 1,770 instances for document-level event extraction and analysis. | Used to analyze causal event pairs, offering 318 instances for document-level event extraction. | Used to study event causality in news articles, providing annotated data for training and evaluating causal relation extraction systems. | Applied to annotate causal and temporal relations in short stories, enhancing the understanding of narrative structures and event sequences. | Used to extract events from news articles, focusing on identifying and classifying events in a structured format. | Used to annotate causal and temporal relations in event structures, containing 488 causal links for semantic annotation. | Used to extract event storylines from online news articles, focusing on the chronological and causal connections between events.",
          "citing_paper_id": "248377560",
          "cited_paper_id": 8387007,
          "context_text": "Previous work has focused on event causality, creating corpora like CausalTimeBank (CTB) (Mirza et al., 2014) from news, CaTeRS (Mostafazadeh et al., 2016) from short stories and EventStoryLine (Caselli and Vossen, 2017) from online news articles.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions three corpora that are relevant to document-level event extraction, specifically focusing on event causality. These corpora are clearly identified and used in previous research.",
          "citing_paper_doi": "10.48550/arXiv.2204.11714",
          "cited_paper_doi": "10.18653/v1/W16-1007",
          "citing_paper_url": "https://www.semanticscholar.org/paper/140e29941a4f38ab00ad9f671473f3e036602b39",
          "cited_paper_url": "https://www.semanticscholar.org/paper/04041a04ede58a464c843f95608e813a7686f6eb",
          "citing_paper_year": 2022,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "6534839",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "80Days"
      ],
      "dataset_details": [
        {
          "dataset_name": "80Days",
          "dataset_description": "Used for annotating implicit arguments in semantic role labeling, focusing on a diverse set of texts and contexts.",
          "citing_paper_id": "220046861",
          "cited_paper_id": 6534839,
          "context_text": "There are several annotation efforts for implicit arguments in SRL, including G&C (Gerber and Chai, 2010, 2012), SemEval-2010 (Ruppenhofer et al., 2009, 2010), and 80Days (Feizabadi and Pad´o, 2014).",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions three annotation efforts for implicit arguments in SRL, which are likely datasets or annotated corpora. However, the context does not specify how they are used in the current research.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.667",
          "cited_paper_doi": "10.3115/1596324.1596352",
          "citing_paper_url": "https://www.semanticscholar.org/paper/65bf813891b05c26d1cb3608c281d36a641ef366",
          "cited_paper_url": "https://www.semanticscholar.org/paper/14c146d457bbd201f3a117ee9c848300d341e5d0",
          "citing_paper_year": 2020,
          "cited_paper_year": 2008
        }
      ]
    },
    {
      "cited_paper_id": "236486186",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "AESPEN"
      ],
      "dataset_details": [
        {
          "dataset_name": "AESPEN",
          "dataset_description": "Utilized for the automated extraction of socio-political events from text, emphasizing challenges and applications in multilingual settings. | Used to extract socio-political events from news articles, focusing on multilingual protest news detection and event classification.",
          "citing_paper_id": "248377560",
          "cited_paper_id": 236486186,
          "context_text": "…Socio-political Events from News (AESPEN) in 2020 (Hürriyeto˘glu et al., 2020b; Hürriyeto˘glu et al., 2020a) and Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE) in 2021 (Hür-riyeto˘glu et al., 2021a; Hürriyeto˘glu et al., 2021b; Hür-riyeto˘glu, 2021).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions two specific datasets, AESPEN and CASE, which are relevant to the topic of document-level event extraction. Both are used in the context of socio-political events from news and text.",
          "citing_paper_doi": "10.48550/arXiv.2204.11714",
          "cited_paper_doi": "10.18653/v1/2021.case-1.11",
          "citing_paper_url": "https://www.semanticscholar.org/paper/140e29941a4f38ab00ad9f671473f3e036602b39",
          "cited_paper_url": "https://www.semanticscholar.org/paper/766e30612f93e2e2b1f517fbb0f6fa4c7e953b71",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "131773936",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "ACE EE"
      ],
      "dataset_details": [
        {
          "dataset_name": "ACE EE",
          "dataset_description": "Used to evaluate model performance on event extraction, achieving 70.1% F1 score.",
          "citing_paper_id": "243865143",
          "cited_paper_id": 131773936,
          "context_text": "…83.5%, 72.1%, and 70.1% in F1 on SQuAD 2.0, FrameNet SRL, and ACE EE respectively, matching the state-of-the-art performance (Devlin et al., 2019; Shi and Lin, 2019; Liu et al., 2020); in the ﬁne-tuning state, we tune parameters on the development set, and ﬁnally the batch size is set as 20,…",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions SQuAD 2.0, FrameNet SRL, and ACE EE as evaluation datasets, but does not provide specific details on their usage beyond reporting performance metrics.",
          "citing_paper_doi": "10.18653/v1/2021.emnlp-main.214",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/648a53e10c8caf276c8bc2e6777ba4baec76fac6",
          "cited_paper_url": "https://www.semanticscholar.org/paper/fddbcabe0fc9be0684855ae3dd059fb525a69e5b",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "38234032",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "EventStoryLine"
      ],
      "dataset_details": [
        {
          "dataset_name": "EventStoryLine",
          "dataset_description": "Used as a benchmark for causal and temporal relation extraction, comparing various models including a dummy model and a dependency path-based LSTM. | Used to address inter-sentence event relations in document-level event extraction, focusing on causal and temporal relations between events across different sentences. | Used to introduce a benchmark for causal and temporal relation extraction, involving 258 documents and 4316 sentences, with a focus on event mention pairs and causal relations.",
          "citing_paper_id": "235097277",
          "cited_paper_id": 38234032,
          "context_text": "In particular, EventStoryLine (i.e., version 0.9) is introduced in (Caselli and Vossen, 2017), involving 258 documents, 22 topics, 4316 sentences, 5334 event mentions, 7805 intra-sentence and 46521 inter-sentence event mention pairs (1770 and 3855 of them are annotated with a causal relation…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "EventStoryLine is a specific dataset with a clear version number and detailed characteristics, making it a verifiable resource.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.273",
          "cited_paper_doi": "10.18653/v1/W17-2711",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5649d1a202e523d0653fbba3cc9017cee539dc19",
          "cited_paper_url": "https://www.semanticscholar.org/paper/210998cf25778b5e07018a34c441e671e034fb1e",
          "citing_paper_year": 2021,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "218517044",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "WordNet 3.0"
      ],
      "dataset_details": [
        {
          "dataset_name": "WordNet 3.0",
          "dataset_description": "Used to perform word-synset mapping, leveraging its lexical structure to enhance word sense disambiguation in the context of event causality recognition.",
          "citing_paper_id": "235097277",
          "cited_paper_id": 218517044,
          "context_text": "In particular, we employ WordNet 3.0 and the state-of-the-art BERT-based WSD model in (Blevins and Zettlemoyer, 2020) to perform the word-synset mapping in this work.",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions WordNet 3.0, which is a lexical database, but does not mention any specific dataset used for document-level event extraction. BERT-based WSD model is a method, not a dataset.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.273",
          "cited_paper_doi": "10.18653/v1/2020.acl-main.95",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5649d1a202e523d0653fbba3cc9017cee539dc19",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9a25609275bb1113aaf7c92b28477ed7ff0677a8",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "63410500",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "DARPA DEFT Program’s Light Entities, Relations and Events (Light ERE) task"
      ],
      "dataset_details": [
        {
          "dataset_name": "DARPA DEFT Program’s Light Entities, Relations and Events (Light ERE) task",
          "dataset_description": "Used for event annotation in both formal newswire and informal discussion forum texts, providing a basis for comparing different styles of annotation. | Used for event argument annotation in the same text types, enabling the integration of multiple annotation styles for comprehensive event extraction.",
          "citing_paper_id": "3137086",
          "cited_paper_id": 63410500,
          "context_text": "The data includes both formal newswire text (NW) and informal discussion forums (DF), drawn from a pool of data also labeled for the DARPA DEFT Program’s Light Entities, Relations and Events (Light ERE) task (Song et al., 2015), and/or the NIST TAC KBP Evaluation Event Argument Task (Ellis et al., 2014), with the goal of ultimately being able to take advantage of multiple styles of event annotation on the same data.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used for event annotation, which are relevant to document-level event extraction.",
          "citing_paper_doi": "10.3115/v1/W15-0809",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/9c34bf7bdb5a4247772c5c6d4982aa4d41e67be9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/0cde937260a4174db2973b2ff400e10bab36ad4f",
          "citing_paper_year": 2015,
          "cited_paper_year": 2014
        }
      ]
    },
    {
      "cited_paper_id": "224814117",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "KnowDis"
      ],
      "dataset_details": [
        {
          "dataset_name": "KnowDis",
          "dataset_description": "Used for knowledge-enhanced data augmentation in event causality detection, leveraging distant supervision to improve model performance.",
          "citing_paper_id": "235097277",
          "cited_paper_id": 224814117,
          "context_text": "Our reimplemented model for BERT achieves higher performance on intra-sentence ECI than those in (Liu et al., 2020); (v) KnowDis (Zuo et al., 2020): a BERT-based model that leverages additional data from distant supervision; (vi) LR+ and LIP (Gao et al., 2019): document structure-based models that…",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'KnowDis' which is a dataset used for knowledge-enhanced data augmentation in event causality detection. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.273",
          "cited_paper_doi": "10.18653/V1/2020.COLING-MAIN.135",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5649d1a202e523d0653fbba3cc9017cee539dc19",
          "cited_paper_url": "https://www.semanticscholar.org/paper/140e4df3512eb1f8469a99f6e4f404d107856646",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "5825949",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "financial news from Reuters and Bloomberg"
      ],
      "dataset_details": [
        {
          "dataset_name": "financial news from Reuters and Bloomberg",
          "dataset_description": "Used to predict stock price movement, focusing on structured events in financial news articles from October 2006 to November 2013.",
          "citing_paper_id": "10638526",
          "cited_paper_id": 5825949,
          "context_text": "We use publicly available ﬁnancial news from Reuters and Bloomberg over the period from October 2006 to November 2013, released by Ding et al. (2014).",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'financial news from Reuters and Bloomberg' which is a specific, domain-qualified data source. It is used for predicting stock price movement.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.3115/v1/D14-1148",
          "citing_paper_url": "https://www.semanticscholar.org/paper/d03b9d5081ca64ce4db2f2dfb1e8f478c3bd44c1",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f9689ecb1b00524fa03c1f62ff503ff88929aba8",
          "citing_paper_year": 2016,
          "cited_paper_year": 2014
        }
      ]
    },
    {
      "cited_paper_id": "207167677",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Freebase"
      ],
      "dataset_details": [
        {
          "dataset_name": "Freebase",
          "dataset_description": "Used as a source of external information to enhance document-level event extraction, providing structured knowledge from Wikipedia and WordNet. | Used as a source of external information to enhance document-level event extraction, providing structured human knowledge. | Used to incorporate external information into the learning process for generating better event representations, providing additional context from a large-scale knowledge graph. | Used to incorporate external information into the learning process for generating better event representations, enhancing the model's understanding of structured human knowledge.",
          "citing_paper_id": "10638526",
          "cited_paper_id": 207167677,
          "context_text": "We propose to incorporate the external information from knowledge graphs, such as Freebase (Bol-lacker et al., 2008) and YAGO (Suchanek et al., 2007), into the learning process to generate better event representations.",
          "confidence_score": 0.8,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions knowledge graphs Freebase and YAGO but does not indicate their use as datasets for document-level event extraction. They are referenced as sources of external information to enhance event representations.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.1145/1376616.1376746",
          "citing_paper_url": "https://www.semanticscholar.org/paper/d03b9d5081ca64ce4db2f2dfb1e8f478c3bd44c1",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1976c9eeccc7115d18a04f1e7fb5145db6b96002",
          "citing_paper_year": 2016,
          "cited_paper_year": 2008
        }
      ]
    },
    {
      "cited_paper_id": "12134535",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "CauSE corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "CauSE corpus",
          "dataset_description": "Used to annotate causal and other relations in text, focusing on corpus lexicography of constructions to enhance understanding of linguistic patterns. | Used to annotate causal and other relations in text, serving as a foundational resource for studying linguistic constructions of causality. | Used to annotate causal and other relations in text, enhancing the original BECauSE corpus with additional data and annotations.",
          "citing_paper_id": "235313431",
          "cited_paper_id": 12134535,
          "context_text": "CauSE corpus (Dunietz et al., 2015) of causal relation and other seven relations.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the CauSE corpus, which is a specific dataset used for annotating causal language and other relations. The corpus is directly relevant to document-level event extraction.",
          "citing_paper_doi": "10.18653/v1/2021.acl-long.276",
          "cited_paper_doi": "10.3115/v1/W15-1622",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1351a827a5039586a3b3e27865ab8ceda342a235",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1f3acc26346ec3a1e2ed66771c3feb598a843318",
          "citing_paper_year": 2021,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "17440009",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "ESC"
      ],
      "dataset_details": [
        {
          "dataset_name": "ESC",
          "dataset_description": "Used to analyze event causality in documents, focusing on the relationship between events and their causal implications. | Used to study causality and temporal information in 184 documents, specifically examining the interplay between events and time.",
          "citing_paper_id": "235313431",
          "cited_paper_id": 17440009,
          "context_text": "9 (ESC) (Caselli and Vossen, 2017) described above; and (2) Causal-TimeBank (Causal-TB) (Mirza and Tonelli, 2014) which contains 184 documents, 6813",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two specific datasets, ESC and Causal-TimeBank, both of which are used in the context of event and causality analysis.",
          "citing_paper_doi": "10.18653/v1/2021.acl-long.276",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/1351a827a5039586a3b3e27865ab8ceda342a235",
          "cited_paper_url": "https://www.semanticscholar.org/paper/434027811ff25dd4564ff6a16f5119db344368b1",
          "citing_paper_year": 2021,
          "cited_paper_year": 2014
        }
      ]
    },
    {
      "cited_paper_id": "9210201",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "CoNLL-2009 Chinese"
      ],
      "dataset_details": [
        {
          "dataset_name": "CoNLL-2009 Chinese",
          "dataset_description": "Used for training, development, and testing in experiments on syntactic and semantic dependencies, following the CoNLL-2009 shared task data splits.",
          "citing_paper_id": "248325339",
          "cited_paper_id": 9210201,
          "context_text": "We conduct experiments on the CoNLL-20093 [14] Chinese and English datasets and use the same data split as CoNLL-2009 share task for train, dev, and test.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the CoNLL-2009 Chinese and English datasets, which are specific and verifiable resources used for training, development, and testing in the experiments.",
          "citing_paper_doi": "10.1145/3528668",
          "cited_paper_doi": "10.3115/1596409.1596411",
          "citing_paper_url": "https://www.semanticscholar.org/paper/3b0698f7f10322c0238cbca08e91e726819597d7",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c7d3f610b528226f1c862c4f9cd6b37623f7390f",
          "citing_paper_year": 2022,
          "cited_paper_year": 2009
        }
      ]
    },
    {
      "cited_paper_id": "224814117",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "distantly labeled training data"
      ],
      "dataset_details": [
        {
          "dataset_name": "distantly labeled training data",
          "dataset_description": "Used to train models for event causality detection, enhancing performance through distant supervision. The dataset provides labeled examples for improving ECI (Event Causality Identification).",
          "citing_paper_id": "235313431",
          "cited_paper_id": 224814117,
          "context_text": "4) KnowDis (Zuo et al., 2020) improved the performance of ECI with the distantly labeled training data.",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'distantly labeled training data' which is likely a dataset used for training purposes in the cited paper. However, the name 'KnowDis' is a method, not a dataset.",
          "citing_paper_doi": "10.18653/v1/2021.acl-long.276",
          "cited_paper_doi": "10.18653/V1/2020.COLING-MAIN.135",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1351a827a5039586a3b3e27865ab8ceda342a235",
          "cited_paper_url": "https://www.semanticscholar.org/paper/140e4df3512eb1f8469a99f6e4f404d107856646",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "52816033",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "CoNLL-2009 Chinese and English test data"
      ],
      "dataset_details": [
        {
          "dataset_name": "CoNLL-2009 Chinese and English test data",
          "dataset_description": "Used to evaluate the performance of the JMEE and JMEE(–GCN) models on document-level event extraction, focusing on the encoding effect of GCN.",
          "citing_paper_id": "248325339",
          "cited_paper_id": 52816033,
          "context_text": "We report our experimental results on the CoNLL-2009 Chinese and English test data in Tables 3 and 4, where JMEE(–GCN) (line 5) is used to further analyze baseline JMEE and the encoding effect of GCN.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'CoNLL-2009 Chinese and English test data' which is a specific dataset used for evaluating the performance of the JMEE model and its variant.",
          "citing_paper_doi": "10.1145/3528668",
          "cited_paper_doi": "10.18653/v1/D18-1156",
          "citing_paper_url": "https://www.semanticscholar.org/paper/3b0698f7f10322c0238cbca08e91e726819597d7",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6f0637f44ac481905d732be7a2e15d8f699aeeb3",
          "citing_paper_year": 2022,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "215548441",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "HiEve"
      ],
      "dataset_details": [
        {
          "dataset_name": "HiEve",
          "dataset_description": "Used to evaluate models on subevent relation extraction, maintaining consistency with prior work and comparing performance across different approaches. | Used to evaluate models on subevent relation extraction, ensuring consistency with prior work and comparing performance metrics. | Used to evaluate model performance on subevent relation extraction, focusing on temporal ordering of events in document-level event extraction.",
          "citing_paper_id": "250291480",
          "cited_paper_id": 215548441,
          "context_text": "Datasets : For subevent relation extraction, we evaluate our models on the HiEve dataset (Glavaˇs et al. 2014) to make it consistent with prior work (Wang et al. 2020; Zhou et al. 2020 (Glavaˇs et al. 2014) 52.2 63.4 57.7 TACOLM (Zhou et al. 2020) 48.5 49.4 48.9 Joint Learning (Wang et al. 2020)…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the HiEve dataset, which is used for evaluating models on subevent relation extraction, consistent with prior work.",
          "citing_paper_doi": "10.1609/aaai.v36i10.21354",
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.436",
          "citing_paper_url": "https://www.semanticscholar.org/paper/caf084d6f1f46f1aad60691efbb1b9bb0a77d257",
          "cited_paper_url": "https://www.semanticscholar.org/paper/cb74deff0feef51eb2a40a59278715d57890a254",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        }
      ]
    }
  ],
  "citation_count_distribution": {
    "3719231": 2,
    "3867049": 2,
    "4803246": 1,
    "19235598": 2,
    "30370175": 1,
    "197544867": 1,
    "198953378": 6,
    "207853145": 15,
    "215737171": 3,
    "218630327": 13,
    "2563759": 1,
    "11986411": 6,
    "119308902": 14,
    "154230030": 1,
    "154992508": 1,
    "196201373": 1,
    "213428800": 1,
    "216562330": 19,
    "216562779": 4,
    "226262283": 8,
    "233219850": 16,
    "235254286": 4,
    "235458429": 8,
    "237353175": 1,
    "250390839": 4,
    "252089843": 1,
    "252569165": 4,
    "254877171": 1,
    "258378242": 1,
    "262825274": 2,
    "264814421": 1,
    "265659367": 1,
    "51871198": 13,
    "252819354": 1,
    "259120735": 1,
    "266163877": 1,
    "13756489": 12,
    "14339673": 17,
    "211529034": 1,
    "248780177": 1,
    "249431954": 3,
    "1320606": 7,
    "2617020": 1,
    "6452487": 12,
    "11187670": 3,
    "19220240": 4,
    "52967399": 24,
    "196178503": 10,
    "231985811": 1,
    "1053009": 1,
    "2114517": 10,
    "2257053": 3,
    "14365335": 3,
    "14492070": 1,
    "52822214": 1,
    "202539496": 7,
    "203701085": 4,
    "204838007": 7,
    "207847663": 1,
    "208031598": 1,
    "218470122": 1,
    "220047190": 2,
    "231602921": 3,
    "235097664": 4,
    "235253912": 7,
    "237363266": 1,
    "247084444": 7,
    "247155069": 2,
    "248512779": 2,
    "248780414": 1,
    "252873525": 1,
    "258887711": 1,
    "258967833": 2,
    "259370571": 2,
    "269214164": 1,
    "426998": 1,
    "14665391": 1,
    "247619149": 5,
    "248780216": 1,
    "3469394": 1,
    "218501728": 1,
    "245934663": 1,
    "1820089": 2,
    "1915014": 3,
    "4249277": 1,
    "10910955": 3,
    "13886709": 1,
    "220048375": 5,
    "35386653": 3,
    "6628106": 10,
    "219683473": 7,
    "243865619": 3,
    "341734": 1,
    "3030259": 1,
    "8143782": 1,
    "11137563": 1,
    "14625075": 1,
    "15926286": 2,
    "17716605": 1,
    "38234032": 1,
    "202120592": 1,
    "202770954": 3,
    "204960716": 9,
    "237491754": 1,
    "243865143": 3,
    "243865639": 1,
    "266177132": 2,
    "202537206": 2,
    "5046366": 1,
    "9631585": 1,
    "17825977": 2,
    "21695474": 1,
    "202786163": 1,
    "204915992": 3,
    "218971783": 5,
    "225039792": 4,
    "233988541": 1,
    "248505827": 1,
    "252090194": 2,
    "258967387": 3,
    "258998173": 1,
    "259950998": 1,
    "265149752": 1,
    "275901979": 1,
    "246241684": 1,
    "251640549": 1,
    "268417143": 1,
    "1942185": 2,
    "2778800": 4,
    "8174613": 2,
    "12108307": 8,
    "17984630": 1,
    "131886": 1,
    "2172129": 1,
    "220484653": 4,
    "226254029": 1,
    "235097376": 1,
    "235166504": 1,
    "235313431": 3,
    "236460024": 3,
    "244678529": 1,
    "249010869": 1,
    "250390907": 1,
    "258297899": 1,
    "259858871": 1,
    "260063107": 1,
    "268249143": 1,
    "270199894": 2,
    "52816033": 6,
    "239998651": 1,
    "247519241": 1,
    "249017743": 2,
    "252683303": 1,
    "254408772": 1,
    "256389694": 1,
    "269613809": 1,
    "6341459": 2,
    "14672517": 1,
    "16925224": 1,
    "35264612": 1,
    "196199409": 1,
    "198118773": 1,
    "202712654": 1,
    "216869183": 1,
    "218551201": 1,
    "236460259": 7,
    "247797575": 5,
    "9776219": 6,
    "231632658": 1,
    "246411621": 1,
    "246426909": 2,
    "247595263": 1,
    "248496614": 7,
    "252762275": 1,
    "257205763": 1,
    "259000027": 1,
    "269762049": 1,
    "269900068": 1,
    "3126319": 1,
    "3519188": 1,
    "5458500": 5,
    "5749336": 1,
    "6644751": 5,
    "10827006": 1,
    "14493443": 1,
    "15894892": 1,
    "18462140": 1,
    "19224644": 2,
    "248986239": 2,
    "254591242": 1,
    "254823489": 1,
    "257353536": 1,
    "257985312": 1,
    "258558102": 1,
    "258841149": 1,
    "267750177": 1,
    "269626679": 1,
    "269803960": 1,
    "270209567": 1,
    "1671874": 2,
    "2926851": 1,
    "9946972": 4,
    "53081291": 2,
    "202773239": 2,
    "221246218": 4,
    "221996144": 5,
    "211296865": 1,
    "251371417": 1,
    "259629787": 1,
    "263829656": 1,
    "5590763": 3,
    "14542261": 4,
    "244119148": 4,
    "248721950": 2,
    "252519442": 1,
    "252819226": 3,
    "268315840": 1,
    "61154509": 1,
    "212648787": 1,
    "231632837": 1,
    "248325339": 1,
    "5421278": 1,
    "12719479": 1,
    "31791545": 1,
    "119297355": 1,
    "222180086": 1,
    "258865260": 2,
    "950755": 7,
    "1240016": 3,
    "2213149": 3,
    "2367456": 7,
    "3480671": 1,
    "9426884": 1,
    "14117526": 3,
    "43095407": 1,
    "51878680": 1,
    "220046861": 7,
    "6771196": 1,
    "155092004": 1,
    "211268325": 1,
    "174800619": 1,
    "257019152": 1,
    "2941631": 1,
    "9778664": 2,
    "70346512": 1,
    "209948413": 1,
    "225157900": 1,
    "225160964": 1,
    "238590886": 1,
    "5692837": 1,
    "8310135": 1,
    "125977708": 1,
    "231728756": 9,
    "234358675": 2,
    "1957433": 3,
    "3626819": 1,
    "10694510": 1,
    "12740621": 3,
    "18779057": 1,
    "210994639": 1,
    "224924246": 1,
    "235363528": 1,
    "235421996": 1,
    "236477583": 3,
    "245335089": 1,
    "247594010": 1,
    "252440614": 1,
    "257126309": 1,
    "257268255": 1,
    "258801534": 1,
    "3292002": 1,
    "51871927": 3,
    "56517517": 1,
    "88492570": 1,
    "222177188": 1,
    "3312944": 2,
    "10913456": 2,
    "140925826": 1,
    "245811890": 1,
    "69988562": 1,
    "2524712": 6,
    "5993783": 2,
    "41089825": 2,
    "202537635": 1,
    "233307138": 1,
    "234790176": 2,
    "6300274": 1,
    "6826032": 1,
    "8471750": 1,
    "8535316": 1,
    "49393754": 1,
    "52349712": 1,
    "201307832": 1,
    "239085620": 1,
    "20744": 2,
    "4952494": 1,
    "8336242": 1,
    "44161048": 1,
    "57193015": 1,
    "204851964": 1,
    "214673189": 1,
    "218551030": 1,
    "11212020": 1,
    "14610045": 1,
    "63777164": 1,
    "5959482": 1,
    "233613419": 1,
    "245123950": 2,
    "226096901": 2,
    "2486369": 1,
    "2505531": 1,
    "2867611": 2,
    "6540287": 1,
    "13804679": 1,
    "202786778": 1,
    "226283556": 3,
    "253510351": 2,
    "256461151": 1,
    "269362270": 1,
    "309759": 2,
    "14416802": 1,
    "131773936": 6,
    "208547716": 2,
    "215745286": 1,
    "261226458": 1,
    "13981987": 1,
    "220524732": 3,
    "235458009": 1,
    "258947053": 1,
    "265221405": 1,
    "267976050": 1,
    "252901047": 1,
    "259370721": 1,
    "259858959": 1,
    "268313449": 1,
    "268342373": 1,
    "53592270": 6,
    "248496246": 1,
    "265221038": 1,
    "433312": 1,
    "222177108": 2,
    "235732095": 1,
    "259370619": 1,
    "264452034": 1,
    "4698173": 1,
    "49312395": 1,
    "201646309": 4,
    "220045828": 1,
    "246472929": 1,
    "236460308": 6,
    "247450724": 1,
    "249063162": 1,
    "250637739": 1,
    "209319719": 2,
    "249579113": 1,
    "259383402": 1,
    "8950084": 2,
    "47252984": 2,
    "174799895": 1,
    "252626402": 2,
    "254043718": 1,
    "259716313": 1,
    "1164487": 1,
    "7228830": 1,
    "61701554": 1,
    "247417818": 1,
    "248780117": 2,
    "252391326": 2,
    "990233": 1,
    "3446415": 1,
    "11392154": 1,
    "16482483": 1,
    "144823696": 1,
    "230799347": 1,
    "250264890": 1,
    "250390478": 1,
    "254043800": 1,
    "11246193": 1,
    "22130590": 1,
    "54437926": 3,
    "237499254": 1,
    "248371142": 1,
    "257050669": 1,
    "10016456": 1,
    "11751039": 3,
    "13241382": 1,
    "13807460": 1,
    "15865939": 2,
    "26791976": 1,
    "135473179": 1,
    "189928589": 3,
    "227230416": 2,
    "238856763": 1,
    "246273659": 1,
    "258011950": 1,
    "258820351": 1,
    "259004542": 1,
    "255522592": 1,
    "259137390": 1,
    "15552794": 3,
    "202539732": 1,
    "202542357": 1,
    "269498086": 1,
    "32821791": 2,
    "109933467": 2,
    "265212914": 1,
    "273185680": 1,
    "6953475": 1,
    "14515377": 1,
    "50771731": 1,
    "53080736": 2,
    "60441361": 1,
    "131774949": 1,
    "202771953": 1,
    "233296646": 1,
    "234742165": 1,
    "236486186": 1,
    "248512966": 1,
    "10743051": 1,
    "184487889": 2,
    "202541610": 3,
    "203610361": 1,
    "215816738": 1,
    "226283579": 2,
    "235792444": 1,
    "1162419": 1,
    "9130816": 2,
    "9137624": 2,
    "17227879": 2,
    "31562985": 1,
    "38687082": 1,
    "51878335": 1,
    "174801632": 1,
    "189898081": 7,
    "202771243": 1,
    "235313618": 2,
    "247594480": 2,
    "8387007": 1,
    "202537879": 1,
    "202782267": 1,
    "235097277": 1,
    "248377560": 1,
    "250291480": 1,
    "252819228": 1,
    "8291528": 1,
    "53109320": 1,
    "54475483": 1,
    "198229624": 1,
    "226976039": 1,
    "4321928": 1,
    "6546734": 1,
    "153312535": 1,
    "222208551": 1,
    "236087324": 1,
    "5165854": 1,
    "7294125": 1,
    "10503028": 1,
    "15139323": 1,
    "202565622": 1,
    "215548441": 1,
    "218581125": 1,
    "232062161": 1,
    "233307040": 1,
    "237100961": 1,
    "17719760": 1,
    "204902024": 1,
    "278288": 1,
    "5073927": 1,
    "5188467": 1,
    "7961699": 3,
    "11239061": 1,
    "54088698": 1,
    "4760632": 2,
    "76666127": 2,
    "238660430": 1,
    "1697424": 1,
    "2797612": 4,
    "6042994": 3,
    "6300165": 1,
    "201646551": 1,
    "1724837": 1,
    "2386383": 2,
    "8236317": 1,
    "14175558": 1,
    "18198203": 1,
    "51605731": 1,
    "51870827": 2,
    "182953200": 1,
    "60827152": 1,
    "67855846": 1,
    "204734128": 1,
    "212657414": 1,
    "235490449": 1,
    "247155039": 1,
    "6844431": 1,
    "14068874": 1,
    "15920102": 1,
    "233874227": 1,
    "240288666": 1,
    "248218685": 1,
    "397533": 1,
    "16389974": 1,
    "65179127": 1,
    "10638526": 1,
    "12981484": 1,
    "208004535": 1,
    "224868016": 1,
    "224948084": 1,
    "2065400": 1,
    "11574815": 1,
    "12179472": 1,
    "131774006": 1,
    "102353905": 4,
    "147704286": 1,
    "15600925": 1,
    "44134226": 1,
    "127986954": 1,
    "577937": 1,
    "1508503": 1,
    "3137086": 1,
    "3534906": 1,
    "14293159": 1,
    "225067984": 1,
    "3782112": 2,
    "235254332": 1,
    "238856938": 1,
    "2723173": 1,
    "3297437": 1,
    "7200347": 1,
    "39871772": 1,
    "53213211": 1,
    "102483181": 1,
    "218613850": 4,
    "219558831": 1,
    "219559263": 1,
    "235485451": 1,
    "248300064": 1,
    "67855713": 1,
    "202542650": 1,
    "214714027": 2,
    "221340666": 1,
    "225039888": 5,
    "236980247": 1,
    "238667590": 1,
    "240490603": 1,
    "246288538": 1,
    "253664325": 1,
    "260601397": 1,
    "21698802": 1,
    "52118895": 2,
    "59599752": 1,
    "215745290": 1,
    "235358168": 3,
    "237491060": 1,
    "237635295": 2,
    "245144787": 1,
    "247939302": 1,
    "248227853": 2,
    "248496086": 1,
    "251518246": 1,
    "254044368": 1,
    "255372865": 2,
    "258762887": 1,
    "259164990": 1,
    "259949704": 1,
    "264590646": 1,
    "88817": 3,
    "214641183": 1,
    "269804131": 1,
    "3719281": 1,
    "202558505": 1,
    "209323787": 1,
    "253107167": 1,
    "254877738": 1,
    "261792194": 1,
    "264412875": 1,
    "266176277": 1,
    "3879949": 1,
    "2381120": 1,
    "5509259": 1,
    "174800839": 1,
    "220525799": 1,
    "233296843": 1,
    "247291740": 2,
    "252918868": 1,
    "259187621": 1,
    "259261857": 1,
    "263830659": 1,
    "263861232": 1,
    "271923564": 1,
    "60709701": 1,
    "220045465": 1,
    "233210350": 1,
    "243865600": 1,
    "266163830": 1,
    "6263378": 1,
    "215768766": 1,
    "227231216": 1,
    "244001886": 1,
    "60246043": 1,
    "228954221": 1,
    "247694170": 1,
    "247961196": 1,
    "254564105": 1,
    "257019958": 1,
    "257766307": 1,
    "160705": 1,
    "804903": 1,
    "2100831": 1,
    "2239324": 1,
    "5730838": 1,
    "8992998": 1,
    "9885298": 1,
    "12873739": 2,
    "13468104": 1,
    "14124213": 1,
    "51605619": 1,
    "174800759": 1,
    "195833740": 1,
    "196215305": 1,
    "203620105": 1,
    "207228784": 1,
    "216078090": 1,
    "4612975": 1,
    "17606580": 1,
    "18930466": 1,
    "59528287": 1,
    "67856607": 1,
    "207169186": 1,
    "221970808": 1,
    "243865630": 1,
    "252904978": 1,
    "261317734": 1,
    "2476229": 1,
    "16483125": 1,
    "52115592": 2,
    "53250562": 2,
    "202889074": 1,
    "208248243": 2,
    "235313883": 1,
    "235790751": 1,
    "237346893": 1,
    "237507023": 1,
    "15359942": 2,
    "190001673": 1,
    "6292807": 1,
    "28671436": 1,
    "212747810": 1,
    "235694418": 1,
    "247450599": 1,
    "793385": 1,
    "53607073": 1,
    "233210556": 1,
    "235313469": 1,
    "238583580": 1,
    "246897443": 1,
    "259108325": 1,
    "2626916": 1,
    "10557799": 1,
    "13861754": 1,
    "14886018": 1,
    "2003493": 1,
    "5112317": 1,
    "209515730": 1,
    "220919723": 1,
    "221738957": 1,
    "226237654": 1,
    "231750020": 1,
    "231879840": 1,
    "235358786": 1,
    "244119359": 1,
    "260429228": 1,
    "277550631": 1,
    "21700944": 1,
    "189762527": 1,
    "226262410": 1
  },
  "merged_dataset_groups": [
    {
      "display_name": "DocRED",
      "normalized_name": "docred",
      "name_variants": [
        "DocRED"
      ],
      "mention_count": 32,
      "cited_papers_count": 25,
      "topic_summary": "The DocRED dataset is primarily used for evaluating document-level relation extraction, particularly focusing on complex relations across multiple sentences in scientific documents. It is employed to compare model performance, such as cased BERT-base, RoBERTa-large, and graph-based models, on tasks like gene-disease and chemical-disease relation extraction. The dataset supports the development and evaluation of methods that enhance interpretability and evidence retrieval, often leveraging pre-trained encoders and crowd-sourced annotations from Wikipedia articles."
    },
    {
      "display_name": "RAMS",
      "normalized_name": "rams",
      "name_variants": [
        "RAMS",
        "RAMS test set"
      ],
      "mention_count": 29,
      "cited_papers_count": 17,
      "topic_summary": "The RAMS dataset is extensively used for document-level event extraction, focusing on fine-grained and multi-sentence event and argument identification. It serves as a benchmark for training and evaluating models, particularly in handling complex event structures and cross-domain scenarios. The dataset contains 27,000+ events and 180,000+ arguments across 27,485 Wikipedia articles, enabling researchers to address challenges such as limited training data, implicit argument detection, and the distribution of role instances. It supports various methodologies, including hyper-parameter tuning, error analysis, and ablation studies, and is used to report performance metrics like Span F1 and Head F1."
    },
    {
      "display_name": "MUC-4",
      "normalized_name": "muc4",
      "name_variants": [
        "MUC-4",
        "MUC4"
      ],
      "mention_count": 16,
      "cited_papers_count": 16,
      "topic_summary": "The MUC-4 dataset is primarily used for document-level event extraction, focusing on identifying and classifying events and their roles across multiple sentences. It is employed to develop and evaluate event templates, compare different extraction methods (classification-based vs. pattern-based), and assess performance metrics (precision, F1, recall). The dataset supports research in various domains, including Japanese joint ventures, micro-electronics, Latin American terrorism, and general news articles. It is also used for template filling, entity-based extraction, and granular event structure analysis, often comparing comprehensive annotation practices (averaging 16 events per document) with more limited annotations (up to 3 events per document)."
    },
    {
      "display_name": "ACE 2005",
      "normalized_name": "ace2005",
      "name_variants": [
        "ACE 2005",
        "ACE2005"
      ],
      "mention_count": 15,
      "cited_papers_count": 11,
      "topic_summary": "The ACE 2005 dataset is extensively used in research for document-level and sentence-level event extraction, focusing on identifying, linking, and tagging events and their arguments within texts. It serves as a benchmark for evaluating data augmentation methods, feature-based models, and structured prediction techniques. The dataset, comprising 529 documents, is used to train and test supervised event extractors, employing standard data splits and preprocessing to ensure consistency with prior studies. It supports the development and comparison of models for improving extraction accuracy and performance in newswire articles and other text types."
    },
    {
      "display_name": "MUC",
      "normalized_name": "muc",
      "name_variants": [
        "MUC",
        "MUC datasets"
      ],
      "mention_count": 6,
      "cited_papers_count": 6,
      "topic_summary": "The MUC dataset is primarily used for information extraction tasks, focusing on event extraction, argument linking, and template filling. It supports the annotation of event structures, particularly n-ary associations, and evaluates systems in slot filling and message understanding. The dataset provides detailed records of events and participants, enabling research in structured information extraction and the development of early event extraction systems."
    },
    {
      "display_name": "ECB+",
      "normalized_name": "ecb",
      "name_variants": [
        "ECB+"
      ],
      "mention_count": 6,
      "cited_papers_count": 6,
      "topic_summary": "The ECB+ dataset is primarily used for training and evaluating models in document-level event extraction and cross-document event coreference resolution. It extends the original ECB dataset with additional annotations, enhancing its utility for tasks such as lexical diversity and event linking in news articles. Researchers use it to compare the performance of various models, including LongFormer, BERT, RoBERTa, and +WD-LCP, often employing methods like clustering gold mentions and concatenating test documents into meta-documents. This dataset supports cross-lingual studies and provides a foundational resource for advancing event coreference resolution techniques."
    },
    {
      "display_name": "ChFinAnn",
      "normalized_name": "chfinann",
      "name_variants": [
        "ChFi-nAnn",
        "ChFinAnn",
        "ChfinAnn"
      ],
      "mention_count": 5,
      "cited_papers_count": 4,
      "topic_summary": "The ChFinAnn dataset is primarily used for document-level event extraction (DEE) in financial documents, focusing on fine-grained event types and arguments. It supports various methodologies, including distant supervision, sequence tagging, key-event-sentence detection, and conditional generation. The dataset is utilized to train and evaluate models on tasks such as multi-sentence argument linking, event argument extraction, and general domain event detection. Its large-scale, diverse, and specialized nature in the financial domain makes it a valuable resource for benchmarking and improving model performance on complex, multi-event documents."
    },
    {
      "display_name": "MAVEN",
      "normalized_name": "maven",
      "name_variants": [
        "MAVEN"
      ],
      "mention_count": 5,
      "cited_papers_count": 4,
      "topic_summary": "The MAVEN dataset is primarily used for document-level event extraction, providing a large-scale resource for training and evaluating models across various domains, including general and financial contexts. It supports multi-sentence argument linking and conditional generation methods, enhancing the ability to handle complex, multi-event documents. MAVEN contains a diverse set of events and arguments, with specific applications in Chinese financial event annotation and fine-grained event type detection. The dataset's extensive size and variety make it a valuable benchmark for improving the robustness and performance of event extraction systems."
    },
    {
      "display_name": "Causal-TimeBank",
      "normalized_name": "causaltimebank",
      "name_variants": [
        "Causal-TimeBank"
      ],
      "mention_count": 5,
      "cited_papers_count": 5,
      "topic_summary": "The Causal-TimeBank dataset is primarily used for evaluating and enhancing document-level event extraction, focusing on causal and temporal relations between events. It supports the annotation and evaluation of causal relations, temporal event sequences, and event co-reference. The dataset, consisting of 184 documents and 6813 events, is utilized to train and evaluate models, particularly in identifying and linking causal and temporal connections within and across sentences. Research applications include narrative understanding, event causality recognition, and performance assessment using various approaches such as rule-based, feature-based, and BERT-based models."
    },
    {
      "display_name": "Nom-Bank",
      "normalized_name": "nombank",
      "name_variants": [
        "Nom-Bank",
        "Nombank"
      ],
      "mention_count": 4,
      "cited_papers_count": 3,
      "topic_summary": "Nom-Bank is primarily used for semantic role labeling, particularly for non-local and implicit arguments associated with nominal predicates. It is expanded and utilized to enhance the coverage and scope of event and role annotations, often serving as a baseline for comparison with other datasets like RAMS. The dataset supports research on how context influences argument identification and is employed in various domains, including novels, to study multi-sentence arguments and event triggers. It is also used to train and evaluate models on document-level event extraction, addressing challenges in cross-sentence event coreference."
    },
    {
      "display_name": "ACE",
      "normalized_name": "ace",
      "name_variants": [
        "ACE",
        "ACE data",
        "ACE dataset"
      ],
      "mention_count": 4,
      "cited_papers_count": 4,
      "topic_summary": "The ACE dataset is used to evaluate and enhance various aspects of event and relation extraction in text. It serves as a benchmark for assessing the accuracy of relation extraction methods, particularly in identifying relations without labeled training data. In the biomedical domain, it aids in identifying molecular events and interactions, improving precision and recall. The dataset also supports event classification and recognition through annotation-based methods, including slot filling and knowledge-based population. Additionally, it highlights annotation consistency issues, addressing the challenges faced by human annotators in event identification."
    },
    {
      "display_name": "SCIREX",
      "normalized_name": "scirex",
      "name_variants": [
        "SCIREX",
        "SciREX"
      ],
      "mention_count": 4,
      "cited_papers_count": 4,
      "topic_summary": "The SCIREX dataset is primarily used to train, test, and evaluate document-level neural template-filling approaches, focusing on event extraction and information extraction tasks across various domains, including scientific documents, news articles, and disease outbreak reports. It facilitates comparisons between older and newer models, assessing performance metrics like precision, recall, and F1 scores, and addressing specific challenges such as technical language and missing template errors. The dataset supports research in scientific document processing, message understanding, and coreference resolution, enabling detailed performance analyses and benchmarking."
    },
    {
      "display_name": "WikiEvents",
      "normalized_name": "wikievents",
      "name_variants": [
        "WikiEvents"
      ],
      "mention_count": 4,
      "cited_papers_count": 4,
      "topic_summary": "The WikiEvents dataset is primarily used in document-level event extraction research, focusing on evaluating metrics such as Span-F1, Head-F1, and Coref-F1 for argument extraction and co-reference linkage. It is employed to train event detection models using tools like OmniEvent and CLEVE PLM, classifying event mentions according to the KAIROS ontology. The dataset highlights entity-centric nature and limited event coverage, aiding in the analysis of event types and building knowledge graphs. It is also used to evaluate complex event argument extraction and address challenges in identifying and linking events within and across sentences."
    },
    {
      "display_name": "GENEVA",
      "normalized_name": "geneva",
      "name_variants": [
        "GENEVA"
      ],
      "mention_count": 4,
      "cited_papers_count": 4,
      "topic_summary": "The GENEVA dataset is used to analyze the distribution of event types across various abstract categories, aiding in the construction of knowledge graphs. It is particularly noted for its diversity, which supports detailed analysis of event types for document-level event extraction. This dataset enables researchers to focus on the nuanced distribution and categorization of events, enhancing the accuracy and comprehensiveness of event extraction models."
    },
    {
      "display_name": "GENIA event corpus",
      "normalized_name": "geniaevent",
      "name_variants": [
        "GENIA Event corpus",
        "GENIA event corpus"
      ],
      "mention_count": 3,
      "cited_papers_count": 2,
      "topic_summary": "The GENIA event corpus is used to develop and evaluate document-level event extraction methods, particularly for genic interactions and their linguistic representations in biomedical texts. It includes annotations for biological events, polarity, certainty, and lexical cues, supporting research in event extraction methodologies. The dataset serves as a basis for shared tasks and evaluates system performance on extracting biological reactions, especially those involving transcription factors in human blood cells. It also highlights the annotation process, including the effort and time required with multiple part-time annotators and coordinators."
    },
    {
      "display_name": "FrameNet",
      "normalized_name": "framenet",
      "name_variants": [
        "FrameNet"
      ],
      "mention_count": 3,
      "cited_papers_count": 3,
      "topic_summary": "FrameNet is used for pre-training models in event extraction and semantic role labeling (SRL), framed in a machine reading comprehension (MRC) formulation. It enhances models' abilities to identify, classify events, and understand semantic roles, improving F1 scores. The dataset is also leveraged to design ontologies for event argument extraction, reducing human effort by exploiting shared properties with SRL, providing a diverse and exhaustive resource."
    },
    {
      "display_name": "EPI",
      "normalized_name": "epi",
      "name_variants": [
        "EPI"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The EPI dataset is used to evaluate and test the performance of EventMine in identifying and extracting biological events, such as protein-protein interactions and gene expression events, achieving high F scores. It is also utilized for annotating event and interaction data in the BioNLP Shared Task 2011, focusing on protein interactions, modifications, and infectious disease mechanisms. This dataset enables researchers to benchmark and improve event extraction systems in the biomedical domain."
    },
    {
      "display_name": "WordNet",
      "normalized_name": "wordnet",
      "name_variants": [
        "WordNet"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "WordNet is used in research to enhance model performance in trigger and argument extraction tasks by retrieving synonyms for data augmentation. This involves synonym replacement to expand the training data, improving the robustness and accuracy of models. The dataset's extensive synonymy feature is crucial for this methodology, enabling more effective natural language processing."
    },
    {
      "display_name": "ERE",
      "normalized_name": "ere",
      "name_variants": [
        "ERE"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The ERE dataset is used for entity recognition and linking, as well as training and evaluating models on entity, relation, and event extraction tasks. It focuses on identifying and linking entities in multilingual and cross-document contexts and assesses model performance with varying training data ratios. This dataset enables researchers to improve and test the robustness of NLP models in complex, multilingual environments."
    },
    {
      "display_name": "TempEval-3 Corpus",
      "normalized_name": "tempeval3corpus",
      "name_variants": [
        "TempEval-3 Corpus"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The TempEval-3 Corpus is primarily used for annotating and evaluating causal relations between events in text. It contains 184 documents, 6813 events, and 318 causal event pairs, focusing on event causality in both Chinese and general text. Researchers use it to evaluate causality detection models, such as CauSeRL, through methods like 5-fold and 10-fold cross-validation, assessing precision, recall, and F1 scores. The dataset supports benchmarking and comparing the performance of different causality annotation systems."
    },
    {
      "display_name": "MUC3",
      "normalized_name": "muc3",
      "name_variants": [
        "MUC3"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The MUC3 dataset is used as a basis for the Relation Extraction and Event (REE) task, simplifying the original formulation for event extraction. However, specific details on the methodology, research questions, or particular characteristics of the dataset in this context are not provided in the available descriptions."
    },
    {
      "display_name": "ChiFinAnn",
      "normalized_name": "chifinann",
      "name_variants": [
        "ChiFinAnn"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The ChiFinAnn dataset is primarily used for Chinese financial event extraction, focusing on document-level annotations and the evaluation of event detection models. It emphasizes the identification of event arguments and relations within financial documents, enhancing the accuracy of event detection through supervised and unsupervised learning methods. The dataset supports research by providing a diverse set of event types and challenging negative samples, enabling the analysis of event distribution and the training of models to handle complex events and real-time extraction scenarios."
    },
    {
      "display_name": "DocEE",
      "normalized_name": "docee",
      "name_variants": [
        "DocEE"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The DocEE dataset is used in research for evaluating and comparing methodologies in document-level event extraction. It focuses on document-level event annotations, typically averaging 16 events per document. The dataset is employed to assess frameworks and annotation practices, comparing different approaches such as those that annotate up to 3 events versus all events in a document. Additionally, it is used to evaluate the performance of HD-LoA prompting in cross-domain settings, contrasting it with supervised methods and extensively trained models."
    },
    {
      "display_name": "PubMed",
      "normalized_name": "pubmed",
      "name_variants": [
        "PubMed"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The PubMed dataset is used to evaluate document-level relation extraction models, particularly focusing on complex relations and event structures that span multiple sentences in biomedical documents. It serves as a source of scientific texts to assess models' ability to identify cross-sentence relations and entity interactions, enhancing the accuracy of information extraction in the biomedical domain."
    },
    {
      "display_name": "Roles Across Multiple Sentences (RAMS)",
      "normalized_name": "rolesacrossmultiplesentencesrams",
      "name_variants": [
        "Roles Across Multiple Sentences (RAMS)"
      ],
      "mention_count": 2,
      "cited_papers_count": 1,
      "topic_summary": "The Roles Across Multiple Sentences (RAMS) dataset is used to annotate and link event-argument structures across multiple sentences, enhancing document-level understanding of events and their participants. It supports the development of models for document-level event extraction by providing a large corpus that focuses on linking arguments across sentences, which is crucial for improving the accuracy and coherence of event representation in natural language processing tasks."
    },
    {
      "display_name": "Re-DocRED",
      "normalized_name": "redocred",
      "name_variants": [
        "Re-DocRED"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The Re-DocRED dataset is used to enhance document-level relation extraction by addressing false negatives and supplementing missing relations in the original DocRED dataset. It is employed in fully supervised settings, applying methods such as adaptive focal loss and knowledge distillation to improve model performance on complex document structures. This dataset provides a high-quality, revised version with improved labeling, enabling more accurate and comprehensive relation extraction experiments."
    },
    {
      "display_name": "GENIA11",
      "normalized_name": "genia11",
      "name_variants": [
        "GENIA11"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The GENIA11 dataset is primarily used for evaluating the precision of machine reading components in biomedical event extraction, specifically comparing systems like TEES and BEEDS. It provides gold standard annotations for supervised learning, enhancing the quality of distantly supervised training sets. This dataset is crucial for the BioNLP Shared Task, focusing on event extraction in biomedical texts."
    },
    {
      "display_name": "FewFC",
      "normalized_name": "fewfc",
      "name_variants": [
        "FewFC"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The FewFC dataset is primarily used to evaluate and train models for few-shot learning tasks, particularly in the context of document-level event extraction. It focuses on the performance of models like BioBERT and Chinese Bert-base in extracting nested and overlapping biomedical events. The dataset enables researchers to assess the effectiveness of these models in low-resource scenarios, providing insights into their capabilities in handling complex event structures and few-shot learning challenges."
    },
    {
      "display_name": "Penn Discourse Treebank (PDTB)",
      "normalized_name": "penndiscoursetreebankpdtb",
      "name_variants": [
        "Penn Discourse Treebank (PDTB)"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The Penn Discourse Treebank (PDTB) is used to annotate semantic relations between clauses, including both explicit and implicit causal relations, enhancing discourse analysis in natural language processing. It defines the 'contingency' label for causality, where one argument provides the reason or explanation for another. The dataset is employed for causal sentence classification, evaluating the effectiveness of baseline models in detecting causal relationships in English news articles."
    },
    {
      "display_name": "Beyond NomBank",
      "normalized_name": "beyondnombank",
      "name_variants": [
        "Beyond NomBank"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 'Beyond NomBank' dataset is used to extend semantic role labeling beyond traditional verb-based predicates, encompassing nominal and adjectival predicates. It enhances coverage of implicit roles and addresses overtness and valency in verb argument structures. This dataset supports research in expanding the scope of nominal semantic role labeling, improving the annotation of verb valency, and enriching the representation of semantic roles in natural language processing tasks."
    },
    {
      "display_name": "GDA",
      "normalized_name": "gda",
      "name_variants": [
        "GDA"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The GDA dataset is used to evaluate and compare graph-based and other models on document-level relation extraction, particularly for gene-disease and chemical-disease associations. It focuses on capturing global context and local entity interactions, enabling researchers to assess the performance of various graph convolutional network approaches and state-of-the-art models."
    },
    {
      "display_name": "BioNLP Shared Task 2011 GE data set",
      "normalized_name": "bionlpsharedtask2011ge",
      "name_variants": [
        "BioNLP Shared Task 2011 GE data set"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The BioNLP Shared Task 2011 GE data set is primarily used to evaluate and enhance the performance of event extraction models, particularly EventMine. It is employed to identify interaction detection events, extract protein-protein interactions, and detect gene expression events, consistently demonstrating high F scores and competitive results. The dataset is also used to train models, with its predictions incorporated into a stacking approach to improve overall model performance."
    },
    {
      "display_name": "SemEval-2010 Task 10",
      "normalized_name": "semeval2010task10",
      "name_variants": [
        "SemEval-2010 Task 10"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The SemEval-2010 Task 10 dataset is primarily used to extend and enhance NomBank for implicit arguments, focusing on nominal predicates in event extraction. It supports research on non-local arguments in semantic role labeling, particularly in stories, and investigates how context influences argument identification. The dataset is also used to compare event extraction performance and study nominal predicates and multi-sentence arguments, similar to the RAMS dataset. This enables researchers to explore and annotate implicit arguments, enhancing the understanding of event triggers and their properties."
    },
    {
      "display_name": "EventKG",
      "normalized_name": "eventkg",
      "name_variants": [
        "EventKG"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "EventKG is used to construct a multilingual event-centric temporal knowledge graph, integrating and representing events from multiple languages and sources. This dataset enables researchers to focus on the integration and representation of events across diverse linguistic and informational contexts, facilitating the creation of comprehensive, interconnected event data structures."
    },
    {
      "display_name": "Gigaword corpus",
      "normalized_name": "gigaword",
      "name_variants": [
        "Gigaword corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Gigaword corpus is used to contextualize training data relevance for event extraction and to fine-tune pre-trained sequence-to-sequence models like T5 for infilling tasks in similar domains. It provides a large-scale textual resource that enhances model performance by offering diverse and contextually rich data."
    },
    {
      "display_name": "SemEval-2010 Task 8",
      "normalized_name": "semeval2010task8",
      "name_variants": [
        "SemEval-2010 Task 8"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The SemEval-2010 Task 8 dataset is primarily used for relation classification in event extraction research. It serves as a benchmark for developing and evaluating recurrent neural network models. The dataset's structured annotations enable researchers to propose and test new tasks, focusing on improving the accuracy of relation classification between entities in text."
    },
    {
      "display_name": "FEED",
      "normalized_name": "feed",
      "name_variants": [
        "FEED"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The FEED dataset is utilized to enhance event extraction accuracy in financial documents, particularly in Chinese texts. It provides event knowledge for DS-based event labeling and is used to construct and evaluate document-level event labeling datasets, focusing on the period 2008-2018. The dataset supports research on model performance and the distinguishability between different models in financial event detection."
    },
    {
      "display_name": "Darpa corpus from 2009",
      "normalized_name": "darpa",
      "name_variants": [
        "Darpa corpus from 2009"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Darpa corpus from 2009 is used to evaluate event extraction systems, particularly in the context of news events. Researchers focus on performance metrics such as F-score to assess the accuracy and robustness of these systems. Despite its historical significance, the dataset's lack of current public availability limits broader use. It enables the evaluation of system performance in event extraction tasks, providing insights into system effectiveness and reliability."
    },
    {
      "display_name": "Few-NERD",
      "normalized_name": "fewnerd",
      "name_variants": [
        "Few-NERD"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Few-NERD dataset is used to train and evaluate few-shot named entity recognition (NER) models, with a focus on leveraging cross-sentence information to enhance entity detection. This dataset enables researchers to address the challenge of identifying entities in low-resource scenarios by providing a structured set of annotated data that supports the development and testing of models capable of utilizing context across multiple sentences."
    },
    {
      "display_name": "ACE05",
      "normalized_name": "ace05",
      "name_variants": [
        "ACE05"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The ACE05 dataset is extensively used in research for various tasks including training components for temporal ordering, visual event and argument extraction, cross-media event coreference, weakly supervised event extraction, document-level argument extraction, and schema matching and prediction. It supports methodologies that integrate multimodal information and focus on entity, event, and relation recognition across different media types, enhancing event detection, coreference, and schema alignment in complex documents and multimedia content."
    },
    {
      "display_name": "EventStoryLine Corpus",
      "normalized_name": "eventstorylinecorpus",
      "name_variants": [
        "EventStoryLine Corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The EventStoryLine Corpus is used for annotating and identifying event causality in 320 short stories, focusing on temporal and causal relations. It serves as a foundational resource for annotating events, enabling research into the structure and dynamics of narrative causality and temporality. This dataset facilitates the study of how events are interconnected in narratives, supporting the development of models that can understand and predict event relationships."
    },
    {
      "display_name": "BECauSE 2.0",
      "normalized_name": "because20",
      "name_variants": [
        "BECauSE 2.0"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "BECauSE 2.0 is used to annotate causal and overlapping relations, expanding upon the original BE-CauSE corpus. This enhanced dataset supports research by providing detailed annotations that capture complex relationships within documents, facilitating more nuanced analysis of causal structures. The additional annotations enable researchers to explore and model intricate event interactions, improving the accuracy and depth of document-level event extraction studies."
    },
    {
      "display_name": "event corpus",
      "normalized_name": "event",
      "name_variants": [
        "event corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 'event corpus' dataset is used for training and developing models to mine biomedical events from literature. It focuses on event extraction and annotation, enabling researchers to identify and categorize specific events within biomedical texts. This dataset supports the development of more accurate and efficient event mining tools, enhancing the analysis of biomedical literature."
    },
    {
      "display_name": "TimeBank-Dense",
      "normalized_name": "timebankdense",
      "name_variants": [
        "TimeBank-Dense"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The TimeBank-Dense dataset is used to augment TDD-Man with TLINK annotations for event pairs more than one sentence apart, enhancing document-level event extraction. This augmentation improves the representation of temporal relationships between events, enabling more accurate and nuanced extraction of event sequences in documents."
    },
    {
      "display_name": "Penn Discourse Treebank",
      "normalized_name": "penndiscoursetreebank",
      "name_variants": [
        "Penn Discourse Treebank"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Penn Discourse Treebank is used to annotate and analyze explicit and implicit causal relations between discourse units, providing a structured resource for studying discourse structure and causality in text. It offers a detailed representation of rhetorical structures, enabling researchers to explore discourse relations and support natural language processing tasks."
    },
    {
      "display_name": "Event Coreference Bank+",
      "normalized_name": "eventcoreferencebank",
      "name_variants": [
        "Event Coreference Bank+"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Event Coreference Bank+ dataset is used for annotating and resolving causal and temporal relations between events in text. It focuses on event coreference resolution, linking events that refer to the same situation within documents, and studying cause-effect relationships, particularly in biomedical texts. This dataset enables researchers to analyze and model complex event interactions, enhancing understanding of textual narratives and scientific literature."
    },
    {
      "display_name": "RAMS development set",
      "normalized_name": "ramsdevelopmentset",
      "name_variants": [
        "RAMS development set"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The RAMS development set is used for hyper-parameter tuning during the fine-tuning process, specifically to optimize the batch size for event extraction. This dataset enables researchers to refine model performance by adjusting key parameters, ensuring more effective and efficient event extraction from documents."
    },
    {
      "display_name": "RED",
      "normalized_name": "red",
      "name_variants": [
        "RED"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The RED dataset is primarily used for document-level event extraction, supporting various aspects of event annotation such as narrative, causal, and temporal relations. It is employed to evaluate and enhance the accuracy of event co-reference, richer event descriptions, and narrative understanding in natural language texts, including short stories and social media. The dataset facilitates the analysis of causal and temporal connections, improving the coherence and structure of event annotations across documents."
    },
    {
      "display_name": "CDG",
      "normalized_name": "cdg",
      "name_variants": [
        "CDG"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The CDG dataset is used to evaluate relation extraction performance, particularly in enhancing interpretability and improving evidence retrieval F1 scores. It focuses on extracting binary interactions, such as chemical-disease and gene-disease relationships, from large document sets (1,500 and 30,192 documents, respectively). This dataset enables researchers to study and improve the accuracy of extracting specific biomedical interactions from literature."
    },
    {
      "display_name": "MEANTIME",
      "normalized_name": "meantime",
      "name_variants": [
        "MEANTIME"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The MEANTIME dataset is primarily used for evaluating and training event coreference systems, focusing on cross-document event linking and coreference resolution in news articles and government/political texts. It supports multilingual event and time annotation, enhancing cross-lingual event extraction and temporal relation analysis. The dataset is also applied to study specific domains like gun violence, extracting and analyzing event mentions and their contexts. Its rich annotations enable detailed research into document-level event extraction and temporal relations."
    },
    {
      "display_name": "TAC KBP 2016",
      "normalized_name": "tackbp2016",
      "name_variants": [
        "TAC KBP 2016"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The TAC KBP 2016 dataset is used to evaluate and compare model performance in document-level event extraction, specifically focusing on methodologies and metrics from the competition. It enables researchers to benchmark their systems against top-performing models, facilitating advancements in event extraction techniques and evaluation strategies."
    },
    {
      "display_name": "MUC1",
      "normalized_name": "muc1",
      "name_variants": [
        "MUC1"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The MUC1 dataset is used to simplify the event-based template-filling task, focusing on methodologies for message understanding and event extraction. It enables researchers to develop and evaluate systems that can accurately identify and extract events from documents, enhancing the precision of information retrieval and processing in natural language understanding tasks."
    },
    {
      "display_name": "WDW (Who Did What)",
      "normalized_name": "wdwwhodidwhat",
      "name_variants": [
        "WDW (Who Did What)"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The WDW (Who Did What) dataset is used for person-centered cloze tests, specifically to identify actions performed by individuals in news articles. This enhances event extraction capabilities by focusing on the roles and activities of people, improving the accuracy and context of event identification in textual data."
    },
    {
      "display_name": "SCIERC",
      "normalized_name": "scierc",
      "name_variants": [
        "SCIERC"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The SCIERC dataset is used to train and evaluate models for identifying entities, relations, and coreferences in scientific abstracts. This enhances the construction of scientific knowledge graphs by focusing on information extraction from scientific article abstracts. The dataset supports methodologies involving entity recognition, relation extraction, and coreference resolution, enabling researchers to improve the accuracy and comprehensiveness of scientific knowledge graph construction."
    },
    {
      "display_name": "TDDMan",
      "normalized_name": "tddman",
      "name_variants": [
        "TDDMan"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The TDDMan dataset is used to evaluate and benchmark models for document-level event extraction, focusing on state-of-the-art performance metrics such as F1 scores. It specifically assesses the temporal ordering of events with uncertainty-guided graph completion, enabling researchers to compare and improve model performance through joint constrained learning methods and benchmarking tests."
    },
    {
      "display_name": "Language Understanding Annotation Corpus",
      "normalized_name": "languageunderstandingannotationcorpus",
      "name_variants": [
        "Language Understanding Annotation Corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Language Understanding Annotation Corpus is used to annotate textual data for modality in event factuality, focusing on the author's committed belief towards reported information. It also annotates degrees of certainty in knowledge-intensive contexts, capturing nuanced levels of belief and confidence. This dataset enables researchers to analyze and model the complexities of linguistic expressions of certainty and belief, enhancing natural language understanding systems."
    },
    {
      "display_name": "FEVER",
      "normalized_name": "fever",
      "name_variants": [
        "FEVER"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The FEVER dataset is primarily used for fact extraction and verification, supporting research in validating claims against textual evidence. It provides a large-scale resource that enables the development and testing of algorithms designed to verify the accuracy of statements by cross-referencing them with supporting documents. This dataset facilitates the advancement of natural language processing techniques in the domain of automated fact-checking."
    },
    {
      "display_name": "RAMS argument linking dataset",
      "normalized_name": "ramsargumentlinking",
      "name_variants": [
        "RAMS argument linking dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The RAMS argument linking dataset is used for document-level event extraction, focusing on identifying and linking argument structures across multiple sentences. It evaluates models on discourse-level tasks, including joint modeling of arguments and ablation studies to assess performance. The dataset enhances understanding of complex event structures by considering non-local arguments and their relationships in the document context, particularly useful for anaphora resolution and multi-sentence argument linking."
    },
    {
      "display_name": "New York Times corpus",
      "normalized_name": "newyorktimes",
      "name_variants": [
        "New York Times corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The New York Times corpus is used as a structured knowledge base for entity and relation matching, enhancing semantic understanding in text. It serves as a common relation extraction dataset, particularly for extracting relations from news articles. The corpus is also utilized to match entities and relations to the Freebase Knowledge Base, supporting document-level event extraction and relation identification. This enables researchers to improve the accuracy and depth of semantic analysis in natural language processing tasks."
    },
    {
      "display_name": "TimeBank",
      "normalized_name": "timebank",
      "name_variants": [
        "TimeBank"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The TimeBank dataset is used to refine and improve the accuracy and consistency of temporal annotations in event temporal relations. It supports the MATRES project by enhancing multi-axis annotation schemes, which are crucial for identifying and understanding temporal relations between events. This dataset enables researchers to conduct experiments and develop more precise methods for temporal relation identification."
    },
    {
      "display_name": "NYT10",
      "normalized_name": "nyt10",
      "name_variants": [
        "NYT10"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The NYT10 dataset is used to enhance semantic understanding by matching entities and relations from the New York Times corpus to the Freebase Knowledge Base. It focuses on document-level event extraction and relation identification, serving as a structured knowledge base that improves the accuracy and depth of textual analysis in research."
    },
    {
      "display_name": "TA-CRED",
      "normalized_name": "tacred",
      "name_variants": [
        "TA-CRED"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The TA-CRED dataset is re-annotated to enhance relation extraction accuracy, particularly addressing challenging samples in the development and test sets. This focus improves the reliability of relation extraction models, enabling more precise identification of relationships within documents. The dataset's refined annotations support research aimed at enhancing the performance and robustness of natural language processing systems in handling complex textual data."
    },
    {
      "display_name": "ACE Challenge dataset",
      "normalized_name": "acechallenge",
      "name_variants": [
        "ACE Challenge dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The ACE Challenge dataset is primarily used for document-level event extraction, focusing on identifying and classifying events and entities in text. It serves as a benchmark for comparing the efficiency and scale of automatically generated datasets, highlighting issues in argument extraction, particularly with pronouns. The dataset is also used to enhance the accuracy of event extraction by computing importance values for arguments and selecting key arguments for each event type. It supports research in named entity recognition, relation extraction, and cross-document coreference, facilitating the evaluation of systems' performance in handling complex linguistic structures."
    },
    {
      "display_name": "KEGG",
      "normalized_name": "kegg",
      "name_variants": [
        "KEGG"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The KEGG dataset is used to create distantly supervised datasets for event descriptions, primarily focusing on biological pathways and their interactions. It provides detailed pathway annotations and signaling pathway data, which are utilized to train models like BEEDS. This enables researchers to extract and describe events from biological pathways, contributing to the development of knowledge bases in systems biology."
    },
    {
      "display_name": "GLACIER",
      "normalized_name": "glacier",
      "name_variants": [
        "GLACIER"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The GLACIER dataset is used to enhance information extraction by jointly considering phrasal and sentential evidence, which improves the model's ability to capture contextual information. This approach is applied to refine the accuracy and depth of extracted information, focusing on the integration of multi-level linguistic features."
    },
    {
      "display_name": "CausalTimeBank (CTB)",
      "normalized_name": "causaltimebankctb",
      "name_variants": [
        "CausalTimeBank (CTB)"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The CausalTimeBank (CTB) dataset is primarily used to annotate and analyze causal and temporal relations in texts, including short stories and news articles. It provides annotated data for document-level event extraction, focusing on event causality and temporal dynamics. The dataset contains 1,770 instances for event pair analysis and 488 causal links, enabling researchers to study event chains, narrative structures, and the chronological and causal connections between events. This resource is crucial for training and evaluating systems that extract and classify events, enhancing the understanding of complex event relationships in various textual contexts."
    },
    {
      "display_name": "80Days",
      "normalized_name": "80days",
      "name_variants": [
        "80Days"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 80Days dataset is used for annotating implicit arguments in semantic role labeling, focusing on a diverse set of texts and contexts. This dataset enables researchers to explore the nuances of implicit argument identification, enhancing the accuracy of semantic role labeling models across various textual genres and scenarios."
    },
    {
      "display_name": "AESPEN",
      "normalized_name": "aespen",
      "name_variants": [
        "AESPEN"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The AESPEN dataset is utilized for the automated extraction of socio-political events from text, particularly in multilingual settings. It is employed to extract and classify socio-political events from news articles, with a focus on detecting protests and other events across multiple languages. This dataset enables researchers to address challenges in multilingual event extraction and classification, enhancing the accuracy and scope of socio-political event analysis in diverse linguistic contexts."
    },
    {
      "display_name": "ACE EE",
      "normalized_name": "aceee",
      "name_variants": [
        "ACE EE"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The ACE EE dataset is used to evaluate model performance on event extraction tasks, specifically achieving a 70.1% F1 score. This dataset enables researchers to assess and compare the effectiveness of different models in identifying events within documents, providing a standardized benchmark for performance evaluation."
    },
    {
      "display_name": "EventStoryLine",
      "normalized_name": "eventstoryline",
      "name_variants": [
        "EventStoryLine"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The EventStoryLine dataset is used as a benchmark for extracting causal and temporal relations between events in documents. It involves 258 documents and 4316 sentences, focusing on event mention pairs. Researchers employ it to compare models, including a dummy model and a dependency path-based LSTM, addressing inter-sentence event relations in document-level event extraction."
    },
    {
      "display_name": "WordNet 3.0",
      "normalized_name": "wordnet30",
      "name_variants": [
        "WordNet 3.0"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "WordNet 3.0 is used to perform word-synset mapping, leveraging its lexical structure to enhance word sense disambiguation, particularly in the context of event causality recognition. This methodology involves utilizing the dataset's rich semantic relationships to improve the accuracy of identifying causal relationships between events in text. The dataset's comprehensive lexical entries and hierarchical organization enable researchers to address complex linguistic challenges in natural language processing tasks."
    },
    {
      "display_name": "DARPA DEFT Program’s Light Entities, Relations and Events (Light ERE) task",
      "normalized_name": "darpadeftprogramslightentitiesrelationsandeventstask",
      "name_variants": [
        "DARPA DEFT Program’s Light Entities, Relations and Events (Light ERE) task"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The DARPA DEFT Program’s Light ERE task dataset is used for event and event argument annotation in both formal newswire and informal discussion forum texts. It facilitates the comparison and integration of different annotation styles, enabling comprehensive event extraction across varied text types. This dataset supports research into the consistency and applicability of annotation methods in diverse textual contexts."
    },
    {
      "display_name": "KnowDis",
      "normalized_name": "knowdis",
      "name_variants": [
        "KnowDis"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The KnowDis dataset is used for knowledge-enhanced data augmentation in event causality detection. It leverages distant supervision to improve model performance, enhancing the accuracy and reliability of causal relationships identified in textual data. This approach specifically addresses the challenge of detecting event causality in documents, utilizing the dataset's rich annotations and structured knowledge to augment training data and refine machine learning models."
    },
    {
      "display_name": "financial news from Reuters and Bloomberg",
      "normalized_name": "financialnewsfromreutersandbloomberg",
      "name_variants": [
        "financial news from Reuters and Bloomberg"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The financial news dataset from Reuters and Bloomberg is used to predict stock price movements by analyzing structured events in news articles from October 2006 to November 2013. Researchers employ methodologies that focus on extracting and structuring event data from these articles to forecast market trends. This dataset enables the identification of key financial events and their impact on stock prices, providing insights into market dynamics and predictive modeling."
    },
    {
      "display_name": "Freebase",
      "normalized_name": "freebase",
      "name_variants": [
        "Freebase"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "Freebase is used as a source of external structured knowledge to enhance document-level event extraction, incorporating information from Wikipedia and WordNet. It provides additional context and structured human knowledge, which improves the generation of event representations and enhances the model's understanding during the learning process."
    },
    {
      "display_name": "CauSE corpus",
      "normalized_name": "cause",
      "name_variants": [
        "CauSE corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The CauSE corpus is used to annotate causal and other relations in text, serving as a foundational resource for studying linguistic constructions of causality. It enhances the original BECauSE corpus with additional data and annotations, focusing on corpus lexicography to improve the understanding of linguistic patterns and constructions. This dataset enables researchers to analyze and annotate causal relationships, contributing to the field of corpus linguistics and the study of causal language structures."
    },
    {
      "display_name": "ESC",
      "normalized_name": "esc",
      "name_variants": [
        "ESC"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The ESC dataset is used to analyze event causality and temporal relationships in documents. It focuses on the interplay between events and their causal implications, as well as the timing of these events. Researchers use it to study how events are connected and influence each other over time, specifically examining 184 documents. This dataset enables detailed analysis of event dynamics and temporal sequences, providing insights into the structure and causality of events within texts."
    },
    {
      "display_name": "CoNLL-2009 Chinese",
      "normalized_name": "conll2009chinese",
      "name_variants": [
        "CoNLL-2009 Chinese"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The CoNLL-2009 Chinese dataset is used for training, development, and testing in experiments focused on syntactic and semantic dependencies. It follows the CoNLL-2009 shared task data splits, enabling researchers to evaluate models on these linguistic tasks. This dataset supports the development of algorithms that can accurately identify and analyze dependency structures in Chinese text, facilitating advancements in natural language processing."
    },
    {
      "display_name": "distantly labeled training data",
      "normalized_name": "distantlylabeledtraining",
      "name_variants": [
        "distantly labeled training data"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 'distantly labeled training data' dataset is used to train models for event causality detection, specifically enhancing ECI (Event Causality Identification). This is achieved through distant supervision, where the dataset provides labeled examples to improve model performance. The dataset's labeled examples facilitate the training process, enabling more accurate identification of causal relationships between events in documents."
    },
    {
      "display_name": "CoNLL-2009 Chinese and English test data",
      "normalized_name": "conll2009chineseandenglishtest",
      "name_variants": [
        "CoNLL-2009 Chinese and English test data"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The CoNLL-2009 Chinese and English test data is used to evaluate the performance of the JMEE and JMEE(–GCN) models on document-level event extraction. Specifically, it assesses the effectiveness of Graph Convolutional Networks (GCN) in encoding contextual information. This dataset enables researchers to compare model performance and analyze the impact of GCN on event extraction accuracy."
    },
    {
      "display_name": "HiEve",
      "normalized_name": "hieve",
      "name_variants": [
        "HiEve"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The HiEve dataset is used to evaluate models on subevent relation extraction, focusing on the temporal ordering of events in document-level event extraction. It maintains consistency with prior work and is employed to compare performance metrics across different approaches, ensuring robust evaluation and benchmarking in this specific research area."
    }
  ]
}