{
  "results": [
    {
      "context_text": "Experiments demonstrate that CMNEE is challenging and event extraction in military domain remains an open issue.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general challenge in the military domain. No verifiable resources are identified.",
      "processing_time": 19.743167400360107,
      "citing_paper_id": "269214164",
      "cited_paper_id": 2563759
    },
    {
      "context_text": "Experiments demonstrate that CMNEE is challenging and event extraction in military domain remains an open issue.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general challenge in the military domain. No verifiable resources are identified.",
      "processing_time": 19.743167400360107,
      "citing_paper_id": "269214164",
      "cited_paper_id": 265659367
    },
    {
      "context_text": "There are also some datasets oriented to other specific domains, such as biomedical domain (Pyysalo et al., 2013), literary domain (Sims et al., 2019), terror-ist attack events (Grishman and Sundheim, 1996), breaking news (Fu et al., 2010), etc.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Message Understanding Conference-6"
      ],
      "dataset_descriptions": {
        "Message Understanding Conference-6": "Used to evaluate systems for processing and understanding terrorist attack events, focusing on information extraction and event detection methodologies."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions several domain-specific datasets but does not provide specific names. Only 'Message Understanding Conference-6' is a specific, identifiable dataset.",
      "processing_time": 23.740375995635986,
      "citing_paper_id": "269214164",
      "cited_paper_id": 2563759
    },
    {
      "context_text": "There are also some datasets oriented to other specific domains, such as biomedical domain (Pyysalo et al., 2013), literary domain (Sims et al., 2019), terror-ist attack events (Grishman and Sundheim, 1996), breaking news (Fu et al., 2010), etc.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Message Understanding Conference-6"
      ],
      "dataset_descriptions": {
        "Message Understanding Conference-6": "Used to evaluate systems for processing and understanding terrorist attack events, focusing on information extraction and event detection methodologies."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions several domain-specific datasets but does not provide specific names. Only 'Message Understanding Conference-6' is a specific, identifiable dataset.",
      "processing_time": 23.740375995635986,
      "citing_paper_id": "269214164",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "There are also some datasets oriented to other specific domains, such as biomedical domain (Pyysalo et al., 2013), literary domain (Sims et al., 2019), terror-ist attack events (Grishman and Sundheim, 1996), breaking news (Fu et al., 2010), etc.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Message Understanding Conference-6"
      ],
      "dataset_descriptions": {
        "Message Understanding Conference-6": "Used to evaluate systems for processing and understanding terrorist attack events, focusing on information extraction and event detection methodologies."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions several domain-specific datasets but does not provide specific names. Only 'Message Understanding Conference-6' is a specific, identifiable dataset.",
      "processing_time": 23.740375995635986,
      "citing_paper_id": "269214164",
      "cited_paper_id": 196201373
    },
    {
      "context_text": "Moreover, most existing event extraction datasets are oriented towards general (Li et al., 2020, 2021a) or financial domains (Han et al., 2022a; Zheng et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'event extraction datasets' but does not specify any particular dataset names. The cited papers provide additional context, but no specific dataset names are mentioned in the citation span.",
      "processing_time": 32.031126976013184,
      "citing_paper_id": "269214164",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Moreover, most existing event extraction datasets are oriented towards general (Li et al., 2020, 2021a) or financial domains (Han et al., 2022a; Zheng et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'event extraction datasets' but does not specify any particular dataset names. The cited papers provide additional context, but no specific dataset names are mentioned in the citation span.",
      "processing_time": 32.031126976013184,
      "citing_paper_id": "269214164",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Moreover, most existing event extraction datasets are oriented towards general (Li et al., 2020, 2021a) or financial domains (Han et al., 2022a; Zheng et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'event extraction datasets' but does not specify any particular dataset names. The cited papers provide additional context, but no specific dataset names are mentioned in the citation span.",
      "processing_time": 32.031126976013184,
      "citing_paper_id": "269214164",
      "cited_paper_id": 252569165
    },
    {
      "context_text": "ChfinAnn (Zheng et al., 2019) is constructed using distant supervision to assist in the construction, with a sizable scale, but it does not contain event trigger information, and can only be used for the event argument extraction task.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChfinAnn"
      ],
      "dataset_descriptions": {
        "ChfinAnn": "Used for Chinese financial event argument extraction, constructed using distant supervision. Lacks event trigger information, suitable only for argument extraction tasks."
      },
      "confidence_score": 0.9,
      "reasoning": "ChfinAnn is identified as a dataset used for Chinese financial event argument extraction, constructed using distant supervision. It lacks event trigger information, limiting its use.",
      "processing_time": 35.04845905303955,
      "citing_paper_id": "269214164",
      "cited_paper_id": 119308902
    },
    {
      "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN",
        "DuEE",
        "MNEE",
        "RAMS",
        "WikiEvents",
        "Duee-fin",
        "ChfinAnn",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models.",
        "DuEE": "Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
        "MNEE": "Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences.",
        "RAMS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance.",
        "WikiEvents": "Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation.",
        "Duee-fin": "Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents.",
        "ChfinAnn": "Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain.",
        "Do-cEE": "Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
      "processing_time": 62.24152708053589,
      "citing_paper_id": "269214164",
      "cited_paper_id": 119308902
    },
    {
      "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN",
        "DuEE",
        "MNEE",
        "RAMS",
        "WikiEvents",
        "Duee-fin",
        "ChfinAnn",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models.",
        "DuEE": "Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
        "MNEE": "Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences.",
        "RAMS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance.",
        "WikiEvents": "Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation.",
        "Duee-fin": "Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents.",
        "ChfinAnn": "Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain.",
        "Do-cEE": "Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
      "processing_time": 62.24152708053589,
      "citing_paper_id": "269214164",
      "cited_paper_id": 207853145
    },
    {
      "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN",
        "DuEE",
        "MNEE",
        "RAMS",
        "WikiEvents",
        "Duee-fin",
        "ChfinAnn",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models.",
        "DuEE": "Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
        "MNEE": "Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences.",
        "RAMS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance.",
        "WikiEvents": "Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation.",
        "Duee-fin": "Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents.",
        "ChfinAnn": "Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain.",
        "Do-cEE": "Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
      "processing_time": 62.24152708053589,
      "citing_paper_id": "269214164",
      "cited_paper_id": 216562779
    },
    {
      "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN",
        "DuEE",
        "MNEE",
        "RAMS",
        "WikiEvents",
        "Duee-fin",
        "ChfinAnn",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models.",
        "DuEE": "Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
        "MNEE": "Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences.",
        "RAMS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance.",
        "WikiEvents": "Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation.",
        "Duee-fin": "Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents.",
        "ChfinAnn": "Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain.",
        "Do-cEE": "Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
      "processing_time": 62.24152708053589,
      "citing_paper_id": "269214164",
      "cited_paper_id": 233219850
    },
    {
      "context_text": ", MAVEN (Wang et al., 2020), DuEE (Li et al., 2020), MNEE (Huang et al., 2023b) and document-level event extraction datasets, RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021b), Duee-fin (Han et al., 2022b), ChfinAnn (Zheng et al., 2019), Do-cEE (Tong et al., 2022",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN",
        "DuEE",
        "MNEE",
        "RAMS",
        "WikiEvents",
        "Duee-fin",
        "ChfinAnn",
        "Do-cEE"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used for general domain event detection, providing a large-scale dataset for training and evaluating event extraction models.",
        "DuEE": "Used for fine-grained document-level event extraction, particularly in financial contexts, to train and evaluate models.",
        "MNEE": "Used for multi-sentence argument linking in document-level event extraction, enhancing the ability to link arguments across sentences.",
        "RAMS": "Used for document-level event argument extraction, focusing on conditional generation methods to improve model performance.",
        "WikiEvents": "Used for document-level event extraction, providing a diverse set of events and arguments for training and evaluation.",
        "Duee-fin": "Used for financial event extraction, focusing on fine-grained event types and arguments in financial documents.",
        "ChfinAnn": "Used for Chinese financial event annotation, providing a specialized dataset for training and evaluating models in the financial domain.",
        "Do-cEE": "Used for document-level event extraction, offering a benchmark for evaluating models on complex, multi-event documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets specifically designed for event extraction, including document-level event extraction. These datasets are clearly identified and used for training and evaluation in the research.",
      "processing_time": 62.24152708053589,
      "citing_paper_id": "269214164",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Extraction of military events from documents is crucial to downstream applications such as intelligence analysis (Santucci, 2022; Bang, 2016; Freed-man, 1983; Ivanov, 2011), decision making assistance (Skryabina et al., 2020), and strategic planning (Schrodt, 2012; Sankar, 2023; Lyu, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction in military contexts. No verifiable resources are identified.",
      "processing_time": 19.12061095237732,
      "citing_paper_id": "269214164",
      "cited_paper_id": 154230030
    },
    {
      "context_text": "Extraction of military events from documents is crucial to downstream applications such as intelligence analysis (Santucci, 2022; Bang, 2016; Freed-man, 1983; Ivanov, 2011), decision making assistance (Skryabina et al., 2020), and strategic planning (Schrodt, 2012; Sankar, 2023; Lyu, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction in military contexts. No verifiable resources are identified.",
      "processing_time": 19.12061095237732,
      "citing_paper_id": "269214164",
      "cited_paper_id": 154992508
    },
    {
      "context_text": "Extraction of military events from documents is crucial to downstream applications such as intelligence analysis (Santucci, 2022; Bang, 2016; Freed-man, 1983; Ivanov, 2011), decision making assistance (Skryabina et al., 2020), and strategic planning (Schrodt, 2012; Sankar, 2023; Lyu, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction in military contexts. No verifiable resources are identified.",
      "processing_time": 19.12061095237732,
      "citing_paper_id": "269214164",
      "cited_paper_id": 213428800
    },
    {
      "context_text": "Extraction of military events from documents is crucial to downstream applications such as intelligence analysis (Santucci, 2022; Bang, 2016; Freed-man, 1983; Ivanov, 2011), decision making assistance (Skryabina et al., 2020), and strategic planning (Schrodt, 2012; Sankar, 2023; Lyu, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction in military contexts. No verifiable resources are identified.",
      "processing_time": 19.12061095237732,
      "citing_paper_id": "269214164",
      "cited_paper_id": null
    },
    {
      "context_text": "For the document-level event extraction task, the commonly used datasets are RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021a), with a smaller number of documents, 9124 and 246, respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event extraction, containing 9124 documents. It serves as a larger-scale resource for training and evaluating event extraction models.",
        "WikiEvents": "Used for document-level event extraction, containing 246 documents. It provides a smaller, more focused dataset for detailed analysis and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for document-level event extraction. Both have clear identifiers and are relevant to the research topic.",
      "processing_time": 31.33611488342285,
      "citing_paper_id": "269214164",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "For the document-level event extraction task, the commonly used datasets are RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021a), with a smaller number of documents, 9124 and 246, respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event extraction, containing 9124 documents. It serves as a larger-scale resource for training and evaluating event extraction models.",
        "WikiEvents": "Used for document-level event extraction, containing 246 documents. It provides a smaller, more focused dataset for detailed analysis and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for document-level event extraction. Both have clear identifiers and are relevant to the research topic.",
      "processing_time": 31.33611488342285,
      "citing_paper_id": "269214164",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "(Du and Cardie, 2020) converted the event extraction task into the natural question answering task.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for converting event extraction into a question answering task.",
      "processing_time": 17.121347188949585,
      "citing_paper_id": "269214164",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Evaluation Following the widely-used setting, we report the micro Precision, Recall, and F-1 scores for event detection and event argument extraction as our evaluation metrics (Wang et al., 2020; Tong et al., 2022).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets by name. It only refers to evaluation metrics and cites papers that could potentially contain relevant datasets.",
      "processing_time": 17.380101203918457,
      "citing_paper_id": "269214164",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "Evaluation Following the widely-used setting, we report the micro Precision, Recall, and F-1 scores for event detection and event argument extraction as our evaluation metrics (Wang et al., 2020; Tong et al., 2022).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets by name. It only refers to evaluation metrics and cites papers that could potentially contain relevant datasets.",
      "processing_time": 17.380101203918457,
      "citing_paper_id": "269214164",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Attack” category, while the MAVEN dataset includes categories like “Attack” and “Defending”.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used to evaluate event detection models, specifically focusing on categories like 'Attack' and 'Defending'. The dataset supports general domain event detection tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MAVEN dataset, which is a specific, verifiable dataset used for event detection. The dataset is clearly identified and used in the research context.",
      "processing_time": 37.28408432006836,
      "citing_paper_id": "269214164",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "MAVEN (Wang et al., 2020) is the largest event detection dataset, which defines 168 event types and labels 19,640 events.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used to train and evaluate event detection models, focusing on a wide range of event types across general domains."
      },
      "confidence_score": 1.0,
      "reasoning": "MAVEN is identified as a dataset in the context, with specific details about its size and content.",
      "processing_time": 34.41948986053467,
      "citing_paper_id": "269214164",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "…text, which is typically separated into two subtasks: event detection and event argument extraction (Ahn, 2006; Yang et al., 2019; Xu et al., 2023; Wang et al., 2021b; Shi et al., 2023; Yang et al., 2023; Wan et al., 2023; Liu et al., 2020; Chu et al., 2023; Peng et al., 2023; Wang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only subtasks in event extraction. No dataset names are present in the text.",
      "processing_time": 16.767024993896484,
      "citing_paper_id": "269214164",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "…text, which is typically separated into two subtasks: event detection and event argument extraction (Ahn, 2006; Yang et al., 2019; Xu et al., 2023; Wang et al., 2021b; Shi et al., 2023; Yang et al., 2023; Wan et al., 2023; Liu et al., 2020; Chu et al., 2023; Peng et al., 2023; Wang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only subtasks in event extraction. No dataset names are present in the text.",
      "processing_time": 16.767024993896484,
      "citing_paper_id": "269214164",
      "cited_paper_id": 235254286
    },
    {
      "context_text": "…text, which is typically separated into two subtasks: event detection and event argument extraction (Ahn, 2006; Yang et al., 2019; Xu et al., 2023; Wang et al., 2021b; Shi et al., 2023; Yang et al., 2023; Wan et al., 2023; Liu et al., 2020; Chu et al., 2023; Peng et al., 2023; Wang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only subtasks in event extraction. No dataset names are present in the text.",
      "processing_time": 16.767024993896484,
      "citing_paper_id": "269214164",
      "cited_paper_id": 258378242
    },
    {
      "context_text": "…text, which is typically separated into two subtasks: event detection and event argument extraction (Ahn, 2006; Yang et al., 2019; Xu et al., 2023; Wang et al., 2021b; Shi et al., 2023; Yang et al., 2023; Wan et al., 2023; Liu et al., 2020; Chu et al., 2023; Peng et al., 2023; Wang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only subtasks in event extraction. No dataset names are present in the text.",
      "processing_time": 16.767024993896484,
      "citing_paper_id": "269214164",
      "cited_paper_id": 262825274
    },
    {
      "context_text": "6 ) TEXT2EVENT (Lu et al., 2021) is a sequence-to-structure generation paradigm that can directly extract events from the text in an end-to-end manner.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation describes a method (Text2Event) rather than a dataset. No specific dataset is mentioned or used in the context.",
      "processing_time": 17.08455753326416,
      "citing_paper_id": "269214164",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "Most of these models use sentence-level text for analysis, and while sentence-level event extraction research is relatively mature (Gao, 2021; Hsu et al., 2021; Huang et al., 2023a), this technology struggles when directly applied to document-level event extraction tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the limitations of applying sentence-level event extraction to document-level tasks.",
      "processing_time": 28.791024923324585,
      "citing_paper_id": "269214164",
      "cited_paper_id": 237353175
    },
    {
      "context_text": "Most of these models use sentence-level text for analysis, and while sentence-level event extraction research is relatively mature (Gao, 2021; Hsu et al., 2021; Huang et al., 2023a), this technology struggles when directly applied to document-level event extraction tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the limitations of applying sentence-level event extraction to document-level tasks.",
      "processing_time": 28.791024923324585,
      "citing_paper_id": "269214164",
      "cited_paper_id": null
    },
    {
      "context_text": "Currently, the FewFC dataset is the main dataset used for the study of overlapping events (Sheng et al., 2021; Cao et al., 2022), but the size of this dataset is relatively small, in which only 18% of the instances contain overlapping events, and its annotation is based on sentences.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewFC"
      ],
      "dataset_descriptions": {
        "FewFC": "Used to study overlapping events, but its size is small, with only 18% of instances containing overlapping events, and annotations are sentence-based."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the FewFC dataset, which is used for studying overlapping events. It provides details about the dataset's size and annotation method.",
      "processing_time": 36.47117042541504,
      "citing_paper_id": "269214164",
      "cited_paper_id": 252089843
    },
    {
      "context_text": "Recently, there have been some efforts using ChatGPT for data annotation in areas like Named Entity Recognition and Relation Extraction, as indicated in references (Ding et al., 2022; Goel et al., 2023; Zhang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of ChatGPT for data annotation in NER and Relation Extraction.",
      "processing_time": 29.539286136627197,
      "citing_paper_id": "269214164",
      "cited_paper_id": 254877171
    },
    {
      "context_text": "Recently, there have been some efforts using ChatGPT for data annotation in areas like Named Entity Recognition and Relation Extraction, as indicated in references (Ding et al., 2022; Goel et al., 2023; Zhang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of ChatGPT for data annotation in NER and Relation Extraction.",
      "processing_time": 29.539286136627197,
      "citing_paper_id": "269214164",
      "cited_paper_id": 264814421
    },
    {
      "context_text": "To comprehensively evaluate our dataset and demonstrate its potential in financial DEE tasks, we selected the following models as baselines: • DCFEE [19] employs an argument-completion strategy and critical event detection techniques to generate document-levelevent records.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'DCFEE' as a baseline model, not a dataset. No specific dataset is mentioned in the citation span.",
      "processing_time": 29.519147157669067,
      "citing_paper_id": "269762511",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "This comparison spans sentence-level datasets (such as ACE2005 [2] and DuEE [10]) to document-level datasets (such as MUC-4 [4], RAMS [3], DCFEE [19], ChFinAnn [23], FEED [7] and DuEE-Fin [5]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "RAMS",
        "DCFEE",
        "ChFinAnn",
        "FEED",
        "DuEE-Fin"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate document-level event extraction, focusing on complex event structures and cross-sentence relations.",
        "RAMS": "Used to assess document-level event extraction, emphasizing diverse event types and argument roles across multiple sentences.",
        "DCFEE": "Used to train and evaluate document-level financial event extraction systems, leveraging automatically labeled training data.",
        "ChFinAnn": "Used to study document-level event extraction in Chinese financial documents, focusing on specific financial events and their contexts.",
        "FEED": "Used to evaluate document-level event extraction, particularly in financial news articles, focusing on event detection and argument linking.",
        "DuEE-Fin": "Used to train and evaluate document-level event extraction in financial documents, providing a large-scale dataset for comprehensive analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets used for document-level event extraction, which are directly relevant to the research topic.",
      "processing_time": 48.88067173957825,
      "citing_paper_id": "269762511",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "This comparison spans sentence-level datasets (such as ACE2005 [2] and DuEE [10]) to document-level datasets (such as MUC-4 [4], RAMS [3], DCFEE [19], ChFinAnn [23], FEED [7] and DuEE-Fin [5]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "RAMS",
        "DCFEE",
        "ChFinAnn",
        "FEED",
        "DuEE-Fin"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate document-level event extraction, focusing on complex event structures and cross-sentence relations.",
        "RAMS": "Used to assess document-level event extraction, emphasizing diverse event types and argument roles across multiple sentences.",
        "DCFEE": "Used to train and evaluate document-level financial event extraction systems, leveraging automatically labeled training data.",
        "ChFinAnn": "Used to study document-level event extraction in Chinese financial documents, focusing on specific financial events and their contexts.",
        "FEED": "Used to evaluate document-level event extraction, particularly in financial news articles, focusing on event detection and argument linking.",
        "DuEE-Fin": "Used to train and evaluate document-level event extraction in financial documents, providing a large-scale dataset for comprehensive analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets used for document-level event extraction, which are directly relevant to the research topic.",
      "processing_time": 48.88067173957825,
      "citing_paper_id": "269762511",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "This comparison spans sentence-level datasets (such as ACE2005 [2] and DuEE [10]) to document-level datasets (such as MUC-4 [4], RAMS [3], DCFEE [19], ChFinAnn [23], FEED [7] and DuEE-Fin [5]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "RAMS",
        "DCFEE",
        "ChFinAnn",
        "FEED",
        "DuEE-Fin"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate document-level event extraction, focusing on complex event structures and cross-sentence relations.",
        "RAMS": "Used to assess document-level event extraction, emphasizing diverse event types and argument roles across multiple sentences.",
        "DCFEE": "Used to train and evaluate document-level financial event extraction systems, leveraging automatically labeled training data.",
        "ChFinAnn": "Used to study document-level event extraction in Chinese financial documents, focusing on specific financial events and their contexts.",
        "FEED": "Used to evaluate document-level event extraction, particularly in financial news articles, focusing on event detection and argument linking.",
        "DuEE-Fin": "Used to train and evaluate document-level event extraction in financial documents, providing a large-scale dataset for comprehensive analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets used for document-level event extraction, which are directly relevant to the research topic.",
      "processing_time": 48.88067173957825,
      "citing_paper_id": "269762511",
      "cited_paper_id": 252569165
    },
    {
      "context_text": "In 2018, Yang et al. [19] constructed the first document-level Chinese event extraction dataset in the financial field, DCFEE, using a distant supervision approach.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DCFEE"
      ],
      "dataset_descriptions": {
        "DCFEE": "Used for document-level Chinese event extraction in the financial field, constructed using a distant supervision approach to automatically label training data."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset, DCFEE, which is used for document-level Chinese event extraction in the financial field. The dataset is clearly identified and its construction method is specified.",
      "processing_time": 24.104450464248657,
      "citing_paper_id": "269762511",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "As illustrated in Figure 1, the arguments for financial profit events annotated in the DuEE-Fin dataset [5] are dispersed across multiple sentences.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE-Fin"
      ],
      "dataset_descriptions": {
        "DuEE-Fin": "Used to annotate arguments for financial profit events dispersed across multiple sentences, focusing on document-level event extraction methodologies."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DuEE-Fin dataset' which is a specific, verifiable dataset used for document-level event extraction, particularly for financial profit events.",
      "processing_time": 35.14648652076721,
      "citing_paper_id": "269762511",
      "cited_paper_id": 252569165
    },
    {
      "context_text": "For event types with fewer samples, few-shot learning methods can be adopted, with current solutions including data augmentation [13], prompt learning [8], transfer learning [12], meta-learning [20], generative adversarial networks [16], and sample weighting [15], among others.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various few-shot learning methods. No dataset names are present in the text.",
      "processing_time": 16.686519861221313,
      "citing_paper_id": "269762511",
      "cited_paper_id": 252819354
    },
    {
      "context_text": "In 2022, Ren et al. [14] introduced a fine-grained event extraction dataset named IREE from an investment perspective, comprising five major news categories and 59 types of risk events.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "IREE"
      ],
      "dataset_descriptions": {
        "IREE": "Used to train and evaluate models for fine-grained event extraction in investment-related news, focusing on 59 types of risk events across five major news categories."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset named IREE, which is introduced for fine-grained event extraction in an investment context.",
      "processing_time": 36.20042133331299,
      "citing_paper_id": "269762511",
      "cited_paper_id": 259120735
    },
    {
      "context_text": "• IPGPF [6] eliminates the dependence on the generation order of argument roles by parallel generating event arguments and iteratively generating event records while adopting a pre-filling strategy to mitigate training deficiencies and zero precision issues in a parallel generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'IPGPF' which is a method, not a dataset. No specific dataset is mentioned or used in the described research.",
      "processing_time": 17.89732837677002,
      "citing_paper_id": "269762511",
      "cited_paper_id": 266163877
    },
    {
      "context_text": "We use a vanilla Transformer [18] as the encoder and employ a CRF (Conditional Random Field) to classify the token representations into entity labels.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the architecture and methodology used.",
      "processing_time": 16.413539171218872,
      "citing_paper_id": "272659306",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "As shown in Figure 2, EADRE first encodes each sentence in D through Transformer [18] and extracts entity mentions at the sentence level (Section 3.1).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Transformer) which is excluded. No verifiable resources are identified.",
      "processing_time": 16.40991187095642,
      "citing_paper_id": "272659306",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Chen et al. [2] proposed a dynamic multi-pool convolutional neural network to uncover clues at the sentence level, employing dynamic pooling layers to retain more information about event trigger words and arguments.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction using a dynamic multi-pool convolutional neural network.",
      "processing_time": 16.68517255783081,
      "citing_paper_id": "272659306",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Most existing approaches [1, 3, 12, 14, 15, 19, 22] focus on Sentence-level Event Extraction (SEE) .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general research area. No dataset names are present in the text.",
      "processing_time": 28.944885730743408,
      "citing_paper_id": "272659306",
      "cited_paper_id": 211529034
    },
    {
      "context_text": "Du and Cardie [4] extracted trigger words and arguments in a fragmentary manner by defining problem templates for trigger words and event roles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 14.781164646148682,
      "citing_paper_id": "272659306",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Liu et al. [10] proposed an unsupervised question generation method, which can avoid the problem of inadequate semantics resulting from template generation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for unsupervised question generation.",
      "processing_time": 14.929541110992432,
      "citing_paper_id": "272659306",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "In contrast, for ChatGLM-6B , we conducted P-tuning-v2 [11] using the encoder-decoder framework with all training data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'all training data', which is too generic.",
      "processing_time": 29.758933544158936,
      "citing_paper_id": "272659306",
      "cited_paper_id": 248780177
    },
    {
      "context_text": "Liang et al. [9] propose ReDEE, a relation-enhanced DEE model, which strengthens the relationships between parameters by introducing an additional relational extraction task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (ReDEE) and a related task (relation-enhanced DEE).",
      "processing_time": 17.013334035873413,
      "citing_paper_id": "272659306",
      "cited_paper_id": 249431954
    },
    {
      "context_text": "— ReDEE [9] introduces the relational extraction task to enhance the relationship between arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a task and a method. The context is about introducing a relational extraction task, which is not a dataset.",
      "processing_time": 17.85068154335022,
      "citing_paper_id": "272659306",
      "cited_paper_id": 249431954
    },
    {
      "context_text": "” Previous methods [9, 23, 25, 27, 28] divided DEE into three tasks: mention extraction , event detection , and event record extraction .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only tasks and methods. No verifiable resources are identified.",
      "processing_time": 28.22128677368164,
      "citing_paper_id": "272659306",
      "cited_paper_id": 249431954
    },
    {
      "context_text": "” Previous methods [9, 23, 25, 27, 28] divided DEE into three tasks: mention extraction , event detection , and event record extraction .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only tasks and methods. No verifiable resources are identified.",
      "processing_time": 28.22128677368164,
      "citing_paper_id": "272659306",
      "cited_paper_id": null
    },
    {
      "context_text": "We conducted experiments on two public DEE datasets including ChiFinAnn [27] and DuEE-Fin [5].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-Fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used for document-level event extraction experiments, focusing on financial news articles to identify and classify events.",
        "DuEE-Fin": "Used for document-level event extraction experiments, providing a large-scale dataset of financial documents to identify and classify complex events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ChiFinAnn and DuEE-Fin, which are used for document-level event extraction experiments.",
      "processing_time": 41.71097135543823,
      "citing_paper_id": "272659306",
      "cited_paper_id": 252569165
    },
    {
      "context_text": "Then, following the approach proposed by Zhu et al. [28], we select a set of roles R k for the k -th event type based on the importance scores of the roles.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for selecting roles for event types based on importance scores.",
      "processing_time": 27.820663452148438,
      "citing_paper_id": "272659306",
      "cited_paper_id": null
    },
    {
      "context_text": "Zhu et al. [28] propose a more efficient DEE model, PTPCG, which constructs a pruned complete graph based on pseudo-trigger words and makes the model learn this graph structure during training.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (PTPCG) and its methodology. There are no clear identifiers for datasets in the text.",
      "processing_time": 30.436201095581055,
      "citing_paper_id": "272659306",
      "cited_paper_id": null
    },
    {
      "context_text": "Finally, we use the methods based on a pseudo-trigger-aware pruned complete graph [28] to obtain event records for each event (Section 3.4).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for obtaining event records.",
      "processing_time": 14.408362627029419,
      "citing_paper_id": "272659306",
      "cited_paper_id": null
    },
    {
      "context_text": "— PTPCG [28] proposes a pseudo-trigger-aware pruned complete graph and extracting different combinations of arguments from it efficiently.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach called PTPCG. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 18.1385760307312,
      "citing_paper_id": "272659306",
      "cited_paper_id": null
    },
    {
      "context_text": "We adopt a pruning-based fully connected graph method [28] to obtain different argument combinations to extract event records.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for extracting event records.",
      "processing_time": 14.612463235855103,
      "citing_paper_id": "272659306",
      "cited_paper_id": null
    },
    {
      "context_text": "Due to insufficient robustness of the models [28], these links cannot be predicted correctly, leading to decreased accuracy in adjacency matrix prediction.",
      "catation_intent": "limitation",
      "resource_type": "limitation",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a limitation in model robustness.",
      "processing_time": 14.277541160583496,
      "citing_paper_id": "272659306",
      "cited_paper_id": null
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event occurrences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to event extraction. No dataset names are present in the text.",
      "processing_time": 16.348270654678345,
      "citing_paper_id": "249431954",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event occurrences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to event extraction. No dataset names are present in the text.",
      "processing_time": 16.348270654678345,
      "citing_paper_id": "249431954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event occurrences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to event extraction. No dataset names are present in the text.",
      "processing_time": 16.348270654678345,
      "citing_paper_id": "249431954",
      "cited_paper_id": 11187670
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event occurrences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to event extraction. No dataset names are present in the text.",
      "processing_time": 16.348270654678345,
      "citing_paper_id": "249431954",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "To train the above four components, we leverage the multi-task learning method (Collobert and Weston, 2008) and integrate the four corresponding loss functions together as the following:",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for training components using multi-task learning.",
      "processing_time": 14.879037857055664,
      "citing_paper_id": "249431954",
      "cited_paper_id": 2617020
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to event extraction. No dataset names are present in the text.",
      "processing_time": 29.96833038330078,
      "citing_paper_id": "249431954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Previously a lot of works((Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018)) deal with event extraction in two stages: firstly, trigger words are detected, which are usually nouns or verbs that clearly express event…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to event extraction. No dataset names are present in the text.",
      "processing_time": 29.96833038330078,
      "citing_paper_id": "249431954",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Most of the previous methods focus on sentencelevel event extraction (SEE) (Ahn, 2006; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Zhao et al., 2018; Sha et al., 2018; Yan et al., 2019; Du and Cardie, 2020; Li\n*These authors contributed equally to this work\net…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous methods and works. No verifiable resources are identified.",
      "processing_time": 16.6152184009552,
      "citing_paper_id": "249431954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Most of the previous methods focus on sentencelevel event extraction (SEE) (Ahn, 2006; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Zhao et al., 2018; Sha et al., 2018; Yan et al., 2019; Du and Cardie, 2020; Li\n*These authors contributed equally to this work\net…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous methods and works. No verifiable resources are identified.",
      "processing_time": 16.6152184009552,
      "citing_paper_id": "249431954",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Then a joint model is created to extract triggers and arguments simultaneously via multi-task learning (Nguyen et al., 2016; Sha et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 17.2401340007782,
      "citing_paper_id": "249431954",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Then a joint model is created to extract triggers and arguments simultaneously via multi-task learning (Nguyen et al., 2016; Sha et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 17.2401340007782,
      "citing_paper_id": "249431954",
      "cited_paper_id": 19220240
    },
    {
      "context_text": "For example, a neural pipeline model is proposed to identify triggers first and then extracts roles and arguments (Chen et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 14.711139440536499,
      "citing_paper_id": "249431954",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "…event extraction (SEE) (Ahn, 2006; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Zhao et al., 2018; Sha et al., 2018; Yan et al., 2019; Du and Cardie, 2020; Li\n*These authors contributed equally to this work\net al., 2020; Paolini et al., 2021; Lu et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works on event extraction. No verifiable resources are identified.",
      "processing_time": 29.693201065063477,
      "citing_paper_id": "249431954",
      "cited_paper_id": 19220240
    },
    {
      "context_text": "Specifically, we use the BERT (Devlin et al., 2019) encoder pre-trained in Roberta setting (Liu et al.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and Roberta, which are models, not datasets. No specific datasets are mentioned.",
      "processing_time": 28.8458411693573,
      "citing_paper_id": "249431954",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Specifically, we use the BERT (Devlin et al., 2019) encoder pre-trained in Roberta setting (Liu et al., 2019).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and Roberta, which are models, not datasets. No specific datasets are mentioned.",
      "processing_time": 15.866430521011353,
      "citing_paper_id": "249431954",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We use BERT encoder in the EER component for fine-tuning and Roberta-chinese-wwm (Yiming et al., 2020) as the pre-trained model.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and Roberta-chinese-wwm, which are models, not datasets. No datasets are explicitly mentioned or used in the described research context.",
      "processing_time": 18.420931339263916,
      "citing_paper_id": "249431954",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "To iteratively generate every argument for a specific event type, we refer to the entity-based directed acyclic graph (EDAG) method (Zheng et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the EDAG method but does not refer to a specific dataset. The context is about a method for generating arguments for event types using EDAG.",
      "processing_time": 17.216969966888428,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "In our experiments we adopt two public Chinese datasets, i.e. ChiFinAnn (Zheng et al., 2019) and DuEE-fin (Li, 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used for Chinese financial event extraction, focusing on document-level annotations and evaluation of event detection methods.",
        "DuEE-fin": "Used for Chinese financial event extraction, focusing on document-level annotations and evaluation of event detection methods."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ChiFinAnn and DuEE-fin, which are used in experiments for Chinese financial event extraction.",
      "processing_time": 26.359599828720093,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "In our experiments we adopt two public Chinese datasets, i.e. ChiFinAnn (Zheng et al., 2019) and DuEE-fin (Li, 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used for Chinese financial event extraction, focusing on document-level annotations and evaluation of event detection methods.",
        "DuEE-fin": "Used for Chinese financial event extraction, focusing on document-level annotations and evaluation of event detection methods."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ChiFinAnn and DuEE-fin, which are used in experiments for Chinese financial event extraction.",
      "processing_time": 26.359599828720093,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "Recently, document-level event extraction (DEE) attracts great attention from both academic and industrial communities, and is regarded as a promising direction to tackle the above issues (Yang et al., 2018; Zheng et al., 2019; Xu et al., 2021b; Yang et al., 2021; Zhu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to document-level event extraction and related works. No verifiable resources are identified.",
      "processing_time": 29.94438600540161,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Recently, document-level event extraction (DEE) attracts great attention from both academic and industrial communities, and is regarded as a promising direction to tackle the above issues (Yang et al., 2018; Zheng et al., 2019; Xu et al., 2021b; Yang et al., 2021; Zhu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to document-level event extraction and related works. No verifiable resources are identified.",
      "processing_time": 29.94438600540161,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "Later, an innovative end-to-end model Doc2EDAG, is proposed (Zheng et al., 2019), which can generate event records via an entity-based directed acyclic graph to fulfill the document-level event extraction effectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions an end-to-end model called Doc2EDAG but does not refer to any specific dataset. The model is described as a method for document-level event extraction.",
      "processing_time": 17.545015335083008,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "For example, Pledger and Pledgee in the EquityPledge event could have a relation named as Pledge2Pledgee, and the order of head and tail entities is determined by the pre-order of event arguments (Zheng et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or framework for document-level event extraction.",
      "processing_time": 14.979043006896973,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "2) Doc2EDAG (Zheng et al., 2019), proposed an end-to-end model which transforms DEE as directly filling event tables with entity-based path expending.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Doc2EDAG' but does not refer to it as a dataset. It is described as a model or method for document-level event extraction.",
      "processing_time": 17.198264122009277,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Based on Doc2EDAG, there are some variants appearing.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or framework called Doc2EDAG. There are no clear identifiers for datasets.",
      "processing_time": 16.565067291259766,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "ChiFinAnn (Zheng et al., 2019) and DuEE-fin (Li, 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used for Chinese financial event extraction, focusing on document-level annotations to improve event detection accuracy.",
        "DuEE-fin": "Applied for financial event extraction, emphasizing document-level context to enhance the identification of complex events."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions two specific datasets, ChiFinAnn and DuEE-fin, which are relevant to document-level event extraction in the financial domain.",
      "processing_time": 40.254446268081665,
      "citing_paper_id": "249431954",
      "cited_paper_id": 119308902
    },
    {
      "context_text": ", 2018), pre-trained language models (Yang et al., 2019), and explicit external knowledge (Liu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to pre-trained language models and external knowledge. No verifiable datasets are identified.",
      "processing_time": 16.904701709747314,
      "citing_paper_id": "249431954",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "To utilize more knowledge, some studies propose to leverage document contexts (Chen et al., 2018; Zhao et al., 2018), pre-trained language models (Yang et al., 2019), and explicit external knowledge (Liu et al., 2019a; Tong et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 29.365994215011597,
      "citing_paper_id": "249431954",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "To predict the argument relations in this step, we adopt the structured self attention network (Xu et al., 2021a) which is the latest method for document-level relation extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (structured self attention network) but does not reference any specific dataset. The context is focused on the methodology rather than a particular dataset.",
      "processing_time": 17.749763250350952,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "Compared with the ground truth, our model correctly predicts all event arguments except one, while GIT only captures one event, with an argument missed.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between a model and another method (GIT).",
      "processing_time": 16.03591537475586,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "A.4 Case Study Figure 4 shows the prediction results of our model and the best baseline model GIT on the example in Figure 1.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between models. No verifiable resources are identified.",
      "processing_time": 15.798741340637207,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "4) GIT (Xu et al., 2021b), a model using heterogeneous graph interaction network as encoder and maintaining a global tracker during the decoding process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (GIT) and its components. The context is about the model's architecture and functionality, not about datasets.",
      "processing_time": 18.36628794670105,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "we adopt the structured self attention network (Xu et al., 2021a) which is the latest method for document-level relation extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a method (structured self attention network) but does not reference any specific dataset. The citation is focused on the method used for document-level relation extraction.",
      "processing_time": 18.36293387413025,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "For instance, GIT (Xu et al., 2021b) designs a heterogeneous graph interaction network to capture global interaction information among different sentences and entity mentions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (GIT) and its purpose. The title of the cited paper also focuses on a method rather than a dataset.",
      "processing_time": 18.90853714942932,
      "citing_paper_id": "249431954",
      "cited_paper_id": 231985811
    },
    {
      "context_text": "…and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Zhao et al., 2018; Sha et al., 2018; Yan et al., 2019; Du and Cardie, 2020; Li\n*These authors contributed equally to this work\net al., 2020; Paolini et al., 2021; Lu et al., 2021), extracting events from a single sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works. There is no indication of a reusable resource being used.",
      "processing_time": 16.524622917175293,
      "citing_paper_id": "249431954",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "A.1 Distribution of Event Type DuEE-fin Table 8 shows the complete event type and corresponding distribution of DuEE-fin dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "DuEE-fin": "Used to analyze the distribution of event types in financial documents, specifically focusing on the frequency and variety of events in the DuEE-fin dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DuEE-fin dataset' which is a specific, verifiable dataset used for event type distribution analysis.",
      "processing_time": 23.359150886535645,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "When it comes to DuEE-fin, a similar phenomenon can be observed that both the RAATs can contribute positively to our model.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'DuEE-fin' but does not provide enough information to determine if it is a dataset, method, or other resource. The citation intent and resource type are unclear.",
      "processing_time": 18.588605880737305,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "The DuEE-fin dataset has 13 different event types and its test set includes a large size of document samples that do not have any event records, which both make it more complicated.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "DuEE-fin": "Used to evaluate document-level event extraction, focusing on a diverse set of event types and a challenging test set with many documents lacking event records."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DuEE-fin' as a dataset with specific characteristics relevant to document-level event extraction, including a variety of event types and a challenging test set.",
      "processing_time": 24.024427890777588,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "By our statistics, the training sets of ChiFinAnn and DuEE-fin have about 98.0% and 98.9% records that scatter across sentences respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used to train models for financial event extraction, focusing on the distribution of records across sentences to understand document-level event scattering.",
        "DuEE-fin": "Used to train models for financial event extraction, focusing on the distribution of records across sentences to understand document-level event scattering."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ChiFinAnn and DuEE-fin, which are used for training. The statistics provided indicate the distribution of records across sentences in these datasets.",
      "processing_time": 29.324668884277344,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "Table 4 shows the comparison results of our model with baselines on the developing set of\nDuEE-fin and its online testing.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "DuEE-fin": "Used to compare the performance of the proposed model with baselines on financial event extraction, focusing on document-level event detection."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DuEE-fin' as a specific dataset used for comparison with baselines. It is a multi-word proper noun and appears to be a verifiable resource.",
      "processing_time": 24.242377758026123,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "We conduct several offline evaluations for ChiFinAnn, but only an online test for DuEE-fin.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used for offline evaluations in financial event extraction, focusing on the performance of models in identifying financial events in documents.",
        "DuEE-fin": "Used for an online test in financial event extraction, evaluating the real-time performance of models in identifying financial events."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'ChiFinAnn' and 'DuEE-fin', which appear to be specific datasets or resources. However, without additional context or disambiguation from cited paper titles, it is unclear if these are datasets or other types of resources.",
      "processing_time": 46.159520626068115,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "DuEE-fin is also from the financial domain with around 11,900 documents in total.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "DuEE-fin": "Used to study document-level event extraction in the financial domain, focusing on a corpus of 11,900 documents to analyze event occurrences and their contexts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DuEE-fin' as a dataset from the financial domain with a specific number of documents, which fits the criteria for a verifiable dataset.",
      "processing_time": 24.683269739151,
      "citing_paper_id": "249431954",
      "cited_paper_id": null
    },
    {
      "context_text": "Document-level event extraction systems utilize drastically different techniques: earlier methods relied on pattern matching (Riloff, 1993; Riloff and Jones, 1999), while more modern approaches use deep learning to represent event components such as triggers and entities (Wad-den et al., 2019; Wang…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques used in document-level event extraction.",
      "processing_time": 15.514826536178589,
      "citing_paper_id": "273993349",
      "cited_paper_id": 1053009
    },
    {
      "context_text": "Document-level event extraction systems utilize drastically different techniques: earlier methods relied on pattern matching (Riloff, 1993; Riloff and Jones, 1999), while more modern approaches use deep learning to represent event components such as triggers and entities (Wad-den et al., 2019; Wang…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques used in document-level event extraction.",
      "processing_time": 15.514826536178589,
      "citing_paper_id": "273993349",
      "cited_paper_id": 2257053
    },
    {
      "context_text": "The vast majority of that research focuses on sentence-level event extraction (Ji and Grishman, 2008; Li et al., 2013; Yang et al., 2019; Wadden et al., 2019, i.a.): given a text and a predefined set of event type s E , each e ∈ E with its own set of arguments A e (also known as roles ), find all…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general research on sentence-level event extraction. No dataset names are present in the text.",
      "processing_time": 17.101044178009033,
      "citing_paper_id": "273993349",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "The vast majority of that research focuses on sentence-level event extraction (Ji and Grishman, 2008; Li et al., 2013; Yang et al., 2019; Wadden et al., 2019, i.a.): given a text and a predefined set of event type s E , each e ∈ E with its own set of arguments A e (also known as roles ), find all…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general research on sentence-level event extraction. No dataset names are present in the text.",
      "processing_time": 17.101044178009033,
      "citing_paper_id": "273993349",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "The vast majority of that research focuses on sentence-level event extraction (Ji and Grishman, 2008; Li et al., 2013; Yang et al., 2019; Wadden et al., 2019, i.a.): given a text and a predefined set of event type s E , each e ∈ E with its own set of arguments A e (also known as roles ), find all…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general research on sentence-level event extraction. No dataset names are present in the text.",
      "processing_time": 17.101044178009033,
      "citing_paper_id": "273993349",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "The vast majority of that research focuses on sentence-level event extraction (Ji and Grishman, 2008; Li et al., 2013; Yang et al., 2019; Wadden et al., 2019, i.a.): given a text and a predefined set of event type s E , each e ∈ E with its own set of arguments A e (also known as roles ), find all…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general research on sentence-level event extraction. No dataset names are present in the text.",
      "processing_time": 17.101044178009033,
      "citing_paper_id": "273993349",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Most recently, the task has been framed as sequence-to-sequence generation (i.e. TANL (Paolini et al., 2021), GTT (Du et al., 2021) and D EGREE (Hsu et al., 2022)) built upon powerful transformer (Vaswani et al., 2017) language models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (TANL, GTT, DEGREE) and a foundational model (transformer) but does not reference any specific datasets. The focus is on the methodologies and their application to document-level event extraction.",
      "processing_time": 21.6566321849823,
      "citing_paper_id": "273993349",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Most recently, the task has been framed as sequence-to-sequence generation (i.e. TANL (Paolini et al., 2021), GTT (Du et al., 2021) and D EGREE (Hsu et al., 2022)) built upon powerful transformer (Vaswani et al., 2017) language models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (TANL, GTT, DEGREE) and a foundational model (transformer) but does not reference any specific datasets. The focus is on the methodologies and their application to document-level event extraction.",
      "processing_time": 21.6566321849823,
      "citing_paper_id": "273993349",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "Most recently, the task has been framed as sequence-to-sequence generation (i.e. TANL (Paolini et al., 2021), GTT (Du et al., 2021) and D EGREE (Hsu et al., 2022)) built upon powerful transformer (Vaswani et al., 2017) language models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (TANL, GTT, DEGREE) and a foundational model (transformer) but does not reference any specific datasets. The focus is on the methodologies and their application to document-level event extraction.",
      "processing_time": 21.6566321849823,
      "citing_paper_id": "273993349",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Most recently, the task has been framed as sequence-to-sequence generation (i.e. TANL (Paolini et al., 2021), GTT (Du et al., 2021) and D EGREE (Hsu et al., 2022)) built upon powerful transformer (Vaswani et al., 2017) language models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (TANL, GTT, DEGREE) and a foundational model (transformer) but does not reference any specific datasets. The focus is on the methodologies and their application to document-level event extraction.",
      "processing_time": 21.6566321849823,
      "citing_paper_id": "273993349",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "We analyze whether using triggers improves event extraction performance in multiple end-to-end and pipelined transformer-based (Vaswani et al., 2017) event extraction models for three document-level event extraction datasets.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'document-level event extraction datasets' but does not specify any particular dataset names. The citation is focused on the methodology and models rather than specific datasets.",
      "processing_time": 17.93228030204773,
      "citing_paper_id": "273993349",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "We primarily focus on TANL (Paolini et al., 2021) and G EN IE (Li et al., 2021) that model the task via sequence generation, though other methods that rely on careful manipulation and learning of embeddings also exist (Chen et al., 2015; Yang et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.812209367752075,
      "citing_paper_id": "273993349",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "We primarily focus on TANL (Paolini et al., 2021) and G EN IE (Li et al., 2021) that model the task via sequence generation, though other methods that rely on careful manipulation and learning of embeddings also exist (Chen et al., 2015; Yang et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.812209367752075,
      "citing_paper_id": "273993349",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "We primarily focus on TANL (Paolini et al., 2021) and G EN IE (Li et al., 2021) that model the task via sequence generation, though other methods that rely on careful manipulation and learning of embeddings also exist (Chen et al., 2015; Yang et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.812209367752075,
      "citing_paper_id": "273993349",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "We primarily focus on TANL (Paolini et al., 2021) and G EN IE (Li et al., 2021) that model the task via sequence generation, though other methods that rely on careful manipulation and learning of embeddings also exist (Chen et al., 2015; Yang et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.812209367752075,
      "citing_paper_id": "273993349",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Docu-ment-level event extraction was introduced in the Message Understanding Conferences ( MUC ) (Sundheim, 1991) as a task to identify occurrences of predefined event types and fill the associated template roles by extracting entity mentions from the text or categorizing aspects of the event.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Message Understanding Conferences (MUC)' but does not specify a particular dataset. It is more about the introduction of a task rather than the use of a specific dataset.",
      "processing_time": 19.698076963424683,
      "citing_paper_id": "273993349",
      "cited_paper_id": 14365335
    },
    {
      "context_text": "Similar to previous work, we perform our analyses on the MUC (Sundheim, 1991), WikiEvents (Li et al., 2021) and CMNEE (Zhu et al., 2024) datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "WikiEvents",
        "CMNEE"
      ],
      "dataset_descriptions": {
        "MUC": "Used for document-level event extraction, focusing on message understanding and evaluation tasks.",
        "WikiEvents": "Used for document-level event extraction, specifically for conditional generation of event arguments.",
        "CMNEE": "Used for document-level event extraction, focusing on open-source Chinese military news."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets: MUC, WikiEvents, and CMNEE. These are clearly identified and used for document-level event extraction analyses.",
      "processing_time": 30.269359588623047,
      "citing_paper_id": "273993349",
      "cited_paper_id": 14365335
    },
    {
      "context_text": "Similar to previous work, we perform our analyses on the MUC (Sundheim, 1991), WikiEvents (Li et al., 2021) and CMNEE (Zhu et al., 2024) datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "WikiEvents",
        "CMNEE"
      ],
      "dataset_descriptions": {
        "MUC": "Used for document-level event extraction, focusing on message understanding and evaluation tasks.",
        "WikiEvents": "Used for document-level event extraction, specifically for conditional generation of event arguments.",
        "CMNEE": "Used for document-level event extraction, focusing on open-source Chinese military news."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets: MUC, WikiEvents, and CMNEE. These are clearly identified and used for document-level event extraction analyses.",
      "processing_time": 30.269359588623047,
      "citing_paper_id": "273993349",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Similar to previous work, we perform our analyses on the MUC (Sundheim, 1991), WikiEvents (Li et al., 2021) and CMNEE (Zhu et al., 2024) datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC",
        "WikiEvents",
        "CMNEE"
      ],
      "dataset_descriptions": {
        "MUC": "Used for document-level event extraction, focusing on message understanding and evaluation tasks.",
        "WikiEvents": "Used for document-level event extraction, specifically for conditional generation of event arguments.",
        "CMNEE": "Used for document-level event extraction, focusing on open-source Chinese military news."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets: MUC, WikiEvents, and CMNEE. These are clearly identified and used for document-level event extraction analyses.",
      "processing_time": 30.269359588623047,
      "citing_paper_id": "273993349",
      "cited_paper_id": 269214164
    },
    {
      "context_text": "Note that event trigger-span identification is not required as part of the output; indeed, most datasets for the task do not include trigger-span annotations (Soboroff, 2023; Jain et al., 2020; Pavlick et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'datasets for the task' but does not specify any particular dataset names. The cited papers' titles suggest potential datasets, but they are not explicitly mentioned in the context.",
      "processing_time": 19.68935751914978,
      "citing_paper_id": "273993349",
      "cited_paper_id": 14492070
    },
    {
      "context_text": "Note that event trigger-span identification is not required as part of the output; indeed, most datasets for the task do not include trigger-span annotations (Soboroff, 2023; Jain et al., 2020; Pavlick et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'datasets for the task' but does not specify any particular dataset names. The cited papers' titles suggest potential datasets, but they are not explicitly mentioned in the context.",
      "processing_time": 19.68935751914978,
      "citing_paper_id": "273993349",
      "cited_paper_id": 218470122
    },
    {
      "context_text": "Note that event trigger-span identification is not required as part of the output; indeed, most datasets for the task do not include trigger-span annotations (Soboroff, 2023; Jain et al., 2020; Pavlick et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'datasets for the task' but does not specify any particular dataset names. The cited papers' titles suggest potential datasets, but they are not explicitly mentioned in the context.",
      "processing_time": 19.68935751914978,
      "citing_paper_id": "273993349",
      "cited_paper_id": null
    },
    {
      "context_text": "Yang et al. (2018b) show that providing rationales as extra supervision enhances a model’s capability to perform multi-hop reasoning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enhancing model capabilities. The cited papers do not provide additional context to identify a specific dataset.",
      "processing_time": 17.96142888069153,
      "citing_paper_id": "273993349",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Yang et al. (2018b) show that providing rationales as extra supervision enhances a model’s capability to perform multi-hop reasoning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enhancing model capabilities. The cited papers do not provide additional context to identify a specific dataset.",
      "processing_time": 17.96142888069153,
      "citing_paper_id": "273993349",
      "cited_paper_id": 52822214
    },
    {
      "context_text": "Existing datasets such as CMNEE and DCFEE (Yang et al., 2018a) are in Chinese (therefore likely require translation before use) while others such as RAMS (Ebner et al., 2020) and Doc-EE (Tong et al., 2022) do not exhibit traits of document level datasets ( RAMS has 1 event per document and…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CMNEE",
        "DCFEE",
        "RAMS",
        "Doc-EE"
      ],
      "dataset_descriptions": {
        "CMNEE": "Used for Chinese document-level event extraction, requiring translation for non-Chinese users. Investigates financial events in documents.",
        "DCFEE": "Used for Chinese document-level financial event extraction, leveraging automatically labeled training data. Focuses on financial events in documents.",
        "RAMS": "Used for event extraction but not at the document level, typically containing one event per document. Suitable for sentence-level event extraction.",
        "Doc-EE": "Used for document-level event extraction, though specifics on its structure and content are not provided. Investigates events across multiple sentences within documents."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific datasets relevant to document-level event extraction, including their languages and characteristics.",
      "processing_time": 38.886815786361694,
      "citing_paper_id": "273993349",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Existing datasets such as CMNEE and DCFEE (Yang et al., 2018a) are in Chinese (therefore likely require translation before use) while others such as RAMS (Ebner et al., 2020) and Doc-EE (Tong et al., 2022) do not exhibit traits of document level datasets ( RAMS has 1 event per document and “doc-ument\" are restricted to 5 sentence windows surrounding the trigger while Doc-EE has only one event per document).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CMNEE",
        "DCFEE",
        "RAMS",
        "Doc-EE"
      ],
      "dataset_descriptions": {
        "CMNEE": "Used for Chinese financial event extraction, requiring translation for non-Chinese users. It is a document-level dataset.",
        "DCFEE": "Used for Chinese financial event extraction, based on automatically labeled training data. It is a document-level dataset.",
        "RAMS": "Used for event extraction but does not support document-level analysis, with only one event per document and limited to 5-sentence windows.",
        "Doc-EE": "Used for document-level event extraction but limited to one event per document, making it less suitable for multi-event document analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets relevant to document-level event extraction, providing details on their characteristics and limitations.",
      "processing_time": 38.588518381118774,
      "citing_paper_id": "273993349",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Existing datasets such as CMNEE and DCFEE (Yang et al., 2018a) are in Chinese (therefore likely require translation before use) while others such as RAMS (Ebner et al., 2020) and Doc-EE (Tong et al., 2022) do not exhibit traits of document level datasets ( RAMS has 1 event per document and “doc-ument\" are restricted to 5 sentence windows surrounding the trigger while Doc-EE has only one event per document).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CMNEE",
        "DCFEE",
        "RAMS",
        "Doc-EE"
      ],
      "dataset_descriptions": {
        "CMNEE": "Used for Chinese financial event extraction, requiring translation for non-Chinese users. It is a document-level dataset.",
        "DCFEE": "Used for Chinese financial event extraction, based on automatically labeled training data. It is a document-level dataset.",
        "RAMS": "Used for event extraction but does not support document-level analysis, with only one event per document and limited to 5-sentence windows.",
        "Doc-EE": "Used for document-level event extraction but limited to one event per document, making it less suitable for multi-event document analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets relevant to document-level event extraction, providing details on their characteristics and limitations.",
      "processing_time": 38.588518381118774,
      "citing_paper_id": "273993349",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Existing datasets such as CMNEE and DCFEE (Yang et al., 2018a) are in Chinese (therefore likely require translation before use) while others such as RAMS (Ebner et al., 2020) and Doc-EE (Tong et al., 2022) do not exhibit traits of document level datasets ( RAMS has 1 event per document and “doc-ument\" are restricted to 5 sentence windows surrounding the trigger while Doc-EE has only one event per document).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CMNEE",
        "DCFEE",
        "RAMS",
        "Doc-EE"
      ],
      "dataset_descriptions": {
        "CMNEE": "Used for Chinese financial event extraction, requiring translation for non-Chinese users. It is a document-level dataset.",
        "DCFEE": "Used for Chinese financial event extraction, based on automatically labeled training data. It is a document-level dataset.",
        "RAMS": "Used for event extraction but does not support document-level analysis, with only one event per document and limited to 5-sentence windows.",
        "Doc-EE": "Used for document-level event extraction but limited to one event per document, making it less suitable for multi-event document analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets relevant to document-level event extraction, providing details on their characteristics and limitations.",
      "processing_time": 38.588518381118774,
      "citing_paper_id": "273993349",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "GTT (Du et al., 2021) is an end-to-end model that takes a document and an ordered list of the possible event types and generates filled templates for all event types in a single pass through BERT (Devlin et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions GTT and BERT but does not refer to any specific dataset. GTT is described as a model, and BERT is referenced as a pre-trained model used within GTT.",
      "processing_time": 20.39988350868225,
      "citing_paper_id": "273993349",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "GTT (Du et al., 2021) is an end-to-end model that takes a document and an ordered list of the possible event types and generates filled templates for all event types in a single pass through BERT (Devlin et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions GTT and BERT but does not refer to any specific dataset. GTT is described as a model, and BERT is referenced as a pre-trained model used within GTT.",
      "processing_time": 20.39988350868225,
      "citing_paper_id": "273993349",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "There is a long history of research in Natural Language Processing (NLP) on the topic of event extraction (Grishman, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to the history of research in event extraction.",
      "processing_time": 15.717701435089111,
      "citing_paper_id": "273993349",
      "cited_paper_id": 203701085
    },
    {
      "context_text": "As shown in Figure 2, TANL fine-tunes a T5-large transformer (Raffel et al., 2020) to complete event extraction in two phases: 1) event detection, and 2) argument extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (T5-large transformer) and a task (event extraction).",
      "processing_time": 16.79035496711731,
      "citing_paper_id": "273993349",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "DeYoung et al. (2020) assert that rationales can function as explanations, helping end users evaluate a system’s trustworthiness.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general assertion about rationales. The cited paper title 'ERASER' is a benchmark, which is excluded.",
      "processing_time": 19.133557081222534,
      "citing_paper_id": "273993349",
      "cited_paper_id": 207847663
    },
    {
      "context_text": "In cases where they denote a (verb or noun) predicate for the event, they will serve as an anchor to localize argument extraction (Ebner et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach for argument extraction.",
      "processing_time": 14.968076944351196,
      "citing_paper_id": "273993349",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Other event extraction datasets include RAMS (Ebner et al., 2020), CMNEE (Zhu et al., 2024), WikiEvents (Li et al., 2021), and MAVEN (Wang et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "CMNEE",
        "WikiEvents",
        "MAVEN"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for multi-sentence argument linking, focusing on event extraction across multiple sentences.",
        "CMNEE": "A large-scale document-level event extraction dataset based on open-source Chinese military news, used to train and evaluate models.",
        "WikiEvents": "Used for document-level event extraction, focusing on diverse event types and their arguments.",
        "MAVEN": "A massive general domain event detection dataset, used to train and evaluate models on a wide range of event types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets used for event extraction, which are relevant to the research topic of document-level event extraction.",
      "processing_time": 36.391072511672974,
      "citing_paper_id": "273993349",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Other event extraction datasets include RAMS (Ebner et al., 2020), CMNEE (Zhu et al., 2024), WikiEvents (Li et al., 2021), and MAVEN (Wang et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "CMNEE",
        "WikiEvents",
        "MAVEN"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for multi-sentence argument linking, focusing on event extraction across multiple sentences.",
        "CMNEE": "A large-scale document-level event extraction dataset based on open-source Chinese military news, used to train and evaluate models.",
        "WikiEvents": "Used for document-level event extraction, focusing on diverse event types and their arguments.",
        "MAVEN": "A massive general domain event detection dataset, used to train and evaluate models on a wide range of event types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets used for event extraction, which are relevant to the research topic of document-level event extraction.",
      "processing_time": 36.391072511672974,
      "citing_paper_id": "273993349",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "Other event extraction datasets include RAMS (Ebner et al., 2020), CMNEE (Zhu et al., 2024), WikiEvents (Li et al., 2021), and MAVEN (Wang et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "CMNEE",
        "WikiEvents",
        "MAVEN"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for multi-sentence argument linking, focusing on event extraction across multiple sentences.",
        "CMNEE": "A large-scale document-level event extraction dataset based on open-source Chinese military news, used to train and evaluate models.",
        "WikiEvents": "Used for document-level event extraction, focusing on diverse event types and their arguments.",
        "MAVEN": "A massive general domain event detection dataset, used to train and evaluate models on a wide range of event types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets used for event extraction, which are relevant to the research topic of document-level event extraction.",
      "processing_time": 36.391072511672974,
      "citing_paper_id": "273993349",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Other event extraction datasets include RAMS (Ebner et al., 2020), CMNEE (Zhu et al., 2024), WikiEvents (Li et al., 2021), and MAVEN (Wang et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "CMNEE",
        "WikiEvents",
        "MAVEN"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for multi-sentence argument linking, focusing on event extraction across multiple sentences.",
        "CMNEE": "A large-scale document-level event extraction dataset based on open-source Chinese military news, used to train and evaluate models.",
        "WikiEvents": "Used for document-level event extraction, focusing on diverse event types and their arguments.",
        "MAVEN": "A massive general domain event detection dataset, used to train and evaluate models on a wide range of event types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets used for event extraction, which are relevant to the research topic of document-level event extraction.",
      "processing_time": 36.391072511672974,
      "citing_paper_id": "273993349",
      "cited_paper_id": 269214164
    },
    {
      "context_text": "…datasets such as CMNEE and DCFEE (Yang et al., 2018a) are in Chinese (therefore likely require translation before use) while others such as RAMS (Ebner et al., 2020) and Doc-EE (Tong et al., 2022) do not exhibit traits of document level datasets ( RAMS has 1 event per document and “doc-ument\"…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CMNEE",
        "DCFEE",
        "RAMS",
        "Doc-EE"
      ],
      "dataset_descriptions": {
        "CMNEE": "Used to study document-level event extraction in Chinese, requiring translation for non-Chinese researchers. Focuses on multi-event documents.",
        "DCFEE": "Used to study document-level event extraction in Chinese, requiring translation for non-Chinese researchers. Focuses on multi-event documents.",
        "RAMS": "Used to study event extraction, but primarily focuses on single-event documents, making it less suitable for document-level event extraction.",
        "Doc-EE": "Used to study document-level event extraction, but lacks traits of true document-level datasets, such as multiple events per document."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions several datasets, including CMNEE, DCFEE, RAMS, and Doc-EE. These are specific datasets used in the context of document-level event extraction, with details on their language and structure.",
      "processing_time": 45.009034156799316,
      "citing_paper_id": "273993349",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Prior work treats triggers as integral to accurate event extraction (M’hamdi et al., 2019; Tong et al., 2020; Lin et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to prior work on event triggers. No verifiable resources are identified.",
      "processing_time": 17.053555011749268,
      "citing_paper_id": "273993349",
      "cited_paper_id": 208031598
    },
    {
      "context_text": "Prior work treats triggers as integral to accurate event extraction (M’hamdi et al., 2019; Tong et al., 2020; Lin et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to prior work on event triggers. No verifiable resources are identified.",
      "processing_time": 17.053555011749268,
      "citing_paper_id": "273993349",
      "cited_paper_id": 220047190
    },
    {
      "context_text": "Prior work treats triggers as integral to accurate event extraction (M’hamdi et al., 2019; Tong et al., 2020; Lin et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to prior work on event triggers. No verifiable resources are identified.",
      "processing_time": 17.053555011749268,
      "citing_paper_id": "273993349",
      "cited_paper_id": 237363266
    },
    {
      "context_text": "Specifically, we study triggers in conjunction with four recent sequence-to-sequence transformer-based approaches to document-level event extraction : TANL (Paolini et al., 2021), GTT (Du et al., 2021), D EGREE (Hsu et al., 2022), and G EN IE (Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (TANL, GTT, DEGREE, GENIE) but does not refer to any specific datasets. The focus is on comparing these methods for document-level event extraction.",
      "processing_time": 20.966114044189453,
      "citing_paper_id": "273993349",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "Specifically, we study triggers in conjunction with four recent sequence-to-sequence transformer-based approaches to document-level event extraction : TANL (Paolini et al., 2021), GTT (Du et al., 2021), D EGREE (Hsu et al., 2022), and G EN IE (Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (TANL, GTT, DEGREE, GENIE) but does not refer to any specific datasets. The focus is on comparing these methods for document-level event extraction.",
      "processing_time": 20.966114044189453,
      "citing_paper_id": "273993349",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Specifically, we study triggers in conjunction with four recent sequence-to-sequence transformer-based approaches to document-level event extraction : TANL (Paolini et al., 2021), GTT (Du et al., 2021), D EGREE (Hsu et al., 2022), and G EN IE (Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (TANL, GTT, DEGREE, GENIE) but does not refer to any specific datasets. The focus is on comparing these methods for document-level event extraction.",
      "processing_time": 20.966114044189453,
      "citing_paper_id": "273993349",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Specifically, we study triggers in conjunction with four recent sequence-to-sequence transformer-based approaches to document-level event extraction : TANL (Paolini et al., 2021), GTT (Du et al., 2021), D EGREE (Hsu et al., 2022), and G EN IE (Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (TANL, GTT, DEGREE, GENIE) but does not refer to any specific datasets. The focus is on comparing these methods for document-level event extraction.",
      "processing_time": 20.966114044189453,
      "citing_paper_id": "273993349",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "An example of the prompt can be found in Appendix B. TANL (Paolini et al., 2021) is a pipeline-based model that takes only the document as input.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (TANL). The context is about the model's input and pipeline structure.",
      "processing_time": 17.914713621139526,
      "citing_paper_id": "273993349",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "We study the performance of four state-of-the-art sequence-to-sequence style systems for document-level event extraction: TANL (Paolini et al., 2021), GTT (Du et al., 2021), D EGREE (Hsu et al., 2022), and G EN IE (Li et al., 2021) and compare them against prompt-based baselines using GPT-4 O and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 17.039985418319702,
      "citing_paper_id": "273993349",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "Our work focuses primarily on such methods due to the flexibility of sequence-to-sequence frameworks (Paolini et al., 2021) and because we believe future methods will increasingly utilize constantly improving LLMs. Event Argument Extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and future trends in using LLMs for event argument extraction.",
      "processing_time": 16.40673828125,
      "citing_paper_id": "273993349",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "G EN IE (Li et al., 2021) was originally proposed for argument extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method called G EN IE. The title confirms that the focus is on a method for argument extraction, not a dataset.",
      "processing_time": 19.613526821136475,
      "citing_paper_id": "273993349",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Argument extraction is a subtask of event extraction that requires identifying fillers for the roles associated with the event given an event type as well as its trigger span (Li et al., 2021; Ren et al., 2023; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the task of argument extraction within event extraction. No dataset names are provided in the context.",
      "processing_time": 17.868919610977173,
      "citing_paper_id": "273993349",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Argument extraction is a subtask of event extraction that requires identifying fillers for the roles associated with the event given an event type as well as its trigger span (Li et al., 2021; Ren et al., 2023; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the task of argument extraction within event extraction. No dataset names are provided in the context.",
      "processing_time": 17.868919610977173,
      "citing_paper_id": "273993349",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Argument extraction is a subtask of event extraction that requires identifying fillers for the roles associated with the event given an event type as well as its trigger span (Li et al., 2021; Ren et al., 2023; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the task of argument extraction within event extraction. No dataset names are provided in the context.",
      "processing_time": 17.868919610977173,
      "citing_paper_id": "273993349",
      "cited_paper_id": 259370571
    },
    {
      "context_text": "Li et al. (2021), for example, find that the arguments of close to 40% of events in their Wikipedia-based dataset appear in sentences other than the event trigger sentence.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wikipedia-based dataset"
      ],
      "dataset_descriptions": {
        "Wikipedia-based dataset": "Used to study document-level event argument extraction, focusing on the distribution of event arguments across sentences in Wikipedia articles."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions a 'Wikipedia-based dataset' which is domain-qualified and specific enough to be included.",
      "processing_time": 22.518043756484985,
      "citing_paper_id": "273993349",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "…of four state-of-the-art sequence-to-sequence style systems for document-level event extraction: TANL (Paolini et al., 2021), GTT (Du et al., 2021), D EGREE (Hsu et al., 2022), and G EN IE (Li et al., 2021) and compare them against prompt-based baselines using GPT-4 O and GPT-4 O - MINI .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several models and systems but does not refer to any specific datasets. The focus is on comparing different models for document-level event extraction.",
      "processing_time": 17.841758966445923,
      "citing_paper_id": "273993349",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "…of four state-of-the-art sequence-to-sequence style systems for document-level event extraction: TANL (Paolini et al., 2021), GTT (Du et al., 2021), D EGREE (Hsu et al., 2022), and G EN IE (Li et al., 2021) and compare them against prompt-based baselines using GPT-4 O and GPT-4 O - MINI .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several models and systems but does not refer to any specific datasets. The focus is on comparing different models for document-level event extraction.",
      "processing_time": 17.841758966445923,
      "citing_paper_id": "273993349",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "Following previous work (Du et al., 2021; Wang et al., 2023a), we restricted event templates to contain 6 out of the original 24 roles — EVENT - TYPE , PER - PETRATOR , PERPETRATOR - ORGANIZATION , TAR -",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only roles in event templates. No verifiable resources are identified.",
      "processing_time": 15.886155366897583,
      "citing_paper_id": "273993349",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "…the performance of four state-of-the-art sequence-to-sequence style systems for document-level event extraction: TANL (Paolini et al., 2021), GTT (Du et al., 2021), D EGREE (Hsu et al., 2022), and G EN IE (Li et al., 2021) and compare them against prompt-based baselines using GPT-4 O and GPT-4 O…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 17.01339817047119,
      "citing_paper_id": "273993349",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "…utilize drastically different techniques: earlier methods relied on pattern matching (Riloff, 1993; Riloff and Jones, 1999), while more modern approaches use deep learning to represent event components such as triggers and entities (Wad-den et al., 2019; Wang et al., 2023c; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only different methodologies for event extraction. No verifiable resources are identified.",
      "processing_time": 16.713443279266357,
      "citing_paper_id": "273993349",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "…utilize drastically different techniques: earlier methods relied on pattern matching (Riloff, 1993; Riloff and Jones, 1999), while more modern approaches use deep learning to represent event components such as triggers and entities (Wad-den et al., 2019; Wang et al., 2023c; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only different methodologies for event extraction. No verifiable resources are identified.",
      "processing_time": 16.713443279266357,
      "citing_paper_id": "273993349",
      "cited_paper_id": 258967833
    },
    {
      "context_text": "This follows findings in recent work (Min et al., 2022) and suggests that learning the concept of a trigger, even without proper examples, meaningfully supports extraction.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a concept related to in-context learning. No verifiable resources are identified.",
      "processing_time": 17.00589370727539,
      "citing_paper_id": "273993349",
      "cited_paper_id": 247155069
    },
    {
      "context_text": "D EGREE (Hsu et al., 2022) is an end-to-end model that takes a document, a natural language template for one event type E and extra information about events of type E (i.e. type definitions, example triggers); it generates filled natural language templates (that include identified triggers) for all…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model called DEGREE. The citation is focused on describing the model and its functionality, not on the use of a dataset.",
      "processing_time": 20.107607126235962,
      "citing_paper_id": "273993349",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "We follow the matching algorithm of Das et al. (2022) to align and score the predicted templates 6 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or algorithm. The context is focused on the alignment and scoring of predicted templates, which is a methodological aspect.",
      "processing_time": 19.592763423919678,
      "citing_paper_id": "273993349",
      "cited_paper_id": 248780414
    },
    {
      "context_text": "Unfortunately, the document-level task setting poses significant challenges (Das et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "limitation",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a challenge in the document-level task setting.",
      "processing_time": 14.897423267364502,
      "citing_paper_id": "273993349",
      "cited_paper_id": 248780414
    },
    {
      "context_text": "Additionally, some more elaborate prompting-based approaches such as C ODE 4S TRUCT (Wang et al., 2022) warrant testing given the rapidly developing capabilities of LLMs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (C ODE 4S TRUCT) which is excluded according to the rules.",
      "processing_time": 18.447953939437866,
      "citing_paper_id": "273993349",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "…(Yang et al., 2018a) are in Chinese (therefore likely require translation before use) while others such as RAMS (Ebner et al., 2020) and Doc-EE (Tong et al., 2022) do not exhibit traits of document level datasets ( RAMS has 1 event per document and “doc-ument\" are restricted to 5 sentence…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "Doc-EE"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to compare against document-level event extraction, specifically noting that it has 1 event per document, which limits its applicability for document-level analysis.",
        "Doc-EE": "Used as a large-scale and fine-grained benchmark for document-level event extraction, focusing on the complexity and diversity of events within documents."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions RAMS and Doc-EE, both of which are specific datasets. RAMS is described as having 1 event per document, and Doc-EE is mentioned as a benchmark for document-level event extraction.",
      "processing_time": 33.88045334815979,
      "citing_paper_id": "273993349",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "For example, I TER X (Chen et al., 2023) formulates event extraction as a Markov decision process while P ROCNET builds a graph over entity representations to be parsed into events (Wang et al., 2023c).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 17.312861919403076,
      "citing_paper_id": "273993349",
      "cited_paper_id": 252873525
    },
    {
      "context_text": "For example, I TER X (Chen et al., 2023) formulates event extraction as a Markov decision process while P ROCNET builds a graph over entity representations to be parsed into events (Wang et al., 2023c).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 17.312861919403076,
      "citing_paper_id": "273993349",
      "cited_paper_id": 258967833
    },
    {
      "context_text": "LLM triggers Recent work has demonstrated that GPT performs well on some information extraction tasks (Wang et al., 2023b; Wadhwa et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that GPT performs well on some information extraction tasks. There are no verifiable resources or datasets mentioned.",
      "processing_time": 18.706462144851685,
      "citing_paper_id": "273993349",
      "cited_paper_id": 258887711
    },
    {
      "context_text": "LLM triggers Recent work has demonstrated that GPT performs well on some information extraction tasks (Wang et al., 2023b; Wadhwa et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that GPT performs well on some information extraction tasks. There are no verifiable resources or datasets mentioned.",
      "processing_time": 18.706462144851685,
      "citing_paper_id": "273993349",
      "cited_paper_id": null
    },
    {
      "context_text": "Triggers , as defined in Walker et al. (2005), refer to text spans (verbs, nouns, or adjectives) that most clearly express the occurrence of one or more events.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a definition from a paper. No verifiable resources are identified.",
      "processing_time": 16.32693839073181,
      "citing_paper_id": "273993349",
      "cited_paper_id": null
    },
    {
      "context_text": "Most recently, Chen et al. (2022) demonstrate the potential of rationale-based NLP systems on adversarial inputs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or system. There are no clear identifiers for datasets in the text.",
      "processing_time": 16.062687397003174,
      "citing_paper_id": "273993349",
      "cited_paper_id": null
    },
    {
      "context_text": "Automated techniques can extract information from clinical medical data that is useful for scientific study [12], increasing the productivity of researchers and hastening the advancement of drug development.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to clinical medical data. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 20.44023585319519,
      "citing_paper_id": "258998173",
      "cited_paper_id": 3469394
    },
    {
      "context_text": "[7] uses a dependency bridge to enhance its information representation when modelling each word.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enhancing information representation.",
      "processing_time": 14.874395370483398,
      "citing_paper_id": "258998173",
      "cited_paper_id": 19220240
    },
    {
      "context_text": "[8] proposed Weakly Aligned Structured Embedding (WASE), a structured representation of semantic information extracted from textual and visual data encoded into a common embedding space.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called WASE. The context focuses on the method's capability to encode textual and visual data into a common embedding space.",
      "processing_time": 20.064800024032593,
      "citing_paper_id": "258998173",
      "cited_paper_id": 218501728
    },
    {
      "context_text": "[3] put out a document-level neural event argument extraction model, which describes tasks as conditional generation following event templates.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model for document-level event argument extraction.",
      "processing_time": 15.354726314544678,
      "citing_paper_id": "258998173",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "4 focus of public opinion more quickly, some researchers [10] are committed to automatically extracting various types of events from vast internet electronic texts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general task of event detection from news. No verifiable resources are identified.",
      "processing_time": 17.290157079696655,
      "citing_paper_id": "258998173",
      "cited_paper_id": 245934663
    },
    {
      "context_text": "We set the learning rate to 5e-5, the batch size to 64, and choose Adam [22] as our optimizer.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Adam optimizer).",
      "processing_time": 14.859015464782715,
      "citing_paper_id": "264146058",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "Given a document D = { s i } |D| i =1 , where s i is the i th sentence containing | s i | tokens, we utilize a Transformer [16] to encode s i following [7, 8, 9]: (1) Next, we obtain the sentence representation S i ∈ R d by max-pooling (cid:101) s i and adding the sentence position embedding: S i =…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Transformer) which is excluded. There are no verifiable resources or datasets mentioned.",
      "processing_time": 17.78321933746338,
      "citing_paper_id": "264146058",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "After that, we employ a CRF [17] layer to recognize entities as candidate event arguments and get the entity recognition loss L er : where ˆ y s i is the golden label sequence of s i .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CRF) for entity recognition.",
      "processing_time": 15.329978942871094,
      "citing_paper_id": "264146058",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "Most previous works of Event Extraction [11, 12, 13, 4, 5] concentrate on Sentence-level Event Extraction (SEE) based on the ACE 2005 [14] dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used for sentence-level event extraction, focusing on identifying events within individual sentences. The dataset provides annotated text for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE 2005 dataset, which is a well-known resource for event extraction tasks. The dataset is specifically used for sentence-level event extraction.",
      "processing_time": 25.42246413230896,
      "citing_paper_id": "264146058",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "Most previous works of Event Extraction [11, 12, 13, 4, 5] concentrate on Sentence-level Event Extraction (SEE) based on the ACE 2005 [14] dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used for sentence-level event extraction, focusing on identifying events within individual sentences. The dataset provides annotated text for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE 2005 dataset, which is a well-known resource for event extraction tasks. The dataset is specifically used for sentence-level event extraction.",
      "processing_time": 25.42246413230896,
      "citing_paper_id": "264146058",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "In contrast to sentence-level event extraction [2, 3, 4, 5, 6] which extracts events within a sentence, DEE faces two specific challenges: arguments-scattering and multi-event.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general challenges in document-level event extraction. No verifiable resources are named.",
      "processing_time": 17.261770725250244,
      "citing_paper_id": "264146058",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "In contrast to sentence-level event extraction [2, 3, 4, 5, 6] which extracts events within a sentence, DEE faces two specific challenges: arguments-scattering and multi-event.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general challenges in document-level event extraction. No verifiable resources are named.",
      "processing_time": 17.261770725250244,
      "citing_paper_id": "264146058",
      "cited_paper_id": 247619149
    },
    {
      "context_text": "In contrast to sentence-level event extraction [2, 3, 4, 5, 6] which extracts events within a sentence, DEE faces two specific challenges: arguments-scattering and multi-event.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general challenges in document-level event extraction. No verifiable resources are named.",
      "processing_time": 17.261770725250244,
      "citing_paper_id": "264146058",
      "cited_paper_id": 248512779
    },
    {
      "context_text": "Document-level Event Extraction (DEE) aims to detect events and extract event arguments of pre-defined types from documents, which plays important roles in various fields, such as question answering [1], financial analysis, speech understanding, etc.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the general concept of document-level event extraction and its applications.",
      "processing_time": 16.29753088951111,
      "citing_paper_id": "264146058",
      "cited_paper_id": 243865619
    },
    {
      "context_text": "DuEE-fin [19] is a recently released public financial DEE dataset comprising 13 event types and 92 event roles extracted from common financial events.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "DuEE-fin": "Used to train and evaluate document-level event extraction models, focusing on 13 financial event types and 92 event roles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions DuEE-fin as a specific dataset with clear identifiers and usage details.",
      "processing_time": 22.298473596572876,
      "citing_paper_id": "264146058",
      "cited_paper_id": null
    },
    {
      "context_text": "Following [10], we evaluate our method on two widely-used DEE datasets: ChFinAnn [7] and DuEE-fin [19].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn",
        "DuEE-fin"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used to evaluate document-level event extraction methods, focusing on financial news articles and reports.",
        "DuEE-fin": "Used to assess document-level event extraction performance, specifically in the financial domain with diverse document types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets used for evaluating the method on document-level event extraction.",
      "processing_time": 24.93137264251709,
      "citing_paper_id": "264146058",
      "cited_paper_id": null
    },
    {
      "context_text": "Adhering to the TimeML specification (Pustejovsky et al., 2003a, 2010), temporal relation datasets such as TimeBank (James Pustejovsky and others, 2006) and TempEval (Ver-hagen et al., 2009, 2010; UzZaman et al., 2013) have been constructed.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TimeBank",
        "TempEval"
      ],
      "dataset_descriptions": {
        "TimeBank": "Used to construct temporal relation datasets adhering to the TimeML specification, focusing on event and temporal expressions in text.",
        "TempEval": "Used to construct temporal relation datasets adhering to the TimeML specification, focusing on event and temporal expressions in text."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, TimeBank and TempEval, which are used for constructing temporal relation datasets adhering to the TimeML specification.",
      "processing_time": 28.09155035018921,
      "citing_paper_id": "269804126",
      "cited_paper_id": 341734
    },
    {
      "context_text": "Adhering to the TimeML specification (Pustejovsky et al., 2003a, 2010), temporal relation datasets such as TimeBank (James Pustejovsky and others, 2006) and TempEval (Ver-hagen et al., 2009, 2010; UzZaman et al., 2013) have been constructed.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TimeBank",
        "TempEval"
      ],
      "dataset_descriptions": {
        "TimeBank": "Used to construct temporal relation datasets adhering to the TimeML specification, focusing on event and temporal expressions in text.",
        "TempEval": "Used to construct temporal relation datasets adhering to the TimeML specification, focusing on event and temporal expressions in text."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, TimeBank and TempEval, which are used for constructing temporal relation datasets adhering to the TimeML specification.",
      "processing_time": 28.09155035018921,
      "citing_paper_id": "269804126",
      "cited_paper_id": 14625075
    },
    {
      "context_text": "Leveraging temporal insights, causal relation datasets (Do et al., 2011; Mirza et al., 2014; Mostafazadeh et al., 2016; Dunietz et al., 2017; Caselli and Vossen, 2017; Tan et al., 2022) have emerged.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'causal relation datasets' but does not specify any particular dataset names. The cited papers do not provide specific dataset names either, only corpus or benchmark names which are excluded.",
      "processing_time": 20.656731128692627,
      "citing_paper_id": "269804126",
      "cited_paper_id": 3030259
    },
    {
      "context_text": "Leveraging temporal insights, causal relation datasets (Do et al., 2011; Mirza et al., 2014; Mostafazadeh et al., 2016; Dunietz et al., 2017; Caselli and Vossen, 2017; Tan et al., 2022) have emerged.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'causal relation datasets' but does not specify any particular dataset names. The cited papers do not provide specific dataset names either, only corpus or benchmark names which are excluded.",
      "processing_time": 20.656731128692627,
      "citing_paper_id": "269804126",
      "cited_paper_id": 17716605
    },
    {
      "context_text": "Leveraging temporal insights, causal relation datasets (Do et al., 2011; Mirza et al., 2014; Mostafazadeh et al., 2016; Dunietz et al., 2017; Caselli and Vossen, 2017; Tan et al., 2022) have emerged.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'causal relation datasets' but does not specify any particular dataset names. The cited papers do not provide specific dataset names either, only corpus or benchmark names which are excluded.",
      "processing_time": 20.656731128692627,
      "citing_paper_id": "269804126",
      "cited_paper_id": 38234032
    },
    {
      "context_text": "Datasets like Cancer Genetics, EPM, GENIA2011, GENIA2013, Pathway Curation, and MLEE (Pyysalo et al., 2013; Ohta et al., 2011; Van Landeghem et al., 2013) are tailored exclusively for the biological domain.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Cancer Genetics",
        "EPM",
        "GENIA2011",
        "GENIA2013",
        "Pathway Curation",
        "MLEE"
      ],
      "dataset_descriptions": {
        "Cancer Genetics": "Used to study genetic alterations in cancer, focusing on event extraction in biological processes and pathways.",
        "EPM": "Utilized for epigenetic and post-translational modification event extraction, analyzing regulatory mechanisms in biological systems.",
        "GENIA2011": "Applied to extract events related to gene expression and regulation, supporting detailed analysis of molecular interactions.",
        "GENIA2013": "Used to enhance event extraction in biological texts, focusing on complex interactions and regulatory processes.",
        "Pathway Curation": "Employed for curating and extracting pathway information, aiding in the understanding of biological signaling networks.",
        "MLEE": "Utilized for molecular event extraction, focusing on detailed annotation of biological processes and interactions."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets that are tailored for the biological domain. These datasets are named and appear to be specific, verifiable resources.",
      "processing_time": 49.79106330871582,
      "citing_paper_id": "269804126",
      "cited_paper_id": 8143782
    },
    {
      "context_text": "The CEC (Fu et al., 2010) dataset, being auto-annotated, encompasses 332 emergency news documents, which is insufficient to capture the vast array of real-world events.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CEC"
      ],
      "dataset_descriptions": {
        "CEC": "Used to study event taggability in Chinese emergency news documents, focusing on the limitations of auto-annotation in capturing diverse real-world events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the CEC dataset, which is a specific, verifiable resource used in the research. The dataset is described as auto-annotated and containing 332 emergency news documents.",
      "processing_time": 25.0720796585083,
      "citing_paper_id": "269804126",
      "cited_paper_id": 11137563
    },
    {
      "context_text": "Chinese Emergency Corpus (CEC) (Fu et al., 2010) is a Chinese dataset pertinent to emergencies, which provides 332 documents covering 5 categories.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Chinese Emergency Corpus (CEC)"
      ],
      "dataset_descriptions": {
        "Chinese Emergency Corpus (CEC)": "Used to study event taggability in Chinese emergency documents, providing 332 documents across 5 categories for analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions 'Chinese Emergency Corpus (CEC)' as a dataset with specific details about its content and structure.",
      "processing_time": 24.310157299041748,
      "citing_paper_id": "269804126",
      "cited_paper_id": 11137563
    },
    {
      "context_text": "We measure the inter-annotator agreements (IAA) of the event argument/summary/relation annotation between two annotators with Cohen’s Kappa (Cohen, 1960).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for measuring inter-annotator agreement.",
      "processing_time": 15.536768198013306,
      "citing_paper_id": "269804126",
      "cited_paper_id": 15926286
    },
    {
      "context_text": "A few datasets (Caselli and Vossen, 2017; Ning et al., 2018; Wang et al., 2022) annotate both temporal and causal relations concurrently.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions datasets that annotate both temporal and causal relations, which are relevant to document-level event extraction. However, specific dataset names are not provided.",
      "processing_time": 17.731577157974243,
      "citing_paper_id": "269804126",
      "cited_paper_id": 38234032
    },
    {
      "context_text": "ChFinAnn (Zheng et al., 2019) is restricted to the financial domain, featuring 5 event types and 35 argument types.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used for Chinese financial event extraction, specifically focusing on 5 event types and 35 argument types in the financial domain."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions ChFinAnn, which is a specific dataset used for Chinese financial event extraction. It is clearly identified and described in the context.",
      "processing_time": 23.986133575439453,
      "citing_paper_id": "269804126",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "ChFinAnn (Zheng et al., 2019) is nar-rowly defined, featuring 5 event types and 35 ar-gument types within the Chinese financial domain.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used to train and evaluate document-level event extraction models in the Chinese financial domain, focusing on 5 event types and 35 argument types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ChFinAnn' as a dataset with specific characteristics relevant to Chinese financial event extraction.",
      "processing_time": 22.97460651397705,
      "citing_paper_id": "269804126",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "We reproduce four representative neural models and report their performances on Deie, including (1) BERT base (Ethayarajh, 2019), a widely-used PLM, we adopt it as the backbone and build classification models on top of it.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT base but does not refer to it as a dataset. It is described as a pre-trained language model used as a backbone for building classification models.",
      "processing_time": 19.970234394073486,
      "citing_paper_id": "269804126",
      "cited_paper_id": 202120592
    },
    {
      "context_text": "…as the foundation for the development of numerous models aimed at improving sentence-level event extraction, resulting in significant achievements in this field (Wang et al., 2019a,b; Yang et al., 2019; Wadden et al., 2019; Tong et al., 2020; Wang et al., 2021; Lu et al., 2021; Liu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods for sentence-level event extraction.",
      "processing_time": 16.247389554977417,
      "citing_paper_id": "269804126",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "…as the foundation for the development of numerous models aimed at improving sentence-level event extraction, resulting in significant achievements in this field (Wang et al., 2019a,b; Yang et al., 2019; Wadden et al., 2019; Tong et al., 2020; Wang et al., 2021; Lu et al., 2021; Liu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods for sentence-level event extraction.",
      "processing_time": 16.247389554977417,
      "citing_paper_id": "269804126",
      "cited_paper_id": 202770954
    },
    {
      "context_text": "(1) BART base (Lewis et al., 2020), a widely-used sequence-to-sequence model for generation tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions BART, which is a model, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 16.90113401412964,
      "citing_paper_id": "269804126",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "RAMS (Ebner et al., 2020) narrows the context to a mere 5 sentences, which poses a challenge to encapsulating document-level event details.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to address challenges in document-level event extraction, specifically focusing on the limitation of narrow context in capturing event details."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions RAMS, which is a dataset for event extraction, but does not provide specific usage details or research questions. The citation is brief and focuses on a limitation rather than detailed usage.",
      "processing_time": 24.279052257537842,
      "citing_paper_id": "269804126",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "RAMS (Ebner et al., 2020) includes 3,993 annotated documents sourced from news, featuring 139 event types and 65 roles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to train and evaluate models on document-level event extraction, featuring 3,993 annotated news documents with 139 event types and 65 roles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS, which is a specific dataset used for document-level event extraction, featuring annotated documents from news sources.",
      "processing_time": 23.971243143081665,
      "citing_paper_id": "269804126",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We show the main statistics of Deie and compare them with some existing widely-used document-level event datasets in Table 2, including MUC-4, WikiEvents, RAMS, ChFinAnn, DuEE-Fin and DocEE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "WikiEvents",
        "RAMS",
        "ChFinAnn",
        "DuEE-Fin",
        "DocEE"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to compare statistics with Deie, focusing on document-level event extraction and annotation standards.",
        "WikiEvents": "Used to compare statistics with Deie, focusing on document-level event extraction and annotation standards.",
        "RAMS": "Used to compare statistics with Deie, focusing on document-level event extraction and annotation standards.",
        "ChFinAnn": "Used to compare statistics with Deie, focusing on document-level event extraction and annotation standards.",
        "DuEE-Fin": "Used to compare statistics with Deie, focusing on document-level event extraction and annotation standards.",
        "DocEE": "Used to compare statistics with Deie, focusing on document-level event extraction and annotation standards."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions multiple datasets by name, which are used for comparing statistics with the Deie dataset. These are specific, verifiable datasets relevant to document-level event extraction.",
      "processing_time": 49.17271018028259,
      "citing_paper_id": "269804126",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "MAVEN (Wang et al., 2020) concentrates on annotating event triggers and contains 168 types within 11,832 sentences.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN"
      ],
      "dataset_descriptions": {
        "MAVEN": "Used to annotate event triggers across a wide range of types, specifically investigating the detection of 168 event types within 11,832 sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "MAVEN is identified as a dataset in the context, which is further described as containing event triggers and a specific number of sentence annotations.",
      "processing_time": 23.95453929901123,
      "citing_paper_id": "269804126",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "(2) MAVEN-ERE (Wang et al., 2022), which provides simple but strong baselines for 4 event relation extraction tasks.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MAVEN-ERE"
      ],
      "dataset_descriptions": {
        "MAVEN-ERE": "Used to establish strong baselines for four event relation extraction tasks, focusing on improving the performance of event detection systems."
      },
      "confidence_score": 1.0,
      "reasoning": "MAVEN-ERE is identified as a dataset providing baselines for event relation extraction tasks, which aligns with the document-level event extraction topic.",
      "processing_time": 23.448359966278076,
      "citing_paper_id": "269804126",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "(2) CPT (Shao et al., 2021), a Chinese language understanding and generation model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions CPT as a model, not a dataset. It is used for Chinese language understanding and generation.",
      "processing_time": 16.566786289215088,
      "citing_paper_id": "269804126",
      "cited_paper_id": 237491754
    },
    {
      "context_text": "Researchers have made a lot of progress in this field (Zhang et al., 2020; Xu et al., 2021; Huang and Jia, 2021; Ren et al., 2022; Ma et al., 2022; Xu et al., 2022; Du and Cardie, 2020; Liu et al., 2021b; Wei et al., 2021; Li et al., 2021; Ren et al., 2023; Li et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research progress and various studies. No verifiable resources are identified.",
      "processing_time": 17.684762954711914,
      "citing_paper_id": "269804126",
      "cited_paper_id": 243865143
    },
    {
      "context_text": "Researchers have made a lot of progress in this field (Zhang et al., 2020; Xu et al., 2021; Huang and Jia, 2021; Ren et al., 2022; Ma et al., 2022; Xu et al., 2022; Du and Cardie, 2020; Liu et al., 2021b; Wei et al., 2021; Li et al., 2021; Ren et al., 2023; Li et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research progress and various studies. No verifiable resources are identified.",
      "processing_time": 17.684762954711914,
      "citing_paper_id": "269804126",
      "cited_paper_id": 266177132
    },
    {
      "context_text": "(3) Relative-Time (Wen and Ji, 2021 (3) For casual relation extraction, this performance is far from perfect, thus suggesting the challenges for event casual identification and presenting ample research opportunities to improve the performance in the future.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the challenges and future research opportunities in event causal identification.",
      "processing_time": 15.469666481018066,
      "citing_paper_id": "269804126",
      "cited_paper_id": 243865639
    },
    {
      "context_text": "The Text Analysis Conference (TAC) has introduced three benchmark datasets (Stephanie Strassel and others, 2014, 2016): TAC-KBP 2015, TAC-KBP 2016, and TAC-KBP 2017, featuring 9, 8, and 8 event types, along with 38, 18, and 18 event subtypes respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TAC-KBP 2015",
        "TAC-KBP 2016",
        "TAC-KBP 2017"
      ],
      "dataset_descriptions": {
        "TAC-KBP 2015": "Used to evaluate document-level event extraction, focusing on 9 event types and 38 event subtypes.",
        "TAC-KBP 2016": "Used to evaluate document-level event extraction, focusing on 8 event types and 18 event subtypes.",
        "TAC-KBP 2017": "Used to evaluate document-level event extraction, focusing on 8 event types and 18 event subtypes."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets introduced by TAC-KBP, which are relevant to document-level event extraction. These datasets are clearly named and have specific versions.",
      "processing_time": 40.284385681152344,
      "citing_paper_id": "269804126",
      "cited_paper_id": null
    },
    {
      "context_text": "For instance, * Yanan Cao is corresponding author MUC-4 dataset (McLean, 1992) encompasses 1,700 documents addressing 4 event types, and these types are close to each other and confined to the terrorist attack topic.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to address 4 event types in 1,700 documents, focusing on terrorist attacks, to study closely related event types in a confined topic."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a specific, verifiable dataset used for document-level event extraction, particularly focusing on terrorist attack events.",
      "processing_time": 25.17197823524475,
      "citing_paper_id": "269804126",
      "cited_paper_id": null
    },
    {
      "context_text": "The MUC-4 dataset (McLean, 1992), centered on Latin American terrorism news articles, comprises 1,700 documents that span 4 event types and 5 argument types.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to study event extraction in Latin American terrorism news articles, focusing on 4 event types and 5 argument types across 1,700 documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions the MUC-4 dataset, which is a specific, verifiable dataset used in the research. The dataset is described in detail, including its content and structure.",
      "processing_time": 25.709767818450928,
      "citing_paper_id": "269804126",
      "cited_paper_id": null
    },
    {
      "context_text": "We adopt CNN-based method and various 425 transformer-based methods as our baselines, in426 cluding: 1) TextCNN (Kim, 2014) uses different 427 sizes CNN kernels to extract key information in 428 text for classification.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets.",
      "processing_time": 16.1965434551239,
      "citing_paper_id": "252648205",
      "cited_paper_id": 3719231
    },
    {
      "context_text": "Following (Hamborg et al., 2018), The main event refers to the event reﬂected in the title and mainly described in the article.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or approach for event retrieval from news articles.",
      "processing_time": 16.219120979309082,
      "citing_paper_id": "252648205",
      "cited_paper_id": 3867049
    },
    {
      "context_text": "MUC-060 4(Grishman and Sundheim, 1996) consists of only 1700 news articles based on an ontology of 4 event types and 5 argument types.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-060"
      ],
      "dataset_descriptions": {
        "MUC-060": "Used to evaluate event extraction systems, focusing on 4 event types and 5 argument types across 1700 news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "MUC-060 is a specific dataset used in the Message Understanding Conferences, which fits the criteria for a verifiable resource.",
      "processing_time": 24.978710412979126,
      "citing_paper_id": "252648205",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "In reality, events usually appear in the form of doc-043 umentary descriptions, and the arguments involved in the event are also scattered in various sentences (Hamborg et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about events in documentary descriptions.",
      "processing_time": 15.675181865692139,
      "citing_paper_id": "252648205",
      "cited_paper_id": 202537206
    },
    {
      "context_text": "Wikipedia contains two kinds of events: historical events and timeline events (Hienert and Luciano, 2012).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets, only a general reference to types of events in Wikipedia.",
      "processing_time": 15.45069432258606,
      "citing_paper_id": "252648205",
      "cited_paper_id": null
    },
    {
      "context_text": "Besides, we provide a good evaluation scenario for testing the ability of the pre-trained models that aim at handling long text understand-107 ing, such as longformer(Beltagy et al., 2020) and ∞ -former(Martins et al., 2021).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only pre-trained models. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 17.646479845046997,
      "citing_paper_id": "252648205",
      "cited_paper_id": null
    },
    {
      "context_text": "WikiEvents(Li et al., 2021) con-065 sists of only 246 documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to study document-level event extraction, focusing on the integration of events across multiple sentences within 246 documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'WikiEvents' as a dataset consisting of 246 documents, which is specific and relevant to document-level event extraction.",
      "processing_time": 23.133658409118652,
      "citing_paper_id": "252648205",
      "cited_paper_id": null
    },
    {
      "context_text": "In order to better model the semantic relationship between entities, we use another BiLSTM ([5]) to get the final set of entity representation e = { e i } ei =1 which contains more complete context information.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BiLSTM). There are no verifiable resources or datasets mentioned.",
      "processing_time": 17.636921882629395,
      "citing_paper_id": "272575907",
      "cited_paper_id": 1915014
    },
    {
      "context_text": "Recent natural language processing advancements have enabled automated extraction and modeling of financial-related events from unstructured texts 17–24 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general advancements in NLP for financial event extraction. No specific dataset names are provided.",
      "processing_time": 18.275580406188965,
      "citing_paper_id": "278488523",
      "cited_paper_id": 216562779
    },
    {
      "context_text": "Recent natural language processing advancements have enabled automated extraction and modeling of financial-related events from unstructured texts 17–24 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general advancements in NLP for financial event extraction. No specific dataset names are provided.",
      "processing_time": 18.275580406188965,
      "citing_paper_id": "278488523",
      "cited_paper_id": 268417143
    },
    {
      "context_text": "The existing dataset does not take into account real-world length public announcements for the financial event extraction task 7,15,27,28 .",
      "catation_intent": "limitation",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'existing dataset' without specifying a name, and the cited papers do not provide additional specific dataset names. The context suggests a limitation in current datasets for financial event extraction.",
      "processing_time": 19.65444326400757,
      "citing_paper_id": "278488523",
      "cited_paper_id": 246241684
    },
    {
      "context_text": "The existing dataset does not take into account real-world length public announcements for the financial event extraction task 7,15,27,28 .",
      "catation_intent": "limitation",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'existing dataset' without specifying a name, and the cited papers do not provide additional specific dataset names. The context suggests a limitation in current datasets for financial event extraction.",
      "processing_time": 19.65444326400757,
      "citing_paper_id": "278488523",
      "cited_paper_id": 252569165
    },
    {
      "context_text": "The existing dataset does not take into account real-world length public announcements for the financial event extraction task 7,15,27,28 .",
      "catation_intent": "limitation",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'existing dataset' without specifying a name, and the cited papers do not provide additional specific dataset names. The context suggests a limitation in current datasets for financial event extraction.",
      "processing_time": 19.65444326400757,
      "citing_paper_id": "278488523",
      "cited_paper_id": null
    },
    {
      "context_text": "Such capabilities form a foundational basis for proactive risk alerting and trend forecasting 25,26 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general capabilities for risk alerting and trend forecasting.",
      "processing_time": 15.876701831817627,
      "citing_paper_id": "278488523",
      "cited_paper_id": 251640549
    },
    {
      "context_text": "These are critical not only for ensuring the stability and growth of financial institutions 1,2 but also for safeguarding the overall security and sustainable development of both financial markets and global economies 3,4 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, models, methods, or other resources. It discusses the importance of certain aspects for financial institutions and markets but does not reference any verifiable resources.",
      "processing_time": 20.53533124923706,
      "citing_paper_id": "278488523",
      "cited_paper_id": null
    },
    {
      "context_text": "These are critical not only for ensuring the stability and growth of financial institutions 1,2 but also for safeguarding the overall security and sustainable development of both financial markets and global economies 3,4 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, models, methods, or other resources. It discusses the importance of certain aspects for financial institutions and markets but does not reference any verifiable resources.",
      "processing_time": 20.53533124923706,
      "citing_paper_id": "278488523",
      "cited_paper_id": null
    },
    {
      "context_text": "The financial expert summarizes and extracts various predefined events by comprehending and analyzing financial documents 12 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general task of event extraction from financial documents.",
      "processing_time": 15.86998963356018,
      "citing_paper_id": "278488523",
      "cited_paper_id": null
    },
    {
      "context_text": "Hybrid event-extraction methods combine statistical methods and pattern-based methods together (Jungermann and Morik, 2008), (Bjorne et al., 2010).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 18.232590198516846,
      "citing_paper_id": "51871198",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Hybrid event-extraction methods combine statistical methods and pattern-based methods together (Jungermann and Morik, 2008), (Bjorne et al., 2010).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 18.232590198516846,
      "citing_paper_id": "51871198",
      "cited_paper_id": 17984630
    },
    {
      "context_text": "Hybrid event-extraction methods combine statistical methods and pattern-based methods together (Jungermann and Morik, 2008), (Bjorne et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 16.751346588134766,
      "citing_paper_id": "51871198",
      "cited_paper_id": 1942185
    },
    {
      "context_text": "DS has proved its effectiveness in automatically labeling data for Relation Extraction (Zeng et al., 2015) and Event Extraction (Chen et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions 'Relation Extraction' and 'Event Extraction' but does not specify any datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 19.631295680999756,
      "citing_paper_id": "51871198",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "DS has proved its effectiveness in automatically labeling data for Relation Extraction (Zeng et al., 2015) and Event Extraction (Chen et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions 'Relation Extraction' and 'Event Extraction' but does not specify any datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 19.631295680999756,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "DS has proved its effectiveness in automatically labeling data for Relation Extraction (Zeng et al., 2015) and Event Extraction (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the technique of distant supervision. No clear, verifiable resource names are present.",
      "processing_time": 17.963191986083984,
      "citing_paper_id": "51871198",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "The current EE approaches can be mainly classified into statistical methods, pattern-based method and hybrid method (Hogenboom et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general approaches to event extraction.",
      "processing_time": 15.16687822341919,
      "citing_paper_id": "51871198",
      "cited_paper_id": 8174613
    },
    {
      "context_text": "We make use of Distance Supervision (DS) which has been validated to generate labeled data for EE (Chen et al., 2017) to automatically generate large-scaled annotated data.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Distance Supervision' and 'automatically generate large-scaled annotated data', but does not specify a named dataset. The cited paper title suggests the generation of labeled data for event extraction, but no specific dataset name is provided.",
      "processing_time": 21.592775106430054,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Event Extraction (EE), a challenging task in Nature Language Processing (NLP), aims at discovering event mentions 3 and extracting events which contain event triggers 4 and event arguments 5 from texts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only describes the general task of Event Extraction in NLP.",
      "processing_time": 16.751582622528076,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Figure 2 describes the architecture of our proposed DCFEE framework which primarily involves the following two components: (i) Data Generation, which makes use of DS to automatically label event mention from the whole documen-t (document-level data) and annotate triggers and arguments from event mention (sentence-level data); (ii) EE system, which contains Sentence-level Event Extraction (SEE) supported by sentence-level labeled data and Document-level Event Extraction (DEE) supported by document-level labeled data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'document-level data' and 'sentence-level data' but does not provide specific, identifiable dataset names. The terms are too generic and do not meet the criteria for inclusion.",
      "processing_time": 20.22039794921875,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "In order to improve recall, there are two main research directions: build relatively complete pattern library and use a semi-automatic method to build trigger dictionary (Chen et al., 2017), (Gu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only research directions and methods.",
      "processing_time": 14.957055807113647,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "In order to improve recall, there are two main research directions: build relatively complete pattern library and use a semi-automatic method to build trigger dictionary (Chen et al., 2017), (Gu et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only research directions and methods.",
      "processing_time": 14.952914476394653,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Figure 4 depicts the overall architecture of the EE system proposed in this paper which primarily involves the following two components: The sentence-level Event Extraction (SEE) purposes to extract event arguments and event triggers from one sentence; The document-level Event Extraction (DEE) aims to extract event arguments from the whole document based on a key event detection model and an arguments-completion strategy.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only describes the components of an event extraction system. No verifiable resources are identified.",
      "processing_time": 18.193992853164673,
      "citing_paper_id": "51871198",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Hybrid event-extraction method-s combine statistical methods and pattern-based methods together (Jungermann and Morik, 2008), (Bjorne et al., 2010).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers are used to support the discussion of hybrid event-extraction methods.",
      "processing_time": 19.325961351394653,
      "citing_paper_id": "51871198",
      "cited_paper_id": 17984630
    },
    {
      "context_text": "Motivated by the one-sense-per-discourse theory (Gale et al., 1992) that mentions of an ambiguous word usually tend to share the same sense in a given discourse, we hypothesize that a participant tends to play consistent roles across multiple events in the same document .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a theoretical concept. No dataset names are present in the citation span.",
      "processing_time": 17.298508644104004,
      "citing_paper_id": "249191641",
      "cited_paper_id": 131886
    },
    {
      "context_text": "Motivated by the one-sense-per-discourse theory (Gale et al., 1992) that mentions of an ambiguous word usually tend to share the same sense in a given discourse, we hypothesize that a participant tends to play consistent roles across multiple events in the same document.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a theoretical concept. No dataset names are present in the citation span.",
      "processing_time": 17.282463788986206,
      "citing_paper_id": "249191641",
      "cited_paper_id": 131886
    },
    {
      "context_text": ", 2021) and (Du and Cardie, 2020) are designed for Role-filler Entity Extraction (REE) task under the assumption that one generic template is produced for each document, while our work focuses on extracting arguments for multiple events for each document.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of tasks and methodologies.",
      "processing_time": 15.375713348388672,
      "citing_paper_id": "249191641",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "It is a practically more useful but more challenging task than sentence-level Ar-gument Extraction (Nguyen et al., 2016; Wadden et al., 2019; Lin et al., 2020) because in a typical long input document events usually scatter across multiple sentences and are inherently connected.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the challenge of document-level event extraction compared to sentence-level argument extraction.",
      "processing_time": 17.554505109786987,
      "citing_paper_id": "249191641",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We compare EA 2 E with document-level BART-Gen (Li et al., 2021), sentence-level ONEIE (Lin et al., 2020) and BERT-CRF (Shi and Lin, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No dataset names are present in the text.",
      "processing_time": 17.282310485839844,
      "citing_paper_id": "249191641",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Du and Ji (2022); Choudhary and Du (2024) leverage end-to-end deep learning-based methods (Du et al., 2017; Du and Cardie, 2018) for generating QA pairs for representing events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for generating QA pairs.",
      "processing_time": 15.581150770187378,
      "citing_paper_id": "273185680",
      "cited_paper_id": 2172129
    },
    {
      "context_text": "Du and Cardie (2020); Liu et al. (2020a) utilize heuristic-based methods for generating questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only heuristic-based methods for generating questions. No clear identifiers for datasets are present.",
      "processing_time": 17.57418394088745,
      "citing_paper_id": "273185680",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Du and Cardie (2020); Liu et al. (2020a) utilize heuristic-based methods for generating questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only heuristic-based methods for generating questions. No clear identifiers for datasets are present.",
      "processing_time": 17.57418394088745,
      "citing_paper_id": "273185680",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "…recent advancements have leveraged PLMs and introduce semantic structures (Tran Phu and Nguyen, 2021; Hu et al., 2023a), external knowledge (Liu et al., 2020b; Cao et al., 2021), and data augmentation (Zuo et al., 2020, 2021) approaches and investigated the potency of ECI with LLMs (Gao et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 18.76561689376831,
      "citing_paper_id": "273185680",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "…recent advancements have leveraged PLMs and introduce semantic structures (Tran Phu and Nguyen, 2021; Hu et al., 2023a), external knowledge (Liu et al., 2020b; Cao et al., 2021), and data augmentation (Zuo et al., 2020, 2021) approaches and investigated the potency of ECI with LLMs (Gao et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 18.76561689376831,
      "citing_paper_id": "273185680",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "Cause Effect language logical/temporal reasoning (Yang et al., 2020, 2023, 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers that discuss methods or findings.",
      "processing_time": 15.81049394607544,
      "citing_paper_id": "273185680",
      "cited_paper_id": 226254029
    },
    {
      "context_text": "Afterwards, we follow previous IE toolkits (Wen et al., 2021; Du et al., 2022) to extract the event arguments with BART-Gen (Li et al., 2021), a generative model for document-level event argument extraction (EAE).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on using BART-Gen for document-level event argument extraction, which is a method, not a dataset.",
      "processing_time": 20.84633207321167,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235097376
    },
    {
      "context_text": "Afterwards, we follow previous IE toolkits (Wen et al., 2021; Du et al., 2022) to extract the event arguments with BART-Gen (Li et al., 2021), a generative model for document-level event argument extraction (EAE).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on using BART-Gen for document-level event argument extraction, which is a method, not a dataset.",
      "processing_time": 20.84633207321167,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "Afterwards, we follow previous IE toolkits (Wen et al., 2021; Du et al., 2022) to extract the event arguments with BART-Gen (Li et al., 2021), a generative model for document-level event argument extraction (EAE).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on using BART-Gen for document-level event argument extraction, which is a method, not a dataset.",
      "processing_time": 20.84633207321167,
      "citing_paper_id": "273185680",
      "cited_paper_id": 249010869
    },
    {
      "context_text": "The event arguments and their single-hop relations are obtained from relevant IE models (Peng et al., 2023b; Li et al., 2021; Eberts and Ulges, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to IE models. No dataset names are present in the context.",
      "processing_time": 17.87207341194153,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "The event arguments and their single-hop relations are obtained from relevant IE models (Peng et al., 2023b; Li et al., 2021; Eberts and Ulges, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to IE models. No dataset names are present in the context.",
      "processing_time": 17.87207341194153,
      "citing_paper_id": "273185680",
      "cited_paper_id": 262825274
    },
    {
      "context_text": "Event Argument Extraction & Joint Entity and Relation Extraction We adopted the pre-trained models released by BART-Gen 6 (Li et al., 2021) and JEREX 7 (Eberts and Ulges, 2021) to conduct EAE and joint entity and relation extraction on our datasets, separately.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'our datasets' which is too generic and does not provide a specific, identifiable dataset name. No other specific datasets are mentioned.",
      "processing_time": 19.278412580490112,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "We adopt the templates defined by Li et al. (2021) to extract arguments for the event mentions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event detection.",
      "processing_time": 15.088784217834473,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "Event Detection We trained an event detection using the OmniEvent toolkit (Peng et al., 2023b) on the WikiEvents dataset (Li et al., 2021), and we selected CLEVE (Wang et al., 2021) as the PLM.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to train an event detection model, focusing on document-level event extraction. The dataset provides annotated documents for supervised learning."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the WikiEvents dataset, which is a specific, verifiable dataset used for training an event detection model. CLEVE is mentioned but is a method, not a dataset.",
      "processing_time": 25.015259981155396,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "Event Detection We trained an event detection using the OmniEvent toolkit (Peng et al., 2023b) on the WikiEvents dataset (Li et al., 2021), and we selected CLEVE (Wang et al., 2021) as the PLM.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to train an event detection model, focusing on document-level event extraction. The dataset provides annotated documents for supervised learning."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the WikiEvents dataset, which is a specific, verifiable dataset used for training an event detection model. CLEVE is mentioned but is a method, not a dataset.",
      "processing_time": 25.015259981155396,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235254286
    },
    {
      "context_text": "Following the previous research in EE (Du and Cardie, 2020; Deng et al., 2021), we define our Event-Event Causal Relation Extraction (ECRE) task as two subtasks: Event Causality Identification (ECI) , which identifies the existence of causal relationships between event mentions, and Causal Relation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only subtasks of the Event-Event Causal Relation Extraction task. No verifiable resources are identified.",
      "processing_time": 19.525118827819824,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "We train an event detection model us-ing the CLEVE (Wang et al., 2021) PLM on the WikiEvents dataset (Li et al., 2021) to classify the event mentions to their most likely belonged event type in the KAIROS ontology.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to train an event detection model using the CLEVE PLM, classifying event mentions to their most likely event type in the KAIROS ontology."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the WikiEvents dataset for training an event detection model. CLEVE is a method, not a dataset.",
      "processing_time": 24.67566227912903,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235166504
    },
    {
      "context_text": "We train an event detection model us-ing the CLEVE (Wang et al., 2021) PLM on the WikiEvents dataset (Li et al., 2021) to classify the event mentions to their most likely belonged event type in the KAIROS ontology.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to train an event detection model using the CLEVE PLM, classifying event mentions to their most likely event type in the KAIROS ontology."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the WikiEvents dataset for training an event detection model. CLEVE is a method, not a dataset.",
      "processing_time": 24.67566227912903,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235254286
    },
    {
      "context_text": "…advancements have leveraged PLMs and introduce semantic structures (Tran Phu and Nguyen, 2021; Hu et al., 2023a), external knowledge (Liu et al., 2020b; Cao et al., 2021), and data augmentation (Zuo et al., 2020, 2021) approaches and investigated the potency of ECI with LLMs (Gao et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles suggest a focus on methodologies rather than specific datasets.",
      "processing_time": 18.994549036026,
      "citing_paper_id": "273185680",
      "cited_paper_id": 235313431
    },
    {
      "context_text": "…advancements have leveraged PLMs and introduce semantic structures (Tran Phu and Nguyen, 2021; Hu et al., 2023a), external knowledge (Liu et al., 2020b; Cao et al., 2021), and data augmentation (Zuo et al., 2020, 2021) approaches and investigated the potency of ECI with LLMs (Gao et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles suggest a focus on methodologies rather than specific datasets.",
      "processing_time": 18.994549036026,
      "citing_paper_id": "273185680",
      "cited_paper_id": 236460024
    },
    {
      "context_text": "We extend the definition proposed by Automatic Content Extraction (ACE), consisting of event mentions and event arguments (Frisoni et al., 2021), with the single-hop relationships of arguments to enrich their information in contexts, as examples shown in Figure 3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Automatic Content Extraction (ACE)' but does not indicate that it is a dataset. It appears to be a framework or project, and there is no clear indication of its use as a dataset.",
      "processing_time": 21.196918725967407,
      "citing_paper_id": "273185680",
      "cited_paper_id": 244678529
    },
    {
      "context_text": "In the single-turn QA strategy, we make use of the prompt proposed by previous work (Man et al., 2022; Gao et al., 2023) and incorporate the event structures of the two event mentions into the prompt.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or strategies for incorporating event structures into prompts.",
      "processing_time": 16.375662565231323,
      "citing_paper_id": "273185680",
      "cited_paper_id": 250390907
    },
    {
      "context_text": "An intuitive option is to utilize LLMs for this procedure; however, since they have been found to be insufficient for IE (Li et al., 2023; Peng et al., 2023a), we adopt PLM-based approaches to construct event structures, consisting of three steps: Event Detection , Event Argument Extraction , and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the use of PLMs for event structure construction, which is not a dataset.",
      "processing_time": 20.13328981399536,
      "citing_paper_id": "273185680",
      "cited_paper_id": 258297899
    },
    {
      "context_text": "In addition, QA-based methods have also been investigated in temporal relation extraction (Cohen and Bar, 2023) and ECI (Gao et al., 2023), or retrieving useful background knowledge to improve event causality recognition (Kruengkrai et al., 2017; Kad-owaki et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers are referenced for their methodologies, not for providing datasets.",
      "processing_time": 18.968985319137573,
      "citing_paper_id": "273185680",
      "cited_paper_id": 259858871
    },
    {
      "context_text": "Unlike previous work that relys heavily on semantic structures, we leverage cross-task knowledge to construct document-level event structures to enrich event information, motivated by the effectiveness of cross-task knowledge in IE (Lin et al., 2020; Jin et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and approaches. The context focuses on leveraging cross-task knowledge for constructing document-level event structures.",
      "processing_time": 19.51065945625305,
      "citing_paper_id": "273185680",
      "cited_paper_id": 260063107
    },
    {
      "context_text": "We compared the performance of KnowQA against the following state-of-the-art baselines from existing ECRE research: (1) PLM (Tran Phu and Nguyen, 2021) 6) HOTECI (Man et al., 2024b) leverages optimal transport to select the most important words and sentences from full documents; (7) GIMC (He et al., 2024) constructs a heterogeneous graph interaction network to model long-distance dependencies between events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing performance against various baselines, none of which are datasets.",
      "processing_time": 19.506521224975586,
      "citing_paper_id": "273185680",
      "cited_paper_id": 268249143
    },
    {
      "context_text": "…(1) PLM (Tran Phu and Nguyen, 2021) 6) HOTECI (Man et al., 2024b) leverages optimal transport to select the most important words and sentences from full documents; (7) GIMC (He et al., 2024) constructs a heterogeneous graph interaction network to model long-distance dependencies between events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited paper title also does not provide additional context about datasets.",
      "processing_time": 18.71268892288208,
      "citing_paper_id": "273185680",
      "cited_paper_id": 268249143
    },
    {
      "context_text": "This phenomenon contributes to low precision and high recall of LLMs on this task, which severely hampers their performance in this field (Gao et al., 2023; Liu et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers discussing issues with LLMs in a certain task.",
      "processing_time": 17.81757926940918,
      "citing_paper_id": "273185680",
      "cited_paper_id": 270199894
    },
    {
      "context_text": "To ensure the richness of classification, we adopt the KAIROS 2 ontology, a superset of ACE 2005 (Walker et al., 2006) that consists of 50 event types and 59 argument roles 3 , to classify the event mentions.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'KAIROS 2 ontology' and 'ACE 2005', which are not datasets but ontologies. No datasets are explicitly mentioned or used in the described research context.",
      "processing_time": 20.78815531730652,
      "citing_paper_id": "273185680",
      "cited_paper_id": null
    },
    {
      "context_text": "The majority of previous studies posit that events are articulated solely within a single sentence, hence their primary focus has been on sentence-level information extraction (Chen et al., 2015; Liu et al., 2018; Zhou et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general references to previous studies and their focus on sentence-level information extraction.",
      "processing_time": 18.08334732055664,
      "citing_paper_id": "272368002",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "The majority of previous studies posit that events are articulated solely within a single sentence, hence their primary focus has been on sentence-level information extraction (Chen et al., 2015; Liu et al., 2018; Zhou et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general references to previous studies and their focus on sentence-level information extraction.",
      "processing_time": 18.08334732055664,
      "citing_paper_id": "272368002",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "We propose new perspectives and methods, solving the example selection problem from the new perspective of Definition-Enhanced Prompt-ing Heuristic Method, promoting explicit heuristic learning in ICL.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. There are no clear identifiers for datasets in the text.",
      "processing_time": 18.349167108535767,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "In contrast to the traditional reliance on vast corpora, the incorporation of In-Context Learning (ICL) within LLMs has emerged as a transformative approach (Brown et al., 2020; Zhou et al., 2022, 2023; Wang et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of In-Context Learning (ICL) within Large Language Models (LLMs).",
      "processing_time": 19.48283553123474,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "Gonen et al. (2023) have noted that the performance of ICL is highly sensitive to the selection of examples.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about the sensitivity of ICL to example selection.",
      "processing_time": 17.45450758934021,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "Gonen et al. (2023) have noted that the performance of ICL is highly sensitive to the selection of examples.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about the sensitivity of ICL to example selection.",
      "processing_time": 17.45450758934021,
      "citing_paper_id": "272368002",
      "cited_paper_id": 254408772
    },
    {
      "context_text": "ICL adeptly diminishes the necessity for extensive datasets by leveraging a modest collection of examples, serving as illustrative prompts for both inputs and outputs.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a general concept of 'extensive datasets' and 'a modest collection of examples', which are too generic and do not meet the criteria for inclusion.",
      "processing_time": 21.65458106994629,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "(Agrawal et al., 2022) have employed LLMs in clinical Event Argument Extraction (EAE) using standard prompts that do not involve any reasoning strategies, while research on prompting strategies specifically tailored for the EAE task is scarce, with only (Zhou et al., 2024) exploring the promising and challenging research direction of reducing the dependence on specific large-scale training datasets through ICL, thereby enhancing the generalization capability of LLMs in EAE tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of LLMs and ICL for EAE tasks. No verifiable resources are identified.",
      "processing_time": 19.71163558959961,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "This implies that well-designed prompts and heuristic rules can effectively enhance ICL performance without the need for fine-tuning on task-specific datasets.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to 'task-specific datasets' which is too generic.",
      "processing_time": 17.80248498916626,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "Utilizing inputs that include document content, task definitions, argument extraction rules, and identified event types and triggers, we constructed a definition-driven heuristic ICL.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The context is too generic to infer any specific dataset.",
      "processing_time": 18.310148239135742,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "This capability is particularly useful in ICL, as LLMs are always faced with unseen samples and unseen classes (Zhou et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general capability in few-shot learning. No verifiable resources are identified.",
      "processing_time": 18.053189992904663,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "The In-Context Learning (ICL) (Brown et al., 2020) methodology is designed to expedite the adaptability of language models across various tasks, necessitating minimal or no prior data (Wei et al., 2022; Kojima et al., 2022).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methodologies and models. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 18.048561811447144,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "The In-Context Learning (ICL) (Brown et al., 2020) methodology is designed to expedite the adaptability of language models across various tasks, necessitating minimal or no prior data (Wei et al., 2022; Kojima et al., 2022).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methodologies and models. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 18.048561811447144,
      "citing_paper_id": "272368002",
      "cited_paper_id": 249017743
    },
    {
      "context_text": "In ICL, heuristics are used to select or design examples (demonstrations) that can guide the model to make correct predictions(Zhou et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach using heuristics in few-shot learning.",
      "processing_time": 17.426551580429077,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "In ICL, heuristics are used to select or design examples (demonstrations) that can guide the model to make correct predictions(Zhou et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach using heuristics in few-shot learning.",
      "processing_time": 17.426551580429077,
      "citing_paper_id": "272368002",
      "cited_paper_id": null
    },
    {
      "context_text": "This includes the choice of prompt templates, the selection of context examples, and the order of examples (Zhao et al., 2021; Lu et al., 2022), as well as the selection of examples and the format of inference steps (Zhang et al., 2022b; Fu et al., 2022; Zhang et al., 2022a), which collectively impact the application of ICL on LLMs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers are referenced for their contributions to few-shot learning and in-context learning in language models.",
      "processing_time": 20.327491521835327,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "The performance of ICL is highly sensitive to specific settings, necessitating the selection of appropriate contextual information and the optimization of the model’s training process.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the sensitivity of ICL to specific settings and the need for optimizing the training process.",
      "processing_time": 18.898563385009766,
      "citing_paper_id": "272368002",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "Document-level EAE commonly relies on manual domain and pattern annotation for supervised learning models (Xiang and Wang, 2019; Lin et al., 2020; Li et al., 2022; Liu et al., 2022; Hsu et al., 2022; Liu et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that discuss supervised learning models for document-level event argument extraction.",
      "processing_time": 18.323604106903076,
      "citing_paper_id": "272368002",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "4 Related works 4.1 Document-level EAE Document-level EAE commonly relies on manual domain and pattern annotation for supervised learning models (Xiang and Wang, 2019; Lin et al., 2020; Li et al., 2022; Liu et al., 2022; Hsu et al., 2022; Liu et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to related works and their approaches to document-level event extraction.",
      "processing_time": 17.771345138549805,
      "citing_paper_id": "272368002",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "CoT has proven particularly adept at tackling complex reasoning challenges, encompassing arithmetic and commonsense reasoning (Cobbe et al., 2021; Wei et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers discussing complex reasoning challenges.",
      "processing_time": 15.964741945266724,
      "citing_paper_id": "272368002",
      "cited_paper_id": 239998651
    },
    {
      "context_text": "For instance, InstructGPT (Ouyang et al., 2022) and ChatGLM (Du et al., 2022) have excelled in diverse downstream applications such as dialogue systems and text summarization generation through metic-ulously crafted instructions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (InstructGPT and ChatGLM). The context focuses on the capabilities of these models in downstream applications.",
      "processing_time": 20.186758995056152,
      "citing_paper_id": "272368002",
      "cited_paper_id": 247519241
    },
    {
      "context_text": "…templates, the selection of context examples, and the order of examples (Zhao et al., 2021; Lu et al., 2022), as well as the selection of examples and the format of inference steps (Zhang et al., 2022b; Fu et al., 2022; Zhang et al., 2022a), which collectively impact the application of ICL on LLMs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers are referenced for their methodologies, not for providing datasets.",
      "processing_time": 18.285743474960327,
      "citing_paper_id": "272368002",
      "cited_paper_id": 252683303
    },
    {
      "context_text": "…of LLMs on data from different domains, which is crucial in real-world applications where large amounts of annotated data may be difficult to obtain (Tong et al., 2022; Luo et al., 2023), we tested the model performance under the Cross domain-settings of the DocEE dataset, as shown in Table 2.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to test model performance under cross-domain settings, focusing on document-level event extraction with limited annotated data."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocEE dataset' which is a specific dataset used for document-level event extraction. The dataset is used to test model performance under cross-domain settings.",
      "processing_time": 24.232003211975098,
      "citing_paper_id": "272368002",
      "cited_paper_id": 256389694
    },
    {
      "context_text": "It is noteworthy that due to the relatively high cost of Deepseek-v2-chat, its evaluation was limited to a subset of the dataset.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context does not provide a specific dataset name, only a generic reference to 'a subset of the dataset'. No clear, verifiable resource is mentioned.",
      "processing_time": 19.656007528305054,
      "citing_paper_id": "272368002",
      "cited_paper_id": 269613809
    },
    {
      "context_text": "The experiments were conducted using two large language models: the publicly available Deepseek-v2-chat (Liu et al., 2024) and Llama3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions two large language models but does not refer to any specific datasets. The context is focused on the models used rather than datasets.",
      "processing_time": 19.141457557678223,
      "citing_paper_id": "272368002",
      "cited_paper_id": 269613809
    },
    {
      "context_text": "When applied to tasks that do not inherently require reasoning, the CoT method risks simplifying the multi-step reasoning process into a potentially in-adequate single-step, thereby undermining its full potential (Shum et al., 2023; Zhou et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the CoT method and its application to tasks.",
      "processing_time": 17.12956690788269,
      "citing_paper_id": "272368002",
      "cited_paper_id": null
    },
    {
      "context_text": "For the Heuristics-driven CoT part, we mainly follow the settings and definitions proposed by Zhou et al. (2024) and Wei et al. (2022) to guide the model along a specific logical path, thereby improving the accuracy of event argument extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and settings from other papers.",
      "processing_time": 16.568178176879883,
      "citing_paper_id": "272368002",
      "cited_paper_id": null
    },
    {
      "context_text": "Here, we present the replication of results based on the CoT prompting method by Zhou et al. (2024), which represents one of the few excellent prompting strategies specifically tailored for the Event Argument Extraction task in LLMs.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (CoT prompting) and a task (Event Argument Extraction).",
      "processing_time": 18.262454986572266,
      "citing_paper_id": "272368002",
      "cited_paper_id": null
    },
    {
      "context_text": "Moreover, cognitive research has found that compared to complex methods, humans use heuristics as an effective cognitive pathway to achieve more accurate reasoning (Gigerenzer and Gaissmaier, 2011; Hogarth and Karelaia, 2007; Zhou et al., 2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to cognitive research findings.",
      "processing_time": 15.646065950393677,
      "citing_paper_id": "272368002",
      "cited_paper_id": null
    },
    {
      "context_text": "As similar results presented in the studies by Wei et al. (2022) and Zhou et al. (2024), paralleling this human cognitive strategy, we enable LLMs to learn from explicit heuristics to enhance reasoning.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to studies and a general approach to enhancing reasoning in LLMs.",
      "processing_time": 18.23905324935913,
      "citing_paper_id": "272368002",
      "cited_paper_id": null
    },
    {
      "context_text": "Within the domain of few-shot learning, our comparative analysis is grounded on the performance data from a limited number of samples as previously reported by Liu et al. (2023) and Zhou et al. (2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to 'performance data'. No multi-word proper nouns, acronyms, or other specific identifiers are present.",
      "processing_time": 19.85013246536255,
      "citing_paper_id": "272368002",
      "cited_paper_id": null
    },
    {
      "context_text": "For the assessment, we follow the metrics outlined in (Ma et al., 2022; Zhou et al., 2024), which are the F1 score for argument identification (Arg-I) and the F1 score for argument classification (Arg-C).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only metrics for evaluation. No dataset names are present in the citation span.",
      "processing_time": 17.979098796844482,
      "citing_paper_id": "272368002",
      "cited_paper_id": null
    },
    {
      "context_text": "Humans use heuristics as an effective cognitive pathway, which often leads to more accurate reasoning than complex methods (Gigerenzer and Gaissmaier, 2011; Hogarth and Karelaia, 2007; Zhou et al., 2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to cognitive heuristics and reasoning methods.",
      "processing_time": 16.863729238510132,
      "citing_paper_id": "272368002",
      "cited_paper_id": null
    },
    {
      "context_text": "Furthermore, recent studies (Lin et al., 2023; Zhou et al., 2024) have expanded the application of LLMs in complex tasks like event extraction by ingeniously constructing prompts, highlighting the broad prospects of LLMs in the EAE domain.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of LLMs in event extraction tasks.",
      "processing_time": 17.09758162498474,
      "citing_paper_id": "272368002",
      "cited_paper_id": null
    },
    {
      "context_text": "We converted the optional templates to required templates and removed the subtypes of the incidents as done in previous work (Chambers, 2013; Du et al., 2021b) We use the tuning data as training data and reserve 10% of the test data, i.e. 12 examples, to create a development/validation set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not mention any specific, verifiable datasets by name. It only refers to 'tuning data' and 'test data', which are too generic and lack specific identifiers.",
      "processing_time": 20.831550121307373,
      "citing_paper_id": "248780414",
      "cited_paper_id": 6341459
    },
    {
      "context_text": "We converted the optional templates to required templates and removed the subtypes of the incidents as done in previous work (Chambers, 2013; Du et al., 2021b) so that the dataset is transformed into standardized templates.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions transforming a dataset into standardized templates, but does not specify the name of the dataset. The cited papers do not provide additional information to identify a specific dataset.",
      "processing_time": 20.421180963516235,
      "citing_paper_id": "248780414",
      "cited_paper_id": 6341459
    },
    {
      "context_text": "We converted the optional templates to required templates and removed the subtypes of the incidents as done in previous work (Chambers, 2013; Du et al., 2021b) so that the dataset is transformed into standardized templates.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions transforming a dataset into standardized templates, but does not specify the name of the dataset. The cited papers do not provide additional information to identify a specific dataset.",
      "processing_time": 20.421180963516235,
      "citing_paper_id": "248780414",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "…(Vilar et al., 2006; Zhou et al., 2008; Farrús et al., 2010; Kholy and Habash, 2011; Ze-man et al., 2011; Popovi´c and Ney, 2011), coreference resolution (Uryupina, 2008; Kummerfeld and Klein, 2013; Martschat and Strube, 2014; Martschat et al., 2015) and parsing (Kummerfeld et al., 2012).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various research works and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 19.590090036392212,
      "citing_paper_id": "248780414",
      "cited_paper_id": 14672517
    },
    {
      "context_text": "…(Vilar et al., 2006; Zhou et al., 2008; Farrús et al., 2010; Kholy and Habash, 2011; Zeman et al., 2011; Popović and Ney, 2011), coreference resolution (Uryupina, 2008; Kummerfeld and Klein, 2013; Martschat and Strube, 2014; Martschat et al., 2015) and parsing (Kummerfeld et al., 2012).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various research works and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 19.60235571861267,
      "citing_paper_id": "248780414",
      "cited_paper_id": 16925224
    },
    {
      "context_text": ", 2011; Popović and Ney, 2011), coreference resolution (Uryupina, 2008; Kummerfeld and Klein, 2013; Martschat and Strube, 2014; Martschat et al., 2015) and parsing (Kummerfeld et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. There are no clear identifiers for datasets, corpora, or other reusable resources.",
      "processing_time": 20.115855932235718,
      "citing_paper_id": "248780414",
      "cited_paper_id": 16925224
    },
    {
      "context_text": "Valls-Vargas et al. (2017) proposed a framework for studying how different errors propagate through an IE system; however, the framework can only be used for pipelined systems, not end-to-end ones.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a framework for error analysis in information extraction systems.",
      "processing_time": 15.886525630950928,
      "citing_paper_id": "248780414",
      "cited_paper_id": 35264612
    },
    {
      "context_text": "testing like Errudite (Wu et al., 2019), CHECKLIST (Ribeiro et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tools or methods. The context is too limited to infer the use of any datasets.",
      "processing_time": 19.06450653076172,
      "citing_paper_id": "248780414",
      "cited_paper_id": 196199409
    },
    {
      "context_text": "Recently, generalized automated error analysis frameworks involving human-in-the-loop testing like Errudite (Wu et al., 2019), CHECK-\nLIST (Ribeiro et al., 2020), CrossCheck (Arendt et al., 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several frameworks but does not refer to any specific datasets. The focus is on methods and tools for error analysis.",
      "processing_time": 18.555176258087158,
      "citing_paper_id": "248780414",
      "cited_paper_id": 196199409
    },
    {
      "context_text": "Recently, generalized automated error analysis frameworks involving human-in-the-loop testing like Errudite (Wu et al., 2019), CHECK-\nLIST (Ribeiro et al., 2020), CrossCheck (Arendt et al., 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several frameworks but does not specify any datasets. The frameworks are tools or methods, not datasets.",
      "processing_time": 17.675629138946533,
      "citing_paper_id": "248780414",
      "cited_paper_id": 196199409
    },
    {
      "context_text": "To date, for example, there has been no attempt to directly compare the error landscape and distribution of\n2See, for example, Zhang et al. (2019), Du and Cardie (2020) and Lin et al. (2020) for within-sentence event extraction; Akbik et al. (2018), and Akbik et al. (2019) for named entity…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 19.577781677246094,
      "citing_paper_id": "248780414",
      "cited_paper_id": 198118773
    },
    {
      "context_text": "To date, for example, there has been no attempt to directly compare the error landscape and distribution of\n2See, for example, Zhang et al. (2019), Du and Cardie (2020) and Lin et al. (2020) for within-sentence event extraction; Akbik et al. (2018), and Akbik et al. (2019) for named entity…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 19.577781677246094,
      "citing_paper_id": "248780414",
      "cited_paper_id": 216562330
    },
    {
      "context_text": ", 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tools and frameworks. The context is about applying these tools to tasks like machine comprehension and relation extraction.",
      "processing_time": 19.78818440437317,
      "citing_paper_id": "248780414",
      "cited_paper_id": 202712654
    },
    {
      "context_text": "L IST (Ribeiro et al., 2020), CrossCheck (Arendt et al., 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions tools and frameworks (L IST, CrossCheck, AllenNLP Interpret) but does not refer to any specific datasets. The context focuses on the application of these tools to tasks like machine comprehension and relation extraction.",
      "processing_time": 21.720791816711426,
      "citing_paper_id": "248780414",
      "cited_paper_id": 202712654
    },
    {
      "context_text": "L IST (Ribeiro et al., 2020), CrossCheck (Arendt et al., 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions tools and frameworks (L IST, CrossCheck, AllenNLP Interpret) but does not refer to any specific datasets. The context focuses on the application of these tools to tasks like machine comprehension and relation extraction.",
      "processing_time": 21.720791816711426,
      "citing_paper_id": "248780414",
      "cited_paper_id": 216869183
    },
    {
      "context_text": "L IST (Ribeiro et al., 2020), CrossCheck (Arendt et al., 2021), and AllenNLP Interpret (Wallace et al., 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions tools and frameworks (L IST, CrossCheck, AllenNLP Interpret) but does not refer to any specific datasets. The context focuses on the application of these tools to tasks like machine comprehension and relation extraction.",
      "processing_time": 21.720791816711426,
      "citing_paper_id": "248780414",
      "cited_paper_id": 218551201
    },
    {
      "context_text": "Although information extraction (IE) research has almost uniformly focused on sentence-level relation and event extraction (Grishman, 2019), the earliest research in the area formulated the task at the document level.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about the focus of IE research.",
      "processing_time": 17.046913385391235,
      "citing_paper_id": "248780414",
      "cited_paper_id": 203701085
    },
    {
      "context_text": ", 2019) have successfully been applied to tasks like machine comprehension and relation extraction (Alt et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tasks like machine comprehension and relation extraction. No verifiable resources are identified.",
      "processing_time": 18.531888961791992,
      "citing_paper_id": "248780414",
      "cited_paper_id": 216869183
    },
    {
      "context_text": "…has been no attempt to directly compare the error landscape and distribution of\n2See, for example, Zhang et al. (2019), Du and Cardie (2020) and Lin et al. (2020) for within-sentence event extraction; Akbik et al. (2018), and Akbik et al. (2019) for named entity recognition (NER); and Zhang et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that discuss various NLP tasks. There are no clear identifiers for datasets.",
      "processing_time": 19.557682514190674,
      "citing_paper_id": "248780414",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "In fact, the problem of document-level information extraction has only recently begun to be revisited (Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of end-to-end neural network techniques that have…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only recent works that revisit document-level information extraction. No clear identifiers for datasets are present.",
      "processing_time": 19.301294326782227,
      "citing_paper_id": "248780414",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "All other hyperparameters are set as in Du et al. (2021b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to another paper for hyperparameters.",
      "processing_time": 16.792850971221924,
      "citing_paper_id": "248780414",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Next, we employ the error analysis framework in a comparison of two state-of-the-art documentlevel neural template-filling approaches, DyGIE++ (Wadden et al., 2019) and GTT (Du et al., 2021b), across three template-filling datasets (SciREX, ProMED (Patwardhan and Riloff, 2009)3, and MUC-4).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SciREX",
        "ProMED",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "SciREX": "Used to compare document-level neural template-filling approaches, focusing on scientific document extraction tasks.",
        "ProMED": "Used to compare document-level neural template-filling approaches, focusing on disease outbreak reports.",
        "MUC-4": "Used to compare document-level neural template-filling approaches, focusing on news articles for event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets used for comparing document-level neural template-filling approaches. These datasets are SciREX, ProMED, and MUC-4.",
      "processing_time": 34.242188692092896,
      "citing_paper_id": "248780414",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Thus, we would also like to improve the time complexity of our template (and mention) matching algorithms using an approach like bipartite matching (Yang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an approach for improving algorithm efficiency.",
      "processing_time": 16.46639394760132,
      "citing_paper_id": "248780414",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "…extraction has only recently begun to be revisited (Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of end-to-end neural network techniques that have been so successful on their…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to recent research works. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 20.46661639213562,
      "citing_paper_id": "248780414",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "(Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of endto-end neural network techniques that have been so successful on their sentence-level counterparts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general reference to testing end-to-end neural network techniques. No clear, verifiable datasets are identified.",
      "processing_time": 20.18281626701355,
      "citing_paper_id": "248780414",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "(Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of endto-end neural network techniques that have been so successful on their sentence-level counterparts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general reference to testing end-to-end neural network techniques. No clear, verifiable datasets are identified.",
      "processing_time": 20.18281626701355,
      "citing_paper_id": "248780414",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "(Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of endto-end neural network techniques that have been so successful on their sentence-level counterparts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general reference to testing end-to-end neural network techniques. No clear, verifiable datasets are identified.",
      "processing_time": 20.18281626701355,
      "citing_paper_id": "248780414",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "…information extraction has only recently begun to be revis-ited (Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of end-to-end neural network techniques that have been so successful on their…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to recent work in information extraction using neural networks.",
      "processing_time": 17.88442611694336,
      "citing_paper_id": "248780414",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "…information extraction has only recently begun to be revis-ited (Quirk and Poon, 2017; Jain et al., 2020; Du et al., 2021b,a; Li et al., 2021; Du, 2021; Yang et al., 2021) in part in an attempt to test the power of end-to-end neural network techniques that have been so successful on their…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to recent work in information extraction using neural networks.",
      "processing_time": 17.88442611694336,
      "citing_paper_id": "248780414",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "As in Jurafsky and Martin (2021), we will refer to document-level information extraction tasks as template-ﬁlling tasks and use the term going forward to refer to both event extraction and document-level relation extraction tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to document-level information extraction tasks.",
      "processing_time": 17.64262866973877,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "As in Jurafsky and Martin (2021), we will refer to document-level information extraction tasks as template-ﬁlling tasks and use the term going forward to refer to both event extraction and document-level relation extraction tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to document-level information extraction tasks.",
      "processing_time": 17.64262866973877,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "In this work, we first introduce a framework for automating error analysis for document-level event and relation extraction, casting both as instances of a general role-filling, or template-filling task (Jurafsky and Martin, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a framework for error analysis in document-level event and relation extraction.",
      "processing_time": 18.145984649658203,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "We ﬁrst discuss the results of DyGIE++ and GTT on SciREX, ProMED, and MUC-4; and then examine the performance of these newer neural models on the 1992 MUC-4 dataset vs. a few of the best-performing IE systems at the time.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SciREX",
        "ProMED",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "SciREX": "Used to evaluate DyGIE++ and GTT models, focusing on scientific document information extraction, comparing performance against other systems.",
        "ProMED": "Used to assess the performance of DyGIE++ and GTT models in extracting information from disease outbreak reports, highlighting model capabilities.",
        "MUC-4": "Used to compare the performance of newer neural models (DyGIE++, GTT) with older IE systems, specifically focusing on event extraction tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions specific datasets used for evaluating models, which are relevant to document-level event extraction.",
      "processing_time": 35.7350754737854,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "MUC-4 (MUC-4, 1992) consists of newswire describing terrorist incidents in Latin America provided by the FBIS (Federal Broadcast Information Services).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to extract events from newswire articles about terrorist incidents in Latin America, focusing on the identification and classification of event types and participants."
      },
      "confidence_score": 1.0,
      "reasoning": "MUC-4 is a well-known dataset in the field of information extraction, specifically designed for event extraction tasks. The context clearly identifies it as a dataset and describes its content.",
      "processing_time": 25.290078163146973,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Table 2 shows the results of evaluating DyGIE++ and GTT on the SciREX, ProMED, and MUC-4 datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SciREX",
        "ProMED",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "SciREX": "Used to evaluate DyGIE++ and GTT on scientific document event extraction, focusing on the performance of these models in identifying events and relations.",
        "ProMED": "Used to evaluate DyGIE++ and GTT on disease outbreak event extraction, assessing the models' ability to detect and classify relevant events in health-related documents.",
        "MUC-4": "Used to evaluate DyGIE++ and GTT on news article event extraction, specifically testing the models' performance in identifying and classifying events in a diverse set of news texts."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions specific datasets used for evaluation, which are relevant to document-level event extraction.",
      "processing_time": 38.44760060310364,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "In our experiments, we train and test two neural-based IE models, described brieﬂy below, on the MUC-4, ProMED, and SciREX datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "ProMED",
        "SciREX"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to train and test neural-based information extraction models, focusing on event extraction in news articles.",
        "ProMED": "Used to train and test neural-based information extraction models, focusing on disease outbreak reports.",
        "SciREX": "Used to train and test neural-based information extraction models, focusing on scientific document event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets used for training and testing neural-based information extraction models.",
      "processing_time": 31.252421855926514,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Consider, for example, the ﬁrst large-scale (for the time) evaluations of IE systems — e.g. MUC-3 (1991) and MUC-4 (1992).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-3",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-3": "Used to evaluate Information Extraction systems, focusing on the performance of entity and relation extraction in news articles.",
        "MUC-4": "Used to evaluate Information Extraction systems, focusing on the performance of entity and relation extraction in news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions MUC-3 and MUC-4, which are specific datasets used for evaluating Information Extraction systems. These are relevant to document-level event extraction.",
      "processing_time": 29.778507709503174,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "From the error count results in Figure 4, we see that GTT makes fewer Missing Template errors than DyGIE++ on the MUC-4 dataset (86 vs. 97).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of GTT and DyGIE++ on document-level event extraction, specifically comparing the number of Missing Template errors."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a specific, verifiable dataset used for evaluating performance on document-level event extraction tasks.",
      "processing_time": 24.55501675605774,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Next, we employ the error analysis framework in a comparison of two state-of-the-art document-level neural template-ﬁlling approaches, DyGIE++ (Wadden et al., 2019) and GTT (Du et al., 2021b), across three template-ﬁlling datasets (SciREX, ProMED (Patwardhan and Riloff, 2009) 3 , and MUC-4).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SciREX",
        "ProMED",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "SciREX": "Used to compare document-level neural template-filling approaches, focusing on scientific document extraction tasks.",
        "ProMED": "Used to compare document-level neural template-filling approaches, focusing on disease outbreak reports.",
        "MUC-4": "Used to compare document-level neural template-filling approaches, focusing on news articles for event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets used for comparing document-level neural template-filling approaches. These datasets are clearly named and relevant to the research topic.",
      "processing_time": 33.28410363197327,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "We can see that all models perform substantially worse on sci-entiﬁc texts (ProMED, SciREX) as compared to news (MUC-4) , likely because the model base is pretrained for general-purpose NLP applications (BERT) or there are not enough examples of scientiﬁc-style text in the pretraining corpus (SciB-ERT).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ProMED",
        "SciREX",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "ProMED": "Used to evaluate model performance on scientific texts, highlighting challenges in handling specialized language.",
        "SciREX": "Used to assess model effectiveness on scientific documents, emphasizing difficulties with technical content.",
        "MUC-4": "Used as a benchmark for news text, demonstrating better model performance on general-purpose language."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions specific datasets used for evaluating model performance across different text types, including scientific and news texts.",
      "processing_time": 30.81250286102295,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "For the MUC-4 and SciREX datasets, GTT is run for 20 epochs, while for ProMED it is run for 36 epochs, to adjust for the smaller size of the dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4",
        "SciREX",
        "ProMED"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to train and evaluate the GTT model for 20 epochs, focusing on document-level event extraction.",
        "SciREX": "Used to train and evaluate the GTT model for 20 epochs, focusing on scientific document event extraction.",
        "ProMED": "Used to train and evaluate the GTT model for 36 epochs, adjusted for its smaller size, focusing on medical document event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets: MUC-4, SciREX, and ProMED. These are used to train and evaluate the GTT model, adjusting the number of epochs based on dataset size.",
      "processing_time": 47.7714307308197,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Table 3 presents the precision, recall, and F1 performance on the MUC-4 dataset for early models from 1992 alongside those of the more recent DyGIE++ and GTT models.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate the performance of early and recent models, specifically comparing precision, recall, and F1 scores in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a specific, verifiable dataset used for evaluating model performance.",
      "processing_time": 33.27989363670349,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Finally, in an attempt to gauge progress in the information extraction ﬁeld over the past 30 years, we employ the framework to compare the performance of four of the original MUC-4 systems with the two newer deep-learning approaches to document-level IE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to compare the performance of original MUC-4 systems with newer deep-learning approaches in document-level information extraction, focusing on system accuracy and efficiency."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'MUC-4' which is a known dataset in the field of information extraction. It is used to compare the performance of older systems with newer deep-learning approaches.",
      "processing_time": 35.994083404541016,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Aside from the original MUC-4 evaluation scoring reports (Chinchor, 1991), which included counts of missing and spurious role ﬁller errors, there have been very few attempts at understanding the types of errors made by IE systems and grounding those errors linguistically.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to evaluate Information Extraction systems, focusing on error types such as missing and spurious role filler errors, providing linguistic grounding for performance analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions MUC-4 evaluation scoring reports, which is a specific dataset used for evaluating Information Extraction systems.",
      "processing_time": 33.687403202056885,
      "citing_paper_id": "248780414",
      "cited_paper_id": null
    },
    {
      "context_text": "Additionally, we validated the effectiveness of argument explanation based prompting on sentence-level EAE datasets using the ACE05 [25].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05"
      ],
      "dataset_descriptions": {
        "ACE05": "Used to validate argument explanation based prompting on sentence-level event argument extraction, focusing on the effectiveness of the prompting method."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the ACE05 dataset for validating argument explanation based prompting on sentence-level EAE datasets. The dataset is clearly identified and relevant to the research topic.",
      "processing_time": 34.626025676727295,
      "citing_paper_id": "275587538",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "We conduct experiments using the ACE05 dataset [25] to demonstrate that our argument explanation-based prompting method can enhance the argument extraction capabilities of large language models.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05"
      ],
      "dataset_descriptions": {
        "ACE05": "Used to demonstrate the effectiveness of an argument explanation-based prompting method for enhancing argument extraction in large language models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the ACE05 dataset for experiments, which is a specific, verifiable dataset relevant to document-level event extraction.",
      "processing_time": 33.41443586349487,
      "citing_paper_id": "275587538",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "The preprocessing of ACE05 follows the methodology outlined by [18].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05"
      ],
      "dataset_descriptions": {
        "ACE05": "Used for preprocessing in entity, relation, and event extraction, following the methodology outlined in the cited paper."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'ACE05' which is a known dataset for event extraction. However, the context does not provide details on how the dataset is used beyond mentioning the preprocessing methodology.",
      "processing_time": 34.617539167404175,
      "citing_paper_id": "275587538",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "A traditional approach of EAE is to employ classification techniques to identify potential text spans and assign roles to them [1]–[3].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general approach to event argument extraction using classification techniques.",
      "processing_time": 26.070234775543213,
      "citing_paper_id": "275587538",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "A traditional approach of EAE is to employ classification techniques to identify potential text spans and assign roles to them [1]–[3].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general approach to event argument extraction using classification techniques.",
      "processing_time": 26.070234775543213,
      "citing_paper_id": "275587538",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "When performing document-level EAE [1], descriptions unrelated to the target arguments constitute noise in EAE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept of 'noise' in event argument extraction. No verifiable resources are identified.",
      "processing_time": 27.28396987915039,
      "citing_paper_id": "275587538",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "For the evaluation of the document-level EAE task, we adopt the RAMS dataset [1] .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the document-level event argument extraction task, focusing on linking arguments across multiple sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions the 'RAMS dataset' for evaluating the document-level EAE task. The dataset is used for a specific evaluation purpose in the research.",
      "processing_time": 33.54450726509094,
      "citing_paper_id": "275587538",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Traditional methods [1], [6]–[8] primarily rely on supervised learning, which requires a large annotated training dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not mention any specific dataset names, only a general reference to 'a large annotated training dataset'. No specific, verifiable datasets are identified.",
      "processing_time": 27.976328134536743,
      "citing_paper_id": "275587538",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Traditional methods [1], [6]–[8] primarily rely on supervised learning, which requires a large annotated training dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not mention any specific dataset names, only a general reference to 'a large annotated training dataset'. No specific, verifiable datasets are identified.",
      "processing_time": 27.976328134536743,
      "citing_paper_id": "275587538",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "5-turbo-instruct [16], [17].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific dataset names or verifiable resources. It only mentions paper IDs which are not datasets.",
      "processing_time": 26.676189422607422,
      "citing_paper_id": "275587538",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "5-turbo-instruct [16], [17].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific dataset names or verifiable resources. It only mentions paper IDs which are not datasets.",
      "processing_time": 26.676189422607422,
      "citing_paper_id": "275587538",
      "cited_paper_id": 246426909
    },
    {
      "context_text": "Due to its complexity and the limited availability of annotated data, prompt engineering of large language models (LLMs) [16], [17], which have become increasingly powerful, serve as an effective alternative [15].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the use of large language models and prompt engineering. No verifiable resources are identified.",
      "processing_time": 27.49759864807129,
      "citing_paper_id": "275587538",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "Due to its complexity and the limited availability of annotated data, prompt engineering of large language models (LLMs) [16], [17], which have become increasingly powerful, serve as an effective alternative [15].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the use of large language models and prompt engineering. No verifiable resources are identified.",
      "processing_time": 27.49759864807129,
      "citing_paper_id": "275587538",
      "cited_paper_id": 246426909
    },
    {
      "context_text": "5-turbo [16], [17] is selected as the base model.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a base model. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 27.264060974121094,
      "citing_paper_id": "275587538",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "5-turbo [16], [17] is selected as the base model.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a base model. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 27.264060974121094,
      "citing_paper_id": "275587538",
      "cited_paper_id": 246426909
    },
    {
      "context_text": "The results of ICL method [20] are significantly lower than those of other methods, indicating that carefully crafted instructions and explanations are more crucial compared to a rich sample repository and similar examples.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of methods. The context focuses on the importance of instructions and explanations over a rich sample repository.",
      "processing_time": 27.25052571296692,
      "citing_paper_id": "275587538",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "One common approach [20] is to select ICL examples involves choosing the nearest neighbors of input instances based on similarity metrics.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for selecting examples for in-context learning.",
      "processing_time": 25.589114904403687,
      "citing_paper_id": "275587538",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "Following [20], when constructing ICL examples, the samples with the highest textual similarity are selected from datas within the training set that share the same event type with the input data.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'training set' but does not specify a named dataset. The reference to 'training set' is too generic and lacks a specific identifier.",
      "processing_time": 27.242382764816284,
      "citing_paper_id": "275587538",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "…Simple-Hard Refining method with several state-of-the-art base-line prompting methods: Standard Prompting used in [13], Chain-of-Thought prompting [9], In-Context Learning method KATE [20], the self-consistency method [12], and the HD-LoA prompting [15] designed specifically for document-level EAE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various prompting methods and models. No verifiable resources are identified.",
      "processing_time": 26.856802940368652,
      "citing_paper_id": "275587538",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "…Simple-Hard Refining method with several state-of-the-art base-line prompting methods: Standard Prompting used in [13], Chain-of-Thought prompting [9], In-Context Learning method KATE [20], the self-consistency method [12], and the HD-LoA prompting [15] designed specifically for document-level EAE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various prompting methods and models. No verifiable resources are identified.",
      "processing_time": 26.856802940368652,
      "citing_paper_id": "275587538",
      "cited_paper_id": 247595263
    },
    {
      "context_text": "Through ICL [20], [23], argument explanation based prompting enables the large language model to give explanations for the extraction process of each argument as the provided one-shot example do.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (in-context learning) and its application. No verifiable resources are identified.",
      "processing_time": 26.658704042434692,
      "citing_paper_id": "275587538",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "Table I shows that our method outperforms the Standard [13], CoT [9], ICL method [20], self-consistency method [12] and HD-LoA [15] baseline models at every stage, except for the argument-explanation-based-prompting performance when using gpt-3.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various methods and models. The context is focused on comparing performance metrics of different approaches.",
      "processing_time": 27.743916273117065,
      "citing_paper_id": "275587538",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "Table I shows that our method outperforms the Standard [13], CoT [9], ICL method [20], self-consistency method [12] and HD-LoA [15] baseline models at every stage, except for the argument-explanation-based-prompting performance when using gpt-3.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various methods and models. The context is focused on comparing performance metrics of different approaches.",
      "processing_time": 27.743916273117065,
      "citing_paper_id": "275587538",
      "cited_paper_id": 246411621
    },
    {
      "context_text": "Table I shows that our method outperforms the Standard [13], CoT [9], ICL method [20], self-consistency method [12] and HD-LoA [15] baseline models at every stage, except for the argument-explanation-based-prompting performance when using gpt-3.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various methods and models. The context is focused on comparing performance metrics of different approaches.",
      "processing_time": 27.743916273117065,
      "citing_paper_id": "275587538",
      "cited_paper_id": 247595263
    },
    {
      "context_text": "Recently, many approaches [20]–[22] have focused on enhancing the capabilities of large models by selecting appropriate examples.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general approaches and models. There are no clear identifiers for datasets in the context.",
      "processing_time": 26.651124715805054,
      "citing_paper_id": "275587538",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "Recent developments have seen a trend towards redefining EAE as a question-answering task [4], [5], [26] or text generation task [8], [30].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a trend in redefining EAE as a question-answering or text generation task. No verifiable resources are identified.",
      "processing_time": 30.540772438049316,
      "citing_paper_id": "275587538",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Recent developments have seen a trend towards redefining EAE as a question-answering task [4], [5], [26] or text generation task [8], [30].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a trend in redefining EAE as a question-answering or text generation task. No verifiable resources are identified.",
      "processing_time": 30.540772438049316,
      "citing_paper_id": "275587538",
      "cited_paper_id": 269900068
    },
    {
      "context_text": "Chain of thought prompting [9] comprises a sequence of intermediate reasoning steps that substantially enhances the capacity of large language models to tackle complex reasoning tasks.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enhancing language models.",
      "processing_time": 25.771142959594727,
      "citing_paper_id": "275587538",
      "cited_paper_id": 246411621
    },
    {
      "context_text": "When applying existing EAE prompt engineering methods [9], [13], [15] to LLMs, LLMs need to determine whether multi-sentence reasoning is required, which leads LLMs to analyze sentences unrelated to argu-ment extraction, thereby introducing additional noise into the extraction process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and challenges in applying EAE prompt engineering to LLMs.",
      "processing_time": 27.039892435073853,
      "citing_paper_id": "275587538",
      "cited_paper_id": 246411621
    },
    {
      "context_text": "…Simple-Hard Refining method with several state-of-the-art base-line prompting methods: Standard Prompting used in [13], Chain-of-Thought prompting [9], In-Context Learning method KATE [20], the self-consistency method [12], and the HD-LoA prompting [15] designed specifically for document-level…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various prompting methods and techniques. There are no clear identifiers for datasets within the text.",
      "processing_time": 27.922330379486084,
      "citing_paper_id": "275587538",
      "cited_paper_id": 246411621
    },
    {
      "context_text": "Our method’s performance in the first stage already surpasses that of CoT [9] and HD-LoA [15], indicating that argument explanation-based prompting is more effective for the EAE task compared to these approaches.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and their performance comparisons.",
      "processing_time": 25.310742139816284,
      "citing_paper_id": "275587538",
      "cited_paper_id": 246411621
    },
    {
      "context_text": "It has been widely demonstrated that enhancing the reasoning ability of large language models by generating detailed thought processes improves their performance [9].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general improvement in model performance through enhanced reasoning.",
      "processing_time": 26.277936458587646,
      "citing_paper_id": "275587538",
      "cited_paper_id": 246411621
    },
    {
      "context_text": "Chain-of-thought prompting (CoT) [9] and its subsequent work [10], [11] has improved the capability of large language models to address complex problems by producing step-by-step solutions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches related to chain-of-thought prompting in large language models.",
      "processing_time": 27.705418586730957,
      "citing_paper_id": "275587538",
      "cited_paper_id": 246411621
    },
    {
      "context_text": "Chain-of-thought prompting (CoT) [9] and its subsequent work [10], [11] has improved the capability of large language models to address complex problems by producing step-by-step solutions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches related to chain-of-thought prompting in large language models.",
      "processing_time": 27.705418586730957,
      "citing_paper_id": "275587538",
      "cited_paper_id": 252762275
    },
    {
      "context_text": "Chain-of-thought prompting (CoT) [9] and its subsequent work [10], [11] has improved the capability of large language models to address complex problems by producing step-by-step solutions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches related to chain-of-thought prompting in large language models.",
      "processing_time": 27.705418586730957,
      "citing_paper_id": "275587538",
      "cited_paper_id": 257205763
    },
    {
      "context_text": "For each argument, soft-hard refining framework requires at most three rounds of requests, yet both Arg-I and Arg-C outperform the self-consistency method [12], which requires five rounds.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between methods. The context is focused on the performance of different argument refinement frameworks.",
      "processing_time": 28.230533361434937,
      "citing_paper_id": "275587538",
      "cited_paper_id": 247595263
    },
    {
      "context_text": "The self-consistency strategy [12] leverages the intuition that a complex reasoning problem can often be solved correctly through various different paths.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or strategy. The context is about reasoning and solving problems, not about using a dataset.",
      "processing_time": 28.452429056167603,
      "citing_paper_id": "275587538",
      "cited_paper_id": 247595263
    },
    {
      "context_text": "5-turbo as the base model, where it is marginally less effective compared to the Standard method [13] and self-consistency method [12].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 27.89951729774475,
      "citing_paper_id": "275587538",
      "cited_paper_id": 247595263
    },
    {
      "context_text": "Self-consistency [12] utilizes the idea that a complex problem generally has multiple distinct approaches that converge on the same correct answer and employs majority voting to finalize the answer selection.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called 'self-consistency'.",
      "processing_time": 26.258546113967896,
      "citing_paper_id": "275587538",
      "cited_paper_id": 247595263
    },
    {
      "context_text": "QA-without-explanation-sc [12] represents the results obtained by conducting multiple rounds of experiments on QA-without-explanation and utilizing majority voting on the extraction results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or process involving QA-without-explanation and majority voting.",
      "processing_time": 27.41870927810669,
      "citing_paper_id": "275587538",
      "cited_paper_id": 247595263
    },
    {
      "context_text": "Following previous approaches [6], [7], we utilized the argument identification F1 score (Arg-I) and the argument classification F1 score (Arg-C) as our evaluation metrics.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. No datasets are identified or discussed in the context.",
      "processing_time": 26.25752091407776,
      "citing_paper_id": "275587538",
      "cited_paper_id": 259000027
    },
    {
      "context_text": "There are also prompt-based methodologies [6], [7] that harness slotted prompts to extract arguments in a generative slot-filling paradigm.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methodologies. There are no clear identifiers for datasets in the text.",
      "processing_time": 26.996917247772217,
      "citing_paper_id": "275587538",
      "cited_paper_id": 259000027
    },
    {
      "context_text": "Data augmentation techniques [27], [28] have also been widely applied to enhance EAE performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only data augmentation techniques. No verifiable resources are identified.",
      "processing_time": 26.785850048065186,
      "citing_paper_id": "275587538",
      "cited_paper_id": 269762049
    },
    {
      "context_text": "OneIE [17]: a joint EE model trained with global features ; BartGen [14]: a document-level event argument extraction (EAE) UIE [25]: a unified text-to-structure generation framework; PAIE [28]: an EAE method that utilizes prompt tuning for ex-tractive",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets.",
      "processing_time": 26.988540649414062,
      "citing_paper_id": "270619369",
      "cited_paper_id": null
    },
    {
      "context_text": "Current event extraction studies are mostly end-to-end methods [1], [2], while most of them still stay at sentence-level modeling and struggle to overcome the long-term dependency problem of event argument entities in document-level tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general statements about current research trends in event extraction.",
      "processing_time": 26.778482675552368,
      "citing_paper_id": "269313129",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "(4) In order to make the model adapt to the task, we employ the rejection mechanism proposed in UIE [6], which can force the model to complete all event argument extraction (even if these arguments may be empty), thus making the model more suitable for downstream tasks.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or mechanism from another paper.",
      "processing_time": 26.106786727905273,
      "citing_paper_id": "269313129",
      "cited_paper_id": 247619149
    },
    {
      "context_text": "In-Context Learning (ICL) [13] is a strategy that enables pre-trained language models to quickly adapt to different tasks with minimal [14] or zero-shot [15] data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only strategies and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 27.863938570022583,
      "citing_paper_id": "271855673",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "In-Context Learning (ICL) [13] is a strategy that enables pre-trained language models to quickly adapt to different tasks with minimal [14] or zero-shot [15] data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only strategies and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 27.863938570022583,
      "citing_paper_id": "271855673",
      "cited_paper_id": 249017743
    },
    {
      "context_text": "The WikiEvents dataset[35] is a resource created to advance research in document-level event extraction, as shown in Table1.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to advance research in document-level event extraction, specifically for conditional generation methods, as demonstrated in Table 1."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions 'WikiEvents dataset' as a resource for advancing research in document-level event extraction, which aligns with the research topic.",
      "processing_time": 34.47531819343567,
      "citing_paper_id": "271855673",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Research indicates that explicit prompting methods for LLMs to decompose problems, such as Least-to-Most[28]and zero-shot CoT, improve the reliability of reasoning.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for improving reasoning in large language models.",
      "processing_time": 26.397624015808105,
      "citing_paper_id": "271855673",
      "cited_paper_id": 248986239
    },
    {
      "context_text": "Furthermore, the application of various prompting techniques[14, 15, 29]has confirmed the effectiveness of decomposition strategies, enabling models to systematically handle complex issues.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only prompting techniques and decomposition strategies. There are no clear identifiers for datasets in the text.",
      "processing_time": 28.401828050613403,
      "citing_paper_id": "271855673",
      "cited_paper_id": 249017743
    },
    {
      "context_text": "Zero-shot CoT [15], with simple prompts like \"Let’s think step by step,\" enhances the transparency and accuracy of the reasoning process.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enhancing reasoning processes in language models.",
      "processing_time": 26.56016230583191,
      "citing_paper_id": "271855673",
      "cited_paper_id": 249017743
    },
    {
      "context_text": "However, ICL exhibits high instability in practical applications, where model predictions are influenced by factors such as example order, input length, prompt format, and training data distribution [17].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general factors affecting model predictions.",
      "processing_time": 26.08288884162903,
      "citing_paper_id": "271855673",
      "cited_paper_id": 254591242
    },
    {
      "context_text": "The use of large language models (LLMs) in natural language processing (NLP) tasks has significantly increased, especially with closed models like PaLM [1] , Claude [2] , and GPT-4 [3].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and their applications in NLP tasks.",
      "processing_time": 26.73383331298828,
      "citing_paper_id": "271855673",
      "cited_paper_id": 254823489
    },
    {
      "context_text": "Prophet framework proposed by Yu, Zhou et al. [11] integrates answer candidates and answer-aware context examples as heuristic information, markedly boosting performance in knowledge-based Visual Question Answering (VQA) tasks and demonstrating compatibility with various VQA models and LLMs.…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Prophet framework) and its application in VQA tasks.",
      "processing_time": 27.836057424545288,
      "citing_paper_id": "271855673",
      "cited_paper_id": 257353536
    },
    {
      "context_text": "To validate our proposed method, we conducted experimental comparisons with the following event extraction models, used as baselines: OntoGPT[37].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a baseline model (OntoGPT) but does not reference any specific dataset. The context focuses on comparing methods rather than using a particular dataset.",
      "processing_time": 29.83722686767578,
      "citing_paper_id": "271855673",
      "cited_paper_id": 257985312
    },
    {
      "context_text": "Wang et al.’s [31] Plan-and-Solve (PS) prompting method guides models to formulate and execute plans to solve complex problems, improving performance in multi-step reasoning tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation discusses a method (Plan-and-Solve prompting) rather than a dataset. No specific dataset is mentioned or used in the context.",
      "processing_time": 28.639325857162476,
      "citing_paper_id": "271855673",
      "cited_paper_id": 258558102
    },
    {
      "context_text": "Kim et al.’s [33] fine-tuning dataset COT COLLECTION enhances the generalization ability of small-scale language models on multi-task unseen problems.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "COT COLLECTION"
      ],
      "dataset_descriptions": {
        "COT COLLECTION": "Used to improve zero-shot and few-shot learning capabilities of small-scale language models through chain-of-thought fine-tuning, enhancing their performance on multi-task unseen problems."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'COT COLLECTION' as a fine-tuning dataset used to enhance the generalization ability of small-scale language models on multi-task unseen problems.",
      "processing_time": 36.702858448028564,
      "citing_paper_id": "271855673",
      "cited_paper_id": 258841149
    },
    {
      "context_text": "Mo et al. [21] [24] effectively improves ICL performance through five stages: expert pool construction, task definition extraction, guided retrieval, expert integration, and continual few-shot learning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving ICL performance.",
      "processing_time": 26.523226261138916,
      "citing_paper_id": "271855673",
      "cited_paper_id": 267750177
    },
    {
      "context_text": "Jiang et al. [19] proposed the P-ICL (Point In-Context Learning) framework, providing critical information about entity types and classifications to LLMs, thereby enhancing named entity recognition tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (P-ICL) and its application to named entity recognition tasks.",
      "processing_time": 28.627232313156128,
      "citing_paper_id": "271855673",
      "cited_paper_id": 269626679
    },
    {
      "context_text": "In the zero-shot event extraction domain, Zhigang Kan et al. [6] improved argument recognition performance through a multi-turn dialogue approach, demonstrating its potential in event detection.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving argument recognition in event extraction.",
      "processing_time": 26.916033506393433,
      "citing_paper_id": "271855673",
      "cited_paper_id": 269803960
    },
    {
      "context_text": "Schema-aware Event Extraction[7].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach for schema-aware event extraction using LLMs.",
      "processing_time": 27.807827949523926,
      "citing_paper_id": "271855673",
      "cited_paper_id": 270209567
    },
    {
      "context_text": "Fatemeh Shiri et al. [7]optimized the application of LLMs in knowledge graph construction and decision support by integrating advanced prompt techniques such as Chain-of-Thought and Retrieval Augmented Generation, reducing hallucination risks and enhancing accuracy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and techniques used in the research.",
      "processing_time": 26.698214054107666,
      "citing_paper_id": "271855673",
      "cited_paper_id": 270209567
    },
    {
      "context_text": "To utilize more knowledge, some studies leverage document context (Chen et al., 2018; Zhao et al., 2018), pre-trained language model (Yang et al., 2019), and explicit external knowledge (Liu et al., 2019a; Tong et al., 2020) such as WordNet (Miller, 1995).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WordNet"
      ],
      "dataset_descriptions": {
        "WordNet": "Used as a lexical database to provide explicit external knowledge for event detection and generation, enhancing the semantic understanding of the model."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions WordNet as a source of explicit external knowledge, which is a lexical database. No other specific datasets are mentioned.",
      "processing_time": 35.03557634353638,
      "citing_paper_id": "235253912",
      "cited_paper_id": 1671874
    },
    {
      "context_text": "To utilize more knowledge, some studies leverage document context (Chen et al., 2018; Zhao et al., 2018), pre-trained language model (Yang et al., 2019), and explicit external knowledge (Liu et al., 2019a; Tong et al., 2020) such as WordNet (Miller, 1995).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WordNet"
      ],
      "dataset_descriptions": {
        "WordNet": "Used as a lexical database to provide explicit external knowledge for event detection and generation, enhancing the semantic understanding of the model."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions WordNet as a source of explicit external knowledge, which is a lexical database. No other specific datasets are mentioned.",
      "processing_time": 35.03557634353638,
      "citing_paper_id": "235253912",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "To utilize more knowledge, some studies leverage document context (Chen et al., 2018; Zhao et al., 2018), pre-trained language model (Yang et al., 2019), and explicit external knowledge (Liu et al., 2019a; Tong et al., 2020) such as WordNet (Miller, 1995).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WordNet"
      ],
      "dataset_descriptions": {
        "WordNet": "Used as a lexical database to provide explicit external knowledge for event detection and generation, enhancing the semantic understanding of the model."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions WordNet as a source of explicit external knowledge, which is a lexical database. No other specific datasets are mentioned.",
      "processing_time": 35.03557634353638,
      "citing_paper_id": "235253912",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "To take advantage of such interdependency, we propose a novel Tracker module inspired by memory network (Weston et al., 2015).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (memory network) which is not included as per instructions.",
      "processing_time": 27.796292781829834,
      "citing_paper_id": "235253912",
      "cited_paper_id": 2926851
    },
    {
      "context_text": "They conduct experiments on MUC-4 (Sundheim, 1992) dataset with 1, 700 documents and 5 kinds of entity-based arguments, and it is formulated as a table-filling task, coping with single event record of single event",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used for experiments involving entity-based arguments, formulated as a table-filling task to cope with single event records of single events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a specific, verifiable dataset used in the research. The dataset is used for experiments involving entity-based arguments and is formulated as a table-filling task.",
      "processing_time": 37.65407419204712,
      "citing_paper_id": "235253912",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "They conduct experiments on MUC-4 (Sundheim, 1992) dataset with 1, 700 documents and 5 kinds of entity-based arguments, and it is formulated as a table-filling task, coping with single event record of single event\ntype.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used for experiments involving entity-based arguments, formulated as a table-filling task to handle single event records of single event types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a specific, verifiable dataset used in the research. The dataset is used for experiments involving entity-based arguments and is formulated as a table-filling task.",
      "processing_time": 37.649861335754395,
      "citing_paper_id": "235253912",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "In our implementation of G IT , we use 8 and 4 layers Transformer (Vaswani et al., 2017) in encoding and decoding module respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the architecture of the Transformer model. No verifiable resources are identified.",
      "processing_time": 28.117361068725586,
      "citing_paper_id": "235253912",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Finally we introduce a Tracker module to continuously track all the records with global memory, in which we utilize the global interdependency among records for multi-event extraction (Sec 3.4). former (Vaswani et al., 2017):",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Tracker module) and a reference to another paper. No verifiable datasets are identified.",
      "processing_time": 29.527501344680786,
      "citing_paper_id": "235253912",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Although Zheng et al. (2019) use Transformer to fuse sentences and entities, interdependency among events is neglected.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Transformer).",
      "processing_time": 25.737879037857056,
      "citing_paper_id": "235253912",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "In our implementation of GIT, we use 8 and 4 layers Transformer (Vaswani et al., 2017) in encoding and decoding module respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the architecture of the model being used.",
      "processing_time": 26.67930769920349,
      "citing_paper_id": "235253912",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "The task does not require to identify event triggers (Zeng et al., 2018; Liu et al., 2019b), which reduces manual effort of annotation and the application scenarios becomes more extensive.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the reduction of manual annotation effort and broader application scenarios.",
      "processing_time": 27.75142788887024,
      "citing_paper_id": "235253912",
      "cited_paper_id": 19224644
    },
    {
      "context_text": "To utilize more knowledge, some studies leverage document context (Chen et al., 2018; Zhao et al., 2018), pre-trained language model (Yang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 28.31446623802185,
      "citing_paper_id": "235253912",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "Most previous methods (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Yang et al., 2019; Du and Cardie, 2020b) focus on sentence-level EE, extracting events from a single sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods focusing on sentence-level event extraction.",
      "processing_time": 27.301920652389526,
      "citing_paper_id": "235253912",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Most of the previous methods (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Yang et al., 2019; Du and Cardie, 2020b) focus on sentence-level EE, extracting events from a single sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods focusing on sentence-level event extraction.",
      "processing_time": 27.298096895217896,
      "citing_paper_id": "235253912",
      "cited_paper_id": 196178503
    },
    {
      "context_text": ", 2018), pre-trained language model (Yang et al., 2019), and explicit external knowledge (Liu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to pre-trained language models and external knowledge. No verifiable datasets are identified.",
      "processing_time": 29.498947858810425,
      "citing_paper_id": "235253912",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Since a document can express events of different types, we formulate the task as a multi-label classification and leverage sentences feature matrix S to\n*Traditional methods in sentence-level EE also utilize graph to extract events (Liu et al., 2018; Yan et al., 2019), based on the dependency tree.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the formulation of the task and the use of graph-based methods for event extraction.",
      "processing_time": 30.951748609542847,
      "citing_paper_id": "235253912",
      "cited_paper_id": 202773239
    },
    {
      "context_text": "*Traditional methods in sentence-level EE also utilize graph to extract events (Liu et al., 2018; Yan et al., 2019), based on the dependency tree.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the use of graph-based methods for event extraction.",
      "processing_time": 29.477952480316162,
      "citing_paper_id": "235253912",
      "cited_paper_id": 202773239
    },
    {
      "context_text": "Some studies also utilize dependency tree information (Liu et al., 2018; Yan et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. No dataset names are present in the citation span.",
      "processing_time": 28.566864013671875,
      "citing_paper_id": "235253912",
      "cited_paper_id": 202773239
    },
    {
      "context_text": "Hence, extracting events at the document-level is critical and has attracted much attention recently (Yang et al., 2018; Zheng et al., 2019; Du and Cardie, 2020a; Du et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. No dataset names are provided in the context.",
      "processing_time": 28.804709672927856,
      "citing_paper_id": "235253912",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "Focusing on single event extraction, Du and Cardie (2020a) and Du et al. (2020) concatenate multiple sentences and only consider a single event, which lacks the ability to model multiple events scattered in a long document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methodological approaches to event extraction.",
      "processing_time": 26.24243140220642,
      "citing_paper_id": "235253912",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "Du and Cardie (2020a) try to encode the sentences in a multi-granularity way and Du et al. (2020) leverage a seq2seq model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on encoding sentences and using seq2seq models, which are not datasets.",
      "processing_time": 30.487966299057007,
      "citing_paper_id": "235253912",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "It has attracted much attention recently (Yang et al., 2018; Zheng et al., 2019; Du and Cardie, 2020a; Du et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 30.003990411758423,
      "citing_paper_id": "235253912",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "After heterogeneous graph construction *, we apply multi-layer Graph Convolution Network (Kipf and Welling, 2017) to model the global interactions inspired by Zeng et al. (2020).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the application of a Graph Convolution Network and does not reference any data sources.",
      "processing_time": 30.90335988998413,
      "citing_paper_id": "235253912",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "After heterogeneous graph construction *, we apply multi-layer Graph Convolution Network (Kipf and Welling, 2017) to model the global interactions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Graph Convolution Network).",
      "processing_time": 27.224523305892944,
      "citing_paper_id": "235253912",
      "cited_paper_id": null
    },
    {
      "context_text": "After heterogeneous graph construction * , we apply multi-layer Graph Convolution Network (Kipf and Welling, 2017) to model the global interactions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Graph Convolution Network).",
      "processing_time": 27.221516847610474,
      "citing_paper_id": "235253912",
      "cited_paper_id": null
    },
    {
      "context_text": "These studies usually conduct experiments on sentencelevel event extraction dataset, ACE05 (Walker et al., 2006).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05"
      ],
      "dataset_descriptions": {
        "ACE05": "Used for sentence-level event extraction experiments, focusing on identifying events within individual sentences using a well-established annotated corpus."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE05' as a specific dataset used for sentence-level event extraction experiments. It is a multi-word proper noun and fits the criteria for a dataset.",
      "processing_time": 36.0703809261322,
      "citing_paper_id": "235253912",
      "cited_paper_id": null
    },
    {
      "context_text": "These studies usually conduct experiments on sentence-level event extraction dataset, ACE05 (Walker et al., 2006).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE05"
      ],
      "dataset_descriptions": {
        "ACE05": "Used for sentence-level event extraction experiments, focusing on identifying events within individual sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE05 dataset, which is a well-known resource for event extraction tasks. It is used for sentence-level event extraction experiments.",
      "processing_time": 34.46179747581482,
      "citing_paper_id": "235253912",
      "cited_paper_id": null
    },
    {
      "context_text": "To optimize these three GPs, we apply Circle loss [Sun et al. , 2020] to alleviate label imbalance of gold arguments and negative spans: where s ( · ) is the score function in GP [Su et al. , 2022], P denotes the set of gold argument spans, N denotes the set of negative spans that are not arguments.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers do not introduce datasets either.",
      "processing_time": 28.217860460281372,
      "citing_paper_id": "271496297",
      "cited_paper_id": 211296865
    },
    {
      "context_text": "To optimize these three GPs, we apply Circle loss [Sun et al. , 2020] to alleviate label imbalance of gold arguments and negative spans: where s ( · ) is the score function in GP [Su et al. , 2022], P denotes the set of gold argument spans, N denotes the set of negative spans that are not arguments.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers do not introduce datasets either.",
      "processing_time": 28.217860460281372,
      "citing_paper_id": "271496297",
      "cited_paper_id": 251371417
    },
    {
      "context_text": "Specifically, we utilize three Global Pointer Networks (GPs) [Su et al. , 2022] to extract each argument (or trigger) from the document and construct the event complete graph simultaneously, without any error propagation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Global Pointer Networks) used for event extraction.",
      "processing_time": 27.996186017990112,
      "citing_paper_id": "271496297",
      "cited_paper_id": 251371417
    },
    {
      "context_text": "…event triggers and corresponding arguments from natural language texts, facilitating various downstream applications, such as information retrieval [Li et al. , 2023], recommender systems [Lu et al. , 2016], and question answering [Liu et al. , 2023] in finance, healthcare, and law industries.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction. No dataset names are present in the text.",
      "processing_time": 29.185737133026123,
      "citing_paper_id": "271496297",
      "cited_paper_id": 259629787
    },
    {
      "context_text": "…event triggers and corresponding arguments from natural language texts, facilitating various downstream applications, such as information retrieval [Li et al. , 2023], recommender systems [Lu et al. , 2016], and question answering [Liu et al. , 2023] in finance, healthcare, and law industries.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event extraction. No dataset names are present in the text.",
      "processing_time": 29.185737133026123,
      "citing_paper_id": "271496297",
      "cited_paper_id": 263829656
    },
    {
      "context_text": "They also generated a large-scale corpus called ChiFinAnn through distant supervised alignment [7, 34, 49].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used to generate automatically labeled data for large-scale event extraction, employing distant supervised alignment to create a large-scale corpus."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ChiFinAnn', which is a specific, multi-word proper noun that fits the criteria for a dataset. The context indicates that it was generated through distant supervised alignment, which is relevant to the topic of document-level event extraction.",
      "processing_time": 38.18651008605957,
      "citing_paper_id": "273195146",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "They also generated a large-scale corpus called ChiFinAnn through distant supervised alignment [7, 34, 49].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used to generate automatically labeled data for large-scale event extraction, employing distant supervised alignment to create a large-scale corpus."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'ChiFinAnn', which is a specific, multi-word proper noun that fits the criteria for a dataset. The context indicates that it was generated through distant supervised alignment, which is relevant to the topic of document-level event extraction.",
      "processing_time": 38.18651008605957,
      "citing_paper_id": "273195146",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Nguyen et al. [36] first used GRU [10] to better model the relationship of words within a sentence and predict both event triggers and arguments; Chen et al. [6] adopted LSTM [18] as the encoder and further proposed a dynamic pooling strategy similar to DMCNN. Compared with GRU, LSTM can…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on comparing GRU and LSTM for event extraction.",
      "processing_time": 29.67011046409607,
      "citing_paper_id": "273195146",
      "cited_paper_id": 5590763
    },
    {
      "context_text": "Nguyen et al. [36] first used GRU [10] to better model the relationship of words within a sentence and predict both event triggers and arguments; Chen et al. [6] adopted LSTM [18] as the encoder and further proposed a dynamic pooling strategy similar to DMCNN. Compared with GRU, LSTM can…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on comparing GRU and LSTM for event extraction.",
      "processing_time": 29.67011046409607,
      "citing_paper_id": "273195146",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Several prior studies have concentrated on sentence-level event extraction (SEE) [8, 13, 25, 30, 36, 38], where events are extracted from individual sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to sentence-level event extraction. No verifiable resources are identified.",
      "processing_time": 29.39303183555603,
      "citing_paper_id": "273195146",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Several prior studies have concentrated on sentence-level event extraction (SEE) [8, 13, 25, 30, 36, 38], where events are extracted from individual sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to sentence-level event extraction. No verifiable resources are identified.",
      "processing_time": 29.39303183555603,
      "citing_paper_id": "273195146",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We empirically use the Adam [21] optimizer with a learning rate of 5e-4.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Adam optimizer, which is a method, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 28.742568254470825,
      "citing_paper_id": "273195146",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "Chen et al. [8] proposed DMCNN, which uses multiple pooling to improve the CNN model [24].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DMCNN) and a reference to improving a CNN model. No verifiable resources are identified.",
      "processing_time": 30.64474391937256,
      "citing_paper_id": "273195146",
      "cited_paper_id": 14542261
    },
    {
      "context_text": "Yang et al. [44] proposed the first end-to-end DEE framework with key-event detection.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or system. The context focuses on the introduction of a new framework for document-level event extraction.",
      "processing_time": 30.4280104637146,
      "citing_paper_id": "273195146",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Aligned with the previous state-of-the-art approach ReDEE [27], the token sequences in the document are first encoded by the BERT [11] encoder.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT for encoding token sequences. BERT is a model, not a dataset.",
      "processing_time": 30.23855495452881,
      "citing_paper_id": "273195146",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Numerous approaches leverage pre-trained language models like BERT [11], built upon the Transformer [39], for event extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only pre-trained language models and their usage for event extraction.",
      "processing_time": 28.176908254623413,
      "citing_paper_id": "273195146",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Entity types have been proved effective for downstream sub-modules [41, 50].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that entity types have been effective for downstream sub-modules. No dataset names are present in the citation span.",
      "processing_time": 30.614978075027466,
      "citing_paper_id": "273195146",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "To fully evaluate our approach, we compare with several existing baselines as follows: (a) Doc2EDAG [50] first formulates the DEE task as a table filling paradigm.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Doc2EDAG).",
      "processing_time": 26.723206281661987,
      "citing_paper_id": "273195146",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Zheng et al. [50] proposed Doc2EDAG, which constructs the entity-based directed acyclic graph (EDAG) by expanding paths autoregressively to extract event records.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions Doc2EDAG, which is a method for document-level event extraction, not a dataset. No specific datasets are mentioned in the citation.",
      "processing_time": 29.633533000946045,
      "citing_paper_id": "273195146",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Each path expansion constitutes a binary classification task utilizing previously modeled entity interactions [27, 41, 50], with the assigned entity becoming an argument.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or framework for document-level event extraction.",
      "processing_time": 27.935354471206665,
      "citing_paper_id": "273195146",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "In this paper, we carried out experiments on two public Chinese datasets: ChiFinAnn [50] and DuEE-Fin [16].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChiFinAnn",
        "DuEE-Fin"
      ],
      "dataset_descriptions": {
        "ChiFinAnn": "Used for Chinese financial event extraction, focusing on document-level event detection and argument identification in financial news articles.",
        "DuEE-Fin": "Used for Chinese financial event extraction, focusing on document-level event detection and argument identification in financial news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ChiFinAnn and DuEE-Fin, which are used for experiments in Chinese financial event extraction.",
      "processing_time": 40.17384886741638,
      "citing_paper_id": "273195146",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Most existing DEE approaches [27, 41, 46, 50, 51] typically employ pipeline models designed to harness entity interactions across sentences in addressing the aforementioned challenges.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches and models. There are no clear identifiers for datasets.",
      "processing_time": 28.954901218414307,
      "citing_paper_id": "273195146",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Ebner et al. [13] regarded the event argument extraction as an argument linking task firstly and proposed a novel dataset named RAMS for evaluation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate event argument extraction as an argument linking task, providing a novel resource for this specific research context."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset named RAMS, which is introduced for evaluating event argument extraction as an argument linking task.",
      "processing_time": 34.21563720703125,
      "citing_paper_id": "273195146",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "A Conditional Random Field (CRF) [23] layer is followed to classify labels of named entities.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (CRF) but does not reference any specific dataset. The context is about using CRF for classifying labels of named entities, which is a methodological detail.",
      "processing_time": 31.942750930786133,
      "citing_paper_id": "273195146",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "In addition, Huang and Jia [20] regarded each event record as a sentence community, events were extracted by community detection.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It describes a method for document-level event extraction using community detection.",
      "processing_time": 29.337167978286743,
      "citing_paper_id": "273195146",
      "cited_paper_id": 244119148
    },
    {
      "context_text": "Xu et al. [42] encoded the document from the global and local perspectives and employed AMR-guided semantic graphs to capture intra-sentence and inter-sentence semantic features of arguments, where Ren et al. [37] proposed a multi-event head attention network that assigns arguments to roles in…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation focuses on the methodologies used for document-level event argument extraction.",
      "processing_time": 30.19391417503357,
      "citing_paper_id": "273195146",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "In recent years, large-scale pre-trained language models were employed to generate event records by filling predefined templates [12, 25, 29, 32].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of pre-trained language models for event extraction.",
      "processing_time": 28.409658908843994,
      "citing_paper_id": "273195146",
      "cited_paper_id": 248721950
    },
    {
      "context_text": "CRS [40] integrated entity-level and contextual-level representations with time-aware attention for user preference modeling, and utilized pre-trained BART for generation module initialization to enhance context modeling and mitigate data scarcity issues.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The focus is on integrating entity-level and contextual-level representations with time-aware attention and using pre-trained BART.",
      "processing_time": 31.757635593414307,
      "citing_paper_id": "273195146",
      "cited_paper_id": 252519442
    },
    {
      "context_text": "…and local perspectives and employed AMR-guided semantic graphs to capture intra-sentence and inter-sentence semantic features of arguments, where Ren et al. [37] proposed a multi-event head attention network that assigns arguments to roles in event-specific subspace with different attention heads.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the use of AMR-guided semantic graphs and a multi-event head attention network, which are methods rather than datasets.",
      "processing_time": 32.661128997802734,
      "citing_paper_id": "273195146",
      "cited_paper_id": 252819226
    },
    {
      "context_text": "TS-AGCMM TS-AGCMM [9] was proposed for sleep stage classification using multichannel brain recordings.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (TS-AGCMM) for sleep stage classification using multichannel brain recordings.",
      "processing_time": 30.363749265670776,
      "citing_paper_id": "273195146",
      "cited_paper_id": 268315840
    },
    {
      "context_text": "Björne and Salakoski [2] used a CNN to obtain a unified linear sentence representation, including semantic embeddings, positional embeddings, and dependency path embeddings.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CNN) and types of embeddings used. There are no verifiable resources or datasets mentioned.",
      "processing_time": 30.572254180908203,
      "citing_paper_id": "273195146",
      "cited_paper_id": null
    },
    {
      "context_text": "Subsequent studies utilized joint models [2] to mitigate error propagation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context is too vague to identify a reusable resource.",
      "processing_time": 29.58125138282776,
      "citing_paper_id": "272950526",
      "cited_paper_id": 61154509
    },
    {
      "context_text": "The last hidden state [4] in the representation direction for each sentence is then concatenated to obtain a semantically enhanced sentence vector representation By performing random queries in graph , this paper transforms the task into a multi-label classification task.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for transforming the task into a multi-label classification problem.",
      "processing_time": 28.65914273262024,
      "citing_paper_id": "272950526",
      "cited_paper_id": 212648787
    },
    {
      "context_text": "(2) While the Doc2EDAG model [9] integrates information from sentences and entities by incorporating the Transform model, it overlooks the interdependence between events, lacking the ability to model multiple events in dispersed documents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (Doc2EDAG) and a method (Transform). The context focuses on the limitations of the model rather than the use of a dataset.",
      "processing_time": 31.891108989715576,
      "citing_paper_id": "272950526",
      "cited_paper_id": 231632837
    },
    {
      "context_text": "By comparing models at different levels, we conducted the following comparative experiments to validate the effectiveness of the proposed model: (1) The DCFEE model [8] employs a remote supervision approach to address the issue of insufficient document data extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (DCFEE) and a method (remote supervision). There are no clear identifiers for datasets in the text.",
      "processing_time": 31.38167428970337,
      "citing_paper_id": "272950526",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Both sentence-level (Chen et al., 2015; Nguyen et al., 2016) and document-level (Zheng et al., 2019; Zhu et al., 2022) event extraction encoded the entity type feature, verifying its significance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The context focuses on the encoding of entity type features in event extraction at both sentence and document levels.",
      "processing_time": 31.894707441329956,
      "citing_paper_id": "259370740",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Both sentence-level (Chen et al., 2015; Nguyen et al., 2016) and document-level (Zheng et al., 2019; Zhu et al., 2022) event extraction encoded the entity type feature, verifying its significance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The context focuses on the encoding of entity type features in event extraction at both sentence and document levels.",
      "processing_time": 31.894707441329956,
      "citing_paper_id": "259370740",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "In this paper, the BERT (Devlin et al., 2019) is used to initialize token embedding, and the vector of i -th token w i is denoted as v i .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT, which is a model, not a dataset. No datasets are explicitly mentioned or used in the described research context.",
      "processing_time": 30.139319896697998,
      "citing_paper_id": "259370740",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Following previous studies (Chen et al., 2018; Wan et al., 2023a), given that the number of “O” tags is much larger than that of other relation tags, the standard cross-entropy loss with weight is used as our objective function to strengthen the influence of relation tags: where n is the number of…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to handling class imbalance in tagging tasks.",
      "processing_time": 28.891875982284546,
      "citing_paper_id": "259370740",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "Consistent with previous work, the Bi-LSTM network can capture the sequence structure information between tokens well, which is conducive to event extraction (Chen et al., 2018; Wan et al., 2023a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the effectiveness of the Bi-LSTM network for event extraction.",
      "processing_time": 30.738685607910156,
      "citing_paper_id": "259370740",
      "cited_paper_id": 53081291
    },
    {
      "context_text": "Consistent with previous work, the Bi-LSTM network can capture the sequence structure information between tokens well, which is conducive to event extraction (Chen et al., 2018; Wan et al., 2023a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the effectiveness of the Bi-LSTM network for event extraction.",
      "processing_time": 30.738685607910156,
      "citing_paper_id": "259370740",
      "cited_paper_id": 248325339
    },
    {
      "context_text": "Sentence-level event extraction approaches (Sha et al., 2018; Yang et al., 2019; Lu et al., 2021; Wan et al., 2021, 2023a) are difficult to deal with the problem of arguments across sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to sentence-level event extraction approaches. No verifiable resources are identified.",
      "processing_time": 29.84422993659973,
      "citing_paper_id": "259370740",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Sentence-level event extraction approaches (Sha et al., 2018; Yang et al., 2019; Lu et al., 2021; Wan et al., 2021, 2023a) are difficult to deal with the problem of arguments across sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to sentence-level event extraction approaches. No verifiable resources are identified.",
      "processing_time": 29.84422993659973,
      "citing_paper_id": "259370740",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "…extraction generally adopted the pipeline pattern (Zheng et al., 2019; Xu et al., 2021; Yang et al., 2021; Huang and Jia, 2021; Zhu et al., 2022; Liang et al., 2022), which decomposes the task into the following sub-tasks: (1) entity extraction (obtaining candidate arguments from a document),…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a methodological approach to document-level event extraction.",
      "processing_time": 28.62804365158081,
      "citing_paper_id": "259370740",
      "cited_paper_id": 249431954
    },
    {
      "context_text": "In terms of implementation strategies, the meth-ods based on graph decoding are mainly divided into entity-based directed acyclic graph (Zheng et al., 2019; Xu et al., 2021; Liang et al., 2022) and pseudo-trigger-aware pruned complete graph (Zhu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 30.30595302581787,
      "citing_paper_id": "259370740",
      "cited_paper_id": 249431954
    },
    {
      "context_text": "Following the studies of Artstein and Poesio (2008) and McHugh (2012), we used Cohen’s kappa coefficient to measure the inter-annotator agreement (IAA) for assessing annotation data consistency.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of Cohen’s kappa coefficient for measuring inter-annotator agreement. No verifiable resources are identified.",
      "processing_time": 30.97552466392517,
      "citing_paper_id": "274023993",
      "cited_paper_id": 5421278
    },
    {
      "context_text": "Following the studies of Artstein and Poesio (2008) and McHugh (2012), we used Cohen’s kappa coefficient to measure the inter-annotator agreement (IAA) for assessing annotation data consistency.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of Cohen’s kappa coefficient for measuring inter-annotator agreement. No verifiable resources are identified.",
      "processing_time": 30.97552466392517,
      "citing_paper_id": "274023993",
      "cited_paper_id": 12719479
    },
    {
      "context_text": "For instance, it can automatically detect and analyze major events in news reports, providing timely information for decision-makers (Tanev et al., 2008; Piskorski et al., 2007; Atkinson et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the capability of event detection systems. No clear identifiers for datasets are present.",
      "processing_time": 29.53433609008789,
      "citing_paper_id": "274023993",
      "cited_paper_id": 31791545
    },
    {
      "context_text": "Evaluation metrics include Precision, Recall, and Macro-F1 score following (Kowsari et al., 2019).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. No dataset names are present in the citation context.",
      "processing_time": 28.853586435317993,
      "citing_paper_id": "274023993",
      "cited_paper_id": 119297355
    },
    {
      "context_text": "Precision Recall F1 Overall Performance Table 2 shows experimental results for event classification, highlighting: 1) Transformer-based models (BERT, RoBERTa, ERNIE 3.0) outperform TextCNN, benefiting from pretraining on large-scale unlabeled corpora and possessing extensive background semantic knowledge.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance. The context focuses on comparing model performance rather than using a particular dataset.",
      "processing_time": 30.51269817352295,
      "citing_paper_id": "274023993",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "3) RoBERTa (Liu et al., 2019) extends BERT with larger training batches and learning rates.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (RoBERTa) and its improvements over BERT. No verifiable resources are identified.",
      "processing_time": 31.141642808914185,
      "citing_paper_id": "274023993",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "The DuEE dataset (Li et al., 2020) consists of 19,640 events divided into 65 event types and 121 argument roles, offering a rich resource for detailed analysis.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DuEE"
      ],
      "dataset_descriptions": {
        "DuEE": "Used for detailed analysis of Chinese event extraction, containing 19,640 events divided into 65 event types and 121 argument roles, providing a rich resource for real-world scenarios."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions the DuEE dataset, which is a specific, verifiable dataset used for Chinese event extraction. The dataset is described in detail, including the number of events, event types, and argument roles.",
      "processing_time": 40.70254945755005,
      "citing_paper_id": "274023993",
      "cited_paper_id": 222180086
    },
    {
      "context_text": "GENEVA (Parekh et al., 2022) is a large-scale benchmarking dataset designed to evaluate the generalizability of Event Argument Extraction (EAE) models, featuring 115 event types and 220 argument roles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GENEVA"
      ],
      "dataset_descriptions": {
        "GENEVA": "Used to evaluate the generalizability of Event Argument Extraction models, featuring 115 event types and 220 argument roles."
      },
      "confidence_score": 1.0,
      "reasoning": "GENEVA is identified as a benchmarking dataset for evaluating EAE models, which aligns with the topic of document-level event extraction.",
      "processing_time": 36.86014723777771,
      "citing_paper_id": "274023993",
      "cited_paper_id": 258865260
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role ﬁllers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 30.49660015106201,
      "citing_paper_id": "236460259",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role ﬁllers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 30.49660015106201,
      "citing_paper_id": "236460259",
      "cited_paper_id": 2213149
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role ﬁllers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 30.49660015106201,
      "citing_paper_id": "236460259",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role ﬁllers by manually designed linguistic features (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012) or neural-based contextual representation (Chen et al., 2020; Du et al., 2020; Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 30.49660015106201,
      "citing_paper_id": "236460259",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "…Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to sentence-level event extraction and the ACE (Assuming ACE is a method or framework, not a dataset).",
      "processing_time": 31.82415461540222,
      "citing_paper_id": "236460259",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "A great number of previous studies (Ahn, 2006; Ji and Grish-man, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 31.662931442260742,
      "citing_paper_id": "236460259",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "These studies are mainly based on hand-designed features (Li et al., 2013; Kai and Gr-ishman, 2015) and neural-based to learn features automatically (Chen et al., 2015; Nguyen et al., 2016; Bj¨orne and Salakoski, 2018; Yang et al., 2019; Chan et al., 2019; Yang et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 31.301349639892578,
      "citing_paper_id": "236460259",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "These studies are mainly based on hand-designed features (Li et al., 2013; Kai and Gr-ishman, 2015) and neural-based to learn features automatically (Chen et al., 2015; Nguyen et al., 2016; Bj¨orne and Salakoski, 2018; Yang et al., 2019; Chan et al., 2019; Yang et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 31.301349639892578,
      "citing_paper_id": "236460259",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "These studies are mainly based on hand-designed features (Li et al., 2013; Kai and Gr-ishman, 2015) and neural-based to learn features automatically (Chen et al., 2015; Nguyen et al., 2016; Bj¨orne and Salakoski, 2018; Yang et al., 2019; Chan et al., 2019; Yang et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 31.301349639892578,
      "citing_paper_id": "236460259",
      "cited_paper_id": 14117526
    },
    {
      "context_text": "These studies are mainly based on hand-designed features (Li et al., 2013; Kai and Gr-ishman, 2015) and neural-based to learn features automatically (Chen et al., 2015; Nguyen et al., 2016; Bj¨orne and Salakoski, 2018; Yang et al., 2019; Chan et al., 2019; Yang et al., 2019; Liu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 31.301349639892578,
      "citing_paper_id": "236460259",
      "cited_paper_id": 51878680
    },
    {
      "context_text": "…studies (Ahn, 2006; Ji and Grish-man, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies focusing on sentence-level event extraction. No verifiable resources are identified.",
      "processing_time": 30.692257165908813,
      "citing_paper_id": "236460259",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "Yang and Mitchell (2016) introduced event structure to jointly extract events and entities within a document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the introduction of a method for joint extraction of events and entities, but does not specify a dataset.",
      "processing_time": 28.57242250442505,
      "citing_paper_id": "236460259",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "All of these de-coders are based on the non-autoregressive mechanism (Gu et al., 2018), which supports the extraction of all events in parallel.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (non-autoregressive mechanism).",
      "processing_time": 28.567994356155396,
      "citing_paper_id": "236460259",
      "cited_paper_id": 3480671
    },
    {
      "context_text": "Both of them are based on the non-autoregressive mechanism (Gu et al., 2018), which supports the extraction of multiple events in parallel.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (non-autoregressive mechanism).",
      "processing_time": 28.80604362487793,
      "citing_paper_id": "236460259",
      "cited_paper_id": 3480671
    },
    {
      "context_text": "…great number of previous studies (Ahn, 2006; Ji and Grish-man, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies focusing on sentence-level event extraction.",
      "processing_time": 29.479616165161133,
      "citing_paper_id": "236460259",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "During training, we employ the AdamW optimizer (Kingma and Ba, 2014) with the learning rate 1e-5 with batch size 16.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the AdamW optimizer, which is a method, not a dataset. No datasets are mentioned in the context.",
      "processing_time": 30.063727855682373,
      "citing_paper_id": "236460259",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "Finally, for comparing extracted events to ground truths, we propose a matching loss function inspired by the Hungarian algorithm (Kuhn, 1955; Munkres, 1957).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Hungarian algorithm) for a matching loss function.",
      "processing_time": 28.553043842315674,
      "citing_paper_id": "236460259",
      "cited_paper_id": 9426884
    },
    {
      "context_text": "Inspired by the assigning problem in the operation research (Kuhn, 1955; Munkres, 1957), we propose a matching loss function, which can produce an optimal bipartite matching between predicted and ground-truth events.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for solving an assignment problem.",
      "processing_time": 28.27390217781067,
      "citing_paper_id": "236460259",
      "cited_paper_id": 9426884
    },
    {
      "context_text": "…Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE"
      ],
      "dataset_descriptions": {
        "ACE": "Used to evaluate sentence-level event extraction systems, providing annotated data for benchmarking performance in identifying and classifying events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE evaluation' which is a specific dataset used for evaluating event extraction systems. The title confirms it is a dataset.",
      "processing_time": 35.14035773277283,
      "citing_paper_id": "236460259",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "…and Grish-man, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works focusing on sentence-level event extraction. No verifiable resources are named.",
      "processing_time": 31.086601495742798,
      "citing_paper_id": "236460259",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "These studies are mainly based on handdesigned features (Li et al., 2013; Kai and Grishman, 2015) and neural-based to learn features automatically (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and previous work.",
      "processing_time": 28.2622287273407,
      "citing_paper_id": "236460259",
      "cited_paper_id": 14117526
    },
    {
      "context_text": "A two-step approach (Zhang et al., 2020) is proposed for argument linking by detecting implicit argument across sentences.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for argument linking. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 30.027930736541748,
      "citing_paper_id": "236460259",
      "cited_paper_id": 43095407
    },
    {
      "context_text": "A two-step approach (Zhang et al., 2020) is proposed for argument linking by detecting implicit argument across sentences.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for argument linking. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 30.027930736541748,
      "citing_paper_id": "236460259",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Recently, Ebner et al. (2020) published the Roles Across Multiple Sentences (RAMS) dataset, which contains annotation for the task of multi-sentence argument linking.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Roles Across Multiple Sentences (RAMS)"
      ],
      "dataset_descriptions": {
        "Roles Across Multiple Sentences (RAMS)": "Used to annotate and link arguments across multiple sentences, supporting the development of systems for document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for multi-sentence argument linking.",
      "processing_time": 36.58289074897766,
      "citing_paper_id": "236460259",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Similar to the sentence length task proposed by Adi et al. (2017), we employed a word count ( WordCt ) task and a sentence count ( SentCt ) task, each predicts the number of words and sentences in the text respectively.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes tasks (WordCt and SentCt) used to predict the number of words and sentences in text.",
      "processing_time": 32.51072573661804,
      "citing_paper_id": "264439234",
      "cited_paper_id": 6771196
    },
    {
      "context_text": "Encoding layers Lastly, we experiment to locate the encoding of IE information in different layers of the encoders, a common topic in previous works (Tenney et al., 2019a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to previous work on encoding layers in encoders.",
      "processing_time": 29.732598066329956,
      "citing_paper_id": "264439234",
      "cited_paper_id": 155092004
    },
    {
      "context_text": "…lookup style embeddings such as GloVe (Pen-nington et al., 2014), these neural contextualized representations are inherently difficult to interpret, leading to ongoing research efforts focused on analyzing their encoded information (Tenney et al., 2019b; Zhou and Srikumar, 2021; Belinkov, 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The focus is on the interpretability of neural contextualized representations.",
      "processing_time": 30.872653245925903,
      "citing_paper_id": "264439234",
      "cited_paper_id": 155092004
    },
    {
      "context_text": "TANL (Paolini et al., 2021) is a multi-task sequence-to-sequence model that fine-tunes T5 model (Raffel et al., 2020) to translate text input to augmented natural languages, with the in-text augmented parts extracted to be triggers and roles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is about a method (TANL) that builds upon another model (T5).",
      "processing_time": 32.22553849220276,
      "citing_paper_id": "264439234",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "This work is inspired by various sentence-level embedding interpretability works, including Conneau et al. (2018) and Alt et al. (2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other research works. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 31.40493893623352,
      "citing_paper_id": "264439234",
      "cited_paper_id": 211268325
    },
    {
      "context_text": "Additionally, we focus on template-filling-capable IE frameworks as they show more generality in applications (and is supported by more available models like GTT), barring classical relation extraction task dataset like the DocRED(Yao et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Not used in this research; mentioned as an example of a classical relation extraction task dataset that is excluded from the study."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'DocRED' as a classical relation extraction task dataset, which is a specific, verifiable dataset. However, it is mentioned in the context of exclusion, not usage.",
      "processing_time": 37.944064140319824,
      "citing_paper_id": "264439234",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "In addition to above observations, we see that DyGIE++ and GTT document embeddings capture event information (EvntCt ↑ ) only marginally better than the baseline, whereas the TANL-finetuned encoder often has subpar performance across tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model performances. No verifiable resources are identified.",
      "processing_time": 29.42003560066223,
      "citing_paper_id": "264439234",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "GTT (Du et al., 2021) is a sequence-to-sequence event-extraction model that perform the task end-to-end, without the need of labeled triggers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (GTT) for event extraction. The title 'Template Filling with Generative Transformers' confirms that the focus is on a method, not a dataset.",
      "processing_time": 33.563846826553345,
      "citing_paper_id": "264439234",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Using GTT with the same hyperparameter in its publication, its finetuned encoder shows semantic information encoding mostly (0-indexed) up to layer 7 (IsArg ↑ , ArgTyp ↑ ), meanwhile, event detection capability increases throughout the encoder (CoEvnt ↑ , EvntCt ↑ ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the performance of a model (GTT) in terms of semantic information encoding and event detection capability.",
      "processing_time": 31.740349531173706,
      "citing_paper_id": "264439234",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "[23] use welldefined features to model and learn event-argument relations between different sentences in a document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for modeling and learning event-argument relations. No clear, verifiable dataset names are present.",
      "processing_time": 31.735917806625366,
      "citing_paper_id": "260386477",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "[2] use two different recurrent neural networks to learn sentence representation and conduct joint event extraction, that is, extract triggers and argument roles simultaneously.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of recurrent neural networks for joint event extraction.",
      "processing_time": 29.69827890396118,
      "citing_paper_id": "260386477",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Most of the previous work has focused on event extraction at the sentence level [1], [2], [3], [4], extracting events from individual sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general focus on sentence-level event extraction.",
      "processing_time": 29.40007185935974,
      "citing_paper_id": "260386477",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "We use the Adam optimizer [29] to optimize the model while using the learning rate of 5e-4 and set the batch size to 64.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Adam optimizer, which is a method for stochastic optimization, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 31.023632049560547,
      "citing_paper_id": "260386477",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "tion datasets usually use distantly supervised and knowledge base [8], [9] to annotate triggers, which are missing and the",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context does not provide specific dataset names, only mentions general methods for annotation. No clear, verifiable datasets are identified.",
      "processing_time": 29.686177492141724,
      "citing_paper_id": "260386477",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "DCFEE-O extracts only one event record from the document and DCFEE-M extracts as many event records as possible.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods or systems (DCFEE-O and DCFEE-M). No verifiable resources are identified.",
      "processing_time": 31.007142305374146,
      "citing_paper_id": "260386477",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "1) DCFEE [10] has two variants: DCFEEO extracts only one event record from the document and DCFEE-M extracts as many event records as possible.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DCFEE, which is a system, not a dataset. No other datasets are mentioned.",
      "processing_time": 29.112019777297974,
      "citing_paper_id": "260386477",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Among all the models, TFECI is the lightest one and is on the same scale with DCFEE [10], while TFECI surpasses",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models. The context is about comparing model performance, not using a dataset.",
      "processing_time": 30.824464797973633,
      "citing_paper_id": "260386477",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Among all the models, TFECI is the lightest one and is on the same scale with DCFEE [10], while TFECI surpasses DCFEE-O with about 15.9 absolute gain in F1 score on the ChFinAnn dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used to evaluate the performance of TFECI against DCFEE-O, focusing on document-level Chinese financial event extraction with F1 score as the primary metric."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ChFinAnn dataset, which is used to evaluate the performance of TFECI compared to DCFEE-O. The dataset is specific and relevant to document-level event extraction.",
      "processing_time": 40.160505294799805,
      "citing_paper_id": "260386477",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "[10] first identify a key sentence in the document and then fill the event table by looking for arguments close to the key sentence, but this approach misses the context and global arguments information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction. No clear, verifiable resource names are present.",
      "processing_time": 30.358613967895508,
      "citing_paper_id": "260386477",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Different from the trigger-based methods [24], [25].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological difference from trigger-based methods.",
      "processing_time": 29.650428533554077,
      "citing_paper_id": "260386477",
      "cited_paper_id": 174800619
    },
    {
      "context_text": "[21] discuss how to do event types detection without triggers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a discussion on event type detection methods.",
      "processing_time": 28.697426080703735,
      "citing_paper_id": "260386477",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "[21] are the first to apply the QuestionAnswer method to solve the problem of event extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 28.876523971557617,
      "citing_paper_id": "260386477",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Because mention type features have been shown to improve the performance on downstream tasks [5], [28], we convert mention type features into vectors by looking up the embedding table.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for converting mention type features into vectors.",
      "processing_time": 30.13056230545044,
      "citing_paper_id": "260386477",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "A lot of work has obtained good performance by using machine learning algorithm[12], [13], [14], [15], [16], [17] for feature extraction and information mining.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general use of machine learning algorithms for feature extraction and information mining.",
      "processing_time": 31.15502119064331,
      "citing_paper_id": "260386477",
      "cited_paper_id": 257019152
    },
    {
      "context_text": "Patwardhan and Riloff [32], Huang and Riloff [33, 34] manually design linguistic features to extract the role ﬁllers with the local and additional context.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of manually designed linguistic features for event extraction.",
      "processing_time": 30.54637122154236,
      "citing_paper_id": "256385289",
      "cited_paper_id": 2213149
    },
    {
      "context_text": "Patwardhan and Riloff [32], Huang and Riloff [33, 34] manually design linguistic features to extract the role fillers with the local and additional context.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the method of manually designing linguistic features for event extraction.",
      "processing_time": 30.5421302318573,
      "citing_paper_id": "256385289",
      "cited_paper_id": 2213149
    },
    {
      "context_text": "Yang and Mitchell [36] use well-deﬁned features to handle the event-argument relations across sentences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for handling event-argument relations. The title confirms the focus on joint extraction methods rather than specific datasets.",
      "processing_time": 32.73943471908569,
      "citing_paper_id": "256385289",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "Many previous feature-based methods focus on designing various hand-crafted features to extract events, such as lexical features and syntactic features [10–12].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general methods and features. No verifiable resources are identified.",
      "processing_time": 31.148247718811035,
      "citing_paper_id": "256385289",
      "cited_paper_id": 2941631
    },
    {
      "context_text": "To utilize more knowledge, some studies adopt pre-trained language model [2], document context [22, 24–26], and explicit external knowledge [27, 28] such as WordNet [29].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and tools. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 32.246267557144165,
      "citing_paper_id": "256385289",
      "cited_paper_id": 9778664
    },
    {
      "context_text": "To utilize more knowledge, some studies adopt pre-trained language model [2], document context [22, 24–26], and explicit external knowledge [27, 28] such as WordNet [29].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and tools. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 32.246267557144165,
      "citing_paper_id": "256385289",
      "cited_paper_id": 70346512
    },
    {
      "context_text": "Previous researches [1–3] mainly focus on sentence-level event extraction (SEE), that is, extracting event information from a sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general focus on sentence-level event extraction. No verifiable resources are named.",
      "processing_time": 32.123042821884155,
      "citing_paper_id": "256385289",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Previous researches [1–3] mainly focus on sentence-level event extraction (SEE), that is, extracting event information from a sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general focus on sentence-level event extraction. No verifiable resources are named.",
      "processing_time": 32.123042821884155,
      "citing_paper_id": "256385289",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "To show the extreme difficulty when arguments-scattering meets multi-events for DEE, we follow the previous works [4, 5, 8, 9] and conduct experiments on two scenarios: single-event (i.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only scenarios and previous works. No clear, verifiable resource names are provided.",
      "processing_time": 31.309162378311157,
      "citing_paper_id": "256385289",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "[4], which adopts a key-event detection to guide event table filled with the arguments from key-event mention and surrounding sentences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation does not mention any specific dataset names, only a method for document-level event extraction. The context is too vague to identify a specific dataset.",
      "processing_time": 32.39518141746521,
      "citing_paper_id": "256385289",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "[4] extract events from a central sentence and find other arguments from neighboring sentences separately.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction. The title suggests the use of automatically labeled training data, but no specific dataset name is provided.",
      "processing_time": 33.67247128486633,
      "citing_paper_id": "256385289",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "[4] first extract events from a central sentence, and then find missing arguments from neighbor sentences as supplements.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction. The title suggests the use of automatically labeled training data, but no specific dataset name is provided.",
      "processing_time": 34.08402633666992,
      "citing_paper_id": "256385289",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "[13] adopt fine-grained bidirectional long short-term memory and support vector machine to deal with the event trigger identification.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context is focused on the methodology used for event trigger identification.",
      "processing_time": 33.09045124053955,
      "citing_paper_id": "256385289",
      "cited_paper_id": 209948413
    },
    {
      "context_text": "Du and Cardie [30] extract events in a Question–Answer way.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 31.977208852767944,
      "citing_paper_id": "256385289",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Du and Cardie [30] extract events in a Question–Answer way.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 31.977208852767944,
      "citing_paper_id": "256385289",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Du and Cardie [6] and Du et al. [7] only consider a single event by concatenate multiple sentences, ignoring the modeling of multiple events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No dataset names are present in the citation context.",
      "processing_time": 33.29569482803345,
      "citing_paper_id": "256385289",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Du and Cardie [6] try to encode the sentences in a multi-granularity way, and [7] leverage a sequence-to-sequence (seq2seq) model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context is focused on the approach and model used rather than a specific dataset.",
      "processing_time": 34.2740523815155,
      "citing_paper_id": "256385289",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Liu et al. [17], Zhang et al. [18], Hu et al. [19], Yan et al. [20], Lu et al. [21] model graph information to enhance information ﬂow by introducing syntactic shortcut arcs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on modeling graph information and enhancing information flow, which is not directly related to document-level event extraction datasets.",
      "processing_time": 36.03075814247131,
      "citing_paper_id": "256385289",
      "cited_paper_id": 225157900
    },
    {
      "context_text": "Chen et al. [14], Wang et al. [15] adopt CNN to extract events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of CNN for event extraction. No verifiable resources are identified.",
      "processing_time": 34.382129192352295,
      "citing_paper_id": "256385289",
      "cited_paper_id": 225160964
    },
    {
      "context_text": "[21] model graph information to enhance information flow by introducing syntactic shortcut arcs.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enhancing information flow in graphs.",
      "processing_time": 33.64046597480774,
      "citing_paper_id": "256385289",
      "cited_paper_id": 238590886
    },
    {
      "context_text": "Next, we leverage a pointer network (Vinyals et al., 2015): where H r ∈ R N r d is event role representation from H t , W r , W a ∈ R d d , v ∈ R d are trainable parameters, + is the broadcasting plus of two matrices, P r ∈ R N r ( N a +1) is the score of arguments corresponding to roles in the…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (pointer network) and its parameters. There are no clear identifiers for datasets.",
      "processing_time": 34.949740409851074,
      "citing_paper_id": "266163877",
      "cited_paper_id": 5692837
    },
    {
      "context_text": "…(1) named entity : mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc (Nadeau and Sekine, 2007); (2) entity mention : a text span of entity in the document which refers to a named entity; (3) event argument : an entity…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general concepts related to named entity recognition and classification. No verifiable resources are identified.",
      "processing_time": 35.23906397819519,
      "citing_paper_id": "266163877",
      "cited_paper_id": 8310135
    },
    {
      "context_text": "Then these tokens are encoded by a vanilla transformer encoder (Vaswani et al., 2017) to get the hidden representation: Where H w ∈ R N w d , d is the hidden dimension.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (transformer encoder) from a cited paper. No datasets are referenced.",
      "processing_time": 35.114375591278076,
      "citing_paper_id": "266163877",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "For extracting multiple events without triggers, a trigger-free method is first designed to detect an event in a center sentence and extract the rest of event arguments from surrounding sentences (Yang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction. The context focuses on the methodology rather than a particular dataset.",
      "processing_time": 34.73874044418335,
      "citing_paper_id": "266163877",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "The ChFinAnn dataset (Zheng et al., 2019) is a large dataset focuses on five event types from the financial text, which has 25 , 632 / 3 , 204 / 3 , 204 for the train/dev/test set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used to train and evaluate models for document-level financial event extraction, focusing on five specific event types with a large annotated corpus."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions 'ChFinAnn dataset' with specific details about its content and split, making it a verifiable resource.",
      "processing_time": 40.81210446357727,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Following (Zheng et al., 2019), IPGPF finishes the event extraction by handling three sub-tasks: (1) Named Entity Recognition (NER) : extracting entity mentions as argument candidates from the document; (2) Event Detection (ED) : judging whether there exist predefined event types in the document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only sub-tasks in a process. The context is about methodological steps in event extraction.",
      "processing_time": 35.63743996620178,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "…between sentence representation and argument representation by employing a vanilla transformer encoder: For focusing on the comparison of event record generation module, we keep the same feature H a ∈ R ( N a +1) d and H s ∈ R N s d with (Zheng et al., 2019; Yang et al., 2021) in Equation (17).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to feature representations and equations. The cited papers' titles suggest a focus on document-level event extraction, but no specific datasets are named in the context.",
      "processing_time": 37.939810037612915,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "…between sentence representation and argument representation by employing a vanilla transformer encoder: For focusing on the comparison of event record generation module, we keep the same feature H a ∈ R ( N a +1) d and H s ∈ R N s d with (Zheng et al., 2019; Yang et al., 2021) in Equation (17).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to feature representations and equations. The cited papers' titles suggest a focus on document-level event extraction, but no specific datasets are named in the context.",
      "processing_time": 37.939810037612915,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "We implement IPGPF under Pytorch (Paszke et al., 2017) based on codes released by (Zheng et al., 2019) and (Yang et al., 2021).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only software frameworks and code releases. The cited papers' titles suggest document-level event extraction, but no specific datasets are named in the context.",
      "processing_time": 37.28062295913696,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "We implement IPGPF under Pytorch (Paszke et al., 2017) based on codes released by (Zheng et al., 2019) and (Yang et al., 2021).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only software frameworks and code releases. The cited papers' titles suggest document-level event extraction, but no specific datasets are named in the context.",
      "processing_time": 37.28062295913696,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "Doc2EDAG (Zheng et al., 2019) designs an auto-regressive entity-based directed acyclic graph (EDAG) to generate event records.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Doc2EDAG' but does not refer to it as a dataset. It is described as a method or framework for document-level event extraction.",
      "processing_time": 36.587252140045166,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Most trigger-free DEE methods (Zheng et al., 2019; Xu et al., 2021a; Liang et al., 2022) build entity-based directed acyclic graph (EDAG) to auto-regressively generate event arguments with their roles under a predefined order.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on describing the methodologies used in document-level event extraction.",
      "processing_time": 35.863067626953125,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Then a widely used entity-based directed acyclic graph (EDAG) generation method is proposed to better deal with multiple events extraction (Zheng et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions an EDAG generation method but does not refer to any specific dataset. The focus is on the method itself rather than a reusable dataset.",
      "processing_time": 36.25479483604431,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Following (Zheng et al., 2019), we use the micro precision, recall, and F1-score over all arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. The context is focused on the methodology and performance metrics rather than data sources.",
      "processing_time": 36.10422492027283,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Due to the space limit, we put the details of NER and ED sub-tasks that are the same with (Zheng et al., 2019) to Appendix A.3 and A.4.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to sub-tasks in another paper. No clear identifiers for datasets are present.",
      "processing_time": 36.093177795410156,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "In the model training, following (Zheng et al., 2019), we generate event records for each event type independently and finally sum the loss of all event types.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating event records and summing losses.",
      "processing_time": 34.68975353240967,
      "citing_paper_id": "266163877",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Regarding the pre-trained encoder, we utilize LERT (Cui et al., 2022) for ChFinAnn and ERNIE (Sun et al., 2019) for DuEE-fin.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions pre-trained encoders LERT and ERNIE but does not refer to any specific datasets. The names are models, not datasets.",
      "processing_time": 36.570210456848145,
      "citing_paper_id": "266163877",
      "cited_paper_id": 125977708
    },
    {
      "context_text": "Recently, some works also tried to cast the event extraction task as question answering task (Du and Cardie, 2020b; Zhou et al., 2021), or sequence-to-sequence task (Xi-angyu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches to event extraction.",
      "processing_time": 35.356343269348145,
      "citing_paper_id": "266163877",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Different from sentence-level event extraction (SEE) (Chen et al., 2015; Nguyen et al., 2016; Du and Cardie, 2020b), event arguments of an event record are usually scattered across multiple sentences, while overlapping arguments contained in several event records appear more often.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses differences between sentence-level and document-level event extraction.",
      "processing_time": 33.99596118927002,
      "citing_paper_id": "266163877",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Most document-level EE meth-ods are built upon the event triggers, with which they conduct sequence labelling (Du and Cardie, 2020a; Veyseh et al., 2021) or span-based prediction (Ebner et al., 2020; Zhang et al., 2020; Xu et al., 2022) to identify event arguments in the document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 36.223814964294434,
      "citing_paper_id": "266163877",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Sequence-to-sequence (Du et al., 2021a,b; Li et al., 2021; Huang et al., 2021; Huang and Peng, 2021; Hsu et al., 2022), and question answering (Wei et al., 2021; Ma et al., 2022) paradigms are also applied.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only paradigms and methods. No dataset names are present in the context.",
      "processing_time": 36.77250409126282,
      "citing_paper_id": "266163877",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "Sequence-to-sequence (Du et al., 2021a,b; Li et al., 2021; Huang et al., 2021; Huang and Peng, 2021; Hsu et al., 2022), and question answering (Wei et al., 2021; Ma et al., 2022) paradigms are also applied.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only paradigms and methods. No dataset names are present in the context.",
      "processing_time": 36.77250409126282,
      "citing_paper_id": "266163877",
      "cited_paper_id": 234358675
    },
    {
      "context_text": "Several variant methods based on EDAG generation are presented by utilizing more meticulous feature engineering, such as heterogeneous graph feature (Xu et al., 2021a; Huang et al., 2021) and entity relation feature (Liang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and features. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 37.2251558303833,
      "citing_paper_id": "266163877",
      "cited_paper_id": 234358675
    },
    {
      "context_text": "1 Introduction Document-level event extraction (DEE) aims to extract multiple event records from the entire document (Ebner et al., 2020; Du et al., 2021b; Li et al., 2021; Xu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other research works. There are no clear identifiers for datasets, corpora, or similar resources.",
      "processing_time": 37.71926236152649,
      "citing_paper_id": "266163877",
      "cited_paper_id": 235097664
    },
    {
      "context_text": "Different from (Yang et al., 2021) which use a one-stage one-to-one matching to train their parallel model, we design a two-stage many-to-one matching algorithm to first performs multiple iterative refinements on the generated event records, and subsequently filters the best results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological difference in the approach to event extraction.",
      "processing_time": 36.88286519050598,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "Parallel models (Yang et al., 2021) are presented to generate all event records and roles simultaneously to avoid the error broadcasts in a given event role order.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction.",
      "processing_time": 36.32656717300415,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "DE-PPN (Yang et al., 2021) uses the same encoders with Doc2EDAG to obtain the features of arguments and sentences, but generates all event roles in parallel.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on describing the methodological approach of DE-PPN.",
      "processing_time": 38.29013919830322,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "Additionally, a parallel method is proposed to avoid the error broadcast in EDAG generation (Yang et al., 2021), and an efficient model is designed to lighten the model and accelerates the decoding speed (Zhu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on methodological improvements and does not reference any data sources.",
      "processing_time": 38.2864875793457,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "For the training epochs, we follow (Zheng et al., 2019; Yang et al., 2021; Xu et al., 2021a) to train 100 epochs for all compared models on the ChFi-nAnn dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFi-nAnn"
      ],
      "dataset_descriptions": {
        "ChFi-nAnn": "Used to train models for document-level event extraction, focusing on parallel prediction networks over 100 epochs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'ChFi-nAnn dataset' which is a specific dataset used for training models in document-level event extraction.",
      "processing_time": 46.223121643066406,
      "citing_paper_id": "266163877",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "SCDEE (Huang and Jia, 2021) builds an enhanced entity-sentence community graph, then detect event records from the graph and extract entities as arguments corresponding to the event roles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction.",
      "processing_time": 37.32120680809021,
      "citing_paper_id": "266163877",
      "cited_paper_id": 244119148
    },
    {
      "context_text": "These applications span knowledge graph construction [1,2], recommender systems [3,4], intelligent question answering [5,6], as well as other tasks [7–11] for more in-depth and precise analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general application areas. No dataset names are present in the text.",
      "processing_time": 38.098013162612915,
      "citing_paper_id": "265006143",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "These applications span knowledge graph construction [1,2], recommender systems [3,4], intelligent question answering [5,6], as well as other tasks [7–11] for more in-depth and precise analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general application areas. No dataset names are present in the text.",
      "processing_time": 38.098013162612915,
      "citing_paper_id": "265006143",
      "cited_paper_id": 18779057
    },
    {
      "context_text": "These applications span knowledge graph construction [1,2], recommender systems [3,4], intelligent question answering [5,6], as well as other tasks [7–11] for more in-depth and precise analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general application areas. No dataset names are present in the text.",
      "processing_time": 38.098013162612915,
      "citing_paper_id": "265006143",
      "cited_paper_id": 210994639
    },
    {
      "context_text": "These applications span knowledge graph construction [1,2], recommender systems [3,4], intelligent question answering [5,6], as well as other tasks [7–11] for more in-depth and precise analysis.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general application areas. No dataset names are present in the text.",
      "processing_time": 38.098013162612915,
      "citing_paper_id": "265006143",
      "cited_paper_id": 235421996
    },
    {
      "context_text": "The GloVe model [25] leverages co-occurrence matrices to capture word semantics comprehensively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the GloVe model but does not refer to a specific dataset. The GloVe model is a method for capturing word semantics using co-occurrence matrices.",
      "processing_time": 40.13663077354431,
      "citing_paper_id": "265006143",
      "cited_paper_id": 1957433
    },
    {
      "context_text": "On the other hand, the ELMo model [26] dynamically adjusts word vectors based on context, effectively addressing the issue of polysemous words; however, it does not fully exploit contextual information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions ELMo as a model, not a dataset. No datasets are explicitly mentioned or used in the given citation span.",
      "processing_time": 39.49110960960388,
      "citing_paper_id": "265006143",
      "cited_paper_id": 3626819
    },
    {
      "context_text": "Nguyen et al. [35] learned sentence representations using a structure based on bidirectional Recurrent Neural Networks (RNN) [36], utilizing memory vectors and memory matrices to store information related to trigger words, arguments, and their dependencies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for learning sentence representations using RNNs.",
      "processing_time": 38.09158253669739,
      "citing_paper_id": "265006143",
      "cited_paper_id": 5590763
    },
    {
      "context_text": "Therefore, we will analyze typical models and methods for event extraction that obtain semantic representations at three different levels: words, sentences, and documents [21–23].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods for event extraction. There are no verifiable resources or datasets mentioned.",
      "processing_time": 39.10707235336304,
      "citing_paper_id": "265006143",
      "cited_paper_id": 10694510
    },
    {
      "context_text": "For an event-argument path consisting of a sequence of entities, the entities in the route are stitched together to obtain a representation of the path 𝑃 (cid:4670)𝐸 (cid:3036) (cid:3117) , … , … , 𝐸 (cid:3036) (cid:3280) (cid:4671) , which is encoded using the Bi-directional Long Short-Term Memory (BiLSTM) [53], adding the embedding transformation of the event type into a vector 𝑇 and a sentence feature vector 𝑆 , which are stored in global storage 𝐺 ,which is shared among the different event types.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BiLSTM) and a model (CRF) used for sequence tagging. The context focuses on the technical details of the model architecture and does not reference any data sources.",
      "processing_time": 44.14943742752075,
      "citing_paper_id": "265006143",
      "cited_paper_id": 12740621
    },
    {
      "context_text": "…path 𝑃 (cid:4670)𝐸 (cid:3036) (cid:3117) , … , … , 𝐸 (cid:3036) (cid:3280) (cid:4671) , which is encoded using the Bi-directional Long Short-Term Memory (BiLSTM) [53], adding the embedding transformation of the event type into a vector 𝑇 and a sentence feature vector 𝑆 , which are stored in…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BiLSTM).",
      "processing_time": 37.65687131881714,
      "citing_paper_id": "265006143",
      "cited_paper_id": 12740621
    },
    {
      "context_text": "Chen et al. [33] proposed dynamic multi-pooled Convolutional Neural Networks (CNN) [34] to extract sentence-level clues, employing dynamic pooling layers to preserve more information about event trigger words and arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (dynamic multi-pooled CNN) and its application to sentence-level event extraction.",
      "processing_time": 39.468908071517944,
      "citing_paper_id": "265006143",
      "cited_paper_id": 14542261
    },
    {
      "context_text": "Yang et al. [44] proposed the DCFEE model, which extracts trigger words and arguments in a sentence-by-sentence manner.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (DCFEE) and its functionality. No verifiable resources are identified.",
      "processing_time": 39.449880599975586,
      "citing_paper_id": "265006143",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "In order to validate the performance of our model, we performed a comparative analysis of several baseline models of the DEE task: •DCFEE [44] reduces the DEE task to a SEE task by extracting arguments from specific core sentences while looking for missing arguments in neighboring sentences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DCFEE) and a task (Document-level Chinese Financial Event Extraction).",
      "processing_time": 39.693010091781616,
      "citing_paper_id": "265006143",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "The BERT model [27], which utilizes the Bidirectional Transformer [28] language model, combines contextual semantics with a masking approach for training, resulting in more expressive word vectors.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the BERT model and the Bidirectional Transformer. These are models, not datasets.",
      "processing_time": 39.45844268798828,
      "citing_paper_id": "265006143",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "To tackle the problem of entities assuming different roles in different events, Yang et al. [38] separated the prediction of arguments and prediction of argument roles tasks, effectively resolving role overlapping.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to event extraction.",
      "processing_time": 37.92697501182556,
      "citing_paper_id": "265006143",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "Sentences of a document are fed into the encoder to obtain a contextual representation, and then the entity information is extracted through the Conditional Random Field (CRF) [52] layer; 2) Heterogeneous Graph for Entity Interactions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Conditional Random Field (CRF)' but does not refer to a specific dataset. The CRF is described as a method or layer used in the process.",
      "processing_time": 41.692482471466064,
      "citing_paper_id": "265006143",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "The first challenge is the effective capture of event information that spans multiple sentences [19].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general challenge in capturing event information across multiple sentences.",
      "processing_time": 38.52063846588135,
      "citing_paper_id": "265006143",
      "cited_paper_id": 224924246
    },
    {
      "context_text": "Xu et al. [46] introduced the Tracker module to model the relationship between events, store decoded event information, and decode information for other event arguments.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Tracker module) used for document-level event extraction.",
      "processing_time": 38.725266456604004,
      "citing_paper_id": "265006143",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "•GIT [46]: The model designs a Heterogeneous Graph Interaction Network to describe the global interactions between sentences.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model design. The context is focused on the methodological approach rather than the data used.",
      "processing_time": 39.89424204826355,
      "citing_paper_id": "265006143",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "Zhou et al. [40] employed a dyadic question and answer approach, enabling the model to comprehend the semantics of roles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The title confirms the focus on a method rather than a dataset.",
      "processing_time": 38.383607625961304,
      "citing_paper_id": "265006143",
      "cited_paper_id": 235363528
    },
    {
      "context_text": "Yang et al. [47] proposed a multi-granularity decoder to extract all events in parallel.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction.",
      "processing_time": 38.03494715690613,
      "citing_paper_id": "265006143",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "To address these challenges, DEE requires models that can integrate document-level information while capturing multiple events across multiple sentences [48,49].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the need for models that can handle document-level information and multiple events.",
      "processing_time": 39.05827617645264,
      "citing_paper_id": "265006143",
      "cited_paper_id": 236477583
    },
    {
      "context_text": "Huang et al. [50] converted each document into an undirected graph based on sentence relationships, dividing the graph into subgraphs representing sentence communities.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for converting documents into graphs.",
      "processing_time": 38.01894760131836,
      "citing_paper_id": "265006143",
      "cited_paper_id": 244119148
    },
    {
      "context_text": "Relying solely on local features such as word-level semantics [32] is inadequate, necessitating the acquisition of contextual semantic representations at the sentence level.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to word-level semantics. No verifiable resources are identified.",
      "processing_time": 39.41634178161621,
      "citing_paper_id": "265006143",
      "cited_paper_id": 245335089
    },
    {
      "context_text": "Event extraction enables us to swiftly capture the essential elements and crucial information regarding public opinion events in social media data [12], facilitating a comprehensive understanding and analysis of these events.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to social media data. No multi-word proper nouns, acronyms, or other specific identifiers are present.",
      "processing_time": 41.92427945137024,
      "citing_paper_id": "265006143",
      "cited_paper_id": 247594010
    },
    {
      "context_text": "To broaden the scope of EE’s applicability [13,14], an increasing number of researchers are turning their attention to document-level event extraction (DEE).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general trend in research. No dataset names are present in the text.",
      "processing_time": 39.63972878456116,
      "citing_paper_id": "265006143",
      "cited_paper_id": 252440614
    },
    {
      "context_text": "Compared to SEE, DEE faces two major challenges: dealing with widely distributed arguments and recognizing multiple events [42].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses challenges in document-level event extraction.",
      "processing_time": 38.187528133392334,
      "citing_paper_id": "265006143",
      "cited_paper_id": 252819226
    },
    {
      "context_text": "Recent statistics indicate a growing proportion of public opinion focusing on the food and cosmetic industries [15–17], highlighting the critical role of DEE in analyzing harmful public opinion specifically related to food and cosmetic products.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general trend in public opinion. No verifiable resources are named.",
      "processing_time": 39.4013934135437,
      "citing_paper_id": "265006143",
      "cited_paper_id": 257126309
    },
    {
      "context_text": "Recent statistics indicate a growing proportion of public opinion focusing on the food and cosmetic industries [15–17], highlighting the critical role of DEE in analyzing harmful public opinion specifically related to food and cosmetic products.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general trend in public opinion. No verifiable resources are named.",
      "processing_time": 39.4013934135437,
      "citing_paper_id": "265006143",
      "cited_paper_id": 258801534
    },
    {
      "context_text": "Hu et al. [51] aimed to identify role arguments of a specific event type in a document.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a research goal related to event argument extraction.",
      "processing_time": 38.47990918159485,
      "citing_paper_id": "265006143",
      "cited_paper_id": 257268255
    },
    {
      "context_text": "We trained all models with the AdamW optimizer (Loshchilov and Hutter, 2018).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the AdamW optimizer, which is a method, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 39.62423300743103,
      "citing_paper_id": "252819226",
      "cited_paper_id": 3312944
    },
    {
      "context_text": "For strictly consistent comparison, we involve the following strong baselines: • BERT-CRF (Loshchilov and Hutter, 2018), which combines BERT with Condition Random Field (Lafferty et al., 2001), is the most popular method in tagging-based event extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BERT-CRF) used for event extraction. The context is focused on describing a baseline method for comparison.",
      "processing_time": 41.901073694229126,
      "citing_paper_id": "252819226",
      "cited_paper_id": 3312944
    },
    {
      "context_text": "Li et al. (2013, 2015) employ various hand-designed features to extract event; (Nguyen and Grishman, 2015; Nguyen et al., 2016; Chen et al., 2015; Liu et al., 2017, 2018) use neural based models such as recurrent neural networks (Zaremba et al., 2014) and convolutional neural network (Le-Cun et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 40.24852919578552,
      "citing_paper_id": "252819226",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Li et al. (2013, 2015) employ various hand-designed features to extract event; (Nguyen and Grishman, 2015; Nguyen et al., 2016; Chen et al., 2015; Liu et al., 2017, 2018) use neural based models such as recurrent neural networks (Zaremba et al., 2014) and convolutional neural network (Le-Cun et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 40.24852919578552,
      "citing_paper_id": "252819226",
      "cited_paper_id": 10913456
    },
    {
      "context_text": "Li et al. (2013, 2015) employ various hand-designed features to extract event; (Nguyen and Grishman, 2015; Nguyen et al., 2016; Chen et al., 2015; Liu et al., 2017, 2018) use neural based models such as recurrent neural networks (Zaremba et al., 2014) and convolutional neural network (Le-Cun et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 40.24852919578552,
      "citing_paper_id": "252819226",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Li et al. (2013, 2015) employ various hand-designed features to extract event; (Nguyen and Grishman, 2015; Nguyen et al., 2016; Chen et al., 2015; Liu et al., 2017, 2018) use neural based models such as recurrent neural networks (Zaremba et al., 2014) and convolutional neural network (Le-Cun et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles also do not provide clear dataset names.",
      "processing_time": 40.24852919578552,
      "citing_paper_id": "252819226",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "Analogy to multi-head attention (Vaswani et al., 2017), we propose a role-intera C tive mu L ti-event head attent I on netw O rk (CLIO) for DEE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (multi-head attention) and a proposed network (CLIO).",
      "processing_time": 40.02282929420471,
      "citing_paper_id": "252819226",
      "cited_paper_id": 13756489
    },
    {
      "context_text": ", 2014) and convolutional neural network (LeCun et al., 1998) to extract event.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (convolutional neural network).",
      "processing_time": 36.738417625427246,
      "citing_paper_id": "252819226",
      "cited_paper_id": 14542261
    },
    {
      "context_text": "Cognitive scientists believe that humans remember and understand reality primarily in terms of events (Shipley and Zacks, 2008).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general belief about human cognition. No verifiable resources are identified.",
      "processing_time": 39.591294288635254,
      "citing_paper_id": "252819226",
      "cited_paper_id": 140925826
    },
    {
      "context_text": "With the recent success of BERT (Devlin et al., 2019), pretrained language models have also been used for SEE (Wang et al., 2019b,c; Yang et al., 2019; Wadden et al., 2019; Tong et al., 2020; Wang et al., 2021; Lu et al., 2021; Liu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of pretrained language models for SEE (Sentence-level Event Extraction) but does not specify any datasets. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 43.08793544769287,
      "citing_paper_id": "252819226",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "With the recent success of BERT (Devlin et al., 2019), pretrained language models have also been used for SEE (Wang et al., 2019b,c; Yang et al., 2019; Wadden et al., 2019; Tong et al., 2020; Wang et al., 2021; Lu et al., 2021; Liu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of pretrained language models for SEE (Sentence-level Event Extraction) but does not specify any datasets. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 43.08793544769287,
      "citing_paper_id": "252819226",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "We apply an approach, proposed by (Hoffmann et al., 2022) based on InfoNCE, to include multiple positives.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method based on InfoNCE. The context focuses on the approach and its application, not on any particular dataset.",
      "processing_time": 42.07028412818909,
      "citing_paper_id": "252819226",
      "cited_paper_id": 245811890
    },
    {
      "context_text": "Despite successful efforts [1, 2, 3, 4, 5, 6, 7] to extract events within a sentence, a.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to efforts in event extraction within sentences.",
      "processing_time": 39.1648223400116,
      "citing_paper_id": "246634770",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Despite successful efforts [1, 2, 3, 4, 5, 6, 7] to extract events within a sentence, a.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to efforts in event extraction within sentences.",
      "processing_time": 39.1648223400116,
      "citing_paper_id": "246634770",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Despite successful efforts [1, 2, 3, 4, 5, 6, 7] to extract events within a sentence, a.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to efforts in event extraction within sentences.",
      "processing_time": 39.1648223400116,
      "citing_paper_id": "246634770",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "Recently, simulating human’s reading cognitive process to address specific natural language processing (NLP) tasks [13, 14] has",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to NLP tasks. No verifiable resources are identified.",
      "processing_time": 39.99797487258911,
      "citing_paper_id": "246634770",
      "cited_paper_id": 69988562
    },
    {
      "context_text": "To date, most DEE methods [8, 9, 10, 11] mainly focus on the first challenge but ignores the second one.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general challenges in DEE methods. No dataset names are present in the text.",
      "processing_time": 40.2087025642395,
      "citing_paper_id": "246634770",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "To date, most DEE methods [8, 9, 10, 11] mainly focus on the first challenge but ignores the second one.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general challenges in DEE methods. No dataset names are present in the text.",
      "processing_time": 40.2087025642395,
      "citing_paper_id": "246634770",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "To date, most DEE methods [8, 9, 10, 11] mainly focus on the first challenge but ignores the second one.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general challenges in DEE methods. No dataset names are present in the text.",
      "processing_time": 40.2087025642395,
      "citing_paper_id": "246634770",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "ArgSpan [10] extracts scattering arguments by enumerating possible argument spans within a specified scope of sentence window.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or tool called ArgSpan [10]. The cited paper title 'Multi-Sentence Argument Linking' does not help in identifying a dataset.",
      "processing_time": 44.018880128860474,
      "citing_paper_id": "246634770",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Early classification models [20, 21], divide DEE into two subtasks: recognition of event descriptors and detecting arguments, using SVM as classifiers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general methods and subtasks in document-level event extraction.",
      "processing_time": 39.15987753868103,
      "citing_paper_id": "251892871",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Early classification models [20, 21], divide DEE into two subtasks: recognition of event descriptors and detecting arguments, using SVM as classifiers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general methods and subtasks in document-level event extraction.",
      "processing_time": 39.15987753868103,
      "citing_paper_id": "251892871",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "SEE uses only features obtained from intrasentences, and traditional feature engineering-based approaches [12, 13], Table 3: F1-score for all event types on single-event (S.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context focuses on the use of features and F1-scores, which are not indicative of a dataset.",
      "processing_time": 43.32271194458008,
      "citing_paper_id": "251892871",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Pipeline methods [14, 15], whether using CNN or RNN, use a pipeline approach to split the extraction process into two separate processes, extracting event trigger words and detecting arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 41.22128081321716,
      "citing_paper_id": "251892871",
      "cited_paper_id": 5993783
    },
    {
      "context_text": "Pipeline methods [14, 15], whether using CNN or RNN, use a pipeline approach to split the extraction process into two separate processes, extracting event trigger words and detecting arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 41.22128081321716,
      "citing_paper_id": "251892871",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "To reduce error transfer, joint methods [16, 17], consider simultaneous extraction of trigger words and arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for joint event extraction.",
      "processing_time": 38.408732891082764,
      "citing_paper_id": "251892871",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "e aim of the Event Extraction (EE) task is to extract structured event information from unstructured text [1].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the general task of Event Extraction.",
      "processing_time": 38.613110303878784,
      "citing_paper_id": "251892871",
      "cited_paper_id": 41089825
    },
    {
      "context_text": "Our proposed method will be evaluated on the ChFinAnn dataset, which is also applied by DCFEE [9], Doc2EDAG [10], and DE-PPN [2].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used to evaluate the proposed method for document-level Chinese financial event extraction, focusing on performance and accuracy in identifying financial events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ChFinAnn dataset, which is used for evaluating the proposed method in document-level Chinese financial event extraction.",
      "processing_time": 47.002103090286255,
      "citing_paper_id": "251892871",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "DCFEE [9] is based on sequence annotation, main event discovery, and arguments complementation strategy to construct the extraction model, which solves the argument-scattering to a certain extent.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DCFEE, which is a system, not a dataset. No other specific datasets are mentioned.",
      "processing_time": 38.94900298118591,
      "citing_paper_id": "251892871",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "S&M DCFEE-O 56.0 46.5 86.7 54.1 48.5 41.2 47.7 45.2 68.4 61.1 61.5 49.6 58.0 — DCFEE-M 48.4 43.1 83.8 53.4 48.1 39.6 47.4 42.0 67.0 60.0 58.9 47.7 55.7 — GreedyDec 75.9 40.8 81.7 49.8 62.2 34.6 65.7 29.4 88.5 42.3 74.8 39.4 60.5 — Doc2EDAG 80.0 61.3 89.4 68.4 77.4 64.6 79.4 69.5 85.5 72.5 82.3 67.3 76.3 — DE-PPN-1 82.4 46.3 78.3 53.9 82.2 45.6 78.1 39.3 82.8 38.5 80.7 44.7 66.2 — DE-PPN 82.1 63.5 89.1 70.5 79.7 66.7 80.6 69.6 88.0 73.2 83.9 68.7 77.9 — DEERE (ours) 84.8 65.4 95.6 71.2 84.5 75.1 83.7 71.1 89.2 77.6 87.6 72.1 81.5 90.8 75.9 83.7\nTable 4: F1-score of ablation tests on DEERE variants.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only performance metrics of various models. No clear identifiers for datasets are present.",
      "processing_time": 39.95046520233154,
      "citing_paper_id": "251892871",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "DCFEE-O and DCFEE-M are the single-event version and multievent version, respectively.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions DCFEE-O and DCFEE-M but does not provide enough information to determine if they are datasets, methods, or other types of resources. The cited paper title suggests they are versions of a system, not datasets.",
      "processing_time": 44.739875078201294,
      "citing_paper_id": "251892871",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Our framework DEERE is compared with the previous SOTA methods as follows: DCFEE [9] proposed a DEE method based on key-event detection and argument completion.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DCFEE) and a framework (DEERE). The cited paper title confirms DCFEE is a method, not a dataset.",
      "processing_time": 43.981263637542725,
      "citing_paper_id": "251892871",
      "cited_paper_id": 51871198
    },
    {
      "context_text": ") are mostly based on BERT [7] or other pretrained language models.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models. BERT is a model, not a dataset.",
      "processing_time": 39.539443492889404,
      "citing_paper_id": "251892871",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In recent years, the relationship extraction SOTA models (Casrel, TPLinker, etc.) are mostly based on BERT [7] or other pretrained language models.)e original BERT uses absolute position encoding and can handle a maximum text length of 512 tokens.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their capabilities. The citation is primarily about the use of BERT and other pretrained language models in relation extraction tasks.",
      "processing_time": 43.28613471984863,
      "citing_paper_id": "251892871",
      "cited_paper_id": 52967399
    },
    {
      "context_text": ")e head size of the GlobalPointer in the relation extraction model is set to 64.)e text encoder adopts the char-based RoFormer (Chinese_roformer_char_L-12_H-768_A-12), whose parameter scale is comparable to BERTand the vocabulary is reduced to 12000.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and architectures. No verifiable resources are identified.",
      "processing_time": 39.28507447242737,
      "citing_paper_id": "251892871",
      "cited_paper_id": 52967399
    },
    {
      "context_text": ")e head size of the GlobalPointer in the relation extraction model is set to 64.)e text encoder adopts the char-based RoFormer (Chinese_roformer_char_L-12_H-768_A-12), whose parameter scale is comparable to BERTand the vocabulary is reduced to 12000.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and architectures. No verifiable resources are identified.",
      "processing_time": 39.28507447242737,
      "citing_paper_id": "251892871",
      "cited_paper_id": 233307138
    },
    {
      "context_text": ")e head size of the GlobalPointer in the relation extraction model is set to 64.)e text encoder adopts the char-based RoFormer (Chinese_roformer_char_L-12_H-768_A-12), whose parameter scale is comparable to BERTand the vocabulary is reduced to 12000.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and architectures. No verifiable resources are identified.",
      "processing_time": 39.28507447242737,
      "citing_paper_id": "251892871",
      "cited_paper_id": null
    },
    {
      "context_text": "To address the problem of overlapping roles, pretrained language models [18, 19], are used to model intrasentence and intersentence contextual information, improving the accuracy of the task overall.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of pretrained language models for improving event extraction. No verifiable resources are identified.",
      "processing_time": 41.54086089134216,
      "citing_paper_id": "251892871",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "To address the problem of overlapping roles, pretrained language models [18, 19], are used to model intrasentence and intersentence contextual information, improving the accuracy of the task overall.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of pretrained language models for improving event extraction. No verifiable resources are identified.",
      "processing_time": 41.54086089134216,
      "citing_paper_id": "251892871",
      "cited_paper_id": 202539496
    },
    {
      "context_text": ")e training results are shown in Figure 5, where Casrel [5] is a two-stage entity-relationship joint extraction model, and NEZHA [11] C B",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (Casrel and NEZHA). The context is focused on model performance rather than dataset usage.",
      "processing_time": 42.466899156570435,
      "citing_paper_id": "251892871",
      "cited_paper_id": 202537635
    },
    {
      "context_text": ")e training results are shown in Figure 5, where Casrel [5] is a two-stage entity-relationship joint extraction model, and NEZHA [11]\nis another pretrained language model using relative position encoding.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance. There are no clear identifiers for datasets in the text.",
      "processing_time": 41.17300319671631,
      "citing_paper_id": "251892871",
      "cited_paper_id": 202537635
    },
    {
      "context_text": "In addition, there are methods [26, 27], that transform EE into other tasks such as reading comprehension and intelligent quizzing.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for transforming event extraction into other tasks.",
      "processing_time": 39.090078830718994,
      "citing_paper_id": "251892871",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "RoleSelection EventDivision EF ER EU EO EP Macro-avg Micro-avg + + 74.5 93.0 80.4 77.9 81.9 81.5 83.7 + − 72.7 92.9 80.7 78.4 81.6 81.3 83.5 − + 72.6 92.2 79.8 75.0 79.6 79.8 81.8 − − 70.0 91.9 74.3 68.0 67.6 74.4 74.6\n50\n60\n70\n80\n90\n(% )\n750 1000 1250 1500 1750 2000 2250 2500500 Max-len of RoFormer\nPrecision Recall F1-score\nFigure 4: Effect of maximum encoding length.\ncannot be adapted to tasks that rely on complex semantic relationships.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only performance metrics and a figure related to the RoFormer model. The cited paper title confirms that RoFormer is a method, not a dataset.",
      "processing_time": 44.33181548118591,
      "citing_paper_id": "251892871",
      "cited_paper_id": 233307138
    },
    {
      "context_text": "For this, we try to use RoFormer [8], a Transformer that uses relative position encoding, to encode every document as a whole.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (RoFormer) which is a variant of the Transformer model. No datasets are referenced for training or evaluation.",
      "processing_time": 42.99964237213135,
      "citing_paper_id": "251892871",
      "cited_paper_id": 233307138
    },
    {
      "context_text": ")e performance of EE is basically synchronized with that of relation extraction, and the combination of GPLinker and RoFormer obtains the best score.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the performance of models and methods.",
      "processing_time": 38.90943193435669,
      "citing_paper_id": "251892871",
      "cited_paper_id": 233307138
    },
    {
      "context_text": "Since most of the documents in the dataset are within 2000 tokens, the maximum encoding length (max_len) of RoFormer is set to 2000.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context does not mention any specific, verifiable dataset name. It only refers to 'the dataset' without providing a clear identifier.",
      "processing_time": 39.272186517715454,
      "citing_paper_id": "251892871",
      "cited_paper_id": 233307138
    },
    {
      "context_text": ")e multilayer bidirectional network MLBiNet [25] fuses cross-sentence semantic and associative event information to enhance the discrimination of each event mention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (MLBiNet) and its functionality. There are no clear identifiers for datasets in the text.",
      "processing_time": 42.6599907875061,
      "citing_paper_id": "251892871",
      "cited_paper_id": 234790176
    },
    {
      "context_text": "Neural network-based classification models [22, 23], use word embeddings as the input to the decision tree, and then the structured information of the document is obtained through the integration of information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets in the text.",
      "processing_time": 40.4865448474884,
      "citing_paper_id": "251892871",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "Each kind of token-pair is recognized by a specific GlobalPointer, and all GlobalPointer modules share the same text encoder.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only describes a technical aspect of the GlobalPointer architecture.",
      "processing_time": 41.1231369972229,
      "citing_paper_id": "251892871",
      "cited_paper_id": null
    },
    {
      "context_text": "However, since the results of relation extraction will directly affect the results of EE, we adopt the recently proposed GPLinker [3], an entity-relationship joint extraction model based on GlobalPointer [4].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of GPLinker and GlobalPointer for entity-relationship joint extraction.",
      "processing_time": 42.650325298309326,
      "citing_paper_id": "251892871",
      "cited_paper_id": null
    },
    {
      "context_text": "GlobalPointer is essentially a token-pair recognition model, which can be used in nested and nonnested NER.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model called GlobalPointer. No datasets are referenced for use in the research.",
      "processing_time": 41.13264775276184,
      "citing_paper_id": "251892871",
      "cited_paper_id": null
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features [11, 12, 26] or neural-based contextual representation [4, 8, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 41.96109628677368,
      "citing_paper_id": "249579113",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features [11, 12, 26] or neural-based contextual representation [4, 8, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 41.96109628677368,
      "citing_paper_id": "249579113",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features [11, 12, 26] or neural-based contextual representation [4, 8, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 41.96109628677368,
      "citing_paper_id": "249579113",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Recent works explore the local and additional context to extract the role fillers by manually designed linguistic features [11, 12, 26] or neural-based contextual representation [4, 8, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 41.96109628677368,
      "citing_paper_id": "249579113",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "TIER [11] extracted role fillers from the secondary context that processes the extraction into three stages: classifying narrative document, recognizing event sentence, and noun phrase analysis.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (TIER) and its stages. No verifiable resources are identified.",
      "processing_time": 41.7448205947876,
      "citing_paper_id": "249579113",
      "cited_paper_id": 950755
    },
    {
      "context_text": "GLACIER [26] used a sentential event recognizer to select sentences and then applied a plausible role filler recognizer to extract role fillers as results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset names, only a method (GLACIER) and its components. The citation is about the method used for information extraction, not a dataset.",
      "processing_time": 44.085296869277954,
      "citing_paper_id": "249579113",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "The mainstream MRC models extract text spans from passages given the questions and have achieved good results [6, 29, 30, 32, 39].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general achievements in MRC models. No dataset names are provided in the context.",
      "processing_time": 41.46501898765564,
      "citing_paper_id": "249579113",
      "cited_paper_id": 6300274
    },
    {
      "context_text": "The mainstream MRC models extract text spans from passages given the questions and have achieved good results [6, 29, 30, 32, 39].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general achievements in MRC models. No dataset names are provided in the context.",
      "processing_time": 41.46501898765564,
      "citing_paper_id": "249579113",
      "cited_paper_id": 8535316
    },
    {
      "context_text": "Previous works [29, 30, 32, 39] have shown that the MRC framework can learn and infer in a document through the question-context pair.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MRC framework' which is likely a method or approach rather than a dataset. No specific dataset names are mentioned in the citation span.",
      "processing_time": 42.62841534614563,
      "citing_paper_id": "249579113",
      "cited_paper_id": 6300274
    },
    {
      "context_text": "Previous works [29, 30, 32, 39] have shown that the MRC framework can learn and infer in a document through the question-context pair.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'MRC framework' which is likely a method or approach rather than a dataset. No specific dataset names are mentioned in the citation span.",
      "processing_time": 42.62841534614563,
      "citing_paper_id": "249579113",
      "cited_paper_id": 8535316
    },
    {
      "context_text": "In recent years, the MRC task has been widely investigated since the release of large-scale corpora [14, 16, 27, 38].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'large-scale corpora' but does not specify any dataset names. The cited paper title 'RACE: Large-scale ReAding Comprehension Dataset From Examinations' suggests a potential dataset, but it is not explicitly mentioned in the citation context.",
      "processing_time": 46.90432286262512,
      "citing_paper_id": "249579113",
      "cited_paper_id": 6826032
    },
    {
      "context_text": "As a fundamental and challenging task in natural language processing (NLP) , EE can produce valuable structured information to facilitate many NLP applications, such as knowledge base construction, question answering, and language understanding [1, 13].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of Event Extraction in NLP.",
      "processing_time": 39.67120957374573,
      "citing_paper_id": "249579113",
      "cited_paper_id": 8471750
    },
    {
      "context_text": "A great number of EE research focuses on SEE, and most are based on the expert-annotated benchmark ACE 2005 [7] dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used as a benchmark for sentence-level event extraction, providing expert-annotated data to train and evaluate models in the field of event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE 2005 dataset, which is a well-known benchmark for event extraction. The dataset is explicitly used for SEE (Sentence-level Event Extraction) research.",
      "processing_time": 50.70049595832825,
      "citing_paper_id": "249579113",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "The second one is how to model long texts, as most MRC methods are based on the Transformer [31] architecture, which is limited to a fixed-length (e.g., 512) input.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a limitation of the Transformer architecture. No verifiable resources are identified.",
      "processing_time": 14.31315565109253,
      "citing_paper_id": "249579113",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "For the basic MRC-based method, we adopt Transformer-base [31], which has 12 layers, 768 hidden units, and 12 attention heads, as the local encoder.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (Transformer-base). The citation is about the model architecture, not a dataset.",
      "processing_time": 41.926307916641235,
      "citing_paper_id": "249579113",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Most of them are based on the Transformer architecture [31] with a multi-layer self-attention mechanism to model long dependencies between tokens with limited sequence length.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model architecture. No dataset names are present in the citation span.",
      "processing_time": 41.09096312522888,
      "citing_paper_id": "249579113",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "In this article, we adopt the Transformer [31], which contains multi-layer self-attention modules, as the local encoder: where h i , j ∈ R d h , d h denotes the hidden size.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Transformer) which is excluded according to the rules.",
      "processing_time": 40.23916268348694,
      "citing_paper_id": "249579113",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "McCann et al. [23] cast 10 tasks (e.g., machine translation, summarization, relation extraction, etc.) as a question answering paradigm and propose a general model for them with jointly training.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a variety of tasks. The focus is on the method and the multitask learning approach.",
      "processing_time": 41.08302712440491,
      "citing_paper_id": "249579113",
      "cited_paper_id": 49393754
    },
    {
      "context_text": "DCFEE [36] proposed a tagging-based model for SEE and a key-event detection model with an arguments-completion strategy for DEE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DCFEE but does not specify a dataset. The cited paper title suggests the use of automatically labeled training data, but no specific dataset name is provided.",
      "processing_time": 43.61319422721863,
      "citing_paper_id": "249579113",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "To solve the preceding challenges, previous works [36, 40] formulated DEE as a two-step paradigm: from sentence-level candidate argument extraction to document-level event fusion.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The cited paper title suggests a system but does not provide a clear dataset name.",
      "processing_time": 43.17627811431885,
      "citing_paper_id": "249579113",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "For exploring the real challenges (i.e., multi-events and arguments scattering) for DEE, DCFEE [36] proposed a pipeline method that contains a neural-based sequence tagging model for SEE and a key-event detection model with an arguments-completion strategy for DEE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method (DCFEE) and its components but does not reference a dataset by name.",
      "processing_time": 43.16201400756836,
      "citing_paper_id": "249579113",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "In recent years, as neural networks proved the effectiveness for NLP, many approaches [2, 3, 5, 19, 25, 28, 37, 37] have been proposed to improve performance on this task by employing deep learning models, such as recurrent neural networks and convolutional neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches and models. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 42.36049675941467,
      "citing_paper_id": "249579113",
      "cited_paper_id": 52349712
    },
    {
      "context_text": "2 A straightforward solution for modeling long texts is the sliding window [34], but this method sacrifices the possibility that the distant tokens “pay attention” to each other.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for handling long texts.",
      "processing_time": 39.184221029281616,
      "citing_paper_id": "249579113",
      "cited_paper_id": 201307832
    },
    {
      "context_text": "To this end, a great number of previous works [9, 19, 25, 33, 37] focus on sentence-level event extraction (SEE) ,which aims to detect events and extract arguments from one sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to sentence-level event extraction. No verifiable resources are identified.",
      "processing_time": 42.131349086761475,
      "citing_paper_id": "249579113",
      "cited_paper_id": 202770954
    },
    {
      "context_text": "MGR [8] proposed a tagging-based model to dynamically incorporate paragraph-and sentence-level representations based on contextualized embeddings produced by the pre-trained language model BERT [6].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method and a pre-trained model (BERT).",
      "processing_time": 40.21104145050049,
      "citing_paper_id": "249579113",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Following prior work [8], we adopt head noun phrase match and exact match accuracy to compare the extractions against gold role fillers for evaluation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and methods.",
      "processing_time": 38.98713135719299,
      "citing_paper_id": "249579113",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Du and Cardie [9], Li et al. [18], and Liu et al. [22] introduce an MRC paradigm for EE in an end-to-end manner.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach (MRC paradigm for EE).",
      "processing_time": 41.051918268203735,
      "citing_paper_id": "249579113",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "In recent years, as neural networks proved the efectiveness for NLP, many approaches [2, 3, 5, 19, 25, 28, 37, 37] have been proposed to improve performance on this task by employing deep learning models, such as recurrent neural networks (RNNs) and convolutional neural networks (CNN).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches and models. There are no clear identifiers for datasets.",
      "processing_time": 41.67751955986023,
      "citing_paper_id": "249579113",
      "cited_paper_id": 239085620
    },
    {
      "context_text": "The first one is the task of document-level event role filler extraction, which is based on the classic MUC-4 dataset [24].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used for document-level event role filler extraction, focusing on identifying and extracting roles within events across multiple sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 dataset, which is a well-known resource for event extraction tasks. The dataset is explicitly used for document-level event role filler extraction.",
      "processing_time": 21.77695941925049,
      "citing_paper_id": "249579113",
      "cited_paper_id": null
    },
    {
      "context_text": "The majority of the previous event extraction works focus on sentence level (Li and Ji, 2014; Huang et al., 2020; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous works focusing on sentence-level event extraction.",
      "processing_time": 41.38566446304321,
      "citing_paper_id": "234358675",
      "cited_paper_id": 20744
    },
    {
      "context_text": "The majority of the previous event extraction works focus on sentence level (Li and Ji, 2014; Huang et al., 2020; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous works focusing on sentence-level event extraction.",
      "processing_time": 41.38566446304321,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "The majority of the previous event extraction works focus on sentence level (Li and Ji, 2014; Huang et al., 2020; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous works focusing on sentence-level event extraction.",
      "processing_time": 41.38566446304321,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Li et al. (2013) 3 Document-level Event Extraction",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not provide specific details about datasets used. It mentions document-level event extraction but does not name any datasets.",
      "processing_time": 40.19795322418213,
      "citing_paper_id": "234358675",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "While some works attempted to capture such dependencies with conditional random field or other structured prediction algorithms on hand-crafted features (Li et al., 2013; Lin et al., 2020), these approaches subject to scalablility issue and require certain level of human efforts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 41.393346548080444,
      "citing_paper_id": "234358675",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "While some works attempted to capture such dependencies with conditional random field or other structured prediction algorithms on hand-crafted features (Li et al., 2013; Lin et al., 2020), these approaches subject to scalablility issue and require certain level of human efforts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 41.393346548080444,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Initial attempts on event extraction relied on hand-crafted features and a pipeline architecture (Ahn, 2006; Gupta and Ji, 2009; Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and approaches in event extraction.",
      "processing_time": 40.36478137969971,
      "citing_paper_id": "234358675",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Initial attempts on event extraction relied on hand-crafted features and a pipeline architecture (Ahn, 2006; Gupta and Ji, 2009; Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and approaches in event extraction.",
      "processing_time": 40.36478137969971,
      "citing_paper_id": "234358675",
      "cited_paper_id": 8336242
    },
    {
      "context_text": "While some works attempted to capture such dependencies with conditional random ﬁeld or other structured prediction algorithms on hand-crafted features (Li et al., 2013; Lin et al., 2020",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 42.85447335243225,
      "citing_paper_id": "234358675",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "While some works attempted to capture such dependencies with conditional random ﬁeld or other structured prediction algorithms on hand-crafted features (Li et al., 2013; Lin et al., 2020",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 42.85447335243225,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "While some works attempted to capture such dependencies with conditional random ﬁeld or other structured prediction algorithms on hand-crafted features (Li et al., 2013; Lin et al., 2020",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 42.85447335243225,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "(Ahn, 2006; Gupta and Ji, 2009; Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other papers. The titles do not provide additional context to identify datasets.",
      "processing_time": 42.534427642822266,
      "citing_paper_id": "234358675",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Biases have been studied in many information extraction tasks, such as relation extraction (Gaut et al., 2020), named entity recognition (Mehrabi et al., 2020), and coreference resolution (Zhao et al., 2018a).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions studies on biases in various NLP tasks but does not specify any datasets used. The cited papers' titles suggest they discuss gender bias in coreference resolution and named entity recognition, but do not mention specific datasets.",
      "processing_time": 45.85003328323364,
      "citing_paper_id": "234358675",
      "cited_paper_id": 4952494
    },
    {
      "context_text": "Biases have been studied in many information extraction tasks, such as relation extraction (Gaut et al., 2020), named entity recognition (Mehrabi et al., 2020), and coreference resolution (Zhao et al., 2018a).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions studies on biases in various NLP tasks but does not specify any datasets used. The cited papers' titles suggest they discuss gender bias in coreference resolution and named entity recognition, but do not mention specific datasets.",
      "processing_time": 45.85003328323364,
      "citing_paper_id": "234358675",
      "cited_paper_id": 204851964
    },
    {
      "context_text": "A structured prediction model that learns cross-event interactions can potentially infer the correct event type for death given the previous S ENTENCE event is often carried out by authorities. the scope of sentence (Yang and Mitchell, 2016; Zhao et al., 2018b; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and models. The context is about structured prediction models and their ability to infer event types, which does not indicate the use of a specific dataset.",
      "processing_time": 45.39050555229187,
      "citing_paper_id": "234358675",
      "cited_paper_id": 4952494
    },
    {
      "context_text": "(Ju et al., 2018; Qin et al., 2018; Stanovsky et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other papers. There is no information about the usage of datasets or their characteristics.",
      "processing_time": 42.070348262786865,
      "citing_paper_id": "234358675",
      "cited_paper_id": 44161048
    },
    {
      "context_text": "Later studies gained signiﬁcant improvement from neural approaches, especially large pre-trained language models (Wad-den et al., 2019; Nguyen et al., 2016; Liu et al., 2018; Lin et al., 2020; Balali et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural approaches and pre-trained language models. No verifiable resources are identified.",
      "processing_time": 43.10703253746033,
      "citing_paper_id": "234358675",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Later studies gained signiﬁcant improvement from neural approaches, especially large pre-trained language models (Wad-den et al., 2019; Nguyen et al., 2016; Liu et al., 2018; Lin et al., 2020; Balali et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural approaches and pre-trained language models. No verifiable resources are identified.",
      "processing_time": 43.10703253746033,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Later studies gained signiﬁcant improvement from neural approaches, especially large pre-trained language models (Wad-den et al., 2019; Nguyen et al., 2016; Liu et al., 2018; Lin et al., 2020; Balali et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural approaches and pre-trained language models. No verifiable resources are identified.",
      "processing_time": 43.10703253746033,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Structured Prediction on Event Extraction Existing event extraction systems integrating structured prediction typically uses conditional random fields (CRFs) to capture dependencies between predicted events (Xu et al., 2019; Wang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the use of CRFs in event extraction systems.",
      "processing_time": 43.10331678390503,
      "citing_paper_id": "234358675",
      "cited_paper_id": 57193015
    },
    {
      "context_text": "Existing event extraction systems integrating structured prediction typically uses conditional random ﬁelds (CRFs) to capture dependencies between predicted events (Xu et al., 2019; Wang et al., 2018).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (CRFs) used in event extraction systems.",
      "processing_time": 41.001396894454956,
      "citing_paper_id": "234358675",
      "cited_paper_id": 57193015
    },
    {
      "context_text": "Zheng et al. (2019) transforms tabular event data into entity-based directed acyclic graphs to tackle the argument scattering challenge.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for transforming tabular event data. The context is focused on the method rather than a specific dataset.",
      "processing_time": 42.82719445228577,
      "citing_paper_id": "234358675",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Evaluation metrics used by previous sentence-level event extraction studies (Wadden et al., 2019; Zheng et al., 2019; Lin et al., 2020) are not suitable for our task as event coreference and entity coreference are not considered.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only that previous evaluation metrics are not suitable for the current task. No dataset names are provided.",
      "processing_time": 43.09376645088196,
      "citing_paper_id": "234358675",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Evaluation metrics used by previous sentence-level event extraction studies (Wadden et al., 2019; Zheng et al., 2019; Lin et al., 2020) are not suitable for our task as event coreference and entity coreference are not considered.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only that previous evaluation metrics are not suitable for the current task. No dataset names are provided.",
      "processing_time": 43.09376645088196,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Evaluation metrics used by previous sentence-level event extraction studies (Wadden et al., 2019; Zheng et al., 2019; Lin et al., 2020) are not suitable for our task as event coreference and entity coreference are not considered.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only that previous evaluation metrics are not suitable for the current task. No dataset names are provided.",
      "processing_time": 43.09376645088196,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Later studies gained significant improvement from neural approaches, especially large pre-trained language models (Wadden et al., 2019; Nguyen et al., 2016; Liu et al., 2018; Lin et al., 2020; Balali et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that discuss neural approaches and pre-trained language models.",
      "processing_time": 42.049530029296875,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "The trigger classiﬁcation F 1 metric adopted by previous works (Wadden et al., 2019; Lin et al., 2020) is used as the oracle value function v ∗ ( y trig , y trig ∗ ) .",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a metric (F1) used in previous works. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 44.52858352661133,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "The trigger classiﬁcation F 1 metric adopted by previous works (Wadden et al., 2019; Lin et al., 2020) is used as the oracle value function v ∗ ( y trig , y trig ∗ ) .",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a metric (F1) used in previous works. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 44.52858352661133,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Evaluation metrics used by previous sentencelevel event extraction studies (Wadden et al., 2019; Zheng et al., 2019; Lin et al., 2020) are not suitable for our task as event coreference and entity coreference are not considered.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics from previous studies. The context does not provide information about datasets used.",
      "processing_time": 42.49710416793823,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Experiments are conducted at the document level instead of sentence level as previous works (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a methodological approach. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 43.52091336250305,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Experiments are conducted at the document level instead of sentence level as previous works (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a methodological approach. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 43.52091336250305,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "…compare D EE D with three baselines: (1) B ASE , the base model described in Section 4.1; (2) BC RF extends B ASE by adding a CRF layer on top of the trigger classiﬁer; (3) OneIE + is a pipeline composed of the joint model presented in Lin et al. (2020) and coreference modules adapted from B ASE .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 43.5167236328125,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "…compare D EE D with three baselines: (1) B ASE , the base model described in Section 4.1; (2) BC RF extends B ASE by adding a CRF layer on top of the trigger classiﬁer; (3) OneIE + is a pipeline composed of the joint model presented in Lin et al. (2020) and coreference modules adapted from B ASE .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 43.5167236328125,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "To understand the capabilities of each module, we show an evaluation breakdown on each component following previous works (Wadden et al., 2019; Lin et al., 2020) in Table 2.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluations and previous works. No clear, verifiable datasets are identified.",
      "processing_time": 42.48620796203613,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "To understand the capabilities of each module, we show an evaluation breakdown on each component following previous works (Wadden et al., 2019; Lin et al., 2020) in Table 2.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluations and previous works. No clear, verifiable datasets are identified.",
      "processing_time": 42.48620796203613,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Lin et al. (2020) is the state-of-the-art sentence-level event extraction model that utilizes beam search and CRF with global features to model cross sub-task dependencies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its methodology. The context is about a sentence-level event extraction model, which is not a dataset.",
      "processing_time": 44.33583331108093,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Lin et al. (2020) is the state-of-the-art sentence-level event extraction model that utilizes beam search and CRF with global features to model cross sub-task dependencies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its methodology. The context is about a sentence-level event extraction model, which is not a dataset.",
      "processing_time": 44.33583331108093,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "This task is similar to the sentence-level event extraction task addressed by previous studies (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies. No verifiable resources are identified.",
      "processing_time": 42.035189628601074,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "This task is similar to the sentence-level event extraction task addressed by previous studies (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies. No verifiable resources are identified.",
      "processing_time": 42.035189628601074,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Arg-I and Arg-C are much lower than the reported scores by previous studies (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies' reported scores. No verifiable resources are identified.",
      "processing_time": 42.80117845535278,
      "citing_paper_id": "234358675",
      "cited_paper_id": 214673189
    },
    {
      "context_text": "Arg-I and Arg-C are much lower than the reported scores by previous studies (Wadden et al., 2019; Lin et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies' reported scores. No verifiable resources are identified.",
      "processing_time": 42.80117845535278,
      "citing_paper_id": "234358675",
      "cited_paper_id": 220048375
    },
    {
      "context_text": "Li et al. (2020a) performs event mention extraction and the two coreference tasks independently using a pipeline approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No dataset names are present in the citation context.",
      "processing_time": 42.462491512298584,
      "citing_paper_id": "234358675",
      "cited_paper_id": 218551030
    },
    {
      "context_text": "Li et al. (2020a) performs event mention extraction and the two coreference tasks independently using a pipeline approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No dataset names are present in the citation context.",
      "processing_time": 42.462491512298584,
      "citing_paper_id": "234358675",
      "cited_paper_id": null
    },
    {
      "context_text": "Du and Cardie (2020) employed a mutli-granularity reader to aggregate representations from different levels of granularity.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (multi-granularity reader).",
      "processing_time": 41.316667795181274,
      "citing_paper_id": "234358675",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "Du and Cardie (2020) evaluates entity coreference using bipartite matching.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating entity coreference.",
      "processing_time": 39.70140218734741,
      "citing_paper_id": "234358675",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "More recently, Du and Cardie (2020) and Du et al. (2020) treat document-level event extraction as a template-ﬁlling task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to document-level event extraction.",
      "processing_time": 41.56804633140564,
      "citing_paper_id": "234358675",
      "cited_paper_id": 221246218
    },
    {
      "context_text": "MUC-4 [18] proposes template-filling task that aims to extract event role fillers from the document.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used to propose a template-filling task for extracting event role fillers from documents, focusing on the methodology and evaluation of information extraction systems."
      },
      "confidence_score": 1.0,
      "reasoning": "MUC-4 is identified as a specific dataset used for template-filling tasks in event role extraction.",
      "processing_time": 48.57926964759827,
      "citing_paper_id": "257366694",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "Attention mechanism [1] is used to choose the next role with the highest probability.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method (attention mechanism).",
      "processing_time": 40.10407733917236,
      "citing_paper_id": "257366694",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "Schema induction means that researchers use unsupervised method [8, 13] to induce event schema via very large corpus and extract corresponding events.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a 'very large corpus' without naming it.",
      "processing_time": 14.166196584701538,
      "citing_paper_id": "257366694",
      "cited_paper_id": 14610045
    },
    {
      "context_text": "[16, 17] use bidirectional RNN to simultaneously extract trigger words and arguments of events to avoid the error propagation problem in the pipeline method.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction using bidirectional RNNs.",
      "processing_time": 41.756821155548096,
      "citing_paper_id": "257366694",
      "cited_paper_id": 63777164
    },
    {
      "context_text": "The ACE conference greatly facilitates the progress of event extraction at the sentence level [2, 5, 9, 14, 16, 20, 24].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the ACE conference, which is not a dataset but a conference that facilitates event extraction research. No specific dataset is mentioned.",
      "processing_time": 43.470134973526,
      "citing_paper_id": "257366694",
      "cited_paper_id": 63777164
    },
    {
      "context_text": "Recently, [6, 12, 25] follow this direction to extract event role fillers and public corresponding RAMS and WIKIEVENTS datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WIKIEVENTS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for extracting event role fillers at the document level, focusing on generative approaches to improve entity extraction accuracy.",
        "WIKIEVENTS": "Used for extracting event role fillers at the document level, focusing on conditional generation methods to enhance argument extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WIKIEVENTS, which are used for document-level event role filler extraction. These datasets are clearly identified and relevant to the research topic.",
      "processing_time": 56.87434792518616,
      "citing_paper_id": "257366694",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "Recently, [6, 12, 25] follow this direction to extract event role fillers and public corresponding RAMS and WIKIEVENTS datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WIKIEVENTS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for extracting event role fillers at the document level, focusing on generative approaches to improve entity extraction accuracy.",
        "WIKIEVENTS": "Used for extracting event role fillers at the document level, focusing on conditional generation methods to enhance argument extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WIKIEVENTS, which are used for document-level event role filler extraction. These datasets are clearly identified and relevant to the research topic.",
      "processing_time": 56.87434792518616,
      "citing_paper_id": "257366694",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "But our framework still gets the highest result on all event types and improves the overall micro F1-score from 71.7% to 73.6% in the multi-event scenario compared to GIT [21].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names. It only compares performance metrics against another method (GIT).",
      "processing_time": 42.22236347198486,
      "citing_paper_id": "257366694",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "Recent works [21, 27] decompose it into multiple steps.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that recent works have decomposed a process into multiple steps. There is no indication of dataset usage.",
      "processing_time": 44.08664917945862,
      "citing_paper_id": "257366694",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "6% in the multi-event scenario compared to GIT [21].",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison in performance between methods.",
      "processing_time": 40.900036096572876,
      "citing_paper_id": "257366694",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "[21] follows the tree expanding and further captures the contextual information and models the relations between events and arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction.",
      "processing_time": 41.273908376693726,
      "citing_paper_id": "257366694",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "• GIT [21]: GIT based on Doc2EDAG, they model the relationship between events and further modeling the relationship between entities and sentences in serial prediction paradigm.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Doc2EDAG) and a model (GIT).",
      "processing_time": 43.28154969215393,
      "citing_paper_id": "257366694",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "[23] first proposes a parallel prediction paradigm for DEE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach for document-level event extraction.",
      "processing_time": 41.976059675216675,
      "citing_paper_id": "257366694",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "The paragraph representation layer utilizes pre-trained word vectors using the skip-gram [10] model in word2vec to map a low-latitude sparse word vector to a high-dimensional dense vector.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of pre-trained word vectors from word2vec, but does not refer to a specific dataset. The citation is about a method (skip-gram model) rather than a dataset.",
      "processing_time": 45.735454082489014,
      "citing_paper_id": "258216783",
      "cited_paper_id": 5959482
    },
    {
      "context_text": "…of this paper’s model for event extraction, this paper’s model is compared with four benchmark models for event extraction, which are: a) JRNN [1], which uses a bidirectional recurrent neural network for joint extraction, and the joint extraction model effectively avoids the error propagation…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing the performance of different models for event extraction.",
      "processing_time": 43.860424280166626,
      "citing_paper_id": "258216783",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "For example, JRNN (joint event extraction via recurrent neural networks) [1], uses bidirectional recurrent neural networks to jointly extract event types, event theoretical elements.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (JRNN) for joint event extraction using bidirectional recurrent neural networks.",
      "processing_time": 43.437420129776,
      "citing_paper_id": "258216783",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "The experimental dataset in this paper is the Chinese financial dataset from the Interdisciplinary Information Science Research at Tsinghua University (https://github.com/dolphin-zs/Doc2EDAG) [12].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Chinese financial dataset from the Interdisciplinary Information Science Research at Tsinghua University"
      ],
      "dataset_descriptions": {
        "Chinese financial dataset from the Interdisciplinary Information Science Research at Tsinghua University": "Used to train and evaluate an end-to-end document-level framework for Chinese financial event extraction, focusing on the performance of the model in identifying and classifying events in financial documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset used for Chinese financial event extraction, which is relevant to the document-level event extraction topic.",
      "processing_time": 53.93240261077881,
      "citing_paper_id": "258216783",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "A joint extraction model based on relation-aware converters [5] uses a relation-aware converter-based encoder to capture contextual information in multiple sentences and then combines the results of event element extraction for event type classification.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction.",
      "processing_time": 41.25101590156555,
      "citing_paper_id": "258216783",
      "cited_paper_id": 233613419
    },
    {
      "context_text": "…network for joint extraction, and the joint extraction model effectively avoids the error propagation problem in the pipeline model. b) PTPCG [13], a document-level event extraction model that is compatible with document-level event extraction with and without triggers through pseudo-trigger…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing different models for document-level event extraction.",
      "processing_time": 34.14599299430847,
      "citing_paper_id": "258216783",
      "cited_paper_id": 245123950
    },
    {
      "context_text": "…the central sentence of the event based on a heuristic strategy, which solves the problem of ar-gument dispersion to some extent. d) HNN-EE [15], a hybrid neural network event joint extraction model, focuses on the dependencies of entities and events in events, using traditional LSTM to…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (HNN-EE) and a technique (LSTM).",
      "processing_time": 43.67204403877258,
      "citing_paper_id": "258216783",
      "cited_paper_id": null
    },
    {
      "context_text": "Transformer's main module is the attention module[6], and its core formula is: network.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to the attention mechanism in transformers. The cited paper title is about BERT, which is a model, not a dataset.",
      "processing_time": 45.42623209953308,
      "citing_paper_id": "247858415",
      "cited_paper_id": 226096901
    },
    {
      "context_text": "\"[7] In contrast to BERT, it employs three masking strategies: word mask, entity mask, and phrase mask, all of which are capable of learning entity attributes and relationships implicitly.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model training strategies. No verifiable resources are identified.",
      "processing_time": 42.38872504234314,
      "citing_paper_id": "247858415",
      "cited_paper_id": null
    },
    {
      "context_text": "Initially, datasets focused on extracting arguments within the same sentence than the event (Palmer et al., 2005; Walker et al., 2006).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general trend in datasets. No clear, verifiable resource names are provided.",
      "processing_time": 42.71044969558716,
      "citing_paper_id": "269004443",
      "cited_paper_id": 2486369
    },
    {
      "context_text": "Initially, datasets focused on extracting arguments within the same sentence than the event (Palmer et al., 2005; Walker et al., 2006).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general trend in datasets. No clear, verifiable resource names are provided.",
      "processing_time": 42.71044969558716,
      "citing_paper_id": "269004443",
      "cited_paper_id": null
    },
    {
      "context_text": "Most event-argument annotation efforts satisfy this requirement, including PropBank (Palmer et al., 2005), NomBank (Meyers et al., 2004), FrameNet (Baker et al., 1998), RAMS, ACE (Doddington et al., 2004), and WikiEvents (Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event extraction, providing annotated data for training and evaluation of event-argument structures.",
        "WikiEvents": "Used for document-level event extraction, offering a large-scale annotated dataset derived from Wikipedia articles for event and argument identification."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions several resources, but they are primarily annotation efforts or frameworks rather than datasets. However, 'RAMS' and 'WikiEvents' are likely datasets used for event extraction.",
      "processing_time": 56.22565698623657,
      "citing_paper_id": "269004443",
      "cited_paper_id": 2486369
    },
    {
      "context_text": "Most event-argument annotation efforts satisfy this requirement, including PropBank (Palmer et al., 2005), NomBank (Meyers et al., 2004), FrameNet (Baker et al., 1998), RAMS, ACE (Doddington et al., 2004), and WikiEvents (Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event extraction, providing annotated data for training and evaluation of event-argument structures.",
        "WikiEvents": "Used for document-level event extraction, offering a large-scale annotated dataset derived from Wikipedia articles for event and argument identification."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions several resources, but they are primarily annotation efforts or frameworks rather than datasets. However, 'RAMS' and 'WikiEvents' are likely datasets used for event extraction.",
      "processing_time": 56.22565698623657,
      "citing_paper_id": "269004443",
      "cited_paper_id": 2505531
    },
    {
      "context_text": "Most event-argument annotation efforts satisfy this requirement, including PropBank (Palmer et al., 2005), NomBank (Meyers et al., 2004), FrameNet (Baker et al., 1998), RAMS, ACE (Doddington et al., 2004), and WikiEvents (Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event extraction, providing annotated data for training and evaluation of event-argument structures.",
        "WikiEvents": "Used for document-level event extraction, offering a large-scale annotated dataset derived from Wikipedia articles for event and argument identification."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions several resources, but they are primarily annotation efforts or frameworks rather than datasets. However, 'RAMS' and 'WikiEvents' are likely datasets used for event extraction.",
      "processing_time": 56.22565698623657,
      "citing_paper_id": "269004443",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "Early models were based on handcrafted features (Li et al., 2013; Liao and Grishman, 2010; Hong et al., 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous work on handcrafted features for event extraction.",
      "processing_time": 42.96580696105957,
      "citing_paper_id": "269004443",
      "cited_paper_id": 2867611
    },
    {
      "context_text": "Like most NLP tasks, models for event argument extraction experienced a transformation building on word embeddings, RNNs, and CNNs (Chen et al., 2015; Nguyen et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general methods and models. No verifiable resources are identified.",
      "processing_time": 42.700642585754395,
      "citing_paper_id": "269004443",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Event argument extraction (Ahn, 2006) has a long history in the field (Grishman and Sundheim, 1996; Doddington et al., 2004).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to historical works in the field of event argument extraction.",
      "processing_time": 43.23131847381592,
      "citing_paper_id": "269004443",
      "cited_paper_id": 6540287
    },
    {
      "context_text": "Event argument extraction (Ahn, 2006) has a long history in the field (Grishman and Sundheim, 1996; Doddington et al., 2004).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to historical works in the field of event argument extraction.",
      "processing_time": 43.23131847381592,
      "citing_paper_id": "269004443",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "Event argument extraction (Ahn, 2006) has a long history in the field (Grishman and Sundheim, 1996; Doddington et al., 2004).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to historical works in the field of event argument extraction.",
      "processing_time": 43.23131847381592,
      "citing_paper_id": "269004443",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "Event argument extraction (Doddington et al., 2004; Aguilar et al., 2014) is about identifying entities participating in events and specifying their role (e.g., the giver , recipient , and thing given in a giving event).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Automatic Content Extraction (ACE)' which is a program, not a dataset. No specific dataset is mentioned or used in the context.",
      "processing_time": 43.816784381866455,
      "citing_paper_id": "269004443",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "Inter-sentential arguments are more challenging and have received less attention (Gerber and Chai, 2010; Ruppenhofer et al., 2010).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to prior work discussing inter-sentential arguments.",
      "processing_time": 42.6906476020813,
      "citing_paper_id": "269004443",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "There are also corpora focused on inter-sentential arguments (Gerber and Chai, 2010; Rup-penhofer et al., 2010; Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'corpora' but does not specify any particular dataset names. The context is too generic and lacks specific identifiers.",
      "processing_time": 44.211947441101074,
      "citing_paper_id": "269004443",
      "cited_paper_id": 13804679
    },
    {
      "context_text": "We use Pytorch (Paszke et al., 2019) and HuggingFace transformers (Wolf et al., 2020).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions Pytorch and HuggingFace transformers, which are software toolkits, not datasets. No datasets are explicitly mentioned or used.",
      "processing_time": 44.213356733322144,
      "citing_paper_id": "269004443",
      "cited_paper_id": 202786778
    },
    {
      "context_text": "Li et al. (2021) and Ma et al. (2022); Du et al. (2021) leverage generative language models (Raffel et al., 2020; Lewis et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only generative language models. No dataset names are present in the context.",
      "processing_time": 43.806968212127686,
      "citing_paper_id": "269004443",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "For contextualized questions, we fine-tune T5 (Raffel et al., 2020) with either SQuAD or the weakly supervised data obtained by prompting GPT-4 (weak supervision from LLMs).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SQuAD"
      ],
      "dataset_descriptions": {
        "SQuAD": "Used to fine-tune T5 for contextualized question answering, focusing on improving model performance through transfer learning."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions SQuAD and weakly supervised data from GPT-4, but only SQuAD is a verifiable dataset. GPT-4 is a model, not a dataset.",
      "processing_time": 50.750486612319946,
      "citing_paper_id": "269004443",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "Some efforts assume event triggers and argument spans are part of the input and present classifiers to identify the argument role (Ebner et al., 2020; Chen et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches for event argument classification.",
      "processing_time": 42.34037899971008,
      "citing_paper_id": "269004443",
      "cited_paper_id": 226283556
    },
    {
      "context_text": "Transforming natural language into structured event knowledge benefits many down-stream tasks such as machine reading comprehension (Han et al., 2021), news summarization (Li et al., 2016), coreference resolution (Huang et al., 2019), and dialogue systems (Su et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of transforming natural language into structured event knowledge.",
      "processing_time": 13.052703380584717,
      "citing_paper_id": "269004443",
      "cited_paper_id": 243865619
    },
    {
      "context_text": "Q1 is generated following a role-specific template, Q2 and Q3 are generated prompting techniques (Du and Ji, 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only techniques and methods for generating questions.",
      "processing_time": 42.1285126209259,
      "citing_paper_id": "269004443",
      "cited_paper_id": 253510351
    },
    {
      "context_text": "Transfer learning has also been explored, including role overlapping knowledge (Zhang et al., 2023), semantic roles (Zhang et al., 2022), abstract meaning representations (Xu et al., 2022), and frame-aware knowledge distillation (Wei et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 44.51942777633667,
      "citing_paper_id": "269004443",
      "cited_paper_id": 256461151
    },
    {
      "context_text": "Framing the problem in terms of questions and answers is popular (Du and Cardie, 2020; Liu et al., 2020; Li et al., 2020; Uddin et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to framing the problem in terms of questions and answers.",
      "processing_time": 43.355730056762695,
      "citing_paper_id": "269004443",
      "cited_paper_id": 269362270
    },
    {
      "context_text": "Both (Lai et al., 2020) and (Deng et al., 2020) extend upon the prototype network model (Snell et al., 2017) for classiﬁcation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only extensions to a model. No dataset names are present in the citation context.",
      "processing_time": 44.18565011024475,
      "citing_paper_id": "233219850",
      "cited_paper_id": 309759
    },
    {
      "context_text": "Both (Lai et al., 2020) and (Deng et al., 2020) extend upon the prototype network model (Snell et al., 2017) for classiﬁcation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only extensions to a model. No dataset names are present in the citation context.",
      "processing_time": 44.18565011024475,
      "citing_paper_id": "233219850",
      "cited_paper_id": 204915992
    },
    {
      "context_text": "In addition to BERT-QA, we also replace our T AP K EY trigger extraction model with a Prototype Network(Snell et al., 2017) 14 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is about replacing a trigger extraction model with a Prototype Network, which is a method.",
      "processing_time": 45.191946029663086,
      "citing_paper_id": "233219850",
      "cited_paper_id": 309759
    },
    {
      "context_text": "In addition to BERT-QA, we also replace our T AP K EY trigger extraction model with a Prototype Network(Snell et al., 2017) 14 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is about replacing a trigger extraction model with a Prototype Network, which is a method.",
      "processing_time": 45.191946029663086,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "For Coref F1, the model is given full credit if the extracted argument is coreferential with the gold-standard argument as used in (Ji and Grishman, 2008).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating coreference resolution. No dataset names are present in the citation context.",
      "processing_time": 44.50741362571716,
      "citing_paper_id": "233219850",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Early work on event extraction originally posed the task as document level role ﬁlling (Grishman and Sundheim, 1996) on a set of narrow scenarios Prosecutors say he drove the truck to Geary Lake in Kansas, that 4,000 pounds of ammonium nitrate laced with nitromethane were loaded into the truck…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It describes early work on event extraction and provides an example scenario, but no dataset names are given.",
      "processing_time": 45.35791349411011,
      "citing_paper_id": "233219850",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "An information seeking session (Mai, 2016) can be divided into 6 stages: task initiation, topic selection, pre-focus exploration, focus information, information collection and search closure (Kuhlthau, 1991).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only stages of an information seeking session. No verifiable resources are identified.",
      "processing_time": 44.169068813323975,
      "citing_paper_id": "233219850",
      "cited_paper_id": 14416802
    },
    {
      "context_text": "Since the baseline BERT-CRF model (Shi and Lin, 2019) cannot handle new labels directly, we exclude it from comparison.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (BERT-CRF) which is excluded from comparison. No datasets are referenced.",
      "processing_time": 44.87810492515564,
      "citing_paper_id": "233219850",
      "cited_paper_id": 131773936
    },
    {
      "context_text": ", 2020) and (Deng et al., 2020) extend upon the prototype network model (Snell et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (prototype network).",
      "processing_time": 42.90298891067505,
      "citing_paper_id": "233219850",
      "cited_paper_id": 204915992
    },
    {
      "context_text": "Our base model is an encoder-decoder language model (BART (Lewis et al., 2020), T5 (Raffel et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models (BART, T5) but does not refer to any specific datasets. The context is about using these models as the base for their research.",
      "processing_time": 45.78162384033203,
      "citing_paper_id": "233219850",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Compared to recent efforts (Du and Cardie, 2020; Feng et al., 2020; Chen et al., 2020) that retarget question answering (QA) models for event extraction, our generationbased model can easily handle the case of missing arguments and multiple arguments in the same role without the need of tuning thresholds and can extract all arguments in a single pass.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only compares methods and models. No verifiable resources are identified.",
      "processing_time": 43.95887064933777,
      "citing_paper_id": "233219850",
      "cited_paper_id": 208547716
    },
    {
      "context_text": "Compared to recent efforts (Du and Cardie, 2020; Feng et al., 2020; Chen et al., 2020) that retarget question answering (QA) models for event extraction, our generationbased model can easily handle the case of missing arguments and multiple arguments in the same role without the need of tuning thresholds and can extract all arguments in a single pass.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only compares methods and models. No verifiable resources are identified.",
      "processing_time": 43.95887064933777,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Compared to recent efforts (Du and Cardie, 2020; Feng et al., 2020; Chen et al., 2020) that retarget question answering (QA) models for event extraction, our generationbased model can easily handle the case of missing arguments and multiple arguments in the same role without the need of tuning thresholds and can extract all arguments in a single pass.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only compares methods and models. No verifiable resources are identified.",
      "processing_time": 43.95887064933777,
      "citing_paper_id": "233219850",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "Compared to recent efforts (Du and Cardie, 2020; Feng et al., 2020; Chen et al., 2020) that retarget question answering (QA) models for event extraction, our generation-based model can easily handle the case of missing arguments and multiple arguments in the same role without the need of tuning…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works and their methodologies. The context focuses on comparing approaches to event extraction.",
      "processing_time": 44.86553740501404,
      "citing_paper_id": "233219850",
      "cited_paper_id": 208547716
    },
    {
      "context_text": "Compared to recent efforts (Du and Cardie, 2020; Feng et al., 2020; Chen et al., 2020) that retarget question answering (QA) models for event extraction, our generation-based model can easily handle the case of missing arguments and multiple arguments in the same role without the need of tuning…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works and their methodologies. The context focuses on comparing approaches to event extraction.",
      "processing_time": 44.86553740501404,
      "citing_paper_id": "233219850",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "Recent work on zero-shot event extraction has posed the problem as question answering (Chen et al., 2020; Du and Cardie, 2020; Feng et al., 2020) with different ways of designing the questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 45.009461879730225,
      "citing_paper_id": "233219850",
      "cited_paper_id": 208547716
    },
    {
      "context_text": "Recent work on zero-shot event extraction has posed the problem as question answering (Chen et al., 2020; Du and Cardie, 2020; Feng et al., 2020) with different ways of designing the questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 45.009461879730225,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Recent work on zero-shot event extraction has posed the problem as question answering (Chen et al., 2020; Du and Cardie, 2020; Feng et al., 2020) with different ways of designing the questions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 45.009461879730225,
      "citing_paper_id": "233219850",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "Inspired by (Shwartz et al., 2020), we use clariﬁcation statements to add back constraints without breaking the end-to-end property of the model.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context is about using clarification statements in a model, which is not a dataset.",
      "processing_time": 45.00667929649353,
      "citing_paper_id": "233219850",
      "cited_paper_id": 215745286
    },
    {
      "context_text": "ularly used BERT-CRF baseline (Shi and Lin, 2019) that performs trigger extraction on sentencelevel and BERT-QA (Du and Cardie, 2020) ran on sentence-level and document-level.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of BERT-CRF and BERT-QA for trigger extraction and question answering.",
      "processing_time": 17.24827265739441,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "The performance of BERT-QA is greatly limited by the trigger identiﬁcation step.",
      "catation_intent": "limitation",
      "resource_type": "limitation",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a limitation of BERT-QA in trigger identification.",
      "processing_time": 44.472628593444824,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "edu/rams (12)Note that our preprocessing procedure is slightly different from (Du and Cardie, 2020) as we kept pronouns as valid event triggers and arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a difference in preprocessing procedures.",
      "processing_time": 43.31413674354553,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Notably, one template per event type is given in the ontology, and does not require further human curation as opposed to the question designing process in question answering (QA) models (Du and Cardie, 2020; Feng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison between event extraction templates and question answering models. No verifiable resources are identified.",
      "processing_time": 45.480531215667725,
      "citing_paper_id": "233219850",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Notably, one template per event type is given in the ontology, and does not require further human curation as opposed to the question designing process in question answering (QA) models (Du and Cardie, 2020; Feng et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison between event extraction templates and question answering models. No verifiable resources are identified.",
      "processing_time": 45.480531215667725,
      "citing_paper_id": "233219850",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "There have been a few datasets published speciﬁcally for implicit semantic role labeling, such as the SemEval 2010 Task 10 (Ruppenhofer et al., 2010), the Beyond NomBank dataset (Gerber and Chai, 2010) and ON5V (Moor et al., 2013).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SemEval 2010 Task 10",
        "Beyond NomBank",
        "ON5V"
      ],
      "dataset_descriptions": {
        "SemEval 2010 Task 10": "Used for implicit semantic role labeling, focusing on identifying roles in sentences where the predicate is not explicitly marked.",
        "Beyond NomBank": "Used for extending semantic role labeling beyond traditional verb-based predicates, including nominal and adjectival predicates.",
        "ON5V": "Used for semantic role labeling of nominalizations, focusing on verbs derived from nouns and their argument structures."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets for implicit semantic role labeling, which are relevant to document-level event extraction.",
      "processing_time": 62.68047022819519,
      "citing_paper_id": "233219850",
      "cited_paper_id": 261226458
    },
    {
      "context_text": "There have been a few datasets published specifically for implicit semantic role labeling, such as the SemEval 2010 Task 10 (Ruppenhofer et al., 2010), the Beyond NomBank dataset (Gerber and Chai, 2010) and ON5V (Moor et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SemEval 2010 Task 10",
        "Beyond NomBank",
        "ON5V"
      ],
      "dataset_descriptions": {
        "SemEval 2010 Task 10": "Used for implicit semantic role labeling, focusing on identifying roles in sentences where the predicate is not explicitly marked.",
        "Beyond NomBank": "Applied to extend semantic role labeling beyond traditional verb-based predicates, including nominal and adjectival predicates.",
        "ON5V": "Utilized for semantic role labeling of nominalizations, enhancing the understanding of implicit roles in complex sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets for implicit semantic role labeling, which are relevant to document-level event extraction.",
      "processing_time": 62.67144250869751,
      "citing_paper_id": "233219850",
      "cited_paper_id": 261226458
    },
    {
      "context_text": "Conversely, the co-occurrence-aware module significantly boosts performance on the WikiEvents and MLEE datasets, increasing the Arg-C metric by 1.7% and 2.8%, respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents",
        "MLEE"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to evaluate the performance of a co-occurrence-aware module in document-level event extraction, focusing on argument classification.",
        "MLEE": "Used to assess the effectiveness of a co-occurrence-aware module in document-level event extraction, specifically improving argument classification."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, WikiEvents and MLEE, which are used to evaluate the performance of a co-occurrence-aware module in event extraction.",
      "processing_time": 57.91702079772949,
      "citing_paper_id": "273962739",
      "cited_paper_id": 13981987
    },
    {
      "context_text": "Following TabEAE, we analyzed CsEAE’s ability to capture event semantic boundaries on the WikiEvents and MLEE datasets from two perspectives: inter-event semantics and intra-event semantics.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents",
        "MLEE"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to analyze inter-event and intra-event semantics, focusing on capturing event semantic boundaries in document-level event extraction.",
        "MLEE": "Used to analyze inter-event and intra-event semantics, focusing on capturing event semantic boundaries in document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets used for analyzing event semantic boundaries in the context of event extraction.",
      "processing_time": 54.58603620529175,
      "citing_paper_id": "273962739",
      "cited_paper_id": 13981987
    },
    {
      "context_text": "For instance, in the WikiEvents dataset, over 94% of arguments are in the same sentence as the trigger; in the Rams dataset, over 82%; and in the MLEE dataset, over 99%.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents",
        "Rams",
        "MLEE"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to analyze argument distribution relative to triggers, showing over 94% of arguments are in the same sentence as the trigger.",
        "Rams": "Used to analyze argument distribution relative to triggers, showing over 82% of arguments are in the same sentence as the trigger.",
        "MLEE": "Used to analyze argument distribution relative to triggers, showing over 99% of arguments are in the same sentence as the trigger."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets used for event extraction, providing statistics on argument distribution relative to triggers.",
      "processing_time": 62.45094084739685,
      "citing_paper_id": "273962739",
      "cited_paper_id": 13981987
    },
    {
      "context_text": "Datasets We used the three most commonly employed datasets for document-level event argument extraction (EAE): Rams (Ebner et al. 2020), WikiEvents (Li, Ji, and Han 2021), and MLEE (Pyysalo et al. 2012).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Rams",
        "WikiEvents",
        "MLEE"
      ],
      "dataset_descriptions": {
        "Rams": "Used for document-level event argument extraction, focusing on identifying and linking event arguments within documents.",
        "WikiEvents": "Used for document-level event argument extraction, focusing on identifying and linking event arguments within documents.",
        "MLEE": "Used for document-level event argument extraction, focusing on identifying and linking event arguments within documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets used for document-level event argument extraction, which are directly relevant to the research topic.",
      "processing_time": 59.05318737030029,
      "citing_paper_id": "273962739",
      "cited_paper_id": 13981987
    },
    {
      "context_text": "Table 3: Overall performance of LLMs. Doc represents training using the WikiEvents, Rams, and MLEE; News represents training using the ACE, Rams, and WikiEvents, ALL signifies that all five datasets were used for training.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents",
        "Rams",
        "MLEE",
        "ACE"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used for training LLMs in document-level event extraction, focusing on diverse event types and their arguments.",
        "Rams": "Used for training LLMs in document-level event extraction, providing a rich set of annotated events and roles.",
        "MLEE": "Used for training LLMs in document-level event extraction, specifically targeting molecular-level events in biological contexts.",
        "ACE": "Used for training LLMs in document-level event extraction, focusing on news articles and a variety of event types."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets used for training LLMs in the context of event extraction. These datasets are specific and relevant to the topic of document-level event extraction.",
      "processing_time": 67.02852630615234,
      "citing_paper_id": "273962739",
      "cited_paper_id": 13981987
    },
    {
      "context_text": "Similarly, on the MLEE dataset, CsEAE achieves improvements of 3.0% in Arg-I and 3.2% in Arg-C metrics.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MLEE"
      ],
      "dataset_descriptions": {
        "MLEE": "Used to evaluate the performance of the CsEAE model in argument identification (Arg-I) and argument classification (Arg-C) tasks, focusing on improvements in these metrics."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MLEE dataset, which is a specific dataset used for evaluating the performance of the CsEAE model. The dataset is relevant to the topic of document-level event extraction.",
      "processing_time": 54.83257055282593,
      "citing_paper_id": "273962739",
      "cited_paper_id": 13981987
    },
    {
      "context_text": "In this paper, we utilize prompts proposed in PAIE (Ma et al. 2022) for the Rams and WikiEvents datasets and those in TabEAE (He, Hu, and Tang 2023) for the MLEE dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Rams",
        "WikiEvents",
        "MLEE"
      ],
      "dataset_descriptions": {
        "Rams": "Used to evaluate prompt-based event extraction methods, focusing on document-level events in news articles.",
        "WikiEvents": "Used to evaluate prompt-based event extraction methods, focusing on document-level events in Wikipedia articles.",
        "MLEE": "Used to evaluate table-based event extraction methods, focusing on document-level events in molecular biology literature."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions specific datasets used for event extraction experiments. These datasets are clearly named and relevant to the research topic.",
      "processing_time": 59.34856581687927,
      "citing_paper_id": "273962739",
      "cited_paper_id": 13981987
    },
    {
      "context_text": "The notable improvement of the co-occurrences-aware module on the WikiEvents and MLEE datasets is attributed to the higher number of events in instances, where the auxiliary information provided by the co-occurrences-aware module leads to a greater performance boost in complex event scenarios.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents",
        "MLEE"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to evaluate the co-occurrences-aware module, focusing on complex event scenarios with a higher number of events per instance.",
        "MLEE": "Used to assess the performance of the co-occurrences-aware module, particularly in scenarios with multiple events, enhancing extraction accuracy."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, WikiEvents and MLEE, which are used to evaluate the performance of a co-occurrences-aware module in complex event scenarios.",
      "processing_time": 58.140779972076416,
      "citing_paper_id": "273962739",
      "cited_paper_id": 13981987
    },
    {
      "context_text": "In the Table 1, our model outperformed all baselines on the Rams and MLEE datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Rams",
        "MLEE"
      ],
      "dataset_descriptions": {
        "Rams": "Used to evaluate model performance in event extraction, focusing on multi-level biological events and comparing against baseline systems.",
        "MLEE": "Used to assess model effectiveness in extracting events across multiple levels of biological organization, benchmarking against existing methods."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions 'Rams' and 'MLEE' as datasets where the model performance is compared against baselines. These appear to be specific datasets used for evaluating event extraction systems.",
      "processing_time": 57.690834045410156,
      "citing_paper_id": "273962739",
      "cited_paper_id": 13981987
    },
    {
      "context_text": "We used BART (Lewis et al. 2020) as the backbone for CsEAE.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BART as a model, not a dataset. No datasets are explicitly mentioned or used according to the given citation span.",
      "processing_time": 45.98568630218506,
      "citing_paper_id": "273962739",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "BART-Gen (Li, Ji, and Han 2021) utilizes a prompt-based generative approach to generate event arguments end-to-end, and subsequently, PAIE (Ma et al. 2022) introduces more effective manually crafted prompts, using slot prompts to extract arguments by filling slots.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on describing the methodologies used in the cited papers.",
      "processing_time": 46.52807116508484,
      "citing_paper_id": "273962739",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "... Gottschalk, and Demidova 2020), dialogue systems (Zhang, Chen, and Bui 2020), and recommendation systems (Li et al. 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of application such as dialogue systems and recommendation systems.",
      "processing_time": 35.86308979988098,
      "citing_paper_id": "273962739",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "We used the methods provided by LLama-Factory 2 for model’s SFT, employing LoRA-based (Hu et al. 2021) fine-tuning with a rank r of 8 and a dropout rate of 0.1.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. No dataset names are present in the citation span.",
      "processing_time": 45.85322117805481,
      "citing_paper_id": "273962739",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "In all experiments in this paper, Arg-I and Arg-C is equivalent to Arg-I+ and Arg-C+. Baselines For SLMs, we categorized the baseline models into two groups: (1) Classification-based models: EEQA (Du and Cardie 2020b), TSAR (Xu et al. 2022), TagPrime-C and TagPrime-CR (Hsu et al. 2023a); (2) Generation-based models: Bart-Gen (Li, Ji, and Han 2021), X-Gear (Huang et al. 2022), AMPERE (Hsu et al. 2023b), PAIE (Ma et al. 2022), TabEAE (He, Hu, and Tang 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 46.68719959259033,
      "citing_paper_id": "273962739",
      "cited_paper_id": 258947053
    },
    {
      "context_text": "Co-occurrences Prefix After constructing the co-occurrences-aware matrix W C for the current event mention D , we condense W C into prefixes (Li and Liang 2021; Hsu et al. 2023b), which then participate in the model’s generation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 46.24168872833252,
      "citing_paper_id": "273962739",
      "cited_paper_id": 258947053
    },
    {
      "context_text": "…Classification-based models: EEQA (Du and Cardie 2020b), TSAR (Xu et al. 2022), TagPrime-C and TagPrime-CR (Hsu et al. 2023a); (2) Generation-based models: Bart-Gen (Li, Ji, and Han 2021), X-Gear (Huang et al. 2022), AMPERE (Hsu et al. 2023b), PAIE (Ma et al. 2022), TabEAE (He, Hu, and Tang 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models but does not refer to any specific datasets. The context is focused on describing different types of models used for event extraction.",
      "processing_time": 47.04497718811035,
      "citing_paper_id": "273962739",
      "cited_paper_id": 258947053
    },
    {
      "context_text": "Some studies incorporate abstract meaning representation into the extraction task (Xu et al. 2022; Yang et al. 2023; Hsu et al. 2023b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or models. The context is about incorporating abstract meaning representation into event extraction tasks.",
      "processing_time": 46.68153357505798,
      "citing_paper_id": "273962739",
      "cited_paper_id": 258947053
    },
    {
      "context_text": "Its best performance, an Arg-C score of 64.71, falls short compared to best results of SLMs (Huang et al. 2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of performance scores.",
      "processing_time": 45.081443548202515,
      "citing_paper_id": "273962739",
      "cited_paper_id": 265221405
    },
    {
      "context_text": "Additionally, to more comprehensively validate the effectiveness of CsEAE, we applied the data processing meth-ods used in TextEE (Huang et al. 2024) to WikiEvents and RAMS.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents",
        "RAMS"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to validate the effectiveness of CsEAE, focusing on document-level event extraction and the performance of data processing methods.",
        "RAMS": "Used to validate the effectiveness of CsEAE, focusing on document-level event extraction and the performance of data processing methods."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, WikiEvents and RAMS, which are used to validate the effectiveness of CsEAE. These datasets are relevant to document-level event extraction.",
      "processing_time": 59.809086561203,
      "citing_paper_id": "273962739",
      "cited_paper_id": 265221405
    },
    {
      "context_text": "Inspired by the use of large-scale high-quality data for continuous pretraining (Yang et al. 2024), we attempted multi-dataset fine-tuning to make the LLMs more familiar with event extraction tasks.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to 'large-scale high-quality data'. No specific dataset names are provided.",
      "processing_time": 47.27233076095581,
      "citing_paper_id": "273962739",
      "cited_paper_id": 267976050
    },
    {
      "context_text": "Through training data, the model can effectively leverage the latent knowledge accumulated during pre-training to understand and respond to extraction instructions (Yang et al. 2024).",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'training data' in a generic sense.",
      "processing_time": 46.866923332214355,
      "citing_paper_id": "273962739",
      "cited_paper_id": 267976050
    },
    {
      "context_text": "We conduct experiments on two commonly used document-level EAE datasets: RAMS [17] and WikiEvents [9].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event argument extraction experiments, focusing on identifying and linking arguments across multiple sentences.",
        "WikiEvents": "Used for document-level event argument extraction experiments, focusing on identifying and linking arguments across multiple sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for document-level event argument extraction experiments.",
      "processing_time": 55.835731744766235,
      "citing_paper_id": "268598877",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Typical efforts in document-level EAE can be roughly divided into classification-based models [1, 2, 3, 4, 5, 6], question answering (QA)-based models [7, 8], generation-based models [9, 10], and prompt-based models [11, 12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of models used in document-level event extraction. No verifiable resources are identified.",
      "processing_time": 47.26313233375549,
      "citing_paper_id": "268598877",
      "cited_paper_id": 234358675
    },
    {
      "context_text": "Typical efforts in document-level EAE can be roughly divided into classification-based models [1, 2, 3, 4, 5, 6], question answering (QA)-based models [7, 8], generation-based models [9, 10], and prompt-based models [11, 12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of models used in document-level event extraction. No verifiable resources are identified.",
      "processing_time": 47.26313233375549,
      "citing_paper_id": "268598877",
      "cited_paper_id": 243865143
    },
    {
      "context_text": "Typical efforts in document-level EAE can be roughly divided into classification-based models [1, 2, 3, 4, 5, 6], question answering (QA)-based models [7, 8], generation-based models [9, 10], and prompt-based models [11, 12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of models used in document-level event extraction. No verifiable resources are identified.",
      "processing_time": 47.26313233375549,
      "citing_paper_id": "268598877",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Typical efforts in document-level EAE can be roughly divided into classification-based models [1, 2, 3, 4, 5, 6], question answering (QA)-based models [7, 8], generation-based models [9, 10], and prompt-based models [11, 12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of models used in document-level event extraction. No verifiable resources are identified.",
      "processing_time": 47.26313233375549,
      "citing_paper_id": "268598877",
      "cited_paper_id": 266177132
    },
    {
      "context_text": "DocMRC [8] is another QA-based method, assisted by two data augmentation regimes: implicit knowledge transfer and explicit data augmentation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'data augmentation' but does not specify a dataset name. The cited paper title suggests a focus on data augmentation methods rather than a specific dataset.",
      "processing_time": 47.70864462852478,
      "citing_paper_id": "268598877",
      "cited_paper_id": 243865143
    },
    {
      "context_text": "Moreover, we use 𝐵𝐸𝑅𝑇 𝑏𝑎𝑠𝑒 [11] and 𝑅𝑜𝐵𝐸𝑅𝑇𝑎 𝑙𝑎𝑟𝑔𝑒 [12] as the pre-trained transformer-based encoder.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and RoBERTa as pre-trained models, which are not datasets. No specific datasets are mentioned.",
      "processing_time": 46.65744614601135,
      "citing_paper_id": "276399825",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We adopt the PLMs default dropout rate as 0.1, batch size to 2, and use AdamW optimizer[15] and a linearly decaying scheduler[16] with 3e-5 learning rate to train RRAG.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only training parameters and optimization methods.",
      "processing_time": 45.66821265220642,
      "citing_paper_id": "276399825",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "It plays a crucial role in extracting event structures for various downstream tasks, including machine reading comprehension[1], dialogue systems[2] and recommendation systems[3].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of event structure extraction.",
      "processing_time": 45.93247938156128,
      "citing_paper_id": "276399825",
      "cited_paper_id": 243865619
    },
    {
      "context_text": "Lin et al.[18] proposed a approach based on curriculum learning and prompt tuning to resolve the long-distance dependency and cross-sentence scatter issues between arguments and the trigger, and use a encoder-decoder model to resemble related knowledge to enhance model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event argument extraction.",
      "processing_time": 46.0803120136261,
      "citing_paper_id": "276399825",
      "cited_paper_id": 248496246
    },
    {
      "context_text": "Recently, some work[22] has attempted to explore to utilize large language models (LLMs) for EAE tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of large language models for event argument extraction tasks.",
      "processing_time": 13.019917011260986,
      "citing_paper_id": "276399825",
      "cited_paper_id": 265221038
    },
    {
      "context_text": "It provides inputs to downstream applications such as Summarization [1], Knowledge Base Population [2], and Recommendation [3].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications. No dataset names are present in the text.",
      "processing_time": 46.83839178085327,
      "citing_paper_id": "272586489",
      "cited_paper_id": 433312
    },
    {
      "context_text": "The Coref F1 evaluates the coreference between extracted arguments and golden arguments as used by Ji and Grishman [21].",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (Coref F1) which is not a dataset. The context is about evaluating coreference, not using a dataset.",
      "processing_time": 49.23866510391235,
      "citing_paper_id": "272586489",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "We set the dropout rate to 0.1, batch size to 8, and train our CasDEE using Adam [24] as optimizer with 3e-5 learning rate.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only training parameters and the Adam optimizer.",
      "processing_time": 46.18911147117615,
      "citing_paper_id": "272586489",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "Early research primarily focused on Sentence-level event argument extraction (S-EAE) [4]–[6], However, in real-world scenarios, many events and their arguments often span multiple sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general shift from sentence-level to document-level event extraction.",
      "processing_time": 47.23347020149231,
      "citing_paper_id": "272586489",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Early research primarily focused on Sentence-level event argument extraction (S-EAE) [4]–[6], However, in real-world scenarios, many events and their arguments often span multiple sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general shift from sentence-level to document-level event extraction.",
      "processing_time": 47.23347020149231,
      "citing_paper_id": "272586489",
      "cited_paper_id": 208547716
    },
    {
      "context_text": "Unlike the well-developed sentence-level event extraction [4]–[6], [30], [31], the D-EAE faces more challenges, as it involves complex inference across multiple sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the challenges of document-level event extraction compared to sentence-level event extraction.",
      "processing_time": 47.52163052558899,
      "citing_paper_id": "272586489",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Unlike the well-developed sentence-level event extraction [4]–[6], [30], [31], the D-EAE faces more challenges, as it involves complex inference across multiple sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the challenges of document-level event extraction compared to sentence-level event extraction.",
      "processing_time": 47.52163052558899,
      "citing_paper_id": "272586489",
      "cited_paper_id": 208547716
    },
    {
      "context_text": "Unlike the well-developed sentence-level event extraction [4]–[6], [30], [31], the D-EAE faces more challenges, as it involves complex inference across multiple sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the challenges of document-level event extraction compared to sentence-level event extraction.",
      "processing_time": 47.52163052558899,
      "citing_paper_id": "272586489",
      "cited_paper_id": 222177108
    },
    {
      "context_text": "We use BERT base [22] and RoBERTa large [23] as our back-bone encoder for CasDEE.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and RoBERTa as backbone encoders for CasDEE, but these are models, not datasets. No datasets are explicitly mentioned or used in the context.",
      "processing_time": 49.22552990913391,
      "citing_paper_id": "272586489",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We use BERT base [22] and RoBERTa large [23] as our back-bone encoder for CasDEE.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and RoBERTa as backbone encoders for CasDEE, but these are models, not datasets. No datasets are explicitly mentioned or used in the context.",
      "processing_time": 49.22552990913391,
      "citing_paper_id": "272586489",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "0 [18] and WikiEvents [7].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used for document-level event extraction, focusing on linking events across multiple sentences in Wikipedia articles."
      },
      "confidence_score": 0.7,
      "reasoning": "The citation mentions 'WikiEvents' which is a known dataset for event extraction. However, the context does not provide enough detail about how it is used.",
      "processing_time": 53.24487352371216,
      "citing_paper_id": "272586489",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We follow the official train/dev/test split for RAMS and WikiEvents datasets and use the evaluation script provided by Ebner et al. [18] to evaluate the performance.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for training, development, and testing in document-level event extraction, evaluating performance using the official splits and evaluation script.",
        "WikiEvents": "Used for training, development, and testing in document-level event extraction, evaluating performance using the official splits and evaluation script."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for training, development, and testing in the research. The datasets are clearly identified and their usage is specified.",
      "processing_time": 60.95246863365173,
      "citing_paper_id": "272586489",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Classification-based methods predict the argument role for candidate text spans which usually have a maximum length limitation [18], [20], [33], [34].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only classification-based methods and their limitations.",
      "processing_time": 46.44467520713806,
      "citing_paper_id": "272586489",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "A document from the RMAS dataset [18].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RMAS dataset"
      ],
      "dataset_descriptions": {
        "RMAS dataset": "Used to link arguments across multiple sentences, focusing on the structure and coherence of argumentative discourse in documents."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'RMAS dataset' which is a specific, verifiable dataset. The title 'Multi-Sentence Argument Linking' suggests that the dataset is used for argument linking, which is related to document-level event extraction.",
      "processing_time": 57.39465641975403,
      "citing_paper_id": "272586489",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "…compare our model with several baselines and the following previous state-of-the-art models: (1) generation-based models: BART-Gen [25], EA2E [26], PAIE [17], SPEAE [27]; (2) question answering-based models: FEAE [28], BERT-QA [29]; (3) classification-based models: TSAR [10], SCPRG [11], TARA [13].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 47.50429582595825,
      "citing_paper_id": "272586489",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "…compare our model with several baselines and the following previous state-of-the-art models: (1) generation-based models: BART-Gen [25], EA2E [26], PAIE [17], SPEAE [27]; (2) question answering-based models: FEAE [28], BERT-QA [29]; (3) classification-based models: TSAR [10], SCPRG [11], TARA [13].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 47.50429582595825,
      "citing_paper_id": "272586489",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "We compare our model with several baselines and the following previous state-of-the-art models: (1) generation-based models: BART-Gen [25], EA2E [26], PAIE [17], SPEAE [27]; (2) question answering-based models: FEAE [28], BERT-QA [29]; (3) classification-based models: TSAR [10], SCPRG [11], TARA…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 48.10434079170227,
      "citing_paper_id": "272586489",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Li et al. [25] framed EAE as an end-to-end conditional generation task using templates.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to event argument extraction.",
      "processing_time": 46.603700160980225,
      "citing_paper_id": "272586489",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "The event Stab is triggered by stabbed and the arguments for three different roles are scattered across different sentences. this issue, Sheng et al. [14] created role-specific taggers to detect if a token marks the start or end of a role-specific argument.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset names, only a method or approach. The cited paper title 'CasEE' does not indicate a dataset.",
      "processing_time": 48.42288279533386,
      "citing_paper_id": "272586489",
      "cited_paper_id": 235732095
    },
    {
      "context_text": "…PLM encoder already implicitly considers these constraints through multi-head attention mechanisms, we introduce Condition Information Fusion (CIF) [14] to incorporate event type representations directly into the span representation: where µ ∈ R and σ ∈ R are the mean and standard variance taken…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Condition Information Fusion) and a model (PLM encoder).",
      "processing_time": 48.418336391448975,
      "citing_paper_id": "272586489",
      "cited_paper_id": 235732095
    },
    {
      "context_text": "For a candidate argument s i,j ranging from w i to w j , Zhang et al. [20] and Xu et al. [10] used average pooling over the hidden states of all tokens within this span to represent it: c s i,j = 1 j − i +1 = i h wk , where h wk is the k th token embedding from H w .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for representing candidate arguments using average pooling over hidden states.",
      "processing_time": 47.91791558265686,
      "citing_paper_id": "272586489",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Most existing classification-based methods assign only one role label for an argument [10], [11], [13], which cannot tackle the scenarios where an argument plays multiple roles of an event.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses limitations of existing methods.",
      "processing_time": 38.55732583999634,
      "citing_paper_id": "272586489",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Following Xu et al. [10], we divide the event arguments in the RAMS dataset into five bins according to sentence distance between arguments and trigger, i.e., l = {− 2 , − 1 , 0 , 1 , 2 } .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to divide event arguments into bins based on sentence distance, enhancing document-level event argument extraction by categorizing arguments relative to their triggers."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for event argument extraction. The dataset is used to divide event arguments into bins based on sentence distance.",
      "processing_time": 56.91200518608093,
      "citing_paper_id": "272586489",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Following Xu et al. [10] and Liu et al. [11], we extract event arguments for each event in a document independently.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to event argument extraction.",
      "processing_time": 47.907670974731445,
      "citing_paper_id": "272586489",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "To capture essential context information relevant to the target event from a document, Xu et al. [10] proposed a two-stream encoding module that encodes the document from both global and local perspectives to better utilize context information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event argument extraction.",
      "processing_time": 48.07989239692688,
      "citing_paper_id": "272586489",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "To enhance argument extraction by better leveraging relevant context information, Xu et al. [10] proposed a two-stream encoding module, considering both global and local perspectives to optimize context utilization.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enhancing argument extraction. No dataset names are present in the citation context.",
      "processing_time": 49.02763509750366,
      "citing_paper_id": "272586489",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Previous methods focused on the start and end positions of the candidate argument separately, not as a unified whole [10], [11].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only previous methods and their limitations.",
      "processing_time": 47.62749123573303,
      "citing_paper_id": "272586489",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Additionally, Lu et al. [12] created context-aware questions for each role to assist the model in better utilizing role-relevant context information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for creating context-aware questions.",
      "processing_time": 48.073028802871704,
      "citing_paper_id": "272586489",
      "cited_paper_id": 259370619
    },
    {
      "context_text": "Wei et al. [28] and Lu et al. [12] reformulated EAE as a machine reading comprehension task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reformulation of EAE as a machine reading comprehension task.",
      "processing_time": 48.75112819671631,
      "citing_paper_id": "272586489",
      "cited_paper_id": 259370619
    },
    {
      "context_text": "Additionally, existing generation-based methods address the issue by generating all arguments for each role [7], [15], [16].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for argument extraction in document-level event extraction.",
      "processing_time": 48.53841233253479,
      "citing_paper_id": "272586489",
      "cited_paper_id": 264452034
    },
    {
      "context_text": "…successfully applied to many NLP tasks, e.g., dialogue response generation (Weston et al., 2018; Wu et al., 2019; Cai et al., 2019a,b), machine translation (Zhang et al., 2018; Xu et al., 2020; He et al., 2021) and information extraction (Lee et al., 2022; Zhang et al., 2022; Chen et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and methods. No verifiable resources are identified.",
      "processing_time": 49.16690254211426,
      "citing_paper_id": "259370571",
      "cited_paper_id": 4698173
    },
    {
      "context_text": "…successfully applied to many NLP tasks, e.g., dialogue response generation (Weston et al., 2018; Wu et al., 2019; Cai et al., 2019a,b), machine translation (Zhang et al., 2018; Xu et al., 2020; He et al., 2021) and information extraction (Lee et al., 2022; Zhang et al., 2022; Chen et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks and methods. No verifiable resources are identified.",
      "processing_time": 49.16690254211426,
      "citing_paper_id": "259370571",
      "cited_paper_id": 220045828
    },
    {
      "context_text": "Retrieval-augmented methods have recently been successfully applied to many NLP tasks, e.g., dialogue response generation (Weston et al., 2018; Wu et al., 2019; Cai et al., 2019a,b), machine translation (Zhang et al., 2018; Xu et al., 2020; He et al., 2021) and information extraction (Lee et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various NLP tasks where retrieval-augmented methods have been applied. No clear, verifiable datasets are identified.",
      "processing_time": 50.50532102584839,
      "citing_paper_id": "259370571",
      "cited_paper_id": 49312395
    },
    {
      "context_text": "We ﬁne-tune the models on each dataset independently using AdamW (Loshchilov and Hutter, 2019) and conducted experiments on 4 NVIDIA-V100-32GB.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the optimization algorithm (AdamW) and hardware used. There are no verifiable resources or datasets mentioned.",
      "processing_time": 50.189353227615356,
      "citing_paper_id": "259370571",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "…consistent comparison, we divide several state-of-the-art models into three categories: (1) Multi-label classiﬁcation-based model: BERT-CRF (Shi and Lin, 2019), PAIE (Ma et al., 2022); (2) QA-based model: EEQA (Du and Cardie, 2020) and DocMRC (Liu et al., 2021); and (3) Generation-based…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 49.427311420440674,
      "citing_paper_id": "259370571",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "For strictly consistent comparison, we divide several state-of-the-art models into three categories: (1) Multi-label classiﬁcation-based model: BERT-CRF (Shi and Lin, 2019), PAIE (Ma et al., 2022); (2) QA-based model: EEQA (Du and Cardie, 2020) and DocMRC (Liu et al., 2021); and (3) Generation-based model: BART-Gen (Li et al., 2021) and T5-baseline.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is focused on categorizing different models for document-level event extraction.",
      "processing_time": 50.06130123138428,
      "citing_paper_id": "259370571",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "For strictly consistent comparison, we divide several state-of-the-art models into three categories: (1) Multi-label classiﬁcation-based model: BERT-CRF (Shi and Lin, 2019), PAIE (Ma et al., 2022); (2) QA-based model: EEQA (Du and Cardie, 2020) and DocMRC (Liu et al., 2021); and (3) Generation-based model: BART-Gen (Li et al., 2021) and T5-baseline.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is focused on categorizing different models for document-level event extraction.",
      "processing_time": 50.06130123138428,
      "citing_paper_id": "259370571",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…strictly consistent comparison, we divide several state-of-the-art models into three categories: (1) Multi-label classiﬁcation-based model: BERT-CRF (Shi and Lin, 2019), PAIE (Ma et al., 2022); (2) QA-based model: EEQA (Du and Cardie, 2020) and DocMRC (Liu et al., 2021); and (3) Generation-based…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 49.69957995414734,
      "citing_paper_id": "259370571",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Du and Ji (2022) applied S-BERT (Reimers and Gurevych, 2019) to retrieve the most relevant example for event extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions S-BERT, which is a method, not a dataset. No specific dataset is mentioned or used in the context.",
      "processing_time": 49.57203006744385,
      "citing_paper_id": "259370571",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "First sample a noise variable (cid:2) from N (0 , 1) Then transform it to 9 − W Calculate the current sample: retrieve (also via S-BERT) the instance label y r that is the top-k relevant to the input label from the training corpus D train .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'training corpus D train' but does not provide enough information to determine if it is a specific, verifiable dataset. The name 'D train' is too generic and lacks specific identifiers.",
      "processing_time": 51.93205428123474,
      "citing_paper_id": "259370571",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "For retrieval, we use S-BERT (Reimers and Gurevych, 2019) to retrieve semantically similar documents x r ∈ D train .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions S-BERT for retrieving semantically similar documents but does not mention any specific dataset. S-BERT is a method, not a dataset.",
      "processing_time": 50.31907320022583,
      "citing_paper_id": "259370571",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "We adopt the T5 model (Raffel et al., 2022), an encoder-decoder pre-trained model, as a backbone.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the T5 model but does not refer to any specific dataset. The T5 model is a method, not a dataset.",
      "processing_time": 36.21298909187317,
      "citing_paper_id": "259370571",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "These retrieval-augmented methods use similarity-based retrieval, which is based on a simple hypothesis (Li et al., 2022): the more x r (retrieved demonstration) resembles x (original input), the more likely y r (demonstration label) resembles y (input label), so it will help the generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The context focuses on the hypothesis and mechanism of retrieval-augmented methods.",
      "processing_time": 50.47700786590576,
      "citing_paper_id": "259370571",
      "cited_paper_id": 246472929
    },
    {
      "context_text": "(Ma et al., 2022), and ‡ denotes the results from our implemented models for a fairer comparison.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a reference to results from implemented models. No verifiable resources are identified.",
      "processing_time": 49.845465660095215,
      "citing_paper_id": "259370571",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "For BART-base model, we report the results from Ma et al. (2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a paper. No dataset names are present in the citation span.",
      "processing_time": 49.84414744377136,
      "citing_paper_id": "259370571",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…we divide several state-of-the-art models into three categories: (1) Multi-label classiﬁcation-based model: BERT-CRF (Shi and Lin, 2019), PAIE (Ma et al., 2022); (2) QA-based model: EEQA (Du and Cardie, 2020) and DocMRC (Liu et al., 2021); and (3) Generation-based model: BART-Gen (Li et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is focused on categorizing different types of models for event extraction.",
      "processing_time": 50.468883752822876,
      "citing_paper_id": "259370571",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "For Coref F1, the model is given full credit if the extracted argument is corefer-ential with the reference as used in Ji and Grishman (2008).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (Coref F1) and a method (cross-document inference). No verifiable resources are identified.",
      "processing_time": 51.04555916786194,
      "citing_paper_id": "258967387",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Wang et al. (2021) pre-trains the EAE model with a contrastive loss built on AMR graphs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions pre-training with AMR graphs but does not specify a dataset. The cited paper title does not help in identifying a specific dataset.",
      "processing_time": 49.834184408187866,
      "citing_paper_id": "258967387",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "Xu and Huang (2022) and Wang et al. (2021) utilize AMR graphs to provide training signals via self-training and contrastive learning, respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'AMR graphs' but does not specify a dataset. The cited papers do not clarify the presence of a specific dataset either.",
      "processing_time": 50.45532727241516,
      "citing_paper_id": "258967387",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "Xu and Huang (2022) and Wang et al. (2021) utilize AMR graphs to provide training signals via self-training and contrastive learning, respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'AMR graphs' but does not specify a dataset. The cited papers do not clarify the presence of a specific dataset either.",
      "processing_time": 50.45532727241516,
      "citing_paper_id": "258967387",
      "cited_paper_id": 249063162
    },
    {
      "context_text": "(1) QA-based models: EEQA (Du and Cardie, 2020b) and FEAE (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (EEQA and FEAE). The context is focused on describing the models rather than datasets.",
      "processing_time": 50.79053831100464,
      "citing_paper_id": "258967387",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Du and Cardie (2020a) chooses the hierarchical method to aggregate information from different granularity.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 48.33291149139404,
      "citing_paper_id": "258967387",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Unlike the well-developed sentence-level event extraction (Xi et al., 2021; Ma et al., 2020), the Doc-level EAE faces more challenges.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to document-level event extraction challenges.",
      "processing_time": 49.66135215759277,
      "citing_paper_id": "258967387",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "To explore the effect of different AMR parsing performance, we compare test results of TARA using transition-based AMR parser and a latest state-of-the-art parser AMRBART (Bai et al., 2022) in Table 9.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions AMR parsers but does not refer to any specific datasets. The focus is on comparing parsing performance rather than using a particular dataset.",
      "processing_time": 51.02936005592346,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "Second, the Smatch score of SOTA AMR parsers is around 85 (Bai et al., 2022), which causes information loss as well.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a performance metric (Smatch score) of state-of-the-art AMR parsers. No dataset names are provided in the context.",
      "processing_time": 52.176804065704346,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "We implement a simple node-to-text aligner and compress the obtained AMR graph as described in Sec-B for AMRBART.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for AMR parsing and generation.",
      "processing_time": 48.8002393245697,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "As shown in the table, though AMRBART brings better AMR parsing performance, it dose not gain more improvements for EAE.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (AMRBART) and its performance in AMR parsing and event argument extraction. No verifiable resources are identified.",
      "processing_time": 52.35709500312805,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "We also show the performance using another state-of-the-art AMR parser, AMRBART (Bai et al., 2022 (3) Span-based models: TSAR (Xu et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing performance of different parsers, which are not considered datasets.",
      "processing_time": 51.65660834312439,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "TAG can be built on vanilla AMR graphs generated by an off-the-shelf AMR parser (Bai et al., 2022; Astudillo et al., 2020), which also provides the alignment information between nodes and words.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and tools. The citation is about using an AMR parser to generate graphs and alignments, which is a methodological step.",
      "processing_time": 52.57302927970886,
      "citing_paper_id": "258967387",
      "cited_paper_id": 247450724
    },
    {
      "context_text": "Lin et al. (2022) and Xu and Huang (2022) introduce AMR path information as training signals to correct argument predictions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. The context focuses on the introduction of AMR path information as a training signal.",
      "processing_time": 51.6513671875,
      "citing_paper_id": "258967387",
      "cited_paper_id": 249063162
    },
    {
      "context_text": "Fan et al. (2022) trains a learnable module to add nodes and edges to the AMR graph.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for adding nodes and edges to an AMR graph.",
      "processing_time": 39.094046115875244,
      "citing_paper_id": "258967387",
      "cited_paper_id": 250637739
    },
    {
      "context_text": "Fan et al. (2022) and Xu et al. (2021) construct an entity-based graph to model dependencies among the document.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving an entity-based graph.",
      "processing_time": 49.63444805145264,
      "citing_paper_id": "258967387",
      "cited_paper_id": 250637739
    },
    {
      "context_text": "(Wang et al., 2021; Du and Cardie, 2020a) utilize the sequence labeling model BiLSTM-CRF (Zhang et al., 2015) for DEE.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BiLSTM-CRF) used for document-level event extraction.",
      "processing_time": 50.87731337547302,
      "citing_paper_id": "259858959",
      "cited_paper_id": 8950084
    },
    {
      "context_text": ", 2021; Du and Cardie, 2020a) utilize the sequence labeling model BiLSTM-CRF (Zhang et al., 2015) for DEE.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BiLSTM-CRF) used for Document-level Event Extraction (DEE).",
      "processing_time": 51.637797117233276,
      "citing_paper_id": "259858959",
      "cited_paper_id": 8950084
    },
    {
      "context_text": ", 2015) firstly propose a neural pipeline model for event extraction and (Nguyen et al., 2016; Nguyen and Grishman, 2015; Liu et al., 2017; Zhou et al., 2020) further extend the pipeline model to recurrent neural networks and convolutional neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 51.62893056869507,
      "citing_paper_id": "259858959",
      "cited_paper_id": 10913456
    },
    {
      "context_text": ", 2015) firstly propose a neural pipeline model for event extraction and (Nguyen et al., 2016; Nguyen and Grishman, 2015; Liu et al., 2017; Zhou et al., 2020) further extend the pipeline model to recurrent neural networks and convolutional neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 51.62893056869507,
      "citing_paper_id": "259858959",
      "cited_paper_id": 35386653
    },
    {
      "context_text": "(Chen et al., 2015) firstly propose a neural pipeline model for event extraction and (Nguyen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction.",
      "processing_time": 49.62072944641113,
      "citing_paper_id": "259858959",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Considering most candidate arguments are negative samples and the imbalanced role distribution, we adopt focal loss (Lin et al., 2017) to make the training process focus more on useful positive samples, where α and γ are hyperparameters.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (focal loss) used to address class imbalance in training.",
      "processing_time": 50.99473810195923,
      "citing_paper_id": "259858959",
      "cited_paper_id": 47252984
    },
    {
      "context_text": "Compared with previous works (Liu et al., 2018; Wadden et al., 2019; Tong et al., 2020) focusing on sentence-level EAE, more and more recent works tend to explore documentlevel EAE (Wang et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous works and their focus on sentence-level or document-level event extraction.",
      "processing_time": 51.627238035202026,
      "citing_paper_id": "259858959",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Compared with previous works (Liu et al., 2018; Wadden et al., 2019; Tong et al., 2020) focusing on sentence-level EAE, more and more recent works tend to explore documentlevel EAE (Wang et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous works and their focus on sentence-level or document-level event extraction.",
      "processing_time": 51.627238035202026,
      "citing_paper_id": "259858959",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Compared with previous works (Liu et al., 2018; Wadden et al., 2019; Tong et al., 2020) focusing on sentence-level EAE, more and more recent works tend to explore documentlevel EAE (Wang et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous works and their focus on sentence-level or document-level event extraction.",
      "processing_time": 51.627238035202026,
      "citing_paper_id": "259858959",
      "cited_paper_id": 220047190
    },
    {
      "context_text": "To model the dependency of words in a sentence, (Liu et al., 2018; Yan et al., 2019; Fernandez Astudillo et al., 2020) leverage dependency trees to model semantic and syntactic relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for modeling dependencies in sentences.",
      "processing_time": 50.401766777038574,
      "citing_paper_id": "259858959",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "(Zheng et al., 2019) propose a transformer-based architecture and model",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model architecture. No dataset names are present in the citation context.",
      "processing_time": 51.187808990478516,
      "citing_paper_id": "259858959",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Compared with previous tagging-based and span-based methods like BERT-CRF and Two-Step, our SCPRG equipped with BERTbase yields an improvement of +8.46/+9.64 ∼ +6.36/+7.14 Span F1 and +7.68/+9.00 ∼ +5.38/+6.40 Head F1 on dev/test set, showing that our SCPRG framework has superiority in excluding impossible candidate spans and solving the imbalance of data distribution problem.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model performance metrics and comparisons. No verifiable resources are identified.",
      "processing_time": 50.983752489089966,
      "citing_paper_id": "259858959",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al., 2020), span-based methods like Two-Step (Zhang et al., 2020b), Two-StepTCD (Ebner et al., 2020), TSAR (Xu et al., 2022), and other generation-based methods such as FEAE (Wei et al., 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al., 2021), EA2E (Zeng et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only various models and methods used for document-level event argument extraction (EAE).",
      "processing_time": 51.84017086029053,
      "citing_paper_id": "259858959",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al., 2020), span-based methods like Two-Step (Zhang et al., 2020b), Two-StepTCD (Ebner et al., 2020), TSAR (Xu et al., 2022), and other generation-based methods such as FEAE (Wei et al., 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al., 2021), EA2E (Zeng et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only various models and methods used for document-level event argument extraction (EAE).",
      "processing_time": 51.84017086029053,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al., 2020), span-based methods like Two-Step (Zhang et al., 2020b), Two-StepTCD (Ebner et al., 2020), TSAR (Xu et al., 2022), and other generation-based methods such as FEAE (Wei et al., 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al., 2021), EA2E (Zeng et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only various models and methods used for document-level event argument extraction (EAE).",
      "processing_time": 51.84017086029053,
      "citing_paper_id": "259858959",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al., 2020), span-based methods like Two-Step (Zhang et al., 2020b), Two-StepTCD (Ebner et al., 2020), TSAR (Xu et al., 2022), and other generation-based methods such as FEAE (Wei et al., 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al., 2021), EA2E (Zeng et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only various models and methods used for document-level event argument extraction (EAE).",
      "processing_time": 51.84017086029053,
      "citing_paper_id": "259858959",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 51.61324977874756,
      "citing_paper_id": "259858959",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Some methods using transformer-based pre-trained model (Wadden et al., 2019; Wang et al., 2019; Tong et al., 2020; Lu et al., 2021; Liu et al., 2022b) also achieve remarkable performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.30856227874756,
      "citing_paper_id": "259858959",
      "cited_paper_id": 174799895
    },
    {
      "context_text": "Some methods using transformer-based pre-trained model (Wadden et al., 2019; Wang et al., 2019; Tong et al., 2020; Lu et al., 2021; Liu et al., 2022b) also achieve remarkable performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.30856227874756,
      "citing_paper_id": "259858959",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "Some methods using transformer-based pre-trained model (Wadden et al., 2019; Wang et al., 2019; Tong et al., 2020; Lu et al., 2021; Liu et al., 2022b) also achieve remarkable performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.30856227874756,
      "citing_paper_id": "259858959",
      "cited_paper_id": 220047190
    },
    {
      "context_text": "Some methods using transformer-based pre-trained model (Wadden et al., 2019; Wang et al., 2019; Tong et al., 2020; Lu et al., 2021; Liu et al., 2022b) also achieve remarkable performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.30856227874756,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248721950
    },
    {
      "context_text": "(Wadden et al., 2019) enumerates all possible spans and construct span graphs with graph neural netpreve nter trans porte r pass enge r origindesti natio n",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for constructing span graphs using graph neural networks.",
      "processing_time": 51.17402172088623,
      "citing_paper_id": "259858959",
      "cited_paper_id": 202539496
    },
    {
      "context_text": "BART-Genlarge is based on BARTlarge (Lewis et al., 2019) which is pre-trained on the same corpus.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BART-Genlarge and BARTlarge, which are models, not datasets. No specific dataset is mentioned or used in the context.",
      "processing_time": 52.86029648780823,
      "citing_paper_id": "259858959",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "First, when we remove span-trigger-based contextual pooling (STCP) module, both Span F1 and\n4BART-Genlarge is based on BARTlarge (Lewis et al., 2019) which is pre-trained on the same corpus.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BARTlarge) and a method (STCP).",
      "processing_time": 51.82915186882019,
      "citing_paper_id": "259858959",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "In this section, we show the complete cooccurrence frequency matrix which contains all roles in RAMS test set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS test set"
      ],
      "dataset_descriptions": {
        "RAMS test set": "Used to generate a cooccurrence frequency matrix for argument linking, focusing on role co-occurrences in multi-sentence contexts."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS test set' as a specific dataset used to show the cooccurrence frequency matrix. The dataset is relevant to document-level event extraction.",
      "processing_time": 60.063440561294556,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Other span based methods (Ebner et al., 2020; Zhang et al., 2020b) predict the argument roles for candidate text spans with a maximum length limitation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets in the text.",
      "processing_time": 39.632044315338135,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Baselines We compare different categories of document-level EAE models which mainly consist of tagging-based methods such as BERT-CRF (Shi and Lin, 2019), BERT-CRFTCD (Ebner et al., 2020), span-based methods like Two-Step (Zhang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 52.10537886619568,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Additionally, when removing role-based latent information guidance (RLIG) module5, the performance of SCPRGbase/ SCPRGlarge drops sharply by 1.03/1.04 Span F1 and 1.58/1.2 Head F1 on RAMS test set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS test set"
      ],
      "dataset_descriptions": {
        "RAMS test set": "Used to evaluate the performance of SCPRGbase and SCPRGlarge models, specifically measuring the impact of removing the RLIG module on Span F1 and Head F1 scores."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS test set, which is a specific dataset used for evaluating the performance of the models. The dataset is used to measure the impact of removing the RLIG module on the performance of SCPRGbase and SCPRGlarge models.",
      "processing_time": 65.31126403808594,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": ", 2022), which needs to solve long-distance dependency (Ebner et al., 2020) and cross-sentence inference (Li et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to solving long-distance dependency and cross-sentence inference. No verifiable resources are identified.",
      "processing_time": 52.8420295715332,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Datasets and Metrics We evaluate the proposed model on two large-scale public document-level\nEAE datasets, RAMSv1.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMSv1"
      ],
      "dataset_descriptions": {
        "RAMSv1": "Used to evaluate the proposed model on document-level event argument extraction, focusing on multi-sentence argument linking and event coreference."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMSv1' as a document-level EAE dataset used for evaluation. It is a specific, verifiable dataset with a clear version tag.",
      "processing_time": 60.98342537879944,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "In the main body of the paper, we conduct ablation study on RAMS dataset for SCPRGbase and SCPRGlarge.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for conducting ablation studies on SCPRGbase and SCPRGlarge, focusing on document-level event extraction performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for document-level event extraction.",
      "processing_time": 57.85336780548096,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Figure 7: A t-SNE visualization example from RAMS, where embeddings of arguments and roles are from 5 different documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to visualize embeddings of arguments and roles from multiple documents, aiding in the analysis of argument linking in document-level event extraction."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'RAMS' as a source of embeddings for a t-SNE visualization, which suggests it is a dataset used for document-level event extraction.",
      "processing_time": 60.03946542739868,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Following (Xu et al., 2022), we report the Span F1 and Head F1 on dev and test sets for RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate document-level event argument extraction, reporting Span F1 and Head F1 on development and test sets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for evaluation. The citation intent is to report performance metrics on this dataset.",
      "processing_time": 59.700963735580444,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Following (Xu et al., 2022), we report the Span F1 and Head F1 on dev and test sets for RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate document-level event argument extraction, reporting Span F1 and Head F1 on development and test sets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for evaluation. The citation intent is to report performance metrics on this dataset.",
      "processing_time": 59.700963735580444,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Moreover, many roles co-occur in multiple events (Ebner et al., 2020; Li et al., 2021), which may have close semantic relevance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to roles co-occurring in multiple events. No clear identifiers for datasets are present.",
      "processing_time": 52.82939434051514,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": ", 2020b), Two-StepTCD (Ebner et al., 2020), TSAR (Xu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods or models. There are no clear identifiers for datasets within the text.",
      "processing_time": 52.268898248672485,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "To better illustrate the capabilities of our components, we conduct ablation study on RAMS dataset as shown in Table 4.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to conduct an ablation study on the performance of different components in a multi-sentence argument linking system, focusing on document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for document-level event extraction.",
      "processing_time": 58.57880210876465,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Specifically, we count and visualize the frequency of co-occurrence between 15 most frequent roles in RAMS dataset in Figure 2.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS dataset"
      ],
      "dataset_descriptions": {
        "RAMS dataset": "Used to count and visualize the frequency of co-occurrence between the 15 most frequent roles, focusing on event extraction and argument linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'RAMS dataset' which is a specific, verifiable dataset used for event extraction and argument linking.",
      "processing_time": 59.841233253479004,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Figure 1: A document from RAMS (Ebner et al., 2020) dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to provide a document example for argument linking, focusing on multi-sentence structures and their relationships in the context of document-level event extraction."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'RAMS' as a dataset, which is a multi-word proper noun and appears to be a specific, verifiable resource. The cited paper title does not contradict this interpretation.",
      "processing_time": 61.67562484741211,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "• Extensive experiments show that SCPRG outperforms previous start-of-the-art models, with 1.13 F1 and 2.64 F1 improvements on public RAMS and WikiEvents (Li et al., 2021) datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the performance of the SCPRG model, specifically measuring F1 score improvements over previous state-of-the-art models.",
        "WikiEvents": "Used to evaluate the performance of the SCPRG model, specifically measuring F1 score improvements over previous state-of-the-art models."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions two specific datasets, RAMS and WikiEvents, which are used to evaluate the performance of the SCPRG model.",
      "processing_time": 64.74512314796448,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Table 2 shows the experimental results on both dev and test set in RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate experimental results on document-level event extraction, focusing on performance metrics on both development and test sets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for evaluation. The dataset is clearly identified and used in the research context.",
      "processing_time": 59.53399896621704,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "63M 48.33 54.04 47.52 55.61 -ASE 372.90M 49.80 56.31 51.73 58.48\nTable 4: Ablation Study on RAMS for SCPRG.\nlarity between latent role representations from two events in RAMS dataset in Fig 6.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for an ablation study on SCPRG, analyzing the clarity between latent role representations from two events in the dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a well-known resource for document-level event extraction. The dataset is used for an ablation study and to analyze the clarity between latent role representations from two events.",
      "processing_time": 61.8157217502594,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "We train SCPRG for 50 epochs for RAMS dataset and 100 epochs for WikiEvents dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to train the SCPRG model for 50 epochs, focusing on document-level event extraction and argument linking.",
        "WikiEvents": "Used to train the SCPRG model for 100 epochs, focusing on document-level event extraction and argument linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and WikiEvents, which are used for training the SCPRG model. These datasets are relevant to document-level event extraction.",
      "processing_time": 65.60044836997986,
      "citing_paper_id": "259858959",
      "cited_paper_id": 207853145
    },
    {
      "context_text": ", 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models or methods. No dataset names are present in the text.",
      "processing_time": 51.93846940994263,
      "citing_paper_id": "259858959",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "(Wang et al., 2021; Du and Cardie, 2020a) utilize the sequence labeling model BiLSTM-CRF (Zhang et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (BiLSTM-CRF). The context is about utilizing a sequence labeling model, which is not a dataset.",
      "processing_time": 16.28464365005493,
      "citing_paper_id": "259858959",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "(Wang et al., 2021; Du and Cardie, 2020a) utilize the sequence labeling model BiLSTM-CRF (Zhang et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (BiLSTM-CRF). The context is about utilizing a sequence labeling model, which is not a dataset.",
      "processing_time": 16.28464365005493,
      "citing_paper_id": "259858959",
      "cited_paper_id": 235254286
    },
    {
      "context_text": "and dialogue systems (Zhang et al., 2020a) for presenting unstructured text containing event information in structured form.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to unstructured text containing event information. No clear, verifiable dataset names are present.",
      "processing_time": 53.26131534576416,
      "citing_paper_id": "259858959",
      "cited_paper_id": 220524732
    },
    {
      "context_text": ", 2021) formulate the problem as conditional generation and (Du et al., 2021) regards the problem as a sequence-to-sequence task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only approaches to the problem of document-level event entity extraction.",
      "processing_time": 51.53432655334473,
      "citing_paper_id": "259858959",
      "cited_paper_id": 231728756
    },
    {
      "context_text": ", 2022) try to construct graphs based on heuristic rules (Xu et al., 2021; Liu et al., 2022a) or syntactic structures (Xu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for constructing graphs. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 53.260915994644165,
      "citing_paper_id": "259858959",
      "cited_paper_id": 235253912
    },
    {
      "context_text": ", 2022) try to construct graphs based on heuristic rules (Xu et al., 2021; Liu et al., 2022a) or syntactic structures (Xu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for constructing graphs. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 53.260915994644165,
      "citing_paper_id": "259858959",
      "cited_paper_id": 252626402
    },
    {
      "context_text": "Base on their architecture, (Xu et al., 2021) construct a heterogeneous graph and a tracker module to capture the interdependency among events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction using a heterogeneous graph and a tracker module.",
      "processing_time": 52.60888862609863,
      "citing_paper_id": "259858959",
      "cited_paper_id": 235253912
    },
    {
      "context_text": ", 2022), and other generation-based methods such as FEAE (Wei et al., 2021), BERTQA (Du and Cardie, 2020b), BART-Gen (Li et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 52.6090989112854,
      "citing_paper_id": "259858959",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "(Wei et al., 2021) reformulate the task as reading a comprehension task.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reformulation of a task. No verifiable resources are identified.",
      "processing_time": 52.22215938568115,
      "citing_paper_id": "259858959",
      "cited_paper_id": 236460308
    },
    {
      "context_text": ", 2022a) or syntactic structures (Xu et al., 2022) and model logical reasoning with Graph Neural Networks (Kipf and Welling, 2016; Zeng et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. No dataset names are present in the citation span.",
      "processing_time": 52.225751638412476,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Moreover, (Xu et al., 2022) propose a twostream encoder with AMR-guided graph to solve long-distance dependency problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or model. The title confirms the focus on a model rather than a dataset.",
      "processing_time": 52.984615087509155,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "However, many previous works (Li et al., 2021; Xu et al., 2022) only utilize pre-trained transformerar X iv :2 31 0.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous works. There are no clear identifiers for datasets in the given context.",
      "processing_time": 52.9872624874115,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Span-Trigger-based Contextual Pooling For a candidate span ranging from wi to wj , most previous span-based methods(Zhang et al., 2020b; Xu et al., 2022) represent it through the average pooling of the hidden state of tokens within this span:",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets in the provided span.",
      "processing_time": 52.98495697975159,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": ", 2020), TSAR (Xu et al., 2022), and other generation-based methods such as FEAE (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the given context.",
      "processing_time": 52.97679138183594,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": ", 2020) focusing on sentence-level EAE, more and more recent works tend to explore documentlevel EAE (Wang et al., 2022b; Yang et al., 2021; Xu et al., 2022), which needs to solve long-distance dependency (Ebner et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to recent works exploring document-level event argument extraction.",
      "processing_time": 52.0297589302063,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Finally, the boundary loss is defined to detect the start and end position following (Xu et al., 2022): Lb = − ∑|D| i=1[y s i logP s i + (1− ys i ) log(1− P s i ) +ye i logP e i + (1− ye i ) log(1− P e i )], (7) where ys i and y e i denote golden labels and P s i = sigmoid(W4h start i ) and P e i = sigmoid(W5h end i ) are the probabilities of the word wi predicted to be the first or last word of a golden argument span.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for defining boundary loss in the context of document-level event argument extraction.",
      "processing_time": 52.58929777145386,
      "citing_paper_id": "259858959",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Besides, (Ren et al., 2022) integrate argument roles into document encoding to aware tokens of multiple role information for nested arguments problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for integrating argument roles into document encoding.",
      "processing_time": 51.25745177268982,
      "citing_paper_id": "259858959",
      "cited_paper_id": 252819226
    },
    {
      "context_text": ", 2022c; Chen and Kou, 2023) and Image Semantic Segmentation (Zhang et al., 2022), its impact on Event Argument Extraction in natural language processing has been relatively limited.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to image semantic segmentation. No verifiable resources are identified.",
      "processing_time": 52.75880217552185,
      "citing_paper_id": "259858959",
      "cited_paper_id": 254043718
    },
    {
      "context_text": "Although deep learning has achieved significant success in many areas of computer vision (Li et al., 2022; Wang et al., 2023, 2022a; Pan et al., 2023; Wang and Chen, 2023) like 3D Scene Graph Generation (Liu et al., 2022c; Chen and Kou, 2023) and Image Semantic Segmentation (Zhang et al., 2022), its impact on Event Argument Extraction in natural language processing has been relatively limited.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research and methods. There are no verifiable resources or datasets mentioned.",
      "processing_time": 53.41013860702515,
      "citing_paper_id": "259858959",
      "cited_paper_id": 254043718
    },
    {
      "context_text": "Although deep learning has achieved significant success in many areas of computer vision (Li et al., 2022; Wang et al., 2023, 2022a; Pan et al., 2023; Wang and Chen, 2023) like 3D Scene Graph Generation (Liu et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to deep learning achievements in computer vision and 3D Scene Graph Generation.",
      "processing_time": 53.41492009162903,
      "citing_paper_id": "259858959",
      "cited_paper_id": 259716313
    },
    {
      "context_text": "First-order logic (FOL) rules can encode declarative knowledge and play a crucial role in symbolic reasoning (Cresswell and Hughes, 1996).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a book about modal logic.",
      "processing_time": 51.2476646900177,
      "citing_paper_id": "259370721",
      "cited_paper_id": 1164487
    },
    {
      "context_text": "Our approach formalizes the reasoning chain as first-order logic (FOL) rules (Cresswell and Hughes, 1996).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any datasets, only a methodological approach using first-order logic rules.",
      "processing_time": 51.06571888923645,
      "citing_paper_id": "259370721",
      "cited_paper_id": 1164487
    },
    {
      "context_text": "Earlier efforts on this problem explore the MUC-4 benchmark (Chinchor, 1991; Huang and Riloff, 2012), also known as “template filling” because the entire document is about one event.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MUC-4": "Used for template filling in event extraction, focusing on one event per document to train and evaluate classifiers."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the MUC-4 benchmark, which is a specific dataset used for event extraction tasks. The dataset is used for template filling, focusing on one event per document.",
      "processing_time": 20.843538999557495,
      "citing_paper_id": "259370721",
      "cited_paper_id": 2213149
    },
    {
      "context_text": "For optimization, we use the Adam optimizer (Kingma and Ba, 2015) with a batch size of 10 from [5, 10, 15, 20] and a learning rate of 1e-4 from [1e-3, 1e-4, 1e-5].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the Adam optimizer and training parameters. No datasets are referenced.",
      "processing_time": 52.410746574401855,
      "citing_paper_id": "259370721",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "We validate this assumption by analyzing its performance in low-resource scenarios and for defending against adversarial attacks (Jia and Liang, 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general scenarios and attacks. No clear, verifiable resource names are provided.",
      "processing_time": 52.18008780479431,
      "citing_paper_id": "259370721",
      "cited_paper_id": 7228830
    },
    {
      "context_text": "Inspired by work that augments neural networks with FOLs (Li and Srikumar, 2019; Ahmed et al., 2022), we present T-Norm fuzzy logic for relaxation (Hajek, 1998), which leads to an end-to-end training regime.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and theoretical work. There are no clear identifiers for datasets in the text.",
      "processing_time": 53.39128375053406,
      "citing_paper_id": "259370721",
      "cited_paper_id": 61701554
    },
    {
      "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate Span-F1, focusing on document-level event role filler extraction using multi-granularity contextualized encoding.",
        "WikiEvents": "Used to evaluate Coref-F1, which considers co-reference linkages between arguments in document-level event argument extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the research topic.",
      "processing_time": 65.37647676467896,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate Span-F1, focusing on document-level event role filler extraction using multi-granularity contextualized encoding.",
        "WikiEvents": "Used to evaluate Coref-F1, which considers co-reference linkages between arguments in document-level event argument extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the research topic.",
      "processing_time": 65.37647676467896,
      "citing_paper_id": "259370721",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate Span-F1, focusing on document-level event role filler extraction using multi-granularity contextualized encoding.",
        "WikiEvents": "Used to evaluate Coref-F1, which considers co-reference linkages between arguments in document-level event argument extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the research topic.",
      "processing_time": 65.37647676467896,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate Span-F1, focusing on document-level event role filler extraction using multi-granularity contextualized encoding.",
        "WikiEvents": "Used to evaluate Coref-F1, which considers co-reference linkages between arguments in document-level event argument extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the research topic.",
      "processing_time": 65.37647676467896,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "We employ Span-F1 on RAMS and Head-F1 and Coref-F1 on WikiEvents as evaluation metrics, where Head-F1 only examines the head word in an argument and Coref-F1 also takes co-reference linkages between arguments into account (Du and Cardie, 2020a; Li et al., 2021; Wei et al., 2021; Ma et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate Span-F1, focusing on document-level event role filler extraction using multi-granularity contextualized encoding.",
        "WikiEvents": "Used to evaluate Coref-F1, which considers co-reference linkages between arguments in document-level event argument extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions RAMS and WikiEvents as datasets used for evaluation metrics in document-level event extraction. These are specific datasets relevant to the research topic.",
      "processing_time": 65.37647676467896,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "BIOlabel (Shi and Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models, but does not explicitly refer to any specific datasets. The names mentioned are likely models or methods rather than datasets.",
      "processing_time": 54.18113970756531,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "BIOlabel (Shi and Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models, but does not explicitly refer to any specific datasets. The names mentioned are likely models or methods rather than datasets.",
      "processing_time": 54.18113970756531,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "BIOlabel (Shi and Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models, but does not explicitly refer to any specific datasets. The names mentioned are likely models or methods rather than datasets.",
      "processing_time": 54.18113970756531,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "…explosion was a sucicde bomber who detonated his belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 52.730072021484375,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "2) Global encoding methods, such as QAEE (Du and Cardie, 2020b) and DocMRC (Liu et al., 2021), which form the task as a document-based question-answering problem, and MemNet (Du et al., 2022), which uses a memory to store global event information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions methods and models (QAEE, DocMRC, MemNet) but does not refer to any specific datasets. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 56.49464964866638,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "2) Global encoding methods, such as QAEE (Du and Cardie, 2020b) and DocMRC (Liu et al., 2021), which form the task as a document-based question-answering problem, and MemNet (Du et al., 2022), which uses a memory to store global event information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions methods and models (QAEE, DocMRC, MemNet) but does not refer to any specific datasets. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 56.49464964866638,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "BIOlabel (Shi and Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is performed by ﬁrst broadcasting the vector to the same dimension as the matrix, followed by an element-wise concatenation operation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models, but does not explicitly refer to any datasets. The names mentioned are likely models or methods rather than datasets.",
      "processing_time": 54.178828954696655,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "BIOlabel (Shi and Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is performed by ﬁrst broadcasting the vector to the same dimension as the matrix, followed by an element-wise concatenation operation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods and models, but does not explicitly refer to any datasets. The names mentioned are likely models or methods rather than datasets.",
      "processing_time": 54.178828954696655,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.65563488006592,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.65563488006592,
      "citing_paper_id": "259370721",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.65563488006592,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247417818
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.65563488006592,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.65563488006592,
      "citing_paper_id": "259370721",
      "cited_paper_id": 252391326
    },
    {
      "context_text": "From the results, we can see that our model maintains a comparable time to earlier methods such as QAEE and is faster than many models such as FEAE and DocMRC, where FEAE has two base models for knowledge distillation and DocMRC uses external data to pretrain the model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing the performance of different models.",
      "processing_time": 53.38215088844299,
      "citing_paper_id": "259370721",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 53.37926411628723,
      "citing_paper_id": "259370721",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "In this task, the major challenge is to model long-range dependencies between event triggers and arguments, as an event expression can span multiple sentences (Ebner et al., 2020; Liu et al., 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses challenges in modeling long-range dependencies in document-level event argument extraction.",
      "processing_time": 53.37662625312805,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "When ground-truth entities are available (such as in WikiEvents (Li et al., 2021)), we consider the candidate set to be the ground-truth entity set; otherwise, we use external toolkits2 to recognize entities.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to define the candidate set for entity recognition in document-level event argument extraction, providing ground-truth entities for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'WikiEvents' as a dataset where ground-truth entities are available. It is used to define the candidate set for entity recognition in document-level event argument extraction.",
      "processing_time": 61.87364482879639,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "(Du et al., 2022) 46.2 47.0 46.6 BART-Gen (Li et al., 2021) 42.1 47.3 44.5 PAIE (Ma et al., 2022) - - 49.5 FEAE (Wei et al., 2021) 53.1 42.7 47.4 TSAR (Xu et al",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and their performance metrics. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.84507751464844,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "(Du et al., 2022) 46.2 47.0 46.6 BART-Gen (Li et al., 2021) 42.1 47.3 44.5 PAIE (Ma et al., 2022) - - 49.5 FEAE (Wei et al., 2021) 53.1 42.7 47.4 TSAR (Xu et al",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and their performance metrics. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.84507751464844,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "(Du et al., 2022) 46.2 47.0 46.6 BART-Gen (Li et al., 2021) 42.1 47.3 44.5 PAIE (Ma et al., 2022) - - 49.5 FEAE (Wei et al., 2021) 53.1 42.7 47.4 TSAR (Xu et al",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and their performance metrics. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.84507751464844,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "(Du et al., 2022) 46.2 47.0 46.6 BART-Gen (Li et al., 2021) 42.1 47.3 44.5 PAIE (Ma et al., 2022) - - 49.5 FEAE (Wei et al., 2021) 53.1 42.7 47.4 TSAR (Xu et al",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and their performance metrics. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.84507751464844,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "(Du et al., 2022) 46.2 47.0 46.6 BART-Gen (Li et al., 2021) 42.1 47.3 44.5 PAIE (Ma et al., 2022) - - 49.5 FEAE (Wei et al., 2021) 53.1 42.7 47.4 TSAR (Xu et al",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names and their performance metrics. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.84507751464844,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "When ground-truth entities are available (such as in WikiEvents (Li et al., 2021)), we consider the candidate set to be the ground-truth entity set; otherwise, we use external toolkits 2 to recognize entities.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to define the candidate set for entity recognition in document-level event argument extraction, providing ground-truth entities for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'WikiEvents' as a dataset where ground-truth entities are available. It is used to define the candidate set for entity recognition in document-level event argument extraction.",
      "processing_time": 61.395302295684814,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "In this task, the major challenge is to model longrange dependencies between event triggers and arguments, as an event expression can span multiple sentences (Ebner et al., 2020; Liu et al., 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the challenge of modeling long-range dependencies in document-level event argument extraction.",
      "processing_time": 53.36738967895508,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.41040539741516,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.41040539741516,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.41040539741516,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "We conduct experiments using two document-level EAE benchmarks: RAMS (Ebner et al., 2020) and WikiEvents (Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event argument extraction experiments, focusing on conditional generation methods to improve extraction accuracy.",
        "WikiEvents": "Used for document-level event argument extraction experiments, focusing on conditional generation methods to improve extraction accuracy."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions two specific benchmarks, RAMS and WikiEvents, which are used for document-level event argument extraction experiments.",
      "processing_time": 63.014857053756714,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": ", participants of an event) is a crucial task for document-level event understanding (Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general task related to document-level event understanding.",
      "processing_time": 12.856319189071655,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We verify the effectiveness of our method on two benchmarks (Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'two benchmarks' but does not specify their names. The context does not provide enough information to identify specific datasets.",
      "processing_time": 53.93343782424927,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "For capturing the document context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event extraction.",
      "processing_time": 52.904661655426025,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "For capturing the document context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event extraction.",
      "processing_time": 52.904661655426025,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "For capturing the document context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event extraction.",
      "processing_time": 52.904661655426025,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "…his belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 53.1616895198822,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "For capturing the document context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 53.59303259849548,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Identifying event arguments (i.e., participants of an event) is a crucial task for document-level event understanding (Ebner et al., 2020; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the task of identifying event arguments for document-level event understanding.",
      "processing_time": 53.15184807777405,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "3) Generative methods, such as BART-Gen (Li et al., 2021), which proposes a sequence-to-sequence paradigm for argument extraction, and PAIE (Ma et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions generative methods for argument extraction but does not specify any datasets. The names 'BART-Gen' and 'PAIE' are models, not datasets.",
      "processing_time": 55.815393686294556,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "3) Generative methods, such as BART-Gen (Li et al., 2021), which proposes a sequence-to-sequence paradigm for argument extraction, and PAIE (Ma et al., 2022), which employs a set generation formulation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions generative methods for argument extraction but does not reference any specific datasets. The cited papers are about methods, not datasets.",
      "processing_time": 54.13438558578491,
      "citing_paper_id": "259370721",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "3) Generative methods, such as BART-Gen (Li et al., 2021), which proposes a sequence-to-sequence paradigm for argument extraction, and PAIE (Ma et al., 2022), which employs a set generation formulation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions generative methods for argument extraction but does not reference any specific datasets. The cited papers are about methods, not datasets.",
      "processing_time": 54.13438558578491,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": ", 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing document-level inductive bias and implicit event argument extraction.",
      "processing_time": 53.92085313796997,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "4) Methods using extra supervisions, for example, FEAE (Wei et al., 2021), which adopts frame-related knowledge, and TSAR (Xu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets.",
      "processing_time": 53.14777898788452,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "4) Methods using extra supervisions, for example, FEAE (Wei et al., 2021), which adopts frame-related knowledge, and TSAR (Xu et al., 2022), which utilizes abstract meaning representation (AMR) resources.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions methods and resources but does not specify any datasets. The cited papers' titles suggest the use of frame-related knowledge and AMR resources, but these are not datasets.",
      "processing_time": 56.24359893798828,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "4) Methods using extra supervisions, for example, FEAE (Wei et al., 2021), which adopts frame-related knowledge, and TSAR (Xu et al., 2022), which utilizes abstract meaning representation (AMR) resources.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions methods and resources but does not specify any datasets. The cited papers' titles suggest the use of frame-related knowledge and AMR resources, but these are not datasets.",
      "processing_time": 56.24359893798828,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248496614
    },
    {
      "context_text": ", 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers and concepts. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.984764099121094,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "…hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b; Liu et al., 2020; Xu et al., 2022; Liu et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and research works. No clear identifiers for datasets are present.",
      "processing_time": 54.12184453010559,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "…belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.800288677215576,
      "citing_paper_id": "259370721",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "…belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.800288677215576,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.800288677215576,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247417818
    },
    {
      "context_text": "…belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.800288677215576,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "…belt as people rushed … beyond-sentence clues by incorporating hierarchical encoding mechanisms (Du and Cardie, 2020a), generative paradigms (Li et al., 2021; Ma et al., 2022; Du et al., 2022), and document-level inductive bias (Wei et al., 2021; Pouran Ben Veyseh et al., 2022; Liu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.800288677215576,
      "citing_paper_id": "259370721",
      "cited_paper_id": 252391326
    },
    {
      "context_text": ", 2021), which proposes a sequence-to-sequence paradigm for argument extraction, and PAIE (Ma et al., 2022), which employs a set generation formulation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions PAIE, which is a method for event argument extraction, not a dataset. No datasets are explicitly mentioned.",
      "processing_time": 54.11763000488281,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…Lin, 2019) 7.5 QAEE (Du and Cardie, 2020b) 28.0 DocMRC (Liu et al., 2021) 55.0 FEAE (Wei et al., 2021) 56.3 BART-Gen (Li et al., 2021) 14.0 PAIE (Ma et al., 2022) 11.1 Our Method 33.5 where the concatenation operator of the vector h T ∈ R d and the matrix H B ∈ R M × d is performed by ﬁrst…",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and scores. The cited paper title 'PAIE: Prompting Argument Interaction for Event Argument Extraction' confirms that PAIE is a method, not a dataset.",
      "processing_time": 57.681938886642456,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "…context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and Cardie, 2020b;…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in prior studies. No clear identifiers for datasets are present.",
      "processing_time": 54.79573321342468,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Currently, it still remains an open problem for effectively capturing such dependencies (Liu et al., 2021, 2022c).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only that capturing certain dependencies remains an open problem. No verifiable resources are named.",
      "processing_time": 54.588310956954956,
      "citing_paper_id": "259370721",
      "cited_paper_id": 247417818
    },
    {
      "context_text": "Currently, it still remains an open problem for effectively capturing such dependencies (Liu et al., 2021, 2022c).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only that capturing certain dependencies remains an open problem. No verifiable resources are named.",
      "processing_time": 54.588310956954956,
      "citing_paper_id": "259370721",
      "cited_paper_id": 252391326
    },
    {
      "context_text": ", 2021), which adopts frame-related knowledge, and TSAR (Xu et al., 2022), which utilizes abstract meaning representation (AMR) resources.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions TSAR, which is a method or tool, not a dataset. No specific datasets are mentioned in the citation context.",
      "processing_time": 54.58655858039856,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248496614
    },
    {
      "context_text": ", 2021), which form the task as a document-based question-answering problem, and MemNet (Du et al., 2022), which uses a memory to store global event information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MemNet, which is a method, not a dataset. No specific datasets are mentioned in the citation context.",
      "processing_time": 54.35391187667847,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "…capturing the document context effectively, prior studies have explored hierarchical encoding mechanisms, generative perspectives (Li et al., 2021; Du et al., 2022; Ma et al., 2022), document-level inductive biases (Wei et al., 2021; Pouran Ben Veyseh et al., 2022), and external resources (Du and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 13.048394441604614,
      "citing_paper_id": "259370721",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "In this case, we do not utilize the broad definition of entity because an event argument is defined to be a noun entity (Walker and Consortium, 2005; Ahn, 2006).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to definitions and concepts.",
      "processing_time": 52.467806339263916,
      "citing_paper_id": "259370721",
      "cited_paper_id": null
    },
    {
      "context_text": "The performance comparison of prompts constructed by the two different strategy on the Strate-gyQA (Geva et al., 2021) and SST-2 (Socher et al., 2013) datasets is illustrated in Figure 4.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "StrategyQA",
        "SST-2"
      ],
      "dataset_descriptions": {
        "StrategyQA": "Used to compare the performance of prompts constructed using different strategies, focusing on implicit reasoning questions.",
        "SST-2": "Used to evaluate sentiment classification performance, comparing different prompting strategies on sentiment analysis tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, StrategyQA and SST-2, which are used for performance comparison of different prompting strategies.",
      "processing_time": 64.00657629966736,
      "citing_paper_id": "265149752",
      "cited_paper_id": 990233
    },
    {
      "context_text": "The performance comparison of prompts constructed by the two different strategy on the Strate-gyQA (Geva et al., 2021) and SST-2 (Socher et al., 2013) datasets is illustrated in Figure 4.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "StrategyQA",
        "SST-2"
      ],
      "dataset_descriptions": {
        "StrategyQA": "Used to compare the performance of prompts constructed using different strategies, focusing on implicit reasoning questions.",
        "SST-2": "Used to evaluate sentiment classification performance, comparing different prompting strategies on sentiment analysis tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, StrategyQA and SST-2, which are used for performance comparison of different prompting strategies.",
      "processing_time": 64.00657629966736,
      "citing_paper_id": "265149752",
      "cited_paper_id": 230799347
    },
    {
      "context_text": "In addressing RQ3 , we have extended our HD-LoA prompting method to sentiment analysis (SA) and natural language inference (NLI) tasks, utilizing the SST-2 (Socher et al., 2013) and SNLI (Bow-man et al., 2015) datasets for evaluation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SST-2",
        "SNLI"
      ],
      "dataset_descriptions": {
        "SST-2": "Used to evaluate the HD-LoA prompting method on sentiment analysis, focusing on fine-grained sentiment classification of movie reviews.",
        "SNLI": "Used to evaluate the HD-LoA prompting method on natural language inference, assessing the ability to determine the relationship between sentence pairs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions SST-2 and SNLI as datasets used for evaluating the HD-LoA prompting method on sentiment analysis and natural language inference tasks.",
      "processing_time": 67.69579339027405,
      "citing_paper_id": "265149752",
      "cited_paper_id": 990233
    },
    {
      "context_text": "Additionally, we utilize the SST-2 (Socher et al., 2013) and SNLI (Bowman et al., 2015) datasets to assess the effectiveness of our HD-LoA prompting strategy on other non-reasoning tasks: sentiment analysis and natural language inference.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SST-2",
        "SNLI"
      ],
      "dataset_descriptions": {
        "SST-2": "Used to evaluate the effectiveness of the HD-LoA prompting strategy on sentiment analysis, assessing model performance on fine-grained sentiment classification.",
        "SNLI": "Used to evaluate the effectiveness of the HD-LoA prompting strategy on natural language inference, assessing model performance on entailment, contradiction, and neutral relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions SST-2 and SNLI datasets, which are used to evaluate the effectiveness of the HD-LoA prompting strategy on sentiment analysis and natural language inference tasks.",
      "processing_time": 70.33547568321228,
      "citing_paper_id": "265149752",
      "cited_paper_id": 990233
    },
    {
      "context_text": "63% on SST-2 and SNLI datasets, respectively.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SST-2",
        "SNLI"
      ],
      "dataset_descriptions": {
        "SST-2": "Used to evaluate sentiment classification performance, focusing on binary sentiment analysis of movie reviews using a treebank structure.",
        "SNLI": "Used to assess natural language inference performance, evaluating the ability to determine the relationship between premise and hypothesis sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions SST-2 and SNLI datasets, which are commonly used in natural language processing for sentiment analysis and natural language inference tasks.",
      "processing_time": 65.90627121925354,
      "citing_paper_id": "265149752",
      "cited_paper_id": 990233
    },
    {
      "context_text": "Cognitive science studies reveals that humans perform analogical reasoning through a sequence of retrieval , mapping , and evaluation (Gentner and Forbus, 2011; Gentner and Markman, 1997).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only cognitive science studies and computational models. No verifiable resources are identified.",
      "processing_time": 54.340975761413574,
      "citing_paper_id": "265149752",
      "cited_paper_id": 3446415
    },
    {
      "context_text": "Cognitive science studies reveals that humans perform analogical reasoning through a sequence of retrieval , mapping , and evaluation (Gentner and Forbus, 2011; Gentner and Markman, 1997).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only cognitive science studies and computational models. No verifiable resources are identified.",
      "processing_time": 54.340975761413574,
      "citing_paper_id": "265149752",
      "cited_paper_id": 16482483
    },
    {
      "context_text": "Similarly, in supervised machine learning (ML) systems, models also learn task-specific patterns through training (Shachaf et al., 2021; Najafabadi et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts about supervised machine learning and pattern learning.",
      "processing_time": 53.537298917770386,
      "citing_paper_id": "265149752",
      "cited_paper_id": 11392154
    },
    {
      "context_text": "For example, students often solve new problems by mapping solutions from known problems (Ross, 1987).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to a general concept of problem-solving.",
      "processing_time": 54.33584117889404,
      "citing_paper_id": "265149752",
      "cited_paper_id": 144823696
    },
    {
      "context_text": "Document-level Event Argument Extraction (EAE) aims to transform unstructured event information from documents into structured formats encapsulating event arguments, facilitating their interpretation and application in various domains (Grishman, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general research area and its goals.",
      "processing_time": 53.099183559417725,
      "citing_paper_id": "265149752",
      "cited_paper_id": 203701085
    },
    {
      "context_text": "EEQA (Du and Cardie, 2020b) 19.54 PAIE (Ma et al., 2022) 29.86 TSAR (Xu et al., 2022) - 26.67 - - CRP (Liu et al., 2023a) 30.09 FewDocAE (Yang et al., RQ2 Can HD-LoA prompting effectively mitigate the dependency on extensive labeled data while enhancing accuracy for EAE task?",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models or methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.944127321243286,
      "citing_paper_id": "265149752",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "EEQA (Du and Cardie, 2020b) 19.54 PAIE (Ma et al., 2022) 29.86 TSAR (Xu et al., 2022) - 26.67 - - CRP (Liu et al., 2023a) 30.09 FewDocAE (Yang et al., RQ2 Can HD-LoA prompting effectively mitigate the dependency on extensive labeled data while enhancing accuracy for EAE task?",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models or methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.944127321243286,
      "citing_paper_id": "265149752",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Additionally, we compare our method with various supervised learning methods in EAE, such as Few-DocAE (Yang et al., 2023), CRP (Liu et al., 2023a), PAIE (Ma et al., 2022), TSAR (Xu et al., 2022), EEQA (Du and Cardie, 2020b), etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several methods/models but does not refer to any specific datasets. The context is focused on comparing different approaches to event argument extraction.",
      "processing_time": 55.37776160240173,
      "citing_paper_id": "265149752",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Additionally, we compare our method with various supervised learning methods in EAE, such as Few-DocAE (Yang et al., 2023), CRP (Liu et al., 2023a), PAIE (Ma et al., 2022), TSAR (Xu et al., 2022), EEQA (Du and Cardie, 2020b), etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several methods/models but does not refer to any specific datasets. The context is focused on comparing different approaches to event argument extraction.",
      "processing_time": 55.37776160240173,
      "citing_paper_id": "265149752",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "The prevalent approach for this task relies on the collection of labeled data and the subsequent model training via supervised learning (Ren et al., 2023; Liu et al., 2023a; Pouran Ben Veyseh et al., 2022; Zhou and Mao, 2022; Du and Cardie, 2020a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach involving labeled data and supervised learning.",
      "processing_time": 53.68014979362488,
      "citing_paper_id": "265149752",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "The prevalent approach for this task relies on the collection of labeled data and the subsequent model training via supervised learning (Ren et al., 2023; Liu et al., 2023a; Pouran Ben Veyseh et al., 2022; Zhou and Mao, 2022; Du and Cardie, 2020a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach involving labeled data and supervised learning.",
      "processing_time": 53.68014979362488,
      "citing_paper_id": "265149752",
      "cited_paper_id": 250390478
    },
    {
      "context_text": "The prevalent approach for this task relies on the collection of labeled data and the subsequent model training via supervised learning (Ren et al., 2023; Liu et al., 2023a; Pouran Ben Veyseh et al., 2022; Zhou and Mao, 2022; Du and Cardie, 2020a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach involving labeled data and supervised learning.",
      "processing_time": 53.68014979362488,
      "citing_paper_id": "265149752",
      "cited_paper_id": 259370571
    },
    {
      "context_text": "The experiments are carried out using three large language models: the publicly available GPT-3 (Brown et al., 2020) in its text-davinci-003 and gpt-3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models but does not refer to any specific datasets. The context is about using language models for experiments, not datasets.",
      "processing_time": 54.93787622451782,
      "citing_paper_id": "265149752",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "In this context, in-context learning (ICL) (Brown et al., 2020; Liu et al., 2022; Zhou et al., 2022), an emergent ability of large language models (LLMs), offers a promising alternative to supervised learning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 55.14364695549011,
      "citing_paper_id": "265149752",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "In this context, in-context learning (ICL) (Brown et al., 2020; Liu et al., 2022; Zhou et al., 2022), an emergent ability of large language models (LLMs), offers a promising alternative to supervised learning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 55.14364695549011,
      "citing_paper_id": "265149752",
      "cited_paper_id": 248986239
    },
    {
      "context_text": "We use 500 test samples from the StrategyQA (Geva et al., 2021) dataset and the prompt from Shum et al. (2023) for evaluation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "StrategyQA"
      ],
      "dataset_descriptions": {
        "StrategyQA": "Used to evaluate 500 test samples, focusing on implicit reasoning strategies in question answering."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the StrategyQA dataset, which is a specific, verifiable resource. The dataset is used for evaluating test samples, and the citation intent is to reference a reusable resource.",
      "processing_time": 61.29969882965088,
      "citing_paper_id": "265149752",
      "cited_paper_id": 230799347
    },
    {
      "context_text": "The WIKIEVENTS dataset (Li et al., 2021) is excluded from our study because it relies on preprocessed entity candidates for annotating event arguments the annotation, which diverges from the direct ar-gument identification of LLMs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKIEVENTS"
      ],
      "dataset_descriptions": {
        "WIKIEVENTS": "Excluded from the study due to reliance on preprocessed entity candidates, which diverges from the direct argument identification approach of LLMs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the WIKIEVENTS dataset and explains why it is excluded from the study, providing a clear reason related to its preprocessing method.",
      "processing_time": 62.661274671554565,
      "citing_paper_id": "265149752",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "The ICL performance is highly sensitive to the design of in-context demonstrations, such as the selection of examples and the formatting of reasoning steps (Zhang et al., 2023, 2022; Fu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the sensitivity of ICL performance to in-context demonstrations.",
      "processing_time": 53.851375341415405,
      "citing_paper_id": "265149752",
      "cited_paper_id": 246426909
    },
    {
      "context_text": "For evaluation, we follow the metrics in (Ma et al., 2022), namely the argument identification F1 score (Arg-I), and the argument classification F1 score (Arg-C).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. The context is focused on the metrics used for evaluation rather than the datasets.",
      "processing_time": 55.3660991191864,
      "citing_paper_id": "265149752",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "The example selection process of ICL is often an indiscriminate, manual process (Liu et al., 2023b; Wei et al., 2022; Zhou et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or processes. There are no clear identifiers for datasets in the context.",
      "processing_time": 29.99199914932251,
      "citing_paper_id": "265149752",
      "cited_paper_id": 248986239
    },
    {
      "context_text": "Neverthe-less, HD-LoA prompting demonstrates competitive performance against supervised methods and even outperform these extensively trained models on the DocEE dataset in the cross-domain setting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to evaluate the performance of HD-LoA prompting in a cross-domain setting, specifically comparing it against supervised methods and extensively trained models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocEE dataset' which is a specific dataset used for document-level event extraction. The dataset is used to evaluate the performance of HD-LoA prompting in a cross-domain setting.",
      "processing_time": 63.81477403640747,
      "citing_paper_id": "265149752",
      "cited_paper_id": 250264890
    },
    {
      "context_text": "Therefore, un-derstandings of supervised ML systems (e.g. pattern learning) are not applicable for ICL (Min et al., 2022; Akyürek et al., 2022), which necessitates distinct explorations on the mechanism of ICL.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to supervised ML systems and ICL. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 56.1715133190155,
      "citing_paper_id": "265149752",
      "cited_paper_id": 254043800
    },
    {
      "context_text": "Table 5 shows how different components in ProCNet contribute to performance: − Hypernetwork Hypernetwork is removed by replacing GNN-FiLM with RGCN (Schlichtkrull et al., 2018), where all proxy nodes in RGCN share the same message-passing function.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RGCN) and a model (GNN-FiLM).",
      "processing_time": 55.1240758895874,
      "citing_paper_id": "258967833",
      "cited_paper_id": 5458500
    },
    {
      "context_text": "(13) can be computed efficiently with (Ramakrishnan et al., 1991; Bertsekas, 1981).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods or algorithms.",
      "processing_time": 52.03988599777222,
      "citing_paper_id": "258967833",
      "cited_paper_id": 11246193
    },
    {
      "context_text": "As the standard Hausdorff distance is highly sensitive to outliers, we use the average Hausdorff distance (Schütze et al., 2012; Taha and Hanbury, 2015): However, in our task, the average Hausdorff distance could suffer a problem that a predicted event, represented by a proxy node, may be guided to…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a performance measure. The context is about a methodological choice in evaluating predicted events.",
      "processing_time": 55.118799686431885,
      "citing_paper_id": "258967833",
      "cited_paper_id": 22130590
    },
    {
      "context_text": "Two variants of DCFEE are DCFEE-O for single-event and DCFEE-M for multi-event.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only variants of a system. The title suggests the use of training data but does not specify a dataset name.",
      "processing_time": 55.343708515167236,
      "citing_paper_id": "258967833",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Yang et al. (2018) proposed a key-event detection model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model proposed by Yang et al. (2018).",
      "processing_time": 54.90613126754761,
      "citing_paper_id": "258967833",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "We can observe that a simple argument completion strategy (DCFEE-O and DCFEE-M) produces the worst results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DCFEE) and its performance. No verifiable resources are identified.",
      "processing_time": 54.51601481437683,
      "citing_paper_id": "258967833",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "More implementation details are in Appendix A.2 Baselines The baselines that we compare with are as follows: DCFEE (Yang et al., 2018) uses an argument-completion strategy in the table-filling task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DCFEE) and its approach. The context is about comparing baselines, not using datasets.",
      "processing_time": 56.3481764793396,
      "citing_paper_id": "258967833",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Finally, Hausdorff Distance Minimization minimizes the distance between the set of predicted events and the set of ground-truth events to perform a global training in the new event-level metric space. on joint-learning of the two sub-tasks (Nguyen and Nguyen, 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the methodology of joint-learning and the use of Hausdorff Distance Minimization.",
      "processing_time": 56.77012252807617,
      "citing_paper_id": "258967833",
      "cited_paper_id": 54437926
    },
    {
      "context_text": "Much research has been done on sentence-level event extraction (Du and Cardie, 2020; Lin et al., 2020; Lu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to prior research on sentence-level event extraction.",
      "processing_time": 54.27889895439148,
      "citing_paper_id": "258967833",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Recently, multi-turn Question-Answer (QA) methods have been investigated for EE with hand-designed or automatically generated questions (Du and Cardie, 2020; Li et al., 2020; Wang et al., 2020; Liu et al., 2020; Lyu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.71138262748718,
      "citing_paper_id": "258967833",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "More recently, prompt-based learning has been explored using the knowledge in pre-trained language models (Lin et al., 2021; Hsu et al., 2021; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 55.332277059555054,
      "citing_paper_id": "258967833",
      "cited_paper_id": 237499254
    },
    {
      "context_text": "More recently, prompt-based learning has been explored using the knowledge in pre-trained language models (Lin et al., 2021; Hsu et al., 2021; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 55.332277059555054,
      "citing_paper_id": "258967833",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "To address the problem, conditional generation have been proposed, which are conditioned on pre-specified templates or prompts (Du et al., 2021; Huang et al., 2021; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 55.5499382019043,
      "citing_paper_id": "258967833",
      "cited_paper_id": 237499254
    },
    {
      "context_text": "To address the problem, conditional generation have been proposed, which are conditioned on pre-specified templates or prompts (Du et al., 2021; Huang et al., 2021; Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 55.5499382019043,
      "citing_paper_id": "258967833",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Existing approaches (Zheng et al., 2019; Yang et al., 2021; Huang and Jia, 2021; Xu et al., 2021; Liang et al., 2022) usually involve two steps: (1) first model the entity interactions based on contextual representations; (2) then design a decoding strategy to decode the entity interactions into events and arguments.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to existing approaches and their methodologies. No verifiable resources are identified.",
      "processing_time": 55.546122312545776,
      "citing_paper_id": "258967833",
      "cited_paper_id": 244119148
    },
    {
      "context_text": "For ChFinAnn, the baseline results are reported in (Zheng et al., 2019; Yang et al., 2021; Xu et al., 2021; Zhu et al., 2022; Liang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers. No dataset names are provided in the context.",
      "processing_time": 55.08939337730408,
      "citing_paper_id": "258967833",
      "cited_paper_id": 245123950
    },
    {
      "context_text": "PTPCG (Zhu et al., 2022) combines event arguments together in a non-autoregressive decoding approach with pruned complete graphs, aiming to consume lower computational resources.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (PTPCG) and its purpose. The title confirms it is about a method, not a dataset.",
      "processing_time": 56.136751890182495,
      "citing_paper_id": "258967833",
      "cited_paper_id": 245123950
    },
    {
      "context_text": "For ChFinAnn, the base-line results are reported in (Zheng et al., 2019; Yang et al., 2021; Xu et al., 2021; Zhu et al., 2022; Liang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers. No dataset names are provided in the context.",
      "processing_time": 55.08451437950134,
      "citing_paper_id": "258967833",
      "cited_paper_id": 245123950
    },
    {
      "context_text": "Lu et al. (2022a) captured event clues as a series of intermediate results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for capturing event clues. No verifiable resources are identified.",
      "processing_time": 35.112590074539185,
      "citing_paper_id": "258967833",
      "cited_paper_id": 248371142
    },
    {
      "context_text": "Apart from QA-based approaches, sequence-to-sequence learning has also been explored, where the event annotation is flattened as a sequence (Paolini et al., 2021; Lu et al., 2021; Li et al., 2021; Lu et al., 2022b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers exploring sequence-to-sequence learning for event annotation.",
      "processing_time": 55.08372116088867,
      "citing_paper_id": "258967833",
      "cited_paper_id": 248371142
    },
    {
      "context_text": "In traditional event extraction tasks, researchers focused more on extracting information from individual sentences, such as Nguyen [1], Yang [2], Chen [3], Huang [4], Yang [5], Liu [6] and etc.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various researchers' works. No verifiable resources are identified.",
      "processing_time": 55.31328320503235,
      "citing_paper_id": "267126385",
      "cited_paper_id": 1240016
    },
    {
      "context_text": "In traditional event extraction tasks, researchers focused more on extracting information from individual sentences, such as Nguyen [1], Yang [2], Chen [3], Huang [4], Yang [5], Liu [6] and etc.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various researchers' works. No verifiable resources are identified.",
      "processing_time": 55.31328320503235,
      "citing_paper_id": "267126385",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "In traditional event extraction tasks, researchers focused more on extracting information from individual sentences, such as Nguyen [1], Yang [2], Chen [3], Huang [4], Yang [5], Liu [6] and etc.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various researchers' works. No verifiable resources are identified.",
      "processing_time": 55.31328320503235,
      "citing_paper_id": "267126385",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "In sentence-level event extraction, Chen et al. [9] used DMCNN to capture sentence-level and word-level features to improve the effect of event extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DMCNN) used for event extraction. The citation is focused on the method rather than a dataset.",
      "processing_time": 56.587870359420776,
      "citing_paper_id": "267126385",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Zhang et al. [7] proposed a two-step strategy that first matches the central word of the argument using the trigger, and then extends the central word to the left or right to obtain the complete argument span.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event argument detection.",
      "processing_time": 53.607163429260254,
      "citing_paper_id": "267126385",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "The both methods have played a certain role in document-level event extraction tasks, but Zhang's method utilizes too little effective information, only establishing a connection between the trigger and the argument [7].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method by Zhang. The context focuses on the effectiveness of the method in document-level event extraction tasks.",
      "processing_time": 56.58228945732117,
      "citing_paper_id": "267126385",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Zhang et al. [7] proposed a two-step strategy model, first using the trigger word to find the head word of the argument through bi-affine, and assuming that the head word can represent the complete meaning of the argument.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event argument detection.",
      "processing_time": 53.78675603866577,
      "citing_paper_id": "267126385",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "In sentence-level event extraction, Ma et al. [19] capture the relationship between trigger and event arguments by modifying the attention heads of the Transformer.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event argument extraction.",
      "processing_time": 53.781163454055786,
      "citing_paper_id": "267126385",
      "cited_paper_id": 222177108
    },
    {
      "context_text": "Paolini et al. [15] propose TANL to handle a variety of structured prediction tasks, including EAE, by a unified text-to-text approach and extract all arguments in a single pass.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (TANL) for handling structured prediction tasks, including Event Argument Extraction (EAE).",
      "processing_time": 56.907182693481445,
      "citing_paper_id": "267126385",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "In document-level event extraction, Du et al. [17] and Li et al. [18] transform the extraction task into a generation task by designing specific templates for each event type respectively, using BERT and BART models to handle document-level event extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 55.87849426269531,
      "citing_paper_id": "267126385",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "In document-level event extraction, Du et al. [17] and Li et al. [18] transform the extraction task into a generation task by designing specific templates for each event type respectively, using BERT and BART models to handle document-level event extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 55.87849426269531,
      "citing_paper_id": "267126385",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Li et al. [18] proposed a BART-based generative model BART-Gen, and for each event type, manually created a corresponding generation template, and blanked out the arguments that needed to be identified and played a certain role in the template , and finally regenerated the entire template to fill…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BART-Gen) and a process for creating templates. No verifiable datasets are referenced.",
      "processing_time": 56.90625548362732,
      "citing_paper_id": "267126385",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "In sentence-level event extraction, Tong et al. [22] introduce open-domain trigger knowledge, and Wang et al. [23] learn event extraction knowledge from large unsupervised databases and semantic structures.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general references to 'large unsupervised databases' which are too generic.",
      "processing_time": 55.667513370513916,
      "citing_paper_id": "267126385",
      "cited_paper_id": 235254286
    },
    {
      "context_text": "Lu et al. [16] follow TANL and convert the event extraction task into an end-to-end event generation task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach for event extraction.",
      "processing_time": 53.59002232551575,
      "citing_paper_id": "267126385",
      "cited_paper_id": 235458429
    },
    {
      "context_text": "Wei et al. [27] proposed a frame-known event argument extraction learning framework FEAE, by designing event templates, identifying and classifying arguments in the way of boundary detection according to the order of the templates.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or framework called FEAE. No verifiable resources are identified.",
      "processing_time": 55.87006735801697,
      "citing_paper_id": "267126385",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "How to further use large scale language models as encoder for event identification and arguments extraction has attracted the attention of researchers [28] [29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of large-scale language models for event identification and argument extraction.",
      "processing_time": 54.8465633392334,
      "citing_paper_id": "267126385",
      "cited_paper_id": 257050669
    },
    {
      "context_text": "Most of them cast event extraction as a classification problem, using global features to capture dependencies among local classifiers and applying joint inference [12, 14, 17, 20, 21, 24].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general approaches to event extraction. No dataset names are present in the text.",
      "processing_time": 56.09837579727173,
      "citing_paper_id": "265452030",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "Most of them cast event extraction as a classification problem, using global features to capture dependencies among local classifiers and applying joint inference [12, 14, 17, 20, 21, 24].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general approaches to event extraction. No dataset names are present in the text.",
      "processing_time": 56.09837579727173,
      "citing_paper_id": "265452030",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Most of them cast event extraction as a classification problem, using global features to capture dependencies among local classifiers and applying joint inference [12, 14, 17, 20, 21, 24].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general approaches to event extraction. No dataset names are present in the text.",
      "processing_time": 56.09837579727173,
      "citing_paper_id": "265452030",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "During training, we used the Adam [10] optimizer with a learning rate of 1 𝑒 -4 for 100 epochs.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Adam optimizer, which is a method, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 55.859546184539795,
      "citing_paper_id": "265452030",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "In Zheng et al. [26] a transformer-based end-to-end model is proposed to solve the DEE problem by filling the event tables with an entity-based directed acyclic graph.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for solving the DEE problem.",
      "processing_time": 54.834335803985596,
      "citing_paper_id": "265452030",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Further, we perform entity recognition as a sequence tagging task with BIO (Begin, Inside, Other) schema using 1 𝑁 𝑤 𝑖 as the input like Zheng et al. [26].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for entity recognition. No dataset names are provided in the context.",
      "processing_time": 55.85869765281677,
      "citing_paper_id": "265452030",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Researchers attempt to conduct DEE in a more realistic trigger-free on the ChFinAnn dataset [26], where event types are directly predicted based on the document semantics.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used for document-level event extraction in a trigger-free setting, focusing on predicting event types based on document semantics in Chinese financial documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'ChFinAnn dataset' which is a specific dataset used for Chinese financial event extraction. The dataset is used for document-level event extraction in a trigger-free setting.",
      "processing_time": 63.57680821418762,
      "citing_paper_id": "265452030",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "We evaluate our method on the public dataset ChFinAnn collected by Zheng et al. [26].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used to evaluate the proposed method for document-level event extraction in Chinese financial documents, focusing on the accuracy and effectiveness of the framework."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ChFinAnn' as a public dataset used for evaluation, which fits the criteria for a specific, verifiable dataset.",
      "processing_time": 20.243383407592773,
      "citing_paper_id": "265452030",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "(2) [Event Role Embeddings]: As predefined by the event extraction task [26], each record is composed of 𝑁 𝑟𝐸 𝑖 event roles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or framework for event role embeddings.",
      "processing_time": 54.830321073532104,
      "citing_paper_id": "265452030",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "For example, the Doc2EDAG model [26] uses a directed acyclic graph to combine arguments, which can be both computationally and memory-consuming.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (Doc2EDAG) and its computational aspects. No verifiable resources are identified.",
      "processing_time": 57.08483076095581,
      "citing_paper_id": "265452030",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Doc2EDAG Zheng et al. [26] proposed an end-to-end model for DEE that employs a transformer encoder to obtain sentence and entity embeddings and approaches DEE by directly filling event tables with entity-based path expending.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Doc2EDAG) and its application to document-level event extraction.",
      "processing_time": 55.84286332130432,
      "citing_paper_id": "265452030",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "For fair comparisons, we adopt the same evaluation standard used in Doc2EDAG [26], and DE-PPN [23].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only other methods for comparison. The context is focused on evaluation standards rather than datasets.",
      "processing_time": 56.69389295578003,
      "citing_paper_id": "265452030",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "On the other hand, event extraction is viewed as an extractive machine learning comprehension task [4, 11, 15], where models are trained to identify relevant answers to a variety of framing questions for each event component.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general approach to event extraction using machine learning. No verifiable resources are named.",
      "processing_time": 56.86826467514038,
      "citing_paper_id": "265452030",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "On the other hand, event extraction is viewed as an extractive machine learning comprehension task [4, 11, 15], where models are trained to identify relevant answers to a variety of framing questions for each event component.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general approach to event extraction using machine learning. No verifiable resources are named.",
      "processing_time": 56.86826467514038,
      "citing_paper_id": "265452030",
      "cited_paper_id": 226262283
    },
    {
      "context_text": "The first group mainly focuses on extracting scattering event arguments in the document [3, 5, 6, 25].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a focus on extracting event arguments. No verifiable resources are named.",
      "processing_time": 55.63196420669556,
      "citing_paper_id": "265452030",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "The first group mainly focuses on extracting scattering event arguments in the document [3, 5, 6, 25].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a focus on extracting event arguments. No verifiable resources are named.",
      "processing_time": 55.63196420669556,
      "citing_paper_id": "265452030",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "The first group mainly focuses on extracting scattering event arguments in the document [3, 5, 6, 25].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a focus on extracting event arguments. No verifiable resources are named.",
      "processing_time": 55.63196420669556,
      "citing_paper_id": "265452030",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "The first group mainly focuses on extracting scattering event arguments in the document [3, 5, 6, 25].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a focus on extracting event arguments. No verifiable resources are named.",
      "processing_time": 55.63196420669556,
      "citing_paper_id": "265452030",
      "cited_paper_id": null
    },
    {
      "context_text": "Recently, there have been developments in using a text generation process for event extraction, which simplifies the event extraction problem [7, 9, 16, 18].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general development in the field of event extraction using text generation.",
      "processing_time": 56.53256392478943,
      "citing_paper_id": "265452030",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "Most recently, a few generation-based event extraction models [7, 9, 16, 18] have been proposed, which generate all arguments and their roles as a way to convert text into a structured form.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets in the text.",
      "processing_time": 56.865294456481934,
      "citing_paper_id": "265452030",
      "cited_paper_id": 231602921
    },
    {
      "context_text": "…role not found in the event schema when generating the Mad Lib, 7 allenai/longformer-base-4096 we may handle this in two ways: (i) we can use SBERT (Reimers and Gurevych, 2019), a popular textual embedding method, to encode the hal-lucinated category name and compute the cosine similarity between…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (SBERT) which is excluded according to the rules.",
      "processing_time": 56.68568134307861,
      "citing_paper_id": "268253036",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "Our matching algorithm compares the argument in the synthetic event structure with every possible n-gram (up to n=20) in the document and returns the n-gram with the highest cosine similarity using SBERT 4 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (SBERT) for comparing n-grams in a document. No verifiable datasets are referenced.",
      "processing_time": 57.92098879814148,
      "citing_paper_id": "268253036",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "For example, if the LLM invents a new role not found in the event schema when generating the Mad Lib, 7 allenai/longformer-base-4096 we may handle this in two ways: (i) we can use SBERT (Reimers and Gurevych, 2019), a popular textual embedding method, to encode the hal-lucinated category name and compute the cosine similarity between it and all possible role names for a given sample.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (SBERT) for encoding and comparing category names.",
      "processing_time": 56.68166995048523,
      "citing_paper_id": "268253036",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "We embed each role in each set using S-BERT (Reimers and Gurevych, 2019) to get a set of source role embeddings S and a set of target role embed-dings T .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions S-BERT, which is a method for generating sentence embeddings, not a dataset. No datasets are explicitly mentioned or used in the given context.",
      "processing_time": 58.090439796447754,
      "citing_paper_id": "268253036",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "MTF augments DocEE documents by masking a single contiguous span of non-annotated text in each document and infilling the mask using a T5 (Raffel et al., 2020) model fine-tuned on the Gi-gaword corpus (Graff et al., 2003).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Gi-gaword corpus"
      ],
      "dataset_descriptions": {
        "Gi-gaword corpus": "Used to fine-tune a T5 model for infilling masked spans in documents, enhancing the model's ability to generate coherent text for document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the Gi-gaword corpus, which is a specific dataset used for fine-tuning a T5 model. The corpus is clearly identified and used in the context of augmenting documents for event extraction.",
      "processing_time": 68.01817083358765,
      "citing_paper_id": "268253036",
      "cited_paper_id": 204838007
    },
    {
      "context_text": "The few prior works in DocEAE augmentation do not generate new data samples but rather augment existing samples (Liu et al., 2022) or use a pre-trained model to weakly label unannotated corpora (Liu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for data augmentation in document-level event argument extraction.",
      "processing_time": 57.05938100814819,
      "citing_paper_id": "268253036",
      "cited_paper_id": 243865143
    },
    {
      "context_text": "The few prior works in DocEAE augmentation do not generate new data samples but rather augment existing samples (Liu et al., 2022) or use a pre-trained model to weakly label unannotated corpora (Liu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for data augmentation in document-level event argument extraction.",
      "processing_time": 57.05938100814819,
      "citing_paper_id": "268253036",
      "cited_paper_id": 252391326
    },
    {
      "context_text": "In (Liu et al., 2021), they use pre-trained EAE models to silver-label (i.e. use a pre-trained model to annotate) unannotated documents as additional data augmentation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'unannotated documents' but does not specify a named dataset. The citation is about using pre-trained models for data augmentation, not a specific dataset.",
      "processing_time": 58.549391984939575,
      "citing_paper_id": "268253036",
      "cited_paper_id": 243865143
    },
    {
      "context_text": "A key issue in the FSCD DocEAE problem is the need to model 0-shot roles (Yang et al., 2023a), i.e. roles which exist in an event’s schema and thus might appear in the test set, but have no representation in the training data.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to 'training data' and 'test set'. No multi-word proper nouns, acronyms, or other specific identifiers are present.",
      "processing_time": 59.95251250267029,
      "citing_paper_id": "268253036",
      "cited_paper_id": 252090194
    },
    {
      "context_text": "For this reason, other recent works have chosen to focus their attention on DocEE (Yang et al., 2023a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'DocEE' but does not provide enough context to determine if it is a dataset, method, or tool. The title of the cited paper suggests it is a method or tool for document-level event argument extraction.",
      "processing_time": 60.98831558227539,
      "citing_paper_id": "268253036",
      "cited_paper_id": 252090194
    },
    {
      "context_text": "Recent works such as (Tong et al., 2022; Yang et al., 2023a) have shown that extracting event arguments from long documents given limited training data in a new domain remains extremely challenging.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the challenge of extracting event arguments from long documents with limited training data in a new domain.",
      "processing_time": 58.07909035682678,
      "citing_paper_id": "268253036",
      "cited_paper_id": 252090194
    },
    {
      "context_text": "In (Liu et al., 2022), they use pre-trained language models to augment existing samples by masking annotated argument spans and then generating alternate ones.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of pre-trained language models for data augmentation. No clear, verifiable dataset names are present.",
      "processing_time": 58.541085958480835,
      "citing_paper_id": "268253036",
      "cited_paper_id": 252391326
    },
    {
      "context_text": "We note that the use of two baseline methods is in-line with prior works on data augmentation for Event Extraction (Gao et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only baseline methods for data augmentation in Event Extraction.",
      "processing_time": 12.004223346710205,
      "citing_paper_id": "268253036",
      "cited_paper_id": 255522592
    },
    {
      "context_text": "Event Argument Extraction (EAE) is a challenging subtask of the Event Extraction (EE) problem, where the goal is to (i) identify which event(s) occur in the text and (ii) extract event arguments from the text as a structure.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only describes the task of Event Argument Extraction. No dataset names are present in the text.",
      "processing_time": 58.226786613464355,
      "citing_paper_id": "268253036",
      "cited_paper_id": 255522592
    },
    {
      "context_text": "Gao et al. (2022) do the opposite by first masking unannotated spans, then using a pre-trained T5 model to replace such spans as data augmentation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for data augmentation. The cited paper title confirms the focus on a method rather than a dataset.",
      "processing_time": 58.06798315048218,
      "citing_paper_id": "268253036",
      "cited_paper_id": 255522592
    },
    {
      "context_text": "For example, many related works in EAE data augmentation such as (Gao et al., 2022; Ma et al., 2023; Wang et al., 2023) only focus on sentence-level tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to related works in event argument extraction data augmentation.",
      "processing_time": 57.651681900024414,
      "citing_paper_id": "268253036",
      "cited_paper_id": 255522592
    },
    {
      "context_text": "This restricts our capacity to evaluate on trigger-dependent EAE baselines (Parekh et al., 2023; Huang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to baselines and evaluation restrictions.",
      "processing_time": 57.03421401977539,
      "citing_paper_id": "268253036",
      "cited_paper_id": 258865260
    },
    {
      "context_text": "This restricts our capacity to evaluate on trigger-dependent EAE baselines (Parekh et al., 2023; Huang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to baselines and evaluation restrictions.",
      "processing_time": 57.03421401977539,
      "citing_paper_id": "268253036",
      "cited_paper_id": null
    },
    {
      "context_text": "In recent years, there has been considerable progress in the domain of Event Argument Extraction (EAE), as advances in question answering (Du and Cardie, 2020), prompt tuning (Ma et al., 2022), and semantic graph modeling (Yang et al., 2023b) have led to state-of-the-art results on EAE benchmarks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only advancements in methods and benchmarks. No clear, verifiable datasets are identified.",
      "processing_time": 58.215553760528564,
      "citing_paper_id": "268253036",
      "cited_paper_id": 258967387
    },
    {
      "context_text": "We use an implementation of F1 score for EAE from the OmniEvent library (Peng et al., 2023).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the use of an implementation of F1 score from the OmniEvent library, which is a method or tool, not a dataset.",
      "processing_time": 58.68192958831787,
      "citing_paper_id": "268253036",
      "cited_paper_id": 259137390
    },
    {
      "context_text": "RAMS only uses documents with only 5-sentences and WikiEvents contains annotation for only a limited number of documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for document-level event extraction, focusing on documents with only 5 sentences. The dataset is utilized to train and evaluate models on event extraction tasks.",
        "WikiEvents": "Used for document-level event extraction, containing annotations for a limited number of documents. The dataset is employed to assess the performance of event extraction models."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions two datasets, RAMS and WikiEvents, which are used for document-level event extraction. However, it does not provide specific details about their usage or characteristics.",
      "processing_time": 73.04927921295166,
      "citing_paper_id": "268253036",
      "cited_paper_id": null
    },
    {
      "context_text": "However, RAMS and WikiEvents have significant limitations, as discussed in (Tong et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to highlight limitations in document-level event extraction, focusing on annotation inconsistencies and coverage issues.",
        "WikiEvents": "Used to highlight limitations in document-level event extraction, focusing on annotation inconsistencies and coverage issues."
      },
      "confidence_score": 0.8,
      "reasoning": "The citation mentions RAMS and WikiEvents as having significant limitations, implying they are datasets used in the field of document-level event extraction.",
      "processing_time": 67.0251841545105,
      "citing_paper_id": "268253036",
      "cited_paper_id": null
    },
    {
      "context_text": "More recently, some work has focused on document-level datasets such as RAMS (Ebner et al., 2020), WikiEvents (Li et al., 2021), and DocEE (Tong et al., 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents",
        "DocEE"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to study document-level event extraction, focusing on complex event structures and their relationships within documents.",
        "WikiEvents": "Applied to explore document-level event extraction, emphasizing the identification of events and their arguments across multiple sentences.",
        "DocEE": "Utilized to investigate document-level event extraction, particularly in the context of financial documents and regulatory filings."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets relevant to document-level event extraction, which are clearly named and used in the research context.",
      "processing_time": 72.82011127471924,
      "citing_paper_id": "268253036",
      "cited_paper_id": null
    },
    {
      "context_text": "For example, (Huang et al., 2023) proposed a new metric (ARG-I+) for trigger-based event extraction to better capture whether a role is associated with the correct trigger.",
      "catation_intent": "research work",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a new metric for trigger-based event extraction.",
      "processing_time": 57.63714003562927,
      "citing_paper_id": "268253036",
      "cited_paper_id": null
    },
    {
      "context_text": "Chen et al. (2015) ﬁrstly propose a neural pipeline model to extract events, while Nguyen et al. (2016) utilize a joint model to mitigate error propagation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on describing different approaches to event extraction.",
      "processing_time": 58.67061424255371,
      "citing_paper_id": "248496614",
      "cited_paper_id": 6452487
    },
    {
      "context_text": "Li et al. (2014) and Judea and Strube (2016) use handcrafted features to extract events from the sentence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of handcrafted features for event extraction.",
      "processing_time": 57.872618198394775,
      "citing_paper_id": "248496614",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "In our implementation, we use BERT base (Devlin et al., 2019) and RoBERTa large (Liu et al., 2019) as our backbone encoder for T SAR , with global and local encoders sharing parameters.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and RoBERTa but does not refer to them as datasets. They are models used as backbone encoders.",
      "processing_time": 58.87046408653259,
      "citing_paper_id": "248496614",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In our implementation, we use BERTbase (Devlin et al., 2019) and RoBERTalarge (Liu et al.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERTbase and RoBERTalarge, which are models, not datasets. No datasets are explicitly mentioned or used according to the given citation span.",
      "processing_time": 59.911582708358765,
      "citing_paper_id": "248496614",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Some studies first identify entities in the document, followed by assigning these entities as specific argument roles (Yang et al., 2018; Zheng et al., 2019; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 58.66269540786743,
      "citing_paper_id": "248496614",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Some studies ﬁrst identify entities in the document, followed by assigning these entities as speciﬁc argument roles (Yang et al., 2018; Zheng et al., 2019; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches for event extraction. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.907639503479004,
      "citing_paper_id": "248496614",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Some studies ﬁrst identify entities in the document, followed by assigning these entities as speciﬁc argument roles (Yang et al., 2018; Zheng et al., 2019; Xu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches for event extraction. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.907639503479004,
      "citing_paper_id": "248496614",
      "cited_paper_id": 202539732
    },
    {
      "context_text": "Data augmentation is also considered (Yang et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to data augmentation. No verifiable resources are identified.",
      "processing_time": 58.65772581100464,
      "citing_paper_id": "248496614",
      "cited_paper_id": 196178503
    },
    {
      "context_text": "From the global perspective, we first construct the global AMR graphs by fully connecting the root nodes of AMR graphs of different sentences, since the root nodes contain the core semantics according to the AMR core-semantic principle (Cai and Lam, 2019) 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological approach to constructing global AMR graphs.",
      "processing_time": 58.19072461128235,
      "citing_paper_id": "248496614",
      "cited_paper_id": 202542357
    },
    {
      "context_text": "436 These results suggest that encoding the document 437 in a two-stream way, and introducing AMR graphs 438 to facilitate interactions, is beneficial to capturing 439\n2We use TSARlarge based on RoBERTalarge to compare with BART-Gen based on BARTlarge, as they are pre-trained on the same corpus with the same batch size and training steps.\nintra-sentential and inter-sentential features, and440 thus improves the performance.441 Moreover, we follow Li et al. (2021) to evaluate442 both argument identification and argument classifi-443 cation, and report the Head F1 and Coref F1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The focus is on comparing different model architectures and their performance on argument identification and classification.",
      "processing_time": 60.05687069892883,
      "citing_paper_id": "248496614",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "5) BART-Gen (Li et al., 2021) for- 423 mulate the task as a sequence-to-sequence task and 424 uses BARTlarge (Lewis et al., 2020) to generate 425 corresponding arguments in a predefined format.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BARTlarge) used for generating arguments. The context focuses on the methodology rather than a dataset.",
      "processing_time": 15.62519645690918,
      "citing_paper_id": "248496614",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "BERT-QA and BERT-QA-Doc extract run on sentence-level and document-level, respectively.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (BERT-QA and BERT-QA-Doc). No verifiable resources are identified.",
      "processing_time": 59.634100914001465,
      "citing_paper_id": "248496614",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "4) BERT-QA (Du and Cardie, 2020c) a QA-based model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT-QA, which is a model, not a dataset. No datasets are explicitly mentioned or used in the given citation context.",
      "processing_time": 60.04702663421631,
      "citing_paper_id": "248496614",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "4) BERT-QA (Du and Cardie, 2020c) is also a QA-based model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model called BERT-QA. The title 'Event Extraction by Answering (Almost) Natural Questions' does not provide additional information about datasets.",
      "processing_time": 61.73523211479187,
      "citing_paper_id": "248496614",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "with BIO-schema (Du and Cardie, 2020a; Veyseh et al., 2021), while span-based methods predict the argument role for candidate text spans which usually have a maximum length limitation (Ebner et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is focused on describing different methodologies for event role filler extraction.",
      "processing_time": 60.04516124725342,
      "citing_paper_id": "248496614",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "Tagging-based methods directly conduct se- 162 quence labeling for each token in the document 163 with BIO-schema (Du and Cardie, 2020a; Veyseh 164 et al., 2021), while span-based methods predict the 165 argument role for candidate text spans which usu- 166 ally have a maximum length limitation (Ebner et al., 167\n2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 59.28687644004822,
      "citing_paper_id": "248496614",
      "cited_paper_id": 218630327
    },
    {
      "context_text": "2) Two-Step (Zhang et al., 2020b) is a span-based method, which ﬁrst identiﬁes the head word of possible argument span, and then extends to the full span.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes a method (Two-Step) rather than a dataset. No specific dataset is mentioned or used in the described research.",
      "processing_time": 59.62076759338379,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "2) Two-Step (Zhang et al., 2020b) is a span-based method, which ﬁrst identiﬁes the head word of possible argument span, and then extends to the full span.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes a method (Two-Step) rather than a dataset. No specific dataset is mentioned or used in the described research.",
      "processing_time": 59.62076759338379,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "It helps to transform the unstructured text into structured event knowledge that can be further utilized in recommendation systems (Li et al., 2020), dialogue systems (Zhang et al., 2020a), and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event knowledge transformation. No dataset names are present.",
      "processing_time": 59.6223361492157,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "It helps to transform the unstructured text into structured event knowledge that can be further utilized in recommendation systems (Li et al., 2020), dialogue systems (Zhang et al., 2020a), and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of event knowledge transformation. No dataset names are present.",
      "processing_time": 59.6223361492157,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "2) Two-Step (Zhang et al., 2020b) is a span-based method, which first identifies the head word of possible argument span, and then extends to the full span.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event argument detection.",
      "processing_time": 58.32991600036621,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Instead, span-based methods predict argu-ment roles for candidate spans (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 60.553500175476074,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Instead, span-based methods predict argu-ment roles for candidate spans (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 60.553500175476074,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "Instead, span-based methods predict argument roles for candidate spans (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for predicting argument roles for candidate spans.",
      "processing_time": 58.8346905708313,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Although Two-Step and BART-Gen wrongly predict the place as Iraq and Syria , and Two-Step even fails to extract the Attacker , T SAR manage to extract the cross-sentence arguments.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance. No verifiable resources are identified.",
      "processing_time": 59.425633907318115,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Although Two-Step and BART-Gen wrongly predict the place as Iraq and Syria , and Two-Step even fails to extract the Attacker , T SAR manage to extract the cross-sentence arguments.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance. No verifiable resources are identified.",
      "processing_time": 59.425633907318115,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "Following Zhang et al. (2020b), we report the Span F1 and Head F1 for RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate event extraction models, reporting Span F1 and Head F1 metrics to assess performance in identifying and classifying events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for event extraction. The dataset is used to report performance metrics (Span F1 and Head F1) in the research.",
      "processing_time": 68.65774750709534,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Following Zhang et al. (2020b), we report the Span F1 and Head F1 for RAMS dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate event extraction models, reporting Span F1 and Head F1 metrics to assess performance in identifying and classifying events."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS dataset, which is a specific, verifiable dataset used for event extraction. The dataset is used to report performance metrics (Span F1 and Head F1) in the research.",
      "processing_time": 68.65774750709534,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "…directly conduct sequence labeling for each token in the document End: with BIO-schema (Du and Cardie, 2020a; Veyseh et al., 2021), while span-based methods predict the argument role for candidate text spans which usually have a maximum length limitation (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for event argument detection. No verifiable resources are identified.",
      "processing_time": 60.54335880279541,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "…directly conduct sequence labeling for each token in the document End: with BIO-schema (Du and Cardie, 2020a; Veyseh et al., 2021), while span-based methods predict the argument role for candidate text spans which usually have a maximum length limitation (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for event argument detection. No verifiable resources are identified.",
      "processing_time": 60.54335880279541,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": ", 2021), while span-based methods predict the argument role for candidate text spans which usually have a maximum length limitation (Ebner et al., 2020; Zhang et al., 2020b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methodological approaches. No dataset names are present in the text.",
      "processing_time": 60.320719957351685,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "BERT-CRF TCD and Two-Step TCD refers to adopting Type-Constraint Decoding mechanism as used in (Ebner et al., 2020).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is focused on describing the use of Type-Constraint Decoding mechanisms, which are not datasets.",
      "processing_time": 61.92879509925842,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "BERT-CRF TCD and Two-Step TCD refers to adopting Type-Constraint Decoding mechanism as used in (Ebner et al., 2020).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is focused on describing the use of Type-Constraint Decoding mechanisms, which are not datasets.",
      "processing_time": 61.92879509925842,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": ", 2020), dialogue systems (Zhang et al., 2020a), and so on.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of application. No dataset names are present in the text.",
      "processing_time": 60.315491676330566,
      "citing_paper_id": "248496614",
      "cited_paper_id": 220524732
    },
    {
      "context_text": "Another line of studies reformulate the task as a sequence-to-sequence task (Du et al., 2021a,b; Li et al., 2021), or machine reading comprehension task (Wei et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only reformulations of the task as sequence-to-sequence or machine reading comprehension. No verifiable resources are identified.",
      "processing_time": 61.92498326301575,
      "citing_paper_id": "248496614",
      "cited_paper_id": 231728756
    },
    {
      "context_text": "Another line of studies reformulate the task as a sequence-to-sequence task (Du et al., 2021a,b; Li et al., 2021), or machine reading comprehension task (Wei et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only reformulations of the task as sequence-to-sequence or machine reading comprehension. No verifiable resources are identified.",
      "processing_time": 61.92498326301575,
      "citing_paper_id": "248496614",
      "cited_paper_id": 236460308
    },
    {
      "context_text": ", 2021), or machine reading comprehension task (Wei et al., 2021).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 62.16579055786133,
      "citing_paper_id": "248496614",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "3) FEAE (Wei et al., 2021), Frame-aware Event Argument Extraction, is a concurrent work based on question answering.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a concurrent work and its approach.",
      "processing_time": 59.41108250617981,
      "citing_paper_id": "248496614",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "To better model the interactions among words, Liu et al. (2018); Yan et al. (2019); Ma et al. (2020) make use of the dependency tree, and Wadden et al. (2019) enumer-ates all possible spans and propagate information in the span graph.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 60.68250370025635,
      "citing_paper_id": "248496614",
      "cited_paper_id": 269498086
    },
    {
      "context_text": "As791 the number of AMR relation types is large, which792 results in too many demanded parameters, we fol-793 low Zhang and Ji (2021) to cluster the relation types794 into main categories as shown in Table 5.795\nB Statistics of Datasets796\nThe detailed data statistics of RAMS and797 WikiEvents…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to provide detailed data statistics for document-level event extraction, focusing on the distribution and characteristics of events and relations.",
        "WikiEvents": "Used to provide detailed data statistics for document-level event extraction, focusing on the distribution and characteristics of events and relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS' and 'WikiEvents' as datasets, which are multi-word proper nouns and appear to be specific, verifiable datasets used in the research.",
      "processing_time": 26.34800624847412,
      "citing_paper_id": "248496614",
      "cited_paper_id": null
    },
    {
      "context_text": "We compare our method against various baselines: BiLSTM (Cheng and Miyao, 2017) captures the dependency paths between events.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BiLSTM) and its application to capturing dependency paths between events.",
      "processing_time": 61.06669211387634,
      "citing_paper_id": "278287001",
      "cited_paper_id": 32821791
    },
    {
      "context_text": "LIP (Gao et al., 2019) combines document structure with textual content, identifying nuanced event relations using structural patterns.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'LIP' which is likely a method or model, not a dataset. No specific dataset is mentioned or used in the described research.",
      "processing_time": 61.53731346130371,
      "citing_paper_id": "278287001",
      "cited_paper_id": 109933467
    },
    {
      "context_text": "Experimental results are depicted in Tables 1 and 2, from which we have the following observations: Firstly, the introduce of retriever significantly enhances cross-encoder performance, with BERT and RoBERTa outperforming more complex models like LIP and RichGCN.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and their performance. The context is focused on the experimental results comparing different models.",
      "processing_time": 61.908605098724365,
      "citing_paper_id": "278287001",
      "cited_paper_id": 109933467
    },
    {
      "context_text": "Experimental results are depicted in Tables 1 and 2, from which we have the following observations: Firstly, the introduce of retriever significantly enhances cross-encoder performance, with BERT and RoBERTa outperforming more complex models like LIP and RichGCN.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and their performance. The context is focused on the experimental results comparing different models.",
      "processing_time": 61.908605098724365,
      "citing_paper_id": "278287001",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "Experimental results are depicted in Tables 1 and 2, from which we have the following observations: Firstly, the introduce of retriever significantly enhances cross-encoder performance, with BERT and RoBERTa outperforming more complex models like LIP and RichGCN.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and their performance. The context is focused on the experimental results comparing different models.",
      "processing_time": 61.908605098724365,
      "citing_paper_id": "278287001",
      "cited_paper_id": null
    },
    {
      "context_text": "We employ diverse retrievers (RoBERTa-Large, Liu et al., 2019) and S-BERT (Reimers and Gurevych, 2019)) and classifiers (RoBERTa-Large and T5-Large (Raffel et al., 2020)).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 60.885254859924316,
      "citing_paper_id": "278287001",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "We employ diverse retrievers (RoBERTa-Large, Liu et al., 2019) and S-BERT (Reimers and Gurevych, 2019)) and classifiers (RoBERTa-Large and T5-Large (Raffel et al., 2020)).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 60.885254859924316,
      "citing_paper_id": "278287001",
      "cited_paper_id": null
    },
    {
      "context_text": "Furthermore, the performance with the RoBERTa retriever gains more improvements, even outperforming S-BERT, possibly because RoBERTa are more proficient to leverage deep contextual insights from coreference chains.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 62.296502351760864,
      "citing_paper_id": "278287001",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "Furthermore, the performance with the RoBERTa retriever gains more improvements, even outperforming S-BERT, possibly because RoBERTa are more proficient to leverage deep contextual insights from coreference chains.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 62.296502351760864,
      "citing_paper_id": "278287001",
      "cited_paper_id": null
    },
    {
      "context_text": "BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019) are transformer-based discriminative models, and T5 (Raffel et al., 2020) is a transformer-based generative model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models (BERT, RoBERTa, T5) but does not refer to any specific datasets. The citation is used to describe the models, not to cite datasets.",
      "processing_time": 63.43125343322754,
      "citing_paper_id": "278287001",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019) are transformer-based discriminative models, and T5 (Raffel et al., 2020) is a transformer-based generative model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models (BERT, RoBERTa, T5) but does not refer to any specific datasets. The citation is used to describe the models, not to cite datasets.",
      "processing_time": 63.43125343322754,
      "citing_paper_id": "278287001",
      "cited_paper_id": null
    },
    {
      "context_text": "( 2) For the second stage we employ the representative RoBERTa and T5 cross-encoders.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (RoBERTa and T5). These are excluded as per the instructions.",
      "processing_time": 61.901310443878174,
      "citing_paper_id": "278287001",
      "cited_paper_id": 198953378
    },
    {
      "context_text": "( 2) For the second stage we employ the representative RoBERTa and T5 cross-encoders.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (RoBERTa and T5). These are excluded as per the instructions.",
      "processing_time": 61.901310443878174,
      "citing_paper_id": "278287001",
      "cited_paper_id": null
    },
    {
      "context_text": "Recent progress of ERE has been made based on pre-trained language models (PLMs), utilizing semantic structures (Tran Phu and Nguyen, 2021; Hu et al., 2023), temporal clues (Wen and Ji, 2021), and external knowledge (Liu et al., 2020a; Cao et al., 2021) to enrich the event representations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide additional dataset information.",
      "processing_time": 62.416086196899414,
      "citing_paper_id": "278287001",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "Recent progress of ERE has been made based on pre-trained language models (PLMs), utilizing semantic structures (Tran Phu and Nguyen, 2021; Hu et al., 2023), temporal clues (Wen and Ji, 2021), and external knowledge (Liu et al., 2020a; Cao et al., 2021) to enrich the event representations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide additional dataset information.",
      "processing_time": 62.416086196899414,
      "citing_paper_id": "278287001",
      "cited_paper_id": 236460024
    },
    {
      "context_text": "Previous research has mainly focused on enriching event semantics (Wen and Ji, 2021; and Nguyen, 2021), or exploiting large language models (LLMs) (Peng et al., 2023a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous research and methods. There are no clear identifiers for datasets.",
      "processing_time": 62.41077518463135,
      "citing_paper_id": "278287001",
      "cited_paper_id": 265212914
    },
    {
      "context_text": "…current research faces a unique challenge in inefficient learning and inference because the determination of relationships requires pairwise classification after iterating through all event pairs (Hu et al., 2023; Wang et al., 2024), which inherently exhibits quadratic time complexity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methodological challenges in document-level event extraction.",
      "processing_time": 61.52290916442871,
      "citing_paper_id": "278287001",
      "cited_paper_id": 273185680
    },
    {
      "context_text": "The T5 model with the S-BERT retriever achieves the best performance on all datasets, demonstrating their superior capability in event relation classification and candidate event pair identification.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance. There are no clear identifiers for datasets.",
      "processing_time": 62.137038469314575,
      "citing_paper_id": "278287001",
      "cited_paper_id": null
    },
    {
      "context_text": "We further investigate the impact of the number of candidates retrieved per event ( k ), where S-BERT re-triever and T5 classifier are used on the ESC dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ESC"
      ],
      "dataset_descriptions": {
        "ESC": "Used to evaluate the impact of the number of candidates retrieved per event using S-BERT retriever and T5 classifier, focusing on document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ESC dataset, which is a specific dataset used for evaluating the impact of the number of candidates retrieved per event using S-BERT retriever and T5 classifier.",
      "processing_time": 70.49181365966797,
      "citing_paper_id": "278287001",
      "cited_paper_id": null
    },
    {
      "context_text": "Finally, after fine-tuning the retriever model, particularly S-BERT, the DERE performance can be further improved.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (S-BERT) which is not a dataset.",
      "processing_time": 61.88367557525635,
      "citing_paper_id": "278287001",
      "cited_paper_id": null
    },
    {
      "context_text": "Moreover, prototypical networks (ProtoNet) (Snell et al., 2017) have been proven to be very powerful for solving few-shot problems by representing each category as a prototype in both Vision (Pan et al., 2019; Dong and Xing, 2018) and NLP (Sun et al., 2019; Gao et al., 2019) domains.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers also do not introduce new datasets.",
      "processing_time": 62.404192209243774,
      "citing_paper_id": "252090194",
      "cited_paper_id": 309759
    },
    {
      "context_text": "Moreover, prototypical networks (ProtoNet) (Snell et al., 2017) have been proven to be very powerful for solving few-shot problems by representing each category as a prototype in both Vision (Pan et al., 2019; Dong and Xing, 2018) and NLP (Sun et al., 2019; Gao et al., 2019) domains.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers also do not introduce new datasets.",
      "processing_time": 62.404192209243774,
      "citing_paper_id": "252090194",
      "cited_paper_id": 131774949
    },
    {
      "context_text": "Moreover, prototypical networks (ProtoNet) (Snell et al., 2017) have been proven to be very powerful for solving few-shot problems by representing each category as a prototype in both Vision (Pan et al., 2019; Dong and Xing, 2018) and NLP (Sun et al., 2019; Gao et al., 2019) domains.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers also do not introduce new datasets.",
      "processing_time": 62.404192209243774,
      "citing_paper_id": "252090194",
      "cited_paper_id": 202771953
    },
    {
      "context_text": "In order to adapt to our few-shot setting, inspired by the successful applications of the prototypical network (ProtoNet) (Snell et al., 2017) for meta-learning, we assume there exists one prototypical representation for each argument type.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (ProtoNet) which is not a dataset.",
      "processing_time": 61.21178841590881,
      "citing_paper_id": "252090194",
      "cited_paper_id": 309759
    },
    {
      "context_text": "The ProtoNet approach (Snell et al., 2017) assumes there exists one prototypical representation for each argument class and learns a metric space where categorization is performed by labeling each query term with the value calculated from the distance between prototype representations that are…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (ProtoNet) and its approach to few-shot learning. No verifiable resources are identified.",
      "processing_time": 63.28866720199585,
      "citing_paper_id": "252090194",
      "cited_paper_id": 309759
    },
    {
      "context_text": "This is opposite to joint extraction where the task is to jointly extract all events and their associated arguments all at once (Sha et al., 2018; Yang and Mitchell, 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to event and entity extraction.",
      "processing_time": 61.88256883621216,
      "citing_paper_id": "252090194",
      "cited_paper_id": 2367456
    },
    {
      "context_text": "Few-shot learning (FSL) (Fei-Fei et al., 2006) is proposed to tackle",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (few-shot learning).",
      "processing_time": 61.66017436981201,
      "citing_paper_id": "252090194",
      "cited_paper_id": 6953475
    },
    {
      "context_text": "Different from FSL for single sentences by traditional N -way- K - Shot sampling, a novel N -Way- D -Doc sampling strategy is proposed for our document-level task, as can be seen from the example in Fig.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a sampling strategy for a document-level task. No verifiable resources are identified.",
      "processing_time": 62.95202684402466,
      "citing_paper_id": "252090194",
      "cited_paper_id": 6953475
    },
    {
      "context_text": "Few-shot learning (FSL) (Fei-Fei et al., 2006) is proposed to tackle such limitations to make machine learning models more applicable given limited annotated examples and has been used a lot in the IE area (Han et al., 2018; Ding et al., 2021; Lai et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the concept of few-shot learning and its application in information extraction. The cited papers' titles suggest potential datasets, but they are not explicitly mentioned in the context.",
      "processing_time": 65.30808067321777,
      "citing_paper_id": "252090194",
      "cited_paper_id": 6953475
    },
    {
      "context_text": "Few-shot learning (FSL) (Fei-Fei et al., 2006) is proposed to tackle such limitations to make machine learning models more applicable given limited annotated examples and has been used a lot in the IE area (Han et al., 2018; Ding et al., 2021; Lai et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the concept of few-shot learning and its application in information extraction. The cited papers' titles suggest potential datasets, but they are not explicitly mentioned in the context.",
      "processing_time": 65.30808067321777,
      "citing_paper_id": "252090194",
      "cited_paper_id": 53080736
    },
    {
      "context_text": "Few-shot learning (FSL) (Fei-Fei et al., 2006) is proposed to tackle such limitations to make machine learning models more applicable given limited annotated examples and has been used a lot in the IE area (Han et al., 2018; Ding et al., 2021; Lai et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the concept of few-shot learning and its application in information extraction. The cited papers' titles suggest potential datasets, but they are not explicitly mentioned in the context.",
      "processing_time": 65.30808067321777,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "2020) mainly focuses on sentence-level event extraction, such as the popular ACE2005 (Doddington et al. 2004) dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE2005"
      ],
      "dataset_descriptions": {
        "ACE2005": "Used for sentence-level event extraction, focusing on identifying and classifying events within individual sentences. The dataset provides annotated text for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE2005 dataset, which is a well-known resource for event extraction. The dataset is specifically used for sentence-level event extraction.",
      "processing_time": 72.17987632751465,
      "citing_paper_id": "252090194",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "Previous research (Yang et al., 2019; Tong et al., 2020) mainly focuses on sentence-level event extraction, such as the popular ACE2005 (Dodding-ton et al., 2004) dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE2005"
      ],
      "dataset_descriptions": {
        "ACE2005": "Used for sentence-level event extraction, focusing on identifying events within individual sentences. The dataset provides annotated text for training and evaluating event extraction systems."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ACE2005 dataset, which is a well-known resource for event extraction. The dataset is specifically used for sentence-level event extraction.",
      "processing_time": 21.773167610168457,
      "citing_paper_id": "252090194",
      "cited_paper_id": 9776219
    },
    {
      "context_text": "While other datasets such as WikiEvents (Li et al., 2021) and MUC-4 (Grishman and Sundheim, 1996) only contain extremely limited types and documents, thus not suitable for our settings.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiEvents",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "WikiEvents": "Used to highlight limitations in document-level event extraction, specifically the limited types and documents, making it unsuitable for the current research setting.",
        "MUC-4": "Used to highlight limitations in document-level event extraction, specifically the limited types and documents, making it unsuitable for the current research setting."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions two datasets, WikiEvents and MUC-4, which are both relevant to document-level event extraction. However, they are described as unsuitable for the current research setting due to limited types and documents.",
      "processing_time": 78.98204159736633,
      "citing_paper_id": "252090194",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "0 (Pradhan et al., 2013) named entity recognition corpora, all focus on single sentence-level semantics.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'named entity recognition corpora' but does not specify any particular dataset names. The title 'Towards Robust Linguistic Analysis using OntoNotes' suggests OntoNotes might be relevant, but it is not explicitly mentioned in the context.",
      "processing_time": 67.1213309764862,
      "citing_paper_id": "252090194",
      "cited_paper_id": 14515377
    },
    {
      "context_text": "Many approaches and datasets (Petroni et al., 2018; Hürriyeto˘glu et al., 2021; Giorgi et al., 2021; Zavarella et al., 2022) across diverse domains have been proposed for document-level argument extraction to go beyond single-sentence inference.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation span mentions 'datasets' but does not specify any particular dataset names. It refers to general approaches and datasets across diverse domains, which are not specific enough to be considered verifiable resources.",
      "processing_time": 65.12626552581787,
      "citing_paper_id": "252090194",
      "cited_paper_id": 50771731
    },
    {
      "context_text": "Many approaches and datasets (Petroni et al., 2018; Hürriyeto˘glu et al., 2021; Giorgi et al., 2021; Zavarella et al., 2022) across diverse domains have been proposed for document-level argument extraction to go beyond single-sentence inference.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation span mentions 'datasets' but does not specify any particular dataset names. It refers to general approaches and datasets across diverse domains, which are not specific enough to be considered verifiable resources.",
      "processing_time": 65.12626552581787,
      "citing_paper_id": "252090194",
      "cited_paper_id": 236486186
    },
    {
      "context_text": "There have been growing interests under few-shot settings for named entity recognition (Ding et al., 2021; Das et al., 2022), and relation extraction (Han et al., 2018; Popovic and Färber, 2022) under single-sentence and document-level scenarios.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "Few-NERD"
      ],
      "dataset_descriptions": {
        "FewRel": "Used for few-shot relation classification, providing a large-scale supervised dataset for evaluating few-shot learning models in relation extraction tasks.",
        "Few-NERD": "Used for few-shot named entity recognition, offering a dataset designed to support few-shot learning scenarios in NER tasks."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions few-shot settings for named entity recognition and relation extraction, but does not explicitly mention any specific datasets. The cited paper titles suggest the presence of datasets, but they are not directly referenced in the citation span.",
      "processing_time": 78.4407970905304,
      "citing_paper_id": "252090194",
      "cited_paper_id": 53080736
    },
    {
      "context_text": "There have been growing interests under few-shot settings for named entity recognition (Ding et al., 2021; Das et al., 2022), and relation extraction (Han et al., 2018; Popovic and Färber, 2022) under single-sentence and document-level scenarios.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "Few-NERD"
      ],
      "dataset_descriptions": {
        "FewRel": "Used for few-shot relation classification, providing a large-scale supervised dataset for evaluating few-shot learning models in relation extraction tasks.",
        "Few-NERD": "Used for few-shot named entity recognition, offering a dataset designed to support few-shot learning scenarios in NER tasks."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions few-shot settings for named entity recognition and relation extraction, but does not explicitly mention any specific datasets. The cited paper titles suggest the presence of datasets, but they are not directly referenced in the citation span.",
      "processing_time": 78.4407970905304,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "There have been growing interests under few-shot settings for named entity recognition (Ding et al., 2021; Das et al., 2022), and relation extraction (Han et al., 2018; Popovic and Färber, 2022) under single-sentence and document-level scenarios.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "Few-NERD"
      ],
      "dataset_descriptions": {
        "FewRel": "Used for few-shot relation classification, providing a large-scale supervised dataset for evaluating few-shot learning models in relation extraction tasks.",
        "Few-NERD": "Used for few-shot named entity recognition, offering a dataset designed to support few-shot learning scenarios in NER tasks."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions few-shot settings for named entity recognition and relation extraction, but does not explicitly mention any specific datasets. The cited paper titles suggest the presence of datasets, but they are not directly referenced in the citation span.",
      "processing_time": 78.4407970905304,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248512966
    },
    {
      "context_text": "This way we ideally reduce the risk of only representing many NOTA token by one vector as also pointed by (Allen et al., 2019), since there might be multiple NOTA Prototypes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or concept related to prototypes and NOTA tokens.",
      "processing_time": 62.640552282333374,
      "citing_paper_id": "252090194",
      "cited_paper_id": 60441361
    },
    {
      "context_text": "Moreover, prototypical networks(ProtoNet) (Snell, Swersky, and Zemel 2017) have been proven to be very powerful for solving few-shot problems by representing each category as a prototype in both CV (Pan et al. 2019; Dong and Xing 2018) and NLP (Sun et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (prototypical networks) and its applications in CV and NLP.",
      "processing_time": 63.38623237609863,
      "citing_paper_id": "252090194",
      "cited_paper_id": 131774949
    },
    {
      "context_text": "Event argument extraction (EAE), a sub-task of event extraction, is a fundamental task for many downstream NLP applications in the IE community.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general task in NLP. No verifiable resources are identified.",
      "processing_time": 63.537145376205444,
      "citing_paper_id": "252090194",
      "cited_paper_id": 202771953
    },
    {
      "context_text": "2019; Dong and Xing 2018) and NLP (Sun et al. 2019; Gao et al. 2019) domains.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general domains (NLP and other unspecified domains). There are no specific, verifiable resources mentioned.",
      "processing_time": 64.04409861564636,
      "citing_paper_id": "252090194",
      "cited_paper_id": 202771953
    },
    {
      "context_text": "There has also been research (Deng et al., 2020; Lai et al., 2021; Feng et al., 2020; Lai et al., 2020) for few-shot event extraction within single-sentence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to research papers. The context is about few-shot event extraction within single-sentence, but no datasets are explicitly named.",
      "processing_time": 64.96066117286682,
      "citing_paper_id": "252090194",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "Instead of initializing the NONA vectors by randomly as by (Sabo et al., 2021) or from sampled support sets as in (Popovic and Färber, 2022) and then gradually update them, we adopt a K-means MNAV strategy.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and strategies. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 63.53125524520874,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "Instead of initializing the NONA vectors by randomly as by (Sabo et al., 2021) or from sampled support sets as in (Popovic and Färber, 2022) and then gradually update them, we adopt a K-means MNAV strategy.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and strategies. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 63.53125524520874,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248512966
    },
    {
      "context_text": "We believe that this is a big challenge for few-shot document-level tasks, which is not only a issue for small language models (Sabo et al., 2021) but also true for large models like GPT-3 (Brown et al., 2020) and leave more exploration for future work.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses challenges in few-shot document-level tasks.",
      "processing_time": 62.777870178222656,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "This extremely unbalanced setting is a good testbed for validating the model ability due to its similar distribution of many real-world few-shot problems, as also pointed by (Sabo et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a general setting. No clear, verifiable resource is identified.",
      "processing_time": 63.04279136657715,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "Here we adjust the Multiple NOTA(None-Of-the-Above) Vectors(MNAV) proposed by (Sabo et al., 2021) for few-shot relation extraction to our Few-DocAE since they both face the same issue that the majority labels belong to NOTA.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (MNAV) and a task (few-shot relation extraction).",
      "processing_time": 63.67666840553284,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "Instead of building a new dataset from scratch, we aim at leveraging the existing supervised dataset for reconstructing the instances by a novel N -Way- D -Doc sampling strategy, inspired by similar work (Sabo et al., 2021; Popovic and Färber, 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions leveraging an existing supervised dataset but does not specify the name of the dataset. The cited papers do not provide additional clarity on the dataset name.",
      "processing_time": 64.6506998538971,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "Instead of building a new dataset from scratch, we aim at leveraging the existing supervised dataset for reconstructing the instances by a novel N -Way- D -Doc sampling strategy, inspired by similar work (Sabo et al., 2021; Popovic and Färber, 2022).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions leveraging an existing supervised dataset but does not specify the name of the dataset. The cited papers do not provide additional clarity on the dataset name.",
      "processing_time": 64.6506998538971,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248512966
    },
    {
      "context_text": "Similar memory issue has also been reported by (Sabo et al., 2021) when handling few-shot learning for relation extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue with few-shot learning for relation extraction.",
      "processing_time": 62.770106077194214,
      "citing_paper_id": "252090194",
      "cited_paper_id": 233296646
    },
    {
      "context_text": "Soft sampling methods like N -Way- K ∼ 2 K Shots in (Ding et al., 2021) still do not work for our long documents since K ∼ 2 K Shots are still hard to be satisfied.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a method (N-Way-K Shots) and a limitation regarding its applicability to long documents.",
      "processing_time": 64.40230894088745,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "The first one masks all arguments in the training set with O if they also appear in the val and test sets as used in (Ding et al. 2021), while in the second strategy, we can mask all the arguments in the val and test sets if they are shared by the training set.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes strategies for masking arguments in training, validation, and test sets, but does not name any particular dataset.",
      "processing_time": 65.57493472099304,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "Soft sampling methods like N -Way-K∼2K Shots in (Ding et al. 2021) still do not work for our long documents since K∼2K Shots are still hard to be satisfied.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (N-Way-K∼2K Shots) and a limitation regarding its applicability to long documents.",
      "processing_time": 64.39439868927002,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "Previous research (Yang and Katiyar, 2020) tries to use greedy sampling to guarantee the strict K shots requirements for sentence-level few-shot NER task, but this is not applicable due to the sparse density of arguments in the document as also been observed by (Ding et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets by name, only referring to previous research and methods. The context is about methodological challenges in few-shot NER, not the use of specific datasets.",
      "processing_time": 65.57521605491638,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "The latest Few-NERD (Ding et al. 2021) named entity recognition dataset also includes information across sentences.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Few-NERD"
      ],
      "dataset_descriptions": {
        "Few-NERD": "Used to train and evaluate few-shot named entity recognition models, focusing on cross-sentence information for improved document-level understanding."
      },
      "confidence_score": 1.0,
      "reasoning": "Few-NERD is a named entity recognition dataset that includes information across sentences, which is relevant to document-level event extraction.",
      "processing_time": 70.6191840171814,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "Previous research (Yang and Katiyar 2020) tries to use greedy sampling to guarantee the strict K shots requirements for sentencelevel few-shot NER task, but this is not applicable due to the sparse density of arguments in the document as also been observed by (Ding et al. 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets by name, only referring to previous research and methodologies. The context is about the challenges in few-shot NER, particularly the sparsity of arguments in documents.",
      "processing_time": 66.37625646591187,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "There have been growing interests under few-shot settings for named entity recognition (Ding et al. 2021; Das et al. 2022), and relation extraction (Han et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Few-NERD"
      ],
      "dataset_descriptions": {
        "Few-NERD": "Used to explore few-shot named entity recognition, focusing on the performance of models with limited labeled data."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Few-NERD' in the context of few-shot named entity recognition, which is a specific dataset. No other datasets are mentioned.",
      "processing_time": 20.65625810623169,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "And (Ding et al. 2021) lose the K shots requirement to K∼2K shots.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method or approach. The title 'Few-NERD' suggests a dataset, but it is not mentioned in the citation context.",
      "processing_time": 65.08738803863525,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "The first one masks all arguments in the training set with O if they also appear in the val and test sets as used in (Ding et al., 2021), while in the second strategy, we can mask all the arguments in the val and test sets if they are shared by the training set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not mention any specific dataset names, only generic references to training, validation, and test sets. The cited paper title 'Few-NERD' is a dataset but is not explicitly mentioned in the context.",
      "processing_time": 67.34567284584045,
      "citing_paper_id": "252090194",
      "cited_paper_id": 234742165
    },
    {
      "context_text": "Many approaches and datasets (Petroni et al., 2018; Hürriyetoğlu et al., 2021; Giorgi et al., 2021; Zavarella et al., 2022) across diverse domains have been proposed for document-level argument extraction to go beyond single-sentence inference.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation mentions 'datasets' in plural but does not specify any particular dataset names. The context is too generic and lacks specific identifiers.",
      "processing_time": 64.62942290306091,
      "citing_paper_id": "252090194",
      "cited_paper_id": 236486186
    },
    {
      "context_text": "Following these datasets, many novel methods for solving such new challenges brought by the longer context have also been investigated and witness significant progress (Du and Cardie, 2020; Li et al., 2021; Xu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that discuss methods and progress. No clear, verifiable datasets are identified.",
      "processing_time": 64.75439357757568,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248496614
    },
    {
      "context_text": "Note that (Popovic and Färber, 2022) adopts D -doc sampling for document-level relation extraction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'D -doc sampling' which is likely a method or technique rather than a dataset. No specific dataset is mentioned in the context.",
      "processing_time": 64.7529571056366,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248512966
    },
    {
      "context_text": "It is notable that (Popovic and Färber, 2022) tackle this problem for few-shot document-level relation extraction by D -Doc setting where both N and K are variables between documents and individual episodes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to few-shot document-level relation extraction.",
      "processing_time": 63.86023807525635,
      "citing_paper_id": "252090194",
      "cited_paper_id": 248512966
    },
    {
      "context_text": "The recent RAMS (Ebner et al., 2020) and DocEE (Tong et al., 2022) corpora focus on multi-sentence event extraction.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "DocEE"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for multi-sentence event extraction, focusing on the identification and classification of events across multiple sentences.",
        "DocEE": "Serves as a large-scale and fine-grained benchmark for document-level event extraction, enhancing the granularity and scale of event extraction tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two corpora, RAMS and DocEE, both of which are used for document-level event extraction. DocEE is specifically noted as a large-scale and fine-grained benchmark.",
      "processing_time": 78.09230375289917,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "On the other hand, the results convince our motivation by extending to document-level argument extraction as a large portion of arguments can only be extracted across sentences, as also confirmed under supervised condition by (Tong et al., 2022).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a general reference to document-level argument extraction. The cited paper title 'DocEE' suggests a benchmark, which is excluded unless it refers to a specific, downloadable dataset.",
      "processing_time": 67.05848336219788,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "For Cross domain, we follow the original event splits in DocEE (Tong et al. 2022) where the authors choose the natural disasters events as the target domain, including Floods, Droughts, Earthquakes, Insect Disaster, Famine, Tsunamis, Mudslides, Hurricanes, Fire, and Volcano Eruption, and leave the remaining 49 event types as source domains.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to train and evaluate cross-domain event extraction models, focusing on natural disaster events as the target domain and other event types as source domains."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocEE' as a benchmark for document-level event extraction, which is a specific dataset used for training and evaluation.",
      "processing_time": 72.11914420127869,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "On the other hand, the results convince our motivation by extending to document-level argument extraction as a large portion of arguments can only be extracted across sentences, as also confirmed under supervised condition by (Tong et al. 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a general reference to 'document-level argument extraction'. The cited paper title suggests a benchmark, but it is not explicitly used as a dataset in the citation context.",
      "processing_time": 66.8478057384491,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "traction dataset is the DocEE (Tong et al. 2022), which consists of 27, 000+ events, 180, 000+ arguments over 27, 485 Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used as a benchmark for document-level event extraction, containing 27,000+ events and 180,000+ arguments across 27,485 Wikipedia articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions 'DocEE' as a dataset with specific statistics, and the cited paper title confirms it is a benchmark for document-level event extraction.",
      "processing_time": 74.37835049629211,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Longformer (Beltagy, Peters, and Cohan 2020)) has also been proven to improve the argument extraction task (Tong et al. 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Longformer) and a task (argument extraction).",
      "processing_time": 64.3689866065979,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "EE datasets include RAMS (Ebner et al., 2020) and DocEE (Tong et al., 2022), and their statistics is shown in Table 1.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "DocEE"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate document-level event extraction systems, providing a benchmark for comparing performance across different models and approaches.",
        "DocEE": "Serves as a large-scale and fine-grained benchmark for document-level event extraction, focusing on detailed event structures and relationships within documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, RAMS and DocEE, which are used for document-level event extraction. Both are clearly identified and relevant to the research topic.",
      "processing_time": 77.40062713623047,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Previous work on document-level EE using BERT Seq(Du and Cardie 2020; Tong et al. 2022) demonstrate the success of using a pre-trained BERT model to sequentially label words in the article.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of BERT for document-level event extraction. The cited paper title 'DocEE' suggests a benchmark, but it is not explicitly referred to as a dataset in the citation context.",
      "processing_time": 68.8496766090393,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "In addition, DocEE (Tong et al. 2022) includes 21, 450 documentlevel events with 109, 395 arguments, making it the largest document-level event extraction dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to benchmark document-level event extraction, focusing on large-scale and fine-grained annotations of events and arguments."
      },
      "confidence_score": 1.0,
      "reasoning": "DocEE is explicitly mentioned as a dataset with specific characteristics relevant to document-level event extraction.",
      "processing_time": 68.85186719894409,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Previous work on document-level EE using BERT_Seq (Du and Cardie, 2020; Tong et al., 2022) demonstrate the success of using a pre-trained BERT model to sequentially label words in the article.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BERT_Seq) and a benchmark (DocEE). DocEE is excluded as it is a benchmark, not a dataset.",
      "processing_time": 66.67843127250671,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Since the DocEE dataset (Tong et al. 2022) follows the main event extraction (Hamborg et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to benchmark document-level event extraction, focusing on fine-grained event types and large-scale evaluation in the context of Tong et al.'s research."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocEE dataset' which is a specific, verifiable dataset used for document-level event extraction. The cited paper title confirms it is a dataset.",
      "processing_time": 73.79293823242188,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "The largest document-level event extraction dataset is the DocEE (Tong et al., 2022), which consists of 27 , 000+ events, 180 , 000+ arguments over 27 , 485 Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used as a benchmark for document-level event extraction, containing 27,000+ events and 180,000+ arguments across 27,485 Wikipedia articles, focusing on fine-grained event and argument identification."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly mentions 'DocEE' as a dataset, which is a large-scale benchmark for document-level event extraction. It provides specific details about the dataset's size and content.",
      "processing_time": 77.0345983505249,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "The authors (Tong et al. 2022) provide Cross domain scenario, where the training and test labels are entirely disjoint, sharing no mutual domain information.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a cross-domain scenario. The context does not provide enough information to identify a specific, verifiable dataset.",
      "processing_time": 54.787245750427246,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "In the released DocEE (Tong et al. 2022) corpus, there are 31 hard news event types and 28 soft news event types with their corresponding arguments.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to benchmark document-level event extraction, specifically evaluating performance on 31 hard news and 28 soft news event types with their arguments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocEE' corpus, which is a specific dataset used for document-level event extraction. The corpus is described as having hard and soft news event types with corresponding arguments.",
      "processing_time": 62.63492298126221,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "The authors (Tong et al., 2022) provide Cross domain scenario, where the training and test labels are entirely disjoint, sharing no mutual domain information.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a cross-domain scenario. The cited paper title suggests a benchmark, but it is not explicitly used as a dataset in the citation context.",
      "processing_time": 55.465463399887085,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "And the superior performance of the long document transformer (e.g. Longformer (Beltagy et al., 2020)) has also been proven to improve the argument extraction task (Tong et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the performance of the Longformer model in improving the argument extraction task.",
      "processing_time": 54.48371934890747,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "2020) and DocEE (Tong et al. 2022) corpora focus on multisentence event extraction.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to develop and evaluate models for document-level event extraction, focusing on multisentence events in a large-scale, fine-grained benchmark."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two corpora, DocEE and another unnamed corpus, both focused on document-level event extraction. DocEE is a specific, named resource with a clear reference to a published benchmark.",
      "processing_time": 62.8650016784668,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "Since the DocEE dataset (Tong et al., 2022) follows the main event extraction (Hamborg et al., 2018) setting where no trigger words exist and the article title t and the article a itself together determine the event type, we follow their setting and assume the event type e is given, then aim at…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocEE"
      ],
      "dataset_descriptions": {
        "DocEE": "Used to benchmark document-level event extraction, focusing on scenarios where no trigger words exist and the article title and content together determine the event type."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'DocEE dataset' which is a specific, verifiable dataset used for document-level event extraction. The dataset is clearly identified and its usage is described in the context.",
      "processing_time": 62.72097730636597,
      "citing_paper_id": "252090194",
      "cited_paper_id": 250390839
    },
    {
      "context_text": "To demonstrate the performance of our model, we evaluate the model on two domains two datasets, which are EventStoryLine 1 [18] and the English dataset in Multilingual Event Causality Identification Corpus (English-MECI) 2 [12].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine",
        "Multilingual Event Causality Identification Corpus (English-MECI)"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to evaluate the model's performance in event extraction, focusing on narrative structures and event relations in stories.",
        "Multilingual Event Causality Identification Corpus (English-MECI)": "Used to assess the model's ability to identify causal relationships between events in English texts, emphasizing cross-lingual applicability."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets used for evaluating the model's performance in event extraction across different domains.",
      "processing_time": 68.62681102752686,
      "citing_paper_id": "279284305",
      "cited_paper_id": 8387007
    },
    {
      "context_text": "To demonstrate the performance of our model, we evaluate the model on two domains two datasets, which are EventStoryLine 1 [18] and the English dataset in Multilingual Event Causality Identification Corpus (English-MECI) 2 [12].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EventStoryLine",
        "Multilingual Event Causality Identification Corpus (English-MECI)"
      ],
      "dataset_descriptions": {
        "EventStoryLine": "Used to evaluate the model's performance in event extraction, focusing on narrative structures and event relations in stories.",
        "Multilingual Event Causality Identification Corpus (English-MECI)": "Used to assess the model's ability to identify causal relationships between events in English texts, emphasizing cross-lingual applicability."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets used for evaluating the model's performance in event extraction across different domains.",
      "processing_time": 68.62681102752686,
      "citing_paper_id": "279284305",
      "cited_paper_id": 252819228
    },
    {
      "context_text": "Although the multi-head attention [24] can generate unique contextual hidden layer representations for di ff erent events, in practice, it tends to focus more on the words adjacent to the target event.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (multi-head attention).",
      "processing_time": 52.041715145111084,
      "citing_paper_id": "279284305",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "We use multi-head attention [24] to capture the dependency information of the target event.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (multi-head attention). The cited paper title 'Attention is All you Need' confirms that the reference is to a method, not a dataset.",
      "processing_time": 55.99305558204651,
      "citing_paper_id": "279284305",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "We optimize our model with AdamW [15].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method (AdamW) used for optimization.",
      "processing_time": 52.26917815208435,
      "citing_paper_id": "279284305",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "Such approaches often leverage syntactic cues and lexical triggers to detect causal links, but their scope is limited to local contexts [25, 19, 21, 8, 9, 22].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general approaches and limitations. The cited papers do not provide additional context to identify a specific dataset.",
      "processing_time": 53.45148015022278,
      "citing_paper_id": "279284305",
      "cited_paper_id": 202537879
    },
    {
      "context_text": "Such approaches often leverage syntactic cues and lexical triggers to detect causal links, but their scope is limited to local contexts [25, 19, 21, 8, 9, 22].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general approaches and limitations. The cited papers do not provide additional context to identify a specific dataset.",
      "processing_time": 53.45148015022278,
      "citing_paper_id": "279284305",
      "cited_paper_id": 248377560
    },
    {
      "context_text": "As shown in Figure 1, event pairs, such as ( grateful and treatment in intra-sentence) and ( left and move in inter-sentence), exist the causal relation, and they either occur within the same sentence [10, 14, 11] or span across an entire document [20, 17, 26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general references to event pairs and their causal relations within or across sentences. No verifiable resource names are provided.",
      "processing_time": 54.53911280632019,
      "citing_paper_id": "279284305",
      "cited_paper_id": 202782267
    },
    {
      "context_text": "As shown in Figure 1, event pairs, such as ( grateful and treatment in intra-sentence) and ( left and move in inter-sentence), exist the causal relation, and they either occur within the same sentence [10, 14, 11] or span across an entire document [20, 17, 26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general references to event pairs and their causal relations within or across sentences. No verifiable resource names are provided.",
      "processing_time": 54.53911280632019,
      "citing_paper_id": "279284305",
      "cited_paper_id": 220484653
    },
    {
      "context_text": "As shown in Figure 1, event pairs, such as ( grateful and treatment in intra-sentence) and ( left and move in inter-sentence), exist the causal relation, and they either occur within the same sentence [10, 14, 11] or span across an entire document [20, 17, 26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general references to event pairs and their causal relations within or across sentences. No verifiable resource names are provided.",
      "processing_time": 54.53911280632019,
      "citing_paper_id": "279284305",
      "cited_paper_id": 235097277
    },
    {
      "context_text": "As shown in Figure 1, event pairs, such as ( grateful and treatment in intra-sentence) and ( left and move in inter-sentence), exist the causal relation, and they either occur within the same sentence [10, 14, 11] or span across an entire document [20, 17, 26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general references to event pairs and their causal relations within or across sentences. No verifiable resource names are provided.",
      "processing_time": 54.53911280632019,
      "citing_paper_id": "279284305",
      "cited_paper_id": 250291480
    },
    {
      "context_text": "DECI studies have introduced methods to integrate global context, employing graph-based models, hierarchical encoders, and attention mechanisms to capture long-distance dependencies among events and entities [6, 20].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on methodologies for integrating global context in event extraction.",
      "processing_time": 53.60175895690918,
      "citing_paper_id": "279284305",
      "cited_paper_id": 235097277
    },
    {
      "context_text": "…data to solve the data lacking; • LR + and LIP [6] that models rich causal structures via designing constraints and objection function; • RichGCN [20] that builds multi-level graphs to capture structure-preserved features; • ERGO [2] that designs an event relational graph and converts the event…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on describing various approaches and models used for event causality identification.",
      "processing_time": 53.875576972961426,
      "citing_paper_id": "279284305",
      "cited_paper_id": 235097277
    },
    {
      "context_text": "• LearnDA [28] that augments data to solve the data lacking; • LR + and LIP [6] that models rich causal structures via designing constraints and objection function; • RichGCN [20] that builds multi-level graphs to capture structure-preserved features; • ERGO [2] that designs an event relational…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on describing various approaches and techniques rather than datasets.",
      "processing_time": 53.30760717391968,
      "citing_paper_id": "279284305",
      "cited_paper_id": 235313431
    },
    {
      "context_text": "Man et al. [17] proposes to model the important context sentences to identify relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for identifying relations using context sentences.",
      "processing_time": 52.12402653694153,
      "citing_paper_id": "279284305",
      "cited_paper_id": 250291480
    },
    {
      "context_text": "Following [12], we use the 263 documents as the Train dataset, 88 documents as the Dev dataset, and 87 documents as the Test dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MECI"
      ],
      "dataset_descriptions": {
        "MECI": "Used to train, develop, and test models for event causality identification, specifically focusing on multilingual document-level event extraction."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific splits of a dataset but does not provide a clear name. The title 'MECI: A Multilingual Dataset for Event Causality Identification' suggests that the dataset being referred to is MECI.",
      "processing_time": 63.25458741188049,
      "citing_paper_id": "279284305",
      "cited_paper_id": 252819228
    },
    {
      "context_text": "5-turbo and gpt-4; • iLIF [13] that designs an iterative learning and identifying framework.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The title suggests a focus on document event causality, but no datasets are named in the citation.",
      "processing_time": 54.63656544685364,
      "citing_paper_id": "279284305",
      "cited_paper_id": 270199894
    },
    {
      "context_text": "Liu et al. [13] proposes to design an iterative learning and identifying framework.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a framework for document event causality identification.",
      "processing_time": 51.94067120552063,
      "citing_paper_id": "279284305",
      "cited_paper_id": 270199894
    },
    {
      "context_text": "In addition, we follow previous work (iLIF) [13], using the multi-iteration to update the d ( i , j ) o to reason the causal relation for event pairs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (iLIF) and a general approach to updating causal relations for event pairs.",
      "processing_time": 53.73980236053467,
      "citing_paper_id": "279284305",
      "cited_paper_id": 270199894
    },
    {
      "context_text": "We strictly follow the settings in [13] for other parameters.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to another paper for parameter settings.",
      "processing_time": 51.928547859191895,
      "citing_paper_id": "279284305",
      "cited_paper_id": 270199894
    },
    {
      "context_text": ") [40], which modifies the term logP (â|D̂, q̂) to −(1− P (â|D̂, q̂)) in (3) for model training, and the method based on example re-weighting (Re-Weighting) [41], which uses a model trained with in-domain data to give out-of-domain and",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is about modifying training procedures and reweighting examples, which are methods rather than datasets.",
      "processing_time": 54.407448530197144,
      "citing_paper_id": "252901047",
      "cited_paper_id": 4321928
    },
    {
      "context_text": "In Discussion (Section VI-D), we compare our method to methods based on loss function modification [40] and example re-weighting [41] to assess its effectiveness.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on comparing different methods, not using datasets.",
      "processing_time": 53.104997634887695,
      "citing_paper_id": "252901047",
      "cited_paper_id": 4321928
    },
    {
      "context_text": "In the ﬁne-tuning state, we employ the RAMS development set for hyper-parameter tuning, and ﬁnally, the batch size is set to 20 (selected from [1, 5, 10, 20, 30, 40]) and the learning rate is set to 2e-5 (picked from [1e-5, 2e-5, 3e-5, 4e-5]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS development set"
      ],
      "dataset_descriptions": {
        "RAMS development set": "Used for hyper-parameter tuning during the fine-tuning phase, specifically adjusting batch size and learning rate for optimal performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the RAMS development set for hyper-parameter tuning, which is a specific dataset used in the research.",
      "processing_time": 60.322691917419434,
      "citing_paper_id": "252901047",
      "cited_paper_id": 6546734
    },
    {
      "context_text": "[40], which modiﬁes the term log P (ˆ a | ˆ D , ˆ q ) to − (1 − P (ˆ a | ˆ D , ˆ q )) in (3) for model training, and the method based on example re-weighting (Re-Weighting) [41], which uses a model trained with in-domain data to give out-of-domain and automatically generated data a weight for…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for handling label noise in deep neural networks.",
      "processing_time": 52.246516704559326,
      "citing_paper_id": "252901047",
      "cited_paper_id": 6546734
    },
    {
      "context_text": "In Discussion (Section VI-D), we compare our method to methods based on loss function modiﬁcation [40] and example re-weighting [41] to assess its effectiveness.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on comparing different methods for robustness under label noise.",
      "processing_time": 53.31266522407532,
      "citing_paper_id": "252901047",
      "cited_paper_id": 6546734
    },
    {
      "context_text": "For this MUC-4 task formulation, traditional approaches have proposed feature-based methods [18], [22], [23], while modern approacheshavestudiedusingneuralnetworksbasedmethodsto obtain document-level cues for learning [19], [24], [25].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on comparing traditional feature-based methods with modern neural network-based methods for document-level event extraction.",
      "processing_time": 54.647839069366455,
      "citing_paper_id": "252901047",
      "cited_paper_id": 6644751
    },
    {
      "context_text": ", VICTIM) regarding an event template [17], [18], [19], [20], [21].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to event templates. No verifiable resources are identified.",
      "processing_time": 52.55973815917969,
      "citing_paper_id": "252901047",
      "cited_paper_id": 11986411
    },
    {
      "context_text": "For the sentence-level event argument extraction task, the existing methods [30], [31] have used distant supervision for data augmentation, leveraging external knowledge bases to generate new training data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'external knowledge bases' but does not specify any particular dataset. The citation is about using distant supervision for data augmentation, which is a method, not a dataset.",
      "processing_time": 54.00267243385315,
      "citing_paper_id": "252901047",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "In the fine-tuning state, we employ the RAMS development set for hyper-parameter tuning, and finally, the batch size is set to 20 (selected from [1, 5, 10, 20, 30, 40])",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for hyper-parameter tuning during the fine-tuning process, specifically to optimize the batch size for event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the RAMS development set for hyper-parameter tuning during the fine-tuning process.",
      "processing_time": 58.25189018249512,
      "citing_paper_id": "252901047",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "In our MRC model, we use a BERT-base-uncased architecture [12] to maintain consistency with previous studies [2], [5].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using BERT but does not refer to any specific dataset. BERT is a model, not a dataset.",
      "processing_time": 52.70260572433472,
      "citing_paper_id": "252901047",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Furthermore, this collaborative architecture allows us to directly leverage the advanced models in MRC to handle document-level EAE, which have been proved to excel in capturing document-level clues [12].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (MRC) and a model (BERT). The context focuses on leveraging advanced models for document-level event argument extraction.",
      "processing_time": 55.19736576080322,
      "citing_paper_id": "252901047",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In particular, we create a BERT based encoder [12] to jointly encode q r and D , by ﬁrst generating an extended input sequence to concatenate q r and D : where [CLS] and [SEP] are special tokens used in BERT [12].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT for encoding. BERT is a model, not a dataset.",
      "processing_time": 53.273592948913574,
      "citing_paper_id": "252901047",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We prefer the BERT-based MRC model [12], and in addition to the question answering dataset, i.e., SQuAD 2.0 [36], we also use corpora in FrameNet semantic role labeling (SRL) [37] and ACE 2005 event extraction (EE) [38] for pre-training 2 , by framing them in an MRC formulation in a similar fashion.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SQuAD 2.0",
        "FrameNet",
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "SQuAD 2.0": "Used for pre-training a BERT-based MRC model, focusing on question answering tasks to improve model performance.",
        "FrameNet": "Used for pre-training a BERT-based MRC model, focusing on semantic role labeling tasks to enhance understanding of sentence structures.",
        "ACE 2005": "Used for pre-training a BERT-based MRC model, focusing on event extraction tasks to improve the identification of events in text."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions SQuAD 2.0, FrameNet, and ACE 2005 as corpora used for pre-training a BERT-based MRC model. These are specific datasets used in the research.",
      "processing_time": 73.86476135253906,
      "citing_paper_id": "252901047",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We prefer the BERT-based MRC model [12], and in addition to the question answering dataset, i.e., SQuAD 2.0 [36], we also use corpora in FrameNet semantic role labeling (SRL) [37] and ACE 2005 event extraction (EE) [38] for pre-training 2 , by framing them in an MRC formulation in a similar fashion.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SQuAD 2.0",
        "FrameNet",
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "SQuAD 2.0": "Used for pre-training a BERT-based MRC model, focusing on question answering tasks to improve model performance.",
        "FrameNet": "Used for pre-training a BERT-based MRC model, focusing on semantic role labeling tasks to enhance understanding of sentence structures.",
        "ACE 2005": "Used for pre-training a BERT-based MRC model, focusing on event extraction tasks to improve the identification of events in text."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions SQuAD 2.0, FrameNet, and ACE 2005 as corpora used for pre-training a BERT-based MRC model. These are specific datasets used in the research.",
      "processing_time": 73.86476135253906,
      "citing_paper_id": "252901047",
      "cited_paper_id": null
    },
    {
      "context_text": "In the implicit knowledge transfer method, after pre-training, the MRC model scores 83.5%, 72.1%, and 70.1% in F1 on SQuAD 2.0, FrameNet SRL, and ACE 2005 EE datasets, respectively, matching the state-of-the-art performance [11], [12], [13].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SQuAD 2.0",
        "FrameNet SRL",
        "ACE 2005 EE"
      ],
      "dataset_descriptions": {
        "SQuAD 2.0": "Used to evaluate the MRC model's performance after pre-training, focusing on question answering tasks with a focus on F1 score.",
        "FrameNet SRL": "Used to assess the model's semantic role labeling capabilities, specifically measuring F1 score post-pre-training.",
        "ACE 2005 EE": "Used to evaluate the model's event extraction performance, particularly in terms of F1 score after pre-training."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three datasets used for evaluating the performance of an MRC model after pre-training. These datasets are SQuAD 2.0, FrameNet SRL, and ACE 2005 EE.",
      "processing_time": 73.86150479316711,
      "citing_paper_id": "252901047",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "To name a few, authors in [9], [33] cast relation",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a vague reference to relations. No clear, verifiable resources are identified.",
      "processing_time": 52.86860203742981,
      "citing_paper_id": "252901047",
      "cited_paper_id": 153312535
    },
    {
      "context_text": "1 (bottom) gives the data statistics of the currently largest document-level benchmark (i.e., RAMS [2]), where we can see that over 63% of roles have less than 100 instances.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to highlight the size and role distribution in a document-level event extraction benchmark, focusing on the scarcity of certain roles."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'RAMS' as a document-level benchmark, which fits the criteria for a dataset. However, it does not provide details on how the dataset is used beyond mentioning its size and role distribution.",
      "processing_time": 62.378989934921265,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "…can be viewed as eliciting knowledge from a pre-trained MRC model to generate new examples, and as the training set is explicitly expanded, the method has the potential to beneﬁt any model proposed for document-level EAE (e.g., that based on sequence labeling [13] or span prediction [2]).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the methodology for document-level event argument extraction (EAE).",
      "processing_time": 53.93209195137024,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "T EXTUAL event descriptions may span over multiple sentences; therefore to fully understand the semantics of an event we need to gather information from a document context for reasoning [1], [2], [3].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the need for document-level context in event extraction.",
      "processing_time": 52.25842571258545,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "T EXTUAL event descriptions may span over multiple sentences; therefore to fully understand the semantics of an event we need to gather information from a document context for reasoning [1], [2], [3].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the need for document-level context in event extraction.",
      "processing_time": 52.25842571258545,
      "citing_paper_id": "252901047",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Despite its effectiveness, one disadvantage of implicit knowl-edgetransferisthatitcannotcreateexplicittrainingdata,henceit canonlybeneﬁtamodelinanMRCformulationbutnotinother formulations[2],[4].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a limitation of a method.",
      "processing_time": 51.608245849609375,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Despite its effectiveness, one disadvantage of implicit knowl-edgetransferisthatitcannotcreateexplicittrainingdata,henceit canonlybeneﬁtamodelinanMRCformulationbutnotinother formulations[2],[4].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a limitation of a method.",
      "processing_time": 51.608245849609375,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "For example, the state-of-the-art model attains less than 10% in F1 when the argument and trigger are in different sentences [2], [4], [6].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only performance metrics and model capabilities. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 53.925156593322754,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "For example, the state-of-the-art model attains less than 10% in F1 when the argument and trigger are in different sentences [2], [4], [6].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only performance metrics and model capabilities. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 53.925156593322754,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "To validate the effectiveness of our approach, we have conducted extensive tests on three datasets, i.e., RAMS [2], WikiEvents [5], and MUC-4 [14].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS",
        "WikiEvents",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to validate the effectiveness of the approach in document-level event extraction, focusing on multi-sentence argument linking.",
        "WikiEvents": "Used to test the approach's performance in identifying and linking events across multiple sentences in Wikipedia articles.",
        "MUC-4": "Used to evaluate the approach's ability to handle complex event structures and relations in news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three specific datasets used for validating the approach: RAMS, WikiEvents, and MUC-4. These are clearly identified and relevant to document-level event extraction.",
      "processing_time": 70.7417380809784,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "To address the data sparsity issue, we take a perspective from MRC and aim to use resources in the domain of MRC for learning, as opposed to previous methods viewing the task as a sequence labeling [13] or span ranking [2].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The context is about using resources in the domain of Machine Reading Comprehension (MRC) but does not specify any datasets.",
      "processing_time": 55.584141969680786,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "[2], W IKI E VENTS (W IKI E) [5] AND MUC-4 [14] 0.9) may be too easy for a model to learn new information, while examples with very low predictive probabilities (e.g., < 0.6) may be too noisy; therefore we choose examples with medium difﬁculty and noisy extent and force the model to train on them.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKI EVENTS",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "WIKI EVENTS": "Used to train and evaluate models on document-level event extraction, focusing on linking events across multiple sentences.",
        "MUC-4": "Used to train and evaluate models on document-level event extraction, specifically for identifying and linking events in news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions WIKI EVENTS (WIKI E) and MUC-4, which are known datasets in the field of document-level event extraction. These datasets are used to train and evaluate models on event extraction tasks.",
      "processing_time": 69.43770265579224,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Document-level event argument extraction (EAE) is such a task requiring a model to extract arguments (i.e., participants) of an event at the document level [2], [4].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the task of document-level event argument extraction. No verifiable resources are named.",
      "processing_time": 53.33419585227966,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "Document-level event argument extraction (EAE) is such a task requiring a model to extract arguments (i.e., participants) of an event at the document level [2], [4].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the task of document-level event argument extraction. No verifiable resources are named.",
      "processing_time": 53.33419585227966,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Unlike theMUC-4formulation,arecentwork[2]proposesanewbench-markthatismoreﬁne-grainedandannotatestriggersintexts.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context does not provide a clear, specific dataset name. 'MUC-4' is mentioned but it is not clear if it is a dataset or a benchmark. The citation intent and resource type are also unclear.",
      "processing_time": 55.86039924621582,
      "citing_paper_id": "252901047",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "…in the implicit knowledge transfer method, and in the explicit data generation method, we apply our method to a BERT-CRF model and a QAEE model [3], which uses a ﬁne-grained query generation strategy (we directly use the trigger prediction result of QAEE andonot…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the use of models and their methodologies.",
      "processing_time": 53.28700923919678,
      "citing_paper_id": "252901047",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Particularly, we note document-level EAE is strongly related to a machine reading comprehension (MRC) problem [7], [8], if the argument extraction process is viewed as an answer retrieving procedure [3], [9], [10], [11].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a conceptual relationship between document-level event argument extraction and machine reading comprehension.",
      "processing_time": 52.762436866760254,
      "citing_paper_id": "252901047",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "To name a few, authors in [9], [33] cast relation extraction into a question answering problem; authors in [10] address named entity recognition via an MRC formulation; authors in [3], [11] frame sentence-level event extraction as an MRC problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The titles of the cited papers do not provide additional context to identify datasets.",
      "processing_time": 53.91086006164551,
      "citing_paper_id": "252901047",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Followingearlierstudies ondocument-levelEAE[2],[3],[4],[25],weuseprecision (P), recall (R), and F1 score (F1) as evaluation metrics and we adopt the exact match (EM) criterion: only when the projected argument span matches exactly a gold one do we consider it a correct prediction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and criteria. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 53.64391899108887,
      "citing_paper_id": "252901047",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Followingearlierstudies ondocument-levelEAE[2],[3],[4],[25],weuseprecision (P), recall (R), and F1 score (F1) as evaluation metrics and we adopt the exact match (EM) criterion: only when the projected argument span matches exactly a gold one do we consider it a correct prediction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and criteria. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 53.64391899108887,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "…BART-Gen employs the BART-large architecture, which has many more parameters than the BERT-base architecture used in previous meth-ods [2], [4], to make the parameter set comparable, we change the conﬁguration to BART-based. roles deﬁned by the gold event types and “ w/o Type Constraint”…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model architectures and configurations. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 53.641109228134155,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "On RAMS, for example, when the event argument is two sentences ahead of 5 The results are based on the development set following [4], and we only use the conﬁguration of “ w/ Type Constraint” to simplify discussion.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used for implicit event argument detection, focusing on the configuration with type constraints to simplify discussion."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'RAMS' which appears to be a dataset used for event argument detection. However, there is no explicit mention of how it is used or the specific research question. The context is brief and lacks detail.",
      "processing_time": 61.90982389450073,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Despitemanyadvancesonthistask,theproblemofinadequate training data still limits a model’s performance [29] — for example, even on the largest dataset RAMS, over 63% of the roles have fewer than 100 examples, limiting the performance of the currently best model to less than 50% in F1 [4].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to highlight the challenge of limited training data in event argument detection, specifically noting that over 63% of roles have fewer than 100 examples, impacting model performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS' as a dataset with inadequate training data, which is relevant to the document-level event extraction topic.",
      "processing_time": 62.08419752120972,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "Despitemanyadvancesonthistask,theproblemofinadequate training data still limits a model’s performance [29] — for example, even on the largest dataset RAMS, over 63% of the roles have fewer than 100 examples, limiting the performance of the currently best model to less than 50% in F1 [4].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to highlight the challenge of limited training data in event argument detection, specifically noting that over 63% of roles have fewer than 100 examples, impacting model performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'RAMS' as a dataset with inadequate training data, which is relevant to the document-level event extraction topic.",
      "processing_time": 62.08419752120972,
      "citing_paper_id": "252901047",
      "cited_paper_id": 236087324
    },
    {
      "context_text": "Followingthework,awork[4]constructs a head-to-region approach yielding promising results; authors in [26] study the extent to which the pre-trained language model can assist learning; authors in [27] suggests that knowledge from FrameNet [28] be used to aid the reasoning process; authors in [5]…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works and methods. No clear identifiers for datasets are present.",
      "processing_time": 53.05546426773071,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "We conduct an error analysis following [4], by randomly selecting 100 error cases from the RAMS development set and determining their commonality.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS development set"
      ],
      "dataset_descriptions": {
        "RAMS development set": "Used for error analysis in implicit event argument detection, focusing on identifying common errors in the development phase of the model."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the RAMS development set, which is a specific dataset used for error analysis in the context of event argument detection.",
      "processing_time": 59.891722440719604,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "(cid:2) Head-Expand [4].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not provide enough context to identify specific datasets or their usage. The title suggests a method for event argument detection, but no datasets are mentioned.",
      "processing_time": 53.626537561416626,
      "citing_paper_id": "252901047",
      "cited_paper_id": 220046861
    },
    {
      "context_text": "in [26] study the extent to which the pre-trained language model can assist learning; authors in [27] suggests that knowledge from",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "RAMS": "Used to evaluate the pre-trained language model's ability to identify and understand event arguments, focusing on the extent of pre-existing knowledge in BERT."
      },
      "confidence_score": 0.8,
      "reasoning": "The context does not provide specific information about the use of datasets, but the cited paper title mentions the RAMS dataset, which is relevant to document-level event extraction.",
      "processing_time": 61.16854906082153,
      "citing_paper_id": "252901047",
      "cited_paper_id": 222208551
    },
    {
      "context_text": "…approach yielding promising results; authors in [26] study the extent to which the pre-trained language model can assist learning; authors in [27] suggests that knowledge from FrameNet [28] be used to aid the reasoning process; authors in [5] investigate a generative perspective on the task,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works and methods. FrameNet is mentioned but it is a knowledge base, not a dataset.",
      "processing_time": 54.83998441696167,
      "citing_paper_id": "252901047",
      "cited_paper_id": 236460308
    },
    {
      "context_text": "These three local words are embedded using the external dictionary GloVE [26] and then concatenated as two local feature vectors e loc 1 and e loc 2 of two events e 1 and e 2 , respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions GloVE but does not indicate its use as a dataset. It is referenced as an embedding method.",
      "processing_time": 52.736493825912476,
      "citing_paper_id": "252625384",
      "cited_paper_id": 1957433
    },
    {
      "context_text": "The dimension of the word embedding in local information and TSDP is 300, using GloVe [26] as the external word to vector dictionary.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "GloVe is a method for generating word vectors, not a dataset. The citation does not mention any specific dataset.",
      "processing_time": 52.73952031135559,
      "citing_paper_id": "252625384",
      "cited_paper_id": 1957433
    },
    {
      "context_text": "Specifically, at the input end of attention, each word on TSDP is embedded by GLoVe [26] and the embedded sequences are denoted as e T = { v 1 , v 2 , ...v k − 1 , v k } , where v i is the embedded representation of each word in TSDP and k is its maximum length.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions GLoVe but does not indicate it is used as a dataset. It is used for word embedding, which is a method.",
      "processing_time": 53.832958698272705,
      "citing_paper_id": "252625384",
      "cited_paper_id": 1957433
    },
    {
      "context_text": "Low prevalence of global document-level temporal ordering annotation in existing corpora allows previous models to achieve moderate performance simply using local syntactic cues, such as SDP (Shortest Dependency Path) [5].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'existing corpora' but does not specify any particular dataset. The reference to SDP (Shortest Dependency Path) is a method, not a dataset.",
      "processing_time": 55.32668495178223,
      "citing_paper_id": "252625384",
      "cited_paper_id": 5165854
    },
    {
      "context_text": "Previous studies on event relation extraction often used SDP [5] as input, which simply connected the two shortest paths from the two events to the root node in a dependency tree.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (SDP) used in previous studies. The cited paper title confirms that SDP is a method, not a dataset.",
      "processing_time": 55.50463795661926,
      "citing_paper_id": "252625384",
      "cited_paper_id": 5165854
    },
    {
      "context_text": "Currently, the most popular temporal relation corpora, Time-Bank [3] and TimeBank-Dense [4], are annotated on sentence-level.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Time-Bank",
        "TimeBank-Dense"
      ],
      "dataset_descriptions": {
        "Time-Bank": "Used for sentence-level temporal relation annotation, focusing on the ordering of events within sentences.",
        "TimeBank-Dense": "Used for sentence-level temporal relation annotation, focusing on dense event ordering within sentences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, Time-Bank and TimeBank-Dense, which are used for temporal relation annotation at the sentence level.",
      "processing_time": 63.64405083656311,
      "citing_paper_id": "252625384",
      "cited_paper_id": 7294125
    },
    {
      "context_text": "Almost all temporal relation corpora are sentence-level and annotated on English, such as TimeBank [3], TimeBank-Dense [4], RED [7] and MATRES [8], which only annotated temporal relations between two events in same sentence or between adjacent sentences.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TimeBank",
        "TimeBank-Dense",
        "RED",
        "MATRES"
      ],
      "dataset_descriptions": {
        "TimeBank": "Used to annotate temporal relations at the sentence level in English, focusing on event ordering within and across sentences.",
        "TimeBank-Dense": "Used to annotate dense event ordering in English, enhancing the annotation of temporal relations within and across sentences.",
        "RED": "Used to integrate event coreference with temporal, causal, and bridging annotations, enriching the representation of event relationships.",
        "MATRES": "Used to annotate temporal relations between events in the same sentence or adjacent sentences, focusing on fine-grained temporal ordering."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets that are used for temporal relation annotation, which are relevant to document-level event extraction.",
      "processing_time": 72.77239727973938,
      "citing_paper_id": "252625384",
      "cited_paper_id": 7294125
    },
    {
      "context_text": "Almost all temporal relation corpora are sentence-level and annotated on English, such as TimeBank [3], TimeBank-Dense [4], RED [7] and MATRES [8], which only annotated temporal relations between two events in same sentence or between adjacent sentences.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TimeBank",
        "TimeBank-Dense",
        "RED",
        "MATRES"
      ],
      "dataset_descriptions": {
        "TimeBank": "Used to annotate temporal relations at the sentence level in English, focusing on event ordering within and across sentences.",
        "TimeBank-Dense": "Used to annotate dense event ordering in English, enhancing the annotation of temporal relations within and across sentences.",
        "RED": "Used to integrate event coreference with temporal, causal, and bridging annotations, enriching the representation of event relationships.",
        "MATRES": "Used to annotate temporal relations between events in the same sentence or adjacent sentences, focusing on fine-grained temporal ordering."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets that are used for temporal relation annotation, which are relevant to document-level event extraction.",
      "processing_time": 72.77239727973938,
      "citing_paper_id": "252625384",
      "cited_paper_id": 15139323
    },
    {
      "context_text": "Besides, we also report the results on the sentence-level event temporal relation dataset TB-Dense [4].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TB-Dense"
      ],
      "dataset_descriptions": {
        "TB-Dense": "Used to report results on sentence-level event temporal relations, focusing on dense event ordering in natural language processing."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions 'TB-Dense' as a dataset used for reporting results on sentence-level event temporal relations.",
      "processing_time": 59.22775220870972,
      "citing_paper_id": "252625384",
      "cited_paper_id": 7294125
    },
    {
      "context_text": "Inspired by Krause et. al [25]who found that incorporating nearby words of the events can provide additional information to improve event coreference task, we choose events themselves and their neighbors as local information which need to be further emphasized and apply them to the local…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The context focuses on using local information (events and their neighbors) for improving event coreference, inspired by the cited work.",
      "processing_time": 56.203280210494995,
      "citing_paper_id": "252625384",
      "cited_paper_id": 10503028
    },
    {
      "context_text": "Motivated by Xu et. al [15], Cheng and Miyao [16]first used SDP as input of BiLSTM to recognize event temporal relations in same sentence or in adjacent sentences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BiLSTM) and a type of input (SDP).",
      "processing_time": 53.807040214538574,
      "citing_paper_id": "252625384",
      "cited_paper_id": 32821791
    },
    {
      "context_text": "CHeng et. al [16] first used SDP in temporal relation classification and proposed the hypothesis of common root, assuming two SDPs distributed in adjacent sentences can be connected through a virtual root.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'SDP' which likely refers to 'Shortest Dependency Path', but does not mention a specific dataset. The citation is about a method or hypothesis rather than a dataset.",
      "processing_time": 55.05259370803833,
      "citing_paper_id": "252625384",
      "cited_paper_id": 32821791
    },
    {
      "context_text": "…method assigns a majority-class label to each event pair; 2) CAEVO [28]: A cascading event ordering architecture which based on sieves; 3) BiLSTM [16]: A BiLSTM model using SDP for the first time; 4) SP+ILP [29]: A method using structured perceptron and integer linear programming to obtain…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 53.30129837989807,
      "citing_paper_id": "252625384",
      "cited_paper_id": 32821791
    },
    {
      "context_text": "…Vector Machine) to improve event representation and extract temporal relation with shared representations and structured prediction; 6) BERT [31]: A BERT-base model which takes the event sentences with the beginning and end tags and then uses the output vector corresponding to the [ CLS ]…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. BERT is referenced but it is a model, not a dataset.",
      "processing_time": 53.770548820495605,
      "citing_paper_id": "252625384",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "…using structured perceptron and integer linear programming to obtain dependencies between events and infer the final temporal relation; 5) MT [30]: A joint model combining BiLSTM and structured SVM(Support Vector Machine) to improve event representation and extract temporal relation with…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the methodology used for event and temporal relation extraction.",
      "processing_time": 54.05158591270447,
      "citing_paper_id": "252625384",
      "cited_paper_id": 202565622
    },
    {
      "context_text": "Joint learning and multi-task learning methods were also applied to obtain better event representation, which contains richer features [6], [19].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets in the text.",
      "processing_time": 53.015852212905884,
      "citing_paper_id": "252625384",
      "cited_paper_id": 215548441
    },
    {
      "context_text": "To remedy this, a few studies have explored the approaches of using external knowledge [20]–[22] and event causal relation patterns [23].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general approaches and methods. There are no clear identifiers for datasets in the text.",
      "processing_time": 53.535293102264404,
      "citing_paper_id": "252625384",
      "cited_paper_id": 218581125
    },
    {
      "context_text": "Obviously, temporal relation contains the temporal clues of document organization and extracting event temporal relation can help many downstream NLP (Natural Languange Processing) applications, such as question answering [1], automatic summarization [2].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of temporal event relations in NLP.",
      "processing_time": 52.30560255050659,
      "citing_paper_id": "252625384",
      "cited_paper_id": 232062161
    },
    {
      "context_text": "Based on this method, Dai et. al [17]used Graph Convolution Network (GCN) to obtain better interaction between words on the shortest dependency path to enhance the performance and Zhang et. al [18]constructed syntactic-guided temporal graph transformer to find deep connections between events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers focus on methodologies rather than using specific datasets.",
      "processing_time": 53.52951622009277,
      "citing_paper_id": "252625384",
      "cited_paper_id": 233307040
    },
    {
      "context_text": "We use the same data division following Naik et. al [9] and Liu et. al [24].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a reference to using the same data division as other works. No verifiable resource names are provided.",
      "processing_time": 54.47899150848389,
      "citing_paper_id": "252625384",
      "cited_paper_id": 237100961
    },
    {
      "context_text": "Liu et. al [24]regarded each document as an uncertainty-guided temporal graph, in which the nodes and edges represented events and event-event relations, respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to document-level event extraction.",
      "processing_time": 52.42901968955994,
      "citing_paper_id": "252625384",
      "cited_paper_id": 237100961
    },
    {
      "context_text": "…model which takes the event sentences with the beginning and end tags and then uses the output vector corresponding to the [ CLS ] of the last layer to extract temporal relations directly; 7) UCGraph [24]: A Graph model using pre-training mechanism to learn inter-dependencies of temporal relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on describing different models used for extracting temporal relations.",
      "processing_time": 54.033897399902344,
      "citing_paper_id": "252625384",
      "cited_paper_id": 237100961
    },
    {
      "context_text": "MaxS ( W j , W i ) represents the maximum semantic similarity between the words W i in sen c and the words W j in sen e following Xu [27].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for calculating semantic similarity.",
      "processing_time": 51.774633169174194,
      "citing_paper_id": "252625384",
      "cited_paper_id": null
    },
    {
      "context_text": "Unsupervised event schema induction based approaches (Chambers and Jurafsky, 2011; Chambers, 2013; Cheung et al., 2013) are also able",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only unsupervised event schema induction approaches. No clear identifiers for datasets are present.",
      "processing_time": 53.51533508300781,
      "citing_paper_id": "231728756",
      "cited_paper_id": 278288
    },
    {
      "context_text": "Unsupervised event schema induction based approaches (Chambers and Jurafsky, 2011; Chambers, 2013; Cheung et al., 2013) are also able",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only unsupervised event schema induction approaches. No clear identifiers for datasets are present.",
      "processing_time": 53.51533508300781,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6341459
    },
    {
      "context_text": "Unsupervised event schema induction based approaches (Chambers and Jurafsky, 2011; Cham-bers, 2013; Cheung et al., 2013) to model the coreference relations and entities at document-level, but have been proved to perform substantially worse than supervised models (Pat-wardhan and Riloff, 2009; Huang…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. No clear identifiers for datasets are present.",
      "processing_time": 53.73854303359985,
      "citing_paper_id": "231728756",
      "cited_paper_id": 278288
    },
    {
      "context_text": "Evaluation Metric The metric for past work on document-level role-filler mentions extraction (Patwardhan and Riloff, 2009; Huang and Riloff, 2011; Du and Cardie, 2020) calculates mention-level precision across all alternative mentions for each rolefiller entity.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 54.16277265548706,
      "citing_paper_id": "231728756",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Evaluation Metric The metric for past work on document-level role-filler mentions extraction (Patwardhan and Riloff, 2009; Huang and Riloff, 2011; Du and Cardie, 2020) calculates mention-level precision across all alternative mentions for each rolefiller entity.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 54.16277265548706,
      "citing_paper_id": "221246218",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Previous state-of-the-art methods include Li et al. (2013) and Li et al. (2015), which explored a variety of hand-designed features.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods and their exploration of hand-designed features.",
      "processing_time": 52.47764801979065,
      "citing_paper_id": "231728756",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Previous state-of-the-art methods include Li et al. (2013) and Li et al. (2015), which explored a variety of hand-designed features.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only previous methods and their exploration of hand-designed features.",
      "processing_time": 52.47764801979065,
      "citing_paper_id": "221246218",
      "cited_paper_id": 14117526
    },
    {
      "context_text": "Document-level template filling (Sundheim, 1991, 1993; Grishman and Sundheim, 1996) is a classic problem in information extraction (IE) and NLP (Jurafsky and Martin, 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods in information extraction and NLP.",
      "processing_time": 52.95161747932434,
      "citing_paper_id": "231728756",
      "cited_paper_id": 5073927
    },
    {
      "context_text": "Document-level template filling (Sundheim, 1991, 1993; Grishman and Sundheim, 1996) is a classic problem in information extraction (IE) and NLP (Jurafsky and Martin, 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods in information extraction and NLP.",
      "processing_time": 52.95161747932434,
      "citing_paper_id": "231728756",
      "cited_paper_id": 5188467
    },
    {
      "context_text": "Document-level template ﬁlling (Sundheim, 1991, 1993; Grishman and Sundheim, 1996) is a classic problem in information extraction (IE) and NLP (Jurafsky and Martin, 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to document-level template filling as a classic problem in IE and NLP.",
      "processing_time": 53.89912176132202,
      "citing_paper_id": "231728756",
      "cited_paper_id": 5073927
    },
    {
      "context_text": "We base the REE task on the original MUC3 formulation (Sundheim, 1991), but simplify it as done in prior research (Huang and Riloff, 2012; Du and Cardie, 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC3"
      ],
      "dataset_descriptions": {
        "MUC3": "Used as a basis for the Relation Extraction and Event (REE) task, simplified from the original formulation for easier application in event extraction research."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'MUC3' which is a specific dataset used for event extraction tasks. However, it does not provide details on how the dataset is used in the current research.",
      "processing_time": 62.8399760723114,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "We base the REE task on the original MUC3 formulation (Sundheim, 1991), but simplify it as done in prior research (Huang and Riloff, 2012; Du and Cardie, 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUC3"
      ],
      "dataset_descriptions": {
        "MUC3": "Used as a basis for the Relation Extraction and Event (REE) task, simplified from the original formulation for easier application in event extraction research."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'MUC3' which is a specific dataset used for event extraction tasks. However, it does not provide details on how the dataset is used in the current research.",
      "processing_time": 62.8399760723114,
      "citing_paper_id": "231728756",
      "cited_paper_id": 14365335
    },
    {
      "context_text": "Similar to (Huang and Riloff, 2012; Du and Cardie, 2020), we use the 1300 documents for training, 200 documents (TST1+TST2) as the development set and 200 documents (TST3+TST4) as the test set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions specific sets of documents used for training, development, and testing, but does not provide a specific, named dataset. The numbers and splits are described generically.",
      "processing_time": 55.82084250450134,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "CohesionExtract (Huang and Riloff, 2012) is a bottom-up approach for event extraction that first aggressively identifies candidate role-fillers, and prune the candidates located in event-irrelevant sentences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'CohesionExtract' but does not refer to it as a dataset. It is described as an approach or method for event extraction.",
      "processing_time": 54.66299510002136,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "to model the coreference relations and entities at document-level, but have been proved to perform substantially worse than supervised models (Patwardhan and Riloff, 2009; Huang and Riloff, 2012).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the performance of unsupervised models compared to supervised models.",
      "processing_time": 53.20578622817993,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "These event roles represent the agents, patients, and instruments associated with terrorism events (Huang and Riloff, 2012).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only event roles in the context of terrorism events. No clear, verifiable dataset names are present.",
      "processing_time": 54.47081017494202,
      "citing_paper_id": "231728756",
      "cited_paper_id": 6644751
    },
    {
      "context_text": "We treat document-level REE as a sequence-tosequence task (Sutskever et al., 2014) in order to better model the cross-role dependencies and crosssentence noun phrase coreference structure.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological approach. The cited paper is about a method, not a dataset.",
      "processing_time": 53.92093086242676,
      "citing_paper_id": "231728756",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "We treat document-level REE as a sequence-to-sequence task (Sutskever et al., 2014) in order to better model the cross-role dependencies and cross-sentence noun phrase coreference structure.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for treating document-level REE as a sequence-to-sequence task.",
      "processing_time": 53.66525173187256,
      "citing_paper_id": "231728756",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Instead of using a sequence-to-sequence learning architecture with separate modules (Sutskever et al., 2014; Bahdanau et al., 2015), we use a single pretrained transformer model (Devlin et al., 2019) for both parts, and introduce no additional ﬁne-tuned parameters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the architecture and training approach rather than data sources.",
      "processing_time": 54.24369287490845,
      "citing_paper_id": "231728756",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Instead of using a sequence-to-sequence learning architecture with separate modules (Sutskever et al., 2014; Bahdanau et al., 2015), we use a single pretrained transformer model (Devlin et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 54.239274978637695,
      "citing_paper_id": "231728756",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Instead of using a sequence-to-sequence learning architecture with separate modules (Sutskever et al., 2014; Bahdanau et al., 2015), we use a single pretrained transformer model (Devlin et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 54.239274978637695,
      "citing_paper_id": "221246218",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "We use CEAF-REE which is covered in Section 3 as the evaluation metric.",
      "catation_intent": "none",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an evaluation metric (CEAF-REE).",
      "processing_time": 52.441792249679565,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "Finally, we calculate the precision, recall and F-measure for CEAF-REE as follows: We list several cases (Figure 6) and their CEAF-REE scores (Table 8) to facilitate understanding.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics and scores.",
      "processing_time": 51.85629224777222,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "Drawing insights from the entity-based CEAF metric (Luo, 2005) from the coreference resolution literature, we design a metric (CEAF-REE) for measuring models’ performance on this documentlevel role-filler entity extraction task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric from coreference resolution literature.",
      "processing_time": 52.46089005470276,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "Drawing insights from the entity-based CEAF metric (Luo, 2005) from the coreference resolution literature, we design a metric ( CEAF-REE ) for measuring models’ performance on this document-level role-ﬁller entity extraction task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric from the coreference resolution literature. No datasets are referenced for use in the research.",
      "processing_time": 54.745535373687744,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "We include more details for our CEAF-TF metric in the appendix.",
      "catation_intent": "research work",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric called CEAF-TF. No datasets are referenced for use in the research.",
      "processing_time": 54.73617458343506,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "• To measure the model’s ability to both extract entities for each role, and implicitly recognize coreferent relations between entity mentions, we design a metric (CEAF-REE) based on a maximum bipartite matching algorithm, drawing insights from the CEAF (Luo, 2005) coreference resolution measure.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating coreference resolution.",
      "processing_time": 52.920169830322266,
      "citing_paper_id": "231728756",
      "cited_paper_id": 11239061
    },
    {
      "context_text": "More recently, neural network based models such as recurrent neural networks (Nguyen et al., 2016; Feng et al., 2018), convolutional neural networks (Nguyen and Grish-man, 2015; Chen et al., 2015) and attention mechanisms (Liu et al., 2017, 2018) have also been shown to help improve performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 53.97129940986633,
      "citing_paper_id": "231728756",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "More recently, neural network based models such as recurrent neural networks (Nguyen et al., 2016; Feng et al., 2018), convolutional neural networks (Nguyen and Grish-man, 2015; Chen et al., 2015) and attention mechanisms (Liu et al., 2017, 2018) have also been shown to help improve performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 53.97129940986633,
      "citing_paper_id": "231728756",
      "cited_paper_id": 52816033
    },
    {
      "context_text": ", 2018), convolutional neural networks (Nguyen and Grishman, 2015; Chen et al., 2015) and attention mechanisms (Liu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 54.3746554851532,
      "citing_paper_id": "231728756",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "As a result of these complications, end-to-end sentence-level event extraction models (Chen et al., 2015; Lample et al., 2016), which dominate the literature, are ill-suited for the REE task, which calls for models that encode information and track entities across a longer context.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the limitations of sentence-level event extraction models for the REE task.",
      "processing_time": 55.31345820426941,
      "citing_paper_id": "231728756",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "It is of great importance for automating many real-world tasks, such as event extraction from newswire (Sundheim, 1991).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a general task of event extraction from newswire. No verifiable resource names are provided.",
      "processing_time": 54.7223596572876,
      "citing_paper_id": "231728756",
      "cited_paper_id": 14365335
    },
    {
      "context_text": "It is of great importance for automating many real-world tasks, such as event extraction from newswire (Sundheim, 1991).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a general task of event extraction from newswire. No verifiable resource names are provided.",
      "processing_time": 54.7223596572876,
      "citing_paper_id": "221246218",
      "cited_paper_id": 14365335
    },
    {
      "context_text": "Duan et al. (2017) and Zhao et al. (2018) leverage document embeddings as additional features to aid event detection.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions document embeddings as additional features for event detection but does not specify any datasets. The cited papers' titles do not mention specific datasets either.",
      "processing_time": 55.07552361488342,
      "citing_paper_id": "231728756",
      "cited_paper_id": 51871927
    },
    {
      "context_text": "Duan et al. (2017) and Zhao et al. (2018) leverage document embeddings as additional features to aid event detection.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions document embeddings as additional features for event detection but does not specify any datasets. The cited papers' titles do not mention specific datasets either.",
      "processing_time": 55.07552361488342,
      "citing_paper_id": "221246218",
      "cited_paper_id": 9778664
    },
    {
      "context_text": "For the machine translation task, He et al. (2018) propose a model which shares the parameters of each layer between the encoder and decoder to regularize and coordinate the learning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its application to a machine translation task.",
      "processing_time": 53.38175415992737,
      "citing_paper_id": "231728756",
      "cited_paper_id": 54088698
    },
    {
      "context_text": "Yao et al. (2019) construct an RE dataset of cross-sentence relations on Wikipedia paragraphs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to construct a large-scale document-level relation extraction dataset from Wikipedia paragraphs, focusing on cross-sentence relations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the construction of a dataset for document-level relation extraction, which is directly relevant to the research topic.",
      "processing_time": 58.90476942062378,
      "citing_paper_id": "231728756",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "TIER (Huang and Riloff, 2011) proposes to first determine the document genre with a classifier and then identify event-relevant sentences and role fillers in the",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (TIER) for document-level event extraction.",
      "processing_time": 52.90283751487732,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "C L\n] 1\n3 M\nay 2\n02 0\nwith separate classifiers for each type of role and for relevant context detection (Patwardhan and Riloff, 2009; Huang and Riloff, 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 55.2983181476593,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "C L\n] 1\n3 M\nay 2\n02 0\nwith separate classifiers for each type of role and for relevant context detection (Patwardhan and Riloff, 2009; Huang and Riloff, 2011).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 55.2983181476593,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Similar to Huang and Riloff (2012), we also incorporate both intra-sentence and cross-sentence features (paragraph-level features), but instead of using manually designed linguistic information,",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methodological approaches. There are no clear identifiers for datasets in the given context.",
      "processing_time": 54.55133533477783,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "TIER (Huang and Riloff, 2011) proposes to first determine the document genre with a classifier and then identify event-relevant sentences and role fillers in the document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction.",
      "processing_time": 51.93186855316162,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "The final extraction decisions are based on the product of normalized sentential and phrasal probabilities; TIER (Huang and Riloff, 2011) proposes a multi-stage approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions TIER, which is a method, not a dataset. No datasets are explicitly mentioned or used in the context provided.",
      "processing_time": 54.62064838409424,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "8011 relevant context detection (Patwardhan and Riloff, 2009; Huang and Riloff, 2011).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to papers. No clear identifiers for datasets are present.",
      "processing_time": 54.02847623825073,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "8011 relevant context detection (Patwardhan and Riloff, 2009; Huang and Riloff, 2011).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to papers. No clear identifiers for datasets are present.",
      "processing_time": 54.02847623825073,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Cohesion Extract obtains substantially better precision and with similar level of recall as compared to GLACIER and TIER.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods (GLACIER and TIER). No verifiable resources are identified.",
      "processing_time": 55.356895446777344,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Cohesion Extract obtains substantially better precision and with similar level of recall as compared to GLACIER and TIER.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods (GLACIER and TIER). No verifiable resources are identified.",
      "processing_time": 55.356895446777344,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Huang and Riloff (2012) propose a bottom-up approach that first aggressively identifies candidate role fillers (with lexico-syntactic pattern features), and then removes the candidates that are in spurious sentences (i.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for identifying event role fillers.",
      "processing_time": 53.62108063697815,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "08 - - TIER (Huang and Riloff, 2011) 50.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or tool called TIER. No verifiable datasets are referenced.",
      "processing_time": 54.730934858322144,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "decisions are based on the product of normalized sentential and phrasal probabilities; TIER (Huang and Riloff, 2011) proposes a multi-stage approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions TIER, which is a method, not a dataset. No datasets are explicitly mentioned or used in the context provided.",
      "processing_time": 55.351590633392334,
      "citing_paper_id": "218630327",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Ji and Grishman (2008) enforce event role consistency across documents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for refining event extraction.",
      "processing_time": 52.33098292350769,
      "citing_paper_id": "218630327",
      "cited_paper_id": 1320606
    },
    {
      "context_text": "Many variations of models have been proposed to mitigate the effect of long sequence length, such as Long Short Term Memory (LSTM) Networks (Hochre-iter and Schmidhuber, 1997; Gers et al., 1999; Graves, 2013) and Gated Recurrent Unit Networks (Cho et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 55.86383318901062,
      "citing_paper_id": "218630327",
      "cited_paper_id": 1697424
    },
    {
      "context_text": "…Layer In the embedding layer, we represent each token x i in the input sequence as the concatenation of its word embedding and contextual token representation: • Word Embedding : We use the 100-dimensional GloVe pre-trained word embeddings (Pennington et al., 2014) trained from 6B Web crawl data.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using GloVe pre-trained word embeddings but does not refer to a specific dataset. GloVe is a method for generating word embeddings, not a dataset.",
      "processing_time": 57.04303526878357,
      "citing_paper_id": "218630327",
      "cited_paper_id": 1957433
    },
    {
      "context_text": "Li et al. (2013, 2015) explore various hand-designed features; Nguyen and Grishman (2015); Nguyen et al. (2016); Chen et al. (2015); Liu et al. (2017, 2018) employ deep learning based models such as recurrent neural networks (RNNs) and convolutional neural network (CNN).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 55.15281677246094,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Li et al. (2013, 2015) explore various hand-designed features; Nguyen and Grishman (2015); Nguyen et al. (2016); Chen et al. (2015); Liu et al. (2017, 2018) employ deep learning based models such as recurrent neural networks (RNNs) and convolutional neural network (CNN).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 55.15281677246094,
      "citing_paper_id": "218630327",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "features; Nguyen and Grishman (2015); Nguyen et al. (2016); Chen et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers. There are no clear identifiers for datasets within the given context.",
      "processing_time": 55.626713275909424,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "features; Nguyen and Grishman (2015); Nguyen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not provide specific details about datasets used. It mentions a method or research work but lacks information on datasets.",
      "processing_time": 55.10477685928345,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "GLACIER (Patwardhan and Riloff, 2009) jointly considers crosssentence and noun phrase evidence in a probabilistic framework to extract role fillers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions GLACIER, which is a method for information extraction, not a dataset. No datasets are explicitly mentioned or used in the given context.",
      "processing_time": 56.445913791656494,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "We compare to the pipeline and manual feature engineering based systems: GLACIER (Patwardhan and Riloff, 2009) consists of a sentential event classifier and a set of plausible role filler recog-",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a system called GLACIER which is a method or model, not a dataset.",
      "processing_time": 55.80024719238281,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "We compare to the pipeline and manual feature engineering based systems: GLACIER (Patwardhan and Riloff, 2009) consists of a sentential event classifier and a set of plausible role filler recognizers for each event role.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a system called GLACIER which is a method or tool, not a dataset.",
      "processing_time": 55.79614782333374,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "GLACIER (Patwardhan and Riloff, 2009) jointly considers cross-",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "GLACIER"
      ],
      "dataset_descriptions": {
        "GLACIER": "Used to jointly consider phrasal and sentential evidence for information extraction, enhancing the model's ability to capture contextual information."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'GLACIER' which is a dataset used for information extraction, specifically for joint consideration of phrasal and sentential evidence.",
      "processing_time": 62.58320713043213,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Apart from event extraction, there has been increasing interest on cross-sentence relation extraction (Mintz et al., 2009; Peng et al., 2017; Jia et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to cross-sentence relation extraction. No verifiable resources are identified.",
      "processing_time": 56.133567571640015,
      "citing_paper_id": "218630327",
      "cited_paper_id": 2797612
    },
    {
      "context_text": "Apart from event extraction, there has been increasing interest on cross-sentence relation extraction (Mintz et al., 2009; Peng et al., 2017; Jia et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to cross-sentence relation extraction. No verifiable resources are identified.",
      "processing_time": 56.133567571640015,
      "citing_paper_id": "218630327",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "First, capturing long-term dependencies in long sequences remains a fundamental challenge for recurrent neural networks (Trinh et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological challenge in RNNs.",
      "processing_time": 53.75483059883118,
      "citing_paper_id": "218630327",
      "cited_paper_id": 4760632
    },
    {
      "context_text": "Capturing Long-term Dependencies for Neural Sequence Models For training neural sequence models such as RNNs, capturing long-term dependencies in sequences remains a fundamental challenge (Trinh et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological challenge in training RNNs.",
      "processing_time": 54.69362449645996,
      "citing_paper_id": "218630327",
      "cited_paper_id": 4760632
    },
    {
      "context_text": "Many variations of models have been proposed to mitigate the effect of long sequence length, such as Long Short Term Memory (LSTM) Networks (Hochreiter and Schmidhuber, 1997; Gers et al., 1999; Graves, 2013) and Gated Recurrent Unit Networks (Cho et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria.",
      "processing_time": 55.95435190200806,
      "citing_paper_id": "218630327",
      "cited_paper_id": 5590763
    },
    {
      "context_text": ", 1999; Graves, 2013) and Gated Recurrent Unit Networks (Cho et al., 2014).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only neural network architectures. No dataset names are present in the text.",
      "processing_time": 55.59801745414734,
      "citing_paper_id": "218630327",
      "cited_paper_id": 5590763
    },
    {
      "context_text": "CRF Layer Drawing inspirations for sentencelevel sequence tagging models on tasks like NER (Lample et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CRF Layer) inspired by sentence-level sequence tagging models for NER.",
      "processing_time": 56.18670439720154,
      "citing_paper_id": "218630327",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "We use a multi-layer (3 layers) bi-directional LSTM encoder on top of the token representations, which we denote as BiLSTM:\n{p1,p2, ...,pm} = BiLSTM({x1,x2, ...,xm})\nCRF Layer Drawing inspirations for sentencelevel sequence tagging models on tasks like NER (Lample et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BiLSTM) and a reference to NER tasks. The cited paper title 'Neural Architectures for Named Entity Recognition' confirms the focus on methods rather than datasets.",
      "processing_time": 59.37713313102722,
      "citing_paper_id": "218630327",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "Neural end-to-end models have been shown to excel at sentence-level information extraction tasks, such as named entity recognition (Lample et al., 2016; Chiu and Nichols, 2016) and ACE-type within-sentence event extraction (Chen et al., 2015; Nguyen et al., 2016; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is about neural end-to-end models excelling at sentence-level tasks, but no datasets are explicitly named.",
      "processing_time": 57.91231727600098,
      "citing_paper_id": "218630327",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "Neural end-to-end models have been shown to excel at sentence-level information extraction tasks, such as named entity recognition (Lample et al., 2016; Chiu and Nichols, 2016) and ACE-type within-sentence event extraction (Chen et al., 2015; Nguyen et al., 2016; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is about neural end-to-end models excelling at sentence-level tasks, but no datasets are explicitly named.",
      "processing_time": 57.91231727600098,
      "citing_paper_id": "218630327",
      "cited_paper_id": 6300165
    },
    {
      "context_text": "Neural end-to-end models have been shown to excel at sentence-level information extraction tasks, such as named entity recognition (Lample et al., 2016; Chiu and Nichols, 2016) and ACE-type within-sentence event extraction (Chen et al., 2015; Nguyen et al., 2016; Wadden et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is about neural end-to-end models excelling at sentence-level tasks, but no datasets are explicitly named.",
      "processing_time": 57.91231727600098,
      "citing_paper_id": "218630327",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Liao and Grishman (2010) explore event type co-occurrence patterns to propagate event clas-siﬁcation decisions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving event extraction using document-level cross-event inference.",
      "processing_time": 55.528066873550415,
      "citing_paper_id": "218630327",
      "cited_paper_id": 11187670
    },
    {
      "context_text": "Second, although pretrained bi-directional transformer models such as BERT (Devlin et al., 2019) better capture long-distance dependencies as compared to an RNN architecture, they still have a constraint on the maximum length of the sequence, which is below the length of many articles about events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their limitations. There are no verifiable resources or datasets mentioned.",
      "processing_time": 56.021708250045776,
      "citing_paper_id": "218630327",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Transformer based models (Vaswani et al., 2017; Devlin et al., 2019) have also shown improvements in modeling long text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their improvements in modeling long text.",
      "processing_time": 54.63736963272095,
      "citing_paper_id": "218630327",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "• Pre-trained LM representation: Contextualized embeddings produced by pre-trained language models (Peters et al., 2018; Devlin et al., 2019) have been proved to be capable of modeling context beyond the sentence boundary and improve performance on a variety of tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only pre-trained language models and their capabilities. No verifiable datasets are referenced.",
      "processing_time": 55.69176769256592,
      "citing_paper_id": "218630327",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Specifically, we use the average of all the 12 layers’ representations and freeze the\nweights (Peters et al., 2019) during training after empirical trials4.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for using pretrained representations.",
      "processing_time": 54.818519592285156,
      "citing_paper_id": "218630327",
      "cited_paper_id": 76666127
    },
    {
      "context_text": "Specifically, we use the average of all the 12 layers’ representations and freeze the weights (Peters et al., 2019) during training",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method for using pretrained representations.",
      "processing_time": 54.62823820114136,
      "citing_paper_id": "218630327",
      "cited_paper_id": 76666127
    },
    {
      "context_text": "There has also been work on unsupervised event schema induction (Chambers and Jurafsky, 2011; Chambers, 2013) and open-domain event extraction (Liu et al., 2019) from documents: the main idea is to group entities corresponding to the same role into an event template.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general concepts and methods. No clear identifiers for datasets are present.",
      "processing_time": 56.00755715370178,
      "citing_paper_id": "218630327",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Similar results regarding the context length have also been found in document-level coreference resolution (Joshi et al., 2019).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a research finding related to document-level coreference resolution.",
      "processing_time": 55.511263847351074,
      "citing_paper_id": "218630327",
      "cited_paper_id": 201646551
    },
    {
      "context_text": "We model labeling decisions jointly using a conditional random field (Lafferty et al., 2001).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (conditional random field).",
      "processing_time": 54.83412146568298,
      "citing_paper_id": "218630327",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "For instance, (Ren et al., 2017; Zheng et al., 2017; Zeng et al., 2018a; Wang et al., 2018) focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.876100301742554,
      "citing_paper_id": "119308902",
      "cited_paper_id": 1724837
    },
    {
      "context_text": "For instance, (Ren et al., 2017; Zheng et al., 2017; Zeng et al., 2018a; Wang et al., 2018) focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.876100301742554,
      "citing_paper_id": "119308902",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "For instance, (Ren et al., 2017; Zheng et al., 2017; Zeng et al., 2018a; Wang et al., 2018) focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.876100301742554,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51605731
    },
    {
      "context_text": "For instance, (Ren et al., 2017; Zheng et al., 2017; Zeng et al., 2018a; Wang et al., 2018) focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.876100301742554,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51870827
    },
    {
      "context_text": "For instance, [Ren et al. , 2017; Zheng et al. , 2017; Zeng et al. , 2018a; Wang et al. , 2018] focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about specific datasets.",
      "processing_time": 58.02267074584961,
      "citing_paper_id": "119308902",
      "cited_paper_id": 1724837
    },
    {
      "context_text": "For instance, [Ren et al. , 2017; Zheng et al. , 2017; Zeng et al. , 2018a; Wang et al. , 2018] focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about specific datasets.",
      "processing_time": 58.02267074584961,
      "citing_paper_id": "119308902",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "For instance, [Ren et al. , 2017; Zheng et al. , 2017; Zeng et al. , 2018a; Wang et al. , 2018] focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about specific datasets.",
      "processing_time": 58.02267074584961,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51605731
    },
    {
      "context_text": "For instance, [Ren et al. , 2017; Zheng et al. , 2017; Zeng et al. , 2018a; Wang et al. , 2018] focused on jointly extracting entities and inter-entity relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of jointly extracting entities and inter-entity relations. The cited papers' titles do not provide additional information about specific datasets.",
      "processing_time": 58.02267074584961,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51870827
    },
    {
      "context_text": "To mitigate such problems, we utilize the scheduled sampling (Bengio et al., 2015) to gradually switch the inputs of document-level entity encoding from ground-truth entity mentions to model recognized ones.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (scheduled sampling).",
      "processing_time": 54.70253038406372,
      "citing_paper_id": "119308902",
      "cited_paper_id": 1820089
    },
    {
      "context_text": "Although a great number of efforts [Ahn, 2006; Ji and Gr-ishman, 2008; Liao and Grishman, 2010; Hong et al. , 2011; Riedel and McCallum, 2011; Li et al. , 2013; Li et al. , 2014; Chen et al. , 2015; Yang and Mitchell, 2016; Nguyen et al. , 2016; Liu et al. , 2017; Sha et al. , 2018; Zhang and Ji,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 57.05091047286987,
      "citing_paper_id": "119308902",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Although a great number of efforts [Ahn, 2006; Ji and Gr-ishman, 2008; Liao and Grishman, 2010; Hong et al. , 2011; Riedel and McCallum, 2011; Li et al. , 2013; Li et al. , 2014; Chen et al. , 2015; Yang and Mitchell, 2016; Nguyen et al. , 2016; Liu et al. , 2017; Sha et al. , 2018; Zhang and Ji,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 57.05091047286987,
      "citing_paper_id": "119308902",
      "cited_paper_id": 18198203
    },
    {
      "context_text": "Traditionally, when applying DS to relation extraction, researchers put huge efforts into alleviating labeling noises (Riedel et al., 2010; Lin et al., 2016; Feng et al., 2018; Zheng et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research efforts in relation extraction. No verifiable resources are identified.",
      "processing_time": 56.289419412612915,
      "citing_paper_id": "119308902",
      "cited_paper_id": 2386383
    },
    {
      "context_text": "Traditionally, when applying DS to relation extraction, researchers put huge efforts into alleviating labeling noises (Riedel et al., 2010; Lin et al., 2016; Feng et al., 2018; Zheng et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research efforts in relation extraction. No verifiable resources are identified.",
      "processing_time": 56.289419412612915,
      "citing_paper_id": "119308902",
      "cited_paper_id": 182953200
    },
    {
      "context_text": "Besides, we employ the Adam [ Kingma and Ba, 2015 ] optimizer with the learning rate 1 e − 4 , train for at most 100 epochs and pick the best epoch by the validation score on the development set.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Adam optimizer).",
      "processing_time": 54.57869362831116,
      "citing_paper_id": "119308902",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "…the scaled dot-product attention [Vaswani et al. , 2017] operations: to produce a single embedding ˆ x ∈ R d w , where Q ∈ R d w is a trainable parameter, LayerNorm is the layer normalization [Ba et al. , 2016] and Dropout is an effective technique to avoid overﬁtting [Srivastava et al. , 2014].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques such as scaled dot-product attention, layer normalization, and dropout. These are not datasets.",
      "processing_time": 57.10264205932617,
      "citing_paper_id": "119308902",
      "cited_paper_id": 8236317
    },
    {
      "context_text": "Therefore, (Chen et al., 2017; Yang et al., 2018) employed either linguistic resources or predefined dictionaries for trigger-words labeling.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of linguistic resources or predefined dictionaries. No clear, verifiable dataset names are provided.",
      "processing_time": 56.27757692337036,
      "citing_paper_id": "119308902",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Therefore, [Chen et al. , 2017; Yang et al. , 2018] employed either linguistic resources or predeﬁned dictionaries for trigger-words labeling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of linguistic resources or predefined dictionaries. No clear, verifiable dataset names are provided.",
      "processing_time": 56.27750778198242,
      "citing_paper_id": "119308902",
      "cited_paper_id": 12108307
    },
    {
      "context_text": "Moreover, for the entity recognition part, we refer readers to [Huang et al. , 2015] for details about stacking the conditional random ﬁeld (CRF) layer over encoded representations.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CRF layer) used in sequence tagging.",
      "processing_time": 55.31901526451111,
      "citing_paper_id": "119308902",
      "cited_paper_id": 12740621
    },
    {
      "context_text": "We conduct this task at the sentence level and follow a classic method, BI-LSTM-CRF (Huang et al., 2015), that first encodes the token sequence and then adds a conditional random field (CRF) layer to facilitate the sequence tagging.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BI-LSTM-CRF) used for sequence tagging.",
      "processing_time": 55.791717290878296,
      "citing_paper_id": "119308902",
      "cited_paper_id": 12740621
    },
    {
      "context_text": "…same to the focus of this paper, a few studies aimed at designing joint models for the entity and event extraction, such as handcrafted-feature-based [Li et al. , 2014; Yang and Mitchell, 2016; Judea and Strube, 2016] and neural-network-based [ Zhang and Ji, 2018; Nguyen and Nguyen, 2019] models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods. No verifiable resources are identified.",
      "processing_time": 56.01565504074097,
      "citing_paper_id": "119308902",
      "cited_paper_id": 14175558
    },
    {
      "context_text": "…same to the focus of this paper, a few studies aimed at designing joint models for the entity and event extraction, such as handcrafted-feature-based [Li et al. , 2014; Yang and Mitchell, 2016; Judea and Strube, 2016] and neural-network-based [ Zhang and Ji, 2018; Nguyen and Nguyen, 2019] models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and methods. No verifiable resources are identified.",
      "processing_time": 56.01565504074097,
      "citing_paper_id": "119308902",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "…[Ahn, 2006; Ji and Gr-ishman, 2008; Liao and Grishman, 2010; Hong et al. , 2011; Riedel and McCallum, 2011; Li et al. , 2013; Li et al. , 2014; Chen et al. , 2015; Yang and Mitchell, 2016; Nguyen et al. , 2016; Liu et al. , 2017; Sha et al. , 2018; Zhang and Ji, 2018; Nguyen and Nguyen, 2019…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 57.34948921203613,
      "citing_paper_id": "119308902",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "Although a great number of efforts (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Riedel and McCallum, 2011; Li et al., 2013, 2014; Chen et al., 2015; Yang and Mitchell, 2016; Nguyen et al., 2016; Liu et al., 2017; Sha et al., 2018; Zhang and Ji, 2018; Nguyen and Nguyen, 2019; Wang et al., 2019) have been put on EE, most of them are based on ACE 20052, an expert-annotated benchmark, which only tagged event arguments within the sentence scope.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used to tag event arguments within the sentence scope, serving as a benchmark for event extraction systems."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ACE 2005' as an expert-annotated benchmark used for event extraction, which fits the criteria for a dataset. It is used to tag event arguments within the sentence scope.",
      "processing_time": 65.46863722801208,
      "citing_paper_id": "119308902",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "In the meantime, the same to the focus of this paper, a few studies aimed at designing joint models for the entity and event extraction, such as handcrafted-feature-based (Li et al., 2014; Yang and Mitchell, 2016; Judea and Strube, 2016) and neural-network-based (Zhang and Ji, 2018; Nguyen and Nguyen, 2019) models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets.",
      "processing_time": 55.4791533946991,
      "citing_paper_id": "119308902",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "…number of efforts [Ahn, 2006; Ji and Gr-ishman, 2008; Liao and Grishman, 2010; Hong et al. , 2011; Riedel and McCallum, 2011; Li et al. , 2013; Li et al. , 2014; Chen et al. , 2015; Yang and Mitchell, 2016; Nguyen et al. , 2016; Liu et al. , 2017; Sha et al. , 2018; Zhang and Ji, 2018; Nguyen…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various research works. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 57.74269700050354,
      "citing_paper_id": "119308902",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "On the other hand, another recent work [Zeng et al. , 2018b] showed that directly labeling event arguments without trigger words was also feasible.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for labeling event arguments without trigger words.",
      "processing_time": 55.77601671218872,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51870827
    },
    {
      "context_text": "Some previous studies [Zeng et al. , 2018b] attempted to use a similar no-trigger-words design, but they only considered the SEE setting and cannot be directly applied to the DEE setting.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context focuses on the limitations of previous work in a specific setting.",
      "processing_time": 56.90991020202637,
      "citing_paper_id": "119308902",
      "cited_paper_id": 51870827
    },
    {
      "context_text": "To address this problem, some researches attempted to adapt distant supervision (DS) to the EE setting, since DS has shown promising results by employing knowledge bases to generate training data for relation extraction [Mintz et al., 2009] automatically.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'knowledge bases' but does not specify a particular dataset. It is unclear if a specific knowledge base is being referred to, and there are no multi-word proper nouns or acronyms that could be identified as a dataset.",
      "processing_time": 59.467018365859985,
      "citing_paper_id": "119308902",
      "cited_paper_id": null
    },
    {
      "context_text": ", 2018], attempted to explore DEE on ChFinAnn, by employing distant supervision (DS) [Mintz et al., 2009] to generate EE data and performing a two-stage extraction: 1) a sequence tagging model for SEE, and 2) a key-event-sentence detection model to detect the key sentence and an arguments-completion strategy that padded missing arguments from surrounding sentences for DEE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ChFinAnn"
      ],
      "dataset_descriptions": {
        "ChFinAnn": "Used to explore document-level event extraction through distant supervision and a two-stage process involving sequence tagging and key-event-sentence detection."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'ChFinAnn' as a specific dataset used for document-level event extraction. It describes the methodology involving distant supervision and a two-stage extraction process.",
      "processing_time": 63.59584951400757,
      "citing_paper_id": "119308902",
      "cited_paper_id": null
    },
    {
      "context_text": "To address this problem, some researches attempted to adapt distant supervision (DS) to the EE setting, since DS has shown promising results by employing knowledge bases to generate training data for relation extraction [Mintz et al. , 2009] automatically.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (distant supervision) and its application to event extraction. No verifiable resources are named.",
      "processing_time": 57.2302041053772,
      "citing_paper_id": "119308902",
      "cited_paper_id": null
    },
    {
      "context_text": "Using fuzzy string match techniques (Levenshtein, 1965), we only mark the longer argument span in case of redundancy.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for handling redundant argument spans.",
      "processing_time": 55.51193571090698,
      "citing_paper_id": "253840075",
      "cited_paper_id": 60827152
    },
    {
      "context_text": "We curate such a dataset by collating the following datasets: i) DROP Dataset (Dua et al., 2019) which is an abstractive, reasoning QA dataset with a special focus on numerical reasoning; ii) Hindi annotated instances of MLQA (Lewis et al., 2020) and XQuAD (Artetxe et al., 2020) datasets and iii) Bengali annotated instances from TyDi QA dataset (Clark et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DROP Dataset",
        "Hindi annotated instances of MLQA",
        "Hindi annotated instances of XQuAD",
        "Bengali annotated instances from TyDi QA"
      ],
      "dataset_descriptions": {
        "DROP Dataset": "Used for abstractive, reasoning-based question answering with a focus on numerical reasoning, contributing to a comprehensive dataset for document-level event extraction.",
        "Hindi annotated instances of MLQA": "Used to provide Hindi-language question-answer pairs, enhancing cross-lingual capabilities in the collated dataset for document-level event extraction.",
        "Hindi annotated instances of XQuAD": "Used to provide additional Hindi-language question-answer pairs, further enriching the dataset for document-level event extraction.",
        "Bengali annotated instances from TyDi QA": "Used to provide Bengali-language question-answer pairs, expanding the linguistic diversity of the dataset for document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets that are being collated for a new dataset. Each dataset is clearly identified and has a specific purpose in the research.",
      "processing_time": 74.17870545387268,
      "citing_paper_id": "253840075",
      "cited_paper_id": 67855846
    },
    {
      "context_text": "We curate such a dataset by collating the following datasets: i) DROP Dataset (Dua et al., 2019) which is an abstractive, reasoning QA dataset with a special focus on numerical reasoning; ii) Hindi annotated instances of MLQA (Lewis et al., 2020) and XQuAD (Artetxe et al., 2020) datasets and iii) Bengali annotated instances from TyDi QA dataset (Clark et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DROP Dataset",
        "Hindi annotated instances of MLQA",
        "Hindi annotated instances of XQuAD",
        "Bengali annotated instances from TyDi QA"
      ],
      "dataset_descriptions": {
        "DROP Dataset": "Used for abstractive, reasoning-based question answering with a focus on numerical reasoning, contributing to a comprehensive dataset for document-level event extraction.",
        "Hindi annotated instances of MLQA": "Used to provide Hindi-language question-answer pairs, enhancing cross-lingual capabilities in the collated dataset for document-level event extraction.",
        "Hindi annotated instances of XQuAD": "Used to provide additional Hindi-language question-answer pairs, further enriching the dataset for document-level event extraction.",
        "Bengali annotated instances from TyDi QA": "Used to provide Bengali-language question-answer pairs, expanding the linguistic diversity of the dataset for document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets that are being collated for a new dataset. Each dataset is clearly identified and has a specific purpose in the research.",
      "processing_time": 74.17870545387268,
      "citing_paper_id": "253840075",
      "cited_paper_id": 204734128
    },
    {
      "context_text": "We curate such a dataset by collating the following datasets: i) DROP Dataset (Dua et al., 2019) which is an abstractive, reasoning QA dataset with a special focus on numerical reasoning; ii) Hindi annotated instances of MLQA (Lewis et al., 2020) and XQuAD (Artetxe et al., 2020) datasets and iii)…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DROP Dataset",
        "Hindi annotated instances of MLQA",
        "XQuAD"
      ],
      "dataset_descriptions": {
        "DROP Dataset": "Used for its abstractive, reasoning QA tasks with a focus on numerical reasoning, enhancing the complexity of the curated dataset.",
        "Hindi annotated instances of MLQA": "Incorporated to provide multilingual capabilities, specifically Hindi annotations, enriching the diversity of the curated dataset.",
        "XQuAD": "Included for cross-lingual question answering, contributing to the multilingual aspects of the curated dataset."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific datasets used for curating a new dataset, which are relevant to the topic of document-level event extraction.",
      "processing_time": 70.85534834861755,
      "citing_paper_id": "253840075",
      "cited_paper_id": 67855846
    },
    {
      "context_text": "…Dataset (Dua et al., 2019) which is an abstractive, reasoning QA dataset with a special focus on numerical reasoning; ii) Hindi annotated instances of MLQA (Lewis et al., 2020) and XQuAD (Artetxe et al., 2020) datasets and iii) Bengali annotated instances from TyDi QA dataset (Clark et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Dataset (Dua et al., 2019)",
        "MLQA",
        "XQuAD",
        "TyDi QA"
      ],
      "dataset_descriptions": {
        "Dataset (Dua et al., 2019)": "Used for abstractive, reasoning QA with a focus on numerical reasoning, enhancing the model's ability to handle complex questions.",
        "MLQA": "Hindi annotated instances used to evaluate cross-lingual performance, specifically for evaluating model performance on extractive question answering tasks.",
        "XQuAD": "Hindi annotated instances used to evaluate cross-lingual performance, specifically for assessing model robustness across different languages.",
        "TyDi QA": "Bengali annotated instances used to evaluate information-seeking question answering in typologically diverse languages, focusing on multilingual capabilities."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets: Dataset (Dua et al., 2019), MLQA (Lewis et al., 2020), and XQuAD (Artetxe et al., 2020), and TyDi QA (Clark et al., 2020). These are clearly identified and used in the research.",
      "processing_time": 75.18850946426392,
      "citing_paper_id": "253840075",
      "cited_paper_id": 204734128
    },
    {
      "context_text": "…Dataset (Dua et al., 2019) which is an abstractive, reasoning QA dataset with a special focus on numerical reasoning; ii) Hindi annotated instances of MLQA (Lewis et al., 2020) and XQuAD (Artetxe et al., 2020) datasets and iii) Bengali annotated instances from TyDi QA dataset (Clark et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Dataset (Dua et al., 2019)",
        "MLQA",
        "XQuAD",
        "TyDi QA"
      ],
      "dataset_descriptions": {
        "Dataset (Dua et al., 2019)": "Used for abstractive, reasoning QA with a focus on numerical reasoning, enhancing the model's ability to handle complex questions.",
        "MLQA": "Hindi annotated instances used to evaluate cross-lingual performance, specifically for evaluating model performance on extractive question answering tasks.",
        "XQuAD": "Hindi annotated instances used to evaluate cross-lingual performance, specifically for assessing model robustness across different languages.",
        "TyDi QA": "Bengali annotated instances used to evaluate information-seeking question answering in typologically diverse languages, focusing on multilingual capabilities."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions three specific datasets: Dataset (Dua et al., 2019), MLQA (Lewis et al., 2020), and XQuAD (Artetxe et al., 2020), and TyDi QA (Clark et al., 2020). These are clearly identified and used in the research.",
      "processing_time": 75.18850946426392,
      "citing_paper_id": "253840075",
      "cited_paper_id": 212657414
    },
    {
      "context_text": "In our work, we adopt (Du and Cardie, 2020; Feng et al., 2020)’s idea of reducing our related task of Document-Level Event Argument Aggregation to that of Natural Language Question Answering.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The context focuses on adopting an idea from other researchers' work.",
      "processing_time": 57.243401765823364,
      "citing_paper_id": "253840075",
      "cited_paper_id": 225039792
    },
    {
      "context_text": "A very recently published work related to the task of Event Argument Generation is that of (Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a related work on event argument generation.",
      "processing_time": 56.17960572242737,
      "citing_paper_id": "253840075",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "While we use the same English documents as those used in the ArgFuse dataset (Kar et al., 2021), we source the Hindi and Bengali documents from reputed news websites.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ArgFuse"
      ],
      "dataset_descriptions": {
        "ArgFuse": "Used to source English documents for document-level event argument aggregation, applying a weakly-supervised framework to enhance event extraction accuracy."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions using the ArgFuse dataset for English documents, which is relevant to document-level event extraction. The Hindi and Bengali documents are sourced from news websites, not a specific dataset.",
      "processing_time": 65.11545872688293,
      "citing_paper_id": "253840075",
      "cited_paper_id": 235490449
    },
    {
      "context_text": "Prompt-based methods have recently gained popularity in a number of related tasks like entity extraction(Wang et al., 2022), question answering(Liu et al., 2022) and text generation(Li et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and tasks. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 57.233760833740234,
      "citing_paper_id": "253840075",
      "cited_paper_id": 247155039
    },
    {
      "context_text": "We apply layer nor-10809 malization (Ba et al., 2016) and dropout (Srivastava et al., 2014) between the EIG reasoning network layers.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (layer normalization and dropout).",
      "processing_time": 56.01808285713196,
      "citing_paper_id": "259370545",
      "cited_paper_id": 6844431
    },
    {
      "context_text": "Early feature-based methods explore different resources for causal expressions, such as lexical and syntactic patterns (Riaz and Girju, 2013, 2014b,a), causality cues or markers (Do et al., 2011; Hidey and McKeown, 2016), temporal patterns (Ning et al., 2018), statistical information (Hashimoto et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses various resources and methods for identifying causal expressions but does not cite any named datasets.",
      "processing_time": 58.18074417114258,
      "citing_paper_id": "259370545",
      "cited_paper_id": 9130816
    },
    {
      "context_text": "Early feature-based methods explore different resources for causal expressions, such as lexical and syntactic patterns (Riaz and Girju, 2013, 2014b,a), causality cues or markers (Do et al., 2011; Hidey and McKeown, 2016), temporal patterns (Ning et al., 2018), statistical information (Hashimoto et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses various resources and methods for identifying causal expressions but does not cite any named datasets.",
      "processing_time": 58.18074417114258,
      "citing_paper_id": "259370545",
      "cited_paper_id": 15920102
    },
    {
      "context_text": "…for causal expressions, such as lexical and syntactic patterns (Riaz and Girju, 2013, 2014b,a), causality cues or markers (Do et al., 2011; Hidey and McKeown, 2016), temporal patterns (Ning et al., 2018), statistical information (Hashimoto et al., 2014; Hu et al., 2017), and weakly…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and approaches for identifying causal relations. No clear, verifiable resource names are present.",
      "processing_time": 57.750327825546265,
      "citing_paper_id": "259370545",
      "cited_paper_id": 9137624
    },
    {
      "context_text": "We also use the Stanford CoreNLP toolkit (Manning et al., 2014) for a supplement.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Stanford CoreNLP toolkit, which is a software tool, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 57.747291803359985,
      "citing_paper_id": "259370545",
      "cited_paper_id": 14068874
    },
    {
      "context_text": "…and syntactic patterns (Riaz and Girju, 2013, 2014b,a), causality cues or markers (Do et al., 2011; Hidey and McKeown, 2016), temporal patterns (Ning et al., 2018), statistical information (Hashimoto et al., 2014; Hu et al., 2017), and weakly supervised data (Hashimoto, 2019; Zuo et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only refers to various types of data and methods used in research, such as syntactic patterns, causality cues, temporal patterns, and weakly supervised data.",
      "processing_time": 60.55415916442871,
      "citing_paper_id": "259370545",
      "cited_paper_id": 17227879
    },
    {
      "context_text": "…and syntactic patterns (Riaz and Girju, 2013, 2014b,a), causality cues or markers (Do et al., 2011; Hidey and McKeown, 2016), temporal patterns (Ning et al., 2018), statistical information (Hashimoto et al., 2014; Hu et al., 2017), and weakly supervised data (Hashimoto, 2019; Zuo et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only refers to various types of data and methods used in research, such as syntactic patterns, causality cues, temporal patterns, and weakly supervised data.",
      "processing_time": 60.55415916442871,
      "citing_paper_id": "259370545",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "We optimize our model with AdamW (Loshchilov and Hutter, 2019) using a learning rate of 2e-5 with a linear warm-up for the first 8% steps.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (AdamW) for optimizing a model.",
      "processing_time": 56.444886207580566,
      "citing_paper_id": "259370545",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "Due to DSGCN (Zhao et al., 2021) does not provide re-sults on benchmark datasets and does not release codes, we do not compare with it here.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions DSGCN but does not refer to any specific dataset. It only discusses the lack of results on benchmark datasets and the absence of released code.",
      "processing_time": 58.37371611595154,
      "citing_paper_id": "259370545",
      "cited_paper_id": 233874227
    },
    {
      "context_text": "By removing: i) event centrality incorporation, ii) event pair nodes and their relevant edges, iii) edge features and modifying g accordingly, CHEER is scalable to DSGCN. (3) ERGO (Chen et al., 2022) has only event-pair nodes and performs self-attention aggregation: (cid:16) (cid:17) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 57.21564507484436,
      "citing_paper_id": "259370545",
      "cited_paper_id": 233874227
    },
    {
      "context_text": "By removing: i) event centrality incorporation, ii) event pair nodes and their relevant edges, iii) edge features and modifying g accordingly, CHEER is scalable to DSGCN. (3) ERGO (Chen et al., 2022) has only event-pair nodes and performs self-attention aggregation: (cid:16) (cid:17) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 57.21564507484436,
      "citing_paper_id": "259370545",
      "cited_paper_id": 248218685
    },
    {
      "context_text": "DSGCN (Zhao et al., 2021) uses a graph inference mechanism to capture interaction among events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions DSGCN, which is a method, not a dataset. No specific dataset is mentioned or used in the context.",
      "processing_time": 57.39200568199158,
      "citing_paper_id": "259370545",
      "cited_paper_id": 233874227
    },
    {
      "context_text": "(2) DSGCN (Zhao et al., 2021) has only event nodes and uses a combination of GCNs: g z (cid:16) (cid:17) , where α k denotes a feature filter.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DSGCN) and its components. There are no clear identifiers for datasets in the citation context.",
      "processing_time": 58.34507632255554,
      "citing_paper_id": "259370545",
      "cited_paper_id": 233874227
    },
    {
      "context_text": "(3) CauSeRL (Zuo et al., 2021a), which learns contextspecific causal patterns from external causal statements.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'CauSeRL' as a method for learning context-specific causal patterns, not as a dataset. No datasets are explicitly mentioned.",
      "processing_time": 57.84988856315613,
      "citing_paper_id": "259370545",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "(3) CauSeRL (Zuo et al., 2021a), which learns context-specific causal patterns from external causal statements.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'CauSeRL' as a method for learning context-specific causal patterns, not a dataset. No datasets are explicitly mentioned.",
      "processing_time": 57.66991853713989,
      "citing_paper_id": "259370545",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "To deal with implicit causal relations, Cao et al. (2021) incorporate external knowledge from Con-ceptNet (Speer et al., 2017), and Zuo et al. (2021a) learn context-specific causal patterns from external causal statements.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of ConceptNet and external causal statements, but does not specify a dataset. These are methods or resources used to enhance causal relation identification.",
      "processing_time": 58.25504207611084,
      "citing_paper_id": "259370545",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "(4) LearnDA (Zuo et al., 2021b), which uses knowledge bases to augment training data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'knowledge bases' but does not specify a particular dataset. The term 'training data' is too generic and lacks a specific identifier.",
      "processing_time": 57.351314544677734,
      "citing_paper_id": "259370545",
      "cited_paper_id": 235313618
    },
    {
      "context_text": "It is a fundamental NLP task and beneficial to various applications, such as question answering (Shi et al., 2021; Sui et al., 2022) and future event forecasting (Hashimoto, 2019; Bai et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of NLP tasks. No dataset names are present in the text.",
      "processing_time": 57.34545564651489,
      "citing_paper_id": "259370545",
      "cited_paper_id": 240288666
    },
    {
      "context_text": ", 2022) and future event forecasting (Hashimoto, 2019; Bai et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing event forecasting and script event prediction.",
      "processing_time": 56.589816093444824,
      "citing_paper_id": "259370545",
      "cited_paper_id": 240288666
    },
    {
      "context_text": ", 2021), and event argument extraction (Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to event argument extraction. No verifiable resources are identified.",
      "processing_time": 56.94974732398987,
      "citing_paper_id": "259370545",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Following the success of sentence-level natural language understanding, many tasks are extended to the entire document, such as relation extraction (Yao et al., 2019), natural language inference (Yin et al., 2021), and event argument extraction (Ma et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks and extensions to document-level processing.",
      "processing_time": 56.29776644706726,
      "citing_paper_id": "259370545",
      "cited_paper_id": 247084444
    },
    {
      "context_text": "Following ERGO (Chen et al., 2022), we adopt the focal loss (Lin et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (focal loss) and a paper (ERGO).",
      "processing_time": 57.06812262535095,
      "citing_paper_id": "259370545",
      "cited_paper_id": 248218685
    },
    {
      "context_text": "To avoid noisy and exhaustive relation extraction, ERGO (Chen et al., 2022) instead takes each event pair as nodes and leverages GNN on the relational graph for high-order causal transitivity, e.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (ERGO) and its application. The context focuses on the methodology and approach rather than a specific dataset.",
      "processing_time": 58.41508078575134,
      "citing_paper_id": "259370545",
      "cited_paper_id": 248218685
    },
    {
      "context_text": "To avoid noisy and exhaustive relation extraction, ERGO (Chen et al., 2022) instead takes each event pair as nodes and leverages GNN on the relational graph for high-order causal transitivity, e.g., cause(A, B) ∧ cause(B, C) ⇒ cause(A, C) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (ERGO) and its application. The context focuses on the methodology and approach rather than the use of a particular dataset.",
      "processing_time": 59.21119976043701,
      "citing_paper_id": "259370545",
      "cited_paper_id": 248218685
    },
    {
      "context_text": "(5) ERGO (Chen et al., 2022), which builds a relational graph and model interaction between event pairs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions ERGO, which is a method for building a relational graph and modeling interactions between event pairs. It does not mention a specific dataset.",
      "processing_time": 57.37774348258972,
      "citing_paper_id": "259370545",
      "cited_paper_id": 248218685
    },
    {
      "context_text": "(3) ERGO (Chen et al., 2022) has only eventpair nodes and performs self-attention aggregation:",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions ERGO, which is a method or model, not a dataset. No other datasets are mentioned in the citation span.",
      "processing_time": 57.46567463874817,
      "citing_paper_id": "259370545",
      "cited_paper_id": 248218685
    },
    {
      "context_text": "ERGO (Chen et al., 2022) builds a relational graph and model interaction between event pairs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions ERGO, which is a method or model, not a dataset. There are no specific datasets mentioned in the citation span.",
      "processing_time": 57.641303300857544,
      "citing_paper_id": "259370545",
      "cited_paper_id": 248218685
    },
    {
      "context_text": "Following conventions (Chen et al., 2022), we add special tokens at the start and end of D (i.e., “ [CLS] ” and “ [SEP] ”), and insert additional special tokens “ <t> ” and “ </t> ”’ at the start and end of all the events to mark the event positions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only special tokens and their usage in marking event positions. The cited paper title suggests a method or model rather than a dataset.",
      "processing_time": 58.175055742263794,
      "citing_paper_id": "259370545",
      "cited_paper_id": 248218685
    },
    {
      "context_text": "Following ERGO (Chen et al., 2022), we adopt the focal loss (Lin et al., 2017) to alleviate the false-negative issue (i.e., the number of negative samples during training far exceeds that of positives).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and findings. The context focuses on adopting a specific loss function to address a training issue.",
      "processing_time": 57.52572679519653,
      "citing_paper_id": "259370545",
      "cited_paper_id": 248218685
    },
    {
      "context_text": "Following conventions (Chen et al., 2022), we add special tokens at the start and end of D (i.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model (ERGO) and a general reference to 'D', which is likely a dataset but not specified.",
      "processing_time": 57.934229373931885,
      "citing_paper_id": "259370545",
      "cited_paper_id": 248218685
    },
    {
      "context_text": "[21], to exploit the information of all available sentences, we can use the attention mechanism to aggregate sentence-level features.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (attention mechanism) for aggregating sentence-level features.",
      "processing_time": 56.62591505050659,
      "citing_paper_id": "235681526",
      "cited_paper_id": 397533
    },
    {
      "context_text": "[20] selected the most valuable sentence to represent the whole sentence bag d and the highest probability sentence is defined as follows:",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for selecting sentences in relation extraction.",
      "processing_time": 55.98152160644531,
      "citing_paper_id": "235681526",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "In the stage of event argument extraction, both of them regard it as a sequence labeling problem similar to NER, where BiLSTM-CRF [9] is a classic model to address this issue.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (BiLSTM-CRF) and a general task (sequence labeling).",
      "processing_time": 56.866371154785156,
      "citing_paper_id": "235681526",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "BiLSTM-CRF is a classic model to address the NER task and has once achieved the state-of-the-art result in accuracy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BiLSTM-CRF) and its performance in NER tasks.",
      "processing_time": 56.75056481361389,
      "citing_paper_id": "235681526",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "In the stage of event argument extraction, both of them regard it as a sequence labeling problem similar to NER, where BiLSTM-CRF [6] is a classic model to address this issue.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (BiLSTM-CRF) which is not included as per instructions.",
      "processing_time": 56.63255786895752,
      "citing_paper_id": "235681526",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "However, most existing studies merely extract arguments within the sentence scope [1, 2, 3], dubbed as sentence-level EE (SEE).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to existing studies. No verifiable resources are identified.",
      "processing_time": 56.238178968429565,
      "citing_paper_id": "235681526",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "[5] claim that critical information can be also inferred implicitly from all sentences, so a max pooling operation is employed to capture the most valuable features in various aspects from all sentences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. There are no clear identifiers for datasets in the given context.",
      "processing_time": 56.50204420089722,
      "citing_paper_id": "235681526",
      "cited_paper_id": 16389974
    },
    {
      "context_text": "Yang et al. [7] and Zheng et al. [8] proposed two different frameworks for DEE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only frameworks for document-level event extraction.",
      "processing_time": 54.35052847862244,
      "citing_paper_id": "235681526",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "However, most existing studies merely extract arguments within the sentence scope [2, 14, 15], dubbed as sentence-level EE (SEE).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about existing studies.",
      "processing_time": 55.22981834411621,
      "citing_paper_id": "235681526",
      "cited_paper_id": 54437926
    },
    {
      "context_text": "[10], to exploit the information of all available sentences, we can use attention mechanism to aggregate sentence-level features.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general method (attention mechanism).",
      "processing_time": 55.2258939743042,
      "citing_paper_id": "235681526",
      "cited_paper_id": 65179127
    },
    {
      "context_text": "[26] propose two different frameworks for DEE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only frameworks for document-level event extraction.",
      "processing_time": 55.399893283843994,
      "citing_paper_id": "235681526",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "In TIER, event extraction is divided into multi-stage tasks, but error propagation between multiple models is ignored.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to event extraction.",
      "processing_time": 55.685654640197754,
      "citing_paper_id": "233613419",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Baseline\nWe use TIER [8], DCFEE [29], and Doc2EDAG [9] models as baseline models.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions models (TIER, DCFEE, Doc2EDAG) used as baselines, but does not mention any specific datasets. The cited paper titles do not introduce any datasets either.",
      "processing_time": 59.743114948272705,
      "citing_paper_id": "233613419",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Baseline\nWe use TIER [8], DCFEE [29], and Doc2EDAG [9] models as baseline models.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions models (TIER, DCFEE, Doc2EDAG) used as baselines, but does not mention any specific datasets. The cited paper titles do not introduce any datasets either.",
      "processing_time": 59.743114948272705,
      "citing_paper_id": "233613419",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Baseline\nWe use TIER [8], DCFEE [29], and Doc2EDAG [9] models as baseline models.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions models (TIER, DCFEE, Doc2EDAG) used as baselines, but does not mention any specific datasets. The cited paper titles do not introduce any datasets either.",
      "processing_time": 59.743114948272705,
      "citing_paper_id": "233613419",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "We use TIER [8], DCFEE [29], and Doc2EDAG [9] models as baseline models.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models (TIER, DCFEE, Doc2EDAG) but does not refer to any specific datasets. The context is focused on using these models as baselines.",
      "processing_time": 58.86994814872742,
      "citing_paper_id": "233613419",
      "cited_paper_id": 950755
    },
    {
      "context_text": "We use TIER [8], DCFEE [29], and Doc2EDAG [9] models as baseline models.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models (TIER, DCFEE, Doc2EDAG) but does not refer to any specific datasets. The context is focused on using these models as baselines.",
      "processing_time": 58.86994814872742,
      "citing_paper_id": "233613419",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "We use TIER [8], DCFEE [29], and Doc2EDAG [9] models as baseline models.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models (TIER, DCFEE, Doc2EDAG) but does not refer to any specific datasets. The context is focused on using these models as baselines.",
      "processing_time": 58.86994814872742,
      "citing_paper_id": "233613419",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "[8] point out that the pipeline architecture with three-stage task can extract documentlevel context information, but error information propagating will be an obstacle to generate correct results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No verifiable resources are identified.",
      "processing_time": 56.08659029006958,
      "citing_paper_id": "233613419",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Training Parameters Optimizer Adam Epoch 30 Learning Rate 10−4 Step [2,4,8] Batch [8,16,32]",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only training parameters. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 56.76792359352112,
      "citing_paper_id": "233613419",
      "cited_paper_id": 950755
    },
    {
      "context_text": "Training Parameters Optimizer Adam Epoch 30 Learning Rate 10−4 Step [2,4,8] Batch [8,16,32]",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only training parameters. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 56.76792359352112,
      "citing_paper_id": "233613419",
      "cited_paper_id": 12981484
    },
    {
      "context_text": "Training Parameters Optimizer Adam Epoch 30 Learning Rate 10−4 Step [2,4,8] Batch [8,16,32]",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only training parameters. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 56.76792359352112,
      "citing_paper_id": "233613419",
      "cited_paper_id": 224948084
    },
    {
      "context_text": "TIER employs a pipeline architecture with three-stage task to get document-level context information: classifying narrative document, recognizing event sentence and noun phrase analysis.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No verifiable resources are identified.",
      "processing_time": 56.08080577850342,
      "citing_paper_id": "233613419",
      "cited_paper_id": 950755
    },
    {
      "context_text": "By incorporating the semantic information of WordNet [17], PALKA can achieve results close to human beings in specific domains.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WordNet"
      ],
      "dataset_descriptions": {
        "WordNet": "Used to incorporate semantic information into PALKA, enhancing its performance in specific domains by leveraging the lexical database."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions WordNet, which is a lexical database, but it is not used as a dataset in the research context. It is referenced for its semantic information, which is used to enhance the performance of PALKA.",
      "processing_time": 63.81085729598999,
      "citing_paper_id": "233613419",
      "cited_paper_id": 1671874
    },
    {
      "context_text": "By incorporating the semantic information of WordNet [17], PALKA can achieve results close to human beings in specific domains.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WordNet"
      ],
      "dataset_descriptions": {
        "WordNet": "Used to incorporate semantic information into PALKA, enhancing its performance in specific domains by leveraging the lexical database."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions WordNet, which is a lexical database, but it is not used as a dataset in the research context. It is referenced for its semantic information, which is used to enhance the performance of PALKA.",
      "processing_time": 63.81085729598999,
      "citing_paper_id": "233613419",
      "cited_paper_id": 12981484
    },
    {
      "context_text": "Kingma, D.P.; Ba, J. Adam: A method for stochastic optimization. arXiv 2014, arXiv:1412.6980.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for stochastic optimization.",
      "processing_time": 54.768635511398315,
      "citing_paper_id": "233613419",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "We employ the Adam [33] optimizer with the learning rate 10−4, and train for at most 30 epochs.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Adam optimizer, which is a method, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 56.16887712478638,
      "citing_paper_id": "233613419",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "[26] propose a joint event embedding model KGEB, which embeds the knowledge graph into the event vector representation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (KGEB) and its application to stock prediction.",
      "processing_time": 55.877904415130615,
      "citing_paper_id": "233613419",
      "cited_paper_id": 10638526
    },
    {
      "context_text": "PALKA [16] uses semantic frames and phrase patterns to represent the extraction schema of events.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for representing extraction schemas using semantic frames and phrase patterns.",
      "processing_time": 55.874284744262695,
      "citing_paper_id": "233613419",
      "cited_paper_id": 12981484
    },
    {
      "context_text": "[6] propose a Dynamic Multi-Pooling Convolution Neural Network (DMCNN) to extract events, which regards event extraction as a two-stage multi-classification task: trigger classification and arguments classification.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DMCNN) for event extraction.",
      "processing_time": 55.006815671920776,
      "citing_paper_id": "233613419",
      "cited_paper_id": 14339673
    },
    {
      "context_text": "[22] first use the self-training [23] and semi-supervised learning method to extend the labeled corpus.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to a method for extending a labeled corpus, which is not a named dataset.",
      "processing_time": 56.87712526321411,
      "citing_paper_id": "233613419",
      "cited_paper_id": 15865939
    },
    {
      "context_text": "Event extraction [1], which aims to identify event arguments which are primary roles composing an event and fill them into corresponding pre-defined event types, is a challenging task in NLP (Natural Language Process).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the general task of event extraction in NLP.",
      "processing_time": 55.02526116371155,
      "citing_paper_id": "233613419",
      "cited_paper_id": 41089825
    },
    {
      "context_text": "DCFEE divides the event extraction into two-stage tasks for processing.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction. The context is too generic to infer any specific dataset.",
      "processing_time": 56.34405183792114,
      "citing_paper_id": "233613419",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "[29] realizes the extraction of equity freezing, pledge, repurchase, and increase or decrease of holdings in financial announcements.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions the extraction of specific events from financial announcements, which aligns with document-level event extraction. However, no specific dataset name is provided.",
      "processing_time": 56.34147238731384,
      "citing_paper_id": "233613419",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "DCFEE proposed by Yang et al. [29] realizes the extraction of equity freezing, pledge, repurchase, and increase or decrease of holdings in financial announcements.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DCFEE, which is a system for document-level Chinese financial event extraction. However, it does not mention a specific dataset by name, only that it uses automatically labeled training data.",
      "processing_time": 58.69857215881348,
      "citing_paper_id": "233613419",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Specifically, compared with DCFEE, TDJEE improves 9.53%, 18.79%, 13.24%, 18.17%, and 22.49% F1 scores on ER, EF, EP, EO, and EU, respectively.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance improvements over another system (DCFEE). No verifiable resources are identified.",
      "processing_time": 56.16592574119568,
      "citing_paper_id": "233613419",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Although DCFEE uses contextual information to predict event triggers, its context-agnostic arguments completion strategy makes it unable to effectively solve the event arguments scattering problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DCFEE) and its limitations. No verifiable resources are identified.",
      "processing_time": 56.22707653045654,
      "citing_paper_id": "233613419",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "Moreover, the direct document-\nlevel supervision are more robust than the extra sentence-level supervision used in DCFEE, which assumes that the sentences having most event arguments would contain the key event.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison between document-level and sentence-level supervision methods.",
      "processing_time": 54.134761333465576,
      "citing_paper_id": "233613419",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "The DCFEE model expands the training corpus by using distant supervision, and divides the event extraction into two-stage sub-tasks.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'training corpus' but does not specify a named dataset. The cited paper title suggests the use of automatically labeled training data, but no specific dataset name is provided.",
      "processing_time": 57.74082922935486,
      "citing_paper_id": "233613419",
      "cited_paper_id": 51871198
    },
    {
      "context_text": "[18] makes full use of document information in event extraction, in which text is encoded by RNN-based fusion hierarchy and attention mechanism, then the representation of text is used to judge event trigger words and types in sentences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for event extraction using document information.",
      "processing_time": 54.527108907699585,
      "citing_paper_id": "233613419",
      "cited_paper_id": 51871927
    },
    {
      "context_text": "Doc2EDAG uses an end-to-end method to identify event arguments at the sentence level first.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for event argument identification. The cited paper title confirms the focus on a method rather than a dataset.",
      "processing_time": 56.58862566947937,
      "citing_paper_id": "233613419",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Moreover, Doc2EDAG designs a memory mechanism for path expanding to support the EDAG generation efficiently.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction.",
      "processing_time": 53.57417583465576,
      "citing_paper_id": "233613419",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Therefore, Doc2EDAG may fail to extract such event.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a potential limitation of the Doc2EDAG framework.",
      "processing_time": 54.57586860656738,
      "citing_paper_id": "233613419",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Doc2EDAG et al. [9] transform the event into an entity-based directed acyclic graph (EDAG), which can transform the hard slot-filling task into several sequential path-expanding sub-tasks.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for transforming events into an entity-based directed acyclic graph (EDAG).",
      "processing_time": 55.60135817527771,
      "citing_paper_id": "233613419",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "Zheng, S.; Cao, W.; Xu, W.; Bian, J. Doc2EDAG: An end-to-end document-level framework for chinese financial event extraction.\narXiv 2019, arXiv:1904.07535.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level event extraction in Chinese financial documents.",
      "processing_time": 54.00941491127014,
      "citing_paper_id": "233613419",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "[9] use an end-to-end model to identify event arguments at the",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an end-to-end model for event argument identification.",
      "processing_time": 53.49725699424744,
      "citing_paper_id": "233613419",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "[9] transform the event into an entity-based directed acyclic graph (EDAG), which can transform the hard slot-filling task into several sequential path-expanding sub-tasks.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for transforming events into an entity-based directed acyclic graph (EDAG).",
      "processing_time": 55.3189594745636,
      "citing_paper_id": "233613419",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "[27] focus on digging out company-related events from text, which includes articles of describing companies on Wikipedia.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wikipedia"
      ],
      "dataset_descriptions": {
        "Wikipedia": "Used to extract company-related events from text, focusing on articles describing companies, employing weak supervision techniques for financial event extraction."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions using Wikipedia articles to extract company-related events, which aligns with the cited paper's focus on financial event extraction using Wikipedia-based weak supervision.",
      "processing_time": 60.64436483383179,
      "citing_paper_id": "233613419",
      "cited_paper_id": 208004535
    },
    {
      "context_text": "Then, the conditional random fields (CRF) method [12] is used to identify the event arguments.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset. It only refers to a method (CRF) for identifying event arguments.",
      "processing_time": 54.50709533691406,
      "citing_paper_id": "233613419",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "The Bi-LSTM (Bi-direction Long Short-Term Memory) [30] and CRF (Conditional Random Fields) [12] are combined to label the event elements in a sentence, and the event trigger word is detected through the dictionary.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 54.3483829498291,
      "citing_paper_id": "233613419",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "[20] combine CNN with gate linear mechanism to accelerate the encoding of text.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method combining CNN with a gate linear mechanism.",
      "processing_time": 54.05369186401367,
      "citing_paper_id": "233613419",
      "cited_paper_id": 224868016
    },
    {
      "context_text": "It has a wide range of applications in the fields such as intelligent question answering, information retrieval [2], automatic summarization [3], recommendation [4], etc.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general application areas. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 55.428725481033325,
      "citing_paper_id": "233613419",
      "cited_paper_id": 224948084
    },
    {
      "context_text": "We recruited three undergraduate students who are major in cybersecurity to perform the data annotation for the processed articles, and the Brat Rapid Annotation tool [25] is used to annotate data.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of the Brat Rapid Annotation tool but does not refer to any specific dataset. The tool is used for data annotation, which is a method rather than a dataset.",
      "processing_time": 57.33793067932129,
      "citing_paper_id": "235235800",
      "cited_paper_id": 2065400
    },
    {
      "context_text": "After that, the higher-level features have been investigated to improve the performance, such as cross-document information [5], [6], cross-event information [7], cross-entity information [8], etc. Li et al. [9] ﬁrst proposed joint model to extract event triggers and event arguments together.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only high-level features and methods. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 55.62739896774292,
      "citing_paper_id": "235235800",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "After that, the higher-level features have been investigated to improve the performance, such as cross-document information [5], [6], cross-event information [7], cross-entity information [8], etc. Li et al. [9] ﬁrst proposed joint model to extract event triggers and event arguments together.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only high-level features and methods. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 55.62739896774292,
      "citing_paper_id": "235235800",
      "cited_paper_id": 11574815
    },
    {
      "context_text": "After that, the higher-level features have been investigated to improve the performance, such as cross-document information [5], [6], cross-event information [7], cross-entity information [8], etc.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only types of information used to improve event extraction performance.",
      "processing_time": 54.36695098876953,
      "citing_paper_id": "235235800",
      "cited_paper_id": 2867611
    },
    {
      "context_text": "An attacker threatens to publish the victim’s data or perpetually block access to it unless a ransom is paid [21].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general threat scenario involving data. There are no verifiable resources or specific datasets mentioned.",
      "processing_time": 54.8468074798584,
      "citing_paper_id": "235235800",
      "cited_paper_id": 12179472
    },
    {
      "context_text": "With such a layer, we can efﬁciently use past and future tags to predict the current tag, and it has been shown that CRFs can produce higher tagging accuracy in general, such as in the NER task [24].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CRFs) and a task (NER).",
      "processing_time": 54.68906617164612,
      "citing_paper_id": "235235800",
      "cited_paper_id": 12740621
    },
    {
      "context_text": "[17] proposed Doc2EDAG, which formalized a DEE task with the no-trigger-words design to ease documentlevel event labeling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Doc2EDAG) for document-level event extraction.",
      "processing_time": 54.833658933639526,
      "citing_paper_id": "235235800",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "[17] proposed a kind of DEE formalization that removes the trigger-words labeling and regards the document-level event extraction task as directly filling event tables based on a document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or framework for document-level event extraction.",
      "processing_time": 54.17587447166443,
      "citing_paper_id": "235235800",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "A few works presented document-level models [16], [17] that could extract document-level events from Chinese financial announcements.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Chinese financial announcements' which suggests a specific type of data, but does not provide a named dataset. The cited paper title confirms the focus on document-level event extraction but does not introduce a specific dataset.",
      "processing_time": 58.474467754364014,
      "citing_paper_id": "235235800",
      "cited_paper_id": 119308902
    },
    {
      "context_text": "In recent research, some researchers have explored the possibility of event detection in the text on the topic of cybersecurity [1], [2].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the topic of cybersecurity events detection. No clear identifiers for datasets are present.",
      "processing_time": 55.064589977264404,
      "citing_paper_id": "235235800",
      "cited_paper_id": 131774006
    },
    {
      "context_text": "Severalmethods [1], [2] have been proposed on the event detection task in the cybersecurity domain, which pay more attention to identify and classify cybersecurity events.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for event detection in cybersecurity. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 55.91399645805359,
      "citing_paper_id": "235235800",
      "cited_paper_id": 131774006
    },
    {
      "context_text": ", 2013) are also able to model the coreference relations and entities at document-level, but have been proved to perform substantially worse than supervised models (Patwardhan and Riloff, 2009).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses models and their performance.",
      "processing_time": 53.80491757392883,
      "citing_paper_id": "221246218",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "Document-level IE Document-level event rolefiller mention extraction has been explored in recent work, using hand-designed features for both local and additional context (Patwardhan and Riloff, 2009; Huang and Riloff, 2011, 2012), and with end-to-end sequence tagging based models with contextualized pre-trained representations (Du and Cardie, 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the methodologies used for document-level event role filler mention extraction.",
      "processing_time": 55.41834545135498,
      "citing_paper_id": "221246218",
      "cited_paper_id": 2524712
    },
    {
      "context_text": "As a result of these complications, end-to-end sentence-level event extraction models (Chen et al., 2015; Lample et al., 2016), which dominate the literature, are illsuited for the template filling task, which calls for models that encode information and track entities across a longer context.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the limitations of sentence-level event extraction models.",
      "processing_time": 55.51550531387329,
      "citing_paper_id": "221246218",
      "cited_paper_id": 6042994
    },
    {
      "context_text": "We treat document-level template filling as a sequence-to-sequence task (Sutskever et al., 2014) in order to better model the cross-role dependencies and cross-sentence noun phrase coreference structure.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for treating document-level template filling as a sequence-to-sequence task.",
      "processing_time": 54.98924660682678,
      "citing_paper_id": "221246218",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Instead of using a sequence-to-sequence learning architecture with separate modules (Sutskever et al., 2014; Bahdanau et al., 2015), we use a single pretrained transformer model (Devlin et al., 2019) for both parts, and introduce no additional fine-tuned parameters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers are used to reference the models and methods, not datasets.",
      "processing_time": 55.87315893173218,
      "citing_paper_id": "221246218",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Instead of using a sequence-to-sequence learning architecture with separate modules (Sutskever et al., 2014; Bahdanau et al., 2015), we use a single pretrained transformer model (Devlin et al., 2019) for both parts, and introduce no additional fine-tuned parameters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers are used to reference the models and methods, not datasets.",
      "processing_time": 55.87315893173218,
      "citing_paper_id": "221246218",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Duan et al. (2017) and Zhao et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not provide specific details about datasets used. It only mentions authors and a year, which is insufficient to identify a dataset.",
      "processing_time": 55.50422978401184,
      "citing_paper_id": "221246218",
      "cited_paper_id": 9778664
    },
    {
      "context_text": "We base the event-based template-filling task on the original MUC1 formulation (Sundheim, 1991), but simplify it as done in prior research (Huang and Riloff, 2012; Du and Cardie, 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions the MUC1 formulation, which is a specific dataset used for message understanding and event extraction tasks. However, the name 'MUC1' does not appear in the context as an exact substring.",
      "processing_time": 58.81608605384827,
      "citing_paper_id": "221246218",
      "cited_paper_id": 14365335
    },
    {
      "context_text": "Du and Cardie (2020), for example, extend standard contextualized representations (Devlin et al., 2019) to produce a documentlevel sequence tagging model for event argument extraction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BERT) and a research application (document-level sequence tagging for event argument extraction).",
      "processing_time": 56.11147212982178,
      "citing_paper_id": "221246218",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Both the baselines are end-toend and fine-tuned BERT (Devlin et al., 2019) contextualized representations with task-specific data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'task-specific data' but does not provide a specific dataset name. The citation is focused on the use of BERT for fine-tuning, which is a method, not a dataset.",
      "processing_time": 58.088918924331665,
      "citing_paper_id": "221246218",
      "cited_paper_id": 52967399
    },
    {
      "context_text": ", 2015), we use a single pretrained transformer model (Devlin et al., 2019) for both parts, and introduce no additional fine-tuned parameters.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a pretrained model (BERT). No datasets are referenced for training or evaluation.",
      "processing_time": 55.036118030548096,
      "citing_paper_id": "221246218",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In the scientiïňĄc domain, Peng et al. (2017); Wang and Poon (2018); Jia et al. (2019) study N -ary cross-sentence RE using distant supervision annotations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'distant supervision annotations' but does not specify a named dataset. The context is about N-ary cross-sentence relation extraction, which is relevant to document-level event extraction.",
      "processing_time": 58.08049535751343,
      "citing_paper_id": "221246218",
      "cited_paper_id": 102353905
    },
    {
      "context_text": "Dong et al. (2019) presents a new unified pre-trained language model that can be fine-tuned for both NLU and NLG tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a pre-trained language model. The context is about the model's capabilities, not the data used.",
      "processing_time": 56.25750517845154,
      "citing_paper_id": "221246218",
      "cited_paper_id": 147704286
    },
    {
      "context_text": "Also on a related note, Chambers and Jurafsky (2011); Chambers (2013); Liu et al. (2019) work on unsupervised event schema induction and open-domain event extraction from documents.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to works on unsupervised event schema induction and open-domain event extraction.",
      "processing_time": 55.452545404434204,
      "citing_paper_id": "221246218",
      "cited_paper_id": 189928589
    },
    {
      "context_text": "Sentence-level Event Extraction Most work in event extraction has focused on the ACE sentencelevel event task (Walker et al., 2006), which requires the detection of an event trigger and extraction of its arguments from within a single sentence.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.5,
      "reasoning": "The context mentions the ACE sentence-level event task, which is a well-known dataset in the field of event extraction. However, the name 'ACE' does not appear in the context as a specific dataset label.",
      "processing_time": 58.39648199081421,
      "citing_paper_id": "221246218",
      "cited_paper_id": null
    },
    {
      "context_text": "Generative approaches include back-translation (Sennrich et al., 2016) and summarization (Yang et al., 2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods (back-translation and summarization).",
      "processing_time": 54.19251322746277,
      "citing_paper_id": "258959328",
      "cited_paper_id": 15600925
    },
    {
      "context_text": "Secondly, we use top-k sampling, where we set k = 640 , in accordance with Fan et al. (2018).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (top-k sampling). The cited paper title does not introduce any datasets either.",
      "processing_time": 55.67596912384033,
      "citing_paper_id": "258959328",
      "cited_paper_id": 44134226
    },
    {
      "context_text": "More recently developed decoding methods include top-k sampling (Fan et al., 2018), top-p (nucleus) sampling (Holtzman et al., 2020), and contrastive search (Su et al., 2022).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only decoding methods. No dataset names are present in the text.",
      "processing_time": 54.55440664291382,
      "citing_paper_id": "258959328",
      "cited_paper_id": 44134226
    },
    {
      "context_text": "More recently developed decoding methods include top-k sampling (Fan et al., 2018), top-p (nucleus) sampling (Holtzman et al., 2020), and contrastive search (Su et al., 2022).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only decoding methods. No dataset names are present in the text.",
      "processing_time": 54.55440664291382,
      "citing_paper_id": "258959328",
      "cited_paper_id": 127986954
    },
    {
      "context_text": ", 2018), top-p (nucleus) sampling (Holtzman et al., 2020), and contrastive search (Su et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and techniques. There are no verifiable resources or datasets mentioned.",
      "processing_time": 55.073036670684814,
      "citing_paper_id": "258959328",
      "cited_paper_id": 127986954
    },
    {
      "context_text": "95 (Holtzman et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a paper. There are no clear identifiers for datasets, models, or other resources.",
      "processing_time": 56.2453248500824,
      "citing_paper_id": "258959328",
      "cited_paper_id": 127986954
    },
    {
      "context_text": "We use BART (Lewis et al., 2020) to generate zero-shot summaries.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BART, which is a model, not a dataset. No datasets are mentioned or implied.",
      "processing_time": 53.61152386665344,
      "citing_paper_id": "258959328",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "We accomplish this feature by using a version of BART which was fine-tuned on CNN/DailyMail summarization dataset (Nallapati et al., 2016).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CNN/DailyMail summarization dataset"
      ],
      "dataset_descriptions": {
        "CNN/DailyMail summarization dataset": "Used to fine-tune BART for summarization tasks, focusing on generating concise summaries from news articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the CNN/DailyMail summarization dataset, which is a specific, verifiable dataset used for fine-tuning BART. The dataset is clearly identified and used for a specific purpose.",
      "processing_time": 61.223864793777466,
      "citing_paper_id": "258959328",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "We generate abstractive summaries using documents from low-resource classes as inputs to BART generative model.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'documents from low-resource classes' which is too generic.",
      "processing_time": 55.418116331100464,
      "citing_paper_id": "258959328",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "• TextRank (Mihalcea and Tarau, 2004): We use the graph based ranking algorithm to rank the sentence-level argument phrases for each argument type in a document extracted using (Kar et al., 2021)’s model.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (TextRank) and a model (Kar et al., 2021).",
      "processing_time": 55.80224895477295,
      "citing_paper_id": "235490449",
      "cited_paper_id": 577937
    },
    {
      "context_text": "Some of the classic works related to the task of ranking text snippets are that of PageRank (Page et al., 1998) and TextRank (Mi-halcea and Tarau, 2004).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions PageRank and TextRank, which are methods, not datasets. No specific datasets are mentioned or used in the context.",
      "processing_time": 55.22499442100525,
      "citing_paper_id": "235490449",
      "cited_paper_id": 1508503
    },
    {
      "context_text": "Event-Argument Extraction, the IE task most related to the task of aggregation has a number of well-documented and reliable datasets annotated at the sentence level in different languages like ACE 2005 and TAC KBP (Mitamura et al., 2015) datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ACE 2005",
        "TAC KBP"
      ],
      "dataset_descriptions": {
        "ACE 2005": "Used for event-argument extraction, annotated at the sentence level in multiple languages, focusing on identifying and linking events and their arguments.",
        "TAC KBP": "Used for event-argument extraction, annotated at the sentence level in multiple languages, focusing on evaluating event extraction and entity linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, ACE 2005 and TAC KBP, which are used for event-argument extraction, a task related to aggregation. These datasets are well-documented and annotated at the sentence level.",
      "processing_time": 64.12725591659546,
      "citing_paper_id": "235490449",
      "cited_paper_id": 3137086
    },
    {
      "context_text": "Based on the ﬁndings reported in (Hu et al., 2018), to avoid bias from the previous epoch, we ﬁne-tune the pre-trained BERT-based classiﬁer on the entire annotated dataset for every run of active learning.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'annotated dataset' but does not provide a specific name or identifier. The term 'annotated dataset' is too generic and lacks the specificity required to be included as a verifiable resource.",
      "processing_time": 58.11704158782959,
      "citing_paper_id": "235490449",
      "cited_paper_id": 3534906
    },
    {
      "context_text": "After each epoch of active learning, 50 most uncertain samples are identiﬁed using the Monte Carlo estimation of error reduction (Roy and McCallum, 2001).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for identifying uncertain samples in active learning.",
      "processing_time": 53.84667921066284,
      "citing_paper_id": "235490449",
      "cited_paper_id": 14293159
    },
    {
      "context_text": "Event argument extraction is a well researched information extraction task which has seen a lot of work at the sentence-level (Wang et al., 2019; Wadden et al., 2019; Nguyen et al., 2016; Luan et al., 2019b; Veyseh et al., 2020) but a scarce amount of research has been carried out at the document level.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research papers. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 55.55317568778992,
      "citing_paper_id": "235490449",
      "cited_paper_id": 225067984
    },
    {
      "context_text": "Most of the existing event-argument extraction systems (Nguyen et al., 2016; Luan et al., 2019a; Wadden et al., 2019; Veyseh et al., 2020) pertain to a sentence-level focus, Figure 1: Example document excerpt from our corpus highlighting the different challenges of the aggregation task.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'our corpus' but does not provide a specific name or identifier for the corpus. It is a generic reference and does not meet the criteria for inclusion.",
      "processing_time": 56.90611791610718,
      "citing_paper_id": "235490449",
      "cited_paper_id": 225067984
    },
    {
      "context_text": "Most of the existing information extraction frameworks (Wadden et al., 2019; Veyseh et al., 2020) focus on sentence-level tasks and are hardly able to capture the consolidated information from a given document.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general frameworks and their limitations. No verifiable resources are identified.",
      "processing_time": 54.609100341796875,
      "citing_paper_id": "235490449",
      "cited_paper_id": 225067984
    },
    {
      "context_text": "…argument extraction is a well researched information extraction task which has seen a lot of work at the sentence-level (Wang et al., 2019; Wad-den et al., 2019; Nguyen et al., 2016; Luan et al., 2019b; Veyseh et al., 2020) but a scarce amount of research has been carried out at the document level.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general research trends in argument extraction. No verifiable resources are identified.",
      "processing_time": 54.97258496284485,
      "citing_paper_id": "235490449",
      "cited_paper_id": 225067984
    },
    {
      "context_text": "ENTRE (Wang et al., 2023), a counterfactual modification of TACRED (Zhang et al., 2017), replaces entities to develop a robust sentence-level RE benchmark.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TACRED"
      ],
      "dataset_descriptions": {
        "TACRED": "Used to develop a robust sentence-level relation extraction benchmark through counterfactual modifications, focusing on entity replacement to enhance model robustness."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions ENTRE and TACRED, but only TACRED is a dataset. ENTRE is a modification of TACRED, not a separate dataset.",
      "processing_time": 60.69154739379883,
      "citing_paper_id": "271064857",
      "cited_paper_id": 3782112
    },
    {
      "context_text": "RE datasets such as DocRED (Yao et al., 2019) and Re-DocRED (Tan et al., 2022b) consist of a factual corpus (Wikipedia) annotated with triples.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "Re-DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction, specifically to train and evaluate models on relational triples annotated from Wikipedia articles.",
        "Re-DocRED": "Used for document-level relation extraction, specifically to enhance and refine models trained on relational triples annotated from Wikipedia articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, DocRED and Re-DocRED, which are used for document-level relation extraction. Both are derived from Wikipedia and annotated with relational triples.",
      "processing_time": 62.3161039352417,
      "citing_paper_id": "271064857",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "In a triple r ∈ R , we have the indices ( i ) of head and tail entities, the relation r t and – if the triple comes from the original DocRED (Yao et al., 2019) – the IDs of the sentences that are the evidence for r .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to provide sentence-level evidence for relation triples, supporting document-level relation extraction tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DocRED' as a source of triples with sentence-level evidence, which is a document-level relation extraction dataset.",
      "processing_time": 58.58760738372803,
      "citing_paper_id": "271064857",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "In document-level RE, triples can span multiple sentences (Yao et al., 2019; Tan et al., 2022b; Xiaoyan et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to document-level relation extraction. No dataset names are provided in the context.",
      "processing_time": 55.23163437843323,
      "citing_paper_id": "271064857",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "A common case is entity bias: the model relies on entities in its parametric knowledge to make a prediction (Long-pre et al., 2021; Qian et al., 2021; Xu et al., 2022; Chen et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a phenomenon (entity bias) discussed in multiple papers. No clear, verifiable resource names are present.",
      "processing_time": 56.09883213043213,
      "citing_paper_id": "271064857",
      "cited_paper_id": 235254332
    },
    {
      "context_text": "A common case is entity bias: the model relies on entities in its parametric knowledge to make a prediction (Long-pre et al., 2021; Qian et al., 2021; Xu et al., 2022; Chen et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a phenomenon (entity bias) discussed in multiple papers. No clear, verifiable resource names are present.",
      "processing_time": 56.09883213043213,
      "citing_paper_id": "271064857",
      "cited_paper_id": null
    },
    {
      "context_text": "We address this by generating CF data and training RE models on them. inferring from the input, they may use their parametric knowledge (McCoy et al., 2019; Kaushik et al., 2020; Paranjape et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context is about generating counterfactual data and training models, which does not specify any named, verifiable datasets.",
      "processing_time": 57.08921790122986,
      "citing_paper_id": "271064857",
      "cited_paper_id": 238856938
    },
    {
      "context_text": "Following Paranjape et al. (2022), we use pairwise consistency as our measure.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a measure (pairwise consistency). The cited paper title does not provide additional context to identify a dataset.",
      "processing_time": 55.65101099014282,
      "citing_paper_id": "271064857",
      "cited_paper_id": 238856938
    },
    {
      "context_text": "Typically, teachers extract knowledge at various levels, such as logits and features ( Romero et al., 2014 ), which can be utilized directly or converted into other networks or kernel functions ( Heo et al., 2019a ; Heo et al., 2019b ; Kim, Park & Kwak, 2018 ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for knowledge extraction and transfer in neural networks.",
      "processing_time": 54.4293155670166,
      "citing_paper_id": "268783461",
      "cited_paper_id": 2723173
    },
    {
      "context_text": "Typically, teachers extract knowledge at various levels, such as logits and features ( Romero et al., 2014 ), which can be utilized directly or converted into other networks or kernel functions ( Heo et al., 2019a ; Heo et al., 2019b ; Kim, Park & Kwak, 2018 ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for knowledge extraction and transfer in neural networks.",
      "processing_time": 54.4293155670166,
      "citing_paper_id": "268783461",
      "cited_paper_id": 53213211
    },
    {
      "context_text": "Typically, teachers extract knowledge at various levels, such as logits and features ( Romero et al., 2014 ), which can be utilized directly or converted into other networks or kernel functions ( Heo et al., 2019a ; Heo et al., 2019b ; Kim, Park & Kwak, 2018 ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for knowledge extraction and transfer in neural networks.",
      "processing_time": 54.4293155670166,
      "citing_paper_id": "268783461",
      "cited_paper_id": 102483181
    },
    {
      "context_text": "…and sentences to create a graph representation using heuristic rules and dependency structures is a popular method for document-level relation extraction, e.g. , Peng et al. (2017) , Liu & Lapata (2018) , Christopoulou, Miwa & Ananiadou (2019) , Nan et al. (2020) and Guo, Zhang & Lu (2019) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for document-level relation extraction.",
      "processing_time": 53.775185108184814,
      "citing_paper_id": "268783461",
      "cited_paper_id": 2797612
    },
    {
      "context_text": "…and sentences to create a graph representation using heuristic rules and dependency structures is a popular method for document-level relation extraction, e.g. , Peng et al. (2017) , Liu & Lapata (2018) , Christopoulou, Miwa & Ananiadou (2019) , Nan et al. (2020) and Guo, Zhang & Lu (2019) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for document-level relation extraction.",
      "processing_time": 53.775185108184814,
      "citing_paper_id": "268783461",
      "cited_paper_id": 39871772
    },
    {
      "context_text": "…and sentences to create a graph representation using heuristic rules and dependency structures is a popular method for document-level relation extraction, e.g. , Peng et al. (2017) , Liu & Lapata (2018) , Christopoulou, Miwa & Ananiadou (2019) , Nan et al. (2020) and Guo, Zhang & Lu (2019) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for document-level relation extraction.",
      "processing_time": 53.775185108184814,
      "citing_paper_id": "268783461",
      "cited_paper_id": 218613850
    },
    {
      "context_text": "For training, we utilize a hybrid precision training model from the Apex library ( Micikevicius et al., 2017 ), optimized by AdamW ( Loshchilov & Hutter, 2019 ) as the learner, with a learning rate of 5e − 5 and linear preheating set to 0.06 ( Goyal et al., 2018 ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and libraries. The focus is on the training process and optimization techniques.",
      "processing_time": 55.00392818450928,
      "citing_paper_id": "268783461",
      "cited_paper_id": 3297437
    },
    {
      "context_text": "Knowledge distillation (KD) ( Pham et al., 2022 ; Gou et al., 2021 ; Hinton, Vinyals & Dean, 2015 ) is a technique that involves transferring learning information from a pre-trained large network (teacher) to a smaller one (student).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the technique of knowledge distillation. No verifiable resources are identified.",
      "processing_time": 54.655766010284424,
      "citing_paper_id": "268783461",
      "cited_paper_id": 7200347
    },
    {
      "context_text": "Knowledge distillation (KD) ( Pham et al., 2022 ; Gou et al., 2021 ; Hinton, Vinyals & Dean, 2015 ) is a technique that involves transferring learning information from a pre-trained large network (teacher) to a smaller one (student).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the technique of knowledge distillation. No verifiable resources are identified.",
      "processing_time": 54.655766010284424,
      "citing_paper_id": "268783461",
      "cited_paper_id": 219559263
    },
    {
      "context_text": "The backbone model we employ is built upon ATLOP, with BERT-base ( Devlin et al., 2019 ) serving as the encoder for document encoding in the DocRED (https://github.com/thunlp/ DocRED) and GDA (https://bitbucket.org/alexwuhkucs/gda-extraction/src/master/) datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "GDA"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction, focusing on complex relations within documents using BERT-based encoding.",
        "GDA": "Utilized for gene-disease association extraction, applying BERT-based encoding to capture contextual information in documents."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, DocRED and GDA, which are used for document-level event extraction. BERT is mentioned but it is a model, not a dataset.",
      "processing_time": 61.961567401885986,
      "citing_paper_id": "268783461",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "To obtain the entity’s embedding for all mentions m ij N ei j = 1 corresponding to e i , logsumexp pooling ( Jia, Wong & Poon, 2019 ) is employed as follows: The pooling operation collects all the information referenced in the document, thereby generating an embedded representation of the entity.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for entity embedding using logsumexp pooling.",
      "processing_time": 53.768269300460815,
      "citing_paper_id": "268783461",
      "cited_paper_id": 102353905
    },
    {
      "context_text": "Considering a given document d = [ x t ] lt = 1 , we locate the entity mentions by placing a special symbol ‘‘ ∗ ’’ at the start and end of each mention ( Shi & Lin, 2019 ; Soares et al., 2019 ; Zhang et al., 2017 ).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods for entity mention identification. No dataset names are present in the text.",
      "processing_time": 54.834240674972534,
      "citing_paper_id": "268783461",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Furthermore, the teacher can consist of a single pre-training network or a group of multiple pre-training networks,or the results of the previous iteration cycle can be used as the teacher model for the next training cycle ( Zhang & Sabuncu, 2020 ; Shen et al., 2022 ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is about the use of teacher models in self-distillation, which is a methodological approach.",
      "processing_time": 56.810288429260254,
      "citing_paper_id": "268783461",
      "cited_paper_id": 219558831
    },
    {
      "context_text": "…between entities in a single sentence by using sentence-level analysis, e.g. , Zhao, Gao & Guo (2023) , Zhang et al. (2023) , Li et al. (2022) , Zheng et al. (2021) , Wu et al. (2021) , Zhang et al. (2020) , Wang et al. (2020) , Ye et al. (2020) , Yu et al. (2020) , Zhang et al. (2018) ; Zeng…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 56.273141860961914,
      "citing_paper_id": "268783461",
      "cited_paper_id": 235485451
    },
    {
      "context_text": "In addition, Zhang & Cheng (2022) modelled inference as a masked network reconstruction problem, where the entity matrix is viewed as an image, which is then stochastically masked and recovered by an inference module in order to capture correlations between relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for document-level relation extraction.",
      "processing_time": 53.2794291973114,
      "citing_paper_id": "268783461",
      "cited_paper_id": 248300064
    },
    {
      "context_text": "Despite achieving great progress with large pre-trained language models in various tasks, modern NLP models are still brittle to out-of-domain data (Hendrycks et al., 2020), adversarial attacks (McCoy et al., 2019) or small perturbation to the input (Ebrahimi et al., 2018).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general issues with NLP models. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 56.092893838882446,
      "citing_paper_id": "270380221",
      "cited_paper_id": 21698802
    },
    {
      "context_text": "Despite achieving great progress with large pre-trained language models in various tasks, modern NLP models are still brittle to out-of-domain data (Hendrycks et al., 2020), adversarial attacks (McCoy et al., 2019) or small perturbation to the input (Ebrahimi et al., 2018).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general issues with NLP models. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 56.092893838882446,
      "citing_paper_id": "270380221",
      "cited_paper_id": 59599752
    },
    {
      "context_text": "Despite achieving great progress with large pre-trained language models in various tasks, modern NLP models are still brittle to out-of-domain data (Hendrycks et al., 2020), adversarial attacks (McCoy et al., 2019) or small perturbation to the input (Ebrahimi et al., 2018).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general issues with NLP models. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 56.092893838882446,
      "citing_paper_id": "270380221",
      "cited_paper_id": 215745290
    },
    {
      "context_text": "…name variation robustness of DocRE models to more domains such as news (Zaporojets et al., 2021), biomedicine (Li et al., 2016), social media (Hu et al., 2023a) and scientific publications (Luan et al., 2018), and more languages such as Chinese (Cheng et al., 2021) and Korean (Yang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only refers to domains and languages where document-level relation extraction (DocRE) models have been applied.",
      "processing_time": 56.55298900604248,
      "citing_paper_id": "270380221",
      "cited_paper_id": 52118895
    },
    {
      "context_text": "The former typically abstract the document by graph structures and perform inference with graph neural networks (Zeng et al., 2020; Zhang et al., 2021; Wei and Li, 2022; Lu et al., 2023), while the latter encode the long-distance contextual dependencies with transformer-only architectures (Zhou et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 54.96672964096069,
      "citing_paper_id": "270380221",
      "cited_paper_id": 235358168
    },
    {
      "context_text": "By introducing various types of perturbation to entity (names), previous works audit or improve model robustness on different tasks like named entity recognition (Lin et al., 2021), machine reading comprehension (Yan et al., 2022) and dialogue state tracking (Cho et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation discusses methods for auditing or improving model robustness through perturbations, but does not mention any specific datasets.",
      "processing_time": 54.963383197784424,
      "citing_paper_id": "270380221",
      "cited_paper_id": 237491060
    },
    {
      "context_text": "Recently, a series of DocRE studies propose various novel models and methods, continuously improving the performance on several DocRE benchmarks (Tan et al., 2022a; Zhou and Lee, 2022; Xiao et al., 2022; Sun et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation span mentions 'DocRE benchmarks' but does not specify any particular datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 55.92624831199646,
      "citing_paper_id": "270380221",
      "cited_paper_id": 237635295
    },
    {
      "context_text": "Recently, a series of DocRE studies propose various novel models and methods, continuously improving the performance on several DocRE benchmarks (Tan et al., 2022a; Zhou and Lee, 2022; Xiao et al., 2022; Sun et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation span mentions 'DocRE benchmarks' but does not specify any particular datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 55.92624831199646,
      "citing_paper_id": "270380221",
      "cited_paper_id": 248496086
    },
    {
      "context_text": "Recently, a series of DocRE studies propose various novel models and methods, continuously improving the performance on several DocRE benchmarks (Tan et al., 2022a; Zhou and Lee, 2022; Xiao et al., 2022; Sun et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation span mentions 'DocRE benchmarks' but does not specify any particular datasets. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 55.92624831199646,
      "citing_paper_id": "270380221",
      "cited_paper_id": 258762887
    },
    {
      "context_text": "Consequently, there has been a growing effort to explore robustness issues in NLP, such as building robustness evaluation benchmarks and proposing robustness enhancement strategies (Wang et al., 2022; Liu et al., 2024a,b; Hu et al., 2024b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general efforts towards robustness in NLP. No verifiable resources are named.",
      "processing_time": 55.365556478500366,
      "citing_paper_id": "270380221",
      "cited_paper_id": 245144787
    },
    {
      "context_text": "Consequently, there has been a growing effort to explore robustness issues in NLP, such as building robustness evaluation benchmarks and proposing robustness enhancement strategies (Wang et al., 2022; Liu et al., 2024a,b; Hu et al., 2024b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general efforts towards robustness in NLP. No verifiable resources are named.",
      "processing_time": 55.365556478500366,
      "citing_paper_id": "270380221",
      "cited_paper_id": null
    },
    {
      "context_text": "…of DocRE, which requires the model to jointly perform mention detection (and optionally classification), coreference resolution and relation extraction, aligning better with real-world application scenarios (Eberts and Ulges, 2021; Giorgi et al., 2022; Xu and Choi, 2022; Zhang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses the task of document-level relation extraction and cites papers for further reading.",
      "processing_time": 55.10959577560425,
      "citing_paper_id": "270380221",
      "cited_paper_id": 247939302
    },
    {
      "context_text": "We calculate the popularity of entities (Huang et al., 2022), i.e., how many times the linked item of the entity appears in a relation instance in Wikidata, in each benchmark’s test set to roughly quantify the entity knowledge.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wikidata"
      ],
      "dataset_descriptions": {
        "Wikidata": "Used to calculate entity popularity by counting relation instances, supporting the quantification of entity knowledge in benchmark test sets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Wikidata' as a source for calculating entity popularity, which is a specific, verifiable dataset. No other datasets are mentioned.",
      "processing_time": 58.895254373550415,
      "citing_paper_id": "270380221",
      "cited_paper_id": 248227853
    },
    {
      "context_text": "…former typically abstract the document by graph structures and perform inference with graph neural networks (Zeng et al., 2020; Zhang et al., 2021; Wei and Li, 2022; Lu et al., 2023), while the latter encode the long-distance contextual dependencies with transformer-only architectures (Zhou et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 54.455742597579956,
      "citing_paper_id": "270380221",
      "cited_paper_id": 251518246
    },
    {
      "context_text": "…networks (Zeng et al., 2020; Zhang et al., 2021; Wei and Li, 2022; Lu et al., 2023), while the latter encode the long-distance contextual dependencies with transformer-only architectures (Zhou et al., 2021; Xie et al., 2022; Zhang et al., 2022; Meng et al., 2023; Ma et al., 2023; Hu et al., 2024a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and architectures. No verifiable resources are identified.",
      "processing_time": 55.096606492996216,
      "citing_paper_id": "270380221",
      "cited_paper_id": 254044368
    },
    {
      "context_text": "Therefore, we also conduct an experiment to explore how robust of ICL for DocRE under entity name variations.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general experimental setup. No verifiable resources are identified.",
      "processing_time": 54.68579721450806,
      "citing_paper_id": "270380221",
      "cited_paper_id": 255372865
    },
    {
      "context_text": "Recently large language models (LLMs) (Brown et al., 2020) have achieved promising few-shot re-sults on many tasks through in-context learning (ICL) (Dong et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only large language models and their performance in in-context learning.",
      "processing_time": 54.45102119445801,
      "citing_paper_id": "270380221",
      "cited_paper_id": 255372865
    },
    {
      "context_text": "(Li et al., 2023; Chen et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not provide any specific information about datasets or their usage. The cited paper titles do not mention any specific datasets.",
      "processing_time": 54.683369159698486,
      "citing_paper_id": "270380221",
      "cited_paper_id": 259164990
    },
    {
      "context_text": "While covering more realistic scenarios than its sentence-level counterpart (Hu et al., 2023b), DocRE also brings new challenges, requiring a comprehensive modeling of interactions among different mentions of an entity, different entities and different entity pairs.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the challenges and requirements of document-level relation extraction.",
      "processing_time": 54.44814443588257,
      "citing_paper_id": "270380221",
      "cited_paper_id": 259949704
    },
    {
      "context_text": "…abstract the document by graph structures and perform inference with graph neural networks (Zeng et al., 2020; Zhang et al., 2021; Wei and Li, 2022; Lu et al., 2023), while the latter encode the long-distance contextual dependencies with transformer-only architectures (Zhou et al., 2021; Xie et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 55.47044563293457,
      "citing_paper_id": "270380221",
      "cited_paper_id": 264590646
    },
    {
      "context_text": "We further apply the proposed pipeline to Do-cRED (Yao et al., 2019) and Re-DocRED (Tan et al., 2022b), due to both being the largest and most widely used DocRE datasets, to create two novel benchmarks, named Env-DocRED and Env-Re-DocRED, for evaluating the robustness of DocRE models to entity name…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Do-cRED",
        "Re-DocRED"
      ],
      "dataset_descriptions": {
        "Do-cRED": "Used to create Env-DocRED benchmark for evaluating the robustness of document-level relation extraction models to entity name variations.",
        "Re-DocRED": "Used to create Env-Re-DocRED benchmark for evaluating the robustness of document-level relation extraction models to entity name variations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, Do-cRED and Re-DocRED, which are used to create new benchmarks for evaluating the robustness of document-level relation extraction models.",
      "processing_time": 62.1056923866272,
      "citing_paper_id": "270380221",
      "cited_paper_id": null
    },
    {
      "context_text": "A natural thought is to leverage convolutional neural networks (CNNs) [6] to enhance salient feature extraction in local areas.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CNNs).",
      "processing_time": 53.63925528526306,
      "citing_paper_id": "274270987",
      "cited_paper_id": 3879949
    },
    {
      "context_text": "Current approaches [1] typically fine-tune Transformer-based [2-3] text embeddings and apply them to downstream tasks, which have demonstrated remarkable language modeling capabilities.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general approaches and models. No verifiable resources are identified.",
      "processing_time": 54.852633237838745,
      "citing_paper_id": "274270987",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Current approaches [1] typically fine-tune Transformer-based [2-3] text embeddings and apply them to downstream tasks, which have demonstrated remarkable language modeling capabilities.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general approaches and models. No verifiable resources are identified.",
      "processing_time": 54.852633237838745,
      "citing_paper_id": "274270987",
      "cited_paper_id": 247619149
    },
    {
      "context_text": "Thirdly, LogicST assumes that entities and their mentions are identified beforehand (Li and Ji, 2014), which falls short of real-world applications.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context focuses on the limitations of the LogicST method.",
      "processing_time": 55.73747754096985,
      "citing_paper_id": "273901511",
      "cited_paper_id": 20744
    },
    {
      "context_text": "Based on Occam’s razor (Domingos, 1999), we only consider the minimal diagnosis , where no subset of the minimal diagnostic set can resolve the conflict.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to a principle (Occam’s razor) used in the research methodology.",
      "processing_time": 56.46205377578735,
      "citing_paper_id": "273901511",
      "cited_paper_id": 2381120
    },
    {
      "context_text": "However, DocRE tasks often suffer from severe class imbalance (Tan et al., 2022a), causing logits to be biased towards popular classes (Menon et al., 2021) and introducing confirmation bias (Cho and Roy, 2004).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only issues related to class imbalance in DocRE tasks. No verifiable resources are named.",
      "processing_time": 55.72510862350464,
      "citing_paper_id": "273901511",
      "cited_paper_id": 5509259
    },
    {
      "context_text": "However, DocRE tasks often suffer from severe class imbalance (Tan et al., 2022a), causing logits to be biased towards popular classes (Menon et al., 2021) and introducing confirmation bias (Cho and Roy, 2004).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only issues related to class imbalance in DocRE tasks. No verifiable resources are named.",
      "processing_time": 55.72510862350464,
      "citing_paper_id": "273901511",
      "cited_paper_id": 220525799
    },
    {
      "context_text": "First, the scoring function of LogicST is designed for settings with incomplete annotations and is not applicable to distant supervision settings (Mintz et al., 2009; Liu et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers discussing methods or approaches.",
      "processing_time": 53.87288165092468,
      "citing_paper_id": "273901511",
      "cited_paper_id": 10910955
    },
    {
      "context_text": "Since the advent of pre-trained language models (Devlin et al., 2019; Liu et al., 2019), research in DocRE has experienced significant growth.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only pre-trained language models. No dataset names are present in the citation span.",
      "processing_time": 55.22703504562378,
      "citing_paper_id": "273901511",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "They benefit from the powerful representations provided by language models (Devlin et al., 2019), but struggle with symbolic reasoning among entity pairs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a reference to language models which are not considered datasets.",
      "processing_time": 54.506133794784546,
      "citing_paper_id": "273901511",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We compare LogicST with LogiRE (Ru et al., 2021), MILR (Fan et al., 2022), and JMRL (Qi et al., 2024) using BERT-base as the encoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models and methods but does not specify any datasets. The cited papers do not introduce new datasets either.",
      "processing_time": 54.84906315803528,
      "citing_paper_id": "273901511",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We compare LogicST with LogiRE (Ru et al., 2021), MILR (Fan et al., 2022), and JMRL (Qi et al., 2024) using BERT-base as the encoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models and methods but does not specify any datasets. The cited papers do not introduce new datasets either.",
      "processing_time": 54.84906315803528,
      "citing_paper_id": "273901511",
      "cited_paper_id": 271923564
    },
    {
      "context_text": "We use BERT-base (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019) as the text encoders.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT-base and RoBERTa-large as text encoders, which are models, not datasets. No datasets are explicitly mentioned or used in the given context.",
      "processing_time": 56.64290642738342,
      "citing_paper_id": "273901511",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "We compare LogicST to the following six types of baselines: 1) vanilla baselines, including various top-performing models under fully supervised settings, such as GAIN (Zeng et al., 2020), AT-LOP (Zhou et al., 2021), and KD-DocRE (Tan et al., 2022a); 2) negative sampling methods (Li et al., 2021); 3) PU learning-based methods, including SSR-PU (Wang et al., 2022a) and P 3 M (Wang et al., 2024); 4) sub-symbolic self-training methods, such as VST (Jie et al., 2019), CREST (Wei et al., 2021), and CAST (Tan et al., 2023b); 5) methods based on large language models (LLMs), including LLaMA2-7B (Touvron et al., 2023), GPT-3.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No dataset names are present in the text.",
      "processing_time": 55.340869665145874,
      "citing_paper_id": "273901511",
      "cited_paper_id": 174800839
    },
    {
      "context_text": "We compare LogicST to the following six types of baselines: 1) vanilla baselines, including various top-performing models under fully supervised settings, such as GAIN (Zeng et al., 2020), AT-LOP (Zhou et al., 2021), and KD-DocRE (Tan et al., 2022a); 2) negative sampling methods (Li et al., 2021); 3) PU learning-based methods, including SSR-PU (Wang et al., 2022a) and P 3 M (Wang et al., 2024); 4) sub-symbolic self-training methods, such as VST (Jie et al., 2019), CREST (Wei et al., 2021), and CAST (Tan et al., 2023b); 5) methods based on large language models (LLMs), including LLaMA2-7B (Touvron et al., 2023), GPT-3.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No dataset names are present in the text.",
      "processing_time": 55.340869665145874,
      "citing_paper_id": "273901511",
      "cited_paper_id": 225039888
    },
    {
      "context_text": "We compare LogicST to the following six types of baselines: 1) vanilla baselines, including various top-performing models under fully supervised settings, such as GAIN (Zeng et al., 2020), AT-LOP (Zhou et al., 2021), and KD-DocRE (Tan et al., 2022a); 2) negative sampling methods (Li et al., 2021); 3) PU learning-based methods, including SSR-PU (Wang et al., 2022a) and P 3 M (Wang et al., 2024); 4) sub-symbolic self-training methods, such as VST (Jie et al., 2019), CREST (Wei et al., 2021), and CAST (Tan et al., 2023b); 5) methods based on large language models (LLMs), including LLaMA2-7B (Touvron et al., 2023), GPT-3.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No dataset names are present in the text.",
      "processing_time": 55.340869665145874,
      "citing_paper_id": "273901511",
      "cited_paper_id": 252918868
    },
    {
      "context_text": "We compare LogicST to the following six types of baselines: 1) vanilla baselines, including various top-performing models under fully supervised settings, such as GAIN (Zeng et al., 2020), AT-LOP (Zhou et al., 2021), and KD-DocRE (Tan et al., 2022a); 2) negative sampling methods (Li et al., 2021); 3) PU learning-based methods, including SSR-PU (Wang et al., 2022a) and P 3 M (Wang et al., 2024); 4) sub-symbolic self-training methods, such as VST (Jie et al., 2019), CREST (Wei et al., 2021), and CAST (Tan et al., 2023b); 5) methods based on large language models (LLMs), including LLaMA2-7B (Touvron et al., 2023), GPT-3.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No dataset names are present in the text.",
      "processing_time": 55.340869665145874,
      "citing_paper_id": "273901511",
      "cited_paper_id": 259187621
    },
    {
      "context_text": "…PU learning-based methods, including SSR-PU (Wang et al., 2022a) and P 3 M (Wang et al., 2024); 4) sub-symbolic self-training methods, such as VST (Jie et al., 2019), CREST (Wei et al., 2021), and CAST (Tan et al., 2023b); 5) methods based on large language models (LLMs), including LLaMA2-7B…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 55.62957692146301,
      "citing_paper_id": "273901511",
      "cited_paper_id": 174800839
    },
    {
      "context_text": "Although semi-automatic strategies, such as the recommend-revise annotation method (Yao et al., 2019), can alleviate annotators’ workload, they still fail to provide gold-quality datasets.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'gold-quality datasets' but does not specify any particular dataset name. The context is about the limitations of semi-automatic annotation methods, not about a specific dataset.",
      "processing_time": 56.63329291343689,
      "citing_paper_id": "273901511",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Consistent with prior work (Tan et al., 2023a; Wang et al., 2024), we adopt the ATLOP model (Zhou et al., 2021) as our backbone.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the ATLOP model which is a method, not a dataset.",
      "processing_time": 55.6203339099884,
      "citing_paper_id": "273901511",
      "cited_paper_id": 225039888
    },
    {
      "context_text": "Consistent with prior work (Tan et al., 2023a; Wang et al., 2024), we adopt the ATLOP model (Zhou et al., 2021) as our backbone.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the ATLOP model which is a method, not a dataset.",
      "processing_time": 55.6203339099884,
      "citing_paper_id": "273901511",
      "cited_paper_id": 259187621
    },
    {
      "context_text": "Consistent with prior work (Tan et al., 2023a; Wang et al., 2024), we adopt the ATLOP model (Zhou et al., 2021) as our backbone.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the ATLOP model which is a method, not a dataset.",
      "processing_time": 55.6203339099884,
      "citing_paper_id": "273901511",
      "cited_paper_id": 259261857
    },
    {
      "context_text": "Substantial progress has been made through the development of complex neural networks (Zhou et al., 2021; Jiang et al., 2022; Tan et al., 2022a), the integration of evidence sentences (Huang et al., 2021; Xie et al., 2022), and the exploration of loss functions (Zhou and Lee, 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 56.26328897476196,
      "citing_paper_id": "273901511",
      "cited_paper_id": 225039888
    },
    {
      "context_text": "Substantial progress has been made through the development of complex neural networks (Zhou et al., 2021; Jiang et al., 2022; Tan et al., 2022a), the integration of evidence sentences (Huang et al., 2021; Xie et al., 2022), and the exploration of loss functions (Zhou and Lee, 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide additional information about datasets.",
      "processing_time": 56.26328897476196,
      "citing_paper_id": "273901511",
      "cited_paper_id": 247291740
    },
    {
      "context_text": "…baselines: 1) vanilla baselines, including various top-performing models under fully supervised settings, such as GAIN (Zeng et al., 2020), AT-LOP (Zhou et al., 2021), and KD-DocRE (Tan et al., 2022a); 2) negative sampling methods (Li et al., 2021); 3) PU learning-based methods, including SSR-PU…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 55.621381521224976,
      "citing_paper_id": "273901511",
      "cited_paper_id": 225039888
    },
    {
      "context_text": "Following prior work (Tan et al., 2023a), we adopt ATLOP (Zhou et al., 2021) as the backbone and NCRL (Zhou and Lee, 2022) as the loss function.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on adopting ATLOP and NCRL for document-level relation extraction.",
      "processing_time": 56.19606256484985,
      "citing_paper_id": "273901511",
      "cited_paper_id": 225039888
    },
    {
      "context_text": "Unlike sentence-level relation extraction, which focuses on individual entity pairs (Stoica et al., 2021), DocRE is challenged by the vast number of potential entity pairs.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general challenge in document-level relation extraction.",
      "processing_time": 53.7764105796814,
      "citing_paper_id": "273901511",
      "cited_paper_id": 233296843
    },
    {
      "context_text": "There has been extensive research aimed at alleviating the impact of false negative samples (Li et al., 2021; Wang et al., 2022a, 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research papers. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 56.095688819885254,
      "citing_paper_id": "273901511",
      "cited_paper_id": 252918868
    },
    {
      "context_text": "…et al., 2021), and KD-DocRE (Tan et al., 2022a); 2) negative sampling methods (Li et al., 2021); 3) PU learning-based methods, including SSR-PU (Wang et al., 2022a) and P 3 M (Wang et al., 2024); 4) sub-symbolic self-training methods, such as VST (Jie et al., 2019), CREST (Wei et al., 2021),…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper title does not provide additional context to identify a dataset.",
      "processing_time": 56.091434955596924,
      "citing_paper_id": "273901511",
      "cited_paper_id": 252918868
    },
    {
      "context_text": "5 (Ope-nAI, 2022), and GPT-4o (OpenAI, 2024), as well as techniques utilizing in-context learning (ICL) for task-specific adaptation (Dong et al., 2022), natural language inference (NLI) models for fuzzy matching (Li et al., 2023a), and data programming for label denoising (Gao et al., 2023); and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 55.78829383850098,
      "citing_paper_id": "273901511",
      "cited_paper_id": 255372865
    },
    {
      "context_text": "Moreover, the performance gains from CAST to LogicST increase as the distance grows.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of performance between two methods (CAST and LogicST).",
      "processing_time": 54.88729476928711,
      "citing_paper_id": "273901511",
      "cited_paper_id": 259187621
    },
    {
      "context_text": "Additionally, LogicST requires only 10 % of the training time of CAST (Tan et al., 2023a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of training times between LogicST and CAST. No verifiable resources are identified.",
      "processing_time": 56.086220502853394,
      "citing_paper_id": "273901511",
      "cited_paper_id": 259187621
    },
    {
      "context_text": "Previous works have attempted to mitigate this issue by sampling the pseudo-labels based on class frequencies (Wei et al., 2021) or scores calculated on the development set (Tan et al., 2023a).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. The context focuses on techniques for mitigating issues in relation extraction, such as sampling pseudo-labels based on class frequencies or scores.",
      "processing_time": 56.78045463562012,
      "citing_paper_id": "273901511",
      "cited_paper_id": 259187621
    },
    {
      "context_text": "…(Tan et al., 2022a); 2) negative sampling methods (Li et al., 2021); 3) PU learning-based methods, including SSR-PU (Wang et al., 2022a) and P 3 M (Wang et al., 2024); 4) sub-symbolic self-training methods, such as VST (Jie et al., 2019), CREST (Wei et al., 2021), and CAST (Tan et al., 2023b); 5)…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper title does not provide additional context to identify datasets.",
      "processing_time": 55.80722999572754,
      "citing_paper_id": "273901511",
      "cited_paper_id": 259261857
    },
    {
      "context_text": "This may be due to LLMs’ difficulty in handling complex reasoning, and domain-specific nuances (Pang et al., 2023 Results on DWIE.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'DWIE' which could be a dataset, but there is insufficient context to confirm its nature or usage. The title does not provide additional clarity.",
      "processing_time": 56.248414516448975,
      "citing_paper_id": "273901511",
      "cited_paper_id": 263830659
    },
    {
      "context_text": "LogicST is implemented within a teacher-student framework (Tarvainen and Valpola, 2017), where the teacher model is first pre-trained to establish a robust initial state.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (teacher-student framework) and a reference to a paper. The cited paper title confirms it is about a method, not a dataset.",
      "processing_time": 56.599782943725586,
      "citing_paper_id": "273901511",
      "cited_paper_id": 263861232
    },
    {
      "context_text": "5 (Ope-nAI, 2022), and GPT-4o (OpenAI, 2024), as well as techniques utilizing in-context learning (ICL) for task-specific adaptation (Dong et al., 2022), natural language inference (NLI) models for fuzzy matching (Li et al., 2023a), and data programming for label denoising (Gao et al., 2023); and 6) logical frameworks designed for supervised DocRE, including LogiRE (Ru et al., 2021), MILR (Fan et al., 2022), and JMRL (Qi et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 55.89232921600342,
      "citing_paper_id": "273901511",
      "cited_paper_id": 271923564
    },
    {
      "context_text": "…al., 2022), natural language inference (NLI) models for fuzzy matching (Li et al., 2023a), and data programming for label denoising (Gao et al., 2023); and 6) logical frameworks designed for supervised DocRE, including LogiRE (Ru et al., 2021), MILR (Fan et al., 2022), and JMRL (Qi et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No dataset names are present in the text.",
      "processing_time": 55.49616551399231,
      "citing_paper_id": "273901511",
      "cited_paper_id": 271923564
    },
    {
      "context_text": "Sentence-level event extraction has been extensively researched (Liu et al., 2018; Wadden et al., 2019; Hamborg et al., 2019; Wang et al., 2023b; Xu et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. No dataset names are present in the context.",
      "processing_time": 55.608943462371826,
      "citing_paper_id": "270703045",
      "cited_paper_id": 52816033
    },
    {
      "context_text": "Sentence-level event extraction has been extensively researched (Liu et al., 2018; Wadden et al., 2019; Hamborg et al., 2019; Wang et al., 2023b; Xu et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. No dataset names are present in the context.",
      "processing_time": 55.608943462371826,
      "citing_paper_id": "270703045",
      "cited_paper_id": 202537206
    },
    {
      "context_text": "(2) Document-level Encoding: Transformer encoder and RST (Rhetorical Structure Theory) (Mann and Thompson, 1987) tree are used to make entities aware of document-level context.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and theories. The citation is used to explain the methodology for document-level encoding.",
      "processing_time": 55.61536455154419,
      "citing_paper_id": "270703045",
      "cited_paper_id": 60709701
    },
    {
      "context_text": "Du and Cardie (2020) proposed a QA approach for event extraction to avoid the dependency of event extraction results on the previous entity recognition step.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for event extraction using a QA approach.",
      "processing_time": 54.160308837890625,
      "citing_paper_id": "270703045",
      "cited_paper_id": 216562330
    },
    {
      "context_text": "Although not many, there have been some studies on cross-document information extraction, such as event coreference resolution (Wu et al., 2020; Held et al., 2021; Eirew et al., 2022) and relation extraction (Yao et al., 2021; Lu et al., 2023).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CodRED"
      ],
      "dataset_descriptions": {
        "CodRED": "Used to acquire knowledge through cross-document relation extraction, focusing on real-world entities and their relationships in diverse documents."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions studies on cross-document information extraction, including event coreference resolution and relation extraction. However, only 'CodRED' is a specific dataset name mentioned in the cited paper titles.",
      "processing_time": 59.34503936767578,
      "citing_paper_id": "270703045",
      "cited_paper_id": 220045465
    },
    {
      "context_text": "Although not many, there have been some studies on cross-document information extraction, such as event coreference resolution (Wu et al., 2020; Held et al., 2021; Eirew et al., 2022) and relation extraction (Yao et al., 2021; Lu et al., 2023).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CodRED"
      ],
      "dataset_descriptions": {
        "CodRED": "Used to acquire knowledge through cross-document relation extraction, focusing on real-world entities and their relationships in diverse documents."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions studies on cross-document information extraction, including event coreference resolution and relation extraction. However, only 'CodRED' is a specific dataset name mentioned in the cited paper titles.",
      "processing_time": 59.34503936767578,
      "citing_paper_id": "270703045",
      "cited_paper_id": 243865600
    },
    {
      "context_text": "We borrowed the approach from Eirew et al. (2021) and optimized its data collection system to gather data from Wikipedia dump files.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions optimizing a data collection system to gather data from Wikipedia dump files, but does not specify a named dataset. The cited paper title suggests a dataset, but it is not explicitly mentioned in the context.",
      "processing_time": 57.06329560279846,
      "citing_paper_id": "270703045",
      "cited_paper_id": 233210350
    },
    {
      "context_text": "Although significant advancements have been made (Xu et al., 2021; Yang et al., 2021a Figure 1: An example of cross-document event extraction, where a comprehensive event is obtained from three event mentions in three documents. et al., 2023a), DEE often encounters limitations in terms of the scope…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general advancements and limitations in document-level event extraction (DEE).",
      "processing_time": 55.59766459465027,
      "citing_paper_id": "270703045",
      "cited_paper_id": 235253912
    },
    {
      "context_text": "Although significant advancements have been made (Xu et al., 2021; Yang et al., 2021a Figure 1: An example of cross-document event extraction, where a comprehensive event is obtained from three event mentions in three documents. et al., 2023a), DEE often encounters limitations in terms of the scope…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general advancements and limitations in document-level event extraction (DEE).",
      "processing_time": 55.59766459465027,
      "citing_paper_id": "270703045",
      "cited_paper_id": 236460259
    },
    {
      "context_text": "…(Xu et al., 2021; Yang et al., 2021a Figure 1: An example of cross-document event extraction, where a comprehensive event is obtained from three event mentions in three documents. et al., 2023a), DEE often encounters limitations in terms of the scope and depth of information that it can provide.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the limitations and scope of Document-Level Event Extraction (DEE).",
      "processing_time": 55.59772443771362,
      "citing_paper_id": "270703045",
      "cited_paper_id": 258967833
    },
    {
      "context_text": "Mi-culicich and Henderson (2022) addressed coreference resolution using a graph-based approach, while Chen et al. (2023) introduced discourse information to model documents, resulting in a significant performance improvement.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on coreference resolution and discourse modeling.",
      "processing_time": 55.032034397125244,
      "citing_paper_id": "270703045",
      "cited_paper_id": 266163830
    },
    {
      "context_text": "Baseline We chose Yu et al. (2022) as the base-line, which determines coreference by enhancing event mention representations with event argument information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a baseline method from a cited paper.",
      "processing_time": 54.591888666152954,
      "citing_paper_id": "270703045",
      "cited_paper_id": null
    },
    {
      "context_text": "In terms of coreference resolution, Yu et al. (2022) proposed a cross-document coreference resolution model that enhances event mention representation by extracting event arguments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for cross-document coreference resolution.",
      "processing_time": 54.83966040611267,
      "citing_paper_id": "270703045",
      "cited_paper_id": null
    },
    {
      "context_text": "With respect to other directions, Caciularu et al. (2021) proposed a novel cross-document pre-training language model to learn rich contextual information across documents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. There are no clear identifiers for datasets in the text.",
      "processing_time": 55.589600801467896,
      "citing_paper_id": "270703045",
      "cited_paper_id": null
    },
    {
      "context_text": "† means BERT-base (Devlin et al., 2018) and ‡ means RoBERTa-large (Liu et al., 2019). at once by one prompt rather than enumerate all entity pairs to ask for relations one by one (which is too costly and time-consuming to execute for plenty of entities on document-level RE).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (BERT and RoBERTa). The context focuses on the methodology of using prompts for relation extraction.",
      "processing_time": 55.93981051445007,
      "citing_paper_id": "265150105",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "To align GPT-generated relations and predefined relation types, we first combine Natural Language Inference (NLI) models (MacCartney, 2009) with GPT to solve zero-shot DocRE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on combining NLI models with GPT for zero-shot document-level relation extraction.",
      "processing_time": 56.28613591194153,
      "citing_paper_id": "265150105",
      "cited_paper_id": 60246043
    },
    {
      "context_text": "Recent studies have utilized GPT (Floridi and Chiriatti, 2020; Chan, 2023) for various structural prediction tasks, such as named entity prediction and relation extraction (Dunn et al., 2022; Gutiér-rez et al., 2022; Wang et al., 2023; Liu et al., 2023; Xu et al., 2023), as well as text…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 55.566577672958374,
      "citing_paper_id": "265150105",
      "cited_paper_id": 228954221
    },
    {
      "context_text": "Recent studies have utilized GPT (Floridi and Chiriatti, 2020; Chan, 2023) for various structural prediction tasks, such as named entity prediction and relation extraction (Dunn et al., 2022; Gutiér-rez et al., 2022; Wang et al., 2023; Liu et al., 2023; Xu et al., 2023), as well as text…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 55.566577672958374,
      "citing_paper_id": "265150105",
      "cited_paper_id": 247961196
    },
    {
      "context_text": "Document-level Relation Extraction (DocRE) is a task that focuses on extracting fine-grained relations between entity pairs within a lengthy context (Yao et al., 2019; Nan et al., 2020; Wang et al., 2020; Zhou et al., 2021; Zhang et al., 2021; Ma et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the task of document-level relation extraction and related works.",
      "processing_time": 55.214078187942505,
      "citing_paper_id": "265150105",
      "cited_paper_id": 235358168
    },
    {
      "context_text": "Document-level Relation Extraction (DocRE) is a task that focuses on extracting fine-grained relations between entity pairs within a lengthy context (Yao et al., 2019; Nan et al., 2020; Wang et al., 2020; Zhou et al., 2021; Zhang et al., 2021; Ma et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the task of document-level relation extraction and related works.",
      "processing_time": 55.214078187942505,
      "citing_paper_id": "265150105",
      "cited_paper_id": 257019958
    },
    {
      "context_text": "Therefore, we employ a NLI model, which has demonstrated effectiveness in assessing factual consistency (Honovich et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (NLI) and its application to factual consistency. No verifiable resources are identified.",
      "processing_time": 56.00319743156433,
      "citing_paper_id": "265150105",
      "cited_paper_id": 247694170
    },
    {
      "context_text": "Huang et al. (2022) undertook manual annotation from scratch, employing two expert an-notators to annotate 96 documents.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes the process of manual annotation by expert annotators.",
      "processing_time": 55.204763412475586,
      "citing_paper_id": "265150105",
      "cited_paper_id": 248227853
    },
    {
      "context_text": "Notably, two representative works, Huang et al. (2022) and Tan et al. (2022b), have contributed to this re-annotation process.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only contributions to a re-annotation process. No clear identifiers for datasets are present.",
      "processing_time": 55.37888526916504,
      "citing_paper_id": "265150105",
      "cited_paper_id": 248227853
    },
    {
      "context_text": "…GPT (Floridi and Chiriatti, 2020; Chan, 2023) for various structural prediction tasks, such as named entity prediction and relation extraction (Dunn et al., 2022; Gutiér-rez et al., 2022; Wang et al., 2023; Liu et al., 2023; Xu et al., 2023), as well as text classification labeling (Gilardi…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only tasks and models. No verifiable resources are identified.",
      "processing_time": 55.28366184234619,
      "citing_paper_id": "265150105",
      "cited_paper_id": 254564105
    },
    {
      "context_text": "We test the SOTA document-level RE model (Ma et al., 2023) In addition, we conducted experiments using two other DocRE models, ATLOP (Zhou et al., 2021) and KD-DocRE (Tan et al., 2022a), by leveraging their officially provided code.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their code. The context focuses on the use of models for document-level relation extraction.",
      "processing_time": 55.99455690383911,
      "citing_paper_id": "265150105",
      "cited_paper_id": 257019958
    },
    {
      "context_text": "…2020; Chan, 2023) for various structural prediction tasks, such as named entity prediction and relation extraction (Dunn et al., 2022; Gutiér-rez et al., 2022; Wang et al., 2023; Liu et al., 2023; Xu et al., 2023), as well as text classification labeling (Gilardi et al., 2023; Törnberg, 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks and methods. No clear identifiers for datasets are present.",
      "processing_time": 55.442086935043335,
      "citing_paper_id": "265150105",
      "cited_paper_id": 257766307
    },
    {
      "context_text": "…2020; Chan, 2023) for various structural prediction tasks, such as named entity prediction and relation extraction (Dunn et al., 2022; Gutiér-rez et al., 2022; Wang et al., 2023; Liu et al., 2023; Xu et al., 2023), as well as text classification labeling (Gilardi et al., 2023; Törnberg, 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks and methods. No clear identifiers for datasets are present.",
      "processing_time": 55.442086935043335,
      "citing_paper_id": "265150105",
      "cited_paper_id": null
    },
    {
      "context_text": "However, such a point estimate is not sufﬁcient to express uncertainty, as point-based methods assume that learned features are always correct (Gal and Ghahramani, 2016; Kendall and Gal, 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and their limitations.",
      "processing_time": 54.60775566101074,
      "citing_paper_id": "243865596",
      "cited_paper_id": 160705
    },
    {
      "context_text": "The early work on this problem has mainly employed rule-based methods (Nairn et al., 2006; Saurı, 2008; Lotan et al., 2013) or machine learning methods (with manually designed features) (Diab et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous work using rule-based methods or machine learning methods with manually designed features.",
      "processing_time": 55.79372000694275,
      "citing_paper_id": "243865596",
      "cited_paper_id": 804903
    },
    {
      "context_text": "Generally, event factuality can be classified into five categories (Saurı, 2008): Certain Positive (certainly happening, denoted as CT+), Certain Negative (certainly not happening, CT-), Possible Positive (possibly happening, PS+), Possible Negative (possibly not happening, PS-) and Underspecified (events’ factuality cannot be identified, Uu).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only categories of event factuality. No verifiable resources are referenced.",
      "processing_time": 55.52275061607361,
      "citing_paper_id": "243865596",
      "cited_paper_id": 804903
    },
    {
      "context_text": ", 2014) and long short-term memory networks (Hochreiter and Schmidhuber, 1997) can also be employed as encoders.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only neural network architectures. No dataset names are present in the citation span.",
      "processing_time": 55.51992845535278,
      "citing_paper_id": "243865596",
      "cited_paper_id": 1915014
    },
    {
      "context_text": "…event is PS+. EFI is an important task in natural language processing (NLP) area, which is beneﬁcial for a wide range of NLP applications, such as rumor detection (Qazvinian et al., 2011), sentiment analysis (Klenner and Clematide, 2016) and machine reading comprehension (Richardson et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general applications of event frame identification (EFI) in NLP. The cited papers do not introduce new datasets either.",
      "processing_time": 56.44715070724487,
      "citing_paper_id": "243865596",
      "cited_paper_id": 2100831
    },
    {
      "context_text": "…event is PS+. EFI is an important task in natural language processing (NLP) area, which is beneﬁcial for a wide range of NLP applications, such as rumor detection (Qazvinian et al., 2011), sentiment analysis (Klenner and Clematide, 2016) and machine reading comprehension (Richardson et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general applications of event frame identification (EFI) in NLP. The cited papers do not introduce new datasets either.",
      "processing_time": 56.44715070724487,
      "citing_paper_id": "243865596",
      "cited_paper_id": 14124213
    },
    {
      "context_text": "In recent years, neural networks have been introduced into the EFI task, and achieved state-of-the-art performance (Rudinger et al., 2018; Qian et al., 2018; Sheng et al., 2019; Huang et al., 2019; Veyseh et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that achieved state-of-the-art performance in the EFI task.",
      "processing_time": 55.77928924560547,
      "citing_paper_id": "243865596",
      "cited_paper_id": 2239324
    },
    {
      "context_text": "In recent years, neural networks have been introduced into the EFI task, and achieved state-of-the-art performance (Rudinger et al., 2018; Qian et al., 2018; Sheng et al., 2019; Huang et al., 2019; Veyseh et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that achieved state-of-the-art performance in the EFI task.",
      "processing_time": 55.77928924560547,
      "citing_paper_id": "243865596",
      "cited_paper_id": 51605619
    },
    {
      "context_text": "In recent years, neural networks have been introduced into the EFI task, and achieved state-of-the-art performance (Rudinger et al., 2018; Qian et al., 2018; Sheng et al., 2019; Huang et al., 2019; Veyseh et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that achieved state-of-the-art performance in the EFI task.",
      "processing_time": 55.77928924560547,
      "citing_paper_id": "243865596",
      "cited_paper_id": 195833740
    },
    {
      "context_text": "In recent years, neural networks have been introduced into the EFI task, and achieved state-of-the-art performance (Rudinger et al., 2018; Qian et al., 2018; Sheng et al., 2019; Huang et al., 2019; Veyseh et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that achieved state-of-the-art performance in the EFI task.",
      "processing_time": 55.77928924560547,
      "citing_paper_id": "243865596",
      "cited_paper_id": 203620105
    },
    {
      "context_text": "…has mainly employed rule-based methods (Nairn et al., 2006; Saurı, 2008; Lotan et al., 2013) or machine learning methods (with manually designed features) (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Saurí and Pustejovsky, 2012; Lee et al., 2015; Qian et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 55.46164345741272,
      "citing_paper_id": "243865596",
      "cited_paper_id": 5730838
    },
    {
      "context_text": "…has mainly employed rule-based methods (Nairn et al., 2006; Saurı, 2008; Lotan et al., 2013) or machine learning methods (with manually designed features) (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Saurí and Pustejovsky, 2012; Lee et al., 2015; Qian et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 55.46164345741272,
      "citing_paper_id": "243865596",
      "cited_paper_id": 8992998
    },
    {
      "context_text": ", 2013) or machine learning methods (with manually designed features) (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Saurí and Pustejovsky, 2012; Lee et al., 2015; Qian et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers using machine learning methods with manually designed features.",
      "processing_time": 55.36763048171997,
      "citing_paper_id": "243865596",
      "cited_paper_id": 8992998
    },
    {
      "context_text": "The early work on this problem has mainly employed rule-based methods (Nairn et al., 2006; Saurı, 2008; Lotan et al., 2013) or machine learning methods (with manually designed features) (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Saurí and Pustejovsky, 2012; Lee et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various methods and approaches. No verifiable resources are identified.",
      "processing_time": 55.5457603931427,
      "citing_paper_id": "243865596",
      "cited_paper_id": 9885298
    },
    {
      "context_text": "In fact, other models like convolutional neural networks (Zeng et al., 2014) and long short-term memory networks (Hochreiter and Schmidhuber, 1997) can also be employed as encoders.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources or datasets mentioned.",
      "processing_time": 55.278711557388306,
      "citing_paper_id": "243865596",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "For example, Vilnis and McCallum (2015) utilize Gaussian embeddings to represent words, where the covariance naturally measures the ambiguity of the words.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Gaussian embeddings). The citation is focused on the method used for word representation.",
      "processing_time": 55.61440372467041,
      "citing_paper_id": "243865596",
      "cited_paper_id": 13468104
    },
    {
      "context_text": "Our local context encoder is based on the Transformer architecture (Vaswani et al., 2017).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a method (Transformer architecture) rather than a dataset. No datasets are referenced.",
      "processing_time": 54.82841372489929,
      "citing_paper_id": "243865596",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "…the size of randomly initialized parameters may not be beneﬁcial for BERT ﬁne-tuning. can beneﬁt many NLP applications, including rumor detection (Qazvinian et al., 2011), sentiment analysis (Klenner and Clematide, 2016), event causality identiﬁcation (Cao et al., 2021; Tran Phu and Nguyen,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only applications of NLP techniques. The context is too generic to infer specific datasets.",
      "processing_time": 55.60705351829529,
      "citing_paper_id": "243865596",
      "cited_paper_id": 14124213
    },
    {
      "context_text": "In recent years, various neural models have been proposed for sentence-level EFI, and achieve state-of-the-art performance (Rudinger et al., 2018; Qian et al., 2018; Veyseh et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural models and their performance in sentence-level event factuality identification.",
      "processing_time": 55.433388471603394,
      "citing_paper_id": "243865596",
      "cited_paper_id": 51605619
    },
    {
      "context_text": "In recent years, various neural models have been proposed for sentence-level EFI, and achieve state-of-the-art performance (Rudinger et al., 2018; Qian et al., 2018; Veyseh et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural models and their performance in sentence-level event factuality identification.",
      "processing_time": 55.433388471603394,
      "citing_paper_id": "243865596",
      "cited_paper_id": 195833740
    },
    {
      "context_text": "In recent years, neural networks have been introduced into the EFI task, and achieved state-ofthe-art performance (Rudinger et al., 2018; Qian et al., 2018; Sheng et al., 2019; Huang et al., 2019; Veyseh et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that achieved state-of-the-art performance in the EFI task.",
      "processing_time": 55.514039278030396,
      "citing_paper_id": "243865596",
      "cited_paper_id": 51605619
    },
    {
      "context_text": "In recent years, neural networks have been introduced into the EFI task, and achieved state-ofthe-art performance (Rudinger et al., 2018; Qian et al., 2018; Sheng et al., 2019; Huang et al., 2019; Veyseh et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that achieved state-of-the-art performance in the EFI task.",
      "processing_time": 55.514039278030396,
      "citing_paper_id": "243865596",
      "cited_paper_id": 203620105
    },
    {
      "context_text": "In recent years, various neural models have been proposed for sentence-level EFI, and achieve stateof-the-art performance (Rudinger et al., 2018; Qian et al., 2018; Veyseh et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to neural models and their performance in sentence-level event factuality identification.",
      "processing_time": 55.59131836891174,
      "citing_paper_id": "243865596",
      "cited_paper_id": 51605619
    },
    {
      "context_text": "For a fair comparison with previous work (Qian et al., 2019), we both perform 10-fold cross-validation on English and Chinese corpora.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'English and Chinese corpora' but does not specify a named dataset. The corpora are too generic and lack specific identifiers.",
      "processing_time": 55.84059429168701,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "Therefore, following previous work (Qian et al., 2019), we mainly focus on the performance of CT+, CT-and PS+.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model configurations (CT+, CT-, PS+). There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 55.999359130859375,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "To further investigate the effectiveness of our method for document-level EFI, we compare our method with Att-Adv on the (1) Compared with improvements over the Att-Adv (Qian et al., 2019) when n = 1, our method achieves more improvements when n> 1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of methods. The context is focused on the performance of the methods rather than the use of a particular dataset.",
      "processing_time": 56.15410542488098,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "We compare the proposed approach ULGN with the following methods: (1) MaxEntVote (Qian et al., 2019), which first uses maximum entropy model to identify sentencelevel event factuality, and then votes, i.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on comparing the proposed approach with other methods.",
      "processing_time": 55.66885471343994,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "From the table, we have two important observations: (1) Compared with improvements over the AttAdv (Qian et al., 2019) when n=1, our method achieves more improvements when n>1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of performance metrics. The context is focused on methodological improvements.",
      "processing_time": 55.162646532058716,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "To this end, Qian et al. (2019) propose the document-level EFI task.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a task proposed in the cited paper.",
      "processing_time": 54.90883469581604,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "(3) The BERT Model achieves comparable performance with complex state-of-the-art methods such as Att-Adv (Qian et al., 2019) on these two datasets, which indicates that the BERT is able to extract useful text features for the task.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'two datasets' but does not specify their names. The citation is focused on comparing model performance rather than describing the datasets.",
      "processing_time": 55.655903577804565,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "Therefore, following previous work (Qian et al., 2019), we mainly focus on the performance of CT+, CT- and PS+.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model configurations (CT+, CT-, PS+).",
      "processing_time": 54.66550397872925,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "We compare the proposed approach ULGN with the following methods: (1) MaxEntVote (Qian et al., 2019), which ﬁrst uses maximum entropy model to identify sentence-level event factuality, and then votes, i.e., choosing the value committed by the most sentences as the document-level factuality value.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on comparing the proposed method with existing methods.",
      "processing_time": 55.40543246269226,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "(3) Att-Adv (Qian et al., 2019), which leverages the intra-sentence and inter-sentence attention to learn the document representation, and utilizes adversarial training to improve the robustness.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Att-Adv) and its application in document-level event factuality identification.",
      "processing_time": 55.323065519332886,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "For example, compared with the previous state-of-the-art model Att-Adv (Qian et al., 2019), our method achieves 11.45% improvements of macro-F1 score on the Chinese event factuality dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Chinese event factuality dataset"
      ],
      "dataset_descriptions": {
        "Chinese event factuality dataset": "Used to evaluate the performance of the proposed method against the previous state-of-the-art model Att-Adv, focusing on macro-F1 score improvements in document-level event extraction."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions a specific dataset, 'Chinese event factuality dataset', which is relevant to document-level event extraction. The dataset is used to evaluate the performance of the proposed method.",
      "processing_time": 59.51863098144531,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "(2) BiLSTM-Att (Qian et al., 2019), which employs the bidirectional long short-term memory network (BiLSTM) to extract features, and uses the intra-sentence attention to capture the most important information in the sentence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (BiLSTM-Att). The context focuses on the model architecture and its components.",
      "processing_time": 55.799368381500244,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "For example, compared with the previous state-of-the-art model Att-Adv (Qian et al., 2019), our method achieves 11.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison with a previous model. No verifiable resources are identified.",
      "processing_time": 55.06203365325928,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "According to our statistics on the English and Chinese event factuality datasets (Qian et al., 2019), 25.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "English and Chinese event factuality datasets"
      ],
      "dataset_descriptions": {
        "English and Chinese event factuality datasets": "Used to identify event factuality in documents, focusing on the statistical distribution of factual and non-factual events across languages using adversarial neural networks."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'English and Chinese event factuality datasets' which are specific and relevant to document-level event extraction. The title confirms the datasets are used for event factuality identification.",
      "processing_time": 58.89393424987793,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "According to our statistics on the English and Chinese event factuality datasets (Qian et al., 2019), 25.7% (English) and 37.8% (Chinese) of instances have the problem of event factuality conﬂict at sentence level for the same event, which is not negligible.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "English and Chinese event factuality datasets"
      ],
      "dataset_descriptions": {
        "English and Chinese event factuality datasets": "Used to analyze event factuality conflicts at the sentence level, revealing significant discrepancies in event representation across languages."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'English and Chinese event factuality datasets' which are specific to the research topic of document-level event extraction. The datasets are used to analyze event factuality conflicts.",
      "processing_time": 58.581453800201416,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "We evaluate our proposed method on two widely used datasets, English and Chinese event factuality datasets (Qian et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "English and Chinese event factuality datasets"
      ],
      "dataset_descriptions": {
        "English and Chinese event factuality datasets": "Used to evaluate the proposed method for document-level event factuality identification, focusing on the accuracy and robustness across languages using adversarial neural networks."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'English and Chinese event factuality datasets' which are specific datasets used for evaluation. The cited paper title confirms the relevance to document-level event extraction.",
      "processing_time": 58.68517732620239,
      "citing_paper_id": "243865596",
      "cited_paper_id": 174800759
    },
    {
      "context_text": "Most existing EFI studies are limited to the sentence-level task (Saurí and Pustejovsky, 2012; De Marneffe et al., 2012; Rudinger et al., 2018; Veyseh et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous studies. There are no clear identifiers for datasets, models, or other resources.",
      "processing_time": 55.303282260894775,
      "citing_paper_id": "243865596",
      "cited_paper_id": 195833740
    },
    {
      "context_text": "Inspired by Zhu et al. (2019), we formally utilize an uncertain graph convolution layer (UGCL) to perform convolution operations between Gaussian distributions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (UGCL) inspired by the cited paper.",
      "processing_time": 54.24984645843506,
      "citing_paper_id": "243865596",
      "cited_paper_id": 196215305
    },
    {
      "context_text": "He et al. (2015) attempt to leverage the Gaussian distribution to represent the entity and relation, which aims to model the uncertainty of entities and relations in knowledge graphs.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for representing knowledge graphs using Gaussian embeddings.",
      "processing_time": 54.078298568725586,
      "citing_paper_id": "243865596",
      "cited_paper_id": 207228784
    },
    {
      "context_text": "Longformer 4 (Beltagy et al., 2020) to extract the global feature for prediction; 2) BERT-GCN and BERT-GAT, which ﬁrst uses the BERT to the lo-cal information, and then employs GCN and GAT (Veliˇckovi´c et al., 2017) for integrating the local information, respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of Longformer, BERT-GCN, and BERT-GAT for document-level event extraction.",
      "processing_time": 55.91743850708008,
      "citing_paper_id": "243865596",
      "cited_paper_id": 215737171
    },
    {
      "context_text": "Thus, we use the reparameterization trick (Kingma and Welling, 2013) to bypass the problem.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (reparameterization trick) rather than a dataset. No dataset names are present in the citation span.",
      "processing_time": 54.81159043312073,
      "citing_paper_id": "243865596",
      "cited_paper_id": 216078090
    },
    {
      "context_text": "…(2) Uncertain Information Aggregation ( § 2.2), which leverages the global structure to integrate the local information; (3) Reparameterization for Prediction ( § 2.3), which utilizes the reparameterization trick (Kingma and Welling, 2013) to obtain the global representation for ﬁnal prediction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and concepts. The reparameterization trick is a technique, not a dataset.",
      "processing_time": 54.80966114997864,
      "citing_paper_id": "243865596",
      "cited_paper_id": 216078090
    },
    {
      "context_text": "…of randomly initialized parameters may not be beneﬁcial for BERT ﬁne-tuning. can beneﬁt many NLP applications, including rumor detection (Qazvinian et al., 2011), sentiment analysis (Klenner and Clematide, 2016), event causality identiﬁcation (Cao et al., 2021; Tran Phu and Nguyen, 2021) and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only applications of NLP techniques. The context does not provide enough information to identify a specific, verifiable dataset.",
      "processing_time": 55.2969708442688,
      "citing_paper_id": "243865596",
      "cited_paper_id": 236460024
    },
    {
      "context_text": ", 2011), sentiment analysis (Klenner and Clematide, 2016), event causality identification (Cao et al., 2021; Tran Phu and Nguyen, 2021) and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general research areas and methods. No clear identifiers for datasets are present.",
      "processing_time": 54.815176248550415,
      "citing_paper_id": "243865596",
      "cited_paper_id": 236460024
    },
    {
      "context_text": "To train and evaluate IE pipelines, numerous datasets have been proposed, covering a large spectrum of settings and applications:\n• Some focus on general domain information (e.g., TREx [10], DocRED [36], or HacRED [5]), other on very specific domains (scientific literature for SciERC [20], biomedicine for FewRel 2.0 [12], or BC5CDR [19]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TREx",
        "DocRED",
        "HacRED",
        "SciERC",
        "FewRel 2.0",
        "BC5CDR"
      ],
      "dataset_descriptions": {
        "TREx": "Used to align natural language with knowledge base triples, specifically for document-level event extraction tasks, focusing on general domain information.",
        "DocRED": "Used to evaluate document-level relation extraction, focusing on complex relations in long documents, enhancing the understanding of entity interactions.",
        "HacRED": "Used to evaluate hierarchical relation extraction, focusing on nested and overlapping relations, improving the accuracy of multi-level relation detection.",
        "SciERC": "Used to train and evaluate scientific relation extraction, focusing on relations in scientific literature, enhancing the understanding of scientific discourse.",
        "FewRel 2.0": "Used to evaluate few-shot relation extraction, focusing on biomedicine, enhancing the ability to generalize from limited labeled data.",
        "BC5CDR": "Used to extract chemical-disease relations from biomedical texts, focusing on the identification of specific chemical and disease entities."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets by name, which are used for training and evaluating information extraction pipelines. These datasets cover various domains and are clearly identified.",
      "processing_time": 64.45441007614136,
      "citing_paper_id": "259949858",
      "cited_paper_id": 88817
    },
    {
      "context_text": "To train and evaluate IE pipelines, numerous datasets have been proposed, covering a large spectrum of settings and applications:\n• Some focus on general domain information (e.g., TREx [10], DocRED [36], or HacRED [5]), other on very specific domains (scientific literature for SciERC [20], biomedicine for FewRel 2.0 [12], or BC5CDR [19]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TREx",
        "DocRED",
        "HacRED",
        "SciERC",
        "FewRel 2.0",
        "BC5CDR"
      ],
      "dataset_descriptions": {
        "TREx": "Used to align natural language with knowledge base triples, specifically for document-level event extraction tasks, focusing on general domain information.",
        "DocRED": "Used to evaluate document-level relation extraction, focusing on complex relations in long documents, enhancing the understanding of entity interactions.",
        "HacRED": "Used to evaluate hierarchical relation extraction, focusing on nested and overlapping relations, improving the accuracy of multi-level relation detection.",
        "SciERC": "Used to train and evaluate scientific relation extraction, focusing on relations in scientific literature, enhancing the understanding of scientific discourse.",
        "FewRel 2.0": "Used to evaluate few-shot relation extraction, focusing on biomedicine, enhancing the ability to generalize from limited labeled data.",
        "BC5CDR": "Used to extract chemical-disease relations from biomedical texts, focusing on the identification of specific chemical and disease entities."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets by name, which are used for training and evaluating information extraction pipelines. These datasets cover various domains and are clearly identified.",
      "processing_time": 64.45441007614136,
      "citing_paper_id": "259949858",
      "cited_paper_id": 4612975
    },
    {
      "context_text": "DWIE [37] Similar to KnowledgeNet and BC5CDR, DWIE contains documents labeled for the four tasks.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DWIE"
      ],
      "dataset_descriptions": {
        "DWIE": "Used for multi-task document-level information extraction, specifically labeling documents for four tasks, enhancing the scope of document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DWIE' as a dataset containing documents labeled for four tasks, which aligns with the cited paper's title describing DWIE as a dataset for multi-task document-level information extraction.",
      "processing_time": 58.05705738067627,
      "citing_paper_id": "259949858",
      "cited_paper_id": 88817
    },
    {
      "context_text": "DWIE [37] Similar to KnowledgeNet and BC5CDR, DWIE contains documents labeled for the four tasks.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DWIE"
      ],
      "dataset_descriptions": {
        "DWIE": "Used for multi-task document-level information extraction, specifically labeling documents for four tasks, enhancing the scope of document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DWIE' as a dataset containing documents labeled for four tasks, which aligns with the cited paper's title describing DWIE as a dataset for multi-task document-level information extraction.",
      "processing_time": 58.05705738067627,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "Indeed, FewRel [15, 12] lacks documents and novel entities; T-REx [10] lacks manual annotations and novel entities; KnowledgeNet [23] and BC5CDR [19] are too small and not diverse enough; DWIE has automatic entity-linking annotations [37]; and HacRED [5], and DocRED [36] lack annotation for entitylinking.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "T-REx",
        "KnowledgeNet",
        "BC5CDR",
        "DWIE",
        "HacRED",
        "DocRED"
      ],
      "dataset_descriptions": {
        "FewRel": "Discussed for lacking documents and novel entities, used for document-level event extraction research, focusing on relation classification.",
        "T-REx": "Noted for lacking manual annotations and novel entities, used for aligning natural language with knowledge base triples.",
        "KnowledgeNet": "Mentioned as too small and not diverse enough, used for document-level relation extraction.",
        "BC5CDR": "Identified as too small and not diverse enough, used for chemical disease relation extraction.",
        "DWIE": "Highlighted for having automatic entity-linking annotations, used for document-level relation extraction.",
        "HacRED": "Noted for lacking entity-linking annotations, used for document-level relation extraction.",
        "DocRED": "Mentioned for lacking entity-linking annotations, used for large-scale document-level relation extraction."
      },
      "confidence_score": 0.8,
      "reasoning": "The context discusses several datasets in the context of document-level relation extraction, highlighting their limitations. No specific usage is described, only their shortcomings.",
      "processing_time": 63.992377519607544,
      "citing_paper_id": "259949858",
      "cited_paper_id": 88817
    },
    {
      "context_text": "Indeed, FewRel [15, 12] lacks documents and novel entities; T-REx [10] lacks manual annotations and novel entities; KnowledgeNet [23] and BC5CDR [19] are too small and not diverse enough; DWIE has automatic entity-linking annotations [37]; and HacRED [5], and DocRED [36] lack annotation for entitylinking.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "T-REx",
        "KnowledgeNet",
        "BC5CDR",
        "DWIE",
        "HacRED",
        "DocRED"
      ],
      "dataset_descriptions": {
        "FewRel": "Discussed for lacking documents and novel entities, used for document-level event extraction research, focusing on relation classification.",
        "T-REx": "Noted for lacking manual annotations and novel entities, used for aligning natural language with knowledge base triples.",
        "KnowledgeNet": "Mentioned as too small and not diverse enough, used for document-level relation extraction.",
        "BC5CDR": "Identified as too small and not diverse enough, used for chemical disease relation extraction.",
        "DWIE": "Highlighted for having automatic entity-linking annotations, used for document-level relation extraction.",
        "HacRED": "Noted for lacking entity-linking annotations, used for document-level relation extraction.",
        "DocRED": "Mentioned for lacking entity-linking annotations, used for large-scale document-level relation extraction."
      },
      "confidence_score": 0.8,
      "reasoning": "The context discusses several datasets in the context of document-level relation extraction, highlighting their limitations. No specific usage is described, only their shortcomings.",
      "processing_time": 63.992377519607544,
      "citing_paper_id": "259949858",
      "cited_paper_id": 4612975
    },
    {
      "context_text": "Indeed, FewRel [15, 12] lacks documents and novel entities; T-REx [10] lacks manual annotations and novel entities; KnowledgeNet [23] and BC5CDR [19] are too small and not diverse enough; DWIE has automatic entity-linking annotations [37]; and HacRED [5], and DocRED [36] lack annotation for entitylinking.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "T-REx",
        "KnowledgeNet",
        "BC5CDR",
        "DWIE",
        "HacRED",
        "DocRED"
      ],
      "dataset_descriptions": {
        "FewRel": "Discussed for lacking documents and novel entities, used for document-level event extraction research, focusing on relation classification.",
        "T-REx": "Noted for lacking manual annotations and novel entities, used for aligning natural language with knowledge base triples.",
        "KnowledgeNet": "Mentioned as too small and not diverse enough, used for document-level relation extraction.",
        "BC5CDR": "Identified as too small and not diverse enough, used for chemical disease relation extraction.",
        "DWIE": "Highlighted for having automatic entity-linking annotations, used for document-level relation extraction.",
        "HacRED": "Noted for lacking entity-linking annotations, used for document-level relation extraction.",
        "DocRED": "Mentioned for lacking entity-linking annotations, used for large-scale document-level relation extraction."
      },
      "confidence_score": 0.8,
      "reasoning": "The context discusses several datasets in the context of document-level relation extraction, highlighting their limitations. No specific usage is described, only their shortcomings.",
      "processing_time": 63.992377519607544,
      "citing_paper_id": "259949858",
      "cited_paper_id": 53080736
    },
    {
      "context_text": "Indeed, FewRel [15, 12] lacks documents and novel entities; T-REx [10] lacks manual annotations and novel entities; KnowledgeNet [23] and BC5CDR [19] are too small and not diverse enough; DWIE has automatic entity-linking annotations [37]; and HacRED [5], and DocRED [36] lack annotation for entitylinking.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "T-REx",
        "KnowledgeNet",
        "BC5CDR",
        "DWIE",
        "HacRED",
        "DocRED"
      ],
      "dataset_descriptions": {
        "FewRel": "Discussed for lacking documents and novel entities, used for document-level event extraction research, focusing on relation classification.",
        "T-REx": "Noted for lacking manual annotations and novel entities, used for aligning natural language with knowledge base triples.",
        "KnowledgeNet": "Mentioned as too small and not diverse enough, used for document-level relation extraction.",
        "BC5CDR": "Identified as too small and not diverse enough, used for chemical disease relation extraction.",
        "DWIE": "Highlighted for having automatic entity-linking annotations, used for document-level relation extraction.",
        "HacRED": "Noted for lacking entity-linking annotations, used for document-level relation extraction.",
        "DocRED": "Mentioned for lacking entity-linking annotations, used for large-scale document-level relation extraction."
      },
      "confidence_score": 0.8,
      "reasoning": "The context discusses several datasets in the context of document-level relation extraction, highlighting their limitations. No specific usage is described, only their shortcomings.",
      "processing_time": 63.992377519607544,
      "citing_paper_id": "259949858",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "However, BC5CDR and KnowledgeNet are too small (see Table 1) and not diverse enough (with only 15 relations types for KnowledgeNet and 1 for BC5CDR), which raises questions regarding their representativeness for realistic IE scenarios.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "BC5CDR",
        "KnowledgeNet"
      ],
      "dataset_descriptions": {
        "BC5CDR": "Used to highlight limitations in size and diversity for realistic information extraction tasks, specifically noting only 1 relation type.",
        "KnowledgeNet": "Used to highlight limitations in size and diversity, specifically noting its use in chemical disease relation extraction with only 15 relation types."
      },
      "confidence_score": 0.85,
      "reasoning": "BC5CDR and KnowledgeNet are mentioned as datasets but are described as too small and not diverse enough for realistic IE scenarios.",
      "processing_time": 58.81774139404297,
      "citing_paper_id": "259949858",
      "cited_paper_id": 88817
    },
    {
      "context_text": "KnowledgeNet [23] and BC5CDR [19] They contain documents and are annotated for the four tasks.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "BC5CDR"
      ],
      "dataset_descriptions": {
        "BC5CDR": "Used for chemical disease relation extraction, specifically annotating documents for chemical and disease entities and their relationships."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'KnowledgeNet' and 'BC5CDR' as containing documents annotated for specific tasks. Based on the cited paper title, BC5CDR is confirmed to be a dataset.",
      "processing_time": 57.61179327964783,
      "citing_paper_id": "259949858",
      "cited_paper_id": 88817
    },
    {
      "context_text": "Similarly to FewRel, BC5CDR has no new knowledge (all entities are already present in the knowledge base).",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 11 column 1 (char 514), response: ```json\n{\n    \"reasoning\": \"BC5CDR is mentioned as a dataset, and the context indicates it is used f",
      "processing_time": 57.23131442070007,
      "citing_paper_id": "259949858",
      "cited_paper_id": 88817
    },
    {
      "context_text": "T-REx [10] Of the seven datasets, it is by far the largest, with around 4.6 million documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "T-REx"
      ],
      "dataset_descriptions": {
        "T-REx": "Used as a large-scale dataset for aligning natural language with knowledge base triples, containing approximately 4.6 million documents, to study document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'T-REx' as a dataset, which is described as the largest among seven datasets, containing around 4.6 million documents. The title confirms it is a dataset.",
      "processing_time": 57.96307611465454,
      "citing_paper_id": "259949858",
      "cited_paper_id": 4612975
    },
    {
      "context_text": "Information extraction can be seen as a supervised task [37, 28, 32], a weakly-supervised task [10], or an unsupervised task [13, 2], the most common setting being supervised information extraction.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general categories of information extraction tasks. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.69552421569824,
      "citing_paper_id": "259949858",
      "cited_paper_id": 4612975
    },
    {
      "context_text": "Information extraction can be seen as a supervised task [37, 28, 32], a weakly-supervised task [10], or an unsupervised task [13, 2], the most common setting being supervised information extraction.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general categories of information extraction tasks. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.69552421569824,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "Information extraction can be seen as a supervised task [37, 28, 32], a weakly-supervised task [10], or an unsupervised task [13, 2], the most common setting being supervised information extraction.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general categories of information extraction tasks. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.69552421569824,
      "citing_paper_id": "259949858",
      "cited_paper_id": 252904978
    },
    {
      "context_text": "• Some are manually annotated (e.g., DocRED [36], FewRel [15] or HacRED [5]), others automatically generated such as T-REx [10] or NYT-10 [29].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "FewRel",
        "HacRED",
        "T-REx",
        "NYT-10"
      ],
      "dataset_descriptions": {
        "DocRED": "Manually annotated dataset used for document-level event extraction, specifically for evaluating document-level relation extraction performance.",
        "FewRel": "Manually annotated dataset used for few-shot relation classification, providing a benchmark for document-level event extraction systems.",
        "HacRED": "Manually annotated dataset designed for hierarchical relation extraction, used to evaluate complex document-level event structures.",
        "T-REx": "Automatically generated dataset aligning natural language with knowledge base triples, used for large-scale document-level event extraction.",
        "NYT-10": "Automatically generated dataset derived from New York Times articles, used for relation extraction and document-level event analysis."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets used for document-level event extraction, including manually annotated and automatically generated ones. T-REx is confirmed as a dataset through the cited paper title.",
      "processing_time": 62.298054695129395,
      "citing_paper_id": "259949858",
      "cited_paper_id": 4612975
    },
    {
      "context_text": "T-REx [10] Of the seven datasets, it is by far the largest, with around 4.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "T-REx"
      ],
      "dataset_descriptions": {
        "T-REx": "Used to align natural language with knowledge base triples, focusing on large-scale alignment and extraction of structured information from text."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'T-REx' as a dataset, which is part of a larger set of datasets. The title confirms it is a specific, verifiable dataset.",
      "processing_time": 57.20160102844238,
      "citing_paper_id": "259949858",
      "cited_paper_id": 4612975
    },
    {
      "context_text": ", using sentences and not documents), or automatically annotated [23, 37, 10, 12].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to other works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.334232807159424,
      "citing_paper_id": "259949858",
      "cited_paper_id": 4612975
    },
    {
      "context_text": ", using sentences and not documents), or automatically annotated [23, 37, 10, 12].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to other works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.334232807159424,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": ", DocRED [36], FewRel [15] or HacRED [5]), others automatically generated such as T-REx [10] or NYT-10 [29].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "FewRel",
        "HacRED",
        "T-REx",
        "NYT-10"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction, focusing on document-level relations and relations in document-level contexts.",
        "FewRel": "Used for few-shot relation classification, emphasizing the ability to generalize from limited labeled data.",
        "HacRED": "Used for document-level relation extraction, specifically designed to address challenges in real-world scenarios.",
        "T-REx": "Automatically generated dataset aligning natural language with knowledge base triples, used for relation extraction tasks.",
        "NYT-10": "Automatically generated dataset from New York Times articles, used for relation extraction and entity linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets by name, which are relevant to document-level relation extraction. Each dataset is used for training or evaluation in the context of relation extraction tasks.",
      "processing_time": 61.35828113555908,
      "citing_paper_id": "259949858",
      "cited_paper_id": 4612975
    },
    {
      "context_text": ", DocRED [36], FewRel [15] or HacRED [5]), others automatically generated such as T-REx [10] or NYT-10 [29].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "FewRel",
        "HacRED",
        "T-REx",
        "NYT-10"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction, focusing on document-level relations and relations in document-level contexts.",
        "FewRel": "Used for few-shot relation classification, emphasizing the ability to generalize from limited labeled data.",
        "HacRED": "Used for document-level relation extraction, specifically designed to address challenges in real-world scenarios.",
        "T-REx": "Automatically generated dataset aligning natural language with knowledge base triples, used for relation extraction tasks.",
        "NYT-10": "Automatically generated dataset from New York Times articles, used for relation extraction and entity linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets by name, which are relevant to document-level relation extraction. Each dataset is used for training or evaluation in the context of relation extraction tasks.",
      "processing_time": 61.35828113555908,
      "citing_paper_id": "259949858",
      "cited_paper_id": 53080736
    },
    {
      "context_text": ", DocRED [36], FewRel [15] or HacRED [5]), others automatically generated such as T-REx [10] or NYT-10 [29].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "FewRel",
        "HacRED",
        "T-REx",
        "NYT-10"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction, focusing on document-level relations and relations in document-level contexts.",
        "FewRel": "Used for few-shot relation classification, emphasizing the ability to generalize from limited labeled data.",
        "HacRED": "Used for document-level relation extraction, specifically designed to address challenges in real-world scenarios.",
        "T-REx": "Automatically generated dataset aligning natural language with knowledge base triples, used for relation extraction tasks.",
        "NYT-10": "Automatically generated dataset from New York Times articles, used for relation extraction and entity linking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions several datasets by name, which are relevant to document-level relation extraction. Each dataset is used for training or evaluation in the context of relation extraction tasks.",
      "processing_time": 61.35828113555908,
      "citing_paper_id": "259949858",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "FewRel [15, 12] - 1 397k 112k 2k 112k 0 56k 80 T-REx [10] 4 650.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "T-REx"
      ],
      "dataset_descriptions": {
        "FewRel": "Used for few-shot relation classification, evaluating models on a large-scale dataset of labeled instances, focusing on cross-document relations.",
        "T-REx": "Used to align natural language with knowledge base triples, providing a large-scale dataset for training and evaluation of alignment models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'FewRel' and 'T-REx', which are specific datasets. FewRel is a relation classification dataset, and T-REx is a dataset aligning natural language with knowledge base triples.",
      "processing_time": 58.75595688819885,
      "citing_paper_id": "259949858",
      "cited_paper_id": 4612975
    },
    {
      "context_text": "FewRel [15, 12] - 1 397k 112k 2k 112k 0 56k 80 T-REx [10] 4 650.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "T-REx"
      ],
      "dataset_descriptions": {
        "FewRel": "Used for few-shot relation classification, evaluating models on a large-scale dataset of labeled instances, focusing on cross-document relations.",
        "T-REx": "Used to align natural language with knowledge base triples, providing a large-scale dataset for training and evaluation of alignment models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'FewRel' and 'T-REx', which are specific datasets. FewRel is a relation classification dataset, and T-REx is a dataset aligning natural language with knowledge base triples.",
      "processing_time": 58.75595688819885,
      "citing_paper_id": "259949858",
      "cited_paper_id": 53080736
    },
    {
      "context_text": ", TREx [10], DocRED [36], or HacRED [5]), other on very specific domains (scientific literature for SciERC [20], biomedicine for FewRel 2.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TREx",
        "DocRED",
        "HacRED"
      ],
      "dataset_descriptions": {
        "TREx": "Used for aligning natural language with knowledge base triples, focusing on large-scale relation extraction tasks.",
        "DocRED": "Used for document-level relation extraction, specifically to evaluate models on complex, multi-sentence relations in scientific literature.",
        "HacRED": "Applied to document-level relation extraction in a specific domain, likely focusing on challenges unique to the HacRED dataset."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets by name, including TREx, DocRED, and HacRED. These are specific, verifiable datasets used in relation extraction tasks.",
      "processing_time": 59.36401629447937,
      "citing_paper_id": "259949858",
      "cited_paper_id": 4612975
    },
    {
      "context_text": ", TREx [10], DocRED [36], or HacRED [5]), other on very specific domains (scientific literature for SciERC [20], biomedicine for FewRel 2.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TREx",
        "DocRED",
        "HacRED"
      ],
      "dataset_descriptions": {
        "TREx": "Used for aligning natural language with knowledge base triples, focusing on large-scale relation extraction tasks.",
        "DocRED": "Used for document-level relation extraction, specifically to evaluate models on complex, multi-sentence relations in scientific literature.",
        "HacRED": "Applied to document-level relation extraction in a specific domain, likely focusing on challenges unique to the HacRED dataset."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets by name, including TREx, DocRED, and HacRED. These are specific, verifiable datasets used in relation extraction tasks.",
      "processing_time": 59.36401629447937,
      "citing_paper_id": "259949858",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "On this sample, we compute the Cohen’s kappa coefficient [7], and obtain",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a statistical measure (Cohen’s kappa coefficient).",
      "processing_time": 53.44945740699768,
      "citing_paper_id": "259949858",
      "cited_paper_id": 15926286
    },
    {
      "context_text": "This metric, among others, is recommended to evaluate coreference resolution models [27, 24, 37].",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics for coreference resolution models.",
      "processing_time": 53.12143540382385,
      "citing_paper_id": "259949858",
      "cited_paper_id": 17606580
    },
    {
      "context_text": "This metric is recommended to evaluate coreference resolution models [24, 27, 37].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric for evaluating coreference resolution models.",
      "processing_time": 53.20078706741333,
      "citing_paper_id": "259949858",
      "cited_paper_id": 18930466
    },
    {
      "context_text": "This model relies on BERT [8], which can only handle documents with at most 512 tokens.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset. It only refers to BERT, which is a model, not a dataset.",
      "processing_time": 53.67211294174194,
      "citing_paper_id": "259949858",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "As we have documents with more than 512 tokens, we propose to replace BERT with Longformer [3], which can encode documents up to 4 096 tokens, with only a marginal decrease in performance compared to BERT.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Longformer) and a comparison to another method (BERT).",
      "processing_time": 53.631916761398315,
      "citing_paper_id": "259949858",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "[38, 39, 37, 40, 6]), who often represent the knowledge explicitly as a graph, which can be processed with Graph Neural Networks (GNN) for inference; Zhou et al. [42] propose to use implicit knowledge representations produced with BERT, which results in a simple, efficient and effective model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. BERT is mentioned but it is a model, not a dataset.",
      "processing_time": 53.75542759895325,
      "citing_paper_id": "259949858",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "FewRel [15, 12] It is large-scale, diverse (it contains many different relation types), and annotated for the four tasks, but it does not contain documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel"
      ],
      "dataset_descriptions": {
        "FewRel": "Used for few-shot relation classification tasks, but lacks document-level annotations, highlighting a gap in current resources."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'FewRel' as a dataset used for few-shot relation classification tasks, but notes it lacks document-level annotations.",
      "processing_time": 55.52290153503418,
      "citing_paper_id": "259949858",
      "cited_paper_id": 53080736
    },
    {
      "context_text": ", FewRel [15, 12], or NYT10 [29]) others on documents (DocRED [36], KnowledgeNet [23], or DWIE [37]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "NYT10",
        "DocRED",
        "KnowledgeNet",
        "DWIE"
      ],
      "dataset_descriptions": {
        "FewRel": "Used to train models for few-shot relation classification, focusing on supervised learning with limited labeled data.",
        "NYT10": "Used to evaluate relation extraction models, focusing on document-level relations in news articles.",
        "DocRED": "Used to train and evaluate document-level relation extraction models, focusing on complex relations across sentences.",
        "KnowledgeNet": "Used to enhance document-level relation extraction, focusing on integrating external knowledge into the extraction process.",
        "DWIE": "Used to train and evaluate multi-task document-level information extraction models, focusing on entity-centric tasks."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets, including FewRel, NYT10, DocRED, KnowledgeNet, and DWIE. Based on the cited paper titles, FewRel, DocRED, and DWIE are confirmed as datasets.",
      "processing_time": 60.99067187309265,
      "citing_paper_id": "259949858",
      "cited_paper_id": 53080736
    },
    {
      "context_text": ", FewRel [15, 12], or NYT10 [29]) others on documents (DocRED [36], KnowledgeNet [23], or DWIE [37]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "NYT10",
        "DocRED",
        "KnowledgeNet",
        "DWIE"
      ],
      "dataset_descriptions": {
        "FewRel": "Used to train models for few-shot relation classification, focusing on supervised learning with limited labeled data.",
        "NYT10": "Used to evaluate relation extraction models, focusing on document-level relations in news articles.",
        "DocRED": "Used to train and evaluate document-level relation extraction models, focusing on complex relations across sentences.",
        "KnowledgeNet": "Used to enhance document-level relation extraction, focusing on integrating external knowledge into the extraction process.",
        "DWIE": "Used to train and evaluate multi-task document-level information extraction models, focusing on entity-centric tasks."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets, including FewRel, NYT10, DocRED, KnowledgeNet, and DWIE. Based on the cited paper titles, FewRel, DocRED, and DWIE are confirmed as datasets.",
      "processing_time": 60.99067187309265,
      "citing_paper_id": "259949858",
      "cited_paper_id": 189898081
    },
    {
      "context_text": ", FewRel [15, 12], or NYT10 [29]) others on documents (DocRED [36], KnowledgeNet [23], or DWIE [37]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "FewRel",
        "NYT10",
        "DocRED",
        "KnowledgeNet",
        "DWIE"
      ],
      "dataset_descriptions": {
        "FewRel": "Used to train models for few-shot relation classification, focusing on supervised learning with limited labeled data.",
        "NYT10": "Used to evaluate relation extraction models, focusing on document-level relations in news articles.",
        "DocRED": "Used to train and evaluate document-level relation extraction models, focusing on complex relations across sentences.",
        "KnowledgeNet": "Used to enhance document-level relation extraction, focusing on integrating external knowledge into the extraction process.",
        "DWIE": "Used to train and evaluate multi-task document-level information extraction models, focusing on entity-centric tasks."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets, including FewRel, NYT10, DocRED, KnowledgeNet, and DWIE. Based on the cited paper titles, FewRel, DocRED, and DWIE are confirmed as datasets.",
      "processing_time": 60.99067187309265,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "The resulting knowledge graph can then be used for multiple downstream tasks such as recommender systems [14], logical reasoning [4], or question answering [17].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of a knowledge graph.",
      "processing_time": 52.5950665473938,
      "citing_paper_id": "259949858",
      "cited_paper_id": 59528287
    },
    {
      "context_text": "[38, 39, 37, 40, 6]), who often represent the knowledge explicitly as a graph, which can be processed with Graph Neural Networks (GNN) for inference; Zhou et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches such as Graph Neural Networks (GNN) and knowledge graphs.",
      "processing_time": 53.30095720291138,
      "citing_paper_id": "259949858",
      "cited_paper_id": 67856607
    },
    {
      "context_text": "DocRED [36] and HacRED [5] They contain around two to five times more documents and annotations than the other manually annotated datasets, which makes them more suitable to train and evaluate IE pipelines.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "HacRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate document-level relation extraction pipelines, providing a large-scale dataset with extensive annotations.",
        "HacRED": "Used to train and evaluate document-level event extraction models, offering a substantial number of documents and annotations compared to other manually annotated datasets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions DocRED and HacRED as large-scale document-level relation extraction datasets, suitable for training and evaluating IE pipelines.",
      "processing_time": 57.16982960700989,
      "citing_paper_id": "259949858",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "At the same time, we notice that one existing dataset, DocRED [36], is almost adequate to train and evaluate an IE pipeline, except for the lack of entity-linking annotations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate an information extraction pipeline, focusing on document-level relation extraction, but lacking entity-linking annotations."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is mentioned as a specific dataset used for training and evaluating an IE pipeline, but it lacks entity-linking annotations.",
      "processing_time": 56.00541067123413,
      "citing_paper_id": "259949858",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "On the one hand, most datasets focus on NER, Coref, and RE, ignoring the last entity-linking step [36, 5].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.5,
      "reasoning": "The context mentions 'datasets' in general but does not specify any particular dataset name. The cited paper title 'DocRED' is a specific dataset, but it is not mentioned in the context.",
      "processing_time": 53.951958894729614,
      "citing_paper_id": "259949858",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "The most recent ones [36, 37, 23] focus on document-level information extraction, a more realistic, albeit more challenging scenario than sentencelevel IE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "DWIE"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate document-level relation extraction, focusing on complex document-level relations, employing document-level annotations for multi-hop reasoning.",
        "DWIE": "Applied to assess multi-task document-level information extraction, including entity linking and coreference resolution, enhancing comprehensive document understanding."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions 'document-level information extraction' which aligns with the cited papers. However, the context does not explicitly mention the names of the datasets. The titles of the cited papers are used to identify the datasets.",
      "processing_time": 57.8441264629364,
      "citing_paper_id": "259949858",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "The most recent ones [36, 37, 23] focus on document-level information extraction, a more realistic, albeit more challenging scenario than sentencelevel IE.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "DWIE"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to evaluate document-level relation extraction, focusing on complex document-level relations, employing document-level annotations for multi-hop reasoning.",
        "DWIE": "Applied to assess multi-task document-level information extraction, including entity linking and coreference resolution, enhancing comprehensive document understanding."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions 'document-level information extraction' which aligns with the cited papers. However, the context does not explicitly mention the names of the datasets. The titles of the cited papers are used to identify the datasets.",
      "processing_time": 57.8441264629364,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "Instead of creating a dataset from scratch, we enhance the widely-used DocRED dataset [36] (already labeled with entities, coreferences, and relations) by annotating each entity with entity-linking.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Enhanced for document-level relation extraction by adding entity-linking annotations to existing entity, coreference, and relation labels."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions enhancing the DocRED dataset, which is a specific, verifiable dataset used for document-level relation extraction.",
      "processing_time": 55.283628702163696,
      "citing_paper_id": "259949858",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "2k 1 141k 99k 9 19k 68k 26 DocRED [36] 5.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED"
      ],
      "dataset_descriptions": {
        "DocRED": "Used to train and evaluate document-level relation extraction models, focusing on complex relations across multiple sentences within documents."
      },
      "confidence_score": 1.0,
      "reasoning": "DocRED is a specific, verifiable dataset mentioned in the context. It is used for document-level relation extraction, which is relevant to the research topic.",
      "processing_time": 55.79465126991272,
      "citing_paper_id": "259949858",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "Information extraction can be seen as a supervised task [28, 32, 37], a weakly-supervised task [10], or an unsupervised task [2, 13], the most common setting being supervised information extraction.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general categories of information extraction tasks. No verifiable resources are identified.",
      "processing_time": 53.162994384765625,
      "citing_paper_id": "259949858",
      "cited_paper_id": 207169186
    },
    {
      "context_text": "LinkedDocRED contains four times more entities and two times more relations than its closest competitor DWIE [37].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LinkedDocRED",
        "DWIE"
      ],
      "dataset_descriptions": {
        "LinkedDocRED": "Used to compare the scale of entities and relations, evaluating the complexity and diversity of document-level information extraction tasks.",
        "DWIE": "Served as a benchmark for multi-task document-level information extraction, focusing on entity-centric tasks and used for comparative analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'LinkedDocRED' and 'DWIE' as datasets, with 'DWIE' being referenced as a competitor dataset. Both are specific, verifiable datasets relevant to document-level information extraction.",
      "processing_time": 57.47541522979736,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "• Some are manually annotated (e.g., DocRED [36], FewRel [15] or HacRED [5]), others automatically generated such as T-REx [10] or • Some focus on sentences (e.g., FewRel [15, 12], or NYT-10 [29]) others on documents (DocRED [36], Knowled-geNet [23], or DWIE [37]).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DocRED",
        "FewRel",
        "HacRED",
        "T-REx",
        "NYT-10",
        "NYT-10",
        "KnowledgeNet",
        "DWIE"
      ],
      "dataset_descriptions": {
        "DocRED": "Used for document-level relation extraction, focusing on complex relations within and across sentences.",
        "FewRel": "Used for few-shot relation classification, focusing on sentence-level relations with limited labeled data.",
        "HacRED": "Used for hierarchical relation extraction, focusing on nested and overlapping relations in documents.",
        "T-REx": "Automatically generated dataset for relation extraction, focusing on large-scale training with distant supervision.",
        "NYT-10": "Used for sentence-level relation extraction, focusing on relations in news articles.",
        "KnowledgeNet": "Used for document-level information extraction, focusing on entity-centric relations and multi-task learning.",
        "DWIE": "Used for multi-task document-level information extraction, focusing on entity-centric relations and complex document structures."
      },
      "confidence_score": 0.95,
      "reasoning": "The context mentions several datasets, including DocRED, FewRel, HacRED, T-REx, NYT-10, KnowledgeNet, and DWIE. These are all specific, verifiable datasets used in the field of information extraction.",
      "processing_time": 62.680506229400635,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "A similar observation was made by Prieur et al. [28] on the DWIE dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DWIE"
      ],
      "dataset_descriptions": {
        "DWIE": "Used to evaluate multi-task document-level information extraction, focusing on entity-centric tasks and their integration within a single document."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the DWIE dataset, which is a specific, verifiable dataset used for document-level information extraction. The title confirms it is a dataset.",
      "processing_time": 55.3336296081543,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "[37] by establishing a clear and coherent set of entity-centric metrics to evaluate the performance of an IE pipeline.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DWIE"
      ],
      "dataset_descriptions": {
        "DWIE": "Used to evaluate the performance of an entity-centric information extraction pipeline, focusing on multi-task document-level extraction tasks."
      },
      "confidence_score": 1.0,
      "reasoning": "The context does not mention any specific datasets, only a set of metrics for evaluating an IE pipeline. However, the cited paper title suggests a relevant dataset.",
      "processing_time": 55.176851749420166,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "As we have said in the introduction, we define information extraction as a four-step process with [28, 37]:",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context does not mention any specific datasets, only a general reference to a process. The cited paper title suggests a relevant dataset, but it is not explicitly mentioned in the context.",
      "processing_time": 53.70324754714966,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "Indeed, FewRel [15, 12] lacks documents and novel entities; T-REx [10] lacks manual annotations and novel entities; KnowledgeNet [23] and BC5CDR [19] are too small and not diverse enough; DWIE has automatic entity-linking annotations [37]; and HacRED [5], and DocRED [36] lack annotation for entity-linking.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DWIE"
      ],
      "dataset_descriptions": {
        "DWIE": "Used for multi-task document-level information extraction, specifically leveraging automatic entity-linking annotations to enhance document-level event extraction."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions several datasets but indicates their limitations rather than their usage. Only DWIE is described with a specific feature (automatic entity-linking annotations), which aligns with the research topic.",
      "processing_time": 55.601823568344116,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "5k 343k 10k 2 19k 10k 0 48k 1 DWIE [37] 0.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DWIE"
      ],
      "dataset_descriptions": {
        "DWIE": "Used for multi-task document-level information extraction, focusing on entity-centric tasks and evaluating the performance of information extraction models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DWIE' which is a specific dataset name as confirmed by the cited paper title. It is used for document-level information extraction.",
      "processing_time": 55.023086071014404,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "Similarly to [37, 28], we define IE as a four-step process with:",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to a process similar to other works.",
      "processing_time": 52.18654823303223,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "Linked-DocRED contains four times more entities and two times more relations than its closest competitor DWIE [37].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DWIE"
      ],
      "dataset_descriptions": {
        "DWIE": "Used to compare the scale and complexity of document-level event extraction, focusing on entity and relation extraction across multiple tasks."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'DWIE' as a dataset for document-level information extraction, which is relevant to the research topic. 'Linked-DocRED' is also mentioned but is not a dataset name in the context.",
      "processing_time": 55.33017158508301,
      "citing_paper_id": "259949858",
      "cited_paper_id": 221970808
    },
    {
      "context_text": "Recent papers often consider the ﬁrst three tasks [40, 38, 16, 20, 33, 31], setting entity-linking aside.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only tasks. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 52.37266397476196,
      "citing_paper_id": "259949858",
      "cited_paper_id": 243865630
    },
    {
      "context_text": "This pipeline is trained using the hyperparameter values proposed by the authors of PURE [41], NeuralCoref, and ATLOP [42].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 52.52410387992859,
      "citing_paper_id": "259949858",
      "cited_paper_id": 261317734
    },
    {
      "context_text": "We propose to use the simple yet eﬀective span-based NER proposed by Zhong and Chen [41, 33, 21] (PURE).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (PURE) for span-based NER. The cited paper title does not introduce a dataset either.",
      "processing_time": 52.76561522483826,
      "citing_paper_id": "259949858",
      "cited_paper_id": 261317734
    },
    {
      "context_text": "In the rest of the paper, we call this NER-Coref-RE ensemble PNA (for PURE [41], NeuralCoref, and ATLOP [42]).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is about naming an ensemble of models.",
      "processing_time": 52.220815896987915,
      "citing_paper_id": "259949858",
      "cited_paper_id": 261317734
    },
    {
      "context_text": "Similarly to previous works (e.g., Zhong and Chen [41]), we consider a predicted mention to be correct if its boundaries and type are the same as the ones of a ground truth mention.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating predicted mentions. No verifiable resources are identified.",
      "processing_time": 52.02254128456116,
      "citing_paper_id": "259949858",
      "cited_paper_id": 261317734
    },
    {
      "context_text": "As we have documents with more than 512 tokens, we pro-pose to replace BERT with Longformer [3], which can encode documents up to 4 096 tokens, with only a marginal decrease in performance compared to",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (Longformer) and a comparison to BERT. No verifiable resources are identified.",
      "processing_time": 52.48389005661011,
      "citing_paper_id": "259949858",
      "cited_paper_id": null
    },
    {
      "context_text": "To evaluate coreferences, we use the B3 metric [1], which is used to evaluate clustering.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the B3 metric, which is a scoring method, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 52.3249454498291,
      "citing_paper_id": "259949858",
      "cited_paper_id": null
    },
    {
      "context_text": "Traditional pipeline approaches (Riedel et al., 2010; Hoffmann et al., 2011; Zeng et al., 2014, 2015; Nayak and Ng, 2019; Jat et al., 2017) first identify entities followed by relation identification one entity pair at a time.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.35874700546265,
      "citing_paper_id": "263334323",
      "cited_paper_id": 2386383
    },
    {
      "context_text": "Traditional pipeline approaches (Riedel et al., 2010; Hoffmann et al., 2011; Zeng et al., 2014, 2015; Nayak and Ng, 2019; Jat et al., 2017) first identify entities followed by relation identification one entity pair at a time.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.35874700546265,
      "citing_paper_id": "263334323",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "Traditional pipeline approaches (Riedel et al., 2010; Hoffmann et al., 2011; Zeng et al., 2014, 2015; Nayak and Ng, 2019; Jat et al., 2017) first identify entities followed by relation identification one entity pair at a time.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.35874700546265,
      "citing_paper_id": "263334323",
      "cited_paper_id": 16483125
    },
    {
      "context_text": "Joint models for relation extraction outperform traditional pipeline models for sentence-level datasets such as NYT (Riedel et al., 2010).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "NYT"
      ],
      "dataset_descriptions": {
        "NYT": "Used to evaluate joint models for document-level event extraction, focusing on relation extraction performance compared to traditional pipeline models."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'NYT' which is likely referring to a dataset, but it does not provide enough context to determine if it is a specific, verifiable dataset. The title of the cited paper does not help in disambiguating this.",
      "processing_time": 55.011332750320435,
      "citing_paper_id": "263334323",
      "cited_paper_id": 2386383
    },
    {
      "context_text": "NYT (Riedel et al., 2010) is a large-scale and popular benchmark for sentence-level RE, and we use this dataset as it is for our sentence-level experiments.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "NYT"
      ],
      "dataset_descriptions": {
        "NYT": "Used for sentence-level relation extraction experiments, focusing on modeling relations and their mentions without labeled text."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'NYT' as a dataset used for sentence-level experiments. The title does not provide additional information to disambiguate the type.",
      "processing_time": 54.29607820510864,
      "citing_paper_id": "263334323",
      "cited_paper_id": 2386383
    },
    {
      "context_text": "Miwa and Bansal (2016) proposed a model that trained the NER and RC module in a single model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its components.",
      "processing_time": 51.34018611907959,
      "citing_paper_id": "263334323",
      "cited_paper_id": 2476229
    },
    {
      "context_text": "The second step, Relation Classification (RC), identifies pairwise relations between the extracted entities (Zeng et al., 2014, 2015; Jat et al., 2017; Nayak and Ng, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and research works.",
      "processing_time": 51.12607288360596,
      "citing_paper_id": "263334323",
      "cited_paper_id": 2778800
    },
    {
      "context_text": "Earlier works (Peng et al., 2021; Quirk and Poon, 2017; Song et al., 2018; Jia et al., 2019) used dependency graph be-tween the two entities to find the relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. The context focuses on the use of dependency graphs for relation extraction.",
      "processing_time": 51.624927043914795,
      "citing_paper_id": "263334323",
      "cited_paper_id": 52115592
    },
    {
      "context_text": "Parameter Settings: We use BERT BASE (cased) (Devlin et al., 2019) for document encoding for all the models except REBEL for which we have used BART BASE (Lewis et al., 2019).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT BASE and BART BASE, which are models, not datasets. No datasets are explicitly mentioned or used in the described research context.",
      "processing_time": 52.24242448806763,
      "citing_paper_id": "263334323",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Parameter Settings: We use BERTBASE (cased) (Devlin et al., 2019) for document encoding for all the models except REBEL for which we",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BERT). No datasets are referenced for training or evaluation.",
      "processing_time": 51.54620838165283,
      "citing_paper_id": "263334323",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In contrast, more recent joint approaches (Zeng et al., 2018; Takanobu et al., 2019; Nayak and Ng, 2020; Wei et al., 2020; Wang et al., 2020b; Zhong and Chen, 2021; Zheng et al., 2021; Li et al., 2021; Wei et al., 2020; Yan et al., 2021; Shang et al., 2022) not only identify entities and relations…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 52.00520992279053,
      "citing_paper_id": "263334323",
      "cited_paper_id": 53250562
    },
    {
      "context_text": "In contrast, more recent joint approaches (Zeng et al., 2018; Takanobu et al., 2019; Nayak and Ng, 2020; Wei et al., 2020; Wang et al., 2020b; Zhong and Chen, 2021; Zheng et al., 2021; Li et al., 2021; Wei et al., 2020; Yan et al., 2021; Shang et al., 2022) not only identify entities and relations…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 52.00520992279053,
      "citing_paper_id": "263334323",
      "cited_paper_id": 208248243
    },
    {
      "context_text": "More recent Transformer-based approaches (Wang et al., 2019; Tang et al., 2020; Huang et al., 2021; Xu et al., 2021a; Zhou et al., 2021; Xie et al., 2022)",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to Transformer-based approaches. No dataset names are present in the context.",
      "processing_time": 51.92612910270691,
      "citing_paper_id": "263334323",
      "cited_paper_id": 202889074
    },
    {
      "context_text": "More recent Transformer-based approaches (Wang et al., 2019; Tang et al., 2020; Huang et al., 2021; Xu et al., 2021a; Zhou et al., 2021; Xie et al., 2022)",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to Transformer-based approaches. No dataset names are present in the context.",
      "processing_time": 51.92612910270691,
      "citing_paper_id": "263334323",
      "cited_paper_id": 247291740
    },
    {
      "context_text": "PtrNet (Nayak and Ng, 2020) and REBEL (Huguet Cabot and Navigli, 2021) use the Seq2Seq approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models (PtrNet and REBEL) and their approach (Seq2Seq) but does not reference any specific datasets.",
      "processing_time": 51.92488360404968,
      "citing_paper_id": "263334323",
      "cited_paper_id": 208248243
    },
    {
      "context_text": "…by presenting triples as a sequence of text and uses special separator tokens, as markers, to achieve the linearization.. WordDecoder model of (Nayak and Ng, 2020) uses a similar approach using LSTMs whereas REBEL is a BART-based Seq2Seq model that utilizes the advantages of transformer model…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on describing the methodologies used in the cited papers.",
      "processing_time": 51.82971501350403,
      "citing_paper_id": "263334323",
      "cited_paper_id": 208248243
    },
    {
      "context_text": "Out of the 5 joint models, we see significantly higher drop in F1 score for OneRel and PtrNet than REBEL, GRTE, and BiRTE models.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance metrics.",
      "processing_time": 50.97577118873596,
      "citing_paper_id": "263334323",
      "cited_paper_id": 208248243
    },
    {
      "context_text": "We chose PtrNet (Nayak and Ng, 2020) and REBEL (Huguet Cabot and Navigli, 2021) as they used Seq2Seq model for this task.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (PtrNet and REBEL). The context focuses on the use of Seq2Seq models for joint entity and relation extraction.",
      "processing_time": 52.361082553863525,
      "citing_paper_id": "263334323",
      "cited_paper_id": 208248243
    },
    {
      "context_text": "A.1 Details of Joint Models A.1.1 PtrNet (Nayak and Ng, 2020) PtrNet utilizes a seq2seq approach along with the pointer network-based decoding for jointly extracting entities and relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (PtrNet) and its approach. No verifiable resources are identified.",
      "processing_time": 51.85606837272644,
      "citing_paper_id": "263334323",
      "cited_paper_id": 208248243
    },
    {
      "context_text": "Additionally, PtrNet extracts index positions for the entities.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (PtrNet) for extracting index positions of entities.",
      "processing_time": 51.31084585189819,
      "citing_paper_id": "263334323",
      "cited_paper_id": 208248243
    },
    {
      "context_text": "PtrNet and REBEL are Seq2Seq models which use a decoder to extract the triples, so they possibly need more training data to learn from longer document contexts.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their training requirements. No verifiable resources are identified.",
      "processing_time": 51.1079466342926,
      "citing_paper_id": "263334323",
      "cited_paper_id": 208248243
    },
    {
      "context_text": "Nayak and Ng (2020); Cabot and Navigli (2021) propose seq2seq models for extracting the triples in a sequence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only seq2seq models for triple extraction. No verifiable resources are identified.",
      "processing_time": 51.41620469093323,
      "citing_paper_id": "263334323",
      "cited_paper_id": 208248243
    },
    {
      "context_text": "Recent works (Guo et al., 2019; Nan et al., 2020; Wang et al., 2020a; Zeng et al., 2020, 2021; Xu et al., 2021c,b) proposed graph-based approaches that use advanced neural techniques to do multi-hop reasoning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only graph-based approaches and neural techniques for multi-hop reasoning. No verifiable resources are identified.",
      "processing_time": 51.688974380493164,
      "citing_paper_id": "263334323",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "Recent works (Guo et al., 2019; Nan et al., 2020; Wang et al., 2020a; Zeng et al., 2020, 2021; Xu et al., 2021c,b) proposed graph-based approaches that use advanced neural techniques to do multi-hop reasoning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only graph-based approaches and neural techniques for multi-hop reasoning. No verifiable resources are identified.",
      "processing_time": 51.688974380493164,
      "citing_paper_id": "263334323",
      "cited_paper_id": 235313883
    },
    {
      "context_text": "Zhang et al. (2017); Wang et al. (2020b, 2021); Shang et al. (2022) formulate the NER and RC tasks as table filling problem where each cell of the table represents the interaction between two tokens.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and formulations for NER and RC tasks.",
      "processing_time": 51.02068758010864,
      "citing_paper_id": "263334323",
      "cited_paper_id": 235790751
    },
    {
      "context_text": "Ren et al. (2022); Zheng et al. (2021); Li et al. (2021); Yan et al. (2021); Wei et al. (2020) have separate NER and RC modules in the same model trained in an end-to-end fashion.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing NER and RC modules. No verifiable resources are identified.",
      "processing_time": 51.466797828674316,
      "citing_paper_id": "263334323",
      "cited_paper_id": 237346893
    },
    {
      "context_text": "In contrast, more recent joint approaches (Zeng et al., 2018; Takanobu et al., 2019; Nayak and Ng, 2020; Wei et al., 2020; Wang et al., 2020b; Zhong and Chen, 2021; Zheng et al., 2021; Li et al., 2021; Wei et al., 2020; Yan et al., 2021; Shang et al., 2022) not only identify entities and relations for the same triple together but also extract all relational triples together.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets in the text.",
      "processing_time": 51.27758502960205,
      "citing_paper_id": "263334323",
      "cited_paper_id": 237346893
    },
    {
      "context_text": "…et al., 2019; Nayak and Ng, 2020; Wei et al., 2020; Wang et al., 2020b; Zhong and Chen, 2021; Zheng et al., 2021; Li et al., 2021; Wei et al., 2020; Yan et al., 2021; Shang et al., 2022) not only identify entities and relations for the same triple together but also extract all relational triples…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for joint entity and relation extraction.",
      "processing_time": 50.77061867713928,
      "citing_paper_id": "263334323",
      "cited_paper_id": 237346893
    },
    {
      "context_text": "OneRel (Shang et al., 2022) used table-filling method whereas BiRTE (Ren et al., 2022) and GRTE (Ren et al., 2021) used sequentially extracting entities and relations in their end-to-end model. with adaptive thresholding and localized context pooling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context focuses on comparing different approaches to relational triple extraction.",
      "processing_time": 51.277827501297,
      "citing_paper_id": "263334323",
      "cited_paper_id": 237507023
    },
    {
      "context_text": "The tagging approaches of BiRTE (Ren et al., 2022) and GRTE (Ren et al., 2021) have a separate entity extraction process in their end-to-end modeling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on tagging approaches and their processes, which are not considered datasets.",
      "processing_time": 51.45498824119568,
      "citing_paper_id": "263334323",
      "cited_paper_id": 237507023
    },
    {
      "context_text": "A.1.3 GRTE (Ren et al., 2021) GRTE utilizes individual tables for each relation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes a method (GRTE) and its usage of individual tables for each relation.",
      "processing_time": 51.45089936256409,
      "citing_paper_id": "263334323",
      "cited_paper_id": 237507023
    },
    {
      "context_text": "We use PL-Marker (Ye et al., 2022) as the NER module and KD-DocRE (Tan et al., 2022), SSAN (Xu et al., 2021a), and experiment with SAIS (Xiao et al., 2022) as relation classification models for our experiments, and train these for specific datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions specific models and methods but does not provide explicit names of datasets. The context focuses on the use of models for relation classification and NER, which are not considered datasets.",
      "processing_time": 51.79992198944092,
      "citing_paper_id": "263334323",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "A.2.2 KD-DocRE (Tan et al., 2022) This paper suggests a semi-supervised framework for extracting document-level relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or framework for document-level relation extraction.",
      "processing_time": 50.67095994949341,
      "citing_paper_id": "263334323",
      "cited_paper_id": 247594480
    },
    {
      "context_text": ", 2022) as the NER module and KD-DocRE (Tan et al., 2022), SSAN (Xu et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the given context.",
      "processing_time": 51.21754455566406,
      "citing_paper_id": "263334323",
      "cited_paper_id": 247594480
    },
    {
      "context_text": "One approach constructs a global information graph using structured attention, dependency structures, or heuristics [4][7-9], followed by the application of graph neural models for reasoning [10-11].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide additional dataset information.",
      "processing_time": 51.11320090293884,
      "citing_paper_id": "267044015",
      "cited_paper_id": 2797612
    },
    {
      "context_text": "One approach constructs a global information graph using structured attention, dependency structures, or heuristics [4][7-9], followed by the application of graph neural models for reasoning [10-11].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles also do not provide additional dataset information.",
      "processing_time": 51.11320090293884,
      "citing_paper_id": "267044015",
      "cited_paper_id": 190001673
    },
    {
      "context_text": "However, a significant portion of relations in mathematical problems span across multiple sentences [4-6].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about relations in mathematical problems.",
      "processing_time": 50.06301236152649,
      "citing_paper_id": "267044015",
      "cited_paper_id": 2797612
    },
    {
      "context_text": "Past research primarily focused on sentence-level relation extraction [1-3].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general area of research. No dataset names are present in the text.",
      "processing_time": 50.920937299728394,
      "citing_paper_id": "267044015",
      "cited_paper_id": 12873739
    },
    {
      "context_text": "We then employ a Transformer-based PLM [21] to encode the document D and generate contextual embeddings.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Transformer-based PLM). The cited paper title 'Attention is All you Need' confirms this is about a method, not a dataset.",
      "processing_time": 51.65729117393494,
      "citing_paper_id": "267044015",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "To address the challenges of manual data annotation in relation extraction tasks, distant supervision has become a widely used technique [14][19-20].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a technique called distant supervision. No verifiable resources are identified.",
      "processing_time": 50.51850366592407,
      "citing_paper_id": "267044015",
      "cited_paper_id": 15359942
    },
    {
      "context_text": "The logsumexp pooling technique is applied to obtain ℎ 𝑒 𝑖 , a method that has demonstrated effectiveness in prior research [22].",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 9 column 1 (char 396), response: ```json\n{\n    \"reasoning\": \"The citation does not mention any specific datasets, only a method (logs",
      "processing_time": 55.28072953224182,
      "citing_paper_id": "267044015",
      "cited_paper_id": 102353905
    },
    {
      "context_text": "Furthermore, Xiao [17] developed a neural classifier for automatic evidence retrieval in conjunction with RE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evidence retrieval in relation extraction.",
      "processing_time": 50.39068102836609,
      "citing_paper_id": "267044015",
      "cited_paper_id": 237635295
    },
    {
      "context_text": "In this work, the temperature T is selected by minimizing the Expected Calibration Error (ECE) (Pakdaman Naeini et al., 2015) on the validation set, and we denote the temperature with the lowest ECE as T ′ .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for selecting the temperature T using the Expected Calibration Error (ECE).",
      "processing_time": 50.71448755264282,
      "citing_paper_id": "264452034",
      "cited_paper_id": 6292807
    },
    {
      "context_text": "In this work, the temperature T is selected by minimizing the Expected Calibration Error (ECE) (Pakdaman Naeini et al., 2015) on the validation set, and we denote the temperature with the lowest ECE as T ′ .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for selecting the temperature T using the Expected Calibration Error (ECE).",
      "processing_time": 50.71448755264282,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "We evaluate our framework on W IKI E VENTS (Li et al., 2021) as it annotates all the events in a document (averagely 16 events per document), while existing document-level datasets such as DocEE (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) only annotate at most 3 events per document.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKI EVENTS",
        "DocEE",
        "RAMS",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "WIKI EVENTS": "Used to evaluate a framework for document-level event extraction, focusing on its ability to handle multiple events per document (averagely 16 events).",
        "DocEE": "Used for comparison, focusing on fewer events per document (at most 3 events).",
        "RAMS": "Used for comparison, focusing on fewer events per document (at most 3 events).",
        "MUC-4": "Used for comparison, focusing on fewer events per document (at most 3 events)."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific datasets used for evaluating a framework for document-level event extraction. WIKI EVENTS is highlighted for its comprehensive annotation of events, while other datasets are mentioned for comparison.",
      "processing_time": 56.28909516334534,
      "citing_paper_id": "264452034",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "We focus on document-level IAE (Li et al., 2021) (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) that only annotate at most 3 events per document, W IKI E VENTS annotates all the events in a document, with an average of 16 events per document.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Expecting ',' delimiter: line 7 column 25 (char 348), response: ```json\n{\n    \"reasoning\": \"The context mentions several datasets by name, including MUC-4 and WIKI ",
      "processing_time": 54.45341920852661,
      "citing_paper_id": "264452034",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "We focus on document-level IAE (Li et al., 2021) (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) that only annotate at most 3 events per document, W IKI E VENTS annotates all the events in a document, with an average of 16 events per document.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Expecting ',' delimiter: line 7 column 25 (char 348), response: ```json\n{\n    \"reasoning\": \"The context mentions several datasets by name, including MUC-4 and WIKI ",
      "processing_time": 54.45341920852661,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "…framework on W IKI E VENTS (Li et al., 2021) as it annotates all the events in a document (averagely 16 events per document), while existing document-level datasets such as DocEE (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) only annotate at most 3 events per document.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WIKI EVENTS",
        "DocEE",
        "RAMS",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "WIKI C-III": "Used to train and evaluate a framework that annotates all events in a document, averaging 16 events per document, making it suitable for comprehensive document-level event extraction.",
        "DocEE": "Used to compare against WIKI EVENTS, this dataset annotates fewer events per document (at most 3), highlighting the difference in annotation density.",
        "RAMS": "Used to compare against WIKI EVENTS, this dataset also annotates fewer events per document (at most 3), emphasizing the need for more comprehensive annotations.",
        "MUC-4": "Used to compare against WIKI EVENTS, this older dataset annotates fewer events per document (at most 3), providing a historical benchmark for document-level event extraction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions multiple datasets used for document-level event extraction, providing specific details about their usage and characteristics.",
      "processing_time": 57.488365173339844,
      "citing_paper_id": "264452034",
      "cited_paper_id": 9946972
    },
    {
      "context_text": "1 Introduction Document-level Event Argument Extraction (EAE) aims at identifying the participants of multiple events from a document and classifying them into proper roles (Li et al., 2021; Du et al., 2022; Xu et al., 2022; Huang et al., 2022; Yang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 50.828606367111206,
      "citing_paper_id": "264452034",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "1 Introduction Document-level Event Argument Extraction (EAE) aims at identifying the participants of multiple events from a document and classifying them into proper roles (Li et al., 2021; Du et al., 2022; Xu et al., 2022; Huang et al., 2022; Yang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 50.828606367111206,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "1 Introduction Document-level Event Argument Extraction (EAE) aims at identifying the participants of multiple events from a document and classifying them into proper roles (Li et al., 2021; Du et al., 2022; Xu et al., 2022; Huang et al., 2022; Yang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 50.828606367111206,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "1 Introduction Document-level Event Argument Extraction (EAE) aims at identifying the participants of multiple events from a document and classifying them into proper roles (Li et al., 2021; Du et al., 2022; Xu et al., 2022; Huang et al., 2022; Yang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 50.828606367111206,
      "citing_paper_id": "264452034",
      "cited_paper_id": 258967387
    },
    {
      "context_text": "Also, it provides complete coreference annotation for evaluating document-level IAE. Recently, generation-based methods have been proposed for document-level EAE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general concepts like 'document-level IAE' and 'document-level EAE'. No verifiable resource names are present.",
      "processing_time": 50.87860321998596,
      "citing_paper_id": "264452034",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "Also, it provides complete coreference annotation for evaluating document-level IAE. Recently, generation-based methods have been proposed for document-level EAE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general concepts like 'document-level IAE' and 'document-level EAE'. No verifiable resource names are present.",
      "processing_time": 50.87860321998596,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Generation-based document-level EAE methods are widely used in recent works (Li et al., 2021; Du et al., 2022; Du and Ji, 2022; Huang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event argument extraction.",
      "processing_time": 50.25222659111023,
      "citing_paper_id": "264452034",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "Generation-based document-level EAE methods are widely used in recent works (Li et al., 2021; Du et al., 2022; Du and Ji, 2022; Huang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event argument extraction.",
      "processing_time": 50.25222659111023,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Generation-based document-level EAE methods are widely used in recent works (Li et al., 2021; Du et al., 2022; Du and Ji, 2022; Huang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event argument extraction.",
      "processing_time": 50.25222659111023,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "Generation-based document-level EAE methods are widely used in recent works (Li et al., 2021; Du et al., 2022; Du and Ji, 2022; Huang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches in document-level event argument extraction.",
      "processing_time": 50.25222659111023,
      "citing_paper_id": "264452034",
      "cited_paper_id": 253510351
    },
    {
      "context_text": "Unlike sentence-level EAE (Li et al., 2014; Du and Cardie, 2020; Xiangyu et al., 2021 and their participants usually spread across the document in document-level EAE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses the difference between sentence-level and document-level event argument extraction.",
      "processing_time": 50.30489492416382,
      "citing_paper_id": "264452034",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "Unlike sentence-level EAE (Li et al., 2014; Du and Cardie, 2020; Xiangyu et al., 2021 and their participants usually spread across the document in document-level EAE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses the difference between sentence-level and document-level event argument extraction.",
      "processing_time": 50.30489492416382,
      "citing_paper_id": "264452034",
      "cited_paper_id": 235694418
    },
    {
      "context_text": "Further, Du et al. (2022); Du and Ji (2022) introduced the idea of “memory” to document-level EAE, where predictions of already predicted events were utilized as additional input.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of 'memory' in document-level event argument extraction (EAE).",
      "processing_time": 50.47752141952515,
      "citing_paper_id": "264452034",
      "cited_paper_id": 15552794
    },
    {
      "context_text": "Further, Du et al. (2022); Du and Ji (2022) introduced the idea of “memory” to document-level EAE, where predictions of already predicted events were utilized as additional input.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of 'memory' in document-level event argument extraction (EAE).",
      "processing_time": 50.47752141952515,
      "citing_paper_id": "264452034",
      "cited_paper_id": 253510351
    },
    {
      "context_text": "Due to its low time overhead and low ECE property, we adopt it in our work.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a property of a method or model.",
      "processing_time": 49.93118739128113,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "Specifically, we adopt temperature scaling (Guo et al., 2017; Desai and Durrett, 2020), a simple and effective method for calibration.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions temperature scaling as a method for calibration, but does not refer to any specific dataset. The cited papers are about calibration methods, not datasets.",
      "processing_time": 50.525750398635864,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "Specifically, we adopt temperature scaling (Guo et al., 2017; Desai and Durrett, 2020), a simple and effective method for calibration.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions temperature scaling as a method for calibration, but does not refer to any specific dataset. The cited papers are about calibration methods, not datasets.",
      "processing_time": 50.525750398635864,
      "citing_paper_id": "264452034",
      "cited_paper_id": 212747810
    },
    {
      "context_text": "Modern DNNs are prone to over-confidence, which implies that the model’s confidence is not reliable (Guo et al., 2017).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue with modern neural networks.",
      "processing_time": 49.82428288459778,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "Among modern calibration approaches, temperature scaling is a simple and effective method (Desai and Durrett, 2020) which can produce low ECE (Guo et al., 2017; Chen et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and findings related to model calibration.",
      "processing_time": 49.87965130805969,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "Among modern calibration approaches, temperature scaling is a simple and effective method (Desai and Durrett, 2020) which can produce low ECE (Guo et al., 2017; Chen et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and findings related to model calibration.",
      "processing_time": 49.87965130805969,
      "citing_paper_id": "264452034",
      "cited_paper_id": 212747810
    },
    {
      "context_text": "However, some studies reveal that current Deep Neural Networks (DNNs) are prone to over-confidence , which implies that the model’s confidence is not reliable (Guo et al., 2017).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue with DNNs. No dataset names are present in the citation context.",
      "processing_time": 50.40647053718567,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "Other works focus on methods such as label smoothing (Pereyra et al., 2017) and data augmentation (Hendrycks* et al., 2020), but these methods cannot produce as low ECE as temperature scaling (Chen et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and their comparative performance.",
      "processing_time": 49.81544470787048,
      "citing_paper_id": "264452034",
      "cited_paper_id": 28671436
    },
    {
      "context_text": "We compare our framework with a series of competitive baselines: (1) BERT-CRF (Shi and Lin, 2019), a simple BERT-based model without incorporating lexical or syntactic features for argument identification and classification.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (BERT-CRF). The context focuses on comparing a framework with a baseline model, not on using a dataset.",
      "processing_time": 50.8376784324646,
      "citing_paper_id": "264452034",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "• All models augmented with retrieval (i.e., w/ M) perform better compared with BERT-CRF and raw BART-Gen, showing the importance of modeling inter-event dependencies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance. There are no clear identifiers for datasets in the text.",
      "processing_time": 50.28432822227478,
      "citing_paper_id": "264452034",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Here, we plot the process of predicting the arguments of E 2 . similarity between E i ’s context c i and each prediction in m using S-BERT (Reimers and Gurevych, 2019) embeddings, and select the prediction with the highest score as additional input to help the prediction of E i : where SBERT() denotes S-BERT encoding, m Ri denotes the retrieved prediction that E i relies on.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of S-BERT embeddings for a prediction task. S-BERT is a method, not a dataset.",
      "processing_time": 50.83391046524048,
      "citing_paper_id": "264452034",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "Here, we plot the process of predicting the arguments of E 2 . similarity between E i ’s context c i and each prediction in m using S-BERT (Reimers and Gurevych, 2019) embeddings, and select the prediction with the highest score as additional input to help the prediction of E i : where SBERT()…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions S-BERT but does not refer to it as a dataset. It is used as a method for generating sentence embeddings.",
      "processing_time": 50.396655559539795,
      "citing_paper_id": "264452034",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "Studies on the calibration of natural language models have been drawing attention recently (Desai and Durrett, 2020; Park and Caragea, 2022; Kim et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies on the calibration of natural language models. No verifiable resources are identified.",
      "processing_time": 50.35246658325195,
      "citing_paper_id": "264452034",
      "cited_paper_id": 212747810
    },
    {
      "context_text": "Studies on the calibration of natural language models have been drawing attention recently (Desai and Durrett, 2020; Park and Caragea, 2022; Kim et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies on the calibration of natural language models. No verifiable resources are identified.",
      "processing_time": 50.35246658325195,
      "citing_paper_id": "264452034",
      "cited_paper_id": 247450599
    },
    {
      "context_text": "We formulate document-level IAE as a generative template-filling task following Li et al. (2021) and Du et al. (2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods or approaches in other papers.",
      "processing_time": 49.83493971824646,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We formulate document-level IAE as a generative template-filling task following Li et al. (2021) and Du et al. (2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to methods or approaches in other papers.",
      "processing_time": 49.83493971824646,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "(2) BART-Gen (Li et al., 2021), a conditional neural text generation model that generates a filled template for each event given the event template and context words.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a model (BART-Gen) rather than a dataset. No specific dataset is referenced in the citation context.",
      "processing_time": 50.181296586990356,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "From the results, we can conclude that: • Our S2C-CD model outperforms all previous methods on W IKI E VENTS as to document-level IAE, with an average gain of 1.4% in F1 on all four settings.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 11 column 1 (char 573), response: ```json\n{\n    \"reasoning\": \"The context mentions 'W IKI E VENTS' as a dataset used to evaluate the p",
      "processing_time": 59.715309381484985,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Following previous studies on document-level IAE (Li et al., 2021; Du et al., 2022), we adopt Head Word Match (Head F1) (Huang and Riloff, 2021) and Coreferential Match (Coref F1) (Ji and Grish-man, 2008) to judge whether the predicted argu-ment span matches the gold argument span.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics (Head F1 and Coref F1). These metrics are not considered datasets.",
      "processing_time": 50.44890522956848,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Following previous studies on document-level IAE (Li et al., 2021; Du et al., 2022), we adopt Head Word Match (Head F1) (Huang and Riloff, 2021) and Coreferential Match (Coref F1) (Ji and Grish-man, 2008) to judge whether the predicted argu-ment span matches the gold argument span.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics (Head F1 and Coref F1). These metrics are not considered datasets.",
      "processing_time": 50.44890522956848,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "First, we introduce our memory-enhanced IAE model (Section 3.1).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a model. There are no verifiable resources or datasets mentioned.",
      "processing_time": 50.056055545806885,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "The main results for document-level IAE are presented in Table 2.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the presentation of results. No dataset names are provided in the context.",
      "processing_time": 49.96409034729004,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We evaluate our framework on W IKI E VENTS (Li et al., 2021) as it annotates all the events in a document (averagely 16 events per document), while existing document-level datasets such as DocEE (Tong et al., 2022), RAMS (Ebner et al., 2020) and MUC-4 (Sundheim, 1992) only annotate at most 3 events…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "W IKI E VENTS",
        "DocEE",
        "RAMS",
        "MUC-4"
      ],
      "dataset_descriptions": {
        "MIMIC-III": "Not mentioned in the given context, hence not included.",
        "W IKI E VENTS": "Used to evaluate the framework on document-level event extraction, focusing on comprehensive event annotation (averagely 16 events per document).",
        "DocEE": "Used as a comparative dataset, which annotates fewer events (at most 3) compared to W IKI E VENTS.",
        "RAMS": "Used as a comparative dataset, which annotates fewer events (at most 3) compared to W IKI E VENTS.",
        "MUC-4": "Used as a comparative dataset, which annotates fewer events (at most 3) compared to W IKI E VENTS."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific datasets used for evaluating a framework on document-level event extraction, with clear identifiers and usage details.",
      "processing_time": 56.70388674736023,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We conduct experiments on a widely used benchmark W IKI E VENTS (Li et al., 2021), and our proposed simple-to-complex framework outperforms the previous SOTA by 1.4% in F1, illustrating the effectiveness of our method.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "W IKI E VENTS"
      ],
      "dataset_descriptions": {
        "W IKI-III": "Used to evaluate the proposed simple-to-complex framework for document-level event extraction, demonstrating a 1.4% improvement in F1 score over the previous state-of-the-art."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'W IKI E VENTS' as a benchmark used for experiments. It is a specific dataset used for document-level event extraction, which aligns with the research topic.",
      "processing_time": 52.73651719093323,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Our memory-enhanced IAE model is based on a generative model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a generative model. No dataset names are present in the context.",
      "processing_time": 50.00776791572571,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Also, it provides complete coreference annotation for document-level IAE.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset names, only a general reference to 'complete coreference annotation'. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 50.7649462223053,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Among them, one line of studies (Li et al., 2021; Huang et al., 2022) treats each event independently and ignores the underlying correlations between events in real-world documents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No dataset names are present in the citation span.",
      "processing_time": 49.83203649520874,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "We calculate the cosine Figure 1: Our simple-to-complex progressive framework for document-level IAE.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a figure and a methodological framework.",
      "processing_time": 49.482532262802124,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "It is the SOTA model on document-level IAE, but still extracts events according to their appearance order in the document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model's performance on a task. No verifiable resources are identified.",
      "processing_time": 49.88008666038513,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Retrieval-Augmented Generation In the input stage (both for training and testing), we augment our model with similarity-based retrieval following Du et al. (2022) to make it capable of finding argument mentions beyond the context of an event, especially informative ones (Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the use of retrieval-augmented generation and conditional generation for event argument extraction.",
      "processing_time": 50.36421275138855,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "In this work, we focus on document-level Informa-tive Argument Extraction 1 (IAE) (Li et al., 2021), where informative arguments are far more distant than local/uninformative ones and provide more useful information about an event.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a research focus on document-level Informative Argument Extraction. No clear, verifiable datasets are identified.",
      "processing_time": 50.147462129592896,
      "citing_paper_id": "264452034",
      "cited_paper_id": 233219850
    },
    {
      "context_text": "Constrained Decoding In the output stage, we introduce argument pair constraints following Du et al. (2022) to constrain the decoding of arguments with conflicting roles.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for constraining argument pairs during decoding.",
      "processing_time": 49.32274079322815,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "Among them, template generation-based approaches (Li et al., 2021; Huang et al., 2022; Du et al., 2022) are widely utilized.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods or approaches. There are no clear identifiers for datasets in the text.",
      "processing_time": 49.715052127838135,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "In this section, we first compare our bounded constraints with those presented in Du et al. (2022), then analyze the impact of the lower and upper bounds individually.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of methods and analysis of bounds.",
      "processing_time": 49.0765221118927,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "Other works (Du et al., 2022; Du and Ji, 2022) start to consider inter-event dependencies and model them by introducing the idea of “memory”, where event predictions (e.g., arguments, roles) are cached and can be retrieved to help the prediction of the upcoming events in a document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of using memory to model inter-event dependencies. No verifiable resources are identified.",
      "processing_time": 49.645745277404785,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "Other works (Du et al., 2022; Du and Ji, 2022) start to consider inter-event dependencies and model them by introducing the idea of “memory”, where event predictions (e.g., arguments, roles) are cached and can be retrieved to help the prediction of the upcoming events in a document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of using memory to model inter-event dependencies. No verifiable resources are identified.",
      "processing_time": 49.645745277404785,
      "citing_paper_id": "264452034",
      "cited_paper_id": 253510351
    },
    {
      "context_text": "However, once an incorrect prediction is used to constrain another, it may cause more errors (Du et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or finding related to error propagation in predictions.",
      "processing_time": 49.3112108707428,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "In Table 5, we observe that when applying the original constraints (Du et al., 2022 performs only comparably with our S2C model.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between models. No verifiable resources are identified.",
      "processing_time": 49.36602592468262,
      "citing_paper_id": "264452034",
      "cited_paper_id": 248780117
    },
    {
      "context_text": "In sentence-level synthetic data, there exists merely one relation triplet within a sentence.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general observation about synthetic data. No clear identifiers or specific resources are mentioned.",
      "processing_time": 49.303887367248535,
      "citing_paper_id": "267200174",
      "cited_paper_id": 793385
    },
    {
      "context_text": "Next, we construct cross-document knowledge graphs according to the pseudo labels and original labels of synthetic data.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 9 column 1 (char 315), response: ```json\n{\n    \"reasoning\": \"The context does not mention any specific, verifiable datasets. It only ",
      "processing_time": 53.1452202796936,
      "citing_paper_id": "267200174",
      "cited_paper_id": 793385
    },
    {
      "context_text": "Next, we construct cross-document knowledge graphs according to the pseudo labels and original labels of synthetic data.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 9 column 1 (char 315), response: ```json\n{\n    \"reasoning\": \"The context does not mention any specific, verifiable datasets. It only ",
      "processing_time": 53.1452202796936,
      "citing_paper_id": "267200174",
      "cited_paper_id": 53607073
    },
    {
      "context_text": "Next, we construct cross-document knowledge graphs according to the pseudo labels and original labels of synthetic data.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 9 column 1 (char 315), response: ```json\n{\n    \"reasoning\": \"The context does not mention any specific, verifiable datasets. It only ",
      "processing_time": 53.1452202796936,
      "citing_paper_id": "267200174",
      "cited_paper_id": 233210556
    },
    {
      "context_text": "Next, we construct cross-document knowledge graphs according to the pseudo labels and original labels of synthetic data.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 9 column 1 (char 315), response: ```json\n{\n    \"reasoning\": \"The context does not mention any specific, verifiable datasets. It only ",
      "processing_time": 53.1452202796936,
      "citing_paper_id": "267200174",
      "cited_paper_id": 259108325
    },
    {
      "context_text": ": [{\" head entity \": \"The Godfather\", \" tail entity \": \"Mario Puzo\", \" relation type \": \"screenwriter\", \" reasoning explanation \": \"Mario Puzo was another co-writer of the screenplay for …\", \" index of supporting sentence \": 2 }, … ]} Figure 4: A sample of the proposed chain-of-retrieval.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a sample output of a tagging scheme. No verifiable resources are identified.",
      "processing_time": 49.35826635360718,
      "citing_paper_id": "267200174",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "The Godfather 7, we can observe that the performance of different unseen relation types significantly improves with the denoised synthetic data on both Re-DocRED and DocRED datasets.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 11 column 1 (char 508), response: ```json\n{\n    \"reasoning\": \"The context mentions 'Re-DocRED' and 'DocRED' as specific datasets used ",
      "processing_time": 58.36023163795471,
      "citing_paper_id": "267200174",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "It can be observed that our GenRDK is able to reduce label noises in synthetic data by 1) Adding correct relational facts by the cross-document knowledge graph, such as the triplets (The Godfather, Francis Ford Coppola, screenwriter) and (Michael Jordan, Chicago Bulls, member of sports team) ; 2) Reducing the false relational facts by the consistency of knowledge, such as the triplet (Michael Jordan, National Basketball Association, member of sports team) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes the functionality of GenRDK in reducing label noise in synthetic data, which is not a specific dataset.",
      "processing_time": 49.870009660720825,
      "citing_paper_id": "267200174",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "Although previous approaches (b) Document-level Generation [1]The Godfatherisa1972AmericanfilmdirectedbyFrancis Ford Coppola.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific, verifiable datasets. It mentions 'Document-level Generation' which is likely a method or approach, not a dataset.",
      "processing_time": 49.26804041862488,
      "citing_paper_id": "267200174",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "Although previous approaches (b) Document-level Generation [1]The Godfatherisa1972AmericanfilmdirectedbyFrancis Ford Coppola.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific, verifiable datasets. It mentions 'Document-level Generation' which is likely a method or approach, not a dataset.",
      "processing_time": 49.26804041862488,
      "citing_paper_id": "267200174",
      "cited_paper_id": 53250562
    },
    {
      "context_text": "As shown in Table 4, it can be observed that all backbone models [1] The Godfather is a 1972 American film directed by Francis Ford Coppola.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, and the context is about a film, which is unrelated to document-level event extraction.",
      "processing_time": 48.75301790237427,
      "citing_paper_id": "267200174",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "One is reducing the incorrect triplet as shown in the red dotted line (The Godfather, Vito Corleone, cast member) , and another is adding the missing triplet as shown in the green solid line (The Godfather, Francis Ford Coppola, screenwriter) .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only examples of triplets. No clear identifiers for datasets are present.",
      "processing_time": 48.63696837425232,
      "citing_paper_id": "267200174",
      "cited_paper_id": 11751039
    },
    {
      "context_text": ":[{“ entity ”: “The Godfather” “ entity type ”: “Miscellaneous”}, {“ entity ”: “Francis Ford Coppola” “ entity type ”: “Person”}, {“ entity ”: “Mario Puzo” “ entity type ”: “Person”}, {“ entity ”: “Marlon Brando” “ entity type ”: “Person”}, {“ entity ”: “Al Pacino” “ entity type ”: “Person”}, {“ entity ”: “James Caan” “ entity type ”: “Person”},",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not contain any specific, verifiable datasets. It lists entities and persons related to 'The Godfather' film, which are not datasets.",
      "processing_time": 48.911566972732544,
      "citing_paper_id": "267200174",
      "cited_paper_id": 11751039
    },
    {
      "context_text": "In the case of document-level synthetic data, there are more than 22 relation triplets distributed across different sentences.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to synthetic data in a general sense without naming a specific dataset.",
      "processing_time": 48.90723657608032,
      "citing_paper_id": "267200174",
      "cited_paper_id": 53607073
    },
    {
      "context_text": "The main contributions of our work are summarized as follows: • We explore [12, 14, 31, 38] and the graph-based [3, 7, 18, 20, 24, 27, 28, 32, 33] models to extract contextual and non-local structural information for aggregating entity representations [12, 14, 31, 38].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 48.957160234451294,
      "citing_paper_id": "267200174",
      "cited_paper_id": 221996144
    },
    {
      "context_text": "The main contributions of our work are summarized as follows: • We explore [12, 14, 31, 38] and the graph-based [3, 7, 18, 20, 24, 27, 28, 32, 33] models to extract contextual and non-local structural information for aggregating entity representations [12, 14, 31, 38].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 48.957160234451294,
      "citing_paper_id": "267200174",
      "cited_paper_id": 225039888
    },
    {
      "context_text": "The main contributions of our work are summarized as follows: • We explore [12, 14, 31, 38] and the graph-based [3, 7, 18, 20, 24, 27, 28, 32, 33] models to extract contextual and non-local structural information for aggregating entity representations [12, 14, 31, 38].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 48.957160234451294,
      "citing_paper_id": "267200174",
      "cited_paper_id": 235313469
    },
    {
      "context_text": "We present extensive experimental results of different popular DocRE backbone models [30, 38] trained on original and denoised synthetic data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'original and denoised synthetic data' but does not provide specific, identifiable dataset names. The terms are too generic and do not meet the criteria for inclusion.",
      "processing_time": 49.380223989486694,
      "citing_paper_id": "267200174",
      "cited_paper_id": 225039888
    },
    {
      "context_text": "[2]ThescreenplaywaswrittenbyCoppolaandMario Puzo,basedonPuzo‘sbest-sell… [3]ThefilmstarsMarlon BrandoasthepatriarchoftheCorleonefamily,withAl Pacino,James Caan,Richard S .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The provided context does not contain any specific, verifiable datasets or resources. It appears to be a fragment of text about a film, which is irrelevant to the topic of document-level event extraction.",
      "processing_time": 49.45924997329712,
      "citing_paper_id": "267200174",
      "cited_paper_id": 233210556
    },
    {
      "context_text": "[2]ThescreenplaywaswrittenbyCoppolaandMario Puzo,basedonPuzo‘sbest-sell… [3]ThefilmstarsMarlon BrandoasthepatriarchoftheCorleonefamily,withAl Pacino,James Caan,Richard S .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The provided context does not contain any specific, verifiable datasets or resources. It appears to be a fragment of text about a film, which is irrelevant to the topic of document-level event extraction.",
      "processing_time": 49.45924997329712,
      "citing_paper_id": "267200174",
      "cited_paper_id": 259108325
    },
    {
      "context_text": "However, synthetic data for document-level relation triplet extraction usually contain complex semantic structures and various relation triplets.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to synthetic data in a general sense without naming any particular dataset.",
      "processing_time": 48.73172903060913,
      "citing_paper_id": "267200174",
      "cited_paper_id": 238583580
    },
    {
      "context_text": "Relation Triplet Extraction (RTE) aims to extract the entity pair and the semantic relation type from the unstructured text, which plays a vital role in various downstream Natural Language Processing (NLP) applications, including knowledge graph construction and information retrieval [15, 22, 29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of Relation Triplet Extraction (RTE) and its applications.",
      "processing_time": 48.5584557056427,
      "citing_paper_id": "267200174",
      "cited_paper_id": 246897443
    },
    {
      "context_text": "We consider an argument span to be correctly identiﬁed if its offsets match any of the gold/reference informative arguments of the current event (i.e., argument identiﬁcation); and it is correctly classiﬁed if its semantic role also matches (i.e., argument classiﬁcation) (Li et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses evaluation criteria for argument identification and classification.",
      "processing_time": 48.22494029998779,
      "citing_paper_id": "248780117",
      "cited_paper_id": 2114517
    },
    {
      "context_text": "Apart from event extraction, in the future, it’s worth investigating how to leverage the global memory idea for other document-level IE problems like (N ary) relation extraction (Quirk and Poon, 2017; Yao et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only future research directions and related work.",
      "processing_time": 47.876179695129395,
      "citing_paper_id": "248780117",
      "cited_paper_id": 15359942
    },
    {
      "context_text": ", 2021) and ignores the global context partially because of the pretrained models’ length limit and their lack of attention for distant context (Khandelwal et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses limitations of pretrained models.",
      "processing_time": 48.10551047325134,
      "citing_paper_id": "248780117",
      "cited_paper_id": 21700944
    },
    {
      "context_text": "(Shi and Lin, 2019) is a popular baseline for semantic role labeling (predicate-argument prediction).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (baseline for semantic role labeling).",
      "processing_time": 48.380478620529175,
      "citing_paper_id": "248780117",
      "cited_paper_id": 131773936
    },
    {
      "context_text": "Bosselut et al. (2019) use generative language models to generate new event knowledge based on crowdsourced triples.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of generative language models and crowdsourced triples. No clear, verifiable dataset names are provided.",
      "processing_time": 48.751681089401245,
      "citing_paper_id": "248780117",
      "cited_paper_id": 189762527
    },
    {
      "context_text": "Apart from event extraction, in the future, it’s worth investigating how to leverage the global memory idea for other document-level IE problems like ( N -ary) relation extraction (Quirk and Poon, 2017; Yao et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to document-level relation extraction. No clear, verifiable dataset names are present.",
      "processing_time": 48.74650716781616,
      "citing_paper_id": "248780117",
      "cited_paper_id": 189898081
    },
    {
      "context_text": "To retrieve the most relevant “event” (i.e., a generated sequence) from the memory store m = { m 1 , m 2 , ... } , we use S-BERT (Reimers and Gurevych, 2019) for dense retrieval (i.e., retrieval with dense representations provided by NN).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions S-BERT for dense retrieval but does not refer to a specific dataset. S-BERT is a method, not a dataset.",
      "processing_time": 48.795241594314575,
      "citing_paper_id": "248780117",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "S-BERT is a modiﬁcation of the BERT model (Devlin et al., 2019) that uses siamese and triplet network structures to obtain semantically meaningful embeddings for text sequences.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 9 column 1 (char 306), response: ```json\n{\n    \"reasoning\": \"The context does not mention any specific datasets, only a modification ",
      "processing_time": 48.39358711242676,
      "citing_paper_id": "248780117",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "Since we ﬁx the parameters from S-BERT, the retrieval module’s parameters are not updated during training.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (S-BERT) which is not a dataset.",
      "processing_time": 48.231011390686035,
      "citing_paper_id": "248780117",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "Event Extraction has long been studied as a local sentence-level task (Grishman and Sundheim, 1996; Ji and Grishman, 2008b; Grishman, 2019; Lin et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies and papers. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 48.84243059158325,
      "citing_paper_id": "248780117",
      "cited_paper_id": 203701085
    },
    {
      "context_text": "• As compared to the raw BART-Gen, with our memory-based training – leveraging previously closest extracted event information substantially helps increase precision (P) and F-1 scores, with smaller but notable improvement in recall especially under Coref Match.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (memory-based training) and a model (BART-Gen).",
      "processing_time": 48.67093300819397,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Our best model with argu-ment pair constrained decoding outperforms substantially both BART-Gen and our memory-based training model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and performance comparisons.",
      "processing_time": 47.89543604850769,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Following Li et al. (2021), the main model of our framework is based on the pretrained encoder-decoder model BART (Lewis et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BART, which is a pretrained model, not a dataset. No datasets are explicitly mentioned or used according to the given text.",
      "processing_time": 48.47410988807678,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "We observe that: • The neural generation-based models (BART-Gen and our framework) are superior in this document-level informative argument extraction problem, as compared to the sequence labeling-based approaches.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance in a document-level informative argument extraction task.",
      "processing_time": 48.23995590209961,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Li et al. (2021) propose to use conditional neural text generation model for the document-level argument extraction problem, it handles each event in isolation ( BART-Gen ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BART-Gen but does not refer to it as a dataset. It is described as a model or method for document-level argument extraction.",
      "processing_time": 48.6032350063324,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "(2021), the main model of our framework is based on the pretrained encoderdecoder model BART (Lewis et al., 2020).",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 9 column 1 (char 298), response: ```json\n{\n    \"reasoning\": \"The citation mentions BART, which is a pretrained model, not a dataset. ",
      "processing_time": 48.382657289505005,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "The intuition behind using BART for the extraction task is that it is pre-trained as a denoising autoencoder – reconstruct the original input sequence.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BART, which is a model, not a dataset.",
      "processing_time": 48.06496834754944,
      "citing_paper_id": "248780117",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "To support the progress for the problem, Ebner et al. (2020) built RAMS dataset, and it contains annotations for cross-sentence arguments but for each document it contains only one event.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "RAMS"
      ],
      "dataset_descriptions": {
        "MIMIC-III": "Used to build a dataset for cross-sentence argument linking, focusing on document-level events with annotations for arguments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the construction of the RAMS dataset, which is used for cross-sentence argument linking with annotations for document-level events.",
      "processing_time": 49.56488871574402,
      "citing_paper_id": "248780117",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "In recent years, there have been efforts focusing on event extraction beyond sentence boundaries with end-to-end learning (Ebner et al., 2020; Du, 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general efforts in event extraction beyond sentence boundaries. No verifiable resources are identified.",
      "processing_time": 48.193325996398926,
      "citing_paper_id": "248780117",
      "cited_paper_id": 207853145
    },
    {
      "context_text": "In recent years, there have been efforts focusing on event extraction beyond sentence boundaries with end-to-end learning (Ebner et al., 2020; Du, 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general efforts in event extraction beyond sentence boundaries. No verifiable resources are identified.",
      "processing_time": 48.193325996398926,
      "citing_paper_id": "248780117",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "In recent years, there have been efforts focusing on event extraction beyond sentence boundaries with end-to-end learning (Ebner et al., 2020; Du, 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general efforts in event extraction beyond sentence boundaries. No verifiable resources are identified.",
      "processing_time": 48.193325996398926,
      "citing_paper_id": "248780117",
      "cited_paper_id": 247797575
    },
    {
      "context_text": "In recent years, there have been efforts focusing on event extraction beyond sentence boundaries with end-to-end learning (Ebner et al., 2020; Du, 2021; Li et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general efforts in event extraction beyond sentence boundaries. No verifiable resources are identified.",
      "processing_time": 48.193325996398926,
      "citing_paper_id": "248780117",
      "cited_paper_id": 247797575
    },
    {
      "context_text": ", 2019) and uses Conditional Random Fields (Lafferty et al., 2001) for structured prediction (BERT-CRF).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Conditional Random Fields) and a model (BERT-CRF).",
      "processing_time": 48.14385175704956,
      "citing_paper_id": "248780117",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "It performs sequence labeling based on automatically extracted features from BERT (Devlin et al., 2019) and uses Conditional Random Fields (Lafferty et al., 2001) for structured prediction ( BERT-CRF ).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and CRF but does not refer to any specific datasets. BERT is a model, and CRF is a method, so they are excluded.",
      "processing_time": 48.48124051094055,
      "citing_paper_id": "248780117",
      "cited_paper_id": 219683473
    },
    {
      "context_text": "For example, if one person has been identified as a JAILER in an event, it’s unlikely that the same person is an ATTACKER in another event in the document (Figure 1), according to world event knowledge (Sap et al., 2019; Yao et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to world event knowledge which is not a verifiable dataset.",
      "processing_time": 47.83061361312866,
      "citing_paper_id": "248780117",
      "cited_paper_id": 226262410
    },
    {
      "context_text": "For example, if one person has been identified as a JAILER in an event, it’s unlikely that the same person is an ATTACKER in another event in the document (Figure 1), according to world event knowledge (Sap et al., 2019; Yao et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to world event knowledge which is not a verifiable dataset.",
      "processing_time": 47.83061361312866,
      "citing_paper_id": "248780117",
      "cited_paper_id": null
    },
    {
      "context_text": "Yao et al. (2020) propose a weakly-supervised approach to extract sub-event relation tuples from the text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for extracting sub-event relation tuples.",
      "processing_time": 47.774189710617065,
      "citing_paper_id": "248780117",
      "cited_paper_id": 226262410
    },
    {
      "context_text": "For example, if one person has been identiﬁed as a JAILER in an event, it’s unlikely that the same person is an ATTACKER in another event in the document (Figure 1), according to world event knowledge (Sap et al., 2019; Yao et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to world event knowledge which is not a verifiable dataset.",
      "processing_time": 47.82288360595703,
      "citing_paper_id": "248780117",
      "cited_paper_id": 226262410
    },
    {
      "context_text": "For example, if one person has been identiﬁed as a JAILER in an event, it’s unlikely that the same person is an ATTACKER in another event in the document (Figure 1), according to world event knowledge (Sap et al., 2019; Yao et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to world event knowledge which is not a verifiable dataset.",
      "processing_time": 47.82288360595703,
      "citing_paper_id": "248780117",
      "cited_paper_id": null
    },
    {
      "context_text": "Sap et al. (2019) propose to use crowdsourcing for obtaining if-then relations be-tween events.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for obtaining if-then relations between events using crowdsourcing.",
      "processing_time": 47.863277435302734,
      "citing_paper_id": "248780117",
      "cited_paper_id": null
    }
  ],
  "filtering_stats": {
    "original_papers_count": 108,
    "filtered_papers_count": 86,
    "filtered_percentage": "79.6%"
  },
  "extraction_stats": {
    "unique_contexts_processed": 1574,
    "total_citation_instances": 1992,
    "successful_extractions": 288,
    "failed_extractions": 1704,
    "total_processing_time": 101.35219645500183
  }
}