{
  "summary": {
    "total_unique_datasets": 113,
    "total_dataset_mentions": 163,
    "unique_dataset_names": 113,
    "extraction_successful": 420,
    "extraction_failed": 5314,
    "unique_contexts_processed": 4438,
    "total_citation_instances": 5734,
    "total_processing_time": 260.5333843231201
  },
  "datasets_sorted_by_citation_count": [
    {
      "cited_paper_id": "59222757",
      "citation_count": 0,
      "total_dataset_mentions": 9,
      "unique_datasets": [
        "PersonaChat"
      ],
      "dataset_details": [
        {
          "dataset_name": "PersonaChat",
          "dataset_description": "Utilized to study casual and diverse conversational patterns, enhancing the ability of models to generate natural and engaging dialogues. | Employed to develop dialogue systems that can handle personal and emotional topics, enhancing the empathy and engagement of generated text. | Applied to analyze short-form, informal conversations, improving the generation of concise and contextually relevant responses. | Used to train dialogue systems for generating personalized responses, focusing on incorporating persona information into conversations.",
          "citing_paper_id": "234757004",
          "cited_paper_id": 3147007,
          "context_text": "There are also several dialog datasets that focus on chit-chat scenarios, such as PERSONA-CHAT dataset (Zhang et al., 2018), Reddit dataset (Al-Rfou et al., 2016), Twitter dataset (Li et al., 2016b) and PersonalDialog dataset (Zheng et al., 2020).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific dialog datasets that are used for chit-chat scenarios, which are directly relevant to personalized text generation.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.157",
          "cited_paper_doi": "10.18653/v1/D16-1127",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a27ef1cae80d9a72734868b7a5d4e5092452dc31",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1298dae5751fb06184f6b067d1503bde8037bdb7",
          "citing_paper_year": 2021,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "PersonaChat",
          "dataset_description": "Utilized to study casual and diverse conversational patterns, enhancing the ability of models to generate natural and engaging dialogues. | Employed to develop dialogue systems that can handle personal and emotional topics, enhancing the empathy and engagement of generated text. | Applied to analyze short-form, informal conversations, improving the generation of concise and contextually relevant responses. | Used to train dialogue systems for generating personalized responses, focusing on incorporating persona information into conversations.",
          "citing_paper_id": "234757004",
          "cited_paper_id": 7287895,
          "context_text": "There are also several dialog datasets that focus on chit-chat scenarios, such as PERSONA-CHAT dataset (Zhang et al., 2018), Reddit dataset (Al-Rfou et al., 2016), Twitter dataset (Li et al., 2016b) and PersonalDialog dataset (Zheng et al., 2020).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific dialog datasets that are used for chit-chat scenarios, which are directly relevant to personalized text generation.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.157",
          "cited_paper_doi": "10.18653/v1/N16-1014",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a27ef1cae80d9a72734868b7a5d4e5092452dc31",
          "cited_paper_url": "https://www.semanticscholar.org/paper/651e5bcc14f14605a879303e97572a27ea8c7956",
          "citing_paper_year": 2021,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "PersonaChat",
          "dataset_description": "Used to personalize chit-chat dialogues, focusing on incorporating personal information into conversations. The dataset contains 10,981 dialogues with 164,356 utterances in English.",
          "citing_paper_id": "221969995",
          "cited_paper_id": 6869582,
          "context_text": "PERSONA-CHAT (Zhang et al., 2018) 10,981 164,356 / English personalizing chit-chat dialogue corpus made by human.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions PERSONA-CHAT, which is a specific dataset used for personalizing chit-chat dialogues. The dataset is described as containing a large number of dialogues in English.",
          "citing_paper_doi": "10.1145/3404835.3463239",
          "cited_paper_doi": "10.18653/v1/P18-1205",
          "citing_paper_url": "https://www.semanticscholar.org/paper/ceb60c07a3584f94586f6ce0b2d55d72abf8952a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6c7046195f64cccac1ed3275d88d77655534b5a4",
          "citing_paper_year": 2020,
          "cited_paper_year": 2018
        },
        {
          "dataset_name": "PersonaChat",
          "dataset_description": "Used to evaluate dialogue systems, focusing on optimizing control of repetition, specificity, and question-asking over multiple turns to enhance engagingness. | Used to train and evaluate dialogue agents in a chitchat setting, focusing on interactions between two participants (human-human or human-bot) to enhance conversational skills.",
          "citing_paper_id": "67855999",
          "cited_paper_id": 6869582,
          "context_text": "PersonaChat (Zhang et al., 2018b) is a chitchat dialogue task involving two participants (two humans or a human and a bot).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "PersonaChat is a specific dataset used for training and evaluating dialogue agents in a chitchat setting, involving interactions between two participants.",
          "citing_paper_doi": "10.18653/v1/N19-1170",
          "cited_paper_doi": "10.18653/v1/P18-1205",
          "citing_paper_url": "https://www.semanticscholar.org/paper/8059b85332572e60c8a1daa0ccb8ddc008513f00",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6c7046195f64cccac1ed3275d88d77655534b5a4",
          "citing_paper_year": 2019,
          "cited_paper_year": 2018
        },
        {
          "dataset_name": "PersonaChat",
          "dataset_description": "Used to facilitate chatbots with configurable and persistent personalities, enhancing coherence and personalization in dialogue systems.",
          "citing_paper_id": "247411350",
          "cited_paper_id": 6862403,
          "context_text": "Existing persona dialogue datasets such as PersonaChat (Zhang et al., 2018; Dinan et al., 2019) and models (Li et al., 2016a; Zhang et al., 2017; Qian et al., 2018) have greatly facilitated the chatbot with conﬁgurable and persistent personalities.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "PersonaChat is mentioned as a specific dataset used in the field of persona dialogue, which is relevant to personalized text generation.",
          "citing_paper_doi": "10.48550/arXiv.2203.05797",
          "cited_paper_doi": "10.1007/s11280-018-0598-6",
          "citing_paper_url": "https://www.semanticscholar.org/paper/081edae651e709e448bdd8a1f1b5760c7c7e1f53",
          "cited_paper_url": "https://www.semanticscholar.org/paper/ba3975cd4dea504142b6d423c8b70790407cfb07",
          "citing_paper_year": 2022,
          "cited_paper_year": 2017
        },
        {
          "dataset_name": "PersonaChat",
          "dataset_description": "Used to facilitate chatbots with configurable and persistent personalities, enhancing coherence and personalization in dialogue systems.",
          "citing_paper_id": "247411350",
          "cited_paper_id": 51608471,
          "context_text": "Existing persona dialogue datasets such as PersonaChat (Zhang et al., 2018; Dinan et al., 2019) and models (Li et al., 2016a; Zhang et al., 2017; Qian et al., 2018) have greatly facilitated the chatbot with conﬁgurable and persistent personalities.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "PersonaChat is mentioned as a specific dataset used in the field of persona dialogue, which is relevant to personalized text generation.",
          "citing_paper_doi": "10.48550/arXiv.2203.05797",
          "cited_paper_doi": "10.24963/ijcai.2018/595",
          "citing_paper_url": "https://www.semanticscholar.org/paper/081edae651e709e448bdd8a1f1b5760c7c7e1f53",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b0f730088bbf129beeac13cc220a18fbb60033ee",
          "citing_paper_year": 2022,
          "cited_paper_year": 2018
        },
        {
          "dataset_name": "PersonaChat",
          "dataset_description": "Used to train and evaluate persona-based dialogue systems, focusing on generating conversations that reflect personal attributes and preferences. | Used to demonstrate rich persona features in a clipped dialogue, focusing on personalizing dialogue agents through persona-based interactions. | Used to experiment with persona-based dialogue generation models, specifically validating a model-agnostic data manipulation method using Transformer and GPT2 architectures. | Used to train and evaluate personalized dialogue agents, focusing on incorporating personal information into conversational responses.",
          "citing_paper_id": "248299824",
          "cited_paper_id": 6869582,
          "context_text": "Dataset The PersonaChat (Zhang et al., 2018a) data is widely used in this ﬁeld (Song et al., 2019, 2020; Wolf et al., 2019; Golovanov et al., 2019).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the PersonaChat dataset, which is a specific, verifiable dataset used in the field of personalized dialogue agents.",
          "citing_paper_doi": "10.48550/arXiv.2204.09867",
          "cited_paper_doi": "10.18653/v1/P18-1205",
          "citing_paper_url": "https://www.semanticscholar.org/paper/11e295b8fd91a893efe7259d789936fc116f7792",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6c7046195f64cccac1ed3275d88d77655534b5a4",
          "citing_paper_year": 2022,
          "cited_paper_year": 2018
        },
        {
          "dataset_name": "PersonaChat",
          "dataset_description": "Used to train and evaluate personalized dialogue agents, focusing on incorporating personal information into conversational responses.",
          "citing_paper_id": "248299824",
          "cited_paper_id": 196184953,
          "context_text": "Dataset The PersonaChat (Zhang et al., 2018a) data is widely used in this ﬁeld (Song et al., 2019, 2020; Wolf et al., 2019; Golovanov et al., 2019).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the PersonaChat dataset, which is a specific, verifiable dataset used in the field of personalized dialogue agents.",
          "citing_paper_doi": "10.48550/arXiv.2204.09867",
          "cited_paper_doi": "10.18653/v1/P19-1608",
          "citing_paper_url": "https://www.semanticscholar.org/paper/11e295b8fd91a893efe7259d789936fc116f7792",
          "cited_paper_url": "https://www.semanticscholar.org/paper/791c3c30f2af10ac06f4fbc5b1e8960064aacbc7",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "PersonaChat",
          "dataset_description": "Used to train and evaluate personalized dialogue agents, focusing on incorporating personal information into conversational responses.",
          "citing_paper_id": "248299824",
          "cited_paper_id": 59222757,
          "context_text": "Dataset The PersonaChat (Zhang et al., 2018a) data is widely used in this ﬁeld (Song et al., 2019, 2020; Wolf et al., 2019; Golovanov et al., 2019).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the PersonaChat dataset, which is a specific, verifiable dataset used in the field of personalized dialogue agents.",
          "citing_paper_doi": "10.48550/arXiv.2204.09867",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/11e295b8fd91a893efe7259d789936fc116f7792",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e81b50f68265b84d55d03dab3c296b9fd4516857",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "12300158",
      "citation_count": 0,
      "total_dataset_mentions": 6,
      "unique_datasets": [
        "OpenSubtitles"
      ],
      "dataset_details": [
        {
          "dataset_name": "OpenSubtitles",
          "dataset_description": "Used to assess sequence-to-sequence models in generating conversational responses, focusing on context sensitivity without long-term knowledge recall. | Used to test sequence-to-sequence models in generating conversational responses, focusing on context sensitivity without long-term knowledge recall. | Used to evaluate models' performance in generating contextually relevant responses, emphasizing the importance of persona information in dialogues. | Used to evaluate sequence-to-sequence models in generating personalized conversational responses, emphasizing recent dialogue history. | Used to assess the effectiveness of sequence-to-sequence models in generating conversational responses, particularly in capturing recent dialogue history. | Used to test sequence-to-sequence models' ability to generate conversational responses, focusing on context sensitivity and recent dialogue history.",
          "citing_paper_id": "53218829",
          "cited_paper_id": 94285,
          "context_text": "For example, popular chit-chat datasets such as Open-Subtitles (Vinyals & Le, 2015), Persona-Chat (Zhang et al., 2018) and Twitter (Sordoni et al., 2015) have tested the ability of sequence-to-sequence models that attend over the recent dialogue history, but do not attempt to recall long-term…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used for testing sequence-to-sequence models in dialogue systems, which are directly relevant to personalized text generation.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.3115/v1/N15-1020",
          "citing_paper_url": "https://www.semanticscholar.org/paper/227458886343b86bd15adf58c769be326b4b058a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/5247a6e3a60ff0381355e66bfc313bf27512ae0c",
          "citing_paper_year": 2018,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "OpenSubtitles",
          "dataset_description": "Used to assess sequence-to-sequence models in generating conversational responses, focusing on context sensitivity without long-term knowledge recall. | Used to test sequence-to-sequence models in generating conversational responses, focusing on context sensitivity without long-term knowledge recall. | Used to evaluate models' performance in generating contextually relevant responses, emphasizing the importance of persona information in dialogues. | Used to evaluate sequence-to-sequence models in generating personalized conversational responses, emphasizing recent dialogue history. | Used to assess the effectiveness of sequence-to-sequence models in generating conversational responses, particularly in capturing recent dialogue history. | Used to test sequence-to-sequence models' ability to generate conversational responses, focusing on context sensitivity and recent dialogue history.",
          "citing_paper_id": "53218829",
          "cited_paper_id": 12300158,
          "context_text": "For example, popular chit-chat datasets such as Open-Subtitles (Vinyals & Le, 2015), Persona-Chat (Zhang et al., 2018) and Twitter (Sordoni et al., 2015) have tested the ability of sequence-to-sequence models that attend over the recent dialogue history, but do not attempt to recall long-term…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used for testing sequence-to-sequence models in dialogue systems, which are directly relevant to personalized text generation.",
          "citing_paper_doi": null,
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/227458886343b86bd15adf58c769be326b4b058a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/86311b182786bfde19446f6ded0854de973d4060",
          "citing_paper_year": 2018,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "OpenSubtitles",
          "dataset_description": "Used to train neural models for dialogue generation, focusing on natural language interactions in movie scripts. | Used to train neural dialogue systems, focusing on short, real-time interactions and social media language. | Utilized for training neural dialogue systems, emphasizing conversational exchanges from movies. | Employed to train neural models for generating dialogues, capturing diverse and informal online conversations.",
          "citing_paper_id": "6869582",
          "cited_paper_id": 3147007,
          "context_text": "…models are ones based on movie scripts such as OpenSubtitles and Cornell Movie-Dialogue Corpus, and dialogue from web platforms such as Reddit and Twitter, all of which have been used for training neural approaches (Vinyals and Le, 2015; Dodge et al., 2015; Li et al., 2016b; Serban et al., 2017b).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used for training neural approaches in dialogue generation, which aligns with the topic of personalized text generation.",
          "citing_paper_doi": "10.18653/v1/P18-1205",
          "cited_paper_doi": "10.18653/v1/D16-1127",
          "citing_paper_url": "https://www.semanticscholar.org/paper/6c7046195f64cccac1ed3275d88d77655534b5a4",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1298dae5751fb06184f6b067d1503bde8037bdb7",
          "citing_paper_year": 2018,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "OpenSubtitles",
          "dataset_description": "Used to train neural models for dialogue generation, focusing on natural language interactions in movie scripts. | Used to train neural dialogue systems, focusing on short, real-time interactions and social media language. | Utilized for training neural dialogue systems, emphasizing conversational exchanges from movies. | Employed to train neural models for generating dialogues, capturing diverse and informal online conversations.",
          "citing_paper_id": "6869582",
          "cited_paper_id": 14857825,
          "context_text": "…models are ones based on movie scripts such as OpenSubtitles and Cornell Movie-Dialogue Corpus, and dialogue from web platforms such as Reddit and Twitter, all of which have been used for training neural approaches (Vinyals and Le, 2015; Dodge et al., 2015; Li et al., 2016b; Serban et al., 2017b).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used for training neural approaches in dialogue generation, which aligns with the topic of personalized text generation.",
          "citing_paper_doi": "10.18653/v1/P18-1205",
          "cited_paper_doi": "10.1609/aaai.v31i1.10983",
          "citing_paper_url": "https://www.semanticscholar.org/paper/6c7046195f64cccac1ed3275d88d77655534b5a4",
          "cited_paper_url": "https://www.semanticscholar.org/paper/609e0f0e60ddfe83fdc71bf5397205323888289d",
          "citing_paper_year": 2018,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "OpenSubtitles",
          "dataset_description": "Utilized for training neural approaches, offering a structured collection of movie dialogues to enhance conversational skills. | Used to train neural conversational models, providing a large corpus of movie subtitles for generating natural dialogues. | Employed to train neural models, leveraging user-generated dialogues from various subreddits to improve conversational fluency and context awareness. | Used to train neural models, utilizing real-time, public conversations to enhance the responsiveness and naturalness of generated text.",
          "citing_paper_id": "6869582",
          "cited_paper_id": 12300158,
          "context_text": "movie scripts such as OpenSubtitles and Cornell Movie-Dialogue Corpus, and dialogue from web platforms such as Reddit and Twitter, all of which have been used for training neural approaches (Vinyals and Le, 2015; Dodge et al., 2015; Li et al., 2016b; Serban et al., 2017b).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used for training neural approaches in conversational models, which are directly relevant to personalized text generation.",
          "citing_paper_doi": "10.18653/v1/P18-1205",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/6c7046195f64cccac1ed3275d88d77655534b5a4",
          "cited_paper_url": "https://www.semanticscholar.org/paper/86311b182786bfde19446f6ded0854de973d4060",
          "citing_paper_year": 2018,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "OpenSubtitles",
          "dataset_description": "Used as a conventional dialogue dataset for comparison with persona-based datasets, highlighting the size difference in terms of utterances. | Used as a conventional dialogue dataset for comparison with persona-based datasets, emphasizing the scale of utterances available.",
          "citing_paper_id": "248299824",
          "cited_paper_id": 7356547,
          "context_text": "Compared with conventional dialogue datasets such as OpenSubtitles (Lison and Tiedemann, 2016) and Weibo (Shang et al., 2015) with millions of utterances, persona-based dialogue datasets are relatively small.",
          "confidence_score": 0.8,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'OpenSubtitles' and 'Weibo' as conventional dialogue datasets, which are specific and verifiable resources. However, they are not used in the current research but compared against persona-based dialogue datasets.",
          "citing_paper_doi": "10.48550/arXiv.2204.09867",
          "cited_paper_doi": "10.3115/v1/P15-1152",
          "citing_paper_url": "https://www.semanticscholar.org/paper/11e295b8fd91a893efe7259d789936fc116f7792",
          "cited_paper_url": "https://www.semanticscholar.org/paper/ba49d3823d43515e447296ca4e1e55d3f1fd8c4d",
          "citing_paper_year": 2022,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "221761251",
      "citation_count": 0,
      "total_dataset_mentions": 6,
      "unique_datasets": [
        "ESCONV"
      ],
      "dataset_details": [
        {
          "dataset_name": "ESCONV",
          "dataset_description": "Used to evaluate state-of-the-art empathetic dialogue generation models, focusing on generating empathetic responses in conversations.",
          "citing_paper_id": "252780132",
          "cited_paper_id": 201124425,
          "context_text": "Our baselines include three empathetic response generators: MoEL (Lin et al., 2019), MIME (Majumder et al., 2020), and EmpDG (Li et al., 2020a); and four state-of-the-art methods on the ESCONV dataset: DialoGPT-Joint, BlenderBot-Joint (Liu et al., 2021), MISC (Tu et al., 2022), and GLHG (Peng et…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the ESCONV dataset, which is used for evaluating state-of-the-art methods in empathetic dialogue generation. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.48550/arXiv.2210.04242",
          "cited_paper_doi": "10.18653/v1/D19-1012",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f36053a516cc4e3e72291ad2eaa042a299a19635",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b47698a589e35ec3f7a0bb30618939fbed0b9e41",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "ESCONV",
          "dataset_description": "Used to evaluate state-of-the-art empathetic dialogue generation models, focusing on generating empathetic responses in conversations.",
          "citing_paper_id": "252780132",
          "cited_paper_id": 245537585,
          "context_text": "Our baselines include three empathetic response generators: MoEL (Lin et al., 2019), MIME (Majumder et al., 2020), and EmpDG (Li et al., 2020a); and four state-of-the-art methods on the ESCONV dataset: DialoGPT-Joint, BlenderBot-Joint (Liu et al., 2021), MISC (Tu et al., 2022), and GLHG (Peng et…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the ESCONV dataset, which is used for evaluating state-of-the-art methods in empathetic dialogue generation. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.48550/arXiv.2210.04242",
          "cited_paper_doi": "10.1609/aaai.v36i10.21347",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f36053a516cc4e3e72291ad2eaa042a299a19635",
          "cited_paper_url": "https://www.semanticscholar.org/paper/01caaf3a67ad31c93048a29fff90e62ad3dac167",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "ESCONV",
          "dataset_description": "Used to evaluate state-of-the-art empathetic dialogue generation models, focusing on generating empathetic responses in conversations.",
          "citing_paper_id": "252780132",
          "cited_paper_id": 216562425,
          "context_text": "Our baselines include three empathetic response generators: MoEL (Lin et al., 2019), MIME (Majumder et al., 2020), and EmpDG (Li et al., 2020a); and four state-of-the-art methods on the ESCONV dataset: DialoGPT-Joint, BlenderBot-Joint (Liu et al., 2021), MISC (Tu et al., 2022), and GLHG (Peng et al., 2022).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the ESCONV dataset, which is used for evaluating state-of-the-art methods in empathetic dialogue generation. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.48550/arXiv.2210.04242",
          "cited_paper_doi": "10.18653/v1/2021.eacl-main.24",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f36053a516cc4e3e72291ad2eaa042a299a19635",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9b539d413393047b28bb7be9b195f142aaf7a80e",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "ESCONV",
          "dataset_description": "Used to evaluate state-of-the-art empathetic dialogue generation models, focusing on generating empathetic responses in conversations. | Used to evaluate empathetic response generators and state-of-the-art methods in emotional support conversations, focusing on generating empathetic and contextually appropriate responses.",
          "citing_paper_id": "252780132",
          "cited_paper_id": 221761251,
          "context_text": "Our baselines include three empathetic response generators: MoEL (Lin et al., 2019), MIME (Majumder et al., 2020), and EmpDG (Li et al., 2020a); and four state-of-the-art methods on the ESCONV dataset: DialoGPT-Joint, BlenderBot-Joint (Liu et al., 2021), MISC (Tu et al., 2022), and GLHG (Peng et al., 2022).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the ESCONV dataset, which is used for evaluating state-of-the-art methods in empathetic dialogue generation. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.48550/arXiv.2210.04242",
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.425",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f36053a516cc4e3e72291ad2eaa042a299a19635",
          "cited_paper_url": "https://www.semanticscholar.org/paper/15c9bbc6de95fbff176b6cb76530785146da81eb",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "ESCONV",
          "dataset_description": "Used to evaluate state-of-the-art empathetic dialogue generation models, focusing on generating empathetic responses in conversations. | Used to train a mixed strategy-aware model for emotional support conversations, integrating COMET to enhance conversational strategies and emotional responses. | Used to evaluate empathetic response generators and state-of-the-art methods in emotional support conversations, focusing on generating empathetic and contextually appropriate responses.",
          "citing_paper_id": "252780132",
          "cited_paper_id": 247748640,
          "context_text": "Our baselines include three empathetic response generators: MoEL (Lin et al., 2019), MIME (Majumder et al., 2020), and EmpDG (Li et al., 2020a); and four state-of-the-art methods on the ESCONV dataset: DialoGPT-Joint, BlenderBot-Joint (Liu et al., 2021), MISC (Tu et al., 2022), and GLHG (Peng et al., 2022).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the ESCONV dataset, which is used for evaluating state-of-the-art methods in empathetic dialogue generation. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.48550/arXiv.2210.04242",
          "cited_paper_doi": "10.48550/arXiv.2203.13560",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f36053a516cc4e3e72291ad2eaa042a299a19635",
          "cited_paper_url": "https://www.semanticscholar.org/paper/4ebff21b83277a523d9ce84c5cc745074b1f642e",
          "citing_paper_year": 2022,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "ESCONV",
          "dataset_description": "Used to evaluate state-of-the-art empathetic dialogue generation models, focusing on generating empathetic responses in conversations. | Used to evaluate empathetic response generators and state-of-the-art methods in emotional support conversations, focusing on generating empathetic and contextually appropriate responses.",
          "citing_paper_id": "252780132",
          "cited_paper_id": 248406141,
          "context_text": "Our baselines include three empathetic response generators: MoEL (Lin et al., 2019), MIME (Majumder et al., 2020), and EmpDG (Li et al., 2020a); and four state-of-the-art methods on the ESCONV dataset: DialoGPT-Joint, BlenderBot-Joint (Liu et al., 2021), MISC (Tu et al., 2022), and GLHG (Peng et al., 2022).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the ESCONV dataset, which is used for evaluating state-of-the-art methods in empathetic dialogue generation. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.48550/arXiv.2210.04242",
          "cited_paper_doi": "10.48550/arXiv.2204.12749",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f36053a516cc4e3e72291ad2eaa042a299a19635",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b78fd9e4049e86f63c22bdf8cd208bbb4bf4a0a1",
          "citing_paper_year": 2022,
          "cited_paper_year": 2022
        }
      ]
    },
    {
      "cited_paper_id": "668431",
      "citation_count": 0,
      "total_dataset_mentions": 5,
      "unique_datasets": [
        "Yelp"
      ],
      "dataset_details": [
        {
          "dataset_name": "Yelp",
          "dataset_description": "Used for sentiment prediction tasks, focusing on user reviews to explore personalized product rating predictions. | Used for sentiment prediction tasks, focusing on movie reviews to explore personalized product rating predictions. | Used to explore personalized sentiment prediction, focusing on user-specific sentiment patterns in reviews. | Used to explore personalized sentiment prediction, focusing on user-specific sentiment patterns in movie reviews.",
          "citing_paper_id": "258298303",
          "cited_paper_id": 236478014,
          "context_text": "Similarly, other work has explored personalized sentiment prediction on publicly available Yelp and IMDB data (Mireshghallah et al., 2022; Zhong et al., 2021) – this work bears a resemblance to the LaMP-3 task and ties back to rating prediction explored in recommendation tasks.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Yelp and IMDB data' as publicly available datasets used for personalized sentiment prediction. These datasets are specific and widely recognized.",
          "citing_paper_doi": "10.48550/arXiv.2304.11406",
          "cited_paper_doi": "10.18653/v1/2021.findings-acl.129",
          "citing_paper_url": "https://www.semanticscholar.org/paper/17170575aa8b4fa4e3eef5d366ada706a94dd836",
          "cited_paper_url": "https://www.semanticscholar.org/paper/331102c42a340e7bcd9a4b063b9b1204f30f665f",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "Yelp",
          "dataset_description": "Used to explore personalized sentiment prediction, focusing on user-specific sentiment patterns in reviews. | Used to explore personalized sentiment prediction, focusing on user-specific sentiment patterns in movie reviews.",
          "citing_paper_id": "258298303",
          "cited_paper_id": 238252929,
          "context_text": "Similarly, other work has explored personalized sentiment prediction on publicly available Yelp and IMDB data (Mireshghallah et al., 2022; Zhong et al., 2021) – this work bears a resemblance to the LaMP-3 task and ties back to rating prediction explored in recommendation tasks.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Yelp and IMDB data' as publicly available datasets used for personalized sentiment prediction. These datasets are specific and widely recognized.",
          "citing_paper_doi": "10.48550/arXiv.2304.11406",
          "cited_paper_doi": "10.18653/v1/2022.naacl-main.252",
          "citing_paper_url": "https://www.semanticscholar.org/paper/17170575aa8b4fa4e3eef5d366ada706a94dd836",
          "cited_paper_url": "https://www.semanticscholar.org/paper/49a328730d3c6397820b733bbac903545568cd9c",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "Yelp",
          "dataset_description": "Used for personalized sentiment prediction tasks, focusing on user reviews and ratings to explore recommendation systems. | Used for personalized sentiment prediction tasks, focusing on movie reviews and ratings to explore recommendation systems. | Used to explore personalized sentiment prediction, focusing on user-specific sentiment patterns in reviews. | Used to explore personalized sentiment prediction, focusing on user-specific sentiment patterns in movie reviews.",
          "citing_paper_id": "258298303",
          "cited_paper_id": null,
          "context_text": "Similarly, other work has explored personalized sentiment prediction on publicly available Yelp and IMDB data (Mireshghallah et al., 2022; Zhong et al., 2021) – this work bears a resemblance to the LaMP-3 task and ties back to rating prediction explored in recommendation tasks.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Yelp and IMDB data' as publicly available datasets used for personalized sentiment prediction. These datasets are specific and widely recognized.",
          "citing_paper_doi": "10.48550/arXiv.2304.11406",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/17170575aa8b4fa4e3eef5d366ada706a94dd836",
          "cited_paper_url": null,
          "citing_paper_year": 2023,
          "cited_paper_year": null
        },
        {
          "dataset_name": "Yelp",
          "dataset_description": "Used to evaluate the FactorCell model's classification accuracy, comparing it against previously reported generative models' performance.",
          "citing_paper_id": "19096382",
          "cited_paper_id": 668431,
          "context_text": "For the DBPedia and Yelp datasets, the FactorCell model beats previously reported classification accuracies for generative models (Yogatama et al., 2017).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'DBPedia and Yelp datasets' which are specific, verifiable datasets used for evaluating the FactorCell model's performance in text classification.",
          "citing_paper_doi": "10.1162/tacl_a_00035",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/5835af39301c156456a1c7168f44ba9321b50278",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6727f574ad8b1c3763be8d58eeaf82c551aa33ef",
          "citing_paper_year": 2017,
          "cited_paper_year": 2017
        },
        {
          "dataset_name": "Yelp",
          "dataset_description": "Used for preliminary experiments to evaluate generative classifier accuracy, focusing on the effectiveness of discriminative text classification in neural language generation.",
          "citing_paper_id": "19096382",
          "cited_paper_id": 11054023,
          "context_text": "ective of our work, including speaker characteristics (Luan et al., 2016; Li et al., 2016), dialog act (Wen et al., 2015), sentiment and other factors (Tang et al., 2016; Hu et al., 2017), and style (Ficler and Goldberg, 2017). As noted earlier, some of this work has used discriminative text classiﬁcation to evaluate generation. In preliminary experiments with the Yelp data set, we found that the generative classiﬁer accur",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the 'Yelp data set' which is a specific, verifiable dataset. It is used for preliminary experiments to evaluate generative classifier accuracy.",
          "citing_paper_doi": "10.1162/tacl_a_00035",
          "cited_paper_doi": "10.18653/v1/W17-4912",
          "citing_paper_url": "https://www.semanticscholar.org/paper/5835af39301c156456a1c7168f44ba9321b50278",
          "cited_paper_url": "https://www.semanticscholar.org/paper/fb39923f6a4cdb486da5b579c5f8e2c500f36a35",
          "citing_paper_year": 2017,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "323921",
      "citation_count": 0,
      "total_dataset_mentions": 4,
      "unique_datasets": [
        "b5-ref corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "b5-ref corpus",
          "dataset_description": "Used to implement a language production task where subjects distinguish a target from distractor objects, focusing on the generation of referring expressions in a given context.",
          "citing_paper_id": "21691164",
          "cited_paper_id": 323921,
          "context_text": "As in much of the existing work on data collection for REG (Gatt et al., 2007; Dale and Viethen, 2009; Paraboni et al., 2017a), the b5-ref corpus was implemented as a language production task in which subjects were requested to distinguish a certain target from distractor objects in a given context…",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the 'b5-ref corpus' as a specific dataset used for a language production task in referring expression generation (REG) research.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.3115/1610195.1610204",
          "citing_paper_url": "https://www.semanticscholar.org/paper/547a6c2a15f8b40c015c7515abf3680a5df74d85",
          "cited_paper_url": "https://www.semanticscholar.org/paper/406b29fd13607ad06d576650aee6576b9abe6e08",
          "citing_paper_year": 2018,
          "cited_paper_year": 2009
        },
        {
          "dataset_name": "b5-ref corpus",
          "dataset_description": "Used to implement a language production task where subjects distinguish a target from distractor objects, focusing on the generation of referring expressions in a given context. | Used to train and evaluate a machine learning model for referring expression generation, focusing on non-discriminatory attribute selection in the b5-ref domain.",
          "citing_paper_id": "21691164",
          "cited_paper_id": 29746672,
          "context_text": "As in much of the existing work on data collection for REG (Gatt et al., 2007; Dale and Viethen, 2009; Paraboni et al., 2017a), the b5-ref corpus was implemented as a language production task in which subjects were requested to distinguish a certain target from distractor objects in a given context…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'b5-ref corpus' as a specific dataset used for a language production task in referring expression generation (REG) research.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.1007/s10579-016-9350-y",
          "citing_paper_url": "https://www.semanticscholar.org/paper/547a6c2a15f8b40c015c7515abf3680a5df74d85",
          "cited_paper_url": "https://www.semanticscholar.org/paper/de65ebd82351cde1a978660436948acd6e579cb8",
          "citing_paper_year": 2018,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "b5-ref corpus",
          "dataset_description": "Used to implement a language production task where subjects distinguish a target from distractor objects, focusing on the generation of referring expressions in a given context. | Used to train and evaluate a machine learning model for referring expression generation, focusing on non-discriminatory attribute selection in the b5-ref domain.",
          "citing_paper_id": "21691164",
          "cited_paper_id": 29272723,
          "context_text": "As in much of the existing work on data collection for REG (Gatt et al., 2007; Dale and Viethen, 2009; Paraboni et al., 2017a), the b5-ref corpus was implemented as a language production task in which subjects were requested to distinguish a certain target from distractor objects in a given context…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'b5-ref corpus' as a specific dataset used for a language production task in referring expression generation (REG) research.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.1007/978-3-319-64206-2_3",
          "citing_paper_url": "https://www.semanticscholar.org/paper/547a6c2a15f8b40c015c7515abf3680a5df74d85",
          "cited_paper_url": "https://www.semanticscholar.org/paper/5fcde9236d654a0f92a76c1a3f07c0cad954985c",
          "citing_paper_year": 2018,
          "cited_paper_year": 2017
        },
        {
          "dataset_name": "b5-ref corpus",
          "dataset_description": "Used to build a personality-dependent lexical choice model, focusing on the lexicalisation of frequent properties in personalized text generation. | Used to build a personality-dependent lexical choice model, focusing on the lexicalization of frequent properties, demonstrating improvements when personality information is included.",
          "citing_paper_id": "21691164",
          "cited_paper_id": 21699698,
          "context_text": "Moreover, results from a personality-dependent lexical choice model built from b5-ref in (Lan and Paraboni, 2018) showed that the lexicali-sation of the most frequent properties (i.e., those for which there is sufﬁcient data in the corpus) greatly improves when personality information is taken into…",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'b5-ref' as a corpus used for building a personality-dependent lexical choice model. The corpus name is specific and plausible, and the usage is clear.",
          "citing_paper_doi": null,
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/547a6c2a15f8b40c015c7515abf3680a5df74d85",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e8f753208fc354fa9aeb3fa9c6acb3d45e7eac7b",
          "citing_paper_year": 2018,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "266163891",
      "citation_count": 0,
      "total_dataset_mentions": 3,
      "unique_datasets": [
        "Reddit TL;DR summarization dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "Reddit TL;DR summarization dataset",
          "dataset_description": "Used to generate summaries with synthetic preferences, focusing on crowdsourced pairwise preferences over Reddit post summaries to train a GPT-J 6B model.",
          "citing_paper_id": "267547503",
          "cited_paper_id": 221665105,
          "context_text": "…text generation tasks (1) Generation with Synthetic Preferences: we use the Reddit TL;DR summarization dataset 4 curated by Stiennon et al. [34], where the pairwise preferences over Reddit post summaries were crowdsourced from multiple workers, and a GPT-J 6B model [37] supervised…",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the 'Reddit TL;DR summarization dataset' which is a specific, verifiable dataset used for generating summaries with synthetic preferences.",
          "citing_paper_doi": "10.48550/arXiv.2402.05133",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/4dcccc23c169293df73da1390c7af32ab47f3995",
          "cited_paper_url": "https://www.semanticscholar.org/paper/053b1d7b97eb2c91fc3921d589c160b0923c70b1",
          "citing_paper_year": 2024,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "Reddit TL;DR summarization dataset",
          "dataset_description": "Used to train and evaluate models on summarizing Reddit posts, focusing on crowdsourced pairwise preferences over summaries to improve personalized text generation.",
          "citing_paper_id": "267547503",
          "cited_paper_id": null,
          "context_text": "…Preferences: we use the Reddit TL;DR summarization dataset 4 curated by Stiennon et al. [34], where the pairwise preferences over Reddit post summaries were crowdsourced from multiple workers, and a GPT-J 6B model [37] supervised fine-tuned using the TRLX library 5 [13] is used as the SFT.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the Reddit TL;DR summarization dataset, which is a specific, verifiable dataset used for training and evaluating models on summarization tasks.",
          "citing_paper_doi": "10.48550/arXiv.2402.05133",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/4dcccc23c169293df73da1390c7af32ab47f3995",
          "cited_paper_url": null,
          "citing_paper_year": 2024,
          "cited_paper_year": null
        },
        {
          "dataset_name": "Reddit TL;DR summarization dataset",
          "dataset_description": "Used to train and evaluate models on summarizing Reddit posts, focusing on crowdsourced pairwise preferences over summaries to improve personalized text generation.",
          "citing_paper_id": "267547503",
          "cited_paper_id": 266163891,
          "context_text": "…Preferences: we use the Reddit TL;DR summarization dataset 4 curated by Stiennon et al. [34], where the pairwise preferences over Reddit post summaries were crowdsourced from multiple workers, and a GPT-J 6B model [37] supervised fine-tuned using the TRLX library 5 [13] is used as the SFT.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the Reddit TL;DR summarization dataset, which is a specific, verifiable dataset used for training and evaluating models on summarization tasks.",
          "citing_paper_doi": "10.48550/arXiv.2402.05133",
          "cited_paper_doi": "10.18653/v1/2023.emnlp-main.530",
          "citing_paper_url": "https://www.semanticscholar.org/paper/4dcccc23c169293df73da1390c7af32ab47f3995",
          "cited_paper_url": "https://www.semanticscholar.org/paper/57daf938ab134ba05a1bef4d596c2074d367e81e",
          "citing_paper_year": 2024,
          "cited_paper_year": 2023
        }
      ]
    },
    {
      "cited_paper_id": "2574224",
      "citation_count": 0,
      "total_dataset_mentions": 3,
      "unique_datasets": [
        "PororoSV"
      ],
      "dataset_details": [
        {
          "dataset_name": "PororoSV",
          "dataset_description": "Introduced to evaluate real-world story synthesis capacity, specifically using visual storytelling to enhance the evaluation of narrative generation systems. | Used as a testbed for evaluating personalized text generation, focusing on visual storytelling and narrative coherence.",
          "citing_paper_id": "253734226",
          "cited_paper_id": 2574224,
          "context_text": "We use three datasets as our testbed, PororoSV [17], FlintstonesSV [19], and VIST [11].",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions three specific datasets by name, which are used as testbeds for the research. These datasets are likely relevant to personalized text generation as they involve storytelling and visualization.",
          "citing_paper_doi": "10.1109/WACV57701.2024.00290",
          "cited_paper_doi": "10.18653/v1/N16-1147",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33ef78737ba57ecc1ff98c22369a8e17ed90eb98",
          "cited_paper_url": "https://www.semanticscholar.org/paper/927987a48c2a519bbc097d8b6c925b64a85b7d8e",
          "citing_paper_year": 2022,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "PororoSV",
          "dataset_description": "Used for evaluating story continuation tasks, focusing on visual quality, relevance, and consistency in generated stories. | Derived from the Flintstones text-to-video synthesis dataset, utilized to integrate commonsense structure into story visualization. | Used as a testbed for evaluating personalized text generation, focusing on visual storytelling and narrative coherence. | Used to evaluate personalized text generation models, focusing on visuospatial and linguistic structure in story visualization.",
          "citing_paper_id": "253734226",
          "cited_paper_id": 54457433,
          "context_text": "We use three datasets as our testbed, PororoSV [17], FlintstonesSV [19], and VIST [11].",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions three specific datasets by name, which are used as testbeds for the research. These datasets are likely relevant to personalized text generation as they involve storytelling and visualization.",
          "citing_paper_doi": "10.1109/WACV57701.2024.00290",
          "cited_paper_doi": "10.1109/CVPR.2019.00649",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33ef78737ba57ecc1ff98c22369a8e17ed90eb98",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3b87e795f1f501843f7f99e83e38f125f6af8600",
          "citing_paper_year": 2022,
          "cited_paper_year": 2018
        },
        {
          "dataset_name": "PororoSV",
          "dataset_description": "Derived from the Flintstones text-to-video synthesis dataset, utilized to integrate commonsense structure into story visualization. | Used to evaluate personalized text generation models, focusing on visuospatial and linguistic structure in story visualization.",
          "citing_paper_id": "253734226",
          "cited_paper_id": 239049842,
          "context_text": "We use three datasets as our testbed, PororoSV [16], FlintstonesSV [18], and VIST [10].",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions three specific datasets used as a testbed for the research. These datasets are likely relevant to personalized text generation as they involve story visualization and structured data.",
          "citing_paper_doi": "10.1109/WACV57701.2024.00290",
          "cited_paper_doi": "10.18653/v1/2021.emnlp-main.543",
          "citing_paper_url": "https://www.semanticscholar.org/paper/33ef78737ba57ecc1ff98c22369a8e17ed90eb98",
          "cited_paper_url": "https://www.semanticscholar.org/paper/ee1d0e141530190a2b0d834737096c5bfda6b304",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "2210455",
      "citation_count": 0,
      "total_dataset_mentions": 3,
      "unique_datasets": [
        "Flickr30k"
      ],
      "dataset_details": [
        {
          "dataset_name": "Flickr30k",
          "dataset_description": "Used to evaluate personalized text generation models, focusing on generating captions that align with visual content.",
          "citing_paper_id": "53022581",
          "cited_paper_id": 945386,
          "context_text": "In this paper we also perform experiments on the COCO [8] and Flickr30k [57] datasets, comparing to a range of models, including both generative models such as in [50, 54, 3] and retrieval based such as in [15, 13, 38].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions two specific datasets, COCO and Flickr30k, which are used for experiments in the paper. These datasets are well-known in the field of image captioning and multimodal reasoning.",
          "citing_paper_doi": "10.1109/CVPR.2019.01280",
          "cited_paper_doi": "10.1109/CVPR.2017.232",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5",
          "citing_paper_year": 2018,
          "cited_paper_year": 2016
        },
        {
          "dataset_name": "Flickr30k",
          "dataset_description": "Used to evaluate personalized text generation models, focusing on generating captions that align with visual content.",
          "citing_paper_id": "53022581",
          "cited_paper_id": 2210455,
          "context_text": "In this paper we also perform experiments on the COCO [8] and Flickr30k [57] datasets, comparing to a range of models, including both generative models such as in [50, 54, 3] and retrieval based such as in [15, 13, 38].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions two specific datasets, COCO and Flickr30k, which are used for experiments in the paper. These datasets are well-known in the field of image captioning and multimodal reasoning.",
          "citing_paper_doi": "10.1109/CVPR.2019.01280",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2",
          "cited_paper_url": "https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628",
          "citing_paper_year": 2018,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "Flickr30k",
          "dataset_description": "Used to evaluate personalized text generation models, focusing on generating captions that align with visual content.",
          "citing_paper_id": "53022581",
          "cited_paper_id": 195347576,
          "context_text": "In this paper we also perform experiments on the COCO [8] and Flickr30k [57] datasets, comparing to a range of models, including both generative models such as in [50, 54, 3] and retrieval based such as in [15, 13, 38].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions two specific datasets, COCO and Flickr30k, which are used for experiments in the paper. These datasets are well-known in the field of image captioning and multimodal reasoning.",
          "citing_paper_doi": "10.1109/CVPR.2019.01280",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2",
          "cited_paper_url": "https://www.semanticscholar.org/paper/faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1",
          "citing_paper_year": 2018,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "16153576",
      "citation_count": 0,
      "total_dataset_mentions": 3,
      "unique_datasets": [
        "PENS"
      ],
      "dataset_details": [
        {
          "dataset_name": "PENS",
          "dataset_description": "Used to construct a personalized headline generation dataset from realistic user interaction data on Microsoft News, focusing on improving user engagement through tailored headlines. | Used to construct a personalized headline generation system, focusing on realistic user interaction data on Microsoft News to enhance personalization in news headlines.",
          "citing_paper_id": "258298303",
          "cited_paper_id": 236460075,
          "context_text": "Finally, Ao et al. (2021) presents a personalized headline generation dataset constructed from realistic user interaction data on Microsoft News.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions a specific dataset 'PENS' used for personalized news headline generation, which is directly relevant to the research topic.",
          "citing_paper_doi": "10.48550/arXiv.2304.11406",
          "cited_paper_doi": "10.18653/v1/2021.acl-long.7",
          "citing_paper_url": "https://www.semanticscholar.org/paper/17170575aa8b4fa4e3eef5d366ada706a94dd836",
          "cited_paper_url": "https://www.semanticscholar.org/paper/90bc51ebd5b676ff31d27a599f36745194d53693",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "PENS",
          "dataset_description": "Used to generate personalized news headlines, focusing on adapting content to individual user preferences and interests.",
          "citing_paper_id": "257427629",
          "cited_paper_id": 16153576,
          "context_text": "…245], sentiment analysis [80, 155, 226], domain classiﬁcation [129, 114, 113], entity resolution [132], and aggression or abuse detection [107, 108]; and are applied to a number of societal domains such as education [118, 163, 241], medicine [3, 15, 225, 235] and news consumption [58, 10, 61, 190].",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context does not mention any specific datasets, only general applications and domains. However, the cited paper 'PENS: A Dataset and Generic Framework for Personalized News Headline Generation' suggests the existence of a dataset called PENS.",
          "citing_paper_doi": "10.48550/arXiv.2303.05453",
          "cited_paper_doi": "10.18653/v1/W15-4506",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e5174aeda1baa67c17f4ac630ae2e44453954cc3",
          "cited_paper_url": "https://www.semanticscholar.org/paper/00be7e98f8e5babba458d0dbf5641e7d7e9b7c7b",
          "citing_paper_year": 2023,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "PENS",
          "dataset_description": "Used to generate personalized news headlines, focusing on adapting content to individual user preferences and interests.",
          "citing_paper_id": "257427629",
          "cited_paper_id": 236460075,
          "context_text": "…245], sentiment analysis [80, 155, 226], domain classiﬁcation [129, 114, 113], entity resolution [132], and aggression or abuse detection [107, 108]; and are applied to a number of societal domains such as education [118, 163, 241], medicine [3, 15, 225, 235] and news consumption [58, 10, 61, 190].",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context does not mention any specific datasets, only general applications and domains. However, the cited paper 'PENS: A Dataset and Generic Framework for Personalized News Headline Generation' suggests the existence of a dataset called PENS.",
          "citing_paper_doi": "10.48550/arXiv.2303.05453",
          "cited_paper_doi": "10.18653/v1/2021.acl-long.7",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e5174aeda1baa67c17f4ac630ae2e44453954cc3",
          "cited_paper_url": "https://www.semanticscholar.org/paper/90bc51ebd5b676ff31d27a599f36745194d53693",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "1055111",
      "citation_count": 0,
      "total_dataset_mentions": 3,
      "unique_datasets": [
        "ArtEmis"
      ],
      "dataset_details": [
        {
          "dataset_name": "ArtEmis",
          "dataset_description": "Used to train neural speakers with two backbone architectures: Show-Attend-Tell and meshed-memory transformers, focusing on generating personalized text based on images.",
          "citing_paper_id": "231639297",
          "cited_paper_id": 1055111,
          "context_text": "We experiment with two popular backbone architectures when designing neural speakers trained on ArtEmis: the Show-Attend-Tell (SAT) approach [62], which combines an image encoder with a word/image attentive LSTM; and the recent line of work of top-down, bottom-up meshed-memory transformers ( M 2 )…",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ArtEmis' as a dataset used for training neural speakers. No other datasets are mentioned that meet the criteria.",
          "citing_paper_doi": "10.1109/CVPR46437.2021.01140",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/3c6a6adffc390f56942b0c8f9b1d246acc7dd1e1",
          "cited_paper_url": "https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd",
          "citing_paper_year": 2021,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "ArtEmis",
          "dataset_description": "Used to fine-tune a pretrained ResNet-32 encoder by minimizing the KL-divergence between the encoder's output and the empirical user distributions, focusing on personalized text generation.",
          "citing_paper_id": "231639297",
          "cited_paper_id": 57246310,
          "context_text": "To address this problem we ﬁne-tune an ImageNet-based [18] pretrained ResNet-32 encoder [26] by minimizing the KL-divergence between its output and the empirical user distributions of ArtEmis.",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ArtEmis' as a source of empirical user distributions, which suggests it is a dataset. However, 'ImageNet' is mentioned only in the context of pretraining the ResNet-32 encoder, so it is excluded.",
          "citing_paper_doi": "10.1109/CVPR46437.2021.01140",
          "cited_paper_doi": "10.1109/CVPR.2009.5206848",
          "citing_paper_url": "https://www.semanticscholar.org/paper/3c6a6adffc390f56942b0c8f9b1d246acc7dd1e1",
          "cited_paper_url": "https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e",
          "citing_paper_year": 2021,
          "cited_paper_year": 2009
        },
        {
          "dataset_name": "ArtEmis",
          "dataset_description": "Used to train neural speakers with two different architectures, focusing on generating personalized text based on images and attention mechanisms.",
          "citing_paper_id": "231639297",
          "cited_paper_id": 206770307,
          "context_text": "We experiment with two popular backbone architectures when designing neural speakers trained on ArtEmis: the Show-Attend-Tell (SAT) approach [62], which combines an image encoder with a word/image attentive LSTM; and the recent line of work of top-down, bottom-up meshed-memory transformers ( M 2 ) [15], which replaces the recurrent units with transformer units and capitalizes on separately computed object-bounding-box detections (computed using Faster R-CNN [25]).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ArtEmis' as a dataset used for training neural speakers. No other datasets are mentioned that meet the criteria.",
          "citing_paper_doi": "10.1109/CVPR46437.2021.01140",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/3c6a6adffc390f56942b0c8f9b1d246acc7dd1e1",
          "cited_paper_url": "https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b",
          "citing_paper_year": 2021,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "155100086",
      "citation_count": 0,
      "total_dataset_mentions": 3,
      "unique_datasets": [
        "Wizard of Wikipedia"
      ],
      "dataset_details": [
        {
          "dataset_name": "Wizard of Wikipedia",
          "dataset_description": "Used to evaluate conversational response generation, focusing on generating contextually relevant and content-rich responses in multi-turn dialogues. | Used to evaluate conversational response generation, focusing on generating contextually relevant and content-specific responses in multi-turn dialogues.",
          "citing_paper_id": "224705337",
          "cited_paper_id": 155100086,
          "context_text": "Table 1: An example from the test set (Test Seen) of Wizard of Wikipedia (Dinan et al., 2019) . such as DialoGPT (Zhang et al., 2019c) have exhibited compelling performance on generating responses that make sense under conversation contexts and at the same time carry speciﬁc content for keeping the conversation going.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Wizard of Wikipedia' as a test set, which is a specific dataset used for evaluating dialogue systems. The other mentions are about models, not datasets.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.272",
          "cited_paper_doi": "10.18653/v1/P19-1499",
          "citing_paper_url": "https://www.semanticscholar.org/paper/3447a432f724aa36595643446acda5b78943db19",
          "cited_paper_url": "https://www.semanticscholar.org/paper/203b543bfa1e564bb80ff4229b43174d7c71b0c0",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "Wizard of Wikipedia",
          "dataset_description": "Used to evaluate conversational response generation, focusing on generating contextually relevant and content-rich responses in multi-turn dialogues. | Used to evaluate conversational response generation, focusing on generating contextually relevant and content-specific responses in multi-turn dialogues.",
          "citing_paper_id": "224705337",
          "cited_paper_id": 195886246,
          "context_text": "Table 1: An example from the test set (Test Seen) of Wizard of Wikipedia (Dinan et al., 2019) . such as DialoGPT (Zhang et al., 2019c) have exhibited compelling performance on generating responses that make sense under conversation contexts and at the same time carry speciﬁc content for keeping the conversation going.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Wizard of Wikipedia' as a test set, which is a specific dataset used for evaluating dialogue systems. The other mentions are about models, not datasets.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.272",
          "cited_paper_doi": "10.18653/v1/P19-1362",
          "citing_paper_url": "https://www.semanticscholar.org/paper/3447a432f724aa36595643446acda5b78943db19",
          "cited_paper_url": "https://www.semanticscholar.org/paper/67262b3ae544f51f7480650b064a740816e194c9",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        },
        {
          "dataset_name": "Wizard of Wikipedia",
          "dataset_description": "Used to evaluate conversational response generation, focusing on generating contextually relevant and content-rich responses in multi-turn dialogues. | Used to evaluate conversational response generation, focusing on generating contextually relevant and content-specific responses in multi-turn dialogues.",
          "citing_paper_id": "224705337",
          "cited_paper_id": 207869708,
          "context_text": "Table 1: An example from the test set (Test Seen) of Wizard of Wikipedia (Dinan et al., 2019) . such as DialoGPT (Zhang et al., 2019c) have exhibited compelling performance on generating responses that make sense under conversation contexts and at the same time carry speciﬁc content for keeping the conversation going.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Wizard of Wikipedia' as a test set, which is a specific dataset used for evaluating dialogue systems. The other mentions are about models, not datasets.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.272",
          "cited_paper_doi": "10.18653/V1/2020.ACL-DEMOS.30",
          "citing_paper_url": "https://www.semanticscholar.org/paper/3447a432f724aa36595643446acda5b78943db19",
          "cited_paper_url": "https://www.semanticscholar.org/paper/388e2fcdcefbe0834e153ab2a0be127092f9674d",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "28695052",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "IMDB dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "IMDB dataset",
          "dataset_description": "Used for comparison and ablation studies in sentiment analysis, evaluating the effectiveness of the UserAdapter method in few-shot user learning scenarios. | Used for comparison and ablation studies in sentiment analysis, assessing the performance of the UserAdapter method in adapting to user-specific sentiments.",
          "citing_paper_id": "238252929",
          "cited_paper_id": 236478014,
          "context_text": "We use the IMDB (Diao et al., 2014) and Yelp (Tang et al., 2015) datasets for comparison with the UserAdapter method (Zhong et al., 2021) and for the ablation studies.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the use of IMDB and Yelp datasets for comparison and ablation studies in sentiment analysis, which is relevant to personalized text generation.",
          "citing_paper_doi": "10.18653/v1/2022.naacl-main.252",
          "cited_paper_doi": "10.18653/v1/2021.findings-acl.129",
          "citing_paper_url": "https://www.semanticscholar.org/paper/49a328730d3c6397820b733bbac903545568cd9c",
          "cited_paper_url": "https://www.semanticscholar.org/paper/331102c42a340e7bcd9a4b063b9b1204f30f665f",
          "citing_paper_year": 2021,
          "cited_paper_year": 2021
        },
        {
          "dataset_name": "IMDB dataset",
          "dataset_description": "Used as the instruction dataset to generate rollouts, collect pairwise feedback data, and for PPO training, focusing on personalized text generation. | Used to fine-tune GPT-2 on movie reviews for supervised fine-tuning, focusing on sentiment analysis and text generation tasks.",
          "citing_paper_id": "275118993",
          "cited_paper_id": 28695052,
          "context_text": "For SFT, we fine-tune GPT-2 until convergence on reviews from the train split of the IMDB dataset and use this GPT-2 backbone for both the reward model and PPO training.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the IMDB dataset, which is a well-known dataset used for sentiment analysis and text classification tasks. It is clearly used for fine-tuning GPT-2 on review data.",
          "citing_paper_doi": "10.48550/arXiv.2402.08925",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/dacc3a8d45968616f220628dc0db8d5d78c1a389",
          "cited_paper_url": "https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
          "citing_paper_year": 2024,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "53298765",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "Dialog NLI dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "Dialog NLI dataset",
          "dataset_description": "Provided the basis for the Dialog NLI dataset, with NLI annotations between persona descriptions and dialogue utterances, enhancing personalized text generation. | Used to train NLI models for evaluating consistency between generated sentences and user comments, focusing on natural language inference in dialogues. | Used to train a sequence classification model for evaluating persona consistency between user comments and generated sentences, focusing on natural language inference annotations. | Provided the basis for the Dialog NLI dataset, used to create a corpus with NLI annotations for evaluating persona consistency in dialogue systems.",
          "citing_paper_id": "234757004",
          "cited_paper_id": 53298765,
          "context_text": "To evaluate persona consistency between user comments and generated sentences, Madotto et al. proposed consistency C score using sequence classiﬁcation model trained on Dialog NLI dataset (Welleck et al., 2019), a corpus based on Persona dataset, with NLI annotation.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'Dialog NLI dataset' and the 'Persona dataset'. Both are specific datasets used in the research for training a sequence classification model to evaluate persona consistency.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.157",
          "cited_paper_doi": "10.18653/v1/P19-1363",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a27ef1cae80d9a72734868b7a5d4e5092452dc31",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1dc04035b9926c46ded436e5762f3924ab29516e",
          "citing_paper_year": 2021,
          "cited_paper_year": 2018
        },
        {
          "dataset_name": "Dialog NLI dataset",
          "dataset_description": "Used to train a Natural Language Inference model, focusing on NLI annotations between persona description sentences and dialogue utterances.",
          "citing_paper_id": "165163819",
          "cited_paper_id": 53298765,
          "context_text": "Aside of standards evaluation metrics, we also train a Natural Language Inference (NLI) model using Dialog NLI (Sean et al., 2018) dataset, a recently proposed corpus based on Persona dataset, with NLI annotation between persona description sentences and dialogues utterance.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the Dialog NLI dataset, which is a specific corpus used for training an NLI model. The dataset is based on the Persona dataset and includes NLI annotations.",
          "citing_paper_doi": "10.18653/v1/P19-1542",
          "cited_paper_doi": "10.18653/v1/P19-1363",
          "citing_paper_url": "https://www.semanticscholar.org/paper/bbc1fa2c9c54d8916469f413fdceb6d4087267a4",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1dc04035b9926c46ded436e5762f3924ab29516e",
          "citing_paper_year": 2019,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "264289231",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "Koala evaluation"
      ],
      "dataset_details": [
        {
          "dataset_name": "Koala evaluation",
          "dataset_description": "Used as the instruction dataset to generate rollouts, collect pairwise feedback data, and for PPO training, focusing on personalized text generation. | Used to test the model's ability to generate answers aligned with different groups of users' preferences, focusing on personalized text generation.",
          "citing_paper_id": "275118993",
          "cited_paper_id": 264289231,
          "context_text": "Following Jang et al. (2023), we use the same 50 instances from Koala evaluation(Geng et al., 2023) and test the model’s ability to generate answers in different groups of users’ preferences.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Koala evaluation' as a specific dataset used for testing the model's ability to generate personalized answers. The dataset is referenced as being used in a similar manner as in Jang et al. (2023).",
          "citing_paper_doi": "10.48550/arXiv.2402.08925",
          "cited_paper_doi": "10.48550/arXiv.2310.11564",
          "citing_paper_url": "https://www.semanticscholar.org/paper/dacc3a8d45968616f220628dc0db8d5d78c1a389",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9bf00afb0efb02a263fa3ddea1e768677498536c",
          "citing_paper_year": 2024,
          "cited_paper_year": 2023
        },
        {
          "dataset_name": "Koala evaluation",
          "dataset_description": "Used to filter out 50 instances requiring open-ended generations for evaluation, focusing on the quality and appropriateness of generated responses.",
          "citing_paper_id": "264289231",
          "cited_paper_id": null,
          "context_text": "Evaluation For evaluation, we manually filter out 50 instances from the Koala evaluation (Geng et al., 2023) that require open-ended generations.",
          "confidence_score": 0.85,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'Koala evaluation' which is used for filtering out specific instances for evaluation. It appears to be a specific dataset or evaluation set.",
          "citing_paper_doi": "10.48550/arXiv.2310.11564",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/9bf00afb0efb02a263fa3ddea1e768677498536c",
          "cited_paper_url": null,
          "citing_paper_year": 2023,
          "cited_paper_year": null
        }
      ]
    },
    {
      "cited_paper_id": "245937117",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "combined preference dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "combined preference dataset",
          "dataset_description": "Used to train and evaluate reinforcement learning with human feedback (RLHF) models, focusing on the alignment of model outputs with human preferences using a single utility reward function.",
          "citing_paper_id": "275118993",
          "cited_paper_id": 245937117,
          "context_text": "To demonstrate our impossibility results as stated in Theorem 1, we perform the three steps of RLHF (described in (Christian, 2020; Ouyang et al., 2022b)) as prevalent currently with a single utility reward function on the combined preference dataset.",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a 'combined preference dataset' which is domain-qualified and relevant to the research on personalized text generation. However, the exact name of the dataset is not provided, only a general description.",
          "citing_paper_doi": "10.48550/arXiv.2402.08925",
          "cited_paper_doi": "10.1111/peps.12500",
          "citing_paper_url": "https://www.semanticscholar.org/paper/dacc3a8d45968616f220628dc0db8d5d78c1a389",
          "cited_paper_url": "https://www.semanticscholar.org/paper/a436dcc635570ed24e7dde7c96acc8df72ebf856",
          "citing_paper_year": 2024,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "combined preference dataset",
          "dataset_description": "Used to train and evaluate reinforcement learning with human feedback (RLHF) models, focusing on the alignment of model outputs with human preferences using a single utility reward function.",
          "citing_paper_id": "275118993",
          "cited_paper_id": 246426909,
          "context_text": "To demonstrate our impossibility results as stated in Theorem 1, we perform the three steps of RLHF (described in (Christian, 2020; Ouyang et al., 2022b)) as prevalent currently with a single utility reward function on the combined preference dataset.",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a 'combined preference dataset' which is domain-qualified and relevant to the research on personalized text generation. However, the exact name of the dataset is not provided, only a general description.",
          "citing_paper_doi": "10.48550/arXiv.2402.08925",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/dacc3a8d45968616f220628dc0db8d5d78c1a389",
          "cited_paper_url": "https://www.semanticscholar.org/paper/d766bffc357127e0dc86dd69561d5aeb520d6f4c",
          "citing_paper_year": 2024,
          "cited_paper_year": 2022
        }
      ]
    },
    {
      "cited_paper_id": "467086",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "Yelp-2016"
      ],
      "dataset_details": [
        {
          "dataset_name": "Yelp-2016",
          "dataset_description": "Used to evaluate recommendation algorithms, specifically comparing performance metrics (MAE, RMSE) across different methods (LRMF, PMF, NMF, SVD++, URP, CTR, RMR, NRT) in the context of personalized text generation.",
          "citing_paper_id": "304614",
          "cited_paper_id": 2095855,
          "context_text": "Books Electronics Movies Yelp-2016\nMAE RMSE MAE RMSE MAE RMSE MAE RMSE\nLRMF 1.939 2.153 2.005 2.203 1.977 2.189 1.809 2.038 PMF 0.882 1.219 1.220 1.612 0.927 1.290 1.320 1.752 NMF 0.731 1.035 0.904 1.297 0.794 1.135 1.062 1.454 SVD++ 0.686 0.967 0.847 1.194 0.745 1.049 1.020 1.349 URP 0.704 0.945 0.860 1.126 0.764 1.006 1.030 1.286 CTR 0.736 0.961 0.903 1.154 0.854 1.069 1.174 1.392 RMR 0.681 0.933 0.822 1.123 0.741 1.005 0.994 1.286 NRT 0.667* 0.927* 0.806* 1.107* 0.702* 0.985* 0.985* 1.277*\n*Statistical significance tests show that our method is better than RMR [21].\nwe notice that the topic modeling based methods CTR and RMR are much better than LRMF, NMF, PMF, and SVD++.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'Yelp-2016' as a dataset used for evaluating various recommendation algorithms. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.1145/3077136.3080822",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/47527f35481e3b16c64e3a27d46499f5efeca096",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6fb07b90b7fd2785ffec0da1069e75c53f7313c2",
          "citing_paper_year": 2017,
          "cited_paper_year": 2000
        },
        {
          "dataset_name": "Yelp-2016",
          "dataset_description": "Used to evaluate recommendation algorithms, specifically comparing performance metrics (MAE, RMSE) across different methods (LRMF, PMF, NMF, SVD++, URP, CTR, RMR, NRT) in the context of personalized text generation.",
          "citing_paper_id": "304614",
          "cited_paper_id": 467086,
          "context_text": "Books Electronics Movies Yelp-2016\nMAE RMSE MAE RMSE MAE RMSE MAE RMSE\nLRMF 1.939 2.153 2.005 2.203 1.977 2.189 1.809 2.038 PMF 0.882 1.219 1.220 1.612 0.927 1.290 1.320 1.752 NMF 0.731 1.035 0.904 1.297 0.794 1.135 1.062 1.454 SVD++ 0.686 0.967 0.847 1.194 0.745 1.049 1.020 1.349 URP 0.704 0.945 0.860 1.126 0.764 1.006 1.030 1.286 CTR 0.736 0.961 0.903 1.154 0.854 1.069 1.174 1.392 RMR 0.681 0.933 0.822 1.123 0.741 1.005 0.994 1.286 NRT 0.667* 0.927* 0.806* 1.107* 0.702* 0.985* 0.985* 1.277*\n*Statistical significance tests show that our method is better than RMR [21].\nwe notice that the topic modeling based methods CTR and RMR are much better than LRMF, NMF, PMF, and SVD++.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'Yelp-2016' as a dataset used for evaluating various recommendation algorithms. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.1145/3077136.3080822",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/47527f35481e3b16c64e3a27d46499f5efeca096",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e19971e7d100386b9b4cf4ea1a0782b62fe036e5",
          "citing_paper_year": 2017,
          "cited_paper_year": 2007
        }
      ]
    },
    {
      "cited_paper_id": "59553505",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "ConvAI2"
      ],
      "dataset_details": [
        {
          "dataset_name": "ConvAI2",
          "dataset_description": "Used to construct a dataset for fine-tuning a pre-trained RoBERTa model for dialogue natural language inference, focusing on consistency and coherence in dialogues. | Used to construct a dataset for fine-tuning a pre-trained RoBERTa model, focusing on dialogue natural language inference tasks.",
          "citing_paper_id": "258823272",
          "cited_paper_id": 53298765,
          "context_text": "A.2 NLI Model NLI model is a triple classification model and can be design as:\nNLI(P,Q,R)\n=  2,if P is consistent with R and Q is coherent with R , 1,if P is consistent with R but Q is not coherent with R\n0,otherwise,\n(18)\nHere NLI (Welleck et al., 2019) is a pre-trained RoBERTa model (Liu et al., 2019), fine-tuned using a dataset constructed based on ConvAI2 and Baidu PersonaChat, and the test set accuracy of NLI model on Chinese and English is 83.2% and 83.1%, respectively.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the use of a dataset constructed from ConvAI2 and Baidu PersonaChat for fine-tuning a pre-trained RoBERTa model. These datasets are relevant to personalized text generation.",
          "citing_paper_doi": "10.48550/arXiv.2305.11482",
          "cited_paper_doi": "10.18653/v1/P19-1363",
          "citing_paper_url": "https://www.semanticscholar.org/paper/6dd3c9f05b319693cb30f700e2f1f128cded7c6f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1dc04035b9926c46ded436e5762f3924ab29516e",
          "citing_paper_year": 2023,
          "cited_paper_year": 2018
        },
        {
          "dataset_name": "ConvAI2",
          "dataset_description": "Used to generate personalized dialogues based on rich personal information, focusing on character-specific facts to enhance conversational intelligence.",
          "citing_paper_id": "258823272",
          "cited_paper_id": 59553505,
          "context_text": "ConvAI2 (Dinan et al., 2019) is an English dataset containing rich personal information, and the dialogues in this dataset are based on the personal facts corresponding to the characters.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions ConvAI2 as an English dataset containing rich personal information, which is directly relevant to personalized text generation.",
          "citing_paper_doi": "10.48550/arXiv.2305.11482",
          "cited_paper_doi": "10.1007/978-3-030-29135-8_7",
          "citing_paper_url": "https://www.semanticscholar.org/paper/6dd3c9f05b319693cb30f700e2f1f128cded7c6f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9ae17b09c59f06f02ef824b856a440de663471d0",
          "citing_paper_year": 2023,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "2239496",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "R EDDIT"
      ],
      "dataset_details": [
        {
          "dataset_name": "R EDDIT",
          "dataset_description": "Used to train and evaluate dialog systems, focusing on the quality of generated responses using a large-scale comment dataset. | Used to train and evaluate dialog systems, focusing on end-to-end learning from user interactions. The dataset provides a large corpus of conversational data for developing and testing dialog models.",
          "citing_paper_id": "52167799",
          "cited_paper_id": 2239496,
          "context_text": "As in (Dodge et al., 2015), we use a preexisting dump of R EDDIT that consists of 1.7 billion comments.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions a 'preexisting dump of R EDDIT' which is a specific, identifiable dataset. It is used for training and evaluation in the context of dialog systems.",
          "citing_paper_doi": "10.18653/v1/D18-1298",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/dde89e64a7f375b90e1cc594142940f4161e1592",
          "cited_paper_url": "https://www.semanticscholar.org/paper/be3a65ef15f79ebb8296e6a0e8d1a9cb5c0f3638",
          "citing_paper_year": 2018,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "R EDDIT",
          "dataset_description": "Used to tokenize and lowercase text using the NLTK tokenizer, focusing on preprocessing for natural language processing tasks.",
          "citing_paper_id": "19096382",
          "cited_paper_id": null,
          "context_text": "The Reddit and SCOTUS data are tokenized and lower-cased using the standard NLTK tokenizer (Bird et al., 2009).",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'Reddit' and 'SCOTUS' data, which are specific datasets used in the research. However, they are not clearly identified as datasets in the citation context.",
          "citing_paper_doi": "10.1162/tacl_a_00035",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/5835af39301c156456a1c7168f44ba9321b50278",
          "cited_paper_url": null,
          "citing_paper_year": 2017,
          "cited_paper_year": null
        }
      ]
    },
    {
      "cited_paper_id": "16447573",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "SogouCS&CA corpus (2008 version)"
      ],
      "dataset_details": [
        {
          "dataset_name": "SogouCS&CA corpus (2008 version)",
          "dataset_description": "Used to train word embeddings for Chinese text analysis, specifically focusing on the 2008 version of the corpus.",
          "citing_paper_id": "6862403",
          "cited_paper_id": 16447573,
          "context_text": "ponse generation model are as follow: The dimension of the hidden layer of the encoder and decoder is 1,024. The dimension of the word embedding is 500 which is obtained by using the word2vec toolkit [29]. The word2vec is trained with the SogouCS&amp;CA corpus (2008 version)2, which is widely used for Chinese text analysis [30, 31]. The details of the training corpus for training word embedding are sh",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the 'SogouCS&CA corpus' as a specific dataset used for training word embeddings, which is relevant to personalized text generation.",
          "citing_paper_doi": "10.1007/s11280-018-0598-6",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/ba3975cd4dea504142b6d423c8b70790407cfb07",
          "cited_paper_url": "https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f",
          "citing_paper_year": 2017,
          "cited_paper_year": 2013
        },
        {
          "dataset_name": "SogouCS&CA corpus (2008 version)",
          "dataset_description": "Used to train word2vec for Chinese text analysis, focusing on the construction of word vectors for natural language processing tasks.",
          "citing_paper_id": "6862403",
          "cited_paper_id": 1003702,
          "context_text": "The word2vec is trained with the SogouCS&CA corpus (2008 version) 2 , which is widely used for Chinese text analysis [30, 31].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the SogouCS&CA corpus, which is a specific dataset used for training word2vec for Chinese text analysis.",
          "citing_paper_doi": "10.1007/s11280-018-0598-6",
          "cited_paper_doi": "10.1145/1367497.1367560",
          "citing_paper_url": "https://www.semanticscholar.org/paper/ba3975cd4dea504142b6d423c8b70790407cfb07",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e0bcc6467b13a7971ee72d8eee49011121006e73",
          "citing_paper_year": 2017,
          "cited_paper_year": 2008
        }
      ]
    },
    {
      "cited_paper_id": "1139492",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "Ubuntu Dialogue Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "Ubuntu Dialogue Corpus",
          "dataset_description": "Used to develop and evaluate unstructured multi-turn dialogue systems, providing a large dataset for training and testing conversational models.",
          "citing_paper_id": "20956365",
          "cited_paper_id": 1139492,
          "context_text": "In particular, dialog or conversational models too have received a lot of attention due to its wide range of applications in human-machine interaction such as personal assistants, technical support for products and services, entertainment, to name a few [Lowe et al., 2015; Serban et al., 2016a; Wen et al., 2015; Li et al., 2016b; Sordoni et al., 2015].",
          "confidence_score": 0.85,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions dialog and conversational models but does not specify any datasets. However, the cited paper 'The Ubuntu Dialogue Corpus' suggests a relevant dataset.",
          "citing_paper_doi": "10.24963/ijcai.2017/521",
          "cited_paper_doi": "10.18653/v1/W15-4639",
          "citing_paper_url": "https://www.semanticscholar.org/paper/feae6b488b039a979afd5776890227a227428148",
          "cited_paper_url": "https://www.semanticscholar.org/paper/337e64d4bcd09b984243771b6902bf4d8fa0c730",
          "citing_paper_year": 2017,
          "cited_paper_year": 2015
        },
        {
          "dataset_name": "Ubuntu Dialogue Corpus",
          "dataset_description": "Used to develop and evaluate unstructured multi-turn dialogue systems, providing a large dataset for training and testing conversational models.",
          "citing_paper_id": "20956365",
          "cited_paper_id": 8379583,
          "context_text": "In particular, dialog or conversational models too have received a lot of attention due to its wide range of applications in human-machine interaction such as personal assistants, technical support for products and services, entertainment, to name a few [Lowe et al., 2015; Serban et al., 2016a; Wen et al., 2015; Li et al., 2016b; Sordoni et al., 2015].",
          "confidence_score": 0.85,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions dialog and conversational models but does not specify any datasets. However, the cited paper 'The Ubuntu Dialogue Corpus' suggests a relevant dataset.",
          "citing_paper_doi": "10.24963/ijcai.2017/521",
          "cited_paper_doi": "10.18653/v1/w15-4640",
          "citing_paper_url": "https://www.semanticscholar.org/paper/feae6b488b039a979afd5776890227a227428148",
          "cited_paper_url": "https://www.semanticscholar.org/paper/916441619914101258c71669b5ccc36424b54a6c",
          "citing_paper_year": 2017,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "235097294",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "HONEST"
      ],
      "dataset_details": [
        {
          "dataset_name": "HONEST",
          "dataset_description": "Used to measure hurtful sentence completion in language models, specifically evaluating the generation of harmful content.",
          "citing_paper_id": "257427629",
          "cited_paper_id": 222090785,
          "context_text": "For example, there are extensive works documenting LLMs on fairness and bias [2, 115, 143, 162, 166, 191, 205, 222]; truthfulness, uncertainty, or hallucination [130, 106, 102]; robustness [208, 112]; privacy [35]; and toxicity [72, 171].",
          "confidence_score": 0.85,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation span does not mention any specific datasets, only general categories of research. However, the cited paper titles suggest the presence of specific datasets.",
          "citing_paper_doi": "10.48550/arXiv.2303.05453",
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.154",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e5174aeda1baa67c17f4ac630ae2e44453954cc3",
          "cited_paper_url": "https://www.semanticscholar.org/paper/645bd6eadc247989abc5e0b0aa0be79ec8b11ea6",
          "citing_paper_year": 2023,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "HONEST",
          "dataset_description": "Used to measure hurtful sentence completion in language models, specifically evaluating the generation of harmful content.",
          "citing_paper_id": "257427629",
          "cited_paper_id": 235097294,
          "context_text": "For example, there are extensive works documenting LLMs on fairness and bias [2, 115, 143, 162, 166, 191, 205, 222]; truthfulness, uncertainty, or hallucination [130, 106, 102]; robustness [208, 112]; privacy [35]; and toxicity [72, 171].",
          "confidence_score": 0.85,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation span does not mention any specific datasets, only general categories of research. However, the cited paper titles suggest the presence of specific datasets.",
          "citing_paper_doi": "10.48550/arXiv.2303.05453",
          "cited_paper_doi": "10.18653/V1/2021.NAACL-MAIN.191",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e5174aeda1baa67c17f4ac630ae2e44453954cc3",
          "cited_paper_url": "https://www.semanticscholar.org/paper/4f76d26369ee573cb03db4b9f6e4ab5d61806095",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "221655075",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "PERPLEXITY API"
      ],
      "dataset_details": [
        {
          "dataset_name": "PERPLEXITY API",
          "dataset_description": "Used to evaluate n-gram diversity and GPT-2 XL perplexity as proxies for fluency and diversity in generated text, focusing on the quality and safety of the outputs. | Used to calculate toxicity scores on full generation sequences, providing a measure of the model's output quality and potential harmfulness.",
          "citing_paper_id": "259064099",
          "cited_paper_id": 221655075,
          "context_text": "We follow previous work [17, 21] to report the toxicity score calculated on each full generation sequence from the PERPLEXITY API, as well as other commonly used metrics for REALTOXICITYPROMPTS, including n-gram diversity and GPT-2 XL perplexity (PPL) as a proxy for fluency.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the use of the PERPLEXITY API and REALTOXICITYPROMPTS, which are specific resources used for evaluating the toxicity and quality of generated text.",
          "citing_paper_doi": "10.48550/arXiv.2306.01693",
          "cited_paper_doi": "10.18653/v1/2021.findings-emnlp.424",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e2e52461194bc81351da7caa978ac42e9e9549cc",
          "cited_paper_url": "https://www.semanticscholar.org/paper/07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6",
          "citing_paper_year": 2023,
          "cited_paper_year": 2020
        },
        {
          "dataset_name": "PERPLEXITY API",
          "dataset_description": "Used to evaluate n-gram diversity and GPT-2 XL perplexity as proxies for fluency and diversity in generated text, focusing on the quality and safety of the outputs. | Used to calculate toxicity scores on full generation sequences, providing a measure of the model's output quality and potential harmfulness.",
          "citing_paper_id": "259064099",
          "cited_paper_id": 235313967,
          "context_text": "We follow previous work [17, 21] to report the toxicity score calculated on each full generation sequence from the PERPLEXITY API, as well as other commonly used metrics for REALTOXICITYPROMPTS, including n-gram diversity and GPT-2 XL perplexity (PPL) as a proxy for fluency.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the use of the PERPLEXITY API and REALTOXICITYPROMPTS, which are specific resources used for evaluating the toxicity and quality of generated text.",
          "citing_paper_doi": "10.48550/arXiv.2306.01693",
          "cited_paper_doi": "10.18653/v1/2021.acl-long.522",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e2e52461194bc81351da7caa978ac42e9e9549cc",
          "cited_paper_url": "https://www.semanticscholar.org/paper/02f033482b8045c687316ef81ba7aaae9f0a2e1c",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "248405661",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "NL human feedback"
      ],
      "dataset_details": [
        {
          "dataset_name": "NL human feedback",
          "dataset_description": "Used to collect and store natural language human feedback in a feedback memory, which the model retrieves to condition its performance on end tasks, enhancing model adaptability and user interaction.",
          "citing_paper_id": "259064099",
          "cited_paper_id": 246016194,
          "context_text": "[23, 6] collect and store NL human feedback in a feedback memory for the model to retrieve and then perform the end task conditioning on the retrieved feedback.",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'NL human feedback' which is domain-qualified data but does not specify a named dataset. The cited papers do not provide additional specific dataset names.",
          "citing_paper_doi": "10.48550/arXiv.2306.01693",
          "cited_paper_doi": "10.18653/v1/2022.emnlp-main.183",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e2e52461194bc81351da7caa978ac42e9e9549cc",
          "cited_paper_url": "https://www.semanticscholar.org/paper/448e1493034dafe35699ae054ff4480b31dcf64a",
          "citing_paper_year": 2023,
          "cited_paper_year": 2022
        },
        {
          "dataset_name": "NL human feedback",
          "dataset_description": "Used to collect and store natural language human feedback in a feedback memory, which the model retrieves to condition its performance on end tasks, enhancing model adaptability and user interaction.",
          "citing_paper_id": "259064099",
          "cited_paper_id": 248405661,
          "context_text": "[23, 6] collect and store NL human feedback in a feedback memory for the model to retrieve and then perform the end task conditioning on the retrieved feedback.",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'NL human feedback' which is domain-qualified data but does not specify a named dataset. The cited papers do not provide additional specific dataset names.",
          "citing_paper_doi": "10.48550/arXiv.2306.01693",
          "cited_paper_doi": "10.48550/arXiv.2204.13074",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e2e52461194bc81351da7caa978ac42e9e9549cc",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e7d75b80e0fa3ae190ff91676dbf18a006d3a311",
          "citing_paper_year": 2023,
          "cited_paper_year": 2022
        }
      ]
    },
    {
      "cited_paper_id": "53039332",
      "citation_count": 0,
      "total_dataset_mentions": 2,
      "unique_datasets": [
        "UESTC dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "UESTC dataset",
          "dataset_description": "Used to extract SMPL sequences and evaluate a pre-trained action recognition model, focusing on human action recognition in the context of personalized text generation. | Used as a benchmark for action-conditioned motion generation tasks, including 25K motion sequences across 40 action categories, to evaluate the performance of models in generating personalized text based on actions.",
          "citing_paper_id": "251953565",
          "cited_paper_id": 53039332,
          "context_text": "ACTOR [2] further uses pre-trained VIBE [83] to extract SMPL [84] sequences from the UESTC dataset and provides pretrained action recognition model for evaluation.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the UESTC dataset, which is a specific, verifiable dataset used for human action recognition. The dataset is used to extract SMPL sequences and evaluate a pre-trained action recognition model.",
          "citing_paper_doi": "10.1109/TPAMI.2024.3355414",
          "cited_paper_doi": "10.1145/3240508.3240675",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1bbf99b5bfe9869876ac3bdd2999e16b2632c283",
          "cited_paper_url": "https://www.semanticscholar.org/paper/8f888a870545af2735118bbd6358ffa68f1e386f",
          "citing_paper_year": 2022,
          "cited_paper_year": 2018
        },
        {
          "dataset_name": "UESTC dataset",
          "dataset_description": "Used to extract SMPL sequences and evaluate a pre-trained action recognition model, focusing on human action recognition in the context of personalized text generation.",
          "citing_paper_id": "251953565",
          "cited_paper_id": 233210075,
          "context_text": "ACTOR [2] further uses pre-trained VIBE [83] to extract SMPL [84] sequences from the UESTC dataset and provides pretrained action recognition model for evaluation.",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the UESTC dataset, which is a specific, verifiable dataset used for human action recognition. The dataset is used to extract SMPL sequences and evaluate a pre-trained action recognition model.",
          "citing_paper_doi": "10.1109/TPAMI.2024.3355414",
          "cited_paper_doi": "10.1109/ICCV48922.2021.01080",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1bbf99b5bfe9869876ac3bdd2999e16b2632c283",
          "cited_paper_url": "https://www.semanticscholar.org/paper/4d44de6653f6192efba8aef36f814d4c0420f21d",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "224270828",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Yelp (restaurant)"
      ],
      "dataset_details": [
        {
          "dataset_name": "Yelp (restaurant)",
          "dataset_description": "Used to evaluate explainable recommendation systems, focusing on user reviews and ratings for restaurants. | Used to evaluate explainable recommendation systems, focusing on user reviews and ratings for movies and TV shows.",
          "citing_paper_id": "235187032",
          "cited_paper_id": 224270828,
          "context_text": "For experimentation, we adopt three publicly available explainable recommendation datasets, and their data splits (Li et al., 2020c (hotel), Amazon (movies & TV) and Yelp (restaurant).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions three specific datasets used for experimentation in explainable recommendation systems.",
          "citing_paper_doi": "10.18653/v1/2021.acl-long.383",
          "cited_paper_doi": "10.1145/3340531.3411992",
          "citing_paper_url": "https://www.semanticscholar.org/paper/0c9a2adda11ed49d091948211fcfd517113b5243",
          "cited_paper_url": "https://www.semanticscholar.org/paper/20cfb6eaf5e3c06af379fb161a84297b88ab1b9c",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "222090785",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "CrowSPairs"
      ],
      "dataset_details": [
        {
          "dataset_name": "CrowSPairs",
          "dataset_description": "Used to evaluate gender bias in language models, specifically measuring pronoun resolution in gendered contexts. | Applied to assess social biases in masked language models, focusing on stereotypical associations and fairness.",
          "citing_paper_id": "246426909",
          "cited_paper_id": 222090785,
          "context_text": "InstructGPT does not significantly improve over GPT-3 on the Winogender (Rudinger et al., 2018) and CrowSPairs (Nangia et al., 2020) datasets.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions two specific datasets, Winogender and CrowSPairs, which are used to measure performance on social biases in language models.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.154",
          "citing_paper_url": "https://www.semanticscholar.org/paper/d766bffc357127e0dc86dd69561d5aeb520d6f4c",
          "cited_paper_url": "https://www.semanticscholar.org/paper/645bd6eadc247989abc5e0b0aa0be79ec8b11ea6",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "239009562",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "FLAN"
      ],
      "dataset_details": [
        {
          "dataset_name": "FLAN",
          "dataset_description": "Used to fine-tune GPT-3 on a variety of NLP tasks with natural language instructions, focusing on zero-shot task generalization. | Used to fine-tune GPT-3 baselines, focusing on multitask prompted training for zero-shot task generalization.",
          "citing_paper_id": "246426909",
          "cited_paper_id": 239009562,
          "context_text": "In Figure 5a, we also compare InstructGPT to our 175B GPT-3 baselines fine-tuned on the FLAN (Wei et al., 2021) and T0 (Sanh et al., 2021) datasets (see Appendix D for details).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions 'FLAN' and 'T0' datasets, which are specific and verifiable resources used for fine-tuning models.",
          "citing_paper_doi": null,
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/d766bffc357127e0dc86dd69561d5aeb520d6f4c",
          "cited_paper_url": "https://www.semanticscholar.org/paper/17dd3555fd1ccf1141cf984347fa1b3fd6b009ca",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "257985497",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Personalized-Soups"
      ],
      "dataset_details": [
        {
          "dataset_name": "Personalized-Soups",
          "dataset_description": "Used to evaluate instruction following under different user preference profiles, specifically analyzing pairwise feedback for responses to GPT4-Alpaca instructions. | Used to conduct pairwise comparisons of responses to GPT-4 Alpaca instructions, focusing on personalized text generation and evaluating model performance. | Used to collect and analyze pairwise feedback for responses to instructions in GPT-4 Alpaca, focusing on improving personalized text generation through user preferences.",
          "citing_paper_id": "267547503",
          "cited_paper_id": 257985497,
          "context_text": "(2) Instruction Following under Different Preference Profiles: we use the Personalized-Soups dataset [17], which includes pairwise feedback for responses to GPT4-Alpaca instructions [26] under various user preference profiles, and Tulu-7B [38], an instruction fine-tuned LLaMA-7B model, as the SFT.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'Personalized-Soups' dataset, which is used for evaluating instruction following under different user preference profiles. The dataset includes pairwise feedback for responses to GPT4-Alpaca instructions.",
          "citing_paper_doi": "10.48550/arXiv.2402.05133",
          "cited_paper_doi": "10.48550/arXiv.2304.03277",
          "citing_paper_url": "https://www.semanticscholar.org/paper/4dcccc23c169293df73da1390c7af32ab47f3995",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9e8cb8c91a0acb6e661b58ad724aa758490f2bea",
          "citing_paper_year": 2024,
          "cited_paper_year": 2023
        }
      ]
    },
    {
      "cited_paper_id": "52967399",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "empathetic conversations"
      ],
      "dataset_details": [
        {
          "dataset_name": "empathetic conversations",
          "dataset_description": "Used to train and evaluate Transformer-based generative and BERT-based retrieval models for empathy in conversations, focusing on improving empathetic responses in dialogue systems.",
          "citing_paper_id": "271403894",
          "cited_paper_id": 52967399,
          "context_text": "Recently, Rashkin et al. (2019) presented a new dataset and benchmark towards empathetic conversations and found that both Transformer-based generative models (Vaswani et al., 2017) and BERT-based retrieval models (Devlin et al., 2019) relying on this dataset exhibit stronger empathy.",
          "confidence_score": 0.85,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a new dataset and benchmark for empathetic conversations, which is directly relevant to personalized text generation. The dataset is used to train and evaluate models for empathy in conversations.",
          "citing_paper_doi": "10.18653/v1/2020.emnlp-main.531",
          "cited_paper_doi": "10.18653/v1/N19-1423",
          "citing_paper_url": "https://www.semanticscholar.org/paper/7b73f7e59fe584a8760d86731fec503e2ae8b52c",
          "cited_paper_url": "https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992",
          "citing_paper_year": 2020,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "59316441",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "PersonalDialog"
      ],
      "dataset_details": [
        {
          "dataset_name": "PersonalDialog",
          "dataset_description": "Used to generate personalized dialogues with diversified traits, focusing on enhancing conversational diversity and personalization in chatbot interactions. | Used to train and evaluate personalized dialogue systems, focusing on generating diverse and contextually appropriate responses in a Chinese social media setting. | Used to generate personalized dialogues, focusing on incorporating diversified traits into conversational responses.",
          "citing_paper_id": "234757004",
          "cited_paper_id": 59316441,
          "context_text": "PD denotes the PersonalDialog dataset (Zheng et al., 2020).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context clearly identifies 'PersonalDialog' as a dataset, which is used for personalized dialogue generation.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.157",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/a27ef1cae80d9a72734868b7a5d4e5092452dc31",
          "cited_paper_url": "https://www.semanticscholar.org/paper/a3ce3004a0eade48a3ae652dbf5c04a60c2416aa",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "210868223",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Pushshift Reddit Dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "Pushshift Reddit Dataset",
          "dataset_description": "Used to provide raw data for preprocessing user attributes, focusing on reproducibility of models and scripts.",
          "citing_paper_id": "234757004",
          "cited_paper_id": 210868223,
          "context_text": "We only released raw data from pushshift.io( Baumgartner et al. (2020)), and open-sourced our scripts for preprocessing user attributes and models for reproducibility.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'raw data from pushshift.io', which is a specific dataset. The cited paper title confirms it is a dataset.",
          "citing_paper_doi": "10.18653/V1/2021.NAACL-MAIN.157",
          "cited_paper_doi": "10.5281/ZENODO.3608135",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a27ef1cae80d9a72734868b7a5d4e5092452dc31",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1a6f4495474f75ae1e8bbf407f70d9a874e5b4d6",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "257834040",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "dataset for evaluating the alignment of language models with 60 US demographic groups"
      ],
      "dataset_details": [
        {
          "dataset_name": "dataset for evaluating the alignment of language models with 60 US demographic groups",
          "dataset_description": "Used to assess the alignment of language models with 60 US demographic groups across various topics, identifying significant misalignment issues.",
          "citing_paper_id": "275118993",
          "cited_paper_id": 257834040,
          "context_text": "Recently (Santurkar et al., 2023) created a dataset for evaluating the alignment of language models with 60 US demographic groups over a wide range of topics and found substantial misalignment between a selanguage models and those groups.",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions a specific dataset created by Santurkar et al. (2023) for evaluating language model alignment with US demographic groups.",
          "citing_paper_doi": "10.48550/arXiv.2402.08925",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/dacc3a8d45968616f220628dc0db8d5d78c1a389",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e38a29f6463f38f43797b128673b9e44d18a991e",
          "citing_paper_year": 2024,
          "cited_paper_year": 2023
        }
      ]
    },
    {
      "cited_paper_id": "207869708",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Chinese Weibo"
      ],
      "dataset_details": [
        {
          "dataset_name": "Chinese Weibo",
          "dataset_description": "Used to conduct experiments on personalized text generation, focusing on social media posts to analyze user-specific language patterns and interactions.",
          "citing_paper_id": "252918698",
          "cited_paper_id": 207869708,
          "context_text": "Following previous study (Ma et al., 2021b), we conduct experiments on two datasets from Chinese Weibo (Qian et al., 2021) and English Red-dit (Zhang et al., 2020a).",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions two datasets, one from Chinese Weibo and another from English Reddit, which are used for conducting experiments. These datasets are specific and relevant to the topic of personalized text generation.",
          "citing_paper_doi": "10.48550/arXiv.2210.08753",
          "cited_paper_doi": "10.18653/V1/2020.ACL-DEMOS.30",
          "citing_paper_url": "https://www.semanticscholar.org/paper/50e405cf242bf603cf43df9df803f5265557bfe1",
          "cited_paper_url": "https://www.semanticscholar.org/paper/388e2fcdcefbe0834e153ab2a0be127092f9674d",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "12383522",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "MeMo FC corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "MeMo FC corpus",
          "dataset_description": "Used to achieve personalization through the use of more 'biased' emotional language, focusing on the impact of emotional content in text generation. | Used to derive sentence templates for personalized text generation, focusing on the structure and content of soccer reportage in multiple languages.",
          "citing_paper_id": "2364329",
          "cited_paper_id": 12383522,
          "context_text": "To achieve this, the templates were derived from sentences in the MeMo FC corpus (Braun et al., 2016).",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'MeMo FC corpus', which is a specific dataset used for deriving templates. The cited paper title does not contradict this being a dataset.",
          "citing_paper_doi": "10.18653/v1/W17-3513",
          "cited_paper_doi": "10.18653/v1/W16-6612",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c5242ab42f2add67fcf04c5ab1ef93d63693a1db",
          "cited_paper_url": "https://www.semanticscholar.org/paper/8700ebd18e6f9726717ecb57dcc9503dfd50306b",
          "citing_paper_year": 2017,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "235458009",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "360PanoI"
      ],
      "dataset_details": [
        {
          "dataset_name": "360PanoI",
          "dataset_description": "Used for fine-tuning paired image-text data, focusing on improving model performance in generating personalized text based on visual inputs.",
          "citing_paper_id": "264590753",
          "cited_paper_id": 235458009,
          "context_text": "The paired image-text data used during the ﬁne-tuning process are from our collected 360PanoI dataset.",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a specific dataset '360PanoI' which is used for fine-tuning paired image-text data. The dataset name is specific and plausible.",
          "citing_paper_doi": "10.1109/WACV57701.2024.00486",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/3e5e06bc5624b2408fec03c301cfe6c3a48747fa",
          "cited_paper_url": "https://www.semanticscholar.org/paper/a8ca46b171467ceb2d7652fbfb67fe701ad86092",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "5450801",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Douban Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "Douban Corpus",
          "dataset_description": "Used to train and evaluate multi-turn response selection in retrieval-based chatbots, focusing on conversational context and relevance in a Chinese social networking environment.",
          "citing_paper_id": "221971391",
          "cited_paper_id": 5450801,
          "context_text": "(2) Douban Corpus (Wu et al. 2017): consists of multi-turn conversations from the Douban group 3 , which is a popular social networking service in China.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a specific dataset, 'Douban Corpus', which is used for multi-turn conversations from a popular Chinese social networking service. This dataset is directly relevant to personalized text generation.",
          "citing_paper_doi": "10.1609/aaai.v35i16.17668",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/40b1ea56c49751366b05f90f91f98d9d4a12e290",
          "cited_paper_url": "https://www.semanticscholar.org/paper/a6eec00f10346ce27d4f69f9e38f5665fffe8056",
          "citing_paper_year": 2020,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "49411029",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "E-commerce Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "E-commerce Corpus",
          "dataset_description": "Used to demonstrate topic shifts in multi-turn conversations, focusing on commodity consultation, logistics express, recommendation, and chitchat. | Used to model multi-turn conversations between customers and shopkeepers on Taobao, focusing on deep utterance aggregation techniques to improve dialogue systems. | Used to model multi-turn conversations in e-commerce settings, focusing on deep utterance aggregation techniques to improve dialogue systems.",
          "citing_paper_id": "221971391",
          "cited_paper_id": 49411029,
          "context_text": "The E-commerce Corpus has an obvious topic shift, including commodity consultation, logistics express, recommendation, and chitchat.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions a specific dataset, 'E-commerce Corpus', which is used to illustrate topic shifts in multi-turn conversations.",
          "citing_paper_doi": "10.1609/aaai.v35i16.17668",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/40b1ea56c49751366b05f90f91f98d9d4a12e290",
          "cited_paper_url": "https://www.semanticscholar.org/paper/977ad9f0ee96707b8b7de76afcd4df40a9c7a69e",
          "citing_paper_year": 2020,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "146120595",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Wikipedia"
      ],
      "dataset_details": [
        {
          "dataset_name": "Wikipedia",
          "dataset_description": "Used to incorporate external product knowledge into personalized product description generation, enhancing the effectiveness of user-cared aspects.",
          "citing_paper_id": "232092620",
          "cited_paper_id": 146120595,
          "context_text": "To enhance the effectiveness of user-cared aspects, other researchers (Chen et al. 2019a,b) propose to incorporate customer’s personalized proﬁles and/or external product knowledge from Wikipedia to generate product descriptions.",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions incorporating customer’s personalized profiles and external product knowledge from Wikipedia, which suggests the use of specific datasets or sources of information.",
          "citing_paper_doi": "10.1609/aaai.v35i16.17682",
          "cited_paper_doi": "10.1145/3292500.3330652",
          "citing_paper_url": "https://www.semanticscholar.org/paper/a60d1026ce915cb8b03c9a4522cc432646f46f9f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/4330aab5e043be0bc4d4c386a6ff72b99b7b4409",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "216009",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "CelebA-HQ"
      ],
      "dataset_details": [
        {
          "dataset_name": "CelebA-HQ",
          "dataset_description": "Used to recognize faces across pose and age, focusing on high-quality images and diverse attributes for personalized text generation.",
          "citing_paper_id": "257766375",
          "cited_paper_id": 216009,
          "context_text": "Based on those criteria, we select two famous face datasets CelebA-HQ [28] and VGGFace2 [11].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions two specific datasets, CelebA-HQ and VGGFace2, which are used for recognizing faces across pose and age. These datasets are clearly identified and relevant to the research topic.",
          "citing_paper_doi": "10.1109/ICCV51070.2023.00202",
          "cited_paper_doi": "10.1109/FG.2018.00020",
          "citing_paper_url": "https://www.semanticscholar.org/paper/d544dd9a6ba9ea5f2c1217bc554cf7fded732fbf",
          "cited_paper_url": "https://www.semanticscholar.org/paper/70c59dc3470ae867016f6ab0e008ac8ba03774a1",
          "citing_paper_year": 2023,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "221005871",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Harvard sentence corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "Harvard sentence corpus",
          "dataset_description": "Used to generate novel sentences for creating transfer stimuli, focusing on the application of median attention weights from the GSP iteration to study personalized text generation.",
          "citing_paper_id": "233739719",
          "cited_paper_id": 221005871,
          "context_text": "We created 156 transfer stimuli by applying the median attention weights of the final GSP iteration to four novel sentences from the Harvard sentence corpus.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the 'Harvard sentence corpus' as a source of novel sentences for creating transfer stimuli. This corpus is a well-known linguistic resource.",
          "citing_paper_doi": "10.21437/Interspeech.2021-1538",
          "cited_paper_doi": "10.17605/OSF.IO/RZK4S",
          "citing_paper_url": "https://www.semanticscholar.org/paper/abf443e48497c5b8d51f1c3a1902fdac031e590e",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b7d8456790cbfccec23b06c354200ee79d8b374e",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "unknown",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "YelpR8"
      ],
      "dataset_details": [
        {
          "dataset_name": "YelpR8",
          "dataset_description": "Used for training and testing personalized text generation models, focusing on the scalability and performance across development and test sets.",
          "citing_paper_id": "9135567",
          "cited_paper_id": null,
          "context_text": "We use the one-fifth training set in the previous experiment of YelpR8 data as our training data, and test on both development and test sets, which have same scales with the sets used in [Tang et al., 2015b; Chen et al., 2016] .",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'YelpR8 data' as a specific dataset used for training and testing. The dataset is clearly identified and used in a specific research context.",
          "citing_paper_doi": "10.24963/ijcai.2017/547",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/2428310bf9343383e3de7a45bb8002acbc044692",
          "cited_paper_url": null,
          "citing_paper_year": 2017,
          "cited_paper_year": null
        }
      ]
    },
    {
      "cited_paper_id": "207246940",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "dataset presented in (Xu et al., 2017)"
      ],
      "dataset_details": [
        {
          "dataset_name": "dataset presented in (Xu et al., 2017)",
          "dataset_description": "Used to experiment with a variety of customer service properties, focusing on chatbot interactions on social media platforms.",
          "citing_paper_id": "34405847",
          "cited_paper_id": 207246940,
          "context_text": "For our experiments we utilized the dataset presented in (Xu et al., 2017), which exhibits a large variety of customer service properties.",
          "confidence_score": 0.85,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a specific dataset from Xu et al., 2017, which is used for experiments involving customer service properties. The title confirms it is a chatbot-related dataset.",
          "citing_paper_doi": "10.18653/v1/W17-3541",
          "cited_paper_doi": "10.1145/3025453.3025496",
          "citing_paper_url": "https://www.semanticscholar.org/paper/24f5bbd587a6b3e20a0e44f7933aa72a8bdee9c2",
          "cited_paper_url": "https://www.semanticscholar.org/paper/90bd099501147609165971b27b5514a2b9c2a7e7",
          "citing_paper_year": 2017,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "219305429",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Response to Livebot dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "Response to Livebot dataset",
          "dataset_description": "Used to generate live video comments based on visual and textual contexts, focusing on the interaction between video content and user-generated comments.",
          "citing_paper_id": "235097581",
          "cited_paper_id": 219305429,
          "context_text": "Part of the data (2,322 videos and 857,993 comments) comes from the publicly available automatic danmu generation Response to Livebot dataset (Wu et al., 2020).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a specific dataset with a clear name and reference, which is relevant to the topic of personalized text generation.",
          "citing_paper_doi": "10.18653/V1/2021.MAIWORKSHOP-1.8",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/af0aa14e280f81aa87eeca63889e07219797e083",
          "cited_paper_url": "https://www.semanticscholar.org/paper/4309406506ea2fbeea8cb7b7f633a2b6f931992a",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "269009728",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "W ORK S M"
      ],
      "dataset_details": [
        {
          "dataset_name": "W ORK S M",
          "dataset_description": "Used to compute auxiliary probabilities in Eq (1) for AITA, focusing on personalizing large language models through retrieval augmentation. The dataset contains private user data.",
          "citing_paper_id": "265213422",
          "cited_paper_id": 269009728,
          "context_text": "Prompt 5: f aux prompt used to compute p aux ( t u | q u ) in Eq (1) for AITA. annotators external to the authors weren’t recruited for authoring requests due to the private nature of the W ORK S M dataset.",
          "confidence_score": 0.6,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'W ORK S M dataset' which appears to be a specific dataset used in the research. However, the name is not clearly defined and seems to be a placeholder or internal reference.",
          "citing_paper_doi": "10.48550/arXiv.2311.09180",
          "cited_paper_doi": "10.1145/3626772.3657783",
          "citing_paper_url": "https://www.semanticscholar.org/paper/35f0cf9f70c408dbaf106e6a675244e2867c164e",
          "cited_paper_url": "https://www.semanticscholar.org/paper/dd416e705a68419edb1cb840a6daa43cc8822c2b",
          "citing_paper_year": 2023,
          "cited_paper_year": 2024
        }
      ]
    },
    {
      "cited_paper_id": "3939596",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "BabyTalk"
      ],
      "dataset_details": [
        {
          "dataset_name": "BabyTalk",
          "dataset_description": "Used to generate personalized text in the Neonatal Intensive Care Unit, focusing on decision support and information management using NLG technology.",
          "citing_paper_id": "947719",
          "cited_paper_id": 3939596,
          "context_text": "In this paper, we discuss our effort to do this in the context of the BabyTalk (Gatt et al., 2009) project.",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'BabyTalk' as a project, which is likely a dataset or corpus used in the research. The cited paper title supports this by indicating the use of NLG technology in a specific domain.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.3233/AIC-2009-0453",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c318642db27765604a3d2090d32d9c340ca73d3d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/123ce23df0548f476f5f2e00109e8adf6536d60b",
          "citing_paper_year": 2011,
          "cited_paper_year": 2009
        }
      ]
    },
    {
      "cited_paper_id": "3348552",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Citation Network Dataset (V14)"
      ],
      "dataset_details": [
        {
          "dataset_name": "Citation Network Dataset (V14)",
          "dataset_description": "Used to generate data samples for personalized text generation, focusing on the structure and content of academic citations and networks. | Used to generate data samples for personalized text generation, leveraging 5,259,858 papers and 29 features per paper to create a comprehensive dataset.",
          "citing_paper_id": "271218187",
          "cited_paper_id": 3348552,
          "context_text": "Data Curation: To generate the data samples, we leverage the Citation Network Dataset (V14) (Tang et al., 2008a), which comprises 5,259,858 papers and 29 features per paper.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the Citation Network Dataset (V14) as a specific dataset used for generating data samples, which is relevant to the research topic of personalized text generation.",
          "citing_paper_doi": "10.48550/arXiv.2407.11016",
          "cited_paper_doi": "10.1145/1401890.1402008",
          "citing_paper_url": "https://www.semanticscholar.org/paper/b618998f9f3634331c8762342bbf110b74ad3fc0",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f020b61789112fe7241b871907268f0bdc5c84fa",
          "citing_paper_year": 2024,
          "cited_paper_year": 2008
        }
      ]
    },
    {
      "cited_paper_id": "202621357",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Amazon Reviews Dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "Amazon Reviews Dataset",
          "dataset_description": "Used to generate data samples for personalized text generation, focusing on leveraging user reviews to enhance recommendation justifications. | Used to generate data samples for personalized text generation, leveraging 150 million reviews to train models on user preferences and review content.",
          "citing_paper_id": "271218187",
          "cited_paper_id": 202621357,
          "context_text": "To generate the data samples, we leverage the Amazon Reviews Dataset (Ni et al., 2019).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'Amazon Reviews Dataset' which is a specific, verifiable dataset used for generating data samples.",
          "citing_paper_doi": "10.48550/arXiv.2407.11016",
          "cited_paper_doi": "10.18653/v1/D19-1018",
          "citing_paper_url": "https://www.semanticscholar.org/paper/b618998f9f3634331c8762342bbf110b74ad3fc0",
          "cited_paper_url": "https://www.semanticscholar.org/paper/41d49ec6f73ab5621ab8e8cb5ddb677a886ccc76",
          "citing_paper_year": 2024,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "28232901",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "WMT15-WMT17"
      ],
      "dataset_details": [
        {
          "dataset_name": "WMT15-WMT17",
          "dataset_description": "Used to collect multilingual data for evaluating machine translation systems, focusing on English as the target language to study translation quality and personalization.",
          "citing_paper_id": "238582870",
          "cited_paper_id": 28232901,
          "context_text": "This data is collected over multiple language pairs which have English as target language (so both the human reference and the hypothesis are in English) of WMT15-WMT17.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'WMT15-WMT17' as a source of data, which is a specific and identifiable dataset used in machine translation evaluation.",
          "citing_paper_doi": "10.18653/v1/2021.emnlp-main.701",
          "cited_paper_doi": "10.18653/v1/W17-4717",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e06ef772c028de1ba093270a62084588e7c4deaa",
          "cited_paper_url": "https://www.semanticscholar.org/paper/704aa23d0be8817dd0aa2d4794068fc167243b85",
          "citing_paper_year": 2021,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "52057510",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "QuAC"
      ],
      "dataset_details": [
        {
          "dataset_name": "QuAC",
          "dataset_description": "Used to investigate themes through dialogic question and answer sequences, focusing on the conversational context in personalized text generation.",
          "citing_paper_id": "53218829",
          "cited_paper_id": 52057510,
          "context_text": "Recently, the QuAC dataset investigates similar themes, but as a sequence of questions and answers in dialogue form instead (Choi et al., 2018).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the QuAC dataset, which is a specific, verifiable resource used for investigating themes through dialogic question and answer sequences.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.18653/v1/D18-1241",
          "citing_paper_url": "https://www.semanticscholar.org/paper/227458886343b86bd15adf58c769be326b4b058a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/39e734da43eb8c72e9549b42e96760545036f8e5",
          "citing_paper_year": 2018,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "237578994",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "FigureSeer"
      ],
      "dataset_details": [
        {
          "dataset_name": "FigureSeer",
          "dataset_description": "Used to generate captions for scientific figures, focusing on the accuracy and relevance of generated text to the figure content. | Employed to generate descriptive captions for scientific figures, specifically targeting the clarity and informativeness of the generated text.",
          "citing_paper_id": "275336716",
          "cited_paper_id": 237578994,
          "context_text": "To facilitate the generation of captions by neural networks, previous research developed a variety of datasets, such as FigureSeer [24], FigureQA [14], DVQA [13], and SciCap [8].",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets by name, which are used for generating captions for figures. These datasets are specific and have clear identifiers.",
          "citing_paper_doi": "10.48550/arXiv.2501.02552",
          "cited_paper_doi": "10.18653/v1/2021.findings-emnlp.277",
          "citing_paper_url": "https://www.semanticscholar.org/paper/da34e8afa177d19e192d175077b985cb82020689",
          "cited_paper_url": "https://www.semanticscholar.org/paper/08b3c84da0da5bdc0e49a1c2f440743d829a5e1c",
          "citing_paper_year": 2025,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "244187",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Movie-DiC"
      ],
      "dataset_details": [
        {
          "dataset_name": "Movie-DiC",
          "dataset_description": "Used to develop and evaluate dialogue generation systems, focusing on movie dialogues. The corpus supports research in personalized text generation by providing a rich source of conversational data.",
          "citing_paper_id": "6862403",
          "cited_paper_id": 244187,
          "context_text": "[47] introduced a search-based system, namely IRIS, to generate dialogues using vector space model and then released the experimental corpus for research and development [48].",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the release of an experimental corpus for research and development, which aligns with the definition of a dataset. The title 'Movie-DiC: a Movie Dialogue Corpus for Research and Development' confirms it is a specific, verifiable dataset.",
          "citing_paper_doi": "10.1007/s11280-018-0598-6",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/ba3975cd4dea504142b6d423c8b70790407cfb07",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e2efefbba8bf3e76605db24da0ba15df7b0adc9e",
          "citing_paper_year": 2017,
          "cited_paper_year": 2012
        }
      ]
    },
    {
      "cited_paper_id": "11668878",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "lexicon from (Wilson et al., 2005)"
      ],
      "dataset_details": [
        {
          "dataset_name": "lexicon from (Wilson et al., 2005)",
          "dataset_description": "Used for recognizing contextual polarity in phrase-level sentiment analysis, providing 2700 words with sentiment labels to enhance personalized text generation.",
          "citing_paper_id": "20981275",
          "cited_paper_id": 11668878,
          "context_text": "The lexicon from (Wilson et al., 2005) contains 2700 words with sentiment labels.",
          "confidence_score": 0.85,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a lexicon with sentiment labels, which is a specific, verifiable resource. The lexicon is used for sentiment analysis, which is relevant to personalized text generation.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.3115/1220575.1220619",
          "citing_paper_url": "https://www.semanticscholar.org/paper/2a215755d7548ffc82079ce734c4ac60b62f6f56",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9b4876f7313b111074e79a01f570e6e9e02c0dce",
          "citing_paper_year": 2017,
          "cited_paper_year": 2005
        }
      ]
    },
    {
      "cited_paper_id": "206422013",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "personal knowledge base"
      ],
      "dataset_details": [
        {
          "dataset_name": "personal knowledge base",
          "dataset_description": "Used to rank responses in an open-domain conversation system, enhancing personalization through long-term memory storage and retrieval.",
          "citing_paper_id": "6862403",
          "cited_paper_id": 206422013,
          "context_text": "[4] proposed an example based approach to extend the input message and utilized a personal knowledge base for responses ranking in open domain conversation systems.",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions a 'personal knowledge base' which is used for responses ranking in a dialogue system. This fits the criteria for a dataset as it is a specific, verifiable resource used in the research.",
          "citing_paper_doi": "10.1007/s11280-018-0598-6",
          "cited_paper_doi": "10.1109/35021BIGCOMP.2015.7072837",
          "citing_paper_url": "https://www.semanticscholar.org/paper/ba3975cd4dea504142b6d423c8b70790407cfb07",
          "cited_paper_url": "https://www.semanticscholar.org/paper/a95c480ef41a5860cd0a34d097494c486fd4a149",
          "citing_paper_year": 2017,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "1957433",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "PchatbotW"
      ],
      "dataset_details": [
        {
          "dataset_name": "PchatbotW",
          "dataset_description": "Used to establish dialogue assessment indicators at the discourse level, focusing on the quality of responses in personalized text generation.",
          "citing_paper_id": "221969995",
          "cited_paper_id": 1957433,
          "context_text": "t has 26 responses in PchatbotW. This helps to establish dialogue assessment indicators at the discourse level. 3.4 Pre-trained Language Models We provide pre-trained language models including GloVe (Pennington et al., 2014), BPE (Sennrich et al.,2016),Fasttext(Bojanowski et al., 2017)andBERT(Devlin et al.,2018)basedonthe dataset. These pre-trained models will be released together with the data. 4 Experiments In this sec",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'PchatbotW' which appears to be a dataset used for establishing dialogue assessment indicators. However, the citation does not provide enough detail about the dataset's structure or source.",
          "citing_paper_doi": "10.1145/3404835.3463239",
          "cited_paper_doi": "10.3115/v1/D14-1162",
          "citing_paper_url": "https://www.semanticscholar.org/paper/ceb60c07a3584f94586f6ce0b2d55d72abf8952a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5",
          "citing_paper_year": 2020,
          "cited_paper_year": 2014
        }
      ]
    },
    {
      "cited_paper_id": "4895052",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "JD Customer Service Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "JD Customer Service Corpus",
          "dataset_description": "Used to train models for dialogue generation, focusing on customer service interactions with a large set of 435,005 dialogues from JD.com.",
          "citing_paper_id": "221969995",
          "cited_paper_id": 4895052,
          "context_text": "Chen et al. [5] constructed the JD Customer Service Corpus including 435,005 dialogues based on customer service dialogues from JD.com.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions a specific dataset, 'JD Customer Service Corpus', which is used for dialogue generation research.",
          "citing_paper_doi": "10.1145/3404835.3463239",
          "cited_paper_doi": "10.1145/3178876.3186077",
          "citing_paper_url": "https://www.semanticscholar.org/paper/ceb60c07a3584f94586f6ce0b2d55d72abf8952a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c499c8423fbfb1bdb6d3ebad257e994f3a7e3046",
          "citing_paper_year": 2020,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "5450801",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Douban Conversation Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "Douban Conversation Corpus",
          "dataset_description": "Used to train and evaluate multi-turn response selection models in retrieval-based chatbots, focusing on Chinese conversation pairs crawled from Douban.",
          "citing_paper_id": "221969995",
          "cited_paper_id": 5450801,
          "context_text": "Douban Conversation Corpus (Wu et al., 2017) 1,060,000 7,092,000 131,747,880 Chinese (session, response) pairs crawled from Douban.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a specific dataset, 'Douban Conversation Corpus', which is used for multi-turn response selection in chatbots. The dataset is described as containing Chinese conversation pairs.",
          "citing_paper_doi": "10.1145/3404835.3463239",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/ceb60c07a3584f94586f6ce0b2d55d72abf8952a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/a6eec00f10346ce27d4f69f9e38f5665fffe8056",
          "citing_paper_year": 2020,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "6440341",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Home"
      ],
      "dataset_details": [
        {
          "dataset_name": "Home",
          "dataset_description": "Used to explore tip information for tips generation and rating prediction, focusing on the unique advantages of tips over conventional reviews. | Used for ablation experiments to demonstrate the performance of each component of the framework, focusing on user preference modeling from a generative perspective.",
          "citing_paper_id": "70350032",
          "cited_paper_id": 6440341,
          "context_text": "are employed to model the user preference from a generative perspective. It still only uses the rating matrix as input. •The baseline methods used in tips quality evaluation: NRT [21], CTR [37], HFT [26]. Ablation experiments: In order to demonstrate the performance of each component of our framework, we conduct the ablation experiments on the dataset Home. We compare the performance of our integrate",
          "confidence_score": 0.7,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Home' as a dataset used for ablation experiments, but it does not provide enough detail to confirm its nature or specific characteristics. The other names mentioned are models or methods, not datasets.",
          "citing_paper_doi": "10.1145/3308558.3313496",
          "cited_paper_doi": "10.1145/2507157.2507163",
          "citing_paper_url": "https://www.semanticscholar.org/paper/002bf3abde1ba29a312eb0e74be888e0eeead8ac",
          "cited_paper_url": "https://www.semanticscholar.org/paper/665f89a20b05472d82df0a12f2dd63e8fcc4f3ea",
          "citing_paper_year": 2019,
          "cited_paper_year": 2013
        }
      ]
    },
    {
      "cited_paper_id": "52167799",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Reddit Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "Reddit Corpus",
          "dataset_description": "Used to train personalized dialogue agents, focusing on chit-chat conversations. The dataset, crawled from Reddit, contains 700 million comments and 1.4 billion tokens, enabling the study of natural language interactions.",
          "citing_paper_id": "221969995",
          "cited_paper_id": 52167799,
          "context_text": "Reddit Corpus (Mazaré et al., 2018) 700,000,000 1,400,000,000 / English personalizing chit-chat dialogue corpus crawled from Reddit.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a specific dataset, 'Reddit Corpus', which is used for personalizing chit-chat dialogue. The dataset is described as being crawled from Reddit and is used in the context of training personalized dialogue agents.",
          "citing_paper_doi": "10.1145/3404835.3463239",
          "cited_paper_doi": "10.18653/v1/D18-1298",
          "citing_paper_url": "https://www.semanticscholar.org/paper/ceb60c07a3584f94586f6ce0b2d55d72abf8952a",
          "cited_paper_url": "https://www.semanticscholar.org/paper/dde89e64a7f375b90e1cc594142940f4161e1592",
          "citing_paper_year": 2020,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "11860229",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "IMDb62"
      ],
      "dataset_details": [
        {
          "dataset_name": "IMDb62",
          "dataset_description": "Used to study authorship attribution and personalized text generation, focusing on the stylistic and thematic consistency in movie reviews written by prolific users.",
          "citing_paper_id": "267523283",
          "cited_paper_id": 11860229,
          "context_text": "IMDb62 contains 62,000 movie reviews written by 62 prolific users of the Internet Movie Database (IMDb) where each user wrote 1,000 reviews (Seroussi et al., 2014).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "IMDb62 is a specific dataset containing movie reviews, which is relevant for personalized text generation research.",
          "citing_paper_doi": "10.48550/arXiv.2402.04914",
          "cited_paper_doi": "10.1162/COLI_a_00173",
          "citing_paper_url": "https://www.semanticscholar.org/paper/de534c7a644ea6017ddf03e22cdabc0724758f7d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c9c4800ec66121ef1856be01f863e6a3fe68f81a",
          "citing_paper_year": 2024,
          "cited_paper_year": 2014
        }
      ]
    },
    {
      "cited_paper_id": "230435736",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "The Pile"
      ],
      "dataset_details": [
        {
          "dataset_name": "The Pile",
          "dataset_description": "Used to pretrain models, focusing on a diverse 825GB English dataset with texts from 22 sources across academic, internet, prose, dialogue, and miscellaneous categories.",
          "citing_paper_id": "267523283",
          "cited_paper_id": 230435736,
          "context_text": "The models were pretrained using the Pile dataset (Gao et al., 2020), an 825GB English dataset containing texts from 22 diverse sources, roughly broken down into five categories: academic writing, internet, prose, dialogue, and miscellaneous.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'The Pile dataset' as a specific, verifiable dataset used for pretraining models. It provides details about the dataset's size and content, which aligns with the criteria for inclusion.",
          "citing_paper_doi": "10.48550/arXiv.2402.04914",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/de534c7a644ea6017ddf03e22cdabc0724758f7d",
          "cited_paper_url": "https://www.semanticscholar.org/paper/db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e",
          "citing_paper_year": 2024,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "44090948",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "NRC VAD lexicon"
      ],
      "dataset_details": [
        {
          "dataset_name": "NRC VAD lexicon",
          "dataset_description": "Used to incorporate external knowledge for capturing subtle user emotions in the MultiESC model, enhancing the representation of emotional states through valence, arousal, and dominance scores.",
          "citing_paper_id": "252780132",
          "cited_paper_id": 44090948,
          "context_text": "For user state modeling, MultiESC captures the user’s subtle emotion expressed in the context by incorporating external knowledge from the NRC VAD lexicon (Mohammad, 2018).",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'NRC VAD lexicon' as an external knowledge source used in the MultiESC model for capturing user emotions. The lexicon is a specific, verifiable resource.",
          "citing_paper_doi": "10.48550/arXiv.2210.04242",
          "cited_paper_doi": "10.18653/v1/P18-1017",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f36053a516cc4e3e72291ad2eaa042a299a19635",
          "cited_paper_url": "https://www.semanticscholar.org/paper/502c1e8bba1578241c354a54926ca913d5fa9c8a",
          "citing_paper_year": 2022,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "198967908",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "CelebAMask-HQ"
      ],
      "dataset_details": [
        {
          "dataset_name": "CelebAMask-HQ",
          "dataset_description": "Used to train the DTI module by providing foreground-masked identity images, focusing on generating textual embeddings for personalized text generation. | Introduced as a large-scale multimodal dataset with prompts of imaginary human-centric depictions, using publicly available images of celebrities for training and evaluation. | Used to enhance personalized text-to-image generation by providing high-quality, well-curated facial image data for training and fine-tuning models. | Used to select 400 unique human identities for pairing with prompts, enhancing the evaluation of personalized text-to-image systems through rich meta-annotations.",
          "citing_paper_id": "266163420",
          "cited_paper_id": 198967908,
          "context_text": "Secondarily, we wish to highlight the potential of leveraging more powerful open-source, non-personalized T2I systems (e.g., SDXL [49]) in combination with well-curated data (e.g., CelebAMask-HQ [36]) to assist personalized generators.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'CelebAMask-HQ' as an example of well-curated data that can be used in combination with powerful T2I systems to assist personalized generators.",
          "citing_paper_doi": "10.48550/arXiv.2312.06116",
          "cited_paper_doi": "10.1109/cvpr42600.2020.00559",
          "citing_paper_url": "https://www.semanticscholar.org/paper/cb01408aed1a7ee32d7556af2c6949ca7f5374ca",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9a2d83ed7d7cc647421e976d8669b023974fff67",
          "citing_paper_year": 2023,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "15956725",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "SubTle"
      ],
      "dataset_details": [
        {
          "dataset_name": "SubTle",
          "dataset_description": "Used to study non-dialog text extracted from movie subtitles, focusing on the linguistic patterns and structures in large-scale subtitle data.",
          "citing_paper_id": "20956365",
          "cited_paper_id": 15956725,
          "context_text": "SubTle dataset The third dataset we consider is the SubTle [Ameixa et al., 2014], which is an enormous, non-dialog corpus extracted from movie subtitles.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'SubTle' as a specific dataset used in the research, which is a corpus of movie subtitles. It is clearly identified and used for research purposes.",
          "citing_paper_doi": "10.24963/ijcai.2017/521",
          "cited_paper_doi": "10.1007/978-3-319-09767-1_2",
          "citing_paper_url": "https://www.semanticscholar.org/paper/feae6b488b039a979afd5776890227a227428148",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2de0401b5f019fb8646a27a3cc50429b38693dd6",
          "citing_paper_year": 2017,
          "cited_paper_year": 2014
        }
      ]
    },
    {
      "cited_paper_id": "1167588",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "ELI5"
      ],
      "dataset_details": [
        {
          "dataset_name": "ELI5",
          "dataset_description": "Used to train a large language model, providing a vast collection of public domain books. | Used for training and evaluating models on explain-like-I'm-5 style questions, focusing on generating clear and concise answers. | Used to train a large language model, providing multilingual text content across various domains. | Used to train a large language model, providing multilingual parliamentary proceedings to enhance language diversity. | Used to train a large language model, providing context-free question-answer pairs to improve the ability to answer natural language questions. | Used to train a large language model, providing multilingual documents from the United Nations to enhance language diversity. | Used to train a large language model, providing user reviews to capture sentiment and opinion expressions. | Used to train a large language model, providing text from 45 subreddits to capture diverse online discussions. | Used to train a large language model, providing web-scraped text data. | Used to train a large language model, providing news articles from various sources to cover current events and topics. | Used to train a large language model, providing question-answer pairs from the Explain Like I'm 5 subreddit to improve explanatory text generation. | Used to train a large language model, providing complex question-answer pairs requiring multi-hop reasoning to improve deep comprehension.",
          "citing_paper_id": "202573071",
          "cited_paper_id": 1167588,
          "context_text": "…from ELI5 (Fan et al., 2019) and the MRQA shared task 3 , which includes the Stanford Question Answering Dataset (Rajpurkar et al., 2016), NewsQA (Trischler et al., 2016), TriviaQA (Joshi et al., 2017), SearchQA (Dunn et al., 2017), HotpotQA (Yang et al., 2018), and Natural Questions…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The citation mentions multiple datasets used in the MRQA shared task, including ELI5 and several question answering datasets. These are specific, verifiable datasets used for training and evaluation.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.18653/v1/W17-2623",
          "citing_paper_url": "https://www.semanticscholar.org/paper/75acc731bdd2b626edc74672a30da3bc51010ae8",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3eda43078ae1f4741f09be08c4ecab6229046a5c",
          "citing_paper_year": 2019,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "257557302",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "LAION-400M"
      ],
      "dataset_details": [
        {
          "dataset_name": "LAION-400M",
          "dataset_description": "Used to train a multimodal latent diffusion model that combines text and image inputs, focusing on joint subject and text conditional image generation.",
          "citing_paper_id": "268537084",
          "cited_paper_id": 257557302,
          "context_text": "UMM-Diffusion [25], leveraging LAION-400M dataset [36], proposed a multimodal latent diffusion approach that combines text and image inputs.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "LAION-400M is a specific, verifiable dataset mentioned in the context. It is used in the research for training a multimodal latent diffusion model.",
          "citing_paper_doi": "10.1109/CVPRW63382.2024.00100",
          "cited_paper_doi": "10.48550/arXiv.2303.09319",
          "citing_paper_url": "https://www.semanticscholar.org/paper/f52ecb5a9b4e59e638311ed3cbfdf0c2cac0ed20",
          "cited_paper_url": "https://www.semanticscholar.org/paper/d4b0fa75565e873eea165e7059435bb55ddeb9ef",
          "citing_paper_year": 2024,
          "cited_paper_year": 2023
        }
      ]
    },
    {
      "cited_paper_id": "unknown",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Gigaword corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "Gigaword corpus",
          "dataset_description": "Used to fine-tune a pre-trained model on text summarization tasks, specifically evaluating performance across different scales of training data (10K, 100K, 1M, and 3.8M article-title pairs).",
          "citing_paper_id": "146808476",
          "cited_paper_id": null,
          "context_text": "We ﬁne-tune the pre-trained model on text summarization task with different scales (10K, 100K, 1M and 3.8M) of training data from the Gigaword corpus (Graff et al., 2003) 9 , which consists of a total of 3.8M article-title pairs in English.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the Gigaword corpus, which is a well-known dataset used for text summarization tasks. The dataset is used to fine-tune a pre-trained model on different scales of training data.",
          "citing_paper_doi": null,
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/145b8b5d99a2beba6029418ca043585b90138d12",
          "cited_paper_url": null,
          "citing_paper_year": 2019,
          "cited_paper_year": null
        }
      ]
    },
    {
      "cited_paper_id": "46939026",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "2018 Duolingo Shared Task on Second Language Acquisition Modeling"
      ],
      "dataset_details": [
        {
          "dataset_name": "2018 Duolingo Shared Task on Second Language Acquisition Modeling",
          "dataset_description": "Used to model second language acquisition, focusing on user responses over the first 30 days of learning. The dataset supports the investigation of personalized learning patterns and user engagement. | Used to model second language acquisition, focusing on user responses over the first 30 days of learning, to understand learning patterns and personalize educational content.",
          "citing_paper_id": "235368201",
          "cited_paper_id": 46939026,
          "context_text": "We use the 2018 Duolingo Shared Task on Second Language Acquisition Modeling (Settles et al., 2018) dataset, which contains questions and responses for Duolingo users over the first 30 days of learning a second language.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions a specific dataset used for modeling second language acquisition, which is directly relevant to personalized text generation.",
          "citing_paper_doi": "10.18653/v1/2021.acl-short.88",
          "cited_paper_doi": "10.18653/v1/W18-0506",
          "citing_paper_url": "https://www.semanticscholar.org/paper/390f174d102c72172249254f3f1048721c0c3161",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3e408acf397874d4859352246c4d485043a36561",
          "citing_paper_year": 2021,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "13752552",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "OpenWebText"
      ],
      "dataset_details": [
        {
          "dataset_name": "OpenWebText",
          "dataset_description": "Used to train models for personalized text generation, providing a diverse and large-scale web-based text corpus. | Used to train models for personalized text generation, focusing on multilingual United Nations documents. | Used to train models for personalized text generation, focusing on user reviews and ratings. | Used to train models for personalized text generation, focusing on news articles and summaries. | Used to train models for personalized text generation, focusing on multilingual parliamentary proceedings.",
          "citing_paper_id": "202573071",
          "cited_paper_id": 13752552,
          "context_text": "…1 , submissions from 45 subreddits, OpenWebText 2 , a large collection of news data (Hermann et al., 2015; Barrault et al., 2019; Sandhaus, 2008; Grusky et al., 2018), Amazon Reviews (McAuley et al., 2015), Europarl and UN data from WMT (En-De, En-Es, En-Fr) (Barrault et al., 2019),…",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions several datasets that are used for training and evaluation in the context of personalized text generation. These datasets are specific and have clear identifiers.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.18653/v1/N18-1065",
          "citing_paper_url": "https://www.semanticscholar.org/paper/75acc731bdd2b626edc74672a30da3bc51010ae8",
          "cited_paper_url": "https://www.semanticscholar.org/paper/4e346eb1628df6a12c1a121f862fb3a16c6fec60",
          "citing_paper_year": 2019,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "221665105",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "dataset of comparisons between two model outputs"
      ],
      "dataset_details": [
        {
          "dataset_name": "dataset of comparisons between two model outputs",
          "dataset_description": "Used to train a reward model on human-preferred outputs, focusing on improving text summarization quality through direct feedback.",
          "citing_paper_id": "246426909",
          "cited_paper_id": 221665105,
          "context_text": "In Stiennon et al. (2020), the RM is trained on a dataset of comparisons between two model outputs on the same input.",
          "confidence_score": 0.7,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a dataset of comparisons between two model outputs, which is specific enough to be considered a dataset, though it lacks a formal name.",
          "citing_paper_doi": null,
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/d766bffc357127e0dc86dd69561d5aeb520d6f4c",
          "cited_paper_url": "https://www.semanticscholar.org/paper/053b1d7b97eb2c91fc3921d589c160b0923c70b1",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "1880070",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "annotated dataset of human response scores"
      ],
      "dataset_details": [
        {
          "dataset_name": "annotated dataset of human response scores",
          "dataset_description": "Used to train ADEM, an evaluation model that scores dialogue responses, focusing on learning from human annotations to assess response quality.",
          "citing_paper_id": "53217693",
          "cited_paper_id": 1880070,
          "context_text": "Examples include ADEM (Lowe et al., 2017), an evaluation model that learns to score responses from an annotated dataset of human responses scores.",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions ADEM, which is an evaluation model, not a dataset. However, it refers to an 'annotated dataset of human response scores' used by ADEM, which fits the criteria for a dataset.",
          "citing_paper_doi": "10.18653/v1/W19-4103",
          "cited_paper_doi": "10.18653/v1/P17-1103",
          "citing_paper_url": "https://www.semanticscholar.org/paper/b36d693ff1ccaa0b08e2728bd2dc01d896699b2b",
          "cited_paper_url": "https://www.semanticscholar.org/paper/339c6e6d46836c173fb6a23b493c724896d4cc70",
          "citing_paper_year": 2018,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "1012652",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Amazon 5-core"
      ],
      "dataset_details": [
        {
          "dataset_name": "Amazon 5-core",
          "dataset_description": "Used to build datasets for personalized text generation, focusing on user-generated reviews and metadata from May 1996 to July 2014, ensuring no duplicated records.",
          "citing_paper_id": "204874165",
          "cited_paper_id": 1012652,
          "context_text": "1 Datasets Our datasets are built upon Amazon 5-core 2 [21] which includes user generated reviews and metadata spanning from May 1996 to July 2014 without duplicated records.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'Amazon 5-core' as a dataset used for building their datasets, which includes user-generated reviews and metadata. This fits the criteria for a specific, verifiable dataset.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.1145/2766462.2767755",
          "citing_paper_url": "https://www.semanticscholar.org/paper/fb394896bf1b31183839c766afc62dd251a7b9b7",
          "cited_paper_url": "https://www.semanticscholar.org/paper/fab4d19ed77dad7c437d885eceb8aa65fae5a783",
          "citing_paper_year": 2021,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "11080756",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Electronics dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "Electronics dataset",
          "dataset_description": "Used to evaluate the performance of text generation models on electronics-related content, focusing on ROUGE scores to measure the quality of generated sentences. | Used to evaluate the performance of text generation models on beauty-related content, focusing on ROUGE scores to measure the quality of generated sentences.",
          "citing_paper_id": "204874165",
          "cited_paper_id": 11080756,
          "context_text": "During the testing stage, we only generate one sentence and calculate ROUGE and BLEU score\nTable 5: ROUGE score on Electronics dataset (in percentage)\nROUGE-1 ROUGE-2 ROUGE-L ROUGE-SU4 recall precision F1 recall precision F1 recall precision F1 recall precision F1\nA 2SeqA 22.80 7.79 10.19 0.45 0.14 0.18 19.93 6.77 8.85 9.26 1.07 1.38 HSS 26.76 15.72 18.36 3.01 1.77 2.05 22.51 13.31 15.47 9.69 3.51 4.10\nTable 6: ROUGE score on Beauty dataset (in percentage)\nbased on the rst sentence in the human reference text.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Electronics dataset' and 'Beauty dataset' which are specific datasets used for evaluating the performance of text generation models using ROUGE scores.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.3115/1073083.1073135",
          "citing_paper_url": "https://www.semanticscholar.org/paper/fb394896bf1b31183839c766afc62dd251a7b9b7",
          "cited_paper_url": "https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9",
          "citing_paper_year": 2021,
          "cited_paper_year": 2002
        }
      ]
    },
    {
      "cited_paper_id": "988010",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Opinosis"
      ],
      "dataset_details": [
        {
          "dataset_name": "Opinosis",
          "dataset_description": "Used to test fine-tuned StyleLM models, specifically evaluating performance on sentences extracted from user reviews on hotels, cars, and various electronics from Tripadvisor, Edmunds.com, and Amazon.com. | Used to obtain source sentences for inference, focusing on the style and content of Mark Twain's writing. | Used to test fine-tuned StyleLM models across various domains, including user reviews from Tripadvisor, Edmunds.com, and Amazon.com, focusing on summarization of highly redundant opinions. | Used to obtain source sentences for inference, focusing on summarizing highly redundant opinions. | Used to study everyday writing styles in abstractive summarization, focusing on highly redundant opinions and their representation in target texts. | Used to obtain source sentences for personalized text generation, focusing on highly redundant opinions to generate abstractive summaries.",
          "citing_paper_id": "202719307",
          "cited_paper_id": 988010,
          "context_text": "All the fine-tuned StyleLM models are tested on a test set that spans different domains – (a) Opinosis (Ganesan, Zhai, and Han 2010) which contains sentences extracted from user reviews on a variety of topics from Tripadvisor (hotels), Edmunds.com (cars) and Amazon.com (various electronics), (b)…",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Opinosis' as a specific dataset used for testing fine-tuned StyleLM models. It is a multi-word proper noun and fits the criteria for a dataset.",
          "citing_paper_doi": "10.1609/AAAI.V34I05.6433",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/f2537047dfb230cf501599715ec993182c9ed47c",
          "cited_paper_url": "https://www.semanticscholar.org/paper/32c4b4c6768abc5ebeeb7d006df7e8a962c114d6",
          "citing_paper_year": 2019,
          "cited_paper_year": 2010
        }
      ]
    },
    {
      "cited_paper_id": "8039072",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "COCO"
      ],
      "dataset_details": [
        {
          "dataset_name": "COCO",
          "dataset_description": "Used to train and evaluate personalized text generation models, focusing on recall at ranks 1, 5, and 10.",
          "citing_paper_id": "53022581",
          "cited_paper_id": 8039072,
          "context_text": "tion using the test split of [24] Model Text Pre- Flickr30k COCO training R@1 R@5 R@10 R@1 R@5 R@10 UVS [25] - 23.0 50.7 62.9 43.4 75.7 85.8 Embedding Net [51] - 40.7 69.7 79.2 50.4 79.3 69.4 sm-LSTM [19] - 42.5 71.9 81.5 53.2 83.1 91.5 VSE++ (ResNet, FT) [13] - 52.9 80.5 87.2 64.6 90.0 95.7 GXN (i2t+t2i) [15] - 56.8 - 89.6 68.5 - 97.9 TransResNet model variants: Transformer, ResNet152 Full 10.3 27.3",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions 'Flickr30k' and 'COCO' as datasets used for evaluation, but does not provide specific details on their usage beyond the test splits.",
          "citing_paper_doi": "10.1109/CVPR.2019.01280",
          "cited_paper_doi": "10.1109/CVPR.2017.767",
          "citing_paper_url": "https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0",
          "citing_paper_year": 2018,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "15886159",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "ROCStories corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "ROCStories corpus",
          "dataset_description": "Used to provide examples of typical stories for personalized text generation, focusing on narrative structure and coherence. | Used to evaluate the model's ability to predict story continuations, focusing on narrative coherence and logical flow in short stories. | Used to provide examples of typical stories for story completion tasks, focusing on narrative structure and coherence in short stories. | Used to evaluate story endings by selecting the correct conclusion from two candidates, focusing on narrative coherence and logical flow.",
          "citing_paper_id": "52136077",
          "cited_paper_id": 15886159,
          "context_text": "Figure 1 shows an example of a typical story in the ROCStories corpus (Mostafazadeh et al. 2016b).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the ROCStories corpus, which is a specific dataset used for story generation and comprehension tasks.",
          "citing_paper_doi": "10.1609/AAAI.V33I01.33016473",
          "cited_paper_doi": "10.18653/v1/W16-2505",
          "citing_paper_url": "https://www.semanticscholar.org/paper/d03d24241fc95e018517d6b1e3be40c5dc31ee66",
          "cited_paper_url": "https://www.semanticscholar.org/paper/f0e626ae39ba9b3478bfc1e15189606aeb794795",
          "citing_paper_year": 2018,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "13707541",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "social media text summarization dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "social media text summarization dataset",
          "dataset_description": "Used to evaluate the performance of the proposed method in personalized text generation, focusing on the effectiveness of the convolutional gated unit in refining source representations.",
          "citing_paper_id": "55461757",
          "cited_paper_id": 13707541,
          "context_text": "(3) CGU : Lin et al. (2018) propose to use the convolutional gated unit to reﬁne the source representation, which achieves the state-of-the-art performance on social media text summarization dataset.",
          "confidence_score": 0.6,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions a 'social media text summarization dataset' but does not provide a specific name. The dataset is used for evaluating the performance of the convolutional gated unit in text summarization.",
          "citing_paper_doi": "10.1609/AAAI.V33I01.33016399",
          "cited_paper_doi": "10.18653/v1/P18-2027",
          "citing_paper_url": "https://www.semanticscholar.org/paper/9509af2b2130b0fae209b08e6eaa03a437d3f29b",
          "cited_paper_url": "https://www.semanticscholar.org/paper/2fed2b40953d33a1fc38221b55476005fd91db70",
          "citing_paper_year": 2018,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "160025533",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "WebText"
      ],
      "dataset_details": [
        {
          "dataset_name": "WebText",
          "dataset_description": "Used for pre-training GPT-2, a large and diverse dataset that contributes to the model's performance across various domains, including natural language generation.",
          "citing_paper_id": "202719307",
          "cited_paper_id": 160025533,
          "context_text": "The recently proposed language model GPT-2 (Radford et al. 2019) is pre-trained on a large and diverse dataset (WebText) and is shown to perform well across several domains and datasets including natural language generation.",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions WebText as a dataset used for pre-training GPT-2, which is relevant to personalized text generation. However, the context does not provide specific details on how WebText is used in the research.",
          "citing_paper_doi": "10.1609/AAAI.V34I05.6433",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/f2537047dfb230cf501599715ec993182c9ed47c",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9405cc0d6169988371b2755e573cc28650d14dfe",
          "citing_paper_year": 2019,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "252519330",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "News Categorization dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "News Categorization dataset",
          "dataset_description": "Used to construct a dataset for personalized text generation, leveraging news articles categorized by topic from the HuffPost website. | Used to create a dataset for personalized text generation, focusing on news articles to study category-specific language patterns and content. | Used to construct a dataset for personalized text generation, leveraging news articles categorized from the HuffPost website.",
          "citing_paper_id": "258298303",
          "cited_paper_id": 252519330,
          "context_text": "To construct our dataset for this task, we leverage the News Categorization dataset (Misra, 2022; Misra and Grover, 2021) from the HuffPost website.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the 'News Categorization dataset' which is a specific, verifiable dataset used for constructing a dataset for the task at hand.",
          "citing_paper_doi": "10.48550/arXiv.2304.11406",
          "cited_paper_doi": "10.48550/arXiv.2209.11429",
          "citing_paper_url": "https://www.semanticscholar.org/paper/17170575aa8b4fa4e3eef5d366ada706a94dd836",
          "cited_paper_url": "https://www.semanticscholar.org/paper/aed386a091fbb5128a67c4364c835b1daaefe0a4",
          "citing_paper_year": 2023,
          "cited_paper_year": 2022
        }
      ]
    },
    {
      "cited_paper_id": "17215563",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "SoLSCSum"
      ],
      "dataset_details": [
        {
          "dataset_name": "SoLSCSum",
          "dataset_description": "Used to highlight limitations in training neural models due to its small size, focusing on extractive summarization and personalization.",
          "citing_paper_id": "55461757",
          "cited_paper_id": 17215563,
          "context_text": "Recently, Nguyen et al. (2016) publish a small extractive sentence-comment dataset which can not be used to train neural models due to its small size.",
          "confidence_score": 0.85,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a specific dataset by Nguyen et al. (2016) that is too small for training neural models. The title confirms it is a dataset.",
          "citing_paper_doi": "10.1609/AAAI.V33I01.33016399",
          "cited_paper_doi": "10.1145/2983323.2983376",
          "citing_paper_url": "https://www.semanticscholar.org/paper/9509af2b2130b0fae209b08e6eaa03a437d3f29b",
          "cited_paper_url": "https://www.semanticscholar.org/paper/ca4a20ab7ce1222b7db0447d2ff9dda67fd36b36",
          "citing_paper_year": 2018,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "44129061",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "CNN/DailyMail"
      ],
      "dataset_details": [
        {
          "dataset_name": "CNN/DailyMail",
          "dataset_description": "Used to evaluate abstractive summarization methods, comparing their performance in personalized text generation, focusing on the performance of the models in terms of ROUGE score.",
          "citing_paper_id": "55461757",
          "cited_paper_id": 44129061,
          "context_text": "uffer from redundancy problem. Recently, with the emergence of neural network models for text generation, a vast majority of the literature on summarization is dedicated to abstractive summarization (Bansal and Chen 2018; Ma et al. 2018b; Zhou et al. 2018). On the text summarization benchmark dataset CNN/DailyMail, the state-ofthe-art abstractive methods outperform the best extractive method in terms of ROUGE score.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the CNN/DailyMail dataset, which is a well-known benchmark for text summarization. The dataset is used to evaluate abstractive summarization methods.",
          "citing_paper_doi": "10.1609/AAAI.V33I01.33016399",
          "cited_paper_doi": "10.18653/v1/P18-1063",
          "citing_paper_url": "https://www.semanticscholar.org/paper/9509af2b2130b0fae209b08e6eaa03a437d3f29b",
          "cited_paper_url": "https://www.semanticscholar.org/paper/41b3180745068934bd9f7f2fbc2efc00c64d534b",
          "citing_paper_year": 2018,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "221969995",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Weibo dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "Weibo dataset",
          "dataset_description": "PChatbotW is a large-scale dataset collected from Weibo, used to develop and test personalized chatbot systems, emphasizing the diversity and complexity of user interactions. | This dataset 'Weibo dataset' was mentioned in the citation context but no detailed description was generated. | This dataset 'PChatbotW' was mentioned in the citation context but no detailed description was generated. | The Weibo dataset, a subset of PChatbotW, is used to train and evaluate personalized chatbot responses, focusing on the nuances of social media interactions over a one-year period.",
          "citing_paper_id": "235792273",
          "cited_paper_id": 221969995,
          "context_text": "Weibo dataset is a subset of PChatbotW [22], which is collected from Weibo for the one-year period beginning from Sept.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'Weibo dataset' and 'PChatbotW', both of which are specific datasets. The Weibo dataset is described as a subset of PChatbotW, which is relevant to personalized chatbot research.",
          "citing_paper_doi": "10.1145/3404835.3462828",
          "cited_paper_doi": "10.1145/3404835.3463239",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1e0542da881f00c6002bca2426c3dab1a10b888c",
          "cited_paper_url": "https://www.semanticscholar.org/paper/ceb60c07a3584f94586f6ce0b2d55d72abf8952a",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "216562425",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "DailyDialog test set"
      ],
      "dataset_details": [
        {
          "dataset_name": "DailyDialog test set",
          "dataset_description": "Used to select context-utterance pairs for evaluating chatbot models, focusing on open-domain conversation quality and coherence.",
          "citing_paper_id": "258378197",
          "cited_paper_id": 216562425,
          "context_text": "We randomly select 50 context-utterance pairs from the DailyDi-alog test set for all models based on the strongest BlenderBot language model.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'DailyDialog test set', which is a specific dataset used for evaluating chatbot performance. The dataset is used to select context-utterance pairs for model evaluation.",
          "citing_paper_doi": "10.18653/v1/2023.eacl-srw.9",
          "cited_paper_doi": "10.18653/v1/2021.eacl-main.24",
          "citing_paper_url": "https://www.semanticscholar.org/paper/b378a4c7d69442912ead0b9d9488db251b383ac0",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9b539d413393047b28bb7be9b195f142aaf7a80e",
          "citing_paper_year": 2023,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "52967399",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Enron data"
      ],
      "dataset_details": [
        {
          "dataset_name": "Enron data",
          "dataset_description": "Used to fine-tune a politeness classifier for measuring politeness transfer quality in generated sequences, focusing on the average score given by the classifier.",
          "citing_paper_id": "258378197",
          "cited_paper_id": 52967399,
          "context_text": "To measure politeness transfer quality, we compute Polite Score , which is defined as the average score given to the generated sequences by our politeness classifier, which we created by finetuning BERT (Devlin et al., 2019) on Madaan et al. (2020)’s Enron data (see Section 4.1).",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'Enron data' as the dataset used to fine-tune a politeness classifier. This dataset is specific and relevant to the research on politeness transfer quality.",
          "citing_paper_doi": "10.18653/v1/2023.eacl-srw.9",
          "cited_paper_doi": "10.18653/v1/N19-1423",
          "citing_paper_url": "https://www.semanticscholar.org/paper/b378a4c7d69442912ead0b9d9488db251b383ac0",
          "cited_paper_url": "https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992",
          "citing_paper_year": 2023,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "1428702",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "MIMDb"
      ],
      "dataset_details": [
        {
          "dataset_name": "MIMDb",
          "dataset_description": "This dataset 'MIMDb' was mentioned in the citation context but no detailed description was generated.",
          "citing_paper_id": "258959321",
          "cited_paper_id": 1428702,
          "context_text": "In controlled sentiment generation , x is a preﬁx of a movie review the IMDb dataset [22], and the policy must generate y with positive sentiment.",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the IMDb dataset, which is a well-known dataset used for sentiment analysis in movie reviews. The dataset is used for controlled sentiment generation, specifically to generate text with positive sentiment.",
          "citing_paper_doi": "10.48550/arXiv.2305.18290",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/0d1c76d45afa012ded7ab741194baf142117c495",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1c61f9ef06fe74505775a833ff849185757199e7",
          "citing_paper_year": 2023,
          "cited_paper_year": 2011
        }
      ]
    },
    {
      "cited_paper_id": "199668753",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "ReDial"
      ],
      "dataset_details": [
        {
          "dataset_name": "ReDial",
          "dataset_description": "Used to experiment with dialog-based recommendation, focusing on knowledge-based interactions in a conversational setting.",
          "citing_paper_id": "248834570",
          "cited_paper_id": 199668753,
          "context_text": "Weexperimentwith dialogbased recommendation following the settings of KBRD [3] on dataset ReDial .",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ReDial' as a dataset used for experimenting with dialog-based recommendation. The cited paper title does not provide additional disambiguation but confirms the relevance to recommender systems.",
          "citing_paper_doi": "10.48550/arXiv.2205.08084",
          "cited_paper_doi": "10.18653/v1/D19-1189",
          "citing_paper_url": "https://www.semanticscholar.org/paper/cbf3bf8f541f5b446c59c8deacbcc18527768c75",
          "cited_paper_url": "https://www.semanticscholar.org/paper/42ffd3a1ab4a139c5ec33b50bd7e5759077f03c4",
          "citing_paper_year": 2022,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "59553505",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "ConvAI2 personalized dialogue corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "ConvAI2 personalized dialogue corpus",
          "dataset_description": "Used to evaluate personalized dialogue systems, focusing on generating contextually appropriate responses that reflect user preferences and personalities.",
          "citing_paper_id": "244478160",
          "cited_paper_id": 59553505,
          "context_text": "We evaluate our approach on the ConvAI2 personalized dialogue corpus (Dinan et al., 2019).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a specific dataset, 'ConvAI2 personalized dialogue corpus', which is used for evaluating the approach in personalized dialogue systems.",
          "citing_paper_doi": "10.5220/0010812500003116",
          "cited_paper_doi": "10.1007/978-3-030-29135-8_7",
          "citing_paper_url": "https://www.semanticscholar.org/paper/848c6701b45f978a8a9a354a062479a7ae1c81ee",
          "cited_paper_url": "https://www.semanticscholar.org/paper/9ae17b09c59f06f02ef824b856a440de663471d0",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "206592766",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Reddit submissions"
      ],
      "dataset_details": [
        {
          "dataset_name": "Reddit submissions",
          "dataset_description": "Used to fine-tune a pretrained DistilBERT model on a variant of triplet loss, focusing on personalized text generation by leveraging user-generated content from over 1.7 million users.",
          "citing_paper_id": "256631001",
          "cited_paper_id": 206592766,
          "context_text": "…et al., 2019) and contrastive representation learning (Gao et al., 2021; Rethmeier and Augenstein, 2021; Xie et al., 2022), we fine-tune a pretrained DistilBERT architecture (Sanh et al., 2020) on a variant of triplet loss (Schroff et al., 2015) using Reddit submissions from more than 1.7m users.",
          "confidence_score": 0.6,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'Reddit submissions' but does not specify a named dataset. It describes a large-scale user-generated content source, which is domain-qualified but lacks a specific, identifiable name.",
          "citing_paper_doi": "10.18653/v1/2022.findings-emnlp.123",
          "cited_paper_doi": "10.1109/CVPR.2015.7298682",
          "citing_paper_url": "https://www.semanticscholar.org/paper/d8d176585614cd55ddcf123b85f3452cc3de83d9",
          "cited_paper_url": "https://www.semanticscholar.org/paper/5aa26299435bdf7db874ef1640a6c3b5a4a2c394",
          "citing_paper_year": 2022,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "245123993",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "ValueNet"
      ],
      "dataset_details": [
        {
          "dataset_name": "ValueNet",
          "dataset_description": "Used to create a numeric speaker profile based on implied values in statements, focusing on the relationship between language and human values in dialogue systems.",
          "citing_paper_id": "257427629",
          "cited_paper_id": 245123993,
          "context_text": "The risk of ‘value proﬁling’ is evidenced by Qiu et al. [192]’s recent work which uses an LLM to create a numeric speaker proﬁle – where for example, the authors say that a speaker “saying ‘I miss my mum’ implies that the speaker values benevolence” (p.7) while the speaker “saying ’forcing my…",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'ValueNet', which is a dataset for human value-driven dialogue systems, and it is used to create a numeric speaker profile based on the values implied by their statements.",
          "citing_paper_doi": "10.48550/arXiv.2303.05453",
          "cited_paper_doi": "10.1609/aaai.v36i10.21368",
          "citing_paper_url": "https://www.semanticscholar.org/paper/e5174aeda1baa67c17f4ac630ae2e44453954cc3",
          "cited_paper_url": "https://www.semanticscholar.org/paper/3af37400f1f9a4f4f211c4a472e18963edc2b34f",
          "citing_paper_year": 2023,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "49667950",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "FlickrStyle10K"
      ],
      "dataset_details": [
        {
          "dataset_name": "FlickrStyle10K",
          "dataset_description": "Used to train single-style captioners, leveraging both factual and stylized captions to generate personalized text descriptions of images.",
          "citing_paper_id": "232306930",
          "cited_paper_id": 49667950,
          "context_text": "With FlickrStyle10K, researchers have built singlestyle captioners (Gan et al. 2017; Chen et al. 2018) where they make use of both factual captions and stylized captions for training.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "FlickrStyle10K is mentioned as a dataset used for training single-style captioners, which aligns with the topic of personalized text generation.",
          "citing_paper_doi": "10.32473/FLAIRS.V34I1.128380",
          "cited_paper_doi": "10.1007/978-3-030-01249-6_32",
          "citing_paper_url": "https://www.semanticscholar.org/paper/ac226bcdf49f294e57a59ebabe5036a3eccf9175",
          "cited_paper_url": "https://www.semanticscholar.org/paper/abc7998326cc4fc3c9c0c3a9ede8ae2538439966",
          "citing_paper_year": 2021,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "53022581",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "PERSONALITY-CAPTIONS"
      ],
      "dataset_details": [
        {
          "dataset_name": "PERSONALITY-CAPTIONS",
          "dataset_description": "Used to generate engaging and conversational captions, focusing on creating more interactive and human-like image descriptions. | Used to train and evaluate a model for generating personalized captions, focusing on engaging image captioning with personality traits. | Used to train a method for generating engaging image captions with personality, focusing on improving the quality and relevance of captions through retraining with a subset of the original dataset. | Used to generate engaging and human-like style captions, focusing on improving the quality and personality of image captions through a dataset of ground truth captions. | Used to generate captions with Humorous or Romantic styles, focusing on linguistic variation in image captioning. | Used to generate engaging and conversational image captions, focusing on creating a more interactive and personalized user experience in image captioning systems. | Used to build engaging caption generation models, specifically focusing on generating captions with distinct personalities. The dataset contains 215 personalities, enhancing the diversity and engagement of generated captions.",
          "citing_paper_id": "232306930",
          "cited_paper_id": 53022581,
          "context_text": "In total, we train 30 epochs when using the PERSONALITY-CAPTIONS dataset (Shuster et al. 2019) with a batch size of 128 and evaluate the model every 3000 iterations.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the use of the PERSONALITY-CAPTIONS dataset for training and evaluating a model, which is directly relevant to personalized text generation.",
          "citing_paper_doi": "10.32473/FLAIRS.V34I1.128380",
          "cited_paper_doi": "10.1109/CVPR.2019.01280",
          "citing_paper_url": "https://www.semanticscholar.org/paper/ac226bcdf49f294e57a59ebabe5036a3eccf9175",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2",
          "citing_paper_year": 2021,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "2210455",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "COCO-captions"
      ],
      "dataset_details": [
        {
          "dataset_name": "COCO-captions",
          "dataset_description": "Used to compare ArtEmis along dimensions of concreteness, subjectivity, and sentiment, providing a benchmark for evaluating generated captions. | Used to collect discriminative utterances for 3D objects, focusing on the linguistic representation of 3D shapes and their attributes. | Used to train and test models on linguistic similarity metrics, comparing performance against held-out utterances in personalized text generation. | Used to evaluate caption generation models, focusing on the distribution of sentiment in generated captions compared to neutral sentiment in ArtEmis.",
          "citing_paper_id": "231639297",
          "cited_paper_id": 2210455,
          "context_text": "First, we observe that on metrics that measure the linguistic similarity to the held-out utterances (BLEU, METEOR, etc.) the speakers fare noticeably worse as compared to how the same architectures fare (modulo secondary-order details) when trained and tested with objective datasets like COCO-captions; e.g., BLEU-1 with SOTA [15] is 82.0.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'COCO-captions' as a dataset used for training and testing models, which is relevant to personalized text generation.",
          "citing_paper_doi": "10.1109/CVPR46437.2021.01140",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/3c6a6adffc390f56942b0c8f9b1d246acc7dd1e1",
          "cited_paper_url": "https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628",
          "citing_paper_year": 2021,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "236034497",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "MSC"
      ],
      "dataset_details": [
        {
          "dataset_name": "MSC",
          "dataset_description": "Used to extend PersonaChat with multi-session conversations, annotated with summaries of important personal points for personalized text generation.",
          "citing_paper_id": "247411350",
          "cited_paper_id": 236034497,
          "context_text": "Recently, Xu et al. (2021) proposed MSC dataset as a multi-session extension of PersonaChat, and its sessions are additionally annotated with summaries of important personal points.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the MSC dataset, which is a specific, verifiable dataset used for multi-session conversations with personal point summaries.",
          "citing_paper_doi": "10.48550/arXiv.2203.05797",
          "cited_paper_doi": "10.18653/v1/2022.acl-long.356",
          "citing_paper_url": "https://www.semanticscholar.org/paper/081edae651e709e448bdd8a1f1b5760c7c7e1f53",
          "cited_paper_url": "https://www.semanticscholar.org/paper/88064de690af282dbdf222774f03ff070b9df22b",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "271403894",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "PEC"
      ],
      "dataset_details": [
        {
          "dataset_name": "PEC",
          "dataset_description": "Used to train empathetic conversational models, focusing on persona-based interactions in multilingual settings. | Used to train conversational models, focusing on persona-based interactions in English.",
          "citing_paper_id": "247411350",
          "cited_paper_id": 271403894,
          "context_text": ", 2020) Text 7 16,878 Multilingual Yes PEC (Zhong et al., 2020) Text 7 355,000 English Yes PCR (Mazaré et al.",
          "confidence_score": 0.9,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'PEC' and 'PCR' which appear to be dataset acronyms. The cited paper title suggests these are related to persona-based conversational models.",
          "citing_paper_doi": "10.48550/arXiv.2203.05797",
          "cited_paper_doi": "10.18653/v1/2020.emnlp-main.531",
          "citing_paper_url": "https://www.semanticscholar.org/paper/081edae651e709e448bdd8a1f1b5760c7c7e1f53",
          "cited_paper_url": "https://www.semanticscholar.org/paper/7b73f7e59fe584a8760d86731fec503e2ae8b52c",
          "citing_paper_year": 2022,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "9126867",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Books Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "Books Corpus",
          "dataset_description": "Used to train models for personalized text generation, focusing on capturing narrative and stylistic elements in the text.",
          "citing_paper_id": "748227",
          "cited_paper_id": 9126867,
          "context_text": "For this experiment and subsequent analysis, we train our models on the Books Corpus introduced in Kiros et al. (2015).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the 'Books Corpus' as a training dataset for the models. The corpus is introduced in Kiros et al. (2015), which aligns with the cited paper title 'Skip-Thought Vectors'.",
          "citing_paper_doi": "10.18653/v1/K16-1002",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/d82b55c35c8673774a708353838918346f6c006f",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8",
          "citing_paper_year": 2015,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "8140521",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "BAM! The Behance Artistic Media Dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "BAM! The Behance Artistic Media Dataset",
          "dataset_description": "Used to introduce a large-scale dataset of artistic imagery with multiple attribute annotations, aimed at recognition beyond photography, enhancing personalized text generation through diverse visual inputs.",
          "citing_paper_id": "231639297",
          "cited_paper_id": 8140521,
          "context_text": "Last, the work of [59] introduces a large scale dataset of artistic imagery with multiple attribute annotations.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions a 'large scale dataset of artistic imagery with multiple attribute annotations', which fits the criteria for a dataset. The title 'BAM! The Behance Artistic Media Dataset for Recognition Beyond Photography' confirms it is a dataset.",
          "citing_paper_doi": "10.1109/CVPR46437.2021.01140",
          "cited_paper_doi": "10.1109/ICCV.2017.136",
          "citing_paper_url": "https://www.semanticscholar.org/paper/3c6a6adffc390f56942b0c8f9b1d246acc7dd1e1",
          "cited_paper_url": "https://www.semanticscholar.org/paper/820b1349751d7e932b74c3de94b96557fa2534cf",
          "citing_paper_year": 2021,
          "cited_paper_year": 2017
        }
      ]
    },
    {
      "cited_paper_id": "150728988",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "International Affective Picture System"
      ],
      "dataset_details": [
        {
          "dataset_name": "International Affective Picture System",
          "dataset_description": "Used to capture discrete emotions, specifically the four negative emotions considered universal and basic, to inform the development of personalized text generation systems.",
          "citing_paper_id": "231639297",
          "cited_paper_id": 150728988,
          "context_text": "The four negative emotions are considered universal and basic (as proposed by Ekman in [22]) and have been shown to capture well the discrete emotions of the International Affective Picture System [11].",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions the International Affective Picture System (IAPS) as a resource used to capture discrete emotions, which is relevant to the study of personalized text generation.",
          "citing_paper_doi": "10.1109/CVPR46437.2021.01140",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/3c6a6adffc390f56942b0c8f9b1d246acc7dd1e1",
          "cited_paper_url": "https://www.semanticscholar.org/paper/c1dc86893e05716961bb674d025011a397b60b1a",
          "citing_paper_year": 2021,
          "cited_paper_year": 2007
        }
      ]
    },
    {
      "cited_paper_id": "unknown",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Svevo Corpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "Svevo Corpus",
          "dataset_description": "Used to evaluate ETC-NLG's effectiveness on a topic-annotated Italian epistolary corpus containing archaic and dialectal terms, focusing on personalized text generation. | Used to evaluate the performance of the GePpeTto generator, specifically assessing its ability to generate text in an epistolary style. | Used to demonstrate conditioned text generation capabilities of ETC-NLG, focusing on producing meaningful sentences despite high perplexity. | Used to generate 120 sentences for personalized text generation, focusing on Italian-English parallel text. | Used to generate 120 sentences for personalized text generation, focusing on English-Italian parallel text. | Utilized for contextual annotations, presenting top 5 topic-related keywords from the prevalent topic extracted through topic modeling. | Used to evaluate ETC-NLG on a topic-annotated Italian epistolary corpus containing archaic and dialectal terms, focusing on personalized text generation. | Used to generate 72 sentences for personalized text generation, with additional 72 gold-labeled sentences for human evaluation. | Used to test ETC-NLG on the Italian subset, focusing on the impact of dialectal and archaic expressions on the quality of generated sentences. | Used to study sequences ranging from few words to multiple sentences, focusing on the structure and variability of text for personalized generation. | Used for gold annotations with keywords representing different topics, aiding in the study of personalized text generation.",
          "citing_paper_id": "221293335",
          "cited_paper_id": null,
          "context_text": "We produce a total of 72 sentences on the Svevo Corpus (plus another 72 on gold labels for human evaluation) and 120 sentences each for both EuroParl-IT and EuroParl-EN.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used for generating sentences, which are relevant to personalized text generation.",
          "citing_paper_doi": "10.4000/ijcol.728",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/e4b3bc794665887c874600b177730286c6527836",
          "cited_paper_url": null,
          "citing_paper_year": 2020,
          "cited_paper_year": null
        }
      ]
    },
    {
      "cited_paper_id": "4937880",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "possessed dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "possessed dataset",
          "dataset_description": "Used for sentiment and style transfer experiments, specifically to evaluate the effectiveness of delete, retrieve, generate approach in modifying text attributes.",
          "citing_paper_id": "153313581",
          "cited_paper_id": 4937880,
          "context_text": "Following previous work, we use the possessed dataset provided by Li et al. (2018).",
          "confidence_score": 0.8,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'possessed dataset' which is a plausible dataset name, and it is used in the context of sentiment and style transfer.",
          "citing_paper_doi": "10.18653/v1/P19-1601",
          "cited_paper_doi": "10.18653/v1/N18-1169",
          "citing_paper_url": "https://www.semanticscholar.org/paper/ae60d15ec4f6c3839df2db19154ee5971a1e9640",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1975ae6d8693eedfb07d5348798351fe51ab242b",
          "citing_paper_year": 2019,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "53298765",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "DialogueNLI"
      ],
      "dataset_details": [
        {
          "dataset_name": "DialogueNLI",
          "dataset_description": "Used to fine-tune a model for the PersonaChat domain, focusing on improving the model's ability to understand and generate contextually appropriate responses. | Used to train an NLI model to assess the consistency between generated responses and persona sentences, focusing on personalized text generation. | Used to evaluate response consistency with provided personas in dialogue systems, focusing on the quality and coherence of generated responses.",
          "citing_paper_id": "248299824",
          "cited_paper_id": 53298765,
          "context_text": ", 2019) (C) is involved, where we follow the default setting and use the output of an NLI model trained on the DialogueNLI dataset (Welleck et al., 2019) to indicate the consistency between a response and persona sentences.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the DialogueNLI dataset, which is a specific dataset used for training an NLI model to assess consistency between responses and persona sentences.",
          "citing_paper_doi": "10.48550/arXiv.2204.09867",
          "cited_paper_doi": "10.18653/v1/P19-1363",
          "citing_paper_url": "https://www.semanticscholar.org/paper/11e295b8fd91a893efe7259d789936fc116f7792",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1dc04035b9926c46ded436e5762f3924ab29516e",
          "citing_paper_year": 2022,
          "cited_paper_year": 2018
        }
      ]
    },
    {
      "cited_paper_id": "7983519",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "b5-ref subcorpus"
      ],
      "dataset_details": [
        {
          "dataset_name": "b5-ref subcorpus",
          "dataset_description": "Intended for future semantic annotation to enhance NLG studies, focusing on generating referring expressions in text. | Intended for future semantic annotation to enhance NLG studies, focusing on generating referring expressions in image captions. | Used to study the effects of human personality on the generation of referring expressions, focusing on how personality traits influence the creation of REGs in NLG.",
          "citing_paper_id": "21691164",
          "cited_paper_id": 7983519,
          "context_text": "The b5-ref subcorpus was built for the study of the effects of human personality on the generation of referring expressions (REG), which is an active research topic in NLG (Krahmer and van Deemter, 2012).",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions 'b5-ref subcorpus' as a specific dataset used for studying the effects of human personality on the generation of referring expressions.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.1162/COLI_a_00088",
          "citing_paper_url": "https://www.semanticscholar.org/paper/547a6c2a15f8b40c015c7515abf3680a5df74d85",
          "cited_paper_url": "https://www.semanticscholar.org/paper/ee4fe11884eca58a76ea797f102bbd5c3c67137b",
          "citing_paper_year": 2018,
          "cited_paper_year": 2012
        }
      ]
    },
    {
      "cited_paper_id": "209376338",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Common Voice"
      ],
      "dataset_details": [
        {
          "dataset_name": "Common Voice",
          "dataset_description": "Used to collect speech data for 2 Portuguese and 2 English speakers (1M/1F), focusing on voice diversity and quality for personalized text generation.",
          "citing_paper_id": "244908340",
          "cited_paper_id": 209376338,
          "context_text": "for 2 Portuguese and 2 English speakers (1M/1F) in the Common Voice [38] dataset.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions the 'Common Voice' dataset, which is a specific, verifiable resource used for speech data. It is clearly identified and used in the context of the research.",
          "citing_paper_doi": null,
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/d627f41961d42beb56081904025bd1d5f88b788b",
          "cited_paper_url": "https://www.semanticscholar.org/paper/63a71de0dafc90910e37a2b07169ff486d9b5fe5",
          "citing_paper_year": 2021,
          "cited_paper_year": 2019
        }
      ]
    },
    {
      "cited_paper_id": "226202134",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "VCTK"
      ],
      "dataset_details": [
        {
          "dataset_name": "VCTK",
          "dataset_description": "Used to evaluate MOS and Sim-MOS scores in English, focusing on speech quality and similarity in personalized text generation. | Used to evaluate MOS and Sim-MOS scores in Portuguese, focusing on speech quality and similarity in personalized text generation.",
          "citing_paper_id": "244908340",
          "cited_paper_id": 226202134,
          "context_text": "Table 1 shows MOS and Sim-MOS with 95% confidence intervals and SECS for all of our experiments in English for the datasets VCTK and LibriTTS and in Portuguese with the Portuguese sub-set of the dataset MLS.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions specific datasets used for experiments in English and Portuguese, which are relevant to personalized text generation.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.21437/Interspeech.2020-2826",
          "citing_paper_url": "https://www.semanticscholar.org/paper/d627f41961d42beb56081904025bd1d5f88b788b",
          "cited_paper_url": "https://www.semanticscholar.org/paper/fef7e29b43e838a0e4bce39add6361c7bcfeb456",
          "citing_paper_year": 2021,
          "cited_paper_year": 2020
        }
      ]
    },
    {
      "cited_paper_id": "207655542",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "GAPED"
      ],
      "dataset_details": [
        {
          "dataset_name": "GAPED",
          "dataset_description": "Used to study valence and normative significance in images, focusing on emotional responses and affective processing in personalized text generation.",
          "citing_paper_id": "21691164",
          "cited_paper_id": 207655542,
          "context_text": "In the present work, images were taken from the GAPED (Dan-Glauser and Scherer, 2011), Face Place (Righi et al.",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "GAPED is identified as a specific dataset from the citation context and the title confirms it is a picture database. Face Place is mentioned but cut off, so it is excluded due to lack of context.",
          "citing_paper_doi": null,
          "cited_paper_doi": "10.3758/s13428-011-0064-1",
          "citing_paper_url": "https://www.semanticscholar.org/paper/547a6c2a15f8b40c015c7515abf3680a5df74d85",
          "cited_paper_url": "https://www.semanticscholar.org/paper/755ef09cc0f7593b792482edc5bf799138243acf",
          "citing_paper_year": 2018,
          "cited_paper_year": 2011
        }
      ]
    },
    {
      "cited_paper_id": "265220723",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "HelpSteer"
      ],
      "dataset_details": [
        {
          "dataset_name": "HelpSteer",
          "dataset_description": "Used to conduct additional experiments on multi-attribute helpfulness, focusing on the effectiveness of SteerLM in generating personalized text.",
          "citing_paper_id": "270764846",
          "cited_paper_id": 265220723,
          "context_text": "Additional experiments on the HelpSteer [50] task are provided in Appendix F.4.",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions 'HelpSteer' in the context of additional experiments, and the title confirms it is a dataset.",
          "citing_paper_doi": "10.48550/arXiv.2406.18853",
          "cited_paper_doi": "10.48550/arXiv.2311.09528",
          "citing_paper_url": "https://www.semanticscholar.org/paper/8b89036b5136b081867fbec089801b2bd4ab0685",
          "cited_paper_url": "https://www.semanticscholar.org/paper/711ac30df7909fc9de881933580c642e7c3e2b08",
          "citing_paper_year": 2024,
          "cited_paper_year": 2023
        }
      ]
    },
    {
      "cited_paper_id": "270227321",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "fixed preference dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "fixed preference dataset",
          "dataset_description": "Used to train a reward representation in a reward-model-free manner, focusing on multi-objective direct preference optimization for language models.",
          "citing_paper_id": "270764846",
          "cited_paper_id": 270227321,
          "context_text": "And MODPO [62] retrains the model in a reward-model-free way, by learning a flexible reward representation and directly training on a fixed preference dataset.",
          "confidence_score": 0.6,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions 'fixed preference dataset' which is a plausible dataset name, but lacks specificity. The title does not provide additional clarity.",
          "citing_paper_doi": "10.48550/arXiv.2406.18853",
          "cited_paper_doi": "10.48550/arXiv.2310.03708",
          "citing_paper_url": "https://www.semanticscholar.org/paper/8b89036b5136b081867fbec089801b2bd4ab0685",
          "cited_paper_url": "https://www.semanticscholar.org/paper/b7c01c660055dc91ac8de8621d5f823f0aa3c46e",
          "citing_paper_year": 2024,
          "cited_paper_year": 2023
        }
      ]
    },
    {
      "cited_paper_id": "6078795",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "Twitter Persona Dataset"
      ],
      "dataset_details": [
        {
          "dataset_name": "Twitter Persona Dataset",
          "dataset_description": "Used to evaluate personalized text generation models, focusing on generating responses that align with user personas. The dataset provides context for tuning and evaluating model performance.",
          "citing_paper_id": "2955580",
          "cited_paper_id": 6078795,
          "context_text": "et al., 2016) we used BLEU (Papineni et al., 2002) for parameter tuning and evaluation. BLEU has been shown to correlate well with human judgment on the response generation task, as demonstrated in (Galley et al., 2015). Besides BLEU scores, we also report perplexity as an indicator of model capability. 6.2 Baseline Since our main experiments are with a new dataset (the Twitter Persona Dataset), we ﬁrst show that ou",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a new dataset called 'Twitter Persona Dataset' which is relevant to personalized text generation. No other specific datasets are mentioned.",
          "citing_paper_doi": "10.18653/v1/P16-1094",
          "cited_paper_doi": "10.3115/v1/P15-2073",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1ea75cdb7ce8c4f5f2599165e3698034b4142e08",
          "cited_paper_url": "https://www.semanticscholar.org/paper/7d0684b19ba46e739e28baa1e180c008226f793a",
          "citing_paper_year": 2016,
          "cited_paper_year": 2015
        }
      ]
    },
    {
      "cited_paper_id": "17047584",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "OpenSubtitles (OSDb)"
      ],
      "dataset_details": [
        {
          "dataset_name": "OpenSubtitles (OSDb)",
          "dataset_description": "Used for pre-training models on a large multilingual parallel corpus before adapting to a TV series dataset, focusing on improving personalized text generation. | Used for pre-training models before adapting them to a TV series dataset, focusing on improving BLEU scores through large-scale multilingual data.",
          "citing_paper_id": "2955580",
          "cited_paper_id": 17047584,
          "context_text": "models using a much larger OpenSubtitles (OSDb) dataset (Tiedemann, 2009), and then adapting the pre-trained model to the TV series dataset.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the OpenSubtitles (OSDb) dataset, which is a specific, verifiable resource. It is used for pre-training models before adapting them to a TV series dataset.",
          "citing_paper_doi": "10.18653/v1/P16-1094",
          "cited_paper_doi": "10.1075/cilt.309.19tie",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1ea75cdb7ce8c4f5f2599165e3698034b4142e08",
          "cited_paper_url": "https://www.semanticscholar.org/paper/fbd201207e51f50f14235c5ea864ccccb6425325",
          "citing_paper_year": 2016,
          "cited_paper_year": 2009
        }
      ]
    },
    {
      "cited_paper_id": "1428702",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "IMDB movie reviews"
      ],
      "dataset_details": [
        {
          "dataset_name": "IMDB movie reviews",
          "dataset_description": "Used to train an external sentiment classifier for evaluating attribute control in the current research, focusing on sentiment analysis of text. | Used to evaluate attribute control with an external sentiment classifier, focusing on sentiment analysis performance and comparing different approaches.",
          "citing_paper_id": "208617790",
          "cited_paper_id": 1428702,
          "context_text": "We also evaluate attribute control with an external sentiment classifier trained on IMDB movie reviews (Maas et al., 2011), which is a different dataset from the one used to train the attribute model (Socher et al.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the use of an external sentiment classifier trained on IMDB movie reviews, which is a specific dataset. The dataset is used to evaluate attribute control in the current research.",
          "citing_paper_doi": null,
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/e04a80263d252a3d8a382ba37a249b9345620570",
          "cited_paper_url": "https://www.semanticscholar.org/paper/1c61f9ef06fe74505775a833ff849185757199e7",
          "citing_paper_year": 2019,
          "cited_paper_year": 2011
        }
      ]
    },
    {
      "cited_paper_id": "unknown",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "HellaSwag"
      ],
      "dataset_details": [
        {
          "dataset_name": "HellaSwag",
          "dataset_description": "Used to evaluate the performance of generating the first token after a start token, focusing on the initial token prediction accuracy.",
          "citing_paper_id": "168169824",
          "cited_paper_id": null,
          "context_text": "Generating the first token after <startbody> results in high\n13This matches findings on the HellaSwag dataset (Zellers et al., 2019b).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The citation mentions the HellaSwag dataset, which is a specific, verifiable resource used in the context of generating the first token after a start token.",
          "citing_paper_doi": null,
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/ad7129af0644dbcafa9aa2f111cb76526ea444a1",
          "cited_paper_url": null,
          "citing_paper_year": 2019,
          "cited_paper_year": null
        }
      ]
    },
    {
      "cited_paper_id": "235457994",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "BABEL"
      ],
      "dataset_details": [
        {
          "dataset_name": "BABEL",
          "dataset_description": "Used to train the MotionDiffuse model, focusing on bodies, action, and behavior with English labels, enhancing personalized text generation through motion data. | Re-annotated with English language labels by BA-BEL and HumanML3D, used for generating diverse and natural 3D human motions from text, enhancing personalized text-to-motion synthesis.",
          "citing_paper_id": "251953565",
          "cited_paper_id": 235457994,
          "context_text": "Implementation Details: We train our proposed MotionDif-fuse on the BABEL dataset [72] with 50 K iterations.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The context mentions the BABEL dataset, which is a specific, verifiable dataset with a clear name and is used for training the MotionDiffuse model.",
          "citing_paper_doi": "10.1109/TPAMI.2024.3355414",
          "cited_paper_doi": "10.1109/CVPR46437.2021.00078",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1bbf99b5bfe9869876ac3bdd2999e16b2632c283",
          "cited_paper_url": "https://www.semanticscholar.org/paper/fe9bc34b3e3b181de6caee3ff79e9c5bf1bbcf98",
          "citing_paper_year": 2022,
          "cited_paper_year": 2021
        }
      ]
    },
    {
      "cited_paper_id": "250602257",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "AMASS"
      ],
      "dataset_details": [
        {
          "dataset_name": "AMASS",
          "dataset_description": "Re-annotated with English language labels by BA-BEL and HumanML3D, used for generating diverse and natural 3D human motions from text, enhancing personalized text-to-motion synthesis.",
          "citing_paper_id": "251953565",
          "cited_paper_id": 250602257,
          "context_text": "Recently, BA-BEL [72] and HumanML3D [48] re-annotates AMASS [73], a large scale motion capture dataset, with English language labels.",
          "confidence_score": 0.9,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "AMASS is identified as a large-scale motion capture dataset re-annotated with English language labels by BA-BEL and HumanML3D. The context indicates the dataset is used for generating diverse and natural 3D human motions from text.",
          "citing_paper_doi": "10.1109/TPAMI.2024.3355414",
          "cited_paper_doi": "10.1109/CVPR52688.2022.00509",
          "citing_paper_url": "https://www.semanticscholar.org/paper/1bbf99b5bfe9869876ac3bdd2999e16b2632c283",
          "cited_paper_url": "https://www.semanticscholar.org/paper/4ccb30b632d847764591481bde34613b69530692",
          "citing_paper_year": 2022,
          "cited_paper_year": 2022
        }
      ]
    },
    {
      "cited_paper_id": "16282767",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "TripAdvisor"
      ],
      "dataset_details": [
        {
          "dataset_name": "TripAdvisor",
          "dataset_description": "Used for language modeling, incorporating hotel identifiers and sentiment scores ranging from one to five stars to generate context-aware text.",
          "citing_paper_id": "19096382",
          "cited_paper_id": 16282767,
          "context_text": "Our fourth dataset, from TripAdvisor, was previously used for language modeling and consists of two relevant context variables: an identifier for the hotel and a sentiment score from one to five stars (Tang et al., 2016).",
          "confidence_score": 1.0,
          "citation_intent": "reusable resource",
          "resource_type": "dataset",
          "reasoning": "The context mentions a specific dataset from TripAdvisor, which is used for language modeling and includes hotel identifiers and sentiment scores.",
          "citing_paper_doi": "10.1162/tacl_a_00035",
          "cited_paper_doi": null,
          "citing_paper_url": "https://www.semanticscholar.org/paper/5835af39301c156456a1c7168f44ba9321b50278",
          "cited_paper_url": "https://www.semanticscholar.org/paper/e87096b110ad0dd22226931208c0c7f1a94df098",
          "citing_paper_year": 2017,
          "cited_paper_year": 2016
        }
      ]
    },
    {
      "cited_paper_id": "6869582",
      "citation_count": 0,
      "total_dataset_mentions": 1,
      "unique_datasets": [
        "C HAT"
      ],
      "dataset_details": [
        {
          "dataset_name": "C HAT",
          "dataset_description": "Used to train chatbots with configurable and persistent personalities, specifically by providing profile sentences for both interlocutors, enhancing personalized dialogue generation. | Used to train and evaluate dialogue agents personalized with personas, focusing on multi-turn dialogues to enhance conversational coherence and personalization. | Used to evaluate personalized dialogue agents, demonstrating superiority in automatic metrics and human evaluations through comparative analysis.",
          "citing_paper_id": "215745354",
          "cited_paper_id": 6869582,
          "context_text": "C HAT dataset contains 8,939 / 1,000 multi-turn dialogues conditioned on 1,155 / 100 per-sonas for train / dev.",
          "confidence_score": 1.0,
          "citation_intent": [
            "b",
            "o",
            "r",
            "a",
            " ",
            "s",
            "c",
            "u",
            "l",
            "e"
          ],
          "resource_type": [
            "a",
            "t",
            "d",
            "s",
            "e"
          ],
          "reasoning": "The C HAT dataset is explicitly mentioned and described, fitting the criteria for a specific, verifiable dataset.",
          "citing_paper_doi": "10.18653/v1/2020.acl-main.131",
          "cited_paper_doi": "10.18653/v1/P18-1205",
          "citing_paper_url": "https://www.semanticscholar.org/paper/298a68153859303ee70b3ef1525ee9c7031e32f5",
          "cited_paper_url": "https://www.semanticscholar.org/paper/6c7046195f64cccac1ed3275d88d77655534b5a4",
          "citing_paper_year": 2020,
          "cited_paper_year": 2018
        }
      ]
    }
  ],
  "citation_count_distribution": {
    "9135567": 1,
    "11860229": 1,
    "14021168": 1,
    "60514661": 1,
    "218973759": 1,
    "230435736": 1,
    "235792273": 1,
    "238252929": 2,
    "239050492": 1,
    "256631001": 1,
    "257353840": 1,
    "257921893": 1,
    "258741409": 1,
    "964287": 7,
    "52167799": 2,
    "202767450": 3,
    "208513249": 1,
    "230433941": 2,
    "233296808": 2,
    "234757004": 1,
    "247693734": 2,
    "142610973": 1,
    "215548699": 1,
    "257766307": 1,
    "257913780": 1,
    "258298303": 7,
    "259108266": 1,
    "4786918": 1,
    "7961699": 4,
    "12900424": 2,
    "127986954": 3,
    "202797141": 1,
    "257804696": 1,
    "257921908": 1,
    "259251773": 1,
    "264289231": 3,
    "265308990": 1,
    "267523283": 3,
    "270560467": 2,
    "271218187": 2,
    "272512070": 1,
    "15595142": 1,
    "235187032": 2,
    "247427270": 1,
    "248779887": 1,
    "267547503": 3,
    "268710872": 1,
    "6628106": 4,
    "13907106": 1,
    "27308776": 1,
    "58370896": 1,
    "211043589": 1,
    "220302360": 1,
    "226227230": 1,
    "251371732": 1,
    "253522998": 1,
    "254044526": 1,
    "258461170": 1,
    "259064099": 2,
    "261823330": 1,
    "263605962": 1,
    "265213422": 1,
    "266359151": 1,
    "267523232": 3,
    "269149624": 1,
    "269740933": 1,
    "271221933": 1,
    "277435679": 1,
    "207178704": 1,
    "258959321": 1,
    "261934663": 1,
    "263605618": 1,
    "265149781": 1,
    "266174252": 1,
    "269348048": 1,
    "275471754": 1,
    "2428314": 2,
    "7004303": 1,
    "8308769": 1,
    "14994977": 1,
    "57825713": 1,
    "166228669": 1,
    "199466300": 1,
    "201698258": 1,
    "221446550": 1,
    "260428188": 1,
    "490669": 1,
    "1911971": 1,
    "3558923": 1,
    "4642971": 1,
    "6862403": 1,
    "7160120": 1,
    "8407569": 1,
    "9424845": 1,
    "9619992": 1,
    "11080756": 7,
    "11349626": 1,
    "12924416": 1,
    "13752895": 3,
    "14600881": 1,
    "17865105": 3,
    "20981275": 1,
    "47019137": 2,
    "52880735": 1,
    "54089884": 1,
    "61222698": 1,
    "85543316": 1,
    "92979801": 1,
    "102352788": 1,
    "127953732": 2,
    "150207412": 1,
    "169453414": 1,
    "201645479": 1,
    "201666566": 1,
    "202714856": 1,
    "202789109": 1,
    "204874165": 1,
    "207847197": 1,
    "208617790": 5,
    "210507349": 1,
    "218971825": 1,
    "220936592": 1,
    "221882637": 1,
    "224705254": 1,
    "232126410": 1,
    "234337004": 1,
    "234790153": 1,
    "235623756": 1,
    "235703107": 1,
    "236468577": 1,
    "243865608": 1,
    "244478160": 1,
    "7200347": 1,
    "16289845": 1,
    "225047150": 1,
    "253237200": 2,
    "257557227": 1,
    "258841328": 1,
    "259375553": 1,
    "260866107": 1,
    "266899669": 1,
    "276558227": 1,
    "3348552": 1,
    "6869582": 3,
    "10488675": 1,
    "170076423": 1,
    "202621357": 1,
    "233473617": 1,
    "256415991": 1,
    "257219404": 3,
    "267200117": 1,
    "268510706": 1,
    "216009": 2,
    "1563370": 5,
    "233323280": 1,
    "244714366": 4,
    "245117814": 2,
    "247628171": 1,
    "248097655": 9,
    "248239727": 3,
    "248986576": 9,
    "251253049": 10,
    "256900833": 1,
    "257219968": 5,
    "257631648": 4,
    "257913352": 3,
    "259847576": 2,
    "264815845": 2,
    "2927709": 1,
    "4676177": 1,
    "7051992": 1,
    "38400465": 1,
    "52814523": 1,
    "207847600": 1,
    "219635496": 1,
    "219955663": 11,
    "231572865": 1,
    "235458009": 10,
    "237303799": 1,
    "244909410": 3,
    "245335280": 14,
    "247618995": 1,
    "248227997": 1,
    "248505896": 1,
    "251649167": 1,
    "254636532": 1,
    "257050406": 1,
    "257404977": 1,
    "257482847": 1,
    "257687714": 2,
    "257687839": 1,
    "257766375": 2,
    "258509524": 1,
    "260082364": 1,
    "260777645": 1,
    "261049723": 1,
    "326772": 3,
    "3531856": 1,
    "14124313": 2,
    "206592484": 1,
    "211296702": 2,
    "232147378": 1,
    "233476314": 1,
    "245117331": 2,
    "245335086": 2,
    "249926846": 5,
    "253734226": 1,
    "255372955": 2,
    "101534": 1,
    "2454882": 1,
    "21357771": 1,
    "53558598": 1,
    "141803939": 1,
    "149560834": 1,
    "198854435": 1,
    "222177356": 1,
    "235700375": 1,
    "12803511": 1,
    "218971783": 4,
    "227209335": 1,
    "245704504": 2,
    "252596252": 1,
    "256627601": 2,
    "257622962": 1,
    "258170077": 2,
    "259252065": 1,
    "259298715": 1,
    "259316242": 1,
    "260202961": 1,
    "263671542": 1,
    "263830433": 1,
    "263831566": 1,
    "263908890": 1,
    "3864050": 1,
    "4844572": 1,
    "9026666": 1,
    "52902832": 1,
    "52967399": 7,
    "57246310": 1,
    "92996193": 1,
    "104292176": 1,
    "197928119": 2,
    "211066479": 1,
    "232306930": 1,
    "235097581": 1,
    "23763057": 1,
    "204402699": 1,
    "214410607": 1,
    "222140788": 6,
    "226742001": 1,
    "253069389": 1,
    "256416326": 1,
    "257364757": 3,
    "258436985": 4,
    "258999106": 1,
    "259252486": 1,
    "260387426": 1,
    "260849232": 1,
    "261101003": 1,
    "264492267": 1,
    "266177436": 1,
    "220665910": 1,
    "221818900": 1,
    "233241040": 1,
    "247518748": 1,
    "250607505": 1,
    "250698823": 1,
    "257833572": 1,
    "258509029": 1,
    "980236": 2,
    "3719281": 2,
    "7023610": 1,
    "8858625": 3,
    "9417016": 1,
    "10319744": 4,
    "13756489": 10,
    "19046372": 1,
    "52889459": 1,
    "54482423": 4,
    "214713859": 1,
    "220871180": 1,
    "235702618": 1,
    "251800180": 7,
    "253581213": 3,
    "256827727": 5,
    "53592270": 3,
    "257557484": 2,
    "257767281": 1,
    "258866047": 1,
    "263671961": 1,
    "9197196": 1,
    "51729727": 1,
    "221819581": 1,
    "232185275": 1,
    "250526766": 1,
    "254823489": 1,
    "254877751": 1,
    "257232490": 2,
    "257427629": 1,
    "2645819": 1,
    "3310672": 1,
    "3639844": 1,
    "12387176": 1,
    "211818224": 1,
    "211818320": 1,
    "219964874": 2,
    "234357997": 3,
    "253254800": 2,
    "256662278": 1,
    "1238927": 2,
    "88524997": 3,
    "174801388": 1,
    "211020900": 1,
    "231846815": 1,
    "232092620": 1,
    "9176830": 1,
    "14924561": 1,
    "52895470": 1,
    "91183909": 1,
    "142861440": 1,
    "196834421": 1,
    "203591432": 1,
    "209377041": 1,
    "211171538": 1,
    "214743564": 1,
    "215548657": 1,
    "229212848": 1,
    "231592822": 2,
    "231603119": 2,
    "231802331": 1,
    "235390635": 1,
    "235658331": 1,
    "236950721": 1,
    "237386023": 1,
    "241033103": 1,
    "244772984": 1,
    "244773443": 1,
    "247157966": 1,
    "249145348": 2,
    "250644432": 1,
    "250956830": 1,
    "46898260": 1,
    "53103701": 1,
    "198897678": 1,
    "202577442": 1,
    "214802845": 2,
    "218719151": 1,
    "236772156": 1,
    "251252882": 3,
    "252668838": 1,
    "252918469": 1,
    "256616002": 1,
    "60666": 1,
    "4492210": 2,
    "59182972": 1,
    "231632658": 3,
    "247939764": 1,
    "254853701": 2,
    "258546701": 1,
    "262054258": 1,
    "44134226": 2,
    "24986117": 1,
    "248834570": 1,
    "257766541": 1,
    "258352270": 1,
    "258352455": 1,
    "258841635": 1,
    "258959284": 1,
    "259165461": 1,
    "261243203": 1,
    "238582870": 1,
    "245855878": 1,
    "258841470": 1,
    "258841553": 2,
    "268297180": 1,
    "275342326": 1,
    "51608471": 2,
    "53298765": 2,
    "160025533": 4,
    "195873898": 1,
    "215745354": 1,
    "231847372": 1,
    "248299824": 1,
    "127986044": 4,
    "244488758": 1,
    "2955580": 3,
    "7338076": 1,
    "21691164": 1,
    "235666838": 1,
    "258267089": 1,
    "201701022": 1,
    "207761262": 1,
    "222278410": 1,
    "235313588": 1,
    "256221409": 1,
    "265609037": 1,
    "269148520": 1,
    "269983560": 2,
    "86611921": 1,
    "244906179": 1,
    "247922246": 1,
    "254408780": 7,
    "258041269": 1,
    "258079316": 3,
    "261917624": 1,
    "267211817": 1,
    "268247980": 1,
    "268512710": 1,
    "268667428": 1,
    "272398104": 1,
    "1687220": 1,
    "12275803": 1,
    "22727274": 1,
    "198967908": 2,
    "220714131": 1,
    "226281395": 1,
    "231639297": 1,
    "232035663": 4,
    "233296711": 2,
    "244908764": 1,
    "247292765": 1,
    "248227685": 1,
    "252917726": 3,
    "253116574": 1,
    "254408758": 2,
    "257952647": 2,
    "259243718": 1,
    "3693512": 1,
    "4704285": 1,
    "10409742": 1,
    "266052536": 2,
    "273532312": 1,
    "276742376": 1,
    "6292200": 1,
    "27290051": 1,
    "208248357": 1,
    "209445099": 1,
    "221971391": 1,
    "237941100": 1,
    "247447133": 1,
    "252780132": 1,
    "256868430": 1,
    "257079092": 1,
    "257235906": 1,
    "261378072": 1,
    "418729": 1,
    "819096": 1,
    "1646733": 1,
    "3416650": 1,
    "14246611": 1,
    "18933022": 1,
    "30673212": 1,
    "60848654": 1,
    "143407414": 1,
    "145565198": 1,
    "145589047": 1,
    "157695530": 1,
    "28780910": 1,
    "195767143": 1,
    "218872004": 1,
    "2765857": 1,
    "16282767": 1,
    "29161455": 4,
    "189762150": 1,
    "215873485": 1,
    "222133992": 1,
    "3000900": 1,
    "4413279": 1,
    "11952750": 1,
    "12190278": 1,
    "15164445": 1,
    "21464874": 1,
    "38629149": 1,
    "40740503": 1,
    "15676318": 1,
    "22987563": 1,
    "218630075": 1,
    "221090498": 1,
    "222291664": 2,
    "226202134": 1,
    "226976076": 1,
    "234778100": 1,
    "244908340": 1,
    "253062025": 1,
    "246472929": 1,
    "257262719": 1,
    "268091298": 1,
    "270843326": 1,
    "205010943": 1,
    "257532912": 1,
    "257687545": 1,
    "258179432": 1,
    "258841022": 1,
    "258960099": 1,
    "259342813": 1,
    "262064720": 1,
    "265722909": 1,
    "267320286": 1,
    "269294082": 1,
    "3038382": 1,
    "11767561": 1,
    "18754233": 1,
    "19228797": 1,
    "27572397": 1,
    "46940529": 1,
    "46941428": 1,
    "195891353": 1,
    "202660943": 1,
    "204960716": 2,
    "209387630": 1,
    "225159510": 1,
    "231915098": 1,
    "235368201": 2,
    "237485277": 1,
    "245218671": 1,
    "247762874": 1,
    "250390433": 1,
    "251308055": 1,
    "201669163": 1,
    "220968925": 1,
    "231591445": 6,
    "247778989": 1,
    "250607546": 1,
    "253760983": 1,
    "257427461": 1,
    "258546711": 1,
    "258888228": 3,
    "263792502": 1,
    "30484693": 1,
    "52941531": 1,
    "53093005": 1,
    "198169848": 1,
    "206593370": 1,
    "211677243": 1,
    "214693045": 1,
    "219980285": 1,
    "232148091": 1,
    "235731535": 1,
    "236088010": 1,
    "247292104": 1,
    "248157334": 1,
    "248476220": 1,
    "248986248": 1,
    "250113850": 1,
    "251040605": 1,
    "251224247": 1,
    "251953565": 1,
    "253080823": 1,
    "253761291": 1,
    "254043959": 1,
    "254221091": 1,
    "255942203": 1,
    "259262201": 1,
    "263830081": 1,
    "264935374": 1,
    "268041236": 1,
    "268876071": 1,
    "270063742": 1,
    "270226625": 1,
    "270226636": 1,
    "270878382": 1,
    "271161859": 1,
    "271244829": 1,
    "273001409": 1,
    "276117223": 1,
    "276317891": 1,
    "277677790": 1,
    "277857630": 1,
    "13995862": 1,
    "173990382": 1,
    "211146177": 1,
    "229297973": 2,
    "257557738": 1,
    "258078844": 1,
    "258740710": 2,
    "258887639": 1,
    "259138505": 2,
    "266736230": 1,
    "266999462": 2,
    "267212094": 1,
    "268183380": 1,
    "268248909": 1,
    "27282405": 1,
    "198317027": 1,
    "202120896": 1,
    "265149820": 1,
    "270563652": 1,
    "271746016": 1,
    "6200260": 1,
    "218763388": 1,
    "219708245": 1,
    "231979499": 3,
    "233168962": 1,
    "257757256": 1,
    "258967805": 1,
    "262084134": 1,
    "264128197": 1,
    "265609355": 1,
    "231802467": 1,
    "1473130": 1,
    "1586456": 1,
    "13690180": 1,
    "113562250": 1,
    "207869708": 2,
    "208006638": 1,
    "221969995": 2,
    "229348988": 1,
    "235826029": 1,
    "247058662": 1,
    "247411350": 1,
    "247628267": 1,
    "252918698": 1,
    "254591615": 1,
    "258378197": 1,
    "258823272": 1,
    "259370601": 1,
    "258887872": 1,
    "267198502": 1,
    "267583021": 1,
    "267638578": 1,
    "656562": 1,
    "22716243": 1,
    "54458806": 1,
    "196186167": 2,
    "198899669": 1,
    "202719307": 1,
    "237940272": 1,
    "16639476": 1,
    "169577694": 1,
    "172136697": 1,
    "207536026": 1,
    "229351463": 1,
    "237416585": 1,
    "245425088": 1,
    "246098480": 1,
    "252282839": 1,
    "252846393": 1,
    "254877310": 1,
    "257532815": 2,
    "257803126": 1,
    "258221707": 1,
    "261046857": 1,
    "261049152": 1,
    "261076002": 1,
    "264334422": 1,
    "264744285": 1,
    "266551049": 1,
    "266844311": 1,
    "268266688": 1,
    "269030019": 1,
    "269354751": 1,
    "270711489": 1,
    "273749420": 1,
    "274163373": 1,
    "274234014": 1,
    "275931918": 1,
    "276106991": 1,
    "276212530": 1,
    "276839200": 1,
    "277549219": 1,
    "225016068": 1,
    "665667": 1,
    "738850": 1,
    "748227": 2,
    "1055111": 1,
    "2024574": 2,
    "2057420": 1,
    "3527896": 1,
    "3626819": 1,
    "6126582": 3,
    "6203757": 1,
    "6484065": 1,
    "7164502": 2,
    "7356547": 2,
    "8379583": 3,
    "9447219": 2,
    "11212020": 4,
    "12300158": 3,
    "14067706": 1,
    "14941970": 1,
    "16447573": 2,
    "18347865": 1,
    "21669082": 2,
    "29797603": 2,
    "31298398": 2,
    "34405847": 2,
    "51608183": 2,
    "51609716": 2,
    "51609768": 1,
    "52136077": 1,
    "52159416": 1,
    "52307098": 1,
    "53217693": 2,
    "53218829": 1,
    "53287752": 2,
    "53771922": 1,
    "53955763": 2,
    "59316441": 2,
    "67855999": 1,
    "69778590": 2,
    "70350032": 1,
    "102354588": 2,
    "131777931": 1,
    "184487709": 2,
    "196176000": 1,
    "196192573": 1,
    "196197006": 2,
    "196210081": 2,
    "199466228": 1,
    "199551982": 1,
    "201666118": 2,
    "202734183": 1,
    "202763690": 2,
    "202770245": 1,
    "202780757": 1,
    "202788651": 2,
    "204735695": 2,
    "211146411": 1,
    "221293335": 1,
    "224705337": 1,
    "467086": 2,
    "3331952": 3,
    "20282961": 1,
    "224280561": 1,
    "229924402": 1,
    "235743020": 1,
    "237278204": 1,
    "246863587": 1,
    "246904359": 1,
    "44614": 1,
    "1849689": 1,
    "2332513": 1,
    "7287895": 2,
    "9514751": 2,
    "12926055": 1,
    "12938495": 1,
    "19208846": 1,
    "36574384": 1,
    "86611657": 1,
    "2172129": 1,
    "11077516": 1,
    "52111971": 1,
    "58772416": 1,
    "201646309": 2,
    "207880647": 1,
    "220045416": 1,
    "233289583": 1,
    "235352574": 1,
    "237684656": 1,
    "1981391": 1,
    "29473470": 2,
    "47012216": 1,
    "53629366": 1,
    "69392767": 1,
    "202774468": 2,
    "220404390": 1,
    "224770745": 1,
    "234789923": 1,
    "236980280": 1,
    "247592257": 1,
    "1129667": 1,
    "13742826": 1,
    "18593743": 1,
    "46939411": 1,
    "67350953": 1,
    "196177632": 1,
    "202712680": 2,
    "207971106": 1,
    "232168936": 1,
    "235165921": 1,
    "4349820": 1,
    "7355407": 1,
    "17498620": 1,
    "24938914": 1,
    "48363067": 1,
    "209322955": 1,
    "209376338": 1,
    "221266065": 1,
    "225066732": 1,
    "233739719": 1,
    "243861060": 1,
    "221516475": 1,
    "255942528": 2,
    "258179774": 1,
    "258999486": 1,
    "259287552": 1,
    "259341735": 1,
    "268030731": 1,
    "268553866": 1,
    "270380175": 1,
    "271050462": 1,
    "273507856": 1,
    "14888175": 1,
    "28266287": 1,
    "64048023": 1,
    "109380360": 1,
    "191256143": 1,
    "232352655": 1,
    "237513697": 1,
    "251066705": 1,
    "252519648": 1,
    "258676160": 1,
    "1578178": 1,
    "3147007": 1,
    "5932528": 1,
    "10565222": 2,
    "14247119": 2,
    "20956365": 2,
    "165163819": 1,
    "210868223": 1,
    "273563": 1,
    "1623913": 1,
    "5045941": 1,
    "5077306": 1,
    "9522695": 1,
    "220486718": 1,
    "220730038": 1,
    "221012566": 1,
    "224280529": 1,
    "228954221": 1,
    "236150308": 1,
    "237941022": 1,
    "265150332": 1,
    "269565799": 1,
    "269761580": 1,
    "4421747": 1,
    "10241043": 1,
    "173990818": 1,
    "253018554": 1,
    "258564230": 1,
    "259129398": 1,
    "260379087": 1,
    "262464745": 1,
    "263829791": 1,
    "267750948": 1,
    "269188036": 1,
    "270226640": 1,
    "271270693": 1,
    "271516195": 1,
    "1856462": 1,
    "8781744": 1,
    "15800462": 1,
    "52956095": 1,
    "62654138": 1,
    "96426372": 1,
    "204981295": 1,
    "223798991": 1,
    "229373521": 1,
    "235490460": 1,
    "238700218": 1,
    "5013313": 1,
    "13936837": 1,
    "32893704": 1,
    "52153976": 1,
    "64318990": 1,
    "201070608": 1,
    "235306313": 1,
    "1957433": 1,
    "7299043": 1,
    "13959787": 2,
    "16997286": 1,
    "19919625": 1,
    "196181724": 1,
    "196471084": 1,
    "202540017": 1,
    "211043910": 1,
    "10627900": 1,
    "14713935": 1,
    "51973914": 1,
    "59553505": 1,
    "80628279": 1,
    "153313581": 1,
    "203180740": 1,
    "246862580": 1,
    "53022581": 1,
    "214604370": 1,
    "231648047": 1,
    "247446806": 1,
    "251280109": 1,
    "257205967": 1,
    "266755649": 1,
    "275336716": 1,
    "1277217": 1,
    "14113767": 1,
    "244714856": 2,
    "258556958": 1,
    "33504": 1,
    "3366315": 1,
    "3633127": 1,
    "4865465": 1,
    "5985692": 1,
    "21010143": 1,
    "26100519": 1,
    "52986403": 1,
    "57721163": 1,
    "102352475": 1,
    "211044093": 1,
    "218595851": 1,
    "232075892": 1,
    "94285": 1,
    "1820614": 1,
    "3389583": 1,
    "3526062": 1,
    "4942873": 1,
    "5523008": 1,
    "5590763": 2,
    "14857825": 1,
    "19096382": 1,
    "28896855": 1,
    "44160625": 1,
    "51606047": 1,
    "67855963": 1,
    "81982679": 1,
    "119304814": 1,
    "146808476": 1,
    "147704286": 1,
    "201327983": 1,
    "218915023": 1,
    "222272091": 1,
    "261514205": 1,
    "266003912": 1,
    "271403894": 1,
    "86903": 1,
    "780171": 1,
    "1169492": 2,
    "1918428": 1,
    "2808203": 1,
    "2867243": 1,
    "2950705": 1,
    "2963092": 1,
    "4940548": 1,
    "8244856": 1,
    "8928715": 1,
    "11216909": 1,
    "12365096": 1,
    "13943041": 1,
    "14420812": 1,
    "16946362": 2,
    "17048224": 2,
    "18124397": 1,
    "238873": 1,
    "311011": 1,
    "2488088": 1,
    "5048947": 1,
    "7672408": 1,
    "8822680": 1,
    "9027681": 1,
    "13530374": 1,
    "23892230": 1,
    "30088448": 1,
    "52012400": 1,
    "61825275": 1,
    "174797747": 1,
    "198917339": 1,
    "201093978": 1,
    "209053721": 1,
    "209532167": 1,
    "210839751": 1,
    "210927488": 1,
    "211171605": 1,
    "216056509": 1,
    "216641852": 1,
    "218614095": 1,
    "218673683": 1,
    "221761146": 1,
    "231855531": 1,
    "232185260": 1,
    "232478685": 1,
    "233004676": 1,
    "233987023": 1,
    "235195882": 1,
    "235782694": 1,
    "237091377": 1,
    "237100969": 1,
    "237940127": 1,
    "244119798": 1,
    "252089836": 1,
    "253553511": 1,
    "256416408": 1,
    "256615816": 1,
    "257669023": 1,
    "258532956": 1,
    "261100919": 1,
    "263609483": 1,
    "265045103": 1,
    "265055617": 1,
    "266162524": 1,
    "266348364": 1,
    "267759856": 1,
    "268032490": 1,
    "13490401": 1,
    "201667597": 1,
    "212650062": 1,
    "219531522": 1,
    "238634774": 1,
    "244130481": 1,
    "249538510": 1,
    "251307839": 1,
    "253237382": 1,
    "253553270": 1,
    "257378493": 1,
    "258676394": 1,
    "259108357": 1,
    "261822707": 1,
    "262480519": 1,
    "266818441": 1,
    "270257988": 1,
    "272366525": 1,
    "3897405": 1,
    "6767966": 1,
    "8278351": 1,
    "9791192": 1,
    "10585115": 1,
    "13689658": 1,
    "206592766": 1,
    "214728393": 1,
    "244908314": 1,
    "246411402": 2,
    "249240415": 1,
    "252596087": 1,
    "252596091": 2,
    "253254916": 1,
    "256390509": 1,
    "257557302": 1,
    "257687552": 1,
    "257901164": 1,
    "258078921": 1,
    "258447166": 1,
    "258887939": 1,
    "258888112": 1,
    "258959444": 1,
    "258960192": 1,
    "258999614": 1,
    "259187900": 1,
    "259262648": 1,
    "259316083": 1,
    "260886966": 1,
    "261705666": 1,
    "263620748": 1,
    "263909602": 1,
    "264172934": 1,
    "264403242": 1,
    "264590753": 1,
    "265050824": 1,
    "265281113": 1,
    "265295502": 1,
    "265445614": 1,
    "265466231": 1,
    "265498336": 1,
    "265498829": 1,
    "265608730": 1,
    "265608824": 1,
    "265659109": 1,
    "266053833": 1,
    "266163420": 1,
    "266374640": 1,
    "266436022": 1,
    "266550896": 1,
    "266551699": 1,
    "267035298": 1,
    "267202776": 1,
    "267782887": 1,
    "267960812": 1,
    "268064742": 1,
    "268527573": 1,
    "268531420": 1,
    "268537084": 1,
    "269005949": 1,
    "269293816": 1,
    "274166550": 1,
    "274235061": 1,
    "274251363": 1,
    "274763217": 1,
    "275994148": 1,
    "1770102": 1,
    "2776693": 1,
    "4833213": 1,
    "5959482": 1,
    "7139779": 1,
    "13480063": 1,
    "16538528": 1,
    "52975881": 1,
    "54457428": 1,
    "55461757": 1,
    "86471548": 1,
    "225039882": 1,
    "232352874": 1,
    "233444273": 1,
    "257427549": 1,
    "4787508": 1,
    "12559116": 1,
    "121987403": 1,
    "174802898": 1,
    "208910339": 1,
    "246426909": 1,
    "246634179": 1,
    "248118878": 1,
    "260333927": 1,
    "261031087": 1,
    "261076203": 1,
    "261531157": 1,
    "263831633": 1,
    "263834741": 1,
    "264306285": 1,
    "264491118": 1,
    "265608726": 1,
    "267411977": 1,
    "267682397": 1,
    "268537409": 1,
    "269214194": 1,
    "270095324": 1,
    "270357470": 1,
    "270559827": 1,
    "270562658": 1,
    "270764846": 1,
    "271213154": 1,
    "275118993": 1,
    "511247": 1,
    "947719": 1,
    "2364329": 1,
    "4581300": 1,
    "9257319": 1,
    "10838471": 1,
    "12016582": 1,
    "22553740": 1,
    "24512760": 1,
    "32041197": 1,
    "37693837": 1,
    "46571650": 1,
    "51966859": 1,
    "145023057": 1,
    "207034961": 1,
    "207821484": 1,
    "261601645": 1,
    "1012652": 1,
    "1998416": 1,
    "8174613": 1,
    "8314118": 1,
    "1177942": 1,
    "7992772": 1,
    "9938081": 1,
    "13083632": 1,
    "14636783": 1,
    "15879823": 1,
    "41140640": 1,
    "146755699": 1,
    "102483628": 1,
    "116376892": 1,
    "195069387": 2,
    "198229624": 1,
    "202558505": 2,
    "168169824": 1,
    "195791872": 1,
    "198968327": 1,
    "202573071": 1,
    "2307261": 1,
    "3051291": 1,
    "3753452": 1,
    "5201925": 1,
    "8517067": 1,
    "12469208": 1,
    "14850173": 1,
    "16313264": 1,
    "18939716": 1,
    "44268933": 1,
    "221275765": 1,
    "9996719": 1,
    "15883006": 1,
    "202542455": 1,
    "235619773": 1,
    "246605112": 1,
    "247778704": 1,
    "248476190": 1,
    "253581838": 1,
    "254535649": 1,
    "258865473": 1,
    "304614": 1,
    "17471203": 1,
    "18712907": 1,
    "186206810": 1,
    "212747830": 1,
    "215737187": 1,
    "218869575": 1,
    "221186870": 1,
    "224270828": 1,
    "229386054": 1,
    "235293983": 1,
    "235792544": 1,
    "739696": 1,
    "2568227": 1,
    "12890187": 1,
    "16482857": 1,
    "1033682": 1,
    "5632716": 1,
    "13637778": 1,
    "211989178": 1,
    "232147187": 1,
    "233305207": 1,
    "236976082": 1,
    "247939336": 1,
    "253708074": 1,
    "257757040": 1,
    "257757213": 1,
    "257834153": 1,
    "257912580": 1,
    "258833547": 1,
    "260866168": 1,
    "260926600": 1,
    "261064940": 1,
    "265714588": 1
  },
  "merged_dataset_groups": [
    {
      "display_name": "PersonaChat",
      "normalized_name": "personachat",
      "name_variants": [
        "PERSONA-CHAT",
        "PersonaChat"
      ],
      "mention_count": 9,
      "cited_papers_count": 7,
      "topic_summary": "The PersonaChat dataset is primarily used to train and evaluate dialogue systems that generate personalized and engaging conversations. It contains 10,981 dialogues with 164,356 utterances, enabling researchers to focus on incorporating personal information and persona attributes into conversational responses. Studies employ this dataset to enhance the naturalness, empathy, and coherence of dialogue systems, particularly in chit-chat settings. Methodologies include training and evaluating models to optimize repetition, specificity, and question-asking, as well as experimenting with persona-based dialogue generation using architectures like Transformer and GPT2."
    },
    {
      "display_name": "OpenSubtitles",
      "normalized_name": "opensubtitles",
      "name_variants": [
        "Open-Subtitles",
        "OpenSubtitles"
      ],
      "mention_count": 6,
      "cited_papers_count": 5,
      "topic_summary": "The OpenSubtitles dataset is primarily used to train and evaluate sequence-to-sequence models for generating conversational responses, with a focus on context sensitivity and recent dialogue history. It is employed to enhance models' ability to produce contextually relevant and natural dialogues, often using neural approaches. The dataset's large scale and diverse content, including movie scripts and online conversations, make it suitable for improving conversational skills and fluency. It is also used for comparative analysis with persona-based datasets, highlighting differences in scale and utterance volume."
    },
    {
      "display_name": "ESCONV",
      "normalized_name": "esconv",
      "name_variants": [
        "ESCONV"
      ],
      "mention_count": 6,
      "cited_papers_count": 6,
      "topic_summary": "The ESCONV dataset is primarily used to evaluate and train state-of-the-art empathetic dialogue generation models. It focuses on generating empathetic and contextually appropriate responses in emotional support conversations. Researchers use it to assess the performance of empathetic response generators and to integrate conversational strategies, such as those enhanced by COMET, to improve emotional support in dialogues."
    },
    {
      "display_name": "Yelp",
      "normalized_name": "yelp",
      "name_variants": [
        "Yelp",
        "Yelp data set"
      ],
      "mention_count": 5,
      "cited_papers_count": 5,
      "topic_summary": "The Yelp dataset is primarily used for sentiment prediction tasks, focusing on user reviews and ratings to explore personalized product and movie rating predictions. It is employed to analyze user-specific sentiment patterns, enhancing recommendation systems. The dataset supports research in personalized sentiment prediction, evaluating models like FactorCell for classification accuracy and comparing them with generative models. It also aids in assessing the effectiveness of discriminative text classification in neural language generation."
    },
    {
      "display_name": "b5-ref corpus",
      "normalized_name": "b5ref",
      "name_variants": [
        "b5-ref",
        "b5-ref corpus"
      ],
      "mention_count": 4,
      "cited_papers_count": 4,
      "topic_summary": "The b5-ref corpus is used to implement language production tasks where subjects generate referring expressions to distinguish target objects from distractors. It trains and evaluates machine learning models for generating non-discriminatory referring expressions and builds personality-dependent lexical choice models, demonstrating improvements when personality information is included. This dataset focuses on the lexicalization of frequent properties and supports research in personalized text generation."
    },
    {
      "display_name": "Reddit TL;DR summarization dataset",
      "normalized_name": "reddittldrsummarization",
      "name_variants": [
        "Reddit TL;DR summarization dataset"
      ],
      "mention_count": 3,
      "cited_papers_count": 3,
      "topic_summary": "The Reddit TL;DR summarization dataset is used to train and evaluate models for generating summaries of Reddit posts, with a focus on incorporating crowdsourced pairwise preferences over summaries. This approach leverages the dataset to improve personalized text generation by training models like GPT-J 6B to align with user preferences, enhancing the quality and relevance of generated summaries."
    },
    {
      "display_name": "PororoSV",
      "normalized_name": "pororosv",
      "name_variants": [
        "PororoSV"
      ],
      "mention_count": 3,
      "cited_papers_count": 3,
      "topic_summary": "The PororoSV dataset is primarily used to evaluate personalized text generation models, with a focus on visual storytelling and narrative coherence. It serves as a testbed for assessing story continuation tasks, integrating visuospatial and linguistic structures, and enhancing the evaluation of narrative generation systems through visual quality, relevance, and consistency. Derived from the Flintstones text-to-video synthesis dataset, it emphasizes the integration of commonsense structure into story visualization."
    },
    {
      "display_name": "Flickr30k",
      "normalized_name": "flickr30k",
      "name_variants": [
        "Flickr30k"
      ],
      "mention_count": 3,
      "cited_papers_count": 3,
      "topic_summary": "The Flickr30k dataset is primarily used to evaluate personalized text generation models, specifically focusing on generating captions that align with visual content. Researchers employ this dataset to assess the effectiveness of their models in producing contextually relevant and personalized textual descriptions of images. The dataset's rich collection of image-caption pairs enables rigorous evaluation of these models' performance in aligning textual output with visual input."
    },
    {
      "display_name": "PENS",
      "normalized_name": "pens",
      "name_variants": [
        "PENS"
      ],
      "mention_count": 3,
      "cited_papers_count": 2,
      "topic_summary": "The PENS dataset is used to construct and enhance personalized headline generation systems, specifically focusing on user interaction data from Microsoft News. It aims to improve user engagement by tailoring headlines to individual preferences and interests, employing realistic user interaction data to refine personalization techniques. This dataset enables researchers to develop and test algorithms that adapt news content to user-specific needs, enhancing the relevance and appeal of news headlines."
    },
    {
      "display_name": "ArtEmis",
      "normalized_name": "artemis",
      "name_variants": [
        "ArtEmis"
      ],
      "mention_count": 3,
      "cited_papers_count": 3,
      "topic_summary": "The ArtEmis dataset is used to train neural models for generating personalized text based on images. It employs two main architectures: Show-Attend-Tell and meshed-memory transformers. Research focuses on fine-tuning a pretrained ResNet-32 encoder by minimizing KL-divergence between the encoder's output and empirical user distributions. This enables the development of neural speakers that can generate personalized text using attention mechanisms and image inputs."
    },
    {
      "display_name": "Wizard of Wikipedia",
      "normalized_name": "wizardofwikipedia",
      "name_variants": [
        "Wizard of Wikipedia"
      ],
      "mention_count": 3,
      "cited_papers_count": 3,
      "topic_summary": "The Wizard of Wikipedia dataset is used to evaluate conversational response generation, specifically focusing on generating contextually relevant and content-rich responses in multi-turn dialogues. Researchers employ this dataset to assess the ability of models to produce content-specific and contextually appropriate responses, enhancing the quality and coherence of conversational interactions."
    },
    {
      "display_name": "IMDB dataset",
      "normalized_name": "imdb",
      "name_variants": [
        "IMDB",
        "IMDB dataset"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The IMDB dataset is primarily used for sentiment analysis and personalized text generation. It supports comparison and ablation studies, evaluating methods like UserAdapter for few-shot user learning and user-specific sentiment adaptation. The dataset is also utilized to generate rollouts, collect pairwise feedback, and train models using PPO, as well as to fine-tune GPT-2 on movie reviews for sentiment analysis and text generation tasks."
    },
    {
      "display_name": "Dialog NLI dataset",
      "normalized_name": "dialognli",
      "name_variants": [
        "Dialog NLI",
        "Dialog NLI dataset"
      ],
      "mention_count": 2,
      "cited_papers_count": 1,
      "topic_summary": "The Dialog NLI dataset is primarily used to train and evaluate Natural Language Inference (NLI) models, focusing on the consistency between persona descriptions and dialogue utterances. It enhances personalized text generation by providing NLI annotations that help assess the alignment between generated sentences and user comments. This dataset supports research in evaluating persona consistency in dialogue systems through sequence classification and NLI tasks."
    },
    {
      "display_name": "Koala evaluation",
      "normalized_name": "koalaevaluation",
      "name_variants": [
        "Koala evaluation"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The 'Koala evaluation' dataset is used in personalized text generation research to generate rollouts, collect pairwise feedback data, and train models using PPO. It tests the model's ability to produce responses aligned with user preferences and filters out 50 instances for evaluating the quality and appropriateness of generated texts. This dataset enables researchers to assess and improve the personalization and relevance of text generation models."
    },
    {
      "display_name": "combined preference dataset",
      "normalized_name": "combinedpreference",
      "name_variants": [
        "combined preference dataset"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The combined preference dataset is used to train and evaluate reinforcement learning with human feedback (RLHF) models. It focuses on aligning model outputs with human preferences through a single utility reward function. This dataset enables researchers to assess and improve the alignment of AI-generated text with human values and preferences, enhancing the usability and acceptability of generated content."
    },
    {
      "display_name": "Yelp-2016",
      "normalized_name": "yelp2016",
      "name_variants": [
        "Yelp-2016"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The Yelp-2016 dataset is used to evaluate recommendation algorithms by comparing performance metrics such as MAE and RMSE across various methods including LRMF, PMF, NMF, SVD++, URP, CTR, RMR, and NRT. Despite the context of personalized text generation, the dataset primarily supports research in algorithmic performance and comparison, enabling researchers to assess the effectiveness of different recommendation techniques."
    },
    {
      "display_name": "ConvAI2",
      "normalized_name": "convai2",
      "name_variants": [
        "ConvAI2"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The ConvAI2 dataset is used to fine-tune pre-trained RoBERTa models for dialogue natural language inference, emphasizing consistency and coherence in dialogues. It is also utilized to generate personalized dialogues by incorporating rich personal information, enhancing conversational intelligence with character-specific facts. This dataset enables researchers to improve dialogue systems through targeted fine-tuning and personalized content generation."
    },
    {
      "display_name": "R EDDIT",
      "normalized_name": "reddit",
      "name_variants": [
        "R EDDIT",
        "Reddit"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The R EDDIT dataset is primarily used to train and evaluate dialog systems, focusing on the quality and end-to-end learning of generated responses from a large-scale comment corpus. It provides a rich source of conversational data for developing and testing dialog models. Additionally, the dataset is utilized for preprocessing tasks such as tokenization and lowercasing text using the NLTK tokenizer, enhancing natural language processing workflows."
    },
    {
      "display_name": "SogouCS&CA corpus (2008 version)",
      "normalized_name": "sogoucsca",
      "name_variants": [
        "SogouCS&CA corpus",
        "SogouCS&CA corpus (2008 version)"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The SogouCS&CA corpus (2008 version) is primarily used to train word embeddings and word2vec models for Chinese text analysis. Researchers focus on constructing word vectors to enhance natural language processing tasks, leveraging the dataset's extensive Chinese text content. This enables the development of more accurate and contextually rich word representations, crucial for various NLP applications."
    },
    {
      "display_name": "Ubuntu Dialogue Corpus",
      "normalized_name": "ubuntudialoguecorpus",
      "name_variants": [
        "Ubuntu Dialogue Corpus"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The Ubuntu Dialogue Corpus is used to develop and evaluate unstructured multi-turn dialogue systems. It provides a large dataset for training and testing conversational models, enabling researchers to assess the performance of these systems in handling natural, multi-turn conversations. The dataset's size and multi-turn nature are crucial for building robust conversational agents."
    },
    {
      "display_name": "HONEST",
      "normalized_name": "honest",
      "name_variants": [
        "HONEST"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The HONEST dataset is used to evaluate the generation of harmful content in language models by measuring hurtful sentence completion. It focuses on assessing how language models complete sentences that could be considered offensive or harmful. This dataset enables researchers to identify and mitigate biases and harmful outputs in AI systems, ensuring they are safer and more responsible."
    },
    {
      "display_name": "PERPLEXITY API",
      "normalized_name": "perplexityapi",
      "name_variants": [
        "PERPLEXITY API"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The PERPLEXITY API dataset is used to evaluate the quality and safety of generated text by assessing n-gram diversity and GPT-2 XL perplexity as proxies for fluency and diversity. It also calculates toxicity scores on full generation sequences to measure the model's output quality and potential harmfulness. This dataset enables researchers to systematically analyze and improve the safety and effectiveness of text generation models."
    },
    {
      "display_name": "NL human feedback",
      "normalized_name": "nlhumanfeedback",
      "name_variants": [
        "NL human feedback"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The 'NL human feedback' dataset is used to collect and store natural language feedback from humans, which is then retrieved by models to condition their performance on various tasks. This enhances model adaptability and improves user interaction. The dataset enables researchers to study how real-time human feedback can be integrated into machine learning models to refine their outputs and better align with user expectations."
    },
    {
      "display_name": "UESTC dataset",
      "normalized_name": "uestc",
      "name_variants": [
        "UESTC dataset"
      ],
      "mention_count": 2,
      "cited_papers_count": 2,
      "topic_summary": "The UESTC dataset is primarily used for evaluating pre-trained action recognition models and benchmarking action-conditioned motion generation tasks. It contains 25K motion sequences across 40 action categories, enabling researchers to assess model performance in generating personalized text based on human actions. The dataset's extensive action categories and SMPL sequences facilitate robust evaluation and development of models in these areas."
    },
    {
      "display_name": "Yelp (restaurant)",
      "normalized_name": "yelprestaurant",
      "name_variants": [
        "Yelp (restaurant)"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Yelp (restaurant) dataset is primarily used to evaluate explainable recommendation systems, focusing on user reviews and ratings for restaurants. Researchers employ this dataset to analyze and enhance the explainability of recommendations, leveraging the rich textual and numerical data to understand user preferences and improve system transparency. This dataset enables detailed evaluations of recommendation algorithms by providing real-world user interactions and feedback."
    },
    {
      "display_name": "CrowSPairs",
      "normalized_name": "crowspairs",
      "name_variants": [
        "CrowSPairs"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The CrowSPairs dataset is used to evaluate and measure gender bias in language models, particularly in pronoun resolution within gendered contexts. It is also applied to assess social biases in masked language models, focusing on stereotypical associations and fairness. This dataset enables researchers to systematically analyze and quantify biases, contributing to the development of more equitable language models."
    },
    {
      "display_name": "FLAN",
      "normalized_name": "flan",
      "name_variants": [
        "FLAN"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The FLAN dataset is used to fine-tune GPT-3 models on a variety of NLP tasks, employing natural language instructions and multitask prompted training. It focuses on enhancing zero-shot task generalization, enabling models to perform well on unseen tasks without additional training data. This approach addresses research questions related to improving model adaptability and efficiency in diverse NLP applications."
    },
    {
      "display_name": "Personalized-Soups",
      "normalized_name": "personalizedsoups",
      "name_variants": [
        "Personalized-Soups"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 'Personalized-Soups' dataset is used to evaluate and improve personalized text generation by analyzing pairwise feedback on responses to GPT-4 Alpaca instructions. It focuses on instruction following under different user preference profiles, conducting pairwise comparisons to assess model performance and enhance personalized text outputs. This dataset enables researchers to refine models based on user-specific preferences, enhancing the quality and relevance of generated text."
    },
    {
      "display_name": "empathetic conversations",
      "normalized_name": "empatheticconversations",
      "name_variants": [
        "empathetic conversations"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 'empathetic conversations' dataset is used to train and evaluate Transformer-based generative and BERT-based retrieval models, specifically focusing on enhancing empathetic responses in dialogue systems. This dataset enables researchers to improve the quality of empathetic interactions by providing a rich set of conversational data annotated for empathy, facilitating the development of more human-like conversational agents."
    },
    {
      "display_name": "PersonalDialog",
      "normalized_name": "personaldialog",
      "name_variants": [
        "PersonalDialog"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The PersonalDialog dataset is used to train and evaluate personalized dialogue systems, focusing on enhancing conversational diversity and personalization. It is employed to generate dialogues with diversified traits, ensuring contextually appropriate and personalized responses, particularly in a Chinese social media setting. This dataset supports research aimed at improving chatbot interactions by incorporating varied conversational elements."
    },
    {
      "display_name": "Pushshift Reddit Dataset",
      "normalized_name": "pushshiftredditdataset",
      "name_variants": [
        "Pushshift Reddit Dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Pushshift Reddit Dataset is used to provide raw data for preprocessing user attributes, focusing on the reproducibility of models and scripts. It enables researchers to ensure that their methodologies and analyses can be replicated, enhancing transparency and reliability in social media research."
    },
    {
      "display_name": "dataset for evaluating the alignment of language models with 60 US demographic groups",
      "normalized_name": "forevaluatingthealignmentoflanguagemodelswith60usdemographicgroups",
      "name_variants": [
        "dataset for evaluating the alignment of language models with 60 US demographic groups"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The dataset is used to assess the alignment of language models with 60 US demographic groups across various topics, focusing on identifying significant misalignment issues. Researchers employ this dataset to evaluate how well language models represent different demographic groups, highlighting areas where the models may be biased or underperform. This enables a more nuanced understanding of model fairness and inclusivity."
    },
    {
      "display_name": "Chinese Weibo",
      "normalized_name": "chineseweibo",
      "name_variants": [
        "Chinese Weibo"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Chinese Weibo dataset is used to conduct experiments on personalized text generation, specifically focusing on social media posts. Researchers analyze user-specific language patterns and interactions to understand and model individual communication styles. This dataset enables the development and evaluation of algorithms that can generate text reflecting the unique linguistic characteristics of Weibo users."
    },
    {
      "display_name": "MeMo FC corpus",
      "normalized_name": "memofc",
      "name_variants": [
        "MeMo FC corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The MeMo FC corpus is used in research to personalize text generation by incorporating emotional language and deriving sentence templates. It focuses on the impact of emotional content and the structural aspects of soccer reportage in multiple languages, enabling studies to explore how emotional and linguistic elements influence text personalization."
    },
    {
      "display_name": "360PanoI",
      "normalized_name": "360panoi",
      "name_variants": [
        "360PanoI"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 360PanoI dataset is used for fine-tuning models with paired image-text data, specifically to enhance the performance of generating personalized text based on visual inputs. This involves improving the model's ability to produce contextually relevant and personalized textual content when given visual stimuli. The dataset's paired nature is crucial for aligning visual and textual information, enabling more accurate and contextually appropriate text generation."
    },
    {
      "display_name": "Douban Corpus",
      "normalized_name": "doubancorpus",
      "name_variants": [
        "Douban Corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Douban Corpus is used to train and evaluate multi-turn response selection in retrieval-based chatbots, specifically focusing on conversational context and relevance within a Chinese social networking environment. This dataset enables researchers to assess the performance of chatbot systems in generating contextually appropriate responses, enhancing the naturalness and coherence of conversations."
    },
    {
      "display_name": "E-commerce Corpus",
      "normalized_name": "ecommercecorpus",
      "name_variants": [
        "E-commerce Corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The E-commerce Corpus is used to model and analyze multi-turn conversations in e-commerce settings, particularly focusing on customer-shopkeeper interactions on platforms like Taobao. Researchers employ deep utterance aggregation techniques to enhance dialogue systems, addressing topics such as commodity consultation, logistics, recommendations, and casual conversation. This dataset enables the demonstration of topic shifts and the improvement of conversational models through detailed interaction analysis."
    },
    {
      "display_name": "Wikipedia",
      "normalized_name": "wikipedia",
      "name_variants": [
        "Wikipedia"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Wikipedia dataset is used to enhance personalized product description generation by incorporating external product knowledge. This approach leverages the comprehensive and structured information available in Wikipedia to enrich the content, focusing on user-cared aspects. The dataset's extensive and diverse content enables researchers to improve the effectiveness and relevance of generated product descriptions."
    },
    {
      "display_name": "CelebA-HQ",
      "normalized_name": "celebahq",
      "name_variants": [
        "CelebA-HQ"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The CelebA-HQ dataset is primarily used for face recognition tasks, particularly focusing on recognizing faces across different poses and ages. It leverages high-quality images and diverse attributes to enhance the accuracy and robustness of facial recognition models. Despite the context mentioning personalized text generation, the dataset's primary application is in improving face recognition methodologies."
    },
    {
      "display_name": "Harvard sentence corpus",
      "normalized_name": "harvardsentence",
      "name_variants": [
        "Harvard sentence corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Harvard sentence corpus is used to generate novel sentences for creating transfer stimuli. Researchers apply median attention weights from the GSP iteration to these sentences to study personalized text generation. This dataset enables the exploration of how attention mechanisms can be utilized to create more contextually relevant and personalized text outputs."
    },
    {
      "display_name": "YelpR8",
      "normalized_name": "yelpr8",
      "name_variants": [
        "YelpR8"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The YelpR8 dataset is used for training and testing personalized text generation models, with a focus on evaluating scalability and performance across development and test sets. This dataset enables researchers to assess how well these models can generate personalized content, providing insights into their effectiveness and efficiency in handling large-scale data."
    },
    {
      "display_name": "dataset presented in (Xu et al., 2017)",
      "normalized_name": "presentedinxuetal2017",
      "name_variants": [
        "dataset presented in (Xu et al., 2017)"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The dataset presented in (Xu et al., 2017) is used to experiment with various customer service properties, particularly focusing on chatbot interactions on social media platforms. Researchers employ this dataset to analyze and improve chatbot performance, enhancing user engagement and satisfaction in customer service scenarios. The dataset's relevance lies in its real-world chat interactions, providing a practical basis for evaluating and refining chatbot methodologies."
    },
    {
      "display_name": "Response to Livebot dataset",
      "normalized_name": "responsetolivebot",
      "name_variants": [
        "Response to Livebot dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 'Response to Livebot dataset' is used to generate live video comments by integrating visual and textual contexts. This dataset focuses on the interaction between video content and user-generated comments, enabling researchers to develop and test models that can dynamically produce relevant and contextually appropriate comments during live video streams."
    },
    {
      "display_name": "W ORK S M",
      "normalized_name": "worksm",
      "name_variants": [
        "W ORK S M"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The W ORK S M dataset is used to compute auxiliary probabilities in equation (1) for AITA, specifically to personalize large language models through retrieval augmentation. It contains private user data, which is leveraged to enhance the personalization capabilities of these models. This dataset enables researchers to improve the contextual relevance and personalization of generated text by integrating user-specific information."
    },
    {
      "display_name": "BabyTalk",
      "normalized_name": "babytalk",
      "name_variants": [
        "BabyTalk"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The BabyTalk dataset is used to generate personalized text in Neonatal Intensive Care Units (NICUs), focusing on decision support and information management through Natural Language Generation (NLG) technology. It enables researchers to develop systems that provide tailored information and support for healthcare providers, enhancing communication and decision-making processes in NICUs."
    },
    {
      "display_name": "Citation Network Dataset (V14)",
      "normalized_name": "citationnetworkdatasetv14",
      "name_variants": [
        "Citation Network Dataset (V14)"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Citation Network Dataset (V14) is used to generate data samples for personalized text generation, specifically focusing on the structure and content of academic citations and networks. It leverages a large corpus of 5,259,858 papers, each with 29 features, to create comprehensive and detailed datasets. This enables researchers to develop and test algorithms that can generate personalized text based on academic citation patterns and network structures."
    },
    {
      "display_name": "Amazon Reviews Dataset",
      "normalized_name": "amazonreviewsdataset",
      "name_variants": [
        "Amazon Reviews Dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Amazon Reviews Dataset is used to generate data samples for personalized text generation, leveraging 150 million user reviews to train models on user preferences and review content. This dataset enhances recommendation justifications by focusing on the textual and preference data within the reviews, enabling researchers to develop more contextually relevant and personalized text outputs."
    },
    {
      "display_name": "WMT15-WMT17",
      "normalized_name": "wmt15wmt17",
      "name_variants": [
        "WMT15-WMT17"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The WMT15-WMT17 dataset is used to collect multilingual data for evaluating machine translation systems, particularly focusing on English as the target language. It is employed to study translation quality and personalization, enabling researchers to assess how well systems handle various linguistic challenges and maintain personalized elements in translations."
    },
    {
      "display_name": "QuAC",
      "normalized_name": "quac",
      "name_variants": [
        "QuAC"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The QuAC dataset is used to investigate themes through dialogic question and answer sequences, focusing on the conversational context. It enables researchers to analyze how conversational dynamics influence responses, particularly in personalized text generation. The dataset's emphasis on natural, multi-turn dialogues provides rich context for understanding and improving conversational models."
    },
    {
      "display_name": "FigureSeer",
      "normalized_name": "figureseer",
      "name_variants": [
        "FigureSeer"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The FigureSeer dataset is used to generate accurate and relevant captions for scientific figures, focusing on enhancing the clarity and informativeness of the generated text. This dataset supports research in automated caption generation, specifically tailored to scientific imagery, ensuring that the captions effectively convey the content and context of the figures."
    },
    {
      "display_name": "Movie-DiC",
      "normalized_name": "moviedic",
      "name_variants": [
        "Movie-DiC"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Movie-DiC dataset is used to develop and evaluate dialogue generation systems, particularly for movie dialogues. It provides a rich source of conversational data, supporting research in personalized text generation. The dataset enables researchers to create more contextually appropriate and engaging dialogues by leveraging its extensive collection of movie conversations."
    },
    {
      "display_name": "lexicon from (Wilson et al., 2005)",
      "normalized_name": "lexiconfromwilsonetal2005",
      "name_variants": [
        "lexicon from (Wilson et al., 2005)"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The lexicon from (Wilson et al., 2005) is used for recognizing contextual polarity in phrase-level sentiment analysis. It provides 2700 words with sentiment labels, enhancing the accuracy of sentiment detection in text. This dataset is employed to improve personalized text generation by refining the model's ability to understand and generate contextually appropriate sentiments."
    },
    {
      "display_name": "personal knowledge base",
      "normalized_name": "personalknowledgebase",
      "name_variants": [
        "personal knowledge base"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 'personal knowledge base' dataset is used to enhance personalization in open-domain conversation systems by ranking responses. It employs long-term memory storage and retrieval to improve the relevance and coherence of conversational interactions. This dataset enables researchers to develop more contextually aware and personalized dialogue systems, focusing on the effective use of stored user-specific information to generate more natural and engaging conversations."
    },
    {
      "display_name": "PchatbotW",
      "normalized_name": "pchatbotw",
      "name_variants": [
        "PchatbotW"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The PchatbotW dataset is used to establish dialogue assessment indicators at the discourse level, specifically focusing on the quality of responses in personalized text generation. Researchers employ this dataset to evaluate and enhance the coherence and relevance of chatbot-generated dialogues, ensuring they meet high standards of interaction quality."
    },
    {
      "display_name": "JD Customer Service Corpus",
      "normalized_name": "jdcustomerservicecorpus",
      "name_variants": [
        "JD Customer Service Corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The JD Customer Service Corpus is used to train models for dialogue generation, specifically focusing on customer service interactions. It contains 435,005 dialogues from JD.com, enabling researchers to develop and evaluate models that can generate realistic and contextually appropriate responses in customer service scenarios. This dataset supports research in improving automated customer service systems through enhanced dialogue management and response generation."
    },
    {
      "display_name": "Douban Conversation Corpus",
      "normalized_name": "doubanconversationcorpus",
      "name_variants": [
        "Douban Conversation Corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Douban Conversation Corpus is used to train and evaluate multi-turn response selection models in retrieval-based chatbots, specifically focusing on Chinese conversation pairs. This dataset enables researchers to improve the accuracy and relevance of responses in conversational systems by leveraging real-world dialogue data from Douban."
    },
    {
      "display_name": "Home",
      "normalized_name": "home",
      "name_variants": [
        "Home"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 'Home' dataset is used to explore tip information for generating tips and predicting ratings, emphasizing the unique advantages of tips over conventional reviews. It is also utilized for ablation experiments to evaluate the performance of each component in user preference modeling from a generative perspective. This dataset enables researchers to refine and test models that enhance the accuracy and relevance of generated tips and ratings."
    },
    {
      "display_name": "Reddit Corpus",
      "normalized_name": "redditcorpus",
      "name_variants": [
        "Reddit Corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Reddit Corpus, containing 700 million comments and 1.4 billion tokens, is used to train personalized dialogue agents, particularly for chit-chat conversations. Researchers employ this dataset to study natural language interactions, leveraging its extensive and diverse content to enhance the conversational abilities of AI systems."
    },
    {
      "display_name": "IMDb62",
      "normalized_name": "imdb62",
      "name_variants": [
        "IMDb62"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The IMDb62 dataset is used to study authorship attribution and personalized text generation, focusing on the stylistic and thematic consistency in movie reviews written by prolific users. Researchers employ methodologies that analyze the unique writing styles and themes to identify authors and generate text that mimics these styles. This dataset enables detailed examination of user-specific linguistic patterns and their application in generating personalized content."
    },
    {
      "display_name": "The Pile",
      "normalized_name": "thepile",
      "name_variants": [
        "The Pile"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Pile is used to pretrain models, leveraging its diverse 825GB English dataset comprising texts from 22 sources, including academic, internet, prose, dialogue, and miscellaneous categories. This dataset enables researchers to develop models with broad linguistic capabilities, enhancing their performance across various natural language processing tasks. The diversity and scale of The Pile support robust pretraining, facilitating the creation of more versatile and adaptable language models."
    },
    {
      "display_name": "NRC VAD lexicon",
      "normalized_name": "nrcvadlexicon",
      "name_variants": [
        "NRC VAD lexicon"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The NRC VAD lexicon is used to enhance the representation of emotional states in the MultiESC model by incorporating external knowledge. It provides valence, arousal, and dominance scores to capture subtle user emotions, thereby improving the model's ability to accurately reflect emotional nuances in its outputs. This dataset enables researchers to address the challenge of emotional representation in computational models, focusing on the integration of emotional dimensions to refine user interaction and emotional understanding."
    },
    {
      "display_name": "CelebAMask-HQ",
      "normalized_name": "celebamaskhq",
      "name_variants": [
        "CelebAMask-HQ"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The CelebAMask-HQ dataset is primarily used to enhance personalized text-to-image generation and to train models for generating textual embeddings. It provides high-quality, well-curated facial image data and foreground-masked identity images, which are crucial for training and fine-tuning models. The dataset includes rich meta-annotations and a diverse set of 400 unique human identities, enabling researchers to evaluate and improve the performance of personalized text-to-image systems."
    },
    {
      "display_name": "SubTle",
      "normalized_name": "subtle",
      "name_variants": [
        "SubTle"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The SubTle dataset is used to study non-dialog text extracted from movie subtitles, focusing on linguistic patterns and structures within large-scale subtitle data. Researchers employ this dataset to analyze and understand the complexities and nuances of language as used in subtitles, which aids in exploring specific linguistic features and their applications in natural language processing."
    },
    {
      "display_name": "ELI5",
      "normalized_name": "eli5",
      "name_variants": [
        "ELI5"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The ELI5 dataset is primarily used to train large language models, providing diverse text content such as public domain books, multilingual texts, parliamentary proceedings, context-free question-answer pairs, user reviews, subreddit discussions, web-scraped data, news articles, and complex question-answer pairs. It is specifically employed to enhance the models' ability to generate clear, concise, and explanatory answers, particularly in the \"Explain Like I'm 5\" style, and to improve multi-hop reasoning and language diversity."
    },
    {
      "display_name": "LAION-400M",
      "normalized_name": "laion400m",
      "name_variants": [
        "LAION-400M"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The LAION-400M dataset is used to train multimodal latent diffusion models that integrate text and image inputs. This approach focuses on generating images conditioned on both textual and visual subjects, enabling research in joint subject and text conditional image generation. The dataset's large-scale multimodal content facilitates the development of models capable of producing high-quality, contextually relevant images."
    },
    {
      "display_name": "Gigaword corpus",
      "normalized_name": "gigaword",
      "name_variants": [
        "Gigaword corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Gigaword corpus is used to fine-tune pre-trained models for text summarization tasks. Researchers evaluate model performance across varying scales of training data, including 10K, 100K, 1M, and 3.8M article-title pairs. This dataset enables the assessment of how different data sizes impact summarization accuracy and efficiency."
    },
    {
      "display_name": "2018 Duolingo Shared Task on Second Language Acquisition Modeling",
      "normalized_name": "2018duolingosharedtaskonsecondlanguageacquisitionmodeling",
      "name_variants": [
        "2018 Duolingo Shared Task on Second Language Acquisition Modeling"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 2018 Duolingo Shared Task on Second Language Acquisition Modeling dataset is used to model second language acquisition by analyzing user responses over the first 30 days of learning. It supports the investigation of personalized learning patterns, user engagement, and the personalization of educational content. The dataset enables researchers to understand how users progress and engage with language learning materials, facilitating the development of more effective and tailored educational strategies."
    },
    {
      "display_name": "OpenWebText",
      "normalized_name": "openwebtext",
      "name_variants": [
        "OpenWebText"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The OpenWebText dataset is primarily used to train models for personalized text generation, leveraging its large-scale and diverse web-based text corpus. Researchers focus on various domains such as multilingual United Nations documents, user reviews and ratings, news articles and summaries, and multilingual parliamentary proceedings. This dataset enables the development of models that can generate contextually relevant and personalized text across different languages and content types."
    },
    {
      "display_name": "dataset of comparisons between two model outputs",
      "normalized_name": "ofcomparisonsbetweentwomodeloutputs",
      "name_variants": [
        "dataset of comparisons between two model outputs"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The dataset of comparisons between two model outputs is used to train a reward model that focuses on enhancing text summarization quality by incorporating human-preferred outputs. This involves using direct feedback to improve the model's ability to generate summaries that align with human preferences. The dataset enables researchers to refine model performance through supervised learning, specifically targeting the quality and relevance of generated text summaries."
    },
    {
      "display_name": "annotated dataset of human response scores",
      "normalized_name": "annotated",
      "name_variants": [
        "annotated dataset of human response scores"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The annotated dataset of human response scores is used to train ADEM, an evaluation model designed to score dialogue responses. This dataset, containing human annotations, enables the model to learn and assess the quality of responses accurately. It focuses on improving the evaluation of dialogue systems by leveraging human-scored data, enhancing the reliability of automated assessment methods."
    },
    {
      "display_name": "Amazon 5-core",
      "normalized_name": "amazon5core",
      "name_variants": [
        "Amazon 5-core"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Amazon 5-core dataset is used to build datasets for personalized text generation, specifically focusing on user-generated reviews and metadata from May 1996 to July 2014. It ensures no duplicated records, providing a clean, extensive resource for researchers to develop and evaluate models that generate personalized text based on historical review data."
    },
    {
      "display_name": "Electronics dataset",
      "normalized_name": "electronics",
      "name_variants": [
        "Electronics dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Electronics dataset is used to evaluate the performance of text generation models on electronics-related content, focusing on ROUGE scores to measure the quality of generated sentences. Despite its name, it is also applied to beauty-related content, indicating versatility in assessing text generation models across different domains."
    },
    {
      "display_name": "Opinosis",
      "normalized_name": "opinosis",
      "name_variants": [
        "Opinosis"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Opinosis dataset is primarily used to test fine-tuned StyleLM models and other abstractive summarization techniques, focusing on summarizing highly redundant opinions from user reviews on platforms like Tripadvisor, Edmunds.com, and Amazon.com. It is employed to evaluate model performance on style and content, particularly in generating abstractive summaries that capture everyday writing styles and specific authorial tones, such as Mark Twain's. The dataset's redundancy and diverse domain coverage make it suitable for these tasks."
    },
    {
      "display_name": "COCO",
      "normalized_name": "coco",
      "name_variants": [
        "COCO"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The COCO dataset is primarily used to train and evaluate personalized text generation models. Research focuses on assessing model performance using metrics such as recall at ranks 1, 5, and 10. This dataset enables researchers to benchmark the effectiveness of their models in generating contextually relevant and personalized text."
    },
    {
      "display_name": "ROCStories corpus",
      "normalized_name": "rocstories",
      "name_variants": [
        "ROCStories corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The ROCStories corpus is used in research to evaluate models on narrative coherence and logical flow in short stories. It provides examples of typical stories for tasks such as story completion and predicting continuations. The dataset enables researchers to assess a model's ability to select the correct story ending from multiple candidates, focusing on maintaining narrative structure and coherence."
    },
    {
      "display_name": "social media text summarization dataset",
      "normalized_name": "socialmediatextsummarization",
      "name_variants": [
        "social media text summarization dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The social media text summarization dataset is primarily used to evaluate the performance of methods in personalized text generation, specifically focusing on the effectiveness of the convolutional gated unit in refining source representations. This dataset enables researchers to assess how well their models can generate personalized content by refining the input data's representation."
    },
    {
      "display_name": "WebText",
      "normalized_name": "webtext",
      "name_variants": [
        "WebText"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The WebText dataset is primarily used for pre-training GPT-2, a large-scale language model. It serves as a diverse and extensive corpus that enhances the model's performance in natural language generation tasks across various domains. The dataset's breadth and variety contribute to the model's ability to generate coherent and contextually appropriate text, making it a crucial resource for advancing natural language processing research."
    },
    {
      "display_name": "News Categorization dataset",
      "normalized_name": "newscategorization",
      "name_variants": [
        "News Categorization dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The News Categorization dataset is primarily used to construct datasets for personalized text generation, leveraging news articles categorized by topic from the HuffPost website. Researchers focus on studying category-specific language patterns and content, enabling the analysis and generation of text that reflects specific news categories. This dataset facilitates the exploration of how language and content vary across different news topics, enhancing the development of personalized text generation models."
    },
    {
      "display_name": "SoLSCSum",
      "normalized_name": "solscsum",
      "name_variants": [
        "SoLSCSum"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The SoLSCSum dataset is used to highlight limitations in training neural models, particularly in the context of extractive summarization and personalization. Researchers employ this dataset to evaluate and demonstrate the challenges posed by its small size, which affects model performance and generalization. This dataset enables studies focused on improving summarization techniques and understanding the impact of data scarcity on neural model training."
    },
    {
      "display_name": "CNN/DailyMail",
      "normalized_name": "cnndailymail",
      "name_variants": [
        "CNN/DailyMail"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The CNN/DailyMail dataset is primarily used to evaluate abstractive summarization methods, specifically focusing on their performance in personalized text generation. Researchers compare different models using metrics like ROUGE scores to assess the effectiveness of these methods in generating coherent and contextually relevant summaries. This dataset enables detailed performance comparisons and advancements in summarization techniques."
    },
    {
      "display_name": "Weibo dataset",
      "normalized_name": "weibo",
      "name_variants": [
        "Weibo dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Weibo dataset, a subset of PChatbotW, is primarily used to train and evaluate personalized chatbot systems, emphasizing the diversity and complexity of user interactions on social media. It focuses on the nuances of social media interactions over a one-year period, enabling researchers to develop and test chatbot responses that are more contextually and socially aware."
    },
    {
      "display_name": "DailyDialog test set",
      "normalized_name": "dailydialog",
      "name_variants": [
        "DailyDialog test set"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The DailyDialog test set is used to evaluate chatbot models by selecting context-utterance pairs, focusing on the quality and coherence of open-domain conversations. This dataset enables researchers to assess how well chatbot responses align with contextual cues, ensuring natural and engaging dialogue."
    },
    {
      "display_name": "Enron data",
      "normalized_name": "enron",
      "name_variants": [
        "Enron data"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Enron data dataset is used to fine-tune a politeness classifier, specifically to measure the politeness transfer quality in generated sequences. This involves evaluating the average score given by the classifier, which helps researchers assess how well politeness is preserved or altered in text generation tasks. The dataset's extensive email communications provide a rich source of natural language data for training and testing the classifier."
    },
    {
      "display_name": "MIMDb",
      "normalized_name": "mimdb",
      "name_variants": [
        "MIMDb"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The MIMDb dataset is mentioned in research citations but lacks detailed descriptions of its usage. There is no explicit information on how it is employed in methodologies, specific research questions, or the characteristics that enable its use. Therefore, based on the provided evidence, no specific research application or methodology can be accurately described for MIMDb."
    },
    {
      "display_name": "ReDial",
      "normalized_name": "redial",
      "name_variants": [
        "ReDial"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The ReDial dataset is used in research to experiment with dialog-based recommendation systems, particularly focusing on knowledge-based interactions in a conversational setting. Researchers employ this dataset to develop and evaluate models that can effectively incorporate knowledge into dialogues, enhancing the quality and relevance of recommendations through natural language conversations."
    },
    {
      "display_name": "ConvAI2 personalized dialogue corpus",
      "normalized_name": "convai2personalizeddialogue",
      "name_variants": [
        "ConvAI2 personalized dialogue corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The ConvAI2 personalized dialogue corpus is used to evaluate personalized dialogue systems, specifically focusing on generating contextually appropriate responses that reflect user preferences and personalities. Researchers employ this dataset to assess the effectiveness of dialogue models in capturing and integrating personal traits into conversations, enhancing the naturalness and relevance of system responses."
    },
    {
      "display_name": "Reddit submissions",
      "normalized_name": "redditsubmissions",
      "name_variants": [
        "Reddit submissions"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Reddit submissions dataset is used to fine-tune a pretrained DistilBERT model on a variant of triplet loss, specifically for personalized text generation. This involves leveraging user-generated content from over 1.7 million users to enhance the model's ability to generate text that reflects individual user styles and preferences."
    },
    {
      "display_name": "ValueNet",
      "normalized_name": "valuenet",
      "name_variants": [
        "ValueNet"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The ValueNet dataset is used to create numeric speaker profiles based on implied values in statements, focusing on the relationship between language and human values in dialogue systems. This involves analyzing how specific values are expressed through language, enabling researchers to develop more nuanced and value-aligned dialogue models. The dataset's key feature is its ability to capture and quantify these values, enhancing the personalization and ethical alignment of conversational agents."
    },
    {
      "display_name": "FlickrStyle10K",
      "normalized_name": "flickrstyle10k",
      "name_variants": [
        "FlickrStyle10K"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The FlickrStyle10K dataset is used to train single-style captioners, integrating both factual and stylized captions to generate personalized text descriptions of images. This approach leverages the dataset's diverse caption styles to enhance the specificity and personalization of image descriptions, addressing research questions related to improving the stylistic and contextual accuracy of generated text."
    },
    {
      "display_name": "PERSONALITY-CAPTIONS",
      "normalized_name": "personalitycaptions",
      "name_variants": [
        "PERSONALITY-CAPTIONS"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The PERSONALITY-CAPTIONS dataset is used to train and evaluate models for generating engaging and conversational image captions with distinct personality traits. It focuses on improving the quality, relevance, and human-like nature of captions through methods that incorporate personality, such as humorous or romantic styles. The dataset, containing 215 personalities, enhances the diversity and interactivity of image captioning systems, enabling researchers to create more personalized and engaging user experiences."
    },
    {
      "display_name": "COCO-captions",
      "normalized_name": "cococaptions",
      "name_variants": [
        "COCO-captions"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The COCO-captions dataset is used to evaluate and compare caption generation models across various dimensions such as concreteness, subjectivity, and sentiment. It serves as a benchmark for assessing generated captions and is utilized to train and test models on linguistic similarity metrics. The dataset also supports research on the linguistic representation of 3D objects and their attributes, enabling the collection of discriminative utterances. It facilitates the evaluation of sentiment distribution in generated captions, often compared to neutral sentiment benchmarks."
    },
    {
      "display_name": "MSC",
      "normalized_name": "msc",
      "name_variants": [
        "MSC"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The MSC dataset is used to enhance PersonaChat by incorporating multi-session conversations, annotated with summaries of key personal points. This extension supports personalized text generation, focusing on maintaining context and personal details across multiple interactions. The dataset's annotated summaries enable researchers to develop models that can generate more coherent and contextually relevant responses, improving the quality of personalized dialogue systems."
    },
    {
      "display_name": "PEC",
      "normalized_name": "pec",
      "name_variants": [
        "PEC"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The PEC dataset is used to train empathetic conversational models, focusing on persona-based interactions. It supports research in both multilingual and English settings, enabling the development of conversational agents that can engage in more natural and contextually appropriate dialogues by incorporating user personas. This dataset facilitates the training of models to better understand and respond to user characteristics, enhancing the quality of conversational interactions."
    },
    {
      "display_name": "Books Corpus",
      "normalized_name": "bookscorpus",
      "name_variants": [
        "Books Corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Books Corpus is used to train models for personalized text generation, specifically focusing on capturing narrative and stylistic elements in the text. This dataset enables researchers to develop models that can generate text with nuanced storytelling and writing styles, enhancing the personalization and coherence of generated content."
    },
    {
      "display_name": "BAM! The Behance Artistic Media Dataset",
      "normalized_name": "bamthebehanceartisticmediadataset",
      "name_variants": [
        "BAM! The Behance Artistic Media Dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The BAM! The Behance Artistic Media Dataset is used to enhance personalized text generation by providing a large-scale collection of artistic imagery with multiple attribute annotations. This dataset supports research in recognizing and generating text based on diverse visual inputs, moving beyond traditional photography. It enables the development of models that can better understand and describe various artistic media, improving the richness and relevance of generated text."
    },
    {
      "display_name": "International Affective Picture System",
      "normalized_name": "internationalaffectivepicturesystem",
      "name_variants": [
        "International Affective Picture System"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The International Affective Picture System is used to capture discrete emotions, particularly focusing on four negative emotions considered universal and basic. This dataset informs the development of personalized text generation systems by providing standardized emotional stimuli. Researchers use these images to elicit and measure emotional responses, which are then integrated into algorithms to enhance the emotional accuracy and relevance of generated text."
    },
    {
      "display_name": "Svevo Corpus",
      "normalized_name": "svevocorpus",
      "name_variants": [
        "Svevo Corpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Svevo Corpus is primarily used for evaluating and demonstrating the capabilities of text generation models, particularly in personalized text generation. It focuses on generating epistolary-style text in Italian, often incorporating archaic and dialectal terms. The dataset is utilized to assess the performance of models like ETC-NLG and GePpeTto, generating sentences in both Italian-English and English-Italian parallel texts. Contextual annotations and topic-related keywords enhance the evaluation, enabling researchers to study the structure, variability, and quality of generated text, including the impact of dialectal and archaic expressions."
    },
    {
      "display_name": "possessed dataset",
      "normalized_name": "possessed",
      "name_variants": [
        "possessed dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 'possessed dataset' is used for sentiment and style transfer experiments, focusing on evaluating the delete, retrieve, generate approach to modify text attributes. This methodology involves altering the sentiment or style of text while preserving its core content. The dataset enables researchers to test and validate the effectiveness of these text transformation techniques, addressing specific research questions related to text attribute modification."
    },
    {
      "display_name": "DialogueNLI",
      "normalized_name": "dialoguenli",
      "name_variants": [
        "DialogueNLI"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The DialogueNLI dataset is used to enhance and evaluate the performance of dialogue models in generating contextually appropriate and consistent responses. It is employed to fine-tune models for the PersonaChat domain, train NLI models to assess response consistency with persona sentences, and evaluate the quality and coherence of generated responses in dialogue systems. This dataset specifically supports research in improving personalized text generation by ensuring that generated dialogues align with user personas and maintain contextual relevance."
    },
    {
      "display_name": "b5-ref subcorpus",
      "normalized_name": "b5refsubcorpus",
      "name_variants": [
        "b5-ref subcorpus"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The b5-ref subcorpus is used to enhance Natural Language Generation (NLG) studies by focusing on the generation of referring expressions in text and image captions. It is also employed to investigate how human personality traits influence the creation of referring expressions, specifically in the context of NLG. The dataset supports semantic annotation and provides a basis for studying the effects of personality on language generation."
    },
    {
      "display_name": "Common Voice",
      "normalized_name": "commonvoice",
      "name_variants": [
        "Common Voice"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Common Voice dataset is used to collect speech data from diverse speakers, including 2 Portuguese and 2 English speakers (1 male, 1 female), focusing on voice diversity and quality. It is employed in personalized text generation research, where the dataset's rich voice samples enable the development and evaluation of models that generate text tailored to individual voices."
    },
    {
      "display_name": "VCTK",
      "normalized_name": "vctk",
      "name_variants": [
        "VCTK"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The VCTK dataset is used to evaluate Mean Opinion Scores (MOS) and Similarity Mean Opinion Scores (Sim-MOS) for speech quality and similarity in personalized text generation. It is employed in both English and Portuguese contexts, focusing on assessing the performance of speech synthesis systems. The dataset's diverse speaker profiles enable researchers to test and improve the naturalness and fidelity of generated speech across different languages."
    },
    {
      "display_name": "GAPED",
      "normalized_name": "gaped",
      "name_variants": [
        "GAPED"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The GAPED dataset is used to study valence and normative significance in images, focusing on emotional responses and affective processing. It is employed in research to understand how images influence emotional states, which can inform the development of personalized text generation systems. The dataset's image-based content and associated emotional ratings enable researchers to explore the psychological impact of visual stimuli, enhancing the contextual relevance and emotional accuracy in text generation."
    },
    {
      "display_name": "HelpSteer",
      "normalized_name": "helpsteer",
      "name_variants": [
        "HelpSteer"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The HelpSteer dataset is used to evaluate the effectiveness of SteerLM in generating personalized text, specifically focusing on multi-attribute helpfulness. Researchers employ this dataset to conduct experiments that assess how well the model can produce text that is tailored to individual user attributes, enhancing the relevance and utility of the generated content."
    },
    {
      "display_name": "fixed preference dataset",
      "normalized_name": "fixedpreference",
      "name_variants": [
        "fixed preference dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The 'fixed preference dataset' is used to train a reward representation in a reward-model-free manner, specifically for multi-objective direct preference optimization in language models. This dataset enables researchers to optimize language models according to predefined preferences without the need for explicit reward models, addressing the challenge of aligning model outputs with user preferences."
    },
    {
      "display_name": "Twitter Persona Dataset",
      "normalized_name": "twitterpersonadataset",
      "name_variants": [
        "Twitter Persona Dataset"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The Twitter Persona Dataset is used to evaluate personalized text generation models by providing context for tuning and assessing model performance in generating responses that align with user personas. This dataset enables researchers to focus on the alignment between generated text and specific user characteristics, enhancing the evaluation of personalized communication in text generation tasks."
    },
    {
      "display_name": "OpenSubtitles (OSDb)",
      "normalized_name": "opensubtitlesosdb",
      "name_variants": [
        "OpenSubtitles (OSDb)"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The OpenSubtitles (OSDb) dataset is used for pre-training models on a large multilingual parallel corpus. This pre-training step enhances the models' performance when they are subsequently adapted to a TV series dataset, specifically aiming to improve BLEU scores and personalized text generation. The dataset's extensive multilingual content is crucial for this pre-training phase, enabling better adaptation and performance in downstream tasks."
    },
    {
      "display_name": "IMDB movie reviews",
      "normalized_name": "imdbmoviereviews",
      "name_variants": [
        "IMDB movie reviews"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The IMDB movie reviews dataset is primarily used for training and evaluating sentiment classifiers, focusing on the sentiment analysis of text. It is employed to assess attribute control in research, comparing different approaches to improve sentiment analysis performance. The dataset's extensive text corpus enables robust evaluation and comparison of various sentiment analysis techniques."
    },
    {
      "display_name": "HellaSwag",
      "normalized_name": "hellaswag",
      "name_variants": [
        "HellaSwag"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The HellaSwag dataset is used to evaluate the performance of models in generating the first token after a start token, specifically focusing on initial token prediction accuracy. This dataset enables researchers to assess and compare the effectiveness of different models in this task, providing insights into their predictive capabilities."
    },
    {
      "display_name": "BABEL",
      "normalized_name": "babel",
      "name_variants": [
        "BABEL"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The BABEL dataset is used to enhance personalized text-to-motion synthesis by training models like MotionDiffuse, which focuses on bodies, actions, and behaviors. It is re-annotated with English labels and integrated with HumanML3D to generate diverse and natural 3D human motions from text, improving the quality and personalization of text-driven motion generation."
    },
    {
      "display_name": "AMASS",
      "normalized_name": "amass",
      "name_variants": [
        "AMASS"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The AMASS dataset is re-annotated with English language labels by BA-BEL and HumanML3D, primarily used for generating diverse and natural 3D human motions from text. This enhances personalized text-to-motion synthesis, focusing on the creation of realistic and contextually appropriate 3D animations driven by textual input. The dataset's rich motion data and linguistic annotations enable researchers to develop more sophisticated and nuanced text-to-motion models."
    },
    {
      "display_name": "TripAdvisor",
      "normalized_name": "tripadvisor",
      "name_variants": [
        "TripAdvisor"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The TripAdvisor dataset is used for language modeling, where hotel identifiers and sentiment scores (ranging from one to five stars) are incorporated to generate context-aware text. This approach enables researchers to explore how contextual information influences text generation, focusing on the integration of structured data like ratings and identifiers to enhance the relevance and accuracy of generated text."
    },
    {
      "display_name": "C HAT",
      "normalized_name": "chat",
      "name_variants": [
        "C HAT"
      ],
      "mention_count": 1,
      "cited_papers_count": 1,
      "topic_summary": "The C HAT dataset is used to train and evaluate chatbots and dialogue agents with personalized and persistent personalities. It provides profile sentences for interlocutors, enhancing multi-turn dialogues to improve conversational coherence and personalization. Research focuses on comparing these agents using automatic metrics and human evaluations, demonstrating their superiority in personalized dialogue generation."
    }
  ]
}