{
  "results": [
    {
      "context_text": "Numerous works have explored learning user embeddings as a way to capture syntactic and semantic properties of the language of individuals (Hovy, 2015; Ould Amer et al., 2016; Zeng et al., 2017; Welch et al., 2020b,a; Rocca and Yarkoni, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to works exploring user embeddings. No verifiable resources are identified.",
      "processing_time": 63.93526601791382,
      "citing_paper_id": "267523283",
      "cited_paper_id": 9135567
    },
    {
      "context_text": "Numerous works have explored learning user embeddings as a way to capture syntactic and semantic properties of the language of individuals (Hovy, 2015; Ould Amer et al., 2016; Zeng et al., 2017; Welch et al., 2020b,a; Rocca and Yarkoni, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to works exploring user embeddings. No verifiable resources are identified.",
      "processing_time": 63.93526601791382,
      "citing_paper_id": "267523283",
      "cited_paper_id": 14021168
    },
    {
      "context_text": "Numerous works have explored learning user embeddings as a way to capture syntactic and semantic properties of the language of individuals (Hovy, 2015; Ould Amer et al., 2016; Zeng et al., 2017; Welch et al., 2020b,a; Rocca and Yarkoni, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to works exploring user embeddings. No verifiable resources are identified.",
      "processing_time": 63.93526601791382,
      "citing_paper_id": "267523283",
      "cited_paper_id": 256631001
    },
    {
      "context_text": "IMDb62 contains 62,000 movie reviews written by 62 prolific users of the Internet Movie Database (IMDb) where each user wrote 1,000 reviews (Seroussi et al., 2014).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "IMDb62"
      ],
      "dataset_descriptions": {
        "IMDb62": "Used for authorship attribution studies, specifically analyzing 62,000 movie reviews written by 62 prolific IMDb users, each contributing 1,000 reviews."
      },
      "confidence_score": 1.0,
      "reasoning": "IMDb62 is a specific dataset with a clear identifier and is used for authorship attribution with topic models.",
      "processing_time": 38.21642518043518,
      "citing_paper_id": "267523283",
      "cited_paper_id": 11860229
    },
    {
      "context_text": "We model 3 RST relations in total.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only RST relations which are part of a theoretical framework.",
      "processing_time": 14.38963007926941,
      "citing_paper_id": "267523283",
      "cited_paper_id": 60514661
    },
    {
      "context_text": "We use the publicly available RST parser 3 introduced by Heilman and Sagae (2015) to obtain RST relations.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a tool (RST parser) rather than a dataset. The cited paper title does not indicate a dataset but a theoretical framework.",
      "processing_time": 31.704877138137817,
      "citing_paper_id": "267523283",
      "cited_paper_id": 60514661
    },
    {
      "context_text": "Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) is one of the most influential approaches for document-level discourse analysis.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions Rhetorical Structure Theory (RST) but does not refer to a specific dataset. It is cited as a theoretical framework rather than a reusable resource.",
      "processing_time": 17.74118161201477,
      "citing_paper_id": "267523283",
      "cited_paper_id": 60514661
    },
    {
      "context_text": "In our work, we consider the frequency of the RST relations for each author’s text to capture discourse coherence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only discusses the use of RST relations in capturing discourse coherence, which is a methodological approach rather than a dataset.",
      "processing_time": 20.983855485916138,
      "citing_paper_id": "267523283",
      "cited_paper_id": 60514661
    },
    {
      "context_text": "Our work is closely related to King and Cook (2020), who analyzed various methods, such as interpolation, fine-tuning, and priming language models for the personalization of general-purpose language models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for personalizing language models.",
      "processing_time": 17.08777952194214,
      "citing_paper_id": "267523283",
      "cited_paper_id": 218973759
    },
    {
      "context_text": "The models were pretrained using the Pile dataset (Gao et al., 2020), an 825GB English dataset containing texts from 22 diverse sources, roughly broken down into five categories: academic writing, internet, prose, dialogue, and miscellaneous.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "The Pile"
      ],
      "dataset_descriptions": {
        "The Pile": "Used to pretrain models, focusing on a diverse 825GB English dataset with texts from 22 sources across academic, internet, prose, dialogue, and miscellaneous categories."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'The Pile dataset' as a specific, verifiable dataset used for pretraining models. It provides details about the dataset's size and content, which aligns with the criteria for inclusion.",
      "processing_time": 41.58472418785095,
      "citing_paper_id": "267523283",
      "cited_paper_id": 230435736
    },
    {
      "context_text": "…and Author 2, respectively. and Yeung, 2018; Bingel et al., 2018), Dialogue Modeling (Zhang et al., 2018; Mazaré et al., 2018; Madotto et al., 2019; Ma et al., 2021; Zhong et al., 2022), Machine Translation (Rabinovich et al., 2017), Grammatical Error Correction (Nadejde and Tetreault, 2019),…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various research areas and papers. No verifiable resources are identified.",
      "processing_time": 15.638956308364868,
      "citing_paper_id": "267523283",
      "cited_paper_id": 235792273
    },
    {
      "context_text": "Underlined and bold words refer to verbs. studies (Mireshghallah et al., 2022; Zhong et al., 2021; Oba et al., 2023) have explored leveraging techniques such as adapters for adapting LLMs for various personalized NLP and NLG tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies exploring techniques for personalizing NLP and NLG tasks.",
      "processing_time": 30.921894788742065,
      "citing_paper_id": "267523283",
      "cited_paper_id": 238252929
    },
    {
      "context_text": "…models by fine-tuning pretrained models with attribute-specific corpora or training conditional generative networks (Keskar et al., 2019; Dathathri et al., 2020; Lample et al., 2019; Lo-geswaran et al., 2018; Krause et al., 2021; Russo et al., 2020; Yu et al., 2021; Kulkarni et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing methods and models. No verifiable resources are identified.",
      "processing_time": 17.039584636688232,
      "citing_paper_id": "267523283",
      "cited_paper_id": 239050492
    },
    {
      "context_text": "Some of the noteworthy lines of research have proposed techniques such as Prefix-Tuning (Qian et al., 2022), Adapters (Houlsby et al., 2019), and Prompt-tuning (Yang et al., 2023; Chen et al., 2023) to approach the problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and techniques. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 20.340750694274902,
      "citing_paper_id": "267523283",
      "cited_paper_id": 257353840
    },
    {
      "context_text": "To evaluate our proposed benchmark and given the ubiquitous adoption of causal language models (CLMs) for various NLP tasks recently, we consider the models from the Pythia Scaling Suite (Biderman et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Pythia Scaling Suite' but does not indicate it is a dataset. It is referenced as a suite of models, which is excluded according to the instructions.",
      "processing_time": 32.60136413574219,
      "citing_paper_id": "267523283",
      "cited_paper_id": 257921893
    },
    {
      "context_text": "In recent years, there has been a flurry of writing and conversational assistants that harness the power of LLMs at each stage of the writing life-cycle (Raheja et al., 2023; Gómez-Rodríguez and Williams, 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to writing and conversational assistants using LLMs.",
      "processing_time": 14.715571880340576,
      "citing_paper_id": "267523283",
      "cited_paper_id": 258741409
    },
    {
      "context_text": "Hyperparameters We use Hugging Face’s trans-formers (Wolf et al., 2020) to fine-tune our models.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions using Hugging Face’s transformers but does not refer to any specific dataset. Transformers is a library, not a dataset.",
      "processing_time": 30.08132839202881,
      "citing_paper_id": "267523283",
      "cited_paper_id": null
    },
    {
      "context_text": "Following [12, 14, 24], we use a variety of metrics that are widely adopted in personalized generation tasks: Bleu [21], Rouge-1, Rouge-2, and Rouge-L [16], even though only Bleu is used to calculate the reward for RL.",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions various metrics but does not refer to any specific datasets. The cited papers do not introduce new datasets either.",
      "processing_time": 14.909684419631958,
      "citing_paper_id": "263333908",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Following [12, 14, 24], we use a variety of metrics that are widely adopted in personalized generation tasks: Bleu [21], Rouge-1, Rouge-2, and Rouge-L [16], even though only Bleu is used to calculate the reward for RL.",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions various metrics but does not refer to any specific datasets. The cited papers do not introduce new datasets either.",
      "processing_time": 14.909684419631958,
      "citing_paper_id": "263333908",
      "cited_paper_id": 202767450
    },
    {
      "context_text": "Mostpriorworkonpersonalized text generationrelies ondomain-specific features or knowledge and proposes models to address a particular domain, such as reviews [13, 14], dialogue agents [17, 30, 31] and social networks [6].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions domain-specific applications of personalized text generation but does not specify any named datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 20.34228801727295,
      "citing_paper_id": "263333908",
      "cited_paper_id": 52167799
    },
    {
      "context_text": "Mostpriorworkonpersonalized text generationrelies ondomain-specific features or knowledge and proposes models to address a particular domain, such as reviews [13, 14], dialogue agents [17, 30, 31] and social networks [6].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions domain-specific applications of personalized text generation but does not specify any named datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 20.34228801727295,
      "citing_paper_id": "263333908",
      "cited_paper_id": 202767450
    },
    {
      "context_text": "Mostpriorworkonpersonalized text generationrelies ondomain-specific features or knowledge and proposes models to address a particular domain, such as reviews [13, 14], dialogue agents [17, 30, 31] and social networks [6].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions domain-specific applications of personalized text generation but does not specify any named datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 20.34228801727295,
      "citing_paper_id": "263333908",
      "cited_paper_id": 234757004
    },
    {
      "context_text": "Mostpriorworkonpersonalized text generationrelies ondomain-specific features or knowledge and proposes models to address a particular domain, such as reviews [13, 14], dialogue agents [17, 30, 31] and social networks [6].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions domain-specific applications of personalized text generation but does not specify any named datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 20.34228801727295,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "Due to the lack of real data, they have explored constructing dialogue data by asking crowd-workers to write dialogues for personas [31], extracting user attributes and utterances from Reddit [17, 30] and Weibo [22, 33].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions constructing dialogue data using crowd-workers and extracting data from Reddit and Weibo. These sources are not specific datasets but methods for data collection.",
      "processing_time": 17.014426946640015,
      "citing_paper_id": "263333908",
      "cited_paper_id": 52167799
    },
    {
      "context_text": "Due to the lack of real data, they have explored constructing dialogue data by asking crowd-workers to write dialogues for personas [31], extracting user attributes and utterances from Reddit [17, 30] and Weibo [22, 33].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions constructing dialogue data using crowd-workers and extracting data from Reddit and Weibo. These sources are not specific datasets but methods for data collection.",
      "processing_time": 17.014426946640015,
      "citing_paper_id": "263333908",
      "cited_paper_id": 234757004
    },
    {
      "context_text": "Due to the lack of real data, they have explored constructing dialogue data by asking crowd-workers to write dialogues for personas [31], extracting user attributes and utterances from Reddit [17, 30] and Weibo [22, 33].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions constructing dialogue data using crowd-workers and extracting data from Reddit and Weibo. These sources are not specific datasets but methods for data collection.",
      "processing_time": 17.014426946640015,
      "citing_paper_id": "263333908",
      "cited_paper_id": 247693734
    },
    {
      "context_text": "Due to the lack of real data, they have explored constructing dialogue data by asking crowd-workers to write dialogues for personas [31], extracting user attributes and utterances from Reddit [17, 30] and Weibo [22, 33].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions constructing dialogue data using crowd-workers and extracting data from Reddit and Weibo. These sources are not specific datasets but methods for data collection.",
      "processing_time": 17.014426946640015,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "There are extensive studies on personalizing dialogue agents [17, 30, 31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general studies on personalizing dialogue agents. No verifiable resources are identified.",
      "processing_time": 16.436575174331665,
      "citing_paper_id": "263333908",
      "cited_paper_id": 52167799
    },
    {
      "context_text": "There are extensive studies on personalizing dialogue agents [17, 30, 31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general studies on personalizing dialogue agents. No verifiable resources are identified.",
      "processing_time": 16.436575174331665,
      "citing_paper_id": "263333908",
      "cited_paper_id": 234757004
    },
    {
      "context_text": "There are extensive studies on personalizing dialogue agents [17, 30, 31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general studies on personalizing dialogue agents. No verifiable resources are identified.",
      "processing_time": 16.436575174331665,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "For example, Li and Tuzhilin [14] use self-attentive recursive autoencoders to generate personalized user reviews given product descriptions, sentiment labels, and user historical reviews.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of product descriptions, sentiment labels, and user historical reviews, but does not specify a named dataset. These are components of the data used, not a specific, verifiable dataset.",
      "processing_time": 20.941548824310303,
      "citing_paper_id": "263333908",
      "cited_paper_id": 202767450
    },
    {
      "context_text": "Paraphrasing-based meth-ods [8, 9] rewrite a given prompt into multiple candidate prompts and select the one with the best performance on the training set.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a generic 'training set' without providing a specific name or identifier.",
      "processing_time": 32.162352085113525,
      "citing_paper_id": "263333908",
      "cited_paper_id": 208513249
    },
    {
      "context_text": "There have been extensive studies on automatically learning continuous prompts (a.k.a. soft prompts) in an embedding space, such as prefix tuning [15] and prompt tuning [10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods for learning continuous prompts. No verifiable resources are identified.",
      "processing_time": 16.096506118774414,
      "citing_paper_id": "263333908",
      "cited_paper_id": 230433941
    },
    {
      "context_text": "There have been extensive studies on automatically learning continuous prompts (a.k.a. soft prompts) in an embedding space, such as prefix tuning [15] and prompt tuning [10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods for learning continuous prompts. No verifiable resources are identified.",
      "processing_time": 16.096506118774414,
      "citing_paper_id": "263333908",
      "cited_paper_id": 233296808
    },
    {
      "context_text": "For simplicity, we refer to their framework to fine-tune the personalized LLM proposed in [12] as FtPersLlm.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a framework for fine-tuning personalized LLMs.",
      "processing_time": 27.35208249092102,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "Recently, large language models (LLMs) have been utilized to produce personalized text across domains [12, 24], and fine-tuning is usually required to adapt the LLMs to personal data and the personalized text generation task.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to 'personal data' which is too generic.",
      "processing_time": 15.799746036529541,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "We evaluate our models on the same set of public datasets as FtPer-sLlm [12].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'public datasets' but does not specify any particular dataset names. The context is too generic to identify specific datasets.",
      "processing_time": 27.925050020217896,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "Since our work focuses on a similar setting as the previous work of personalizing LLMs [12], we briefly introduce their work to facilitate discussion.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to previous work on personalizing LLMs.",
      "processing_time": 15.809298276901245,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "When fine-tuning is feasible, previous work [12] has found that the personalized text generator produces the best results when it is instructed by a prompt that includes descriptions about the user’s personal context that are processed through multiple stages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to fine-tuning personalized text generators.",
      "processing_time": 28.178919315338135,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "The multi-stage and multi-task framework proposed in [12] considers the generation of passage-length personalized outputs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a framework for generating personalized outputs.",
      "processing_time": 14.865039825439453,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "Following [12], we partition the datasets by users so that the validation and the test sets only include documents from users that are not present in the training set.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'datasets' but does not specify any named datasets. It describes a method for partitioning datasets, which is not a specific, verifiable resource.",
      "processing_time": 31.255332469940186,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "Unlike FtPersLlm [12], we consider a scenario where the document generator cannot be fine-tuned but is instead a frozen LLM, which is a black box that accepts a text prompt as input and generates a piece of text as output.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological difference in the use of a frozen LLM for text generation.",
      "processing_time": 17.6473650932312,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "We replicate the data processing steps outlined in [12] with a few differences.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a reference to data processing steps. There are no clear identifiers or names of datasets.",
      "processing_time": 30.84490442276001,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "Our empirical findings suggest that this method is a valuable addition to the keyword-based synthesis proposed by FtPersLlm [12].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 18.348389625549316,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "Each of the three datasets comes from a representative domain: (1) for the Avocado Research Email Collection [20], the task is to generate personalized emails; (2) for the Amazon review data [19], the largest category books is used and the goal is to generate personalized reviews; (3) for the…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Avocado Research Email Collection",
        "Amazon review data"
      ],
      "dataset_descriptions": {
        "Avocado Research Email Collection": "Used to generate personalized emails, focusing on the task of creating contextually appropriate and user-specific email content.",
        "Amazon review data": "Used to generate personalized reviews, specifically targeting the books category to produce user-specific and contextually relevant review text."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions three datasets by name, each associated with a specific task in personalized text generation. The datasets are clearly identified and their usage is described.",
      "processing_time": 43.1582977771759,
      "citing_paper_id": "263333908",
      "cited_paper_id": null
    },
    {
      "context_text": "Historically, text generation in general has been evaluated using the classical metrics in natural language generation (NLG) such as BLEU [20] and ROUGE [14], among other metrics that estimate the similarity between the generated text and a reference.",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions metrics (BLEU, ROUGE) but does not refer to any specific datasets. The cited paper title confirms ROUGE is a metric, not a dataset.",
      "processing_time": 18.05514430999756,
      "citing_paper_id": "264289206",
      "cited_paper_id": 964287
    },
    {
      "context_text": "We evaluate T5 XXL, XL, Large and Base checkpoints in a pairwise manner and show the results in Tables 10, 11, 12, 13, 14 and 15.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model checkpoints. No verifiable resources are identified.",
      "processing_time": 14.03519892692566,
      "citing_paper_id": "264289206",
      "cited_paper_id": 964287
    },
    {
      "context_text": "We evaluate T5 XXL, XL, Large and Base checkpoints in a pairwise manner and show the results in Tables 10, 11, 12, 13, 14 and 15.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model checkpoints. No verifiable resources are identified.",
      "processing_time": 14.03519892692566,
      "citing_paper_id": "264289206",
      "cited_paper_id": 202767450
    },
    {
      "context_text": "We evaluate T5 XXL, XL, Large and Base checkpoints in a pairwise manner and show the results in Tables 10, 11, 12, 13, 14 and 15.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model checkpoints. No verifiable resources are identified.",
      "processing_time": 14.03519892692566,
      "citing_paper_id": "264289206",
      "cited_paper_id": 257766307
    },
    {
      "context_text": "We evaluate T5 XXL, XL, Large and Base checkpoints in a pairwise manner and show the results in Tables 10, 11, 12, 13, 14 and 15.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model checkpoints. No verifiable resources are identified.",
      "processing_time": 14.03519892692566,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "We evaluate T5 XXL, XL, Large and Base checkpoints in a pairwise manner and show the results in Tables 10, 11, 12, 13, 14 and 15.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model checkpoints. No verifiable resources are identified.",
      "processing_time": 14.03519892692566,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "We evaluate T5 XXL, XL, Large and Base checkpoints in a pairwise manner and show the results in Tables 10, 11, 12, 13, 14 and 15.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model checkpoints. No verifiable resources are identified.",
      "processing_time": 14.03519892692566,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "…evaluation is reference-based, where an automatic metric will score the similarity between system-generated texts and human curated, high quality examples (references)—texts that are closer to good references are considered higher quality (e.g., ROUGE [14], BLEU [20], and their variants [22, 28]).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses evaluation metrics for text generation, specifically mentioning ROUGE and BLEU. However, these are metrics, not datasets, and thus do not meet the criteria for inclusion.",
      "processing_time": 19.114141702651978,
      "citing_paper_id": "264289206",
      "cited_paper_id": 964287
    },
    {
      "context_text": "…evaluation is reference-based, where an automatic metric will score the similarity between system-generated texts and human curated, high quality examples (references)—texts that are closer to good references are considered higher quality (e.g., ROUGE [14], BLEU [20], and their variants [22, 28]).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses evaluation metrics for text generation, specifically mentioning ROUGE and BLEU. However, these are metrics, not datasets, and thus do not meet the criteria for inclusion.",
      "processing_time": 19.114141702651978,
      "citing_paper_id": "264289206",
      "cited_paper_id": 215548699
    },
    {
      "context_text": "…evaluation is reference-based, where an automatic metric will score the similarity between system-generated texts and human curated, high quality examples (references)—texts that are closer to good references are considered higher quality (e.g., ROUGE [14], BLEU [20], and their variants [22, 28]).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses evaluation metrics for text generation, specifically mentioning ROUGE and BLEU. However, these are metrics, not datasets, and thus do not meet the criteria for inclusion.",
      "processing_time": 19.114141702651978,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "To address this limitation, we leverage the Elo rating system [6], a method originally designed for ranking chess players, and translate the outcomes of pairwise comparisons into Elo scores.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method (Elo rating system) for ranking chess players. No dataset names are provided in the context.",
      "processing_time": 17.666461944580078,
      "citing_paper_id": "264289206",
      "cited_paper_id": 142610973
    },
    {
      "context_text": "Prior work on personalized text generation has often focused on incorporating domain-specific features or knowledge, such as utilizing product descriptions and user history for personalized review generation [13].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "product descriptions and user history"
      ],
      "dataset_descriptions": {
        "product descriptions and user history": "Used to generate personalized reviews, focusing on incorporating domain-specific features and user interaction history to enhance personalization in text generation."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'product descriptions and user history' as domain-specific features used for personalized review generation, which suggests the use of a specific dataset containing these elements.",
      "processing_time": 24.805374145507812,
      "citing_paper_id": "264289206",
      "cited_paper_id": 202767450
    },
    {
      "context_text": "Personalized text generation [13, 21], which tailors output to the contexts and preferences of individual users in order to provide enhanced and customized relevance and user experience, has emerged as a frontier of natural language generation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of personalized text generation. No verifiable resources are identified.",
      "processing_time": 16.345170259475708,
      "citing_paper_id": "264289206",
      "cited_paper_id": 202767450
    },
    {
      "context_text": "Personalized text generation [13, 21], which tailors output to the contexts and preferences of individual users in order to provide enhanced and customized relevance and user experience, has emerged as a frontier of natural language generation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of personalized text generation. No verifiable resources are identified.",
      "processing_time": 16.345170259475708,
      "citing_paper_id": "264289206",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "One recent approach is to use LLMs to score the rating examples (e.g, [5, 7, 10, 15, 16]).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the use of LLMs for scoring rating examples. No verifiable resources are identified.",
      "processing_time": 17.65627932548523,
      "citing_paper_id": "264289206",
      "cited_paper_id": 257766307
    },
    {
      "context_text": "One recent approach is to use LLMs to score the rating examples (e.g, [5, 7, 10, 15, 16]).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the use of LLMs for scoring rating examples. No verifiable resources are identified.",
      "processing_time": 17.65627932548523,
      "citing_paper_id": "264289206",
      "cited_paper_id": 257913780
    },
    {
      "context_text": "One recent approach is to use LLMs to score the rating examples (e.g, [5, 7, 10, 15, 16]).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the use of LLMs for scoring rating examples. No verifiable resources are identified.",
      "processing_time": 17.65627932548523,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "Tables3presents the head-to-head contest records between different T5 models as well as the human-written texts (GOLD) in all three evaluation dimensions on one of the datasets (more results are included in Appendix A.7 and A.8).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context does not mention any specific dataset names, only referring to 'one of the datasets' without providing a clear identifier.",
      "processing_time": 16.93023419380188,
      "citing_paper_id": "264289206",
      "cited_paper_id": 257766307
    },
    {
      "context_text": "Secondly, the inherent assumption that a human reference is the gold standard is now increasingly debated [1, 10, 19].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses a general assumption about human references in text annotation.",
      "processing_time": 18.007103204727173,
      "citing_paper_id": "264289206",
      "cited_paper_id": 257766307
    },
    {
      "context_text": "Secondly, the inherent assumption that a human reference is the gold standard is now increasingly debated [1, 10, 19].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses a general assumption about human references in text annotation.",
      "processing_time": 18.007103204727173,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "Gilardi et al. [10] shows that ChatGPT outperforms crowd workers in multiple text annotation tasks in terms of accuracy and intercoder agreement.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between ChatGPT and crowd workers in text annotation tasks.",
      "processing_time": 16.92339277267456,
      "citing_paper_id": "264289206",
      "cited_paper_id": 257766307
    },
    {
      "context_text": "Chen et al. [5] employ ChatGPT and InstructGPT for reference-free text quality checks, investigating different LLM usage paradigms from explicit to implicit scoring and direct text comparisons.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The focus is on using LLMs for text quality evaluation.",
      "processing_time": 18.303385972976685,
      "citing_paper_id": "264289206",
      "cited_paper_id": 257913780
    },
    {
      "context_text": "LaMP [21] explores how to bridge personalization and LLMs with a retrieval-augmented approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (LaMP) for personalizing large language models.",
      "processing_time": 16.914151906967163,
      "citing_paper_id": "264289206",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "We follow the processing steps of LaMP [21] to organize emails by sender addresses, which exceeds 279 accounts as there may be external senders.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions organizing emails by sender addresses, which suggests the use of a dataset of emails. However, no specific dataset name is provided, only a reference to a method (LaMP) for processing.",
      "processing_time": 22.020804166793823,
      "citing_paper_id": "264289206",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Teamed with new techniques like PandaLM [25], there is an increasing trend of using LLMs to develop future evaluation techniques.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (PandaLM) and a general trend. No verifiable resources are identified.",
      "processing_time": 20.014806032180786,
      "citing_paper_id": "264289206",
      "cited_paper_id": 259108266
    },
    {
      "context_text": "We explore a different path that builds upon the latest advancements in leveraging Large Language Models for text evaluation [15, 16, 25].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to advancements in using Large Language Models for text evaluation.",
      "processing_time": 17.27107000350952,
      "citing_paper_id": "264289206",
      "cited_paper_id": 259108266
    },
    {
      "context_text": "We explore a different path that builds upon the latest advancements in leveraging Large Language Models for text evaluation [15, 16, 25].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to advancements in using Large Language Models for text evaluation.",
      "processing_time": 17.27107000350952,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "We select A/B testing over individual ratings for its advantages in eliminating biases, controlling for confounders, and simplifying decision-making [3].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only discusses the choice of A/B testing over individual ratings.",
      "processing_time": 19.73880934715271,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "Another type of automatic evaluation applies the generated text as the input to another NLP task (which can be evaluated automatically), assuming that a high quality text would yield a better performance in the downstream task (e.g., 𝑄 2 [11]).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept of using generated text as input for downstream NLP tasks.",
      "processing_time": 18.654577016830444,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "We also include PaLM 2-IT-S in the PaLM-2 model family [1], which is larger than all the T5 models, for one specific experiment when contrasting human and LLM generators in Appendix A.8.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models. The context focuses on the use of PaLM 2-IT-S in the PaLM-2 model family for a specific experiment.",
      "processing_time": 22.007668495178223,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "We also examine the use of different LLMs as the evaluator, in particular PaLM 2-IT-L versus PaLM 2-IT-S in PaLM 2 model family [1] (with PaLM 2-IT-S being a smaller model), to compare the T5-XXL generator with three other generator models: T5-XL, T5-Large, and T5-Base.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their sizes. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 27.44597053527832,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "For the Evaluators , we use PaLM 2-IT-L in the PaLM-2 model family [1] as default unless indicated otherwise.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (PaLM 2-IT-L) which is excluded according to the rules.",
      "processing_time": 28.083455324172974,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "To construct immediate context 𝑄 , user profile 𝑈 𝑡 and ˜ 𝑋 𝑡 , we follow the processing step of [12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a processing step. There are no clear identifiers for datasets, models, or other resources.",
      "processing_time": 28.729403018951416,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "Following prior literature [12]",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only references prior literature without providing details.",
      "processing_time": 27.813950300216675,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "Li et al. [12] propose a general approach for personalized text generation using large language models (LLMs) inspired by the style of writing education.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach for personalized text generation using large language models.",
      "processing_time": 28.07165288925171,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "LLM-EVAL [15] proposes a streamlined alternative with a single prompt and a unified schema, facilitating efficient open-domain dialogue evaluation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating dialogue systems.",
      "processing_time": 26.887866258621216,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "Much prior work has delved into this dimension and contributed valuable insights (e.g., [2, 15]).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only references prior work contributing valuable insights.",
      "processing_time": 28.71544075012207,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "Firstly, the reference text may be unavailable or costly to produce [7, 15].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to general issues regarding reference text availability and cost.",
      "processing_time": 29.597333431243896,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "Moreover, even if human-generated content remains superior, similarity alone fails to capture the nuances and multifaceted nature of text quality [15], especially in specialized tasks like personalized text generation which aims to emulate individual human voices.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It discusses the limitations of using similarity as a metric for evaluating personalized text generation.",
      "processing_time": 31.140503644943237,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "The key to navigating the complexity of personalization, looking beyond mere word overlap, is to relate personalization evaluation to the problem of authorship attribution [24].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to the concept of authorship attribution, which is a research area, not a specific resource.",
      "processing_time": 32.59997248649597,
      "citing_paper_id": "264289206",
      "cited_paper_id": null
    },
    {
      "context_text": "For each iteration of training, we use the Adafac-tor optimizer (Shazeer and Stern, 2018) with a learning rate of 5 × 10 − 6 and a linear learning rate decay of 0 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the optimizer used during training.",
      "processing_time": 27.616780757904053,
      "citing_paper_id": "275358199",
      "cited_paper_id": 4786918
    },
    {
      "context_text": "Indeed, instead of maximization, a SFT sequence-to-sequence loss (Sutskever et al., 2014) can be minimized to train the LLM, 2 with the loss being adjusted based on the amount of reward each output receives.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (SFT sequence-to-sequence loss) used for training LLMs.",
      "processing_time": 30.728769063949585,
      "citing_paper_id": "275358199",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Personalization is an important topic with use cases in search, recommendation, and text generation (Fowler et al., 2015; Xue et al., 2009; Naumov et al., 2019; Salemi et al., 2024b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to personalization in various applications. No verifiable resources are identified.",
      "processing_time": 30.69496512413025,
      "citing_paper_id": "275358199",
      "cited_paper_id": 12900424
    },
    {
      "context_text": "Personalization is an important topic with use cases in search, recommendation, and text generation (Fowler et al., 2015; Xue et al., 2009; Naumov et al., 2019; Salemi et al., 2024b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to personalization in various applications. No verifiable resources are identified.",
      "processing_time": 30.69496512413025,
      "citing_paper_id": "275358199",
      "cited_paper_id": null
    },
    {
      "context_text": "7 using Nucleus Sampling (Holtzman et al., 2020), unless otherwise specified.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called Nucleus Sampling. No verifiable resources are identified.",
      "processing_time": 30.13917899131775,
      "citing_paper_id": "275358199",
      "cited_paper_id": 127986954
    },
    {
      "context_text": "During inference, we limit the input to a maximum of 5,120 tokens and the output to 1536 tokens, where we use nucleus sampling (Holtzman et al., 2020) with a sampling temperature of γ = 0 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (nucleus sampling) and its parameters. No verifiable resources are referenced.",
      "processing_time": 31.76524806022644,
      "citing_paper_id": "275358199",
      "cited_paper_id": 127986954
    },
    {
      "context_text": "…as a critical topic in natural language processing (Salemi et al., 2024b; Kumar et al., 2024), due to its wide-ranging applications in recommender systems (Hua et al., 2023; Chen, 2023), virtual assistants (Li et al., 2024b; Kocaballi et al., 2019), and content generation (Alhafni et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of personalized text generation. No verifiable resources are identified.",
      "processing_time": 30.712730884552002,
      "citing_paper_id": "275358199",
      "cited_paper_id": 202797141
    },
    {
      "context_text": "…as a critical topic in natural language processing (Salemi et al., 2024b; Kumar et al., 2024), due to its wide-ranging applications in recommender systems (Hua et al., 2023; Chen, 2023), virtual assistants (Li et al., 2024b; Kocaballi et al., 2019), and content generation (Alhafni et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of personalized text generation. No verifiable resources are identified.",
      "processing_time": 30.712730884552002,
      "citing_paper_id": "275358199",
      "cited_paper_id": 265308990
    },
    {
      "context_text": "…as a critical topic in natural language processing (Salemi et al., 2024b; Kumar et al., 2024), due to its wide-ranging applications in recommender systems (Hua et al., 2023; Chen, 2023), virtual assistants (Li et al., 2024b; Kocaballi et al., 2019), and content generation (Alhafni et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of personalized text generation. No verifiable resources are identified.",
      "processing_time": 30.712730884552002,
      "citing_paper_id": "275358199",
      "cited_paper_id": 267523283
    },
    {
      "context_text": "Following recent text generation evaluation approaches (Gao et al., 2024; Liu et al., 2023b), we use Gemma 7B (Gemma-Team, 2024) as the evaluator.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Gemma 7B' but it is described as an evaluator, which likely refers to a model rather than a dataset. No other specific datasets are mentioned.",
      "processing_time": 33.7905809879303,
      "citing_paper_id": "275358199",
      "cited_paper_id": 257804696
    },
    {
      "context_text": "Following Liu et al. (2023b), to evaluate the generated outputs, we feed the evaluator LLM with the input prompt, the generated text, and the reference output, accompanied by a prompt that explains the evaluation criteria (as depicted in Figure 6).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for evaluating generated text using an LLM. No verifiable resources are identified.",
      "processing_time": 31.740798950195312,
      "citing_paper_id": "275358199",
      "cited_paper_id": 257804696
    },
    {
      "context_text": "Following the approach proposed by Liu et al. (2023b), we employ an instruction-tuned LLM, Gemma (Gemma-Team, 2024), with 7 billion parameters as our text similarity evaluator.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (Gemma) which is excluded according to the rules.",
      "processing_time": 30.701431274414062,
      "citing_paper_id": "275358199",
      "cited_paper_id": 257804696
    },
    {
      "context_text": "The experiments are conducted on 64 TPU-v4 (Jouppi et al., 2023) cores, each with 32GB of memory, for a maximum duration of 1 day.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only hardware specifications. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 31.456785202026367,
      "citing_paper_id": "275358199",
      "cited_paper_id": 257921908
    },
    {
      "context_text": "Additionally, smaller LLMs can acquire this ability through distillation from larger models (Li et al., 2023b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for distilling larger models into smaller ones.",
      "processing_time": 30.133937120437622,
      "citing_paper_id": "275358199",
      "cited_paper_id": 259251773
    },
    {
      "context_text": "Efforts to personalize LLMs include training retrieval models based on feedback for text generation (Salemi et al., 2024a), optimizing LLMs with personalized feedback (Jang et al., 2023), and automatic personalized prompt generation (Li et al., 2024a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for personalizing LLMs. No verifiable resources are identified.",
      "processing_time": 32.1754035949707,
      "citing_paper_id": "275358199",
      "cited_paper_id": 264289231
    },
    {
      "context_text": "Recent studies have explored parameter-efficient fine-tuning (Tan et al., 2024) and their integration with RAG (Salemi and Zamani, 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and research works.",
      "processing_time": 29.24611783027649,
      "citing_paper_id": "275358199",
      "cited_paper_id": 270560467
    },
    {
      "context_text": "Kumar et al. (2024) extended this by introducing the LongLaMP benchmark for long-form personalized text generation.",
      "catation_intent": "reusable resource",
      "resource_type": "benchmark",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'LongLaMP benchmark' which is a benchmark for long-form personalized text generation. However, benchmarks are excluded unless they refer to a specific, downloadable dataset. The context does not provide evidence of a specific dataset.",
      "processing_time": 35.61410093307495,
      "citing_paper_id": "275358199",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "We perform our experiments on the Long-form Language Model Personalization (LongLaMP) benchmark (Kumar et al., 2024), comprising four diverse long-form personalized text generation tasks.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Long-form Language Model Personalization (LongLaMP) benchmark"
      ],
      "dataset_descriptions": {
        "Long-form Language Model Personalization (LongLaMP) benchmark": "Used to evaluate personalized long-form text generation models across four diverse tasks, focusing on the effectiveness of personalization in generating coherent and contextually relevant text."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Long-form Language Model Personalization (LongLaMP) benchmark' which is a specific benchmark for personalized long-form text generation tasks. It is used as a dataset for experimentation.",
      "processing_time": 44.4277560710907,
      "citing_paper_id": "275358199",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "In this paper, we utilize the LongLaMP benchmark (Kumar et al., 2024) to con-12 duct our experiments, which consists of four personalized long-form text generation tasks: 1.",
      "catation_intent": "reusable resource",
      "resource_type": "benchmark",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'LongLaMP benchmark' which is a benchmark for personalized long-form text generation. However, benchmarks are excluded unless they refer to a specific, downloadable dataset. The context does not provide such details.",
      "processing_time": 35.31111288070679,
      "citing_paper_id": "275358199",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "Personalizing large language models (LLMs) emerges as a critical topic in natural language processing (Salemi et al., 2024b; Kumar et al., 2024), due to its wide-ranging applications in recommender systems (Hua et al., 2023; Chen, 2023), virtual assistants (Li et al., 2024b; Kocaballi et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing personalization in LLMs and their applications.",
      "processing_time": 31.952452421188354,
      "citing_paper_id": "275358199",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "Current state-of-the-art methods for personalizing LLMs augment the input with a personalized context (often retrieved from a personal corpus) (Salemi et al., 2024b,a; Kumar et al., 2024).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'personal corpus' but does not specify a named dataset. The term 'personal corpus' is too generic and lacks a clear identifier.",
      "processing_time": 33.23957562446594,
      "citing_paper_id": "275358199",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "For the baselines, we evaluate LLMs that were: (1) trained using SFT with retrieval augmentation (Salemi et al., 2024b; Kumar et al., 2024), (2) trained using SFT with Reasoning-Enhancement as described in Section 3.1, and (3) trained exclusively using self-training with ReST-EM (Singh et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for training LLMs. The context is focused on describing different training methodologies rather than datasets.",
      "processing_time": 33.52224588394165,
      "citing_paper_id": "275358199",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "Although the LongLaMP benchmark (Kumar et al., 2024) primarily relies on ROUGE (Lin, 2004) to assess the quality of long-form text generation, prior studies suggest that lexical overlap metrics often fail to capture semantic similarities (Zhang et al., 2020), especially in long-form generation…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the LongLaMP benchmark but does not refer to it as a dataset. It focuses on the use of ROUGE, which is a metric, and discusses limitations of lexical overlap metrics.",
      "processing_time": 34.939878702163696,
      "citing_paper_id": "275358199",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "This section reports the results of the experiments performed in Section 4 on the validation set of the datasets in the LongLaMP benchmark (Kumar et al., 2024).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'LongLaMP benchmark' which is a benchmark for personalized long-form text generation. However, it does not specify individual datasets within the benchmark, only referring to it as a whole.",
      "processing_time": 35.29242539405823,
      "citing_paper_id": "275358199",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "We adopt the LongLaMP benchmark (Kumar et al., 2024) to conduct our experiments, which consists of four personalized long-form text generation tasks: (1) Personalized Email Completion, (2) Personalized Abstract Generation, (3) Personalized Review Writing, and (4) Personalized Topic Writing.",
      "catation_intent": "reusable resource",
      "resource_type": "benchmark",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'LongLaMP benchmark' but does not refer to it as a dataset. It is described as a benchmark for personalized long-form text generation tasks, which is more aligned with a suite of tasks rather than a specific, downloadable dataset.",
      "processing_time": 36.54969024658203,
      "citing_paper_id": "275358199",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "This improves performance of LLMs in complex tasks such as mathematical, logical, and commonsense reasoning (Wei et al., 2024; Liu et al., 2023a; Yin et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only improvements in LLM performance in various reasoning tasks.",
      "processing_time": 31.69846749305725,
      "citing_paper_id": "275358199",
      "cited_paper_id": 272512070
    },
    {
      "context_text": "This improves performance of LLMs in complex tasks such as mathematical, logical, and commonsense reasoning (Wei et al., 2024; Liu et al., 2023a; Yin et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only improvements in LLM performance in various reasoning tasks.",
      "processing_time": 31.69846749305725,
      "citing_paper_id": "275358199",
      "cited_paper_id": null
    },
    {
      "context_text": "Recent efforts in the community have shifted toward utilizing LLMs as evaluators (Li et al., 2024c).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a shift in the community towards using LLMs as evaluators.",
      "processing_time": 32.84848976135254,
      "citing_paper_id": "275358199",
      "cited_paper_id": null
    },
    {
      "context_text": "Since this LLM is trained on large instruction tuning datasets, if provided with a well-defined evaluation instruction, it can serve as effective judges for text similarity tasks (Li et al., 2024c).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'large instruction tuning datasets' without providing a specific name.",
      "processing_time": 34.04727602005005,
      "citing_paper_id": "275358199",
      "cited_paper_id": null
    },
    {
      "context_text": "LLMs have proven effective in learning from their context (Wei et al., 2022; Brown et al., 2020), making the augmentation of their input with personalized context an effective strategy for personalizing their responses (Salemi et al., 2024b; Salemi and Zamani, 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to the effectiveness of LLMs and the strategy of augmenting their input with personalized context.",
      "processing_time": 35.03616118431091,
      "citing_paper_id": "275358199",
      "cited_paper_id": null
    },
    {
      "context_text": "Here, the LLM generates outputs for given inputs, and those that are of high quality, assessed by a reward function, are used to train the model further (Singh et al., 2024; Zelikman et al., 2022",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general process of training a model using outputs assessed by a reward function.",
      "processing_time": 35.687248945236206,
      "citing_paper_id": "275358199",
      "cited_paper_id": null
    },
    {
      "context_text": "Furthermore, Lee, H. Y. et al. [5] used a social network-based framework to personalize Recurrent Neural Networks (RNNs).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for personalizing RNNs using a social network-based framework.",
      "processing_time": 37.45446300506592,
      "citing_paper_id": "274332909",
      "cited_paper_id": 15595142
    },
    {
      "context_text": "…to individual user data like user-specific features and user identity, large language models can offer more relevant and context-aware content, which can improve user satisfaction and effectiveness in tasks such as recommendation systems [1], sentiment classification, and interactive storytelling.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of personalized large language models.",
      "processing_time": 36.79966473579407,
      "citing_paper_id": "274332909",
      "cited_paper_id": 235187032
    },
    {
      "context_text": "Cao, X. et al. [8] also explored injecting user identity into pre-trained models to improve document-level sentiment classification, reinforcing the need for deeper user integration in NLP models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving document-level sentiment classification by injecting user identity.",
      "processing_time": 38.851101875305176,
      "citing_paper_id": "274332909",
      "cited_paper_id": 247427270
    },
    {
      "context_text": "Welch, C. et al. [6] leveraged user similarity to enhance personalization in language models by integrating user behavior across similar profiles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions leveraging user similarity to enhance personalization in language models, but does not specify a dataset name. The context is about a method or approach rather than a specific dataset.",
      "processing_time": 42.08091616630554,
      "citing_paper_id": "274332909",
      "cited_paper_id": 248779887
    },
    {
      "context_text": "For instance, Li, Xinyu et al. [4] leveraged data from user profiles to enhance personalized model performance by integrating personalized user representations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "data from user profiles"
      ],
      "dataset_descriptions": {
        "data from user profiles": "Used to enhance personalized model performance by integrating personalized user representations, focusing on improving model accuracy through user-specific data."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'data from user profiles' which is domain-qualified and relevant to personalized text generation. However, it does not specify a named dataset.",
      "processing_time": 49.429924726486206,
      "citing_paper_id": "274332909",
      "cited_paper_id": 267547503
    },
    {
      "context_text": "However, despite its capabilities, standard Transformer models generally treat everything equally that do not account for individual user characteristics [3].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general limitation of Transformer models. No verifiable resources are identified.",
      "processing_time": 40.43028497695923,
      "citing_paper_id": "274332909",
      "cited_paper_id": 268710872
    },
    {
      "context_text": "The learning rate is tuned among { 1 𝑒 -3 , 1 𝑒 -4 , 1 𝑒 -5 } .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only learning rate tuning parameters.",
      "processing_time": 39.111165046691895,
      "citing_paper_id": "277627895",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "Some works [11, 46] learn the collaborative information between users and items through matrix factorization [19], while others [10, 40] further explore higher-order collaborative information between users and items using graph neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods and models for recommendation systems, specifically matrix factorization and graph neural networks. No specific datasets are mentioned.",
      "processing_time": 40.9686381816864,
      "citing_paper_id": "277627895",
      "cited_paper_id": 13907106
    },
    {
      "context_text": "Some works [11, 46] learn the collaborative information between users and items through matrix factorization [19], while others [10, 40] further explore higher-order collaborative information between users and items using graph neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods and models for recommendation systems, specifically matrix factorization and graph neural networks. No specific datasets are mentioned.",
      "processing_time": 40.9686381816864,
      "citing_paper_id": "277627895",
      "cited_paper_id": 27308776
    },
    {
      "context_text": "Some works [11, 46] learn the collaborative information between users and items through matrix factorization [19], while others [10, 40] further explore higher-order collaborative information between users and items using graph neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods and models for recommendation systems, specifically matrix factorization and graph neural networks. No specific datasets are mentioned.",
      "processing_time": 40.9686381816864,
      "citing_paper_id": "277627895",
      "cited_paper_id": 58370896
    },
    {
      "context_text": "Some works [11, 46] learn the collaborative information between users and items through matrix factorization [19], while others [10, 40] further explore higher-order collaborative information between users and items using graph neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods and models for recommendation systems, specifically matrix factorization and graph neural networks. No specific datasets are mentioned.",
      "processing_time": 40.9686381816864,
      "citing_paper_id": "277627895",
      "cited_paper_id": 211043589
    },
    {
      "context_text": "Inspired by the application of collaborative filtering in recommender systems [11, 40, 46], we propose to adapt collaborative information into RAG to personalize LLMs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the concept of collaborative filtering which is a method. No verifiable datasets are named or described.",
      "processing_time": 41.805583238601685,
      "citing_paper_id": "277627895",
      "cited_paper_id": 13907106
    },
    {
      "context_text": "Inspired by the application of collaborative filtering in recommender systems [11, 40, 46], we propose to adapt collaborative information into RAG to personalize LLMs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the concept of collaborative filtering which is a method. No verifiable datasets are named or described.",
      "processing_time": 41.805583238601685,
      "citing_paper_id": "277627895",
      "cited_paper_id": 27308776
    },
    {
      "context_text": "Some works [3, 13] encode retrieved documents using separate encoders, and then fuse the results with the language model using cross-attention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 41.47423791885376,
      "citing_paper_id": "277627895",
      "cited_paper_id": 220302360
    },
    {
      "context_text": "Some works [3, 13] encode retrieved documents using separate encoders, and then fuse the results with the language model using cross-attention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 41.47423791885376,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Some works [3, 13] encode retrieved documents using separate encoders, and then fuse the results with the language model using cross-attention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 41.47423791885376,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Firstly, to address Challenge 1, since there are no explicit user similarity labels, we use contrastive learning [15, 44] to train user embeddings for retrieving similar users to introduce collaborative information.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (contrastive learning) for training user embeddings. No verifiable resources are identified.",
      "processing_time": 41.78534483909607,
      "citing_paper_id": "277627895",
      "cited_paper_id": 226227230
    },
    {
      "context_text": "To address this, we employ a contrastive learning [15, 44] approach.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (contrastive learning).",
      "processing_time": 40.047186613082886,
      "citing_paper_id": "277627895",
      "cited_paper_id": 226227230
    },
    {
      "context_text": "Retrieval Augmented Generation [7, 8] introduces external knowledge through document retrieval, alleviating issues such as LLM hallucinations [53], and enhancing LLMs’ capabilities in knowledge-intensive tasks [17] such as open-domain question answering [14, 20].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods. No verifiable resources are identified.",
      "processing_time": 41.25054383277893,
      "citing_paper_id": "277627895",
      "cited_paper_id": 251371732
    },
    {
      "context_text": "Retrieval Augmented Generation [7, 8] introduces external knowledge through document retrieval, alleviating issues such as LLM hallucinations [53], and enhancing LLMs’ capabilities in knowledge-intensive tasks [17] such as open-domain question answering [14, 20].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods. No verifiable resources are identified.",
      "processing_time": 41.25054383277893,
      "citing_paper_id": "277627895",
      "cited_paper_id": 253522998
    },
    {
      "context_text": "Retrieval Augmented Generation [7, 8] introduces external knowledge through document retrieval, alleviating issues such as LLM hallucinations [53], and enhancing LLMs’ capabilities in knowledge-intensive tasks [17] such as open-domain question answering [14, 20].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods. No verifiable resources are identified.",
      "processing_time": 41.25054383277893,
      "citing_paper_id": "277627895",
      "cited_paper_id": 266359151
    },
    {
      "context_text": "Retrieval Augmented Generation [7, 8] introduces external knowledge through document retrieval, alleviating issues such as LLM hallucinations [53], and enhancing LLMs’ capabilities in knowledge-intensive tasks [17] such as open-domain question answering [14, 20].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods. No verifiable resources are identified.",
      "processing_time": 41.25054383277893,
      "citing_paper_id": "277627895",
      "cited_paper_id": 269740933
    },
    {
      "context_text": "Retrieval Augmented Generation [7, 8] introduces external knowledge through document retrieval, alleviating issues such as LLM hallucinations [53], and enhancing LLMs’ capabilities in knowledge-intensive tasks [17] such as open-domain question answering [14, 20].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and methods. No verifiable resources are identified.",
      "processing_time": 41.25054383277893,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Pre-trained dense retrieval models [54] only retrieve based on the semantic relevance between the query and document.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach to dense text retrieval using pre-trained models.",
      "processing_time": 41.260676860809326,
      "citing_paper_id": "277627895",
      "cited_paper_id": 254044526
    },
    {
      "context_text": "Personalized Retrieval-Augmented Generation (RAG) [8] has become a commonly used approach for personalizing LLMs [29, 31, 32, 57].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (Retrieval-Augmented Generation) and a concept (personalizing LLMs).",
      "processing_time": 43.77864456176758,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Personalized Retrieval-Augmented Generation (RAG) [8] has become a commonly used approach for personalizing LLMs [29, 31, 32, 57].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (Retrieval-Augmented Generation) and a concept (personalizing LLMs).",
      "processing_time": 43.77864456176758,
      "citing_paper_id": "277627895",
      "cited_paper_id": 266359151
    },
    {
      "context_text": "Personalized Retrieval-Augmented Generation (RAG) [8] has become a commonly used approach for personalizing LLMs [29, 31, 32, 57].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (Retrieval-Augmented Generation) and a concept (personalizing LLMs).",
      "processing_time": 43.77864456176758,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "(3) Incorporating user-specific context into the prompt [21, 27, 29, 31, 32, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of incorporating user-specific context into prompts. No verifiable resources are named.",
      "processing_time": 42.668381214141846,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "(3) Incorporating user-specific context into the prompt [21, 27, 29, 31, 32, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of incorporating user-specific context into prompts. No verifiable resources are named.",
      "processing_time": 42.668381214141846,
      "citing_paper_id": "277627895",
      "cited_paper_id": 265213422
    },
    {
      "context_text": "(3) Incorporating user-specific context into the prompt [21, 27, 29, 31, 32, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of incorporating user-specific context into prompts. No verifiable resources are named.",
      "processing_time": 42.668381214141846,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "(3) Incorporating user-specific context into the prompt [21, 27, 29, 31, 32, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of incorporating user-specific context into prompts. No verifiable resources are named.",
      "processing_time": 42.668381214141846,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "(3) Incorporating user-specific context into the prompt [21, 27, 29, 31, 32, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of incorporating user-specific context into prompts. No verifiable resources are named.",
      "processing_time": 42.668381214141846,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "• Experimental results on the Language Model Personalization (LaMP) [32] benchmark validate the effectiveness of CFRAG.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LaMP"
      ],
      "dataset_descriptions": {
        "LaMP": "Used to validate the effectiveness of CFRAG in personalizing large language models, focusing on performance improvements through personalization techniques."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Language Model Personalization (LaMP)' as a benchmark, which is primarily used for score comparison. However, since it is referred to as a benchmark and not just a leaderboard, it may contain specific, downloadable datasets. The context does not provide enough detail to confirm this, so the confidence is lowered.",
      "processing_time": 55.15589475631714,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Following previous works [31, 32], we evaluate Accuracy and F-1 score for LaMP-1 and LaMP-2, mean absolute error (MAE) and root mean squared error (RMSE) for LaMP-3, ROUGE-1 and ROUGE-L [24] for LaMP-4, LaMP-5 and LaMP-7.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and models. The context is focused on evaluating different versions of LaMP models using various metrics.",
      "processing_time": 43.48830246925354,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "We conducted experiments on the Language Model Personalization (LaMP) [32] benchmark, which consists of seven personalized text generation tasks.",
      "catation_intent": "reusable resource",
      "resource_type": "benchmark",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Language Model Personalization (LaMP) benchmark', which is a specific benchmark consisting of personalized text generation tasks. However, it is excluded because it is primarily a suite for score comparison rather than a specific, downloadable dataset.",
      "processing_time": 48.08147978782654,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Salemi et al. [31, 32] used RAG to retrieve relevant documents from user history based on the input query and incorporated them into the prompt.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'RAG' which is a method, not a dataset. No specific dataset is mentioned or used according to the given context.",
      "processing_time": 43.22353672981262,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "In recent years, this in-context RAG framework has also been applied to LLM personalization, which is personalized by retrieving documents from the user’s history [31, 32, 57].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RAG framework) and a concept (LLM personalization). No verifiable resources are identified.",
      "processing_time": 44.31699585914612,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "In recent years, this in-context RAG framework has also been applied to LLM personalization, which is personalized by retrieving documents from the user’s history [31, 32, 57].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RAG framework) and a concept (LLM personalization). No verifiable resources are identified.",
      "processing_time": 44.31699585914612,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Personalizing Large Language Models (LLMs) [55] to generate personalized outputs tailored to individual user preferences has emerged as a significant and rapidly growing field [16, 23, 29, 31, 32, 36, 37, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the general topic of personalizing large language models. No verifiable resources are identified.",
      "processing_time": 43.21644115447998,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Personalizing Large Language Models (LLMs) [55] to generate personalized outputs tailored to individual user preferences has emerged as a significant and rapidly growing field [16, 23, 29, 31, 32, 36, 37, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the general topic of personalizing large language models. No verifiable resources are identified.",
      "processing_time": 43.21644115447998,
      "citing_paper_id": "277627895",
      "cited_paper_id": 264289231
    },
    {
      "context_text": "Personalizing Large Language Models (LLMs) [55] to generate personalized outputs tailored to individual user preferences has emerged as a significant and rapidly growing field [16, 23, 29, 31, 32, 36, 37, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the general topic of personalizing large language models. No verifiable resources are identified.",
      "processing_time": 43.21644115447998,
      "citing_paper_id": "277627895",
      "cited_paper_id": 267523232
    },
    {
      "context_text": "Personalizing Large Language Models (LLMs) [55] to generate personalized outputs tailored to individual user preferences has emerged as a significant and rapidly growing field [16, 23, 29, 31, 32, 36, 37, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the general topic of personalizing large language models. No verifiable resources are identified.",
      "processing_time": 43.21644115447998,
      "citing_paper_id": "277627895",
      "cited_paper_id": 267547503
    },
    {
      "context_text": "Personalizing Large Language Models (LLMs) [55] to generate personalized outputs tailored to individual user preferences has emerged as a significant and rapidly growing field [16, 23, 29, 31, 32, 36, 37, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the general topic of personalizing large language models. No verifiable resources are identified.",
      "processing_time": 43.21644115447998,
      "citing_paper_id": "277627895",
      "cited_paper_id": 270560467
    },
    {
      "context_text": "Personalizing Large Language Models (LLMs) [55] to generate personalized outputs tailored to individual user preferences has emerged as a significant and rapidly growing field [16, 23, 29, 31, 32, 36, 37, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the general topic of personalizing large language models. No verifiable resources are identified.",
      "processing_time": 43.21644115447998,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Personalizing Large Language Models (LLMs) [55] to generate personalized outputs tailored to individual user preferences has emerged as a significant and rapidly growing field [16, 23, 29, 31, 32, 36, 37, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the general topic of personalizing large language models. No verifiable resources are identified.",
      "processing_time": 43.21644115447998,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "However, since LLMs are typically designed to serve all tasks with a single model and are trained on broad, domain-agnostic data, they face challenges in adapting to the personalized needs of individual users [4, 32].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general challenges faced by LLMs in personalization.",
      "processing_time": 41.561896085739136,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "[Input] from user [10000041] [32].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation does not mention any specific datasets, only a method (LaMP) which is not a dataset. The context is too vague to infer any specific dataset usage.",
      "processing_time": 44.811615228652954,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Personalization of LLMs. Large Language Models (LLMs) [55] have demonstrated remarkable capabilities in various fields, such as text generation [22], information retrieval [56], recommender systems [5, 41], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of LLMs. No verifiable resources are identified.",
      "processing_time": 42.63548469543457,
      "citing_paper_id": "277627895",
      "cited_paper_id": 258461170
    },
    {
      "context_text": "(2) Aligning LLMs with user-specific preferences through Rein-forcement Learning from Human Feedback (RLHF) [16, 23, 43]; Jang et al. [16] first trained different parameters for various objectives using RLHF, then merged these parameters based on users’ personalized needs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 43.20101976394653,
      "citing_paper_id": "277627895",
      "cited_paper_id": 259064099
    },
    {
      "context_text": "(2) Aligning LLMs with user-specific preferences through Rein-forcement Learning from Human Feedback (RLHF) [16, 23, 43]; Jang et al. [16] first trained different parameters for various objectives using RLHF, then merged these parameters based on users’ personalized needs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 43.20101976394653,
      "citing_paper_id": "277627895",
      "cited_paper_id": 264289231
    },
    {
      "context_text": "(2) Aligning LLMs with user-specific preferences through Rein-forcement Learning from Human Feedback (RLHF) [16, 23, 43]; Jang et al. [16] first trained different parameters for various objectives using RLHF, then merged these parameters based on users’ personalized needs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 43.20101976394653,
      "citing_paper_id": "277627895",
      "cited_paper_id": 267547503
    },
    {
      "context_text": "5 [45].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation does not provide any context about the use of a specific dataset. The title 'C-Pack: Packaged Resources To Advance General Chinese Embedding' suggests a resource, but there is no information on how it is used in the research.",
      "processing_time": 48.50604748725891,
      "citing_paper_id": "277627895",
      "cited_paper_id": 261823330
    },
    {
      "context_text": "Specifically, we first use an embedding model (such as BERT [6], RoBERTa [26], BGE [45] etc.) Emb (·) to encode each document in the user’s history , where e = Emb ( 𝑑 ) and 𝑑 is the embedding dimension.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only embedding models. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 42.635958194732666,
      "citing_paper_id": "277627895",
      "cited_paper_id": 261823330
    },
    {
      "context_text": "Specifically, we first use an embedding model (such as BERT [6], RoBERTa [26], BGE [45] etc.) Emb (·) to encode each document in the user’s history , where e = Emb ( 𝑑 ) and 𝑑 is the embedding dimension.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only embedding models. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 42.635958194732666,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Specifically, we first use an embedding model (such as BERT [6], RoBERTa [26], BGE [45] etc.) Emb (·) to encode each document in the user’s history , where e = Emb ( 𝑑 ) and 𝑑 is the embedding dimension.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only embedding models. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 42.635958194732666,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "The cross-encoder used for reranker in Section 4.3.1 is bge-reranker-base 3 [45].",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a model or method (bge-reranker-base).",
      "processing_time": 41.99944615364075,
      "citing_paper_id": "277627895",
      "cited_paper_id": 261823330
    },
    {
      "context_text": "…(2) Recency selects the most recent 𝑘 items from the user’s history; (3) BM25 [30] retrieves top-𝑘 items from the user’s history using BM25; (4) BGE [45] retrieves top-𝑘 items from the user’s history using BGE retriever; (5) ROPG [31] optimizes the dense retrieval model based on the results…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It describes methods and models used for retrieving items from user history.",
      "processing_time": 42.843027114868164,
      "citing_paper_id": "277627895",
      "cited_paper_id": 261823330
    },
    {
      "context_text": "We use a pre-trained cross-encoder (such as the BGE reranker [45]) to encode the query and document, obtaining the hidden state corresponding to the [CLS] token from the last layer: where h ∈ R .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (cross-encoder) and a tool (BGE reranker). The cited paper title does not provide additional information about a dataset.",
      "processing_time": 46.21369981765747,
      "citing_paper_id": "277627895",
      "cited_paper_id": 261823330
    },
    {
      "context_text": "First, we use a pre-trained dense retrieval model (such as BGE retriever [45]) to compute the semantic relevance between the query and the candidate documents: where Encoder (·) → R and Encoder (·) → R are the encoders for the query and the document in the retrieval model, respectively.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (pre-trained dense retrieval model) and a general process (computing semantic relevance).",
      "processing_time": 44.05269122123718,
      "citing_paper_id": "277627895",
      "cited_paper_id": 261823330
    },
    {
      "context_text": "Directly using these models for retrieval may not necessarily result in content that allows the LLM to generate outputs that meet the user’s needs [25, 35].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models. There are no clear identifiers for datasets in the text.",
      "processing_time": 42.43022799491882,
      "citing_paper_id": "277627895",
      "cited_paper_id": 263605962
    },
    {
      "context_text": "A more common approach is to directly include the retrieved documents in the prompt of the LLM [2, 9, 20, 25, 35].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to using retrieved documents in prompts for LLMs.",
      "processing_time": 43.171793937683105,
      "citing_paper_id": "277627895",
      "cited_paper_id": 263605962
    },
    {
      "context_text": "A more common approach is to directly include the retrieved documents in the prompt of the LLM [2, 9, 20, 25, 35].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to using retrieved documents in prompts for LLMs.",
      "processing_time": 43.171793937683105,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "A more common approach is to directly include the retrieved documents in the prompt of the LLM [2, 9, 20, 25, 35].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to using retrieved documents in prompts for LLMs.",
      "processing_time": 43.171793937683105,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "A more common approach is to directly include the retrieved documents in the prompt of the LLM [2, 9, 20, 25, 35].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach to using retrieved documents in prompts for LLMs.",
      "processing_time": 43.171793937683105,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Since the pre-trained dense retrieval model is not fine-tuned for our specific task, the retrieved results may not necessarily lead to LLM responses that better match the target output 𝑦 [25, 35].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a pre-trained model and a task. There are no clear identifiers for datasets in the text.",
      "processing_time": 44.26501393318176,
      "citing_paper_id": "277627895",
      "cited_paper_id": 263605962
    },
    {
      "context_text": "Therefore, LLM personalization has attracted widespread attention [16, 31, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only that LLM personalization has attracted attention. No verifiable resources are named.",
      "processing_time": 43.66935658454895,
      "citing_paper_id": "277627895",
      "cited_paper_id": 264289231
    },
    {
      "context_text": "Therefore, LLM personalization has attracted widespread attention [16, 31, 57].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only that LLM personalization has attracted attention. No verifiable resources are named.",
      "processing_time": 43.66935658454895,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Existing works on LLM personalization mainly include the following types of methods: (1) Fine-tuning a personalized LLM for each user [36, 37, 42]; Tan et al. [37] fine-tuned the LLM using LoRA [12] to get personalized LoRA parameters for each user.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for personalizing large language models.",
      "processing_time": 42.232749938964844,
      "citing_paper_id": "277627895",
      "cited_paper_id": 267523232
    },
    {
      "context_text": "Existing works on LLM personalization mainly include the following types of methods: (1) Fine-tuning a personalized LLM for each user [36, 37, 42]; Tan et al. [37] fine-tuned the LLM using LoRA [12] to get personalized LoRA parameters for each user.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for personalizing large language models.",
      "processing_time": 42.232749938964844,
      "citing_paper_id": "277627895",
      "cited_paper_id": 270560467
    },
    {
      "context_text": "Existing works on LLM personalization mainly include the following types of methods: (1) Fine-tuning a personalized LLM for each user [36, 37, 42]; Tan et al. [37] fine-tuned the LLM using LoRA [12] to get personalized LoRA parameters for each user.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for personalizing large language models.",
      "processing_time": 42.232749938964844,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Existing works on LLM personalization mainly include the following types of methods: (1) Fine-tuning a personalized LLM for each user [36, 37, 42]; Tan et al. [37] fine-tuned the LLM using LoRA [12] to get personalized LoRA parameters for each user.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for personalizing large language models.",
      "processing_time": 42.232749938964844,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Existing works on LLM personalization mainly include the following types of methods: (1) Fine-tuning a personalized LLM for each user [36, 37, 42]; Tan et al. [37] fine-tuned the LLM using LoRA [12] to get personalized LoRA parameters for each user.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for personalizing large language models.",
      "processing_time": 42.232749938964844,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Existing works on LLM personalization mainly include the following types of methods: (1) Fine-tuning a personalized LLM for each user [36, 37, 42]; Tan et al. [37] fine-tuned the LLM using LoRA [12] to get personalized LoRA parameters for each user.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for personalizing large language models.",
      "processing_time": 42.232749938964844,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "Collaborative filtering has already been applied in fields such as recommender systems [33, 34, 38, 48–52] and has been proven effective.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of collaborative filtering. No verifiable resources are identified.",
      "processing_time": 42.81377363204956,
      "citing_paper_id": "277627895",
      "cited_paper_id": 269149624
    },
    {
      "context_text": "Collaborative filtering has already been applied in fields such as recommender systems [33, 34, 38, 48–52] and has been proven effective.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of collaborative filtering. No verifiable resources are identified.",
      "processing_time": 42.81377363204956,
      "citing_paper_id": "277627895",
      "cited_paper_id": 271221933
    },
    {
      "context_text": "Collaborative filtering has already been applied in fields such as recommender systems [33, 34, 38, 48–52] and has been proven effective.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of collaborative filtering. No verifiable resources are identified.",
      "processing_time": 42.81377363204956,
      "citing_paper_id": "277627895",
      "cited_paper_id": 277435679
    },
    {
      "context_text": "We conducted experiments on two LLMs: Llama3-8B-Instruct [1] and Qwen2-7B-Instruct [47].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions two LLMs but does not refer to any specific datasets. The context is focused on the models themselves, not on datasets.",
      "processing_time": 44.508289098739624,
      "citing_paper_id": "277627895",
      "cited_paper_id": null
    },
    {
      "context_text": "For RAG-based personalization, we employ two widely-used retrievers BM25 (Robertson et al., 2009) and Contriever (Lei et al., 2023).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions BM25 and Contriever as retrievers used for RAG-based personalization, but neither are datasets. They are methods or models.",
      "processing_time": 45.495880365371704,
      "citing_paper_id": "276885086",
      "cited_paper_id": 207178704
    },
    {
      "context_text": "DPO Baseline The DPO algorithm (Rafailov et al., 2024) reframes preference learning by directly optimizing a policy to align with human preferences without explicit reward modeling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an algorithm. There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 43.661709785461426,
      "citing_paper_id": "276885086",
      "cited_paper_id": 258959321
    },
    {
      "context_text": "Additionally, since we obtained style-agnostic responses, we also employ DPO loss (Rafailov et al., 2024) to guide the model to generate user-authentic responses rather than style-agnostic responses.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DPO loss) used to guide the model's response generation.",
      "processing_time": 43.67969012260437,
      "citing_paper_id": "276885086",
      "cited_paper_id": 258959321
    },
    {
      "context_text": "Since we obtained style-agnostic responses, we also employ DPO loss (Rafailov et al., 2024) alignment through lightweight adapters while maintaining the base model’s capabilities.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DPO loss) and a technique (lightweight adapters).",
      "processing_time": 43.67573595046997,
      "citing_paper_id": "276885086",
      "cited_paper_id": 258959321
    },
    {
      "context_text": "A more granular approach could represent users through sparse combinations (Cunningham et al., 2023; Lieberum et al., 2024) of concept-specific vectors, enabling precise control over individual style components.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. The context focuses on the use of sparse combinations of concept-specific vectors, which is a methodological approach rather than a dataset.",
      "processing_time": 47.13616704940796,
      "citing_paper_id": "276885086",
      "cited_paper_id": 261934663
    },
    {
      "context_text": "Recent advances in activation engineering (Zou et al., 2023; Liu et al., 2023; Rimsky et al., 2024) reveal that LLMs encode features and concepts as linear directions in hidden activation space.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only advancements in activation engineering within LLMs. No verifiable resources are identified.",
      "processing_time": 44.2460503578186,
      "citing_paper_id": "276885086",
      "cited_paper_id": 263605618
    },
    {
      "context_text": "Recent advances in activation engineering (Zou et al., 2023; Liu et al., 2023; Rimsky et al., 2024) reveal that LLMs encode features and concepts as linear directions in hidden activation space.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only advancements in activation engineering within LLMs. No verifiable resources are identified.",
      "processing_time": 44.2460503578186,
      "citing_paper_id": "276885086",
      "cited_paper_id": 265149781
    },
    {
      "context_text": "Recent advances in activation engineering (Zou et al., 2023; Liu et al., 2023; Rimsky et al., 2024) reveal that LLMs encode features and concepts as linear directions in hidden activation space.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only advancements in activation engineering within LLMs. No verifiable resources are identified.",
      "processing_time": 44.2460503578186,
      "citing_paper_id": "276885086",
      "cited_paper_id": 266174252
    },
    {
      "context_text": "Emerging research in activation engineering has uncovered that LLMs encode semantic concepts as linear subspaces within hidden activation representations (Zou et al., 2023; Liu et al., 2023; Rimsky et al., 2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research findings about LLMs encoding semantic concepts as linear subspaces. No verifiable resources are identified.",
      "processing_time": 45.465086698532104,
      "citing_paper_id": "276885086",
      "cited_paper_id": 263605618
    },
    {
      "context_text": "Emerging research in activation engineering has uncovered that LLMs encode semantic concepts as linear subspaces within hidden activation representations (Zou et al., 2023; Liu et al., 2023; Rimsky et al., 2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research findings about LLMs encoding semantic concepts as linear subspaces. No verifiable resources are identified.",
      "processing_time": 45.465086698532104,
      "citing_paper_id": "276885086",
      "cited_paper_id": 265149781
    },
    {
      "context_text": "Emerging research in activation engineering has uncovered that LLMs encode semantic concepts as linear subspaces within hidden activation representations (Zou et al., 2023; Liu et al., 2023; Rimsky et al., 2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research findings about LLMs encoding semantic concepts as linear subspaces. No verifiable resources are identified.",
      "processing_time": 45.465086698532104,
      "citing_paper_id": "276885086",
      "cited_paper_id": 266174252
    },
    {
      "context_text": "…for personalized AI assistants highlights the need to customize LLMs to better align with the specific preference of each user (Kirk et al., 2024; Chen et al., 2024a; Au et al., 2025; Cai et al., 2024; Jang et al., 2023; Lin et al., 2024; Zhang et al., 2024b; Liu et al., 2024a; Zhu et al., 2025).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 44.74596643447876,
      "citing_paper_id": "276885086",
      "cited_paper_id": 264289231
    },
    {
      "context_text": "…for personalized AI assistants highlights the need to customize LLMs to better align with the specific preference of each user (Kirk et al., 2024; Chen et al., 2024a; Au et al., 2025; Cai et al., 2024; Jang et al., 2023; Lin et al., 2024; Zhang et al., 2024b; Liu et al., 2024a; Zhu et al., 2025).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 44.74596643447876,
      "citing_paper_id": "276885086",
      "cited_paper_id": 275471754
    },
    {
      "context_text": "…for personalized AI assistants highlights the need to customize LLMs to better align with the specific preference of each user (Kirk et al., 2024; Chen et al., 2024a; Au et al., 2025; Cai et al., 2024; Jang et al., 2023; Lin et al., 2024; Zhang et al., 2024b; Liu et al., 2024a; Zhu et al., 2025).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 44.74596643447876,
      "citing_paper_id": "276885086",
      "cited_paper_id": null
    },
    {
      "context_text": "…for personalized AI assistants highlights the need to customize LLMs to better align with the specific preference of each user (Kirk et al., 2024; Chen et al., 2024a; Au et al., 2025; Cai et al., 2024; Jang et al., 2023; Lin et al., 2024; Zhang et al., 2024b; Liu et al., 2024a; Zhu et al., 2025).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 44.74596643447876,
      "citing_paper_id": "276885086",
      "cited_paper_id": null
    },
    {
      "context_text": "Following (Rimsky et al., 2024), we intervene every token position of the generated text after the end of the initial prompt t ≥ | x | .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for intervening in token positions during text generation.",
      "processing_time": 42.5610294342041,
      "citing_paper_id": "276885086",
      "cited_paper_id": 266174252
    },
    {
      "context_text": "Personalized text generation has emerged as a critical research frontier (Salemi et al., 2024b; Kumar et al., 2024; Alhafni et al., 2024; Chen and Moscholios, 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research papers. There are no clear identifiers for datasets, models, or other resources.",
      "processing_time": 45.237754821777344,
      "citing_paper_id": "276885086",
      "cited_paper_id": 267523283
    },
    {
      "context_text": "The increasing demand for personalized AI assistants highlights the need to customize LLMs to better align with the specific preference of each user (Kirk et al., 2024; Chen et al., 2024a; Au et al., 2025; Cai et al., 2024; Jang et al., 2023; Lin et al., 2024; Zhang et al., 2024b; Liu et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing the personalization of LLMs. No verifiable resources are named.",
      "processing_time": 45.23336839675903,
      "citing_paper_id": "276885086",
      "cited_paper_id": 269348048
    },
    {
      "context_text": "While foundational work (Zhang et al., 2023; Salemi and Zamani, 2024a; Salemi et al., 2024a; Richardson et al., 2023) (Salemi and Zamani, 2024a) reveal that PEFT approaches, particularly those employing user-specific adapter tuning (Tan et al., 2024a; Zhuang et al., 2024; Liu et al., 2024b; Ding et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided citation span does not mention any specific datasets, only references to research works and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 45.22940683364868,
      "citing_paper_id": "276885086",
      "cited_paper_id": null
    },
    {
      "context_text": "While foundational work (Zhang et al., 2023; Salemi and Zamani, 2024a; Salemi et al., 2024a; Richardson et al., 2023) (Salemi and Zamani, 2024a) reveal that PEFT approaches, particularly those employing user-specific adapter tuning (Tan et al., 2024a; Zhuang et al., 2024; Liu et al., 2024b; Ding et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided citation span does not mention any specific datasets, only references to research works and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 45.22940683364868,
      "citing_paper_id": "276885086",
      "cited_paper_id": null
    },
    {
      "context_text": "While foundational work (Zhang et al., 2023; Salemi and Zamani, 2024a; Salemi et al., 2024a; Richardson et al., 2023) (Salemi and Zamani, 2024a) reveal that PEFT approaches, particularly those employing user-specific adapter tuning (Tan et al., 2024a; Zhuang et al., 2024; Liu et al., 2024b; Ding et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided citation span does not mention any specific datasets, only references to research works and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 45.22940683364868,
      "citing_paper_id": "276885086",
      "cited_paper_id": null
    },
    {
      "context_text": "Current approaches predominantly fall into two categories: (1) Retrieval-augmented generation (RAG) methods (Zhang et al., 2023; Salemi and Zamani, 2024a,b), which enhance input prompts by retrieving personalized information from P u , and (2) parameter-efficient fine-tuning (PEFT) methods (Salemi…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 44.20098924636841,
      "citing_paper_id": "276885086",
      "cited_paper_id": null
    },
    {
      "context_text": "…Richardson et al., 2023) (Salemi and Zamani, 2024a) reveal that PEFT approaches, particularly those employing user-specific adapter tuning (Tan et al., 2024a; Zhuang et al., 2024; Liu et al., 2024b; Ding et al., 2025), achieve competitive personalization while maintaining computational efficiency.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no clear identifiers for datasets within the text.",
      "processing_time": 44.19756722450256,
      "citing_paper_id": "276885086",
      "cited_paper_id": null
    },
    {
      "context_text": "Additionally, since the sampling process is nondifferentiable, we use Gumbell-softmax relaxation trick to solve this problem [8, 19].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Gumbell-softmax relaxation) used to address a technical challenge in the sampling process.",
      "processing_time": 45.21896958351135,
      "citing_paper_id": "235703107",
      "cited_paper_id": 2428314
    },
    {
      "context_text": "However, deep learning models can be vulnerable to adversarial attacks [21].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general vulnerability of deep learning models to adversarial attacks.",
      "processing_time": 42.16011953353882,
      "citing_paper_id": "235703107",
      "cited_paper_id": 7004303
    },
    {
      "context_text": "While adversarial attacks on deep learning models have received a lot of attention in graph representation learning, natural language processing, and computer vision domains [21], the vulnerability of deep user sequence embedding-based classification models remains unknown.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general domains where adversarial attacks have been studied. No verifiable resources are named.",
      "processing_time": 43.627134799957275,
      "citing_paper_id": "235703107",
      "cited_paper_id": 7004303
    },
    {
      "context_text": "A non-parametric Maximum Mean Discrepancy (MMD) based on the Reproducing Kernel Hilbert Space (RKHS) is utilized to effectively estimate this kind of distance [25].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for estimating distance using MMD and RKHS.",
      "processing_time": 43.0868661403656,
      "citing_paper_id": "235703107",
      "cited_paper_id": 8308769
    },
    {
      "context_text": "Here we treat the text generation process as a conditional language model which can leverage additional information [14, 15].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general reference to a conditional language model. No verifiable resources are identified.",
      "processing_time": 44.684693336486816,
      "citing_paper_id": "235703107",
      "cited_paper_id": 14994977
    },
    {
      "context_text": "Here we treat the text generation process as a conditional language model which can leverage additional information [14, 15].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general reference to a conditional language model. No verifiable resources are identified.",
      "processing_time": 44.684693336486816,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "Similar to the training of conditional language model [14, 15], we train G by using Maximal Likelihood Estimation (MLE) with teacher-forcing and minimize the loss of negative log-likelihood for all posts based on the corresponding posts and contexts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general methods and approaches. No verifiable resources are identified.",
      "processing_time": 43.32610726356506,
      "citing_paper_id": "235703107",
      "cited_paper_id": 14994977
    },
    {
      "context_text": "Similar to the training of conditional language model [14, 15], we train G by using Maximal Likelihood Estimation (MLE) with teacher-forcing and minimize the loss of negative log-likelihood for all posts based on the corresponding posts and contexts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general methods and approaches. No verifiable resources are identified.",
      "processing_time": 43.32610726356506,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "However, these models can not be directly used to attack sequence classification models, as generated text is not personalized to the user and thus, can be identified by anomaly detection models [1].",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general limitation of models in generating personalized text.",
      "processing_time": 42.71820378303528,
      "citing_paper_id": "235703107",
      "cited_paper_id": 57825713
    },
    {
      "context_text": "The proliferation of undesirable users, such as fake accounts [20], spammers [3, 23], fake news spreaders [15, 26], abnormal users [1], vandal editors [12], fraudsters [11], and sockpuppets [10], poses a threat to the safety and integrity of online communities.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only types of undesirable users in online communities. No verifiable resources are identified.",
      "processing_time": 44.42491412162781,
      "citing_paper_id": "235703107",
      "cited_paper_id": 57825713
    },
    {
      "context_text": "The proliferation of undesirable users, such as fake accounts [20], spammers [3, 23], fake news spreaders [15, 26], abnormal users [1], vandal editors [12], fraudsters [11], and sockpuppets [10], poses a threat to the safety and integrity of online communities.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only types of undesirable users in online communities. No verifiable resources are identified.",
      "processing_time": 44.42491412162781,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "However, these models have various shortcomings: they are incapable of fully leveraging a user’s rich history of posts, they can not generate original content, and their modifications can be easily detected by finding misspelled words and improperly manipulated sentences [22].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses limitations of models.",
      "processing_time": 41.87713098526001,
      "citing_paper_id": "235703107",
      "cited_paper_id": 166228669
    },
    {
      "context_text": "(1)HierarchicalRecurrentNeuralNetwork (HRNN) is amodel where the sequential pattern of the input text is captured by the hierarchical structure for accurate classification [30].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model architecture. There are no verifiable resources or datasets mentioned.",
      "processing_time": 44.16106843948364,
      "citing_paper_id": "235703107",
      "cited_paper_id": 199466300
    },
    {
      "context_text": "To determine whether a user is malicious or not, existing methods usually focus on building deep sequence embedding models to encode the sequential information and use the embedding for downstream applications [13, 16, 30].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 45.18175911903381,
      "citing_paper_id": "235703107",
      "cited_paper_id": 199466300
    },
    {
      "context_text": "(c)Universal adversarial Trigger (UniTrigger) [27]: UniTrigger generates an input-agnostic and fixed-length sequence of tokens to attack the classifier when concatenated to the end of an existing post.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a method (UniTrigger) for generating adversarial triggers. The citation is focused on describing the method rather than a dataset.",
      "processing_time": 47.04158020019531,
      "citing_paper_id": "235703107",
      "cited_paper_id": 201698258
    },
    {
      "context_text": "Modifications include changing or adding characters, words, or phrases [4, 9, 17, 27].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only refers to modifications in a general sense.",
      "processing_time": 44.406973123550415,
      "citing_paper_id": "235703107",
      "cited_paper_id": 201698258
    },
    {
      "context_text": "Specifically, we test whether posts generated by PETGEN are more realistic compared to those generated by Malcom (the SOTA end-to-end adversarial text generation method).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between two methods (PETGEN and Malcom).",
      "processing_time": 44.403712034225464,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "Among the remaining posts, reviewers label 58.33% posts by PETGEN more realistic than Malcom.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between posts generated by PETGEN and Malcom. No verifiable resources are identified.",
      "processing_time": 44.976112842559814,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "Following the similar vectorization method in the previous works [15], we use the Latent Dirichlet Allocation model trained on the whole text to compute the vector representation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to a method (Latent Dirichlet Allocation) used for vector representation.",
      "processing_time": 46.07282829284668,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "In each pair, one post is generated by PETGEN and the other by Malcom.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions two systems, PETGEN and Malcom, but does not specify any datasets. The cited paper title suggests Malcom is a method, not a dataset.",
      "processing_time": 47.280370473861694,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "Compared to the Malcom model, PETGEN deploys the context-aware text generator and the learning task of recent post relevance to leverage the historical post and recent post information for generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing PETGEN and Malcom models, without referencing any datasets.",
      "processing_time": 46.450870990753174,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "Existing text generation methods suffer from three major shortcomings with respect to our attack setting: (a) recent work has adversarially attacked fake news detection classifiers by generating fake reply comments on the posts [15].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating malicious comments to attack fake news detection models.",
      "processing_time": 44.63253140449524,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "We turn to the topic modeling function in this specific application setting, similar to that adopted in prior work [15].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general application setting. No verifiable resources are identified.",
      "processing_time": 44.61425542831421,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "A recent attack model called Malcom [15] generates new fake reply comments to news articles to fool detectors.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Malcom' as an attack model, which is not a dataset but a method for generating malicious comments. No datasets are explicitly mentioned.",
      "processing_time": 47.02430438995361,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "Attacks that append short random text or phrases to the original text can also be detected by topic coherence checkers [15].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for detecting attacks on text. There are no clear identifiers for datasets in the context.",
      "processing_time": 46.43632125854492,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "From this result, we can see our method is able to outperform Malcom in generating realistic posts, and has great potential in real-world applications.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of methods. The context focuses on the performance of the method compared to Malcom.",
      "processing_time": 45.77973461151123,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "We select Relational Memory Recurrent Network (RMRN) as the basic text generationmodelg ofG, following previous work [15, 19], as RMRN models have shown remarkable performance in generating long text posts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (RMRN) which is not a dataset. No verifiable resources are identified.",
      "processing_time": 47.01368975639343,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "(e)Malcom [15]: Malcom is the current state-of-the-art model in adversarial text generation to fool classifiers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions Malcom as a model, not a dataset. There are no specific, verifiable datasets mentioned in the citation context.",
      "processing_time": 46.25358033180237,
      "citing_paper_id": "235703107",
      "cited_paper_id": 221446550
    },
    {
      "context_text": "Generating adversarial text to attack text classifiers is an important task due to its contribution tomodel robustness [29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general task related to adversarial attacks on text classifiers.",
      "processing_time": 45.35157012939453,
      "citing_paper_id": "235703107",
      "cited_paper_id": 260428188
    },
    {
      "context_text": "Individual fairness (Zemel et al., 2013; Joseph et al., 2016) requires similar users to receive similar predictions.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of individual fairness. No dataset names are present in the citation span.",
      "processing_time": 46.41822099685669,
      "citing_paper_id": "253157965",
      "cited_paper_id": 490669
    },
    {
      "context_text": "One way explored for CF in personalization involves removing all information about the protected attribute in representations via discriminators (Zemel et al., 2013; Li et al., 2021b; Wang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for fair representation learning in collaborative filtering.",
      "processing_time": 45.33521008491516,
      "citing_paper_id": "253157965",
      "cited_paper_id": 490669
    },
    {
      "context_text": "One way explored for CF in personalization involves removing all information about the protected attribute in representations via discriminators (Zemel et al., 2013; Li et al., 2021b; Wang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for fair representation learning in collaborative filtering.",
      "processing_time": 45.33521008491516,
      "citing_paper_id": "253157965",
      "cited_paper_id": 234790153
    },
    {
      "context_text": "Fairness Notions: Various fairness notions exist in the literature, with group-wise fairness notions being the firstly studied ones (Zafar et al., 2015; Hardt et al., 2016; Zafar et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only fairness notions and related works. No verifiable resources are identified.",
      "processing_time": 45.758742332458496,
      "citing_paper_id": "253157965",
      "cited_paper_id": 1911971
    },
    {
      "context_text": "Fairness Notions: Various fairness notions exist in the literature, with group-wise fairness notions being the firstly studied ones (Zafar et al., 2015; Hardt et al., 2016; Zafar et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only fairness notions and related works. No verifiable resources are identified.",
      "processing_time": 45.758742332458496,
      "citing_paper_id": "253157965",
      "cited_paper_id": 14600881
    },
    {
      "context_text": "We add the constraint with Lagrangian relaxation as a regularization in the loss (Russell et al., 2017) min with 3) denotes all other losses except for the CF constraint, and λ is a hyper-parameter for fairness-utility trade-off.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach involving Lagrangian relaxation and a fairness-utility trade-off.",
      "processing_time": 45.75406050682068,
      "citing_paper_id": "253157965",
      "cited_paper_id": 3558923
    },
    {
      "context_text": "By controlling the input attribute values for counterfactual inference (CI), we impose a measure-specific CF constraint (Russell et al., 2017) on generated explanations.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for counterfactual inference. No verifiable resources are identified.",
      "processing_time": 46.23104238510132,
      "citing_paper_id": "253157965",
      "cited_paper_id": 3558923
    },
    {
      "context_text": "…(CF) (Kusner et al., 2017), considering fairness from a causal perspective, has gained prominence recently as a more robust fairness notion (Russell et al., 2017; Wu et al., 2019; Makhlouf et al., 2020), which can also enhance group-wise fairness in certain scenarios (Zhang and Bareinboim,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and concepts related to fairness and counterfactuals.",
      "processing_time": 46.01413059234619,
      "citing_paper_id": "253157965",
      "cited_paper_id": 3558923
    },
    {
      "context_text": "[2] show that mortgage algorithms have been discriminatory towards Latino and African Americans, causing them to pay significantly higher interest rates than other risk-equivalent borrowers.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation discusses discriminatory practices in mortgage algorithms but does not mention a specific dataset. The content is more about findings rather than a reusable resource.",
      "processing_time": 46.39586281776428,
      "citing_paper_id": "253157965",
      "cited_paper_id": 4642971
    },
    {
      "context_text": "Personalized text generation (PTG) has extensive applications, such as explainable recommendation (Zhang and Chen, 2020; Chen et al., 2021), post generation (Yuan and Huang, 2019; He et al., 2021), and conversational systems (Zhang et al., 2018, 2019; Lee et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 46.975929975509644,
      "citing_paper_id": "253157965",
      "cited_paper_id": 6862403
    },
    {
      "context_text": "Personalized text generation (PTG) has extensive applications, such as explainable recommendation (Zhang and Chen, 2020; Chen et al., 2021), post generation (Yuan and Huang, 2019; He et al., 2021), and conversational systems (Zhang et al., 2018, 2019; Lee et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 46.975929975509644,
      "citing_paper_id": "253157965",
      "cited_paper_id": 9424845
    },
    {
      "context_text": "Personalized text generation (PTG) has extensive applications, such as explainable recommendation (Zhang and Chen, 2020; Chen et al., 2021), post generation (Yuan and Huang, 2019; He et al., 2021), and conversational systems (Zhang et al., 2018, 2019; Lee et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 46.975929975509644,
      "citing_paper_id": "253157965",
      "cited_paper_id": 13752895
    },
    {
      "context_text": "Personalized text generation (PTG) has extensive applications, such as explainable recommendation (Zhang and Chen, 2020; Chen et al., 2021), post generation (Yuan and Huang, 2019; He et al., 2021), and conversational systems (Zhang et al., 2018, 2019; Lee et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 46.975929975509644,
      "citing_paper_id": "253157965",
      "cited_paper_id": 127953732
    },
    {
      "context_text": "Personalized text generation (PTG) has extensive applications, such as explainable recommendation (Zhang and Chen, 2020; Chen et al., 2021), post generation (Yuan and Huang, 2019; He et al., 2021), and conversational systems (Zhang et al., 2018, 2019; Lee et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 46.975929975509644,
      "citing_paper_id": "253157965",
      "cited_paper_id": 204874165
    },
    {
      "context_text": "Personalized text generation (PTG) has extensive applications, such as explainable recommendation (Zhang and Chen, 2020; Chen et al., 2021), post generation (Yuan and Huang, 2019; He et al., 2021), and conversational systems (Zhang et al., 2018, 2019; Lee et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 46.975929975509644,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235703107
    },
    {
      "context_text": "Personalized text generation (PTG) has extensive applications, such as explainable recommendation (Zhang and Chen, 2020; Chen et al., 2021), post generation (Yuan and Huang, 2019; He et al., 2021), and conversational systems (Zhang et al., 2018, 2019; Lee et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 46.975929975509644,
      "citing_paper_id": "253157965",
      "cited_paper_id": 244478160
    },
    {
      "context_text": "Personalized text generation (PTG) has broad applications in ecommerce systems, such as explainable recommendation [7, 66, 75], conversational systems [28, 74, 76], review summarization [11, 31, 74], etc.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 47.22821640968323,
      "citing_paper_id": "253157965",
      "cited_paper_id": 6862403
    },
    {
      "context_text": "Personalized text generation (PTG) has broad applications in ecommerce systems, such as explainable recommendation [7, 66, 75], conversational systems [28, 74, 76], review summarization [11, 31, 74], etc.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 47.22821640968323,
      "citing_paper_id": "253157965",
      "cited_paper_id": 17865105
    },
    {
      "context_text": "Personalized text generation (PTG) has broad applications in ecommerce systems, such as explainable recommendation [7, 66, 75], conversational systems [28, 74, 76], review summarization [11, 31, 74], etc.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 47.22821640968323,
      "citing_paper_id": "253157965",
      "cited_paper_id": 202767450
    },
    {
      "context_text": "However, due to historical, social, or behavioral reasons, inherent bias may exist within the review text, associating specific linguistic characteristics with the users’ protected attributes such as gender or race (Newman et al., 2008; Alim et al., 2016; Volz et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses the existence of bias in review text, particularly in relation to gender and race. However, no specific datasets are mentioned by name.",
      "processing_time": 47.821701526641846,
      "citing_paper_id": "253157965",
      "cited_paper_id": 7160120
    },
    {
      "context_text": "However, due to historical, social, or behavioral reasons, inherent bias may exist within the review text, associating specific linguistic characteristics with the users’ protected attributes such as gender or race (Newman et al., 2008; Alim et al., 2016; Volz et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses the existence of bias in review text, particularly in relation to gender and race. However, no specific datasets are mentioned by name.",
      "processing_time": 47.821701526641846,
      "citing_paper_id": "253157965",
      "cited_paper_id": 150207412
    },
    {
      "context_text": "However, due to historical, social, or behavioral reasons, inherent bias may exist within the review text, associating specific linguistic characteristics with the users’ protected attributes such as gender or race (Newman et al., 2008; Alim et al., 2016; Volz et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses the existence of bias in review text, particularly in relation to gender and race. However, no specific datasets are mentioned by name.",
      "processing_time": 47.821701526641846,
      "citing_paper_id": "253157965",
      "cited_paper_id": 210507349
    },
    {
      "context_text": "While certain linguistic features that capture the diversity of language use (Newman et al., 2008; Groenwold et al., 2020) are suitable for personalization, others pertaining to the linguistic quality of explanations, such as informativeness or detailedness, (Louis, 2013), should be excluded.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general linguistic features and qualities. No clear, verifiable resource names are provided.",
      "processing_time": 47.22127604484558,
      "citing_paper_id": "253157965",
      "cited_paper_id": 7160120
    },
    {
      "context_text": "Without proper intervention, the system can exhibit such bias, thus adversarially affecting the users’ experience, reliance and trust in the system (Tintarev and Masthoff, 2015).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue of bias in recommendation systems.",
      "processing_time": 45.482847929000854,
      "citing_paper_id": "253157965",
      "cited_paper_id": 8407569
    },
    {
      "context_text": "The generators are typically language models trained on user written reviews from e-commerce platforms (Zhang et al., 2018; Ni et al., 2019; Yang et al., 2021), where sentences related to item descriptions are retained to construct the ground-truth explanations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'user written reviews from e-commerce platforms' but does not specify a named dataset. The reference is too generic and lacks a specific identifier.",
      "processing_time": 48.41825771331787,
      "citing_paper_id": "253157965",
      "cited_paper_id": 9424845
    },
    {
      "context_text": "There have been extensive efforts on developing algorithms formaking fair predictions in resource allocation [20, 26, 60, 62, 64, 68, 71].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing algorithms for fair predictions.",
      "processing_time": 45.9841206073761,
      "citing_paper_id": "253157965",
      "cited_paper_id": 9424845
    },
    {
      "context_text": "There have been extensive efforts on developing algorithms formaking fair predictions in resource allocation [20, 26, 60, 62, 64, 68, 71].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing algorithms for fair predictions.",
      "processing_time": 45.9841206073761,
      "citing_paper_id": "253157965",
      "cited_paper_id": 232126410
    },
    {
      "context_text": "From a broader perspective, the bias can reinforce itself by influencing how users write online, and jeopar-dize fairness in the long run (Schwartz et al., 2016; Alim et al., 2016; Bordia and Bowman, 2019).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts about bias in language and social media. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 49.09937334060669,
      "citing_paper_id": "253157965",
      "cited_paper_id": 9619992
    },
    {
      "context_text": "From a broader perspective, the bias can reinforce itself by influencing how users write online, and jeopar-dize fairness in the long run (Schwartz et al., 2016; Alim et al., 2016; Bordia and Bowman, 2019).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts about bias in language and social media. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 49.09937334060669,
      "citing_paper_id": "253157965",
      "cited_paper_id": 102352788
    },
    {
      "context_text": "From a broader perspective, the bias can reinforce itself by influencing how users write online, and jeopar-dize fairness in the long run (Schwartz et al., 2016; Alim et al., 2016; Bordia and Bowman, 2019).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts about bias in language and social media. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 49.09937334060669,
      "citing_paper_id": "253157965",
      "cited_paper_id": 150207412
    },
    {
      "context_text": "Besides commonly used BLEU-{1,4} (Papineni et al., 2002) (Lin, 2004) scores, we also employ the increasingly popular BERTScore (Zhang et al., 2020), known for better semantic alignment between target and generated text and stronger correlation with human judgments.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only evaluation metrics. Metrics are excluded according to the instructions.",
      "processing_time": 47.44643020629883,
      "citing_paper_id": "253157965",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "• BT (pre-processing): Back-translation has been shown in NLP to help normalize text and reduce bias [8, 48].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (back-translation).",
      "processing_time": 46.942277669906616,
      "citing_paper_id": "253157965",
      "cited_paper_id": 11349626
    },
    {
      "context_text": "Yet, group-wise fairness has different quantitative definitions that are generally incompatible (Kleinberg et al., 2017; Berk et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers discussing fairness in risk assessments.",
      "processing_time": 47.63781523704529,
      "citing_paper_id": "253157965",
      "cited_paper_id": 12924416
    },
    {
      "context_text": "Finally, besides counterfactual metrics, we also evaluate COFFEE’s generalization to improve group-wise fairness by the popular notion of demographic disparity (DDP) (Zafar et al., 2015): All fairness metrics are lower the better , and the quality expectation on each user-item pair is calculated over N = 3 sampled explanations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating fairness metrics. No dataset names are present in the citation context.",
      "processing_time": 48.964317083358765,
      "citing_paper_id": "253157965",
      "cited_paper_id": 14600881
    },
    {
      "context_text": "We plot results on Amazon Movies and Yelp in Figure 4, where we use DDP on FeatCov for fairness and BERTScore for utility.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Amazon Movies",
        "Yelp"
      ],
      "dataset_descriptions": {
        "Amazon Movies": "Used to evaluate the fairness and utility of the DDP on FeatCov method, focusing on movie reviews to assess bias and performance.",
        "Yelp": "Used to evaluate the fairness and utility of the DDP on FeatCov method, focusing on restaurant reviews to assess bias and performance."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions 'Amazon Movies' and 'Yelp' as datasets used for plotting results. These are well-known datasets in the domain of personalized text generation and are likely used to evaluate the fairness and utility of the DDP on FeatCov method.",
      "processing_time": 64.99813890457153,
      "citing_paper_id": "253157965",
      "cited_paper_id": 14600881
    },
    {
      "context_text": "Additionally, we evaluate COFFEE’s generalization to improve group-wise fairness evaluated by demographic disparity (DDP) (Zafar et al., 2015).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a method for evaluating fairness. The term 'demographic disparity' is a metric, not a dataset.",
      "processing_time": 49.7627067565918,
      "citing_paper_id": "253157965",
      "cited_paper_id": 14600881
    },
    {
      "context_text": "Notably, COFFEE achieves the best trade-off by drastically reducing DDP with minimal impact on BERTScore.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (BERTScore) and a method (COFFEE). There are no verifiable resources or datasets mentioned.",
      "processing_time": 50.99388003349304,
      "citing_paper_id": "253157965",
      "cited_paper_id": 14600881
    },
    {
      "context_text": "…counterfactual metrics, we also evaluate COFFEE’s generalization to improve group-wise fairness by the popular notion of demographic disparity (DDP) (Zafar et al., 2015): All fairness metrics are lower the better , and the quality expectation on each user-item pair is calculated over N = 3 sampled…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only fairness metrics and demographic disparity. No clear, verifiable dataset names are present.",
      "processing_time": 50.04799437522888,
      "citing_paper_id": "253157965",
      "cited_paper_id": 14600881
    },
    {
      "context_text": "…metrics, we also evaluate COFFEE’s generalization to improve group-wise fairness by the popular notion of demographic disparity (DDP) (Zafar et al., 2015): All fairness metrics are lower the better , and the quality expectation on each user-item pair is calculated over N = 3 sampled…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only fairness metrics and demographic disparity. No clear, verifiable dataset names are present.",
      "processing_time": 50.197494983673096,
      "citing_paper_id": "253157965",
      "cited_paper_id": 14600881
    },
    {
      "context_text": "This is similar to works in controllable text generation [10, 21, 45, 53], where disentangled attribute tokens are used as input to control the topic, sentiment, or style of the generated text.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts related to controllable text generation.",
      "processing_time": 49.41513991355896,
      "citing_paper_id": "253157965",
      "cited_paper_id": 20981275
    },
    {
      "context_text": "In this work, we investigate the fairness issues in PTG, focusing on one of the mostly studied settings: generating natural language explanations for recommendations (Wang et al., 2018; Chen et al., 2021; Yang et al., 2021; Li et al., 2021a; Yang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies on generating natural language explanations for recommendations. No verifiable resources are identified.",
      "processing_time": 50.67017388343811,
      "citing_paper_id": "253157965",
      "cited_paper_id": 47019137
    },
    {
      "context_text": "In this work, we investigate the fairness issues in PTG, focusing on one of the mostly studied settings: generating natural language explanations for recommendations (Wang et al., 2018; Chen et al., 2021; Yang et al., 2021; Li et al., 2021a; Yang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies on generating natural language explanations for recommendations. No verifiable resources are identified.",
      "processing_time": 50.67017388343811,
      "citing_paper_id": "253157965",
      "cited_paper_id": 204874165
    },
    {
      "context_text": "In this work, we investigate the fairness issues in PTG, focusing on one of the mostly studied settings: generating natural language explanations for recommendations (Wang et al., 2018; Chen et al., 2021; Yang et al., 2021; Li et al., 2021a; Yang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies on generating natural language explanations for recommendations. No verifiable resources are identified.",
      "processing_time": 50.67017388343811,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235187032
    },
    {
      "context_text": "User and item IDs are conventionally input to the generator for explanation generation, represented as learned embedding vectors (Li et al., 2017; Wang et al., 2018; Li et al., 2021a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the use of user and item IDs as inputs to a generator for explanation generation. No verifiable resources are identified.",
      "processing_time": 51.665133476257324,
      "citing_paper_id": "253157965",
      "cited_paper_id": 47019137
    },
    {
      "context_text": "User and item IDs are conventionally input to the generator for explanation generation, represented as learned embedding vectors (Li et al., 2017; Wang et al., 2018; Li et al., 2021a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the use of user and item IDs as inputs to a generator for explanation generation. No verifiable resources are identified.",
      "processing_time": 51.665133476257324,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235187032
    },
    {
      "context_text": "Though CF has been studied in some non-personalized NLP tasks (Huang et al., 2020; Garg et al., 2019), most existing works study the dependency of model outputs on attribute-specific words within the input text (Blodgett et al., 2020; Liang et al., 2021; Sheng et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 51.26928782463074,
      "citing_paper_id": "253157965",
      "cited_paper_id": 52880735
    },
    {
      "context_text": "Though CF has been studied in some non-personalized NLP tasks (Huang et al., 2020; Garg et al., 2019), most existing works study the dependency of model outputs on attribute-specific words within the input text (Blodgett et al., 2020; Liang et al., 2021; Sheng et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 51.26928782463074,
      "citing_paper_id": "253157965",
      "cited_paper_id": 207847197
    },
    {
      "context_text": "Though CF has been studied in some non-personalized NLP tasks (Huang et al., 2020; Garg et al., 2019), most existing works study the dependency of model outputs on attribute-specific words within the input text (Blodgett et al., 2020; Liang et al., 2021; Sheng et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 51.26928782463074,
      "citing_paper_id": "253157965",
      "cited_paper_id": 218971825
    },
    {
      "context_text": "Though CF has been studied in some non-personalized NLP tasks (Huang et al., 2020; Garg et al., 2019), most existing works study the dependency of model outputs on attribute-specific words within the input text (Blodgett et al., 2020; Liang et al., 2021; Sheng et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 51.26928782463074,
      "citing_paper_id": "253157965",
      "cited_paper_id": 234337004
    },
    {
      "context_text": "Though CF has been studied in some non-personalized NLP tasks (Huang et al., 2020; Garg et al., 2019), most existing works study the dependency of model outputs on attribute-specific words within the input text (Blodgett et al., 2020; Liang et al., 2021; Sheng et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies and methods. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 51.26928782463074,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235623756
    },
    {
      "context_text": "In such cases, CI can be easily performed on the input text itself, such as changing male pronouns to female pronouns (Huang et al., 2020; Garg et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods or approaches for counterfactual fairness and bias reduction.",
      "processing_time": 50.41769886016846,
      "citing_paper_id": "253157965",
      "cited_paper_id": 52880735
    },
    {
      "context_text": "In such cases, CI can be easily performed on the input text itself, such as changing male pronouns to female pronouns (Huang et al., 2020; Garg et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods or approaches for counterfactual fairness and bias reduction.",
      "processing_time": 50.41769886016846,
      "citing_paper_id": "253157965",
      "cited_paper_id": 207847197
    },
    {
      "context_text": "COFFEE treats a user’s protected attribute value as a separate token input to the model, and disentangles its representation from the user’s representation (Ma et al., 2019; Locatello et al., 2019b; Zheng et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The focus is on the technique of treating a user’s protected attribute value as a separate token input to the model.",
      "processing_time": 52.7719190120697,
      "citing_paper_id": "253157965",
      "cited_paper_id": 54089884
    },
    {
      "context_text": "COFFEE treats a user’s protected attribute value as a separate token input to the model, and disentangles its representation from the user’s representation (Ma et al., 2019; Locatello et al., 2019b; Zheng et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The focus is on the technique of treating a user’s protected attribute value as a separate token input to the model.",
      "processing_time": 52.7719190120697,
      "citing_paper_id": "253157965",
      "cited_paper_id": 202789109
    },
    {
      "context_text": "…value as a separate token input to the model, along with user and item IDs, and learns disentangled attribute representations from the user representation to encapsulate the effect of each attribute value in explanation generation (Locatello et al., 2019a,b; Ma et al., 2019; Zheng et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the methodology of using disentangled attribute representations in recommendation systems.",
      "processing_time": 52.16596555709839,
      "citing_paper_id": "253157965",
      "cited_paper_id": 54089884
    },
    {
      "context_text": "…value as a separate token input to the model, along with user and item IDs, and learns disentangled attribute representations from the user representation to encapsulate the effect of each attribute value in explanation generation (Locatello et al., 2019a,b; Ma et al., 2019; Zheng et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the methodology of using disentangled attribute representations in recommendation systems.",
      "processing_time": 52.16596555709839,
      "citing_paper_id": "253157965",
      "cited_paper_id": 202789109
    },
    {
      "context_text": "As an example, we study the Amazon Games reviews1, and use the length of reviews as a case study to evaluate the text quality, since length is shown to strongly correlate and indicate text quality in writing assessment and easy to measure [15, 18, 38, 47].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Amazon Games reviews"
      ],
      "dataset_descriptions": {
        "Amazon Games reviews": "Used to evaluate the correlation between review length and text quality, focusing on the impact of length as a measurable indicator of writing quality."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'Amazon Games reviews' as a dataset used to study the relationship between review length and text quality. The cited papers support the relevance of text length in writing assessment.",
      "processing_time": 61.28442144393921,
      "citing_paper_id": "253157965",
      "cited_paper_id": 61222698
    },
    {
      "context_text": "As an example, we study the Amazon Games reviews1, and use the length of reviews as a case study to evaluate the text quality, since length is shown to strongly correlate and indicate text quality in writing assessment and easy to measure [15, 18, 38, 47].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Amazon Games reviews"
      ],
      "dataset_descriptions": {
        "Amazon Games reviews": "Used to evaluate the correlation between review length and text quality, focusing on the impact of length as a measurable indicator of writing quality."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'Amazon Games reviews' as a dataset used to study the relationship between review length and text quality. The cited papers support the relevance of text length in writing assessment.",
      "processing_time": 61.28442144393921,
      "citing_paper_id": "253157965",
      "cited_paper_id": 221882637
    },
    {
      "context_text": "…2017), considering fairness from a causal perspective, has gained prominence recently as a more robust fairness notion (Russell et al., 2017; Wu et al., 2019; Makhlouf et al., 2020), which can also enhance group-wise fairness in certain scenarios (Zhang and Bareinboim, 2018; Khademi et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to fairness notions and causal perspectives in algorithmic decision-making.",
      "processing_time": 51.856101751327515,
      "citing_paper_id": "253157965",
      "cited_paper_id": 85543316
    },
    {
      "context_text": "…2017), considering fairness from a causal perspective, has gained prominence recently as a more robust fairness notion (Russell et al., 2017; Wu et al., 2019; Makhlouf et al., 2020), which can also enhance group-wise fairness in certain scenarios (Zhang and Bareinboim, 2018; Khademi et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to fairness notions and causal perspectives in algorithmic decision-making.",
      "processing_time": 51.856101751327515,
      "citing_paper_id": "253157965",
      "cited_paper_id": 224705254
    },
    {
      "context_text": "Fairness requirements are subjective, contingent on both the application and the the designer’s objective (Hu and Chen, 2020; Khademi et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses fairness in algorithmic decision-making.",
      "processing_time": 51.49214839935303,
      "citing_paper_id": "253157965",
      "cited_paper_id": 85543316
    },
    {
      "context_text": "Additionally, introducing Q numtoken and Q feat in COFFEE-NT bol-sters fairness optimization in FeatCov, suggesting that enhanced quality measures can aid fairness optimization, echoing findings in (Bose and Hamilton, 2019).",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and findings. The context focuses on fairness optimization in graph embeddings, which is not directly related to personalized text generation.",
      "processing_time": 53.89914393424988,
      "citing_paper_id": "253157965",
      "cited_paper_id": 92979801
    },
    {
      "context_text": "Bordia and Bowman (2019) revealed a more frequent co-occurrence of the ’doctor’ with male pronouns and ’nurse’ with female pronouns in generated text.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset by name, only a finding about gender bias in generated text.",
      "processing_time": 52.14033842086792,
      "citing_paper_id": "253157965",
      "cited_paper_id": 102352788
    },
    {
      "context_text": "However, due to its immense power and wide reach, PTG can inadvertently give rise to fairness issues and lead to unintended consequences (Alim et al., 2016; Bor-dia and Bowman, 2019; Blodgett et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues related to fairness and unintended consequences in personalized text generation.",
      "processing_time": 52.74561953544617,
      "citing_paper_id": "253157965",
      "cited_paper_id": 150207412
    },
    {
      "context_text": "However, due to its immense power and wide reach, PTG can inadvertently give rise to fairness issues and lead to unintended consequences (Alim et al., 2016; Bor-dia and Bowman, 2019; Blodgett et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general issues related to fairness and unintended consequences in personalized text generation.",
      "processing_time": 52.74561953544617,
      "citing_paper_id": "253157965",
      "cited_paper_id": 218971825
    },
    {
      "context_text": "Uniqueness and Importance: Fairness in machine learning (ML) is originally studied in automatic decision-making systems that directly impose \"significant\" or \"legal\" effects on individuals (Voigt and Bussche, 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to fairness in machine learning. No verifiable resources are identified.",
      "processing_time": 53.16792058944702,
      "citing_paper_id": "253157965",
      "cited_paper_id": 169453414
    },
    {
      "context_text": "…considerations often revolve around resource allocation by ML models, exemplified in contexts like loan assessments (Lee and Floridi, 2021) or job applications (Singh and Joachims, 2018), where model predictions can un-favorably affect a protected group (Du et al., 2021; Mehrabi et al., 2021).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses fairness in machine learning, particularly in loan assessments and job applications, but does not mention any specific datasets.",
      "processing_time": 53.1571090221405,
      "citing_paper_id": "253157965",
      "cited_paper_id": 201645479
    },
    {
      "context_text": "…considerations often revolve around resource allocation by ML models, exemplified in contexts like loan assessments (Lee and Floridi, 2021) or job applications (Singh and Joachims, 2018), where model predictions can un-favorably affect a protected group (Du et al., 2021; Mehrabi et al., 2021).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses fairness in machine learning, particularly in loan assessments and job applications, but does not mention any specific datasets.",
      "processing_time": 53.1571090221405,
      "citing_paper_id": "253157965",
      "cited_paper_id": 201666566
    },
    {
      "context_text": "…al., 2017), considering fairness from a causal perspective, has gained prominence recently as a more robust fairness notion (Russell et al., 2017; Wu et al., 2019; Makhlouf et al., 2020), which can also enhance group-wise fairness in certain scenarios (Zhang and Bareinboim, 2018; Khademi et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works and concepts. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.326170682907104,
      "citing_paper_id": "253157965",
      "cited_paper_id": 202714856
    },
    {
      "context_text": "In particular, we treat each user’s protected attribute value as a separate token input to the model, together with the user and item IDs, and disentangle the attribute’s representation from the user’s representation [37, 39, 77].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for disentangling representations in recommendation systems.",
      "processing_time": 52.73153805732727,
      "citing_paper_id": "253157965",
      "cited_paper_id": 202789109
    },
    {
      "context_text": "To overcome this, we consider the protected attribute’s value as a special token input to the model along with the associated user and item IDs, and propose to learn disentangled user representations for counterfactual inference [36, 37, 39, 77].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on using protected attributes and user/item IDs for learning disentangled representations.",
      "processing_time": 54.61449480056763,
      "citing_paper_id": "253157965",
      "cited_paper_id": 202789109
    },
    {
      "context_text": "This is because the disentan-glement mechanism enables better representation learning (Ma et al., 2019; Zheng et al., 2021) and increases the flexibility and accuracy of interactions between the user and item for better explanation generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The focus is on the disentanglement mechanism and its benefits for recommendation systems.",
      "processing_time": 54.959898471832275,
      "citing_paper_id": "253157965",
      "cited_paper_id": 202789109
    },
    {
      "context_text": "This is because the disentanglement mechanism enables better representation learning [39, 77] and increases the flexibility and accuracy of interactions between the user and item for better explanation",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach for recommendation systems.",
      "processing_time": 52.70848488807678,
      "citing_paper_id": "253157965",
      "cited_paper_id": 202789109
    },
    {
      "context_text": "Existing models for personalized explanation generation mostly adopt either Transformer (Li et al., 2021a) or RNN (Li et al., 2017; Chen et al., 2021; Yang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 53.700148820877075,
      "citing_paper_id": "253157965",
      "cited_paper_id": 204874165
    },
    {
      "context_text": "Existing models for personalized explanation generation mostly adopt either Transformer (Li et al., 2021a) or RNN (Li et al., 2017; Chen et al., 2021; Yang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 53.700148820877075,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235187032
    },
    {
      "context_text": "For instance, Huang et al. (2020) analyze the sentence completion by a GPT-2 model, and find different sentiment distributions of completed sentences when the occupation word is counterfactu-ally changed in the prompts.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses the analysis of sentiment distributions in sentence completions using a GPT-2 model, which is a method/model, not a dataset.",
      "processing_time": 46.640239238739014,
      "citing_paper_id": "253157965",
      "cited_paper_id": 207847197
    },
    {
      "context_text": "This mirrors methods in controllable text generation (Oraby et al., 2018; Shu et al., 2020; Dathathri et al., 2020), where disentangled attribute tokens are utilized as inputs to modulate the topic, sentiment, or style of generated text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the methodology of using disentangled attribute tokens for controlled text generation.",
      "processing_time": 55.32826590538025,
      "citing_paper_id": "253157965",
      "cited_paper_id": 208617790
    },
    {
      "context_text": "In contrast to resource allocation fairness, NLP researchers primarily examine the representational fairness (Blodgett et al., 2020; Liang et al., 2021; Sheng et al., 2021) regarding how language models shape social biases and stereotypes through natu-ral language understanding (NLU) or generation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts and research areas. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.93875312805176,
      "citing_paper_id": "253157965",
      "cited_paper_id": 218971825
    },
    {
      "context_text": "In contrast to resource allocation fairness, NLP researchers primarily examine the representational fairness (Blodgett et al., 2020; Liang et al., 2021; Sheng et al., 2021) regarding how language models shape social biases and stereotypes through natu-ral language understanding (NLU) or generation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts and research areas. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.93875312805176,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235623756
    },
    {
      "context_text": "We use the multilingual model mBART (Tang et al., 2020) from EasyNMT 7 to perform the translation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using mBART for translation but does not refer to any specific dataset. mBART is a model, not a dataset.",
      "processing_time": 54.75165557861328,
      "citing_paper_id": "253157965",
      "cited_paper_id": 220936592
    },
    {
      "context_text": ") as well as human-judged text quality [15, 38].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only human-judged text quality. No clear identifiers for datasets are present.",
      "processing_time": 54.29473352432251,
      "citing_paper_id": "253157965",
      "cited_paper_id": 221882637
    },
    {
      "context_text": "This verifies that length is a general and strong indicator for text quality [15, 18, 38].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about text length and writing assessment.",
      "processing_time": 53.492438316345215,
      "citing_paper_id": "253157965",
      "cited_paper_id": 221882637
    },
    {
      "context_text": "…to resource allocation fairness, NLP researchers primarily examine the representational fairness (Blodgett et al., 2020; Liang et al., 2021; Sheng et al., 2021) regarding how language models shape social biases and stereotypes through natu-ral language understanding (NLU) or generation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and research areas. The cited paper title suggests a focus on societal biases in language generation, but no specific datasets are named.",
      "processing_time": 57.0673131942749,
      "citing_paper_id": "253157965",
      "cited_paper_id": 234337004
    },
    {
      "context_text": "• ADV (in-processing): Adversarially removing the sensitive information in user or item representations by adding a discriminator (Li et al., 2021b).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving adversarial removal of sensitive information.",
      "processing_time": 53.49313449859619,
      "citing_paper_id": "253157965",
      "cited_paper_id": 234790153
    },
    {
      "context_text": "(1) evaluates the quality distribution of explanations generated had the user’s protected attribute value been a ′ , given that the observed attribute value is a (Kusner et al., 2017; Li et al., 2021b).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and concepts related to fairness and causal notions.",
      "processing_time": 53.818947315216064,
      "citing_paper_id": "253157965",
      "cited_paper_id": 234790153
    },
    {
      "context_text": "In PETER (Li et al., 2021a), user and item IDs, represented as special tokens, are appended to the start of each explanation sequence before being in-putted to transformer layers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method (PETER) and its usage but does not reference any dataset by name.",
      "processing_time": 56.05065369606018,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235187032
    },
    {
      "context_text": "For the raw PETER model (Li et al., 2021a), we mostly follow the original paper’s hyper-parameters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (PETER) and its hyper-parameters. No verifiable resources are identified.",
      "processing_time": 55.554826498031616,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235187032
    },
    {
      "context_text": "As an example, we investigate the explanation generation on Amazon Movies 1 with the personalized transformer model PETER (Li et al., 2021a).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Amazon Movies 1"
      ],
      "dataset_descriptions": {
        "Amazon Movies 1": "Used to investigate explanation generation for movie recommendations, focusing on personalized explanations using the PETER model."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'Amazon Movies 1' as a dataset used for investigating explanation generation with a personalized transformer model. The dataset name is specific and plausible.",
      "processing_time": 62.194194078445435,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235187032
    },
    {
      "context_text": "Denote the loss of the generator for a given user u and item i by L gen ( G θ ( u, i | A = a ) , e ) , which is typically the negative log-likelihood (NLL) loss or a combination of several losses (Li et al., 2017; Yang et al., 2021; Li et al., 2021a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only losses and methods. No verifiable resources are identified.",
      "processing_time": 54.256428241729736,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235187032
    },
    {
      "context_text": "We denote the overall loss as L peter , which is the sum of the NLL loss and context prediction loss (Li et al., 2021a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a loss function and a method. The context is focused on the technical aspects of the model rather than the data used.",
      "processing_time": 56.716304302215576,
      "citing_paper_id": "253157965",
      "cited_paper_id": 235187032
    },
    {
      "context_text": "We use user-side fairness by default in discussions, but COFFEE is general to ensure fairness on either user or item side in the two-sided market (Wang and Joachims, 2021), and be adapted to different models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model called COFFEE. The context focuses on the adaptability of COFFEE to ensure fairness in two-sided markets.",
      "processing_time": 57.66910696029663,
      "citing_paper_id": "253157965",
      "cited_paper_id": 236468577
    },
    {
      "context_text": "• BT (pre-processing): Back-translation has been shown to help normalize text and reduce bias (Ra-binovich et al., 2017; Christiansen et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (back-translation) and its effects on reducing bias in text normalization.",
      "processing_time": 55.26353049278259,
      "citing_paper_id": "253157965",
      "cited_paper_id": 243865608
    },
    {
      "context_text": "This work also demonstrated that the standard text generation scores, such as BLEU, ROUGE (Lin, 2004), METEOR (Lavie & Agarwal, 2007), and BERT (Kim et al., 2021) do not always give a clear understanding of whether the generative models are good matches for the user’s writing style, due to the fact that long-form text generation tasks such as email writing are under-specified compared to tasks such as translation and summarization that many of these metrics were designed for.",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses evaluation metrics for text generation, specifically mentioning ROUGE and METEOR. However, these are metrics, not datasets, and thus do not meet the criteria for inclusion.",
      "processing_time": 57.5360152721405,
      "citing_paper_id": "276249973",
      "cited_paper_id": 964287
    },
    {
      "context_text": "This work also demonstrated that the standard text generation scores, such as BLEU, ROUGE (Lin, 2004), METEOR (Lavie & Agarwal, 2007), and BERT (Kim et al., 2021) do not always give a clear understanding of whether the generative models are good matches for the user’s writing style, due to the fact that long-form text generation tasks such as email writing are under-specified compared to tasks such as translation and summarization that many of these metrics were designed for.",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses evaluation metrics for text generation, specifically mentioning ROUGE and METEOR. However, these are metrics, not datasets, and thus do not meet the criteria for inclusion.",
      "processing_time": 57.5360152721405,
      "citing_paper_id": "276249973",
      "cited_paper_id": 16289845
    },
    {
      "context_text": "This work also demonstrated that the standard text generation scores, such as BLEU, ROUGE (Lin, 2004), METEOR (Lavie & Agarwal, 2007), and BERT (Kim et al., 2021) do not always give a clear understanding of whether the generative models are good matches for the user’s writing style, due to the fact…",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only evaluation metrics. The cited papers are about metrics, not datasets.",
      "processing_time": 54.7002170085907,
      "citing_paper_id": "276249973",
      "cited_paper_id": 964287
    },
    {
      "context_text": "This work also demonstrated that the standard text generation scores, such as BLEU, ROUGE (Lin, 2004), METEOR (Lavie & Agarwal, 2007), and BERT (Kim et al., 2021) do not always give a clear understanding of whether the generative models are good matches for the user’s writing style, due to the fact…",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only evaluation metrics. The cited papers are about metrics, not datasets.",
      "processing_time": 54.7002170085907,
      "citing_paper_id": "276249973",
      "cited_paper_id": 16289845
    },
    {
      "context_text": "The ability to compact these models further via distillation, pruning, or quantization (Hinton et al., 2015; Frantar & Alistarh, 2023; Frantar et al., 2022), and the discovery of parameter-efficient finetuning (PEFT) (Hu et al., 2021; Dettmers et al., 2023; Nikdan et al., 2024), to specialize these…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques such as distillation, pruning, quantization, and parameter-efficient finetuning. The cited papers also do not provide specific dataset names.",
      "processing_time": 58.932738304138184,
      "citing_paper_id": "276249973",
      "cited_paper_id": 7200347
    },
    {
      "context_text": "The ability to compact these models further via distillation, pruning, or quantization (Hinton et al., 2015; Frantar & Alistarh, 2023; Frantar et al., 2022), and the discovery of parameter-efficient finetuning (PEFT) (Hu et al., 2021; Dettmers et al., 2023; Nikdan et al., 2024), to specialize these…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques such as distillation, pruning, quantization, and parameter-efficient finetuning. The cited papers also do not provide specific dataset names.",
      "processing_time": 58.932738304138184,
      "citing_paper_id": "276249973",
      "cited_paper_id": 253237200
    },
    {
      "context_text": "Generative AI technologies have already had a profound impact on both the scale and impact of cybercrime (Schmitt & Flechais, 2024; Basit et al., 2021; Blessing et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing AI-enabled phishing attacks and their impacts on cybercrime.",
      "processing_time": 55.770267724990845,
      "citing_paper_id": "276249973",
      "cited_paper_id": 225047150
    },
    {
      "context_text": "Using LLMs, composing texts that are both persuasive and “human-like” has become very easy to do at scale, and, in fact, generative AI is frequently used for such attacks (Anderljung et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of LLMs for generating persuasive and human-like texts. There are no clear identifiers for datasets.",
      "processing_time": 57.19956374168396,
      "citing_paper_id": "276249973",
      "cited_paper_id": 257557227
    },
    {
      "context_text": "…(Hinton et al., 2015; Frantar & Alistarh, 2023; Frantar et al., 2022), and the discovery of parameter-efficient finetuning (PEFT) (Hu et al., 2021; Dettmers et al., 2023; Nikdan et al., 2024), to specialize these models for a specific setting, has made model adaptation a practically and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and findings related to model adaptation and parameter-efficient fine-tuning.",
      "processing_time": 55.51374626159668,
      "citing_paper_id": "276249973",
      "cited_paper_id": 258841328
    },
    {
      "context_text": "Further reducing barriers to entry, techniques such as low-rank, sparse, and quantized finetuning (Hu et al., 2021; Dettmers et al., 2023; Nikdan et al., 2024; Zhao et al., 2024; Liu et al., 2024b) allow these models to be fine-tuned on a custom dataset on a commercially available GPU such as an…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'custom dataset' but does not provide a specific, identifiable dataset name. The focus is on techniques for fine-tuning models rather than a particular dataset.",
      "processing_time": 57.651392698287964,
      "citing_paper_id": "276249973",
      "cited_paper_id": 258841328
    },
    {
      "context_text": "Further reducing barriers to entry, techniques such as low-rank, sparse, and quantized finetuning (Hu et al., 2021; Dettmers et al., 2023; Nikdan et al., 2024; Zhao et al., 2024; Liu et al., 2024b) allow these models to be fine-tuned on a custom dataset on a commercially available GPU such as an…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'custom dataset' but does not provide a specific, identifiable dataset name. The focus is on techniques for fine-tuning models rather than a particular dataset.",
      "processing_time": 57.651392698287964,
      "citing_paper_id": "276249973",
      "cited_paper_id": 266899669
    },
    {
      "context_text": "Further reducing barriers to entry, techniques such as low-rank, sparse, and quantized finetuning (Hu et al., 2021; Dettmers et al., 2023; Nikdan et al., 2024; Zhao et al., 2024; Liu et al., 2024b) allow these models to be fine-tuned on a custom dataset on a commercially available GPU such as an…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'custom dataset' but does not provide a specific, identifiable dataset name. The focus is on techniques for fine-tuning models rather than a particular dataset.",
      "processing_time": 57.651392698287964,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "While scientists and the media have been raising alarms regarding the potential of Generative AI to cause great harms in malicious hands (Mouton et al., 2024; Anderljung et al., 2023, 2024), the impact of LLM personalization as a way to spoof written media is less explored.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concerns about Generative AI and LLM personalization. No verifiable resources are identified.",
      "processing_time": 56.69586205482483,
      "citing_paper_id": "276249973",
      "cited_paper_id": 259375553
    },
    {
      "context_text": "More recently, Panza (Nicolicioiu et al., 2025) combined these techniques with instruction back-translation (Li et al., 2024), which allows for the use of any text as data for instruction fine-tuning, by using an LLM to write synthetic prompts to which the (genuine) text samples are the desired…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses techniques and methods but does not reference any named datasets.",
      "processing_time": 55.73642039299011,
      "citing_paper_id": "276249973",
      "cited_paper_id": 260866107
    },
    {
      "context_text": "More recently, Panza (Nicolicioiu et al., 2025) combined these techniques with instruction back-translation (Li et al., 2024), which allows for the use of any text as data for instruction fine-tuning, by using an LLM to write synthetic prompts to which the (genuine) text samples are the desired…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses techniques and methods but does not reference any named datasets.",
      "processing_time": 55.73642039299011,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "…Frantar & Alistarh, 2023; Frantar et al., 2022), and the discovery of parameter-efficient finetuning (PEFT) (Hu et al., 2021; Dettmers et al., 2023; Nikdan et al., 2024), to specialize these models for a specific setting, has made model adaptation a practically and theoretically interesting area…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and research findings related to parameter-efficient fine-tuning.",
      "processing_time": 55.04763436317444,
      "citing_paper_id": "276249973",
      "cited_paper_id": 266899669
    },
    {
      "context_text": "An alternative is to fine-tune open-source models for personalization, which Tan et al. (2024) and Nicolicioiu et al. (2025) found necessary for high-quality personal imitation, has also become a feasible approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the approach of fine-tuning open-source models for personalization.",
      "processing_time": 55.23566460609436,
      "citing_paper_id": "276249973",
      "cited_paper_id": 267523232
    },
    {
      "context_text": "An alternative is to fine-tune open-source models for personalization, which Tan et al. (2024) and Nicolicioiu et al. (2025) found necessary for high-quality personal imitation, has also become a feasible approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the approach of fine-tuning open-source models for personalization.",
      "processing_time": 55.23566460609436,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "One PEFT Per User (Tan et al., 2024) used the LAMP benchmark to create models personalized to individual users by means of parameter-efficient finetuning and RAG, where both addressed deployment practicality by demonstrating that these models can be created on relatively cheap hardware, and by improving the state-of-the-art on model personalization.",
      "catation_intent": "findings",
      "resource_type": "benchmark",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'LAMP benchmark' which is a specific benchmark. However, it is used primarily for score comparison rather than as a reusable dataset. No other specific datasets are mentioned.",
      "processing_time": 58.48603630065918,
      "citing_paper_id": "276249973",
      "cited_paper_id": 267523232
    },
    {
      "context_text": "One PEFT Per User (Tan et al., 2024) used the LAMP benchmark to create models personalized to individual users by means of parameter-efficient finetuning and RAG, where both addressed deployment practicality by demonstrating that these models can be created on relatively cheap hardware, and by improving the state-of-the-art on model personalization.",
      "catation_intent": "findings",
      "resource_type": "benchmark",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'LAMP benchmark' which is a specific benchmark. However, it is used primarily for score comparison rather than as a reusable dataset. No other specific datasets are mentioned.",
      "processing_time": 58.48603630065918,
      "citing_paper_id": "276249973",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "One PEFT Per User (Tan et al., 2024) used the LAMP benchmark to create models personalized to individual users by means of parameter-efficient finetuning and RAG, where both addressed deployment practicality by demonstrating that these models can be created on relatively cheap hardware, and by improving the state-of-the-art on model personalization.",
      "catation_intent": "findings",
      "resource_type": "benchmark",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'LAMP benchmark' which is a specific benchmark. However, it is used primarily for score comparison rather than as a reusable dataset. No other specific datasets are mentioned.",
      "processing_time": 58.48603630065918,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "One PEFT Per User (Tan et al., 2024) used the LAMP benchmark to create models personalized to individual users by means of parameter-efficient finetuning and RAG, where both addressed deployment practicality by demonstrating that these models can be created on relatively cheap hardware, and by…",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'LAMP benchmark' but does not refer to it as a dataset. It is likely a benchmark or leaderboard, which is excluded according to the instructions.",
      "processing_time": 58.04673361778259,
      "citing_paper_id": "276249973",
      "cited_paper_id": 267523232
    },
    {
      "context_text": "The introduction of the Language Model Personalization Benchmark (LAMP) (Salemi et al., 2024) and, subsequently, its long-form version Long-LAMP (Kumar et al., 2024) provided actionable benchmarks for several tasks, including tweet generation, movie reviewing, e-mail and social media post writing.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LAMP",
        "Long-LAMP"
      ],
      "dataset_descriptions": {
        "LAMP": "Used to evaluate personalized text generation tasks, including tweet generation, movie reviewing, e-mail, and social media post writing, providing structured data for benchmarking.",
        "Long-LAMP": "Used to evaluate personalized long-form text generation tasks, extending the scope of LAMP to longer texts, providing structured data for benchmarking."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific benchmarks, LAMP and Long-LAMP, which are used for evaluating personalized text generation tasks. These are considered datasets as they provide structured data for benchmarking.",
      "processing_time": 71.77669072151184,
      "citing_paper_id": "276249973",
      "cited_paper_id": 271218187
    },
    {
      "context_text": "…of distinguishing human from AI-generated text will necessarily lead to a larger proportion of authentic work being incorrectly flagged as AI-generated (currently estimated as between 1-8% depending on the tool and threshold used) (Saha & Feizi, 2025), creating problems for honest students.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the challenges and potential issues with AI detection tools.",
      "processing_time": 55.22203326225281,
      "citing_paper_id": "276249973",
      "cited_paper_id": 276558227
    },
    {
      "context_text": "…techniques such as low-rank, sparse, and quantized finetuning (Hu et al., 2021; Dettmers et al., 2023; Nikdan et al., 2024; Zhao et al., 2024; Liu et al., 2024b) allow these models to be fine-tuned on a custom dataset on a commercially available GPU such as an NVIDIA GeForce RTX 4080…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'custom dataset' but does not provide a specific, identifiable name. The citation focuses on techniques for fine-tuning models rather than a specific dataset.",
      "processing_time": 57.84370756149292,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "The ability to compact these models further via distillation, pruning, or quantization (Hinton et al., 2015; Frantar & Alistarh, 2023; Frantar et al., 2022), and the discovery of parameter-efficient finetuning (PEFT) (Hu et al., 2021; Dettmers et al., 2023; Nikdan et al., 2024), to specialize these models for a specific setting, has made model adaptation a practically and theoretically interesting area of study.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and techniques for model adaptation.",
      "processing_time": 54.644360303878784,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "By combining open-source models with the family of PEFT methods referenced in Section 2, attackers – with access only to consumer-grade compute hardware – can combine the writing style of the “sender” with the injection of specific information and preferences of the target into the prompt, further increasing the verisimilitude and persuasiveness of these attacks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and potential applications. There are no clear identifiers for datasets in the text.",
      "processing_time": 56.65840435028076,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "…or quantization (Hinton et al., 2015; Frantar & Alistarh, 2023; Frantar et al., 2022), and the discovery of parameter-efficient finetuning (PEFT) (Hu et al., 2021; Dettmers et al., 2023; Nikdan et al., 2024), to specialize these models for a specific setting, has made model adaptation a…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and techniques. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 57.137691020965576,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "However, as discussed in Nicolicioiu et al. (2025) and in Section 2, current metrics used for text personalized text generation are not sufficiently indicative of the actual quality of the text, thus possibly hiding progress in this area, and ethically collected datasets on which such measurements…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not provide specific names of datasets, only a general reference to 'ethically collected datasets'. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 59.44593930244446,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "Nicolicioiu et al. (2025) addresses this gap by additionally using the MAUVE metric, which measures the distributional distance between corpora produced by different authors, and conducting a range of human studies, demonstrating that the Panza-generated emails can be attributed to the individuals the models were finetuned on, and that the AI-generated emails are not easily distinguished from genuine ones by the authors’ acquaintances, even when the models are finetuned on small samples of the data (75 emails).",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the MAUVE metric and human studies. The context focuses on the evaluation of AI-generated emails, but no named datasets are referenced.",
      "processing_time": 30.42377758026123,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "More recently, Panza (Nicolicioiu et al., 2025) combined these techniques with instruction back-translation (Li et al., 2024), which allows for the use of any text as data for instruction fine-tuning, by using an LLM to write synthetic prompts to which the (genuine) text samples are the desired answers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses techniques and methods but does not reference any named datasets.",
      "processing_time": 56.40893602371216,
      "citing_paper_id": "276249973",
      "cited_paper_id": null
    },
    {
      "context_text": "Overall gains for both the settings are discussed in Table 18 in Appendix D. Personalized Email Completion: For this task, both settings show improvements, with ROUGE-L showing the highest gains.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and results. The context is focused on reporting performance improvements.",
      "processing_time": 56.15706968307495,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "In the user setting, the best performance is achieved by retrieving 2 profiles, resulting in a 101.8% increase in ROUGE-L scores, while the temporal setting sees an 86.2% gain.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics and settings. No verifiable resources are identified.",
      "processing_time": 55.64557147026062,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "In the temporal setting, personalized outcomes improve across all metrics, with ROUGE-L increasing by 4.02%.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (ROUGE-L) which is excluded according to the instructions.",
      "processing_time": 56.597200870513916,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Contriever shows slight advantages in ROUGE-1 and ROUGE-L, while both models perform similarly in METEOR.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics. No datasets are referenced or used in the context provided.",
      "processing_time": 56.39496326446533,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Overall we see an average improvement of 30.21% with ROUGE-1 metric and 47.5 % with ROUGE-L across all tasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only improvements in ROUGE metrics. No verifiable resources are identified.",
      "processing_time": 56.132224559783936,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "In the user setting Contriever performs slightly better in ROUGE-1 and ROUGE-L, and BM25 performs better in METEOR.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. No verifiable resources are identified.",
      "processing_time": 55.13804388046265,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Evaluation: Following previous works, we use ROUGE-1 and ROUGE-L (Lin, 2004) as task evaluation metrics.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions ROUGE-1 and ROUGE-L as evaluation metrics, which are not datasets but rather evaluation tools. No specific datasets are mentioned.",
      "processing_time": 57.53478956222534,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Personalized Abstract Generation: The user setting shows better results in ROUGE-1 and ME-TEOR, but a slight decrease in ROUGE-L.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. The context focuses on the performance of personalized abstract generation using ROUGE-1, ME-TEOR, and ROUGE-L metrics.",
      "processing_time": 59.738348960876465,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "5 exhibits a slight deterioration in the ROUGE-L score, however, shows performance improvements for ROUGE-1 and ME-TEOR scores.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. No verifiable resources are identified.",
      "processing_time": 55.37980079650879,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Contriever generally excels in ROUGE-L, and BM25 performs better in ROUGE-1, with both models showing similar METEOR scores.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics of models. No verifiable resources are identified.",
      "processing_time": 56.124032497406006,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Except for a very small decline in the ROUGE-L score, performance improvements can be seen across all other metrics while using the GPT-3.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (GPT-3) and a metric (ROUGE-L).",
      "processing_time": 57.22929620742798,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "5 and LLaMA2 models with the exception of a slight decline in ROUGE-L score while using the LLaMA2 as displayed in Table 3.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and evaluation metrics. There are no verifiable resources that meet the criteria.",
      "processing_time": 57.05776858329773,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "In the user setting, METEOR shows the highest gain of 6.89%, with Contriever performing slightly better in ROUGE-1 and ROUGE-L, and equally in METEOR.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and model performance.",
      "processing_time": 54.92055106163025,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Retrieving one profile yields the best results, with BM25 excelling in ROUGE-1 and METEOR, while Contriever leads in ROUGE-L.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and methods. No verifiable resources are identified.",
      "processing_time": 56.5587739944458,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "5 and LLaMA2 are utilized, and the evaluation metrics used are ROUGE-1, ROUGE-L, and METEOR.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and evaluation metrics. No verifiable resources are identified.",
      "processing_time": 56.354923248291016,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "In the temporal setting, METEOR achieves the highest gain of 9.89%, with both models performing equally in METEOR, Con-triever showing slightly better results in ROUGE-L, and BM25 outperforming in ROUGE-1.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and models. The context focuses on performance comparisons.",
      "processing_time": 56.55126667022705,
      "citing_paper_id": "271218187",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Data Curation: To generate the data samples, we leverage the Citation Network Dataset (V14) (Tang et al., 2008a), which comprises 5,259,858 papers and 29 features per paper.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Citation Network Dataset (V14)"
      ],
      "dataset_descriptions": {
        "Citation Network Dataset (V14)": "Used to generate data samples for personalized text generation, leveraging 5,259,858 papers and 29 features per paper to create a comprehensive dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the Citation Network Dataset (V14) as a specific dataset used for generating data samples, which is relevant to the research topic of personalized text generation.",
      "processing_time": 67.61524796485901,
      "citing_paper_id": "271218187",
      "cited_paper_id": 3348552
    },
    {
      "context_text": "To generate the data samples, we leverage the Citation Network Dataset (V14) (Tang et al., 2008a).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Citation Network Dataset (V14)"
      ],
      "dataset_descriptions": {
        "Citation Network Dataset (V14)": "Used to generate data samples for personalized text generation, focusing on academic social network structures and relationships."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'Citation Network Dataset (V14)', which is a specific dataset used for generating data samples. The dataset is clearly identified and relevant to the research context.",
      "processing_time": 65.59149289131165,
      "citing_paper_id": "271218187",
      "cited_paper_id": 3348552
    },
    {
      "context_text": "It has been explored across various areas such as product review generation (Li and Tuzhilin, 2019; Li et al., 2020), dialog agents (Zhang et al., 2018; Mazaré et al., 2018; Tang et al., 2008b), sentiment analysis (El-Ansari and Beni-Hssane, 2023; Mireshghallah et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research areas and applications. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.14809226989746,
      "citing_paper_id": "271218187",
      "cited_paper_id": 6869582
    },
    {
      "context_text": "It has been explored across various areas such as product review generation (Li and Tuzhilin, 2019; Li et al., 2020), dialog agents (Zhang et al., 2018; Mazaré et al., 2018; Tang et al., 2008b), sentiment analysis (El-Ansari and Beni-Hssane, 2023; Mireshghallah et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research areas and applications. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 58.14809226989746,
      "citing_paper_id": "271218187",
      "cited_paper_id": 238252929
    },
    {
      "context_text": "Fine-tuning language models on user data raises privacy risks, including data exposure through memorization of training data (Carlini et al., 2019) and inference attacks exploiting model outputs to reveal sensitive user information (Shokri et al., 2017).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses privacy risks in fine-tuning language models, mentioning memorization and inference attacks. No specific datasets are named, only general concepts.",
      "processing_time": 58.13755416870117,
      "citing_paper_id": "271218187",
      "cited_paper_id": 10488675
    },
    {
      "context_text": "Fine-tuning language models on user data raises privacy risks, including data exposure through memorization of training data (Carlini et al., 2019) and inference attacks exploiting model outputs to reveal sensitive user information (Shokri et al., 2017).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses privacy risks in fine-tuning language models, mentioning memorization and inference attacks. No specific datasets are named, only general concepts.",
      "processing_time": 58.13755416870117,
      "citing_paper_id": "271218187",
      "cited_paper_id": 170076423
    },
    {
      "context_text": "We employ nucleus sampling with temperature 0.8 (Holtzman et al., 2019) as the decoding technique.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a decoding technique but does not reference any specific dataset. The focus is on the method rather than a reusable dataset.",
      "processing_time": 57.34721803665161,
      "citing_paper_id": "271218187",
      "cited_paper_id": 127986954
    },
    {
      "context_text": "To generate the data samples, we leverage the Amazon Reviews Dataset (Ni et al., 2019).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Amazon Reviews Dataset"
      ],
      "dataset_descriptions": {
        "Amazon Reviews Dataset": "Used to generate data samples for training or evaluating a recommendation system, focusing on leveraging user reviews to justify recommendations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'Amazon Reviews Dataset' which is a specific, verifiable dataset. It is used for generating data samples, likely for training or evaluating a recommendation system.",
      "processing_time": 63.86623764038086,
      "citing_paper_id": "271218187",
      "cited_paper_id": 202621357
    },
    {
      "context_text": "Data Curation: To generate data samples, we leverage the Amazon Reviews Dataset (Ni et al., 2019), which comprises 150 million reviews { 2 \"name\" : \"Roberto Battiti\", 3 \"input\" : \"Generate an abstract for the title \\\"Reactive and dynamic local search for max-clique: Engineering effective building blocks\\\" using the following items: 1.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Amazon Reviews Dataset"
      ],
      "dataset_descriptions": {
        "Amazon Reviews Dataset": "Used to generate data samples for personalized text generation, leveraging 150 million reviews to train models on user preferences and review content."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the Amazon Reviews Dataset, which is a specific, verifiable dataset used for generating data samples. The dataset is clearly identified and used in the research context.",
      "processing_time": 64.370521068573,
      "citing_paper_id": "271218187",
      "cited_paper_id": 202621357
    },
    {
      "context_text": "Data Curation: To generate data samples, we leverage the Amazon Reviews Dataset (Ni et al., 2019), which comprises 150 million reviews { 2 \"name\" : \"Roberto Battiti\", 3 \"input\" : \"Generate an abstract for the title \\\"Reactive and dynamic local search for max-clique: Engineering effective building…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Amazon Reviews Dataset"
      ],
      "dataset_descriptions": {
        "Amazon Reviews Dataset": "Used to generate data samples for personalized text generation, leveraging 150 million reviews to train models on user preferences and review content."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'Amazon Reviews Dataset' as a source of data samples for generating personalized text. The dataset is specific and verifiable, with a clear reference to its size and origin.",
      "processing_time": 24.61807131767273,
      "citing_paper_id": "271218187",
      "cited_paper_id": 202621357
    },
    {
      "context_text": "Email completion can greatly benefit from personalization (Trajanovski et al., 2021) as email tone varies significantly based on the recipient.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept of personalization in email completion.",
      "processing_time": 56.51504993438721,
      "citing_paper_id": "271218187",
      "cited_paper_id": 233473617
    },
    {
      "context_text": "Email completion is a task that can significantly benefit from personalization (Trajanovski et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general task that could benefit from personalization. No verifiable resources are named.",
      "processing_time": 57.88014197349548,
      "citing_paper_id": "271218187",
      "cited_paper_id": 233473617
    },
    {
      "context_text": "For fine-tuning experiments, we employed FLAN-T5 base (Longpre et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions FLAN-T5 base, which is a model, not a dataset. No datasets are explicitly mentioned in the citation context.",
      "processing_time": 58.271305322647095,
      "citing_paper_id": "271218187",
      "cited_paper_id": 256415991
    },
    {
      "context_text": "5 (size unknown) (Achiam et al., 2023) and LLaMA-2 3 (7B parameters) (Touvron et al., 2023) as LLMs.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions LLaMA-2 but does not indicate it is a dataset. It is clearly a model, so it should be excluded.",
      "processing_time": 58.30897903442383,
      "citing_paper_id": "271218187",
      "cited_paper_id": 257219404
    },
    {
      "context_text": "The remaining emails were then organized by sender’s email address, selecting only those with a sending frequency of 10 to 200 emails, aligning with established methodologies (Salemi et al., 2023).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It refers to a method of organizing emails by sender's email address and sending frequency, which is a process rather than a dataset.",
      "processing_time": 60.232527017593384,
      "citing_paper_id": "271218187",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Personalizing the text generated from Large Language Models (LLMs) has recently attracted significant attention (Salemi et al., 2023; Richardson et al., 2023a,b; Mysore et al., 2023; Alhafni et al., 2024a; Li et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to recent research on personalizing text generation from LLMs.",
      "processing_time": 57.850740909576416,
      "citing_paper_id": "271218187",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Personalizing the text generated from Large Language Models (LLMs) has recently attracted significant attention (Salemi et al., 2023; Richardson et al., 2023a,b; Mysore et al., 2023; Alhafni et al., 2024a; Li et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to recent research on personalizing text generation from LLMs.",
      "processing_time": 57.850740909576416,
      "citing_paper_id": "271218187",
      "cited_paper_id": 267523283
    },
    {
      "context_text": "Salemi et al. (2023) introduce a benchmark for evaluating personalized LLMs using the RAG approach.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a benchmark for evaluating personalized LLMs, but does not specify a dataset name. The term 'benchmark' is excluded as it likely refers to a suite of tasks rather than a specific, downloadable dataset.",
      "processing_time": 61.41500639915466,
      "citing_paper_id": "271218187",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "RAG architectures are increasingly adopted for personalized agents (Wang et al., 2024; Quidwai and Lagana, 2024), due to their ability to retrieve relevant passages to augment prompts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of RAG architectures for personalized agents. No verifiable resources are identified.",
      "processing_time": 58.50831580162048,
      "citing_paper_id": "271218187",
      "cited_paper_id": 267200117
    },
    {
      "context_text": "RAG architectures are increasingly adopted for personalized agents (Wang et al., 2024; Quidwai and Lagana, 2024), due to their ability to retrieve relevant passages to augment prompts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of RAG architectures for personalized agents. No verifiable resources are identified.",
      "processing_time": 58.50831580162048,
      "citing_paper_id": "271218187",
      "cited_paper_id": 268510706
    },
    {
      "context_text": "Then we extract an embedding from each detected face with an Inception-ResnetV1 [35] pre-trained on VGGFace2 [3].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "VGGFace2"
      ],
      "dataset_descriptions": {
        "VGGFace2": "Used to train the Inception-ResnetV1 model for facial recognition, focusing on recognizing faces across pose and age variations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'VGGFace2' which is a dataset used for training the Inception-ResnetV1 model. The dataset is relevant to the research topic of personalized text generation as it involves facial recognition, which can be a component of personalized systems.",
      "processing_time": 68.84119701385498,
      "citing_paper_id": "258041269",
      "cited_paper_id": 216009
    },
    {
      "context_text": "Then we extract an embedding from each detected face with an Inception-ResnetV1 [35] pre-trained on VGGFace2 [3].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "VGGFace2"
      ],
      "dataset_descriptions": {
        "VGGFace2": "Used to train the Inception-ResnetV1 model for facial recognition, focusing on recognizing faces across pose and age variations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'VGGFace2' which is a dataset used for training the Inception-ResnetV1 model. The dataset is relevant to the research topic of personalized text generation as it involves facial recognition, which can be a component of personalized systems.",
      "processing_time": 68.84119701385498,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "Then we extract an embedding from each detected face with an Inception-ResnetV1 [37] pre-trained on VGGFace2 [7].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "VGGFace2"
      ],
      "dataset_descriptions": {
        "VGGFace2": "Used to train the Inception-ResnetV1 model for recognizing faces across pose and age, focusing on improving face recognition accuracy under varying conditions."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'VGGFace2' which is a dataset used for training the Inception-ResnetV1 model. The dataset is specifically used for recognizing faces across pose and age.",
      "processing_time": 66.88451099395752,
      "citing_paper_id": "258041269",
      "cited_paper_id": 216009
    },
    {
      "context_text": "Then we extract an embedding from each detected face with an Inception-ResnetV1 [37] pre-trained on VGGFace2 [7].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "VGGFace2"
      ],
      "dataset_descriptions": {
        "VGGFace2": "Used to train the Inception-ResnetV1 model for recognizing faces across pose and age, focusing on improving face recognition accuracy under varying conditions."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'VGGFace2' which is a dataset used for training the Inception-ResnetV1 model. The dataset is specifically used for recognizing faces across pose and age.",
      "processing_time": 66.88451099395752,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "Generative Adversarial Networks [31, 41, 1, 15] are usually used for text-to-image generation in early years.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general application area (text-to-image generation). No verifiable resources are identified.",
      "processing_time": 58.51141571998596,
      "citing_paper_id": "258041269",
      "cited_paper_id": 1563370
    },
    {
      "context_text": "Generative Adversarial Networks [31, 41, 1, 15] are usually used for text-to-image generation in early years.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general application area (text-to-image generation). No verifiable resources are identified.",
      "processing_time": 58.51141571998596,
      "citing_paper_id": "258041269",
      "cited_paper_id": 245117814
    },
    {
      "context_text": "The specific list of prompts is in the Supplement.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a list of prompts in the supplement. No verifiable resources are identified.",
      "processing_time": 58.256691217422485,
      "citing_paper_id": "258041269",
      "cited_paper_id": 233323280
    },
    {
      "context_text": "More following work are proposed using transformers [10, 11] or diffusion models [18, 3, 5, 17, 19, 23, 25] to generate high-fidelity images from text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods for generating high-fidelity images from text.",
      "processing_time": 57.84131407737732,
      "citing_paper_id": "258041269",
      "cited_paper_id": 244714366
    },
    {
      "context_text": "More following work are proposed using transformers [10, 11] or diffusion models [18, 3, 5, 17, 19, 23, 25] to generate high-fidelity images from text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods for generating high-fidelity images from text.",
      "processing_time": 57.84131407737732,
      "citing_paper_id": "258041269",
      "cited_paper_id": 248239727
    },
    {
      "context_text": "Modern visual synthesis systems are usually powered by large text-to-image foundation models [2, 4, 7, 8, 10, 16, 24, 27, 28].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers. There are no clear identifiers for datasets within the text.",
      "processing_time": 14.296927213668823,
      "citing_paper_id": "258041269",
      "cited_paper_id": 247628171
    },
    {
      "context_text": "Recent advances in personalized image generation have enabled text-to-image models [2, 4, 7, 8, 10, 14, 16, 24, 27, 28, 34] to learn a new concept from a small set of images then create images of that concept in different poses, perspectives, styles, and scenes.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general advancement in personalized image generation. No verifiable resources are named.",
      "processing_time": 58.49403500556946,
      "citing_paper_id": "258041269",
      "cited_paper_id": 247628171
    },
    {
      "context_text": "We encode X into a global concept embedding c g via Concept Encoder E g and obtain",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only a method for encoding concepts into embeddings.",
      "processing_time": 57.12795686721802,
      "citing_paper_id": "258041269",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "We encode X into a global concept embedding c g via Concept Encoder E g and obtain",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, only a method for encoding concepts into embeddings.",
      "processing_time": 57.12795686721802,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257631648
    },
    {
      "context_text": "We use the official code base for Textual Inversion and ELITE, and a third-party replication [40] for DreamBooth, where the base text-to-image model is changed from Imagen [32] to Stable Diffusion [29].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the use of code bases and models, not datasets.",
      "processing_time": 59.6012487411499,
      "citing_paper_id": "258041269",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "We use the official code base for Textual Inversion and ELITE, and a third-party replication [40] for DreamBooth, where the base text-to-image model is changed from Imagen [32] to Stable Diffusion [29].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the use of code bases and models, not datasets.",
      "processing_time": 59.6012487411499,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "We use the official code base for Textual Inversion and ELITE, and a third-party replication [40] for DreamBooth, where the base text-to-image model is changed from Imagen [32] to Stable Diffusion [29].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the use of code bases and models, not datasets.",
      "processing_time": 59.6012487411499,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "We use the official code base for Textual Inversion and ELITE, and a third-party replication [40] for DreamBooth, where the base text-to-image model is changed from Imagen [32] to Stable Diffusion [29].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the use of code bases and models, not datasets.",
      "processing_time": 59.6012487411499,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "Align ↑ Face Sim ↑ Recon ↑ Time (s) ↓ TI [11] 0.2556 0.1130 0.7832 ∼ 1500 DB [30] 0.3088 0.2408 0.8335 ∼ 600 ELITE [38] 1.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only performance metrics and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 59.59752035140991,
      "citing_paper_id": "258041269",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "Align ↑ Face Sim ↑ Recon ↑ Time (s) ↓ TI [11] 0.2556 0.1130 0.7832 ∼ 1500 DB [30] 0.3088 0.2408 0.8335 ∼ 600 ELITE [38] 1.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only performance metrics and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 59.59752035140991,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "The first is test-time finetuning-based methods [5, 9, 11–13, 17, 30, 31, 36, 37].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There are no verifiable resources or datasets mentioned.",
      "processing_time": 58.860243797302246,
      "citing_paper_id": "258041269",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "The first is test-time finetuning-based methods [5, 9, 11–13, 17, 30, 31, 36, 37].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There are no verifiable resources or datasets mentioned.",
      "processing_time": 58.860243797302246,
      "citing_paper_id": "258041269",
      "cited_paper_id": 259847576
    },
    {
      "context_text": "Quality ↑ Alignment ↑ Identity ↑ TI [11] 2.89 3.04 2.97 DB [30] 3.50 3.50 3.55 ELITE [38] 3.14 3.08 3.08 Ours 3.53 3.58 3.55 Table 2.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only model performance metrics. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 59.392799854278564,
      "citing_paper_id": "258041269",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "Quality ↑ Alignment ↑ Identity ↑ TI [11] 2.89 3.04 2.97 DB [30] 3.50 3.50 3.55 ELITE [38] 3.14 3.08 3.08 Ours 3.53 3.58 3.55 Table 2.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only model performance metrics. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 59.392799854278564,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "In this section, we compare our approach with Textual Inversion (TI) [11] and DreamBooth (DB) [30], both of which require heavy test-time finetuning, as well as with ELITE [38], a zero-shot personalization method.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 59.07095408439636,
      "citing_paper_id": "258041269",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "In this section, we compare our approach with Textual Inversion (TI) [11] and DreamBooth (DB) [30], both of which require heavy test-time finetuning, as well as with ELITE [38], a zero-shot personalization method.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 59.07095408439636,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "In this section, we compare our approach with Textual Inversion (TI) [11] and DreamBooth (DB) [30], both of which require heavy test-time finetuning, as well as with ELITE [38], a zero-shot personalization method.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 59.07095408439636,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "Existing approaches [11, 17, 30] for this task can be mainly categorized into two types.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of approaches. No verifiable resources are identified.",
      "processing_time": 58.2189199924469,
      "citing_paper_id": "258041269",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "First, many existing models [5, 9, 11–13, 17, 30, 31, 36, 37] require individual finetuning for each new concept.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general statement about existing models requiring fine-tuning. No verifiable resources are identified.",
      "processing_time": 59.59327435493469,
      "citing_paper_id": "258041269",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "First, many existing models [5, 9, 11–13, 17, 30, 31, 36, 37] require individual finetuning for each new concept.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general statement about existing models requiring fine-tuning. No verifiable resources are identified.",
      "processing_time": 59.59327435493469,
      "citing_paper_id": "258041269",
      "cited_paper_id": 259847576
    },
    {
      "context_text": "More recently, approaches built upon pre-trained text-to-image models have been proposed for more controllable multi-modal image generation [20, 23, 42].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to pre-trained text-to-image models and their controllable abilities.",
      "processing_time": 58.84201693534851,
      "citing_paper_id": "258041269",
      "cited_paper_id": 256900833
    },
    {
      "context_text": "Note that, since ELITE can accept only a single image, we compare ELITE using a single image as input, whereas all other methods use multiple images as inputs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison of methods. The cited paper title does not provide additional dataset information.",
      "processing_time": 59.22283673286438,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "ELITE [38] finetunes the pretrained parameters in the attention layers and sometimes fails to generate images with diverse poses/viewpoints.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (ELITE) and its limitations in generating diverse images.",
      "processing_time": 58.821542263031006,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "Quantitative comparison in “ person ” category of TI (Textual Inversion), DB (DreamBooth), ELITE and our method.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific, verifiable datasets. It only refers to methods or models (TI, DB, ELITE) and a comparison of their performance.",
      "processing_time": 60.74338340759277,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "Quantitative comparison in “ person ” category of TI (Textual Inversion), DB (DreamBooth), ELITE and our method.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific, verifiable datasets. It only refers to methods or models (TI, DB, ELITE) and a comparison of their performance.",
      "processing_time": 60.74338340759277,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "6 showcases our method’s performance with a single input image, indicating the superiority of our methods over ELITE in a single image input penalization setting.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison with a method called ELITE. The context is about method performance, not dataset usage.",
      "processing_time": 16.606647491455078,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "DreamBooth ELITE ”open arms,” while maintaining the identity.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not provide any specific dataset names or verifiable resources. The mention of 'DreamBooth ELITE' is likely referring to a method or model, not a dataset.",
      "processing_time": 61.02085089683533,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "DreamBooth ELITE ”open arms,” while maintaining the identity.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not provide any specific dataset names or verifiable resources. The mention of 'DreamBooth ELITE' is likely referring to a method or model, not a dataset.",
      "processing_time": 61.02085089683533,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "ELITE cannot maintain the identity, but note it is not a completely fair comparison since ELITE is trained on OpenIm-ages [18] of general categories, while ours are trained on specific categories.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "OpenImages"
      ],
      "dataset_descriptions": {
        "OpenImages": "Used to train ELITE on general categories, contrasting with the specific categories used in the current research, to highlight differences in performance and applicability."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'OpenImages' as a dataset used for training ELITE, which is relevant to the topic of personalized text generation.",
      "processing_time": 65.16337442398071,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "To allow the pretrained text-to-image generator to adapt visual input, ELITE [39] finetunes the pretrained parameters in the attention layers and UMM-Diffusion [24] only learns a visual mapping layer but freeze the weight of the pretrained generator.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the adaptation of pretrained models for text-to-image generation.",
      "processing_time": 59.98304033279419,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "We also recognize several concurrent works [39, 24, 9].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only acknowledges concurrent works.",
      "processing_time": 58.206433057785034,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "The second is encoder-based methods [6, 15, 19, 22, 38, 39, 41], which learn image embeddings from the input images as the representation of the concept.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.96948528289795,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257913352
    },
    {
      "context_text": "The second is encoder-based methods [6, 15, 19, 22, 38, 39, 41], which learn image embeddings from the input images as the representation of the concept.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 59.96948528289795,
      "citing_paper_id": "258041269",
      "cited_paper_id": 264815845
    },
    {
      "context_text": "SuTI [6] learns the concept from a massive amount of paired images generated by subject-driven expert models.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to 'paired images' but does not provide a name or identifier for a dataset.",
      "processing_time": 60.573155879974365,
      "citing_paper_id": "258041269",
      "cited_paper_id": 257913352
    },
    {
      "context_text": "2 outlines the inference pipeline of our method for generating images from image set X = { x i } Ni =1 ( N can be 1 or larger) and text prompt P .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes a general method for generating images from an image set and a text prompt.",
      "processing_time": 60.44496989250183,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "DreamBooth can generate high-quality images; however, when the input person subject occupies a small portion (e.g., row 2 and 4 of Fig.4), it tends to generated the person within a small portion of the image, thus limiting the identity preservation ability.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a limitation of the DreamBooth model. No verifiable resources are identified.",
      "processing_time": 59.77131414413452,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "All the comparison methods tend to replicate the pose of the foreground person, and Textual Inversion and DreamBooth also replicate the background.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and their outcomes. There are no verifiable resources or datasets mentioned.",
      "processing_time": 59.95545291900635,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "We adopt the official code base for Textual Inversion and third-party replication[40] for DreamBooth where the base text-to-image model is replaced from Imagen [35] to Stable Diffusion [33].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 60.103193521499634,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "For all experiments of our model, we use “sks” as the unique identifier V̂ as suggested in DreamBooth [40].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a unique identifier used in experiments. No verifiable resources are referenced.",
      "processing_time": 59.76100420951843,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "Moreover, even when the input image contains a large portion of the person object (e.g., row 5 of Fig.4), DreamBooth often only preserves the person’s outfit but distorts the face identity.",
      "catation_intent": "limitation",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It describes a limitation of DreamBooth in preserving face identity.",
      "processing_time": 60.552369594573975,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "We conduct a user study to compare our method with DreamBooth and Textual Inversion perceptually.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (DreamBooth and Textual Inversion).",
      "processing_time": 60.10306930541992,
      "citing_paper_id": "258041269",
      "cited_paper_id": null
    },
    {
      "context_text": "Image Quality: We evaluated Fréchet Inception Distance (FID) [47] and Kernel Inception Distance (KID) [48].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions FID and KID, which are metrics, not datasets. No datasets are explicitly mentioned or used according to the provided context.",
      "processing_time": 60.968671560287476,
      "citing_paper_id": "269736331",
      "cited_paper_id": 326772
    },
    {
      "context_text": "Image Quality: We evaluated Fréchet Inception Distance (FID) [47] and Kernel Inception Distance (KID) [48].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions FID and KID, which are metrics, not datasets. No datasets are explicitly mentioned or used according to the provided context.",
      "processing_time": 60.968671560287476,
      "citing_paper_id": "269736331",
      "cited_paper_id": 3531856
    },
    {
      "context_text": "Generative Adversarial Networks (GANs) [14], [15], [16] are commonly employed for text-to-image generation in the early stages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only generative models and their application. No verifiable resources are identified.",
      "processing_time": 16.241543769836426,
      "citing_paper_id": "269736331",
      "cited_paper_id": 1563370
    },
    {
      "context_text": "Generative Adversarial Networks (GANs) [14], [15], [16] are commonly employed for text-to-image generation in the early stages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only generative models and their application. No verifiable resources are identified.",
      "processing_time": 16.241543769836426,
      "citing_paper_id": "269736331",
      "cited_paper_id": 245117814
    },
    {
      "context_text": "Generative Adversarial Networks (GANs) [14], [15], [16] are commonly employed for text-to-image generation in the early stages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only generative models and their application. No verifiable resources are identified.",
      "processing_time": 16.241543769836426,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "(cid:2) We present a style-guided module for the diffusion model, which extracts style features from given images by VGG [13] and the Gram algorithm.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (VGG) and an algorithm (Gram).",
      "processing_time": 60.80801320075989,
      "citing_paper_id": "269736331",
      "cited_paper_id": 14124313
    },
    {
      "context_text": "The formula for calculating FID is given by: where N ( μ, Σ) is the multivariate normal distribution estimated from Inception v3 [49] features of the real images, and N ( μ g , Σ g ) is the multivariate normal distribution estimated from Inception v3 features of the generated images.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the Inception v3 model which is a method, not a dataset.",
      "processing_time": 61.126306772232056,
      "citing_paper_id": "269736331",
      "cited_paper_id": 206592484
    },
    {
      "context_text": "Personalization models are commonly used in ﬁelds such as recommendation systems [35], [36] or federated learning [37], [38], [39].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general fields where personalization models are used. No verifiable resources are identified.",
      "processing_time": 61.80603742599487,
      "citing_paper_id": "269736331",
      "cited_paper_id": 211296702
    },
    {
      "context_text": "Personalization models are commonly used in ﬁelds such as recommendation systems [35], [36] or federated learning [37], [38], [39].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general fields where personalization models are used. No verifiable resources are identified.",
      "processing_time": 61.80603742599487,
      "citing_paper_id": "269736331",
      "cited_paper_id": 232147378
    },
    {
      "context_text": "Personalization models are commonly used in ﬁelds such as recommendation systems [35], [36] or federated learning [37], [38], [39].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general fields where personalization models are used. No verifiable resources are identified.",
      "processing_time": 61.80603742599487,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "Personalization models are commonly used in ﬁelds such as recommendation systems [35], [36] or federated learning [37], [38], [39].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general fields where personalization models are used. No verifiable resources are identified.",
      "processing_time": 61.80603742599487,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "Further research has proposed using trans-formers [17], [18] or diffusion models [19], [20], [21], [22], [23], [24], [25] to generate high-ﬁdelity images from text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers also do not provide clear dataset names within the context.",
      "processing_time": 62.36335062980652,
      "citing_paper_id": "269736331",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "Further research has proposed using trans-formers [17], [18] or diffusion models [19], [20], [21], [22], [23], [24], [25] to generate high-ﬁdelity images from text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers also do not provide clear dataset names within the context.",
      "processing_time": 62.36335062980652,
      "citing_paper_id": "269736331",
      "cited_paper_id": 244714366
    },
    {
      "context_text": "Further research has proposed using trans-formers [17], [18] or diffusion models [19], [20], [21], [22], [23], [24], [25] to generate high-ﬁdelity images from text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers also do not provide clear dataset names within the context.",
      "processing_time": 62.36335062980652,
      "citing_paper_id": "269736331",
      "cited_paper_id": 245117331
    },
    {
      "context_text": "Further research has proposed using trans-formers [17], [18] or diffusion models [19], [20], [21], [22], [23], [24], [25] to generate high-ﬁdelity images from text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers also do not provide clear dataset names within the context.",
      "processing_time": 62.36335062980652,
      "citing_paper_id": "269736331",
      "cited_paper_id": 245335086
    },
    {
      "context_text": "Further research has proposed using trans-formers [17], [18] or diffusion models [19], [20], [21], [22], [23], [24], [25] to generate high-ﬁdelity images from text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers also do not provide clear dataset names within the context.",
      "processing_time": 62.36335062980652,
      "citing_paper_id": "269736331",
      "cited_paper_id": 248239727
    },
    {
      "context_text": "Unlike traditional denoising probability diffusion models [19], SD compresses images into a latent space using a pre-trained autoencoder and trains the model in this latent space.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (denoising probability diffusion models).",
      "processing_time": 61.80670619010925,
      "citing_paper_id": "269736331",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "Text-image Consistency: We use CLIP similarity (CLIPSIM [50]) to evaluate the textual-image consistency between the generated images and their corresponding text prompts.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions CLIP similarity (CLIPSIM) but does not refer to a specific dataset. CLIPSIM is a method or metric, not a dataset.",
      "processing_time": 63.35662007331848,
      "citing_paper_id": "269736331",
      "cited_paper_id": 233476314
    },
    {
      "context_text": "Models like DALL-E2 [28], Imagen [2] and Stable Diffusion [1] are trained on large-scale text-image pairs, showing the robust capabilities of diffusion models in generating complex scenes and semantics. eDiff-I [29] employs a multi-stage approach to image generation, with each stage us-ing…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their capabilities. There are no clear identifiers for datasets in the text.",
      "processing_time": 62.94056415557861,
      "citing_paper_id": "269736331",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "Models like DALL-E2 [28], Imagen [2] and Stable Diffusion [1] are trained on large-scale text-image pairs, showing the robust capabilities of diffusion models in generating complex scenes and semantics. eDiff-I [29] employs a multi-stage approach to image generation, with each stage us-ing…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their capabilities. There are no clear identifiers for datasets in the text.",
      "processing_time": 62.94056415557861,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "Additionally, Parti [27] has shown that further improving visual quality is possible by increasing model size and training data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation does not mention any specific dataset names, only a general reference to 'training data'. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 65.08408236503601,
      "citing_paper_id": "269736331",
      "cited_paper_id": 249926846
    },
    {
      "context_text": "The objective of personalized text-to-image generation [3], [4], [5], [6] is to learn a concept from a set of images, such as a speciﬁc object or the overall style of the images, and then incorporate this concept into the generated image based on input prompts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the general concept of personalized text-to-image generation. No verifiable resources are identified.",
      "processing_time": 63.5222327709198,
      "citing_paper_id": "269736331",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "Textual-Inversion [4] reverses input images into text embeddings and labels them with textual identiﬁers during ﬁnetuning Stable Diffusion (SD) [1].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on describing a technique rather than a dataset.",
      "processing_time": 63.51927161216736,
      "citing_paper_id": "269736331",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "Textual-Inversion [4] reverses input images into text embeddings and labels them with textual identiﬁers during ﬁnetuning Stable Diffusion (SD) [1].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on describing a technique rather than a dataset.",
      "processing_time": 63.51927161216736,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "Textual-Inversion [4] uses textual identiﬁers to label text embeddings obtained by inverting images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method (Textual-Inversion) and its application, but no dataset names are provided.",
      "processing_time": 64.59724354743958,
      "citing_paper_id": "269736331",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "This generation approach has numerous applications, including animation, game development [7], personalized ad creation, and image restoration [8], and has garnered signiﬁcant attention from both academic and industrial communities.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of text generation. There are no verifiable resources or specific datasets mentioned.",
      "processing_time": 63.867799520492554,
      "citing_paper_id": "269736331",
      "cited_paper_id": 253734226
    },
    {
      "context_text": "Muse [30], a Transformer-based text-to-image model, generates images by predicting randomly masked image labels and has been proven to be more efﬁcient and effective than diffusion models and autoregressive models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions Muse, which is a Transformer-based text-to-image model, not a dataset. No datasets are explicitly mentioned or used in the given citation.",
      "processing_time": 64.73760914802551,
      "citing_paper_id": "269736331",
      "cited_paper_id": 255372955
    },
    {
      "context_text": "The text-to-image generation of SGDM is based on LDM [1], more known as Stable Diffusion (SD).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models or methods. There are no verifiable resources that meet the criteria.",
      "processing_time": 64.01414656639099,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "In this part, we compare SGDM with Stable Diffusion [1], recent state-of-the-art conditional diffusion models (i.e., Con-trolNet [10] and T2I-Adapter [44]) and diffusion-based method InST [41].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 64.58408236503601,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "These models [1], [2] can produce high-quality and diverse images based on natural language prompts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models capable of producing images from natural language prompts.",
      "processing_time": 13.92242431640625,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "ControlStyle[43]viaupgrading apre-trainedtext-to-imagemodelwithatrainablemodulation network,diffusionstyleandcontentregularizationstopursue high-quality stylized text-to-image generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for upgrading a pre-trained text-to-image model.",
      "processing_time": 62.55135679244995,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "P2-GAN P2-GAN [34], a novel Patch Permutation GAN network that uses patch permutation to generate multiple training samples, and uses a novel patch discriminator to process the patch-wise images and the natural images simultaneously and that can be efﬁciently trained by a single style image for the…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (P2-GAN). There are no verifiable resources or datasets mentioned.",
      "processing_time": 29.69039535522461,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "We constructed the dataset based on a subset of the Pinterest [45] image dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Pinterest image dataset"
      ],
      "dataset_descriptions": {
        "Pinterest image dataset": "Used as a source to construct a subset for personalized text generation, focusing on image-based content and user interactions."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'Pinterest image dataset' as a source for constructing their dataset, which is a specific, identifiable resource.",
      "processing_time": 21.850637674331665,
      "citing_paper_id": "269736331",
      "cited_paper_id": null
    },
    {
      "context_text": "Many traditional persuasive systems have been employed in various fields such as law [20], car sales [21], and smart education [22].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of persuasive systems. There are no verifiable resources or specific datasets mentioned.",
      "processing_time": 15.8046875,
      "citing_paper_id": "269191092",
      "cited_paper_id": 101534
    },
    {
      "context_text": "As part of recent research, a text generator system has been designed for commodity trading that emphasizes negotiation rather than persuasion [3, 4].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a text generator system for negotiation dialogues. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 15.80116581916809,
      "citing_paper_id": "269191092",
      "cited_paper_id": 2454882
    },
    {
      "context_text": "During the last few years, personal chat systems have gained popularity due to their ability to interact with users more effectively [18].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general trend in personal chat systems. No verifiable resources are identified.",
      "processing_time": 28.511285543441772,
      "citing_paper_id": "269191092",
      "cited_paper_id": 21357771
    },
    {
      "context_text": "In the first part of this questionnaire, there are 44 questions to determine the score of each personality trait that is mentioned in [23, 25], and the second part consists of ten three-part categories, each category contains a text with a logical strategy, a text with an emotional strategy, and a…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a questionnaire structure. No clear identifiers for datasets are present.",
      "processing_time": 14.126874923706055,
      "citing_paper_id": "269191092",
      "cited_paper_id": 53558598
    },
    {
      "context_text": "This research has focused a significant amount of time and effort on developing these technologies for a variety of applications, including advertising, promoting healthy behavior [24, 25], quitting destructive behaviors and reducing energy consumption [26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of technology. No verifiable resources are identified.",
      "processing_time": 27.602878093719482,
      "citing_paper_id": "269191092",
      "cited_paper_id": 53558598
    },
    {
      "context_text": "They had different ways of how persuasion strategies are grouped; Cialdini [10] proposes six principles, while Fog [11] describes 40 strategies in a more general sense.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only different categorizations of persuasion strategies by Cialdini and Fog.",
      "processing_time": 27.212472200393677,
      "citing_paper_id": "269191092",
      "cited_paper_id": 141803939
    },
    {
      "context_text": "This score is computed based on the 44 questions in [29] and the scoring instructions given therein.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not mention any specific dataset, only a reference to scoring instructions. The context is too vague to identify a verifiable dataset.",
      "processing_time": 17.54413104057312,
      "citing_paper_id": "269191092",
      "cited_paper_id": 149560834
    },
    {
      "context_text": "In general, different individuals hold different views on a subject based on their personal experiences or epistemic beliefs [13, 14].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts about individual views and beliefs.",
      "processing_time": 14.101619005203247,
      "citing_paper_id": "269191092",
      "cited_paper_id": 198854435
    },
    {
      "context_text": "As a result, several studies in natural language processing identify and classify persuasion through automated methods and hierarchical neural networks [1, 8, 15, 16]; or in [17] the authors identify persuasion in online discussions or news articles.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general methods and approaches to identifying persuasion in online discussions or news articles.",
      "processing_time": 29.659215450286865,
      "citing_paper_id": "269191092",
      "cited_paper_id": 222177356
    },
    {
      "context_text": "This system that presented in [5] proposes a category-based text generation system that uses the SentiGAN framework [6] to train multiple generators simultaneously on six negotiation principles. but in this framework, as the number of categories increases, the parameters needed for training may…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It focuses on the SentiGAN framework and the concept of category-based text generation, but does not reference any particular dataset.",
      "processing_time": 20.04983615875244,
      "citing_paper_id": "269191092",
      "cited_paper_id": 235700375
    },
    {
      "context_text": "Also, it hasn't been used in [5] personalization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to personalization. There are no specific, verifiable resources mentioned.",
      "processing_time": 14.105155229568481,
      "citing_paper_id": "269191092",
      "cited_paper_id": 235700375
    },
    {
      "context_text": "Early attempts, which often centered on particular architectures or tasks, were largely characterized by manually-curated data collection, fine-tuning, or retraining from scratch [10,19,33,47].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. There are no clear identifiers for datasets.",
      "processing_time": 17.177987813949585,
      "citing_paper_id": "268732776",
      "cited_paper_id": 12803511
    },
    {
      "context_text": "Manual prompt engineering is one of the most popular approaches to eliciting desired behaviors from large pre-trained models because it uses little or no data and does not require fine-tuning [2, 22].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach to using pre-trained models.",
      "processing_time": 12.861969470977783,
      "citing_paper_id": "268732776",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "Several methods tackle conditional image generation in a training-free manner by using pretrained diffusion models as priors for the data distribution [5, 9, 18, 31, 32], and analogous approaches exist for T2I diffusion models (e.g., StableDiffusion) [8,25,43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses methods and models for conditional image generation and T2I diffusion models but does not mention any specific datasets. The cited papers also do not provide clear dataset names.",
      "processing_time": 17.52310800552368,
      "citing_paper_id": "268732776",
      "cited_paper_id": 227209335
    },
    {
      "context_text": "Several methods tackle conditional image generation in a training-free manner by using pretrained diffusion models as priors for the data distribution [5, 9, 18, 31, 32], and analogous approaches exist for T2I diffusion models (e.g., StableDiffusion) [8,25,43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses methods and models for conditional image generation and T2I diffusion models but does not mention any specific datasets. The cited papers also do not provide clear dataset names.",
      "processing_time": 17.52310800552368,
      "citing_paper_id": "268732776",
      "cited_paper_id": 245704504
    },
    {
      "context_text": "Several methods tackle conditional image generation in a training-free manner by using pretrained diffusion models as priors for the data distribution [5, 9, 18, 31, 32], and analogous approaches exist for T2I diffusion models (e.g., StableDiffusion) [8,25,43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses methods and models for conditional image generation and T2I diffusion models but does not mention any specific datasets. The cited papers also do not provide clear dataset names.",
      "processing_time": 17.52310800552368,
      "citing_paper_id": "268732776",
      "cited_paper_id": 252596252
    },
    {
      "context_text": "Several methods tackle conditional image generation in a training-free manner by using pretrained diffusion models as priors for the data distribution [5, 9, 18, 31, 32], and analogous approaches exist for T2I diffusion models (e.g., StableDiffusion) [8,25,43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses methods and models for conditional image generation and T2I diffusion models but does not mention any specific datasets. The cited papers also do not provide clear dataset names.",
      "processing_time": 17.52310800552368,
      "citing_paper_id": "268732776",
      "cited_paper_id": 257622962
    },
    {
      "context_text": "Several methods tackle conditional image generation in a training-free manner by using pretrained diffusion models as priors for the data distribution [5, 9, 18, 31, 32], and analogous approaches exist for T2I diffusion models (e.g., StableDiffusion) [8,25,43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses methods and models for conditional image generation and T2I diffusion models but does not mention any specific datasets. The cited papers also do not provide clear dataset names.",
      "processing_time": 17.52310800552368,
      "citing_paper_id": "268732776",
      "cited_paper_id": 259298715
    },
    {
      "context_text": "Several methods tackle conditional image generation in a training-free manner by using pretrained diffusion models as priors for the data distribution [5, 9, 18, 31, 32], and analogous approaches exist for T2I diffusion models (e.g., StableDiffusion) [8,25,43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses methods and models for conditional image generation and T2I diffusion models but does not mention any specific datasets. The cited papers also do not provide clear dataset names.",
      "processing_time": 17.52310800552368,
      "citing_paper_id": "268732776",
      "cited_paper_id": 259316242
    },
    {
      "context_text": "Today, perhaps the most popular approach for controllable generation is to guide the generation process with a piece of textual information, or prompt, that describes the properties of the desired output using text-to-image (T2I) generative models [24, 42].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach using text-to-image generative models. No verifiable resources are identified.",
      "processing_time": 15.48209524154663,
      "citing_paper_id": "268732776",
      "cited_paper_id": 249926846
    },
    {
      "context_text": "To create diverse scenes, we follow [8] and use descriptive prompts from PartiPrompts [42] as prefixes to the output prompts similar to the previous setting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PartiPrompts"
      ],
      "dataset_descriptions": {
        "PartiPrompts": "Used to generate diverse scenes by providing descriptive prompts as prefixes to output prompts, enhancing content-rich text-to-image generation."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'PartiPrompts' as a source of descriptive prompts, which appears to be a specific resource used for generating content-rich text-to-image outputs.",
      "processing_time": 23.298516988754272,
      "citing_paper_id": "268732776",
      "cited_paper_id": 249926846
    },
    {
      "context_text": "Your rating should strictly follow this format: \"Rating: [[rating]]\", the rating in the double-closed brackets is a number from 0 to 10, e,g, \"Rating: [[5]]\".",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to ratings which is too generic.",
      "processing_time": 12.85015344619751,
      "citing_paper_id": "268732776",
      "cited_paper_id": 252596252
    },
    {
      "context_text": "…mentioning any of the irrelevant elements such as the subjects, the objects in the image, the themes and other contents unrelated to the sytle, 5) if you achieve high score, you can copy the prompt you generated the previous iteration and append the changes you want to make, 6) look carefully…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets or resources. It describes a process or instructions for generating prompts, which is not a dataset.",
      "processing_time": 28.19008231163025,
      "citing_paper_id": "268732776",
      "cited_paper_id": 252596252
    },
    {
      "context_text": "…of the object, 4) if you achieve high score, you can copy the prompt you generated the previous iteration and append the changes you want to make, 5) look carefully at the difference between the object genereated in the output image and the object in the input reference image and try to avoid…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, models, or methods. It describes a process or instructions for generating and refining prompts, which is not sufficient to identify a verifiable resource.",
      "processing_time": 19.673803567886353,
      "citing_paper_id": "268732776",
      "cited_paper_id": 252596252
    },
    {
      "context_text": "…in this spirit tend to require pre-collected, architecture-specific keywords 1 or white-box, embedding-based optimiza-1 tion [6,16], leading to non-interpretable prompts [39] and precluding the possibility of directly generating prompts for closed-source T2I models (e.g., Midjourney or DALL-E).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the challenges of using pre-collected keywords and optimization techniques for prompt tuning.",
      "processing_time": 31.816269874572754,
      "citing_paper_id": "268732776",
      "cited_paper_id": 256627601
    },
    {
      "context_text": "Through text, T2I models allow users to quickly and easily describe a wide variety of concepts, and model designers can more efficiently explore the behavior of their model through a myriad of strategies [3,39].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses the capabilities of T2I models in general terms.",
      "processing_time": 16.842545747756958,
      "citing_paper_id": "268732776",
      "cited_paper_id": 256627601
    },
    {
      "context_text": "Through text, T2I models allow users to quickly and easily describe a wide variety of concepts, and model designers can more efficiently explore the behavior of their model through a myriad of strategies [3,39].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses the capabilities of T2I models in general terms.",
      "processing_time": 16.842545747756958,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263908890
    },
    {
      "context_text": "Baselines We choose Textual Inversion (TI) [6], BLIP-2 (BLIP2) [12], CLIP-Interrogator (CLIP-Int) and PEZ [39] as the baselines.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods used as baselines.",
      "processing_time": 25.95919632911682,
      "citing_paper_id": "268732776",
      "cited_paper_id": 256627601
    },
    {
      "context_text": "The key difference between PRISM and prior methods is that PRISM updates the entire sampling distribution of prompts, whereas prior works [6, 16,39] directly update the tokens of a single prompt or the embedding of the prompt.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on comparing PRISM with other methods in terms of updating prompts and embeddings.",
      "processing_time": 18.59259843826294,
      "citing_paper_id": "268732776",
      "cited_paper_id": 256627601
    },
    {
      "context_text": "Experimentally, our results indicate that PRISM consistently out-performs existing methods, including Textual Inversion [6], PEZ [39], BLIP2 [12] and CLIP-Interrogator 1 , with respect to human-interpretability while maintaining high visual accuracy.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing performance against existing methods.",
      "processing_time": 27.55931067466736,
      "citing_paper_id": "268732776",
      "cited_paper_id": 256627601
    },
    {
      "context_text": "One potential direction is to combine gradient-based search methods like PEZ [39] with PRISM to create model-specific prompts similar to CLIP-Interrogator.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and tools. The context focuses on combining gradient-based search methods with PRISM for creating model-specific prompts.",
      "processing_time": 18.826878786087036,
      "citing_paper_id": "268732776",
      "cited_paper_id": 256627601
    },
    {
      "context_text": "Prompt tuning methods such as Textual Inversion [6], PEZ [39], and PH2P [16,39] are in the same spirit as this paper, as they do not require fine-tuning or optimizing the underlying model and generate images that inherit the properties of a given reference image.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on prompt tuning methods and their application in generating images.",
      "processing_time": 29.024824619293213,
      "citing_paper_id": "268732776",
      "cited_paper_id": 256627601
    },
    {
      "context_text": "…object, 3) avoid mentioning any of the irrelevant elements such as the background, environment, lighting, camera angle and the pose of the object, 4) if you achieve high score, you can copy the prompt you generated the previous iteration and append the changes you want to make, 5) look carefully…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets or resources. It only describes guidelines for generating text-to-image prompts.",
      "processing_time": 16.402394771575928,
      "citing_paper_id": "268732776",
      "cited_paper_id": 257913352
    },
    {
      "context_text": "…the artists can help a lot, 3) if you can identify the name of the genre and the time era of this art style, mentioning those will help a lot too, 4) avoid mentioning any of the irrelevant elements such as the subjects, the objects in the image, the themes and other contents unrelated to the…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It provides guidelines for describing art styles, which are not datasets.",
      "processing_time": 28.434083938598633,
      "citing_paper_id": "268732776",
      "cited_paper_id": 257913352
    },
    {
      "context_text": "Another class of approaches such as ControlNet [44], IP-Adapter [41], Dreambooth [26], SuTI [4] and InstantBooth [29] also improve the control-lability of pretrained T2I models, but they require expensive fine-tuning or re-training of the underlying model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the methodologies used to improve the controllability of pretrained text-to-image models.",
      "processing_time": 19.65276002883911,
      "citing_paper_id": "268732776",
      "cited_paper_id": 257913352
    },
    {
      "context_text": "While personalized T2I methods often involve fine-tuning or retraining the underlying T2I model [4,26,29], several approaches focus specifically on automating prompt engineering to generate effective prompts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general approaches to personalized T2I methods.",
      "processing_time": 15.163519144058228,
      "citing_paper_id": "268732776",
      "cited_paper_id": 257913352
    },
    {
      "context_text": "Following [26], we also use DINO V2 [21] embedding similarity to calculate the object-sensitive image similarity for the personalized T2I generation task.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DINO V2 but does not refer to it as a dataset. It is used as a method for calculating object-sensitive image similarity in personalized text-to-image generation.",
      "processing_time": 31.60391640663147,
      "citing_paper_id": "268732776",
      "cited_paper_id": 258170077
    },
    {
      "context_text": "A simple so-lution is to use pre-trained discriminative models such as CLIP [22] and DINO [21], and measure the distance of images in their embedding spaces.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only pre-trained models (CLIP and DINO). These models are used to measure the distance of images in their embedding spaces, which is a methodological approach rather than a dataset.",
      "processing_time": 19.83280348777771,
      "citing_paper_id": "268732776",
      "cited_paper_id": 258170077
    },
    {
      "context_text": "In Figure 13, 14, 15, 16 and 17, we provide additional qualitative showcases for subject-driven personalized T2I generation, style-driven personalized T2I generation, direct image inversion and prompt editing.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only qualitative showcases for various types of personalized text-to-image generation. No verifiable resources are identified.",
      "processing_time": 14.79986047744751,
      "citing_paper_id": "268732776",
      "cited_paper_id": 259252065
    },
    {
      "context_text": "In Figure 13, 14, 15, 16 and 17, we provide additional qualitative showcases for subject-driven personalized T2I generation, style-driven personalized T2I generation, direct image inversion and prompt editing.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only qualitative showcases for various types of personalized text-to-image generation. No verifiable resources are identified.",
      "processing_time": 14.79986047744751,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263831566
    },
    {
      "context_text": "To address this issue, several methods have been proposed to construct the prompts in an automated manner [7, 17, 30, 40, 45, 46].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods for constructing prompts. There are no verifiable resources or datasets mentioned.",
      "processing_time": 15.1272873878479,
      "citing_paper_id": "268732776",
      "cited_paper_id": 259252065
    },
    {
      "context_text": "In particular, the field of LLM jailbreaking is concerned with automatically designing prompts that can elicit specific content (which is often objectionable or illicit) from a targeted LLM [14,23,37,48].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the concept of jailbreaking LLMs. No verifiable resources are identified.",
      "processing_time": 15.123501539230347,
      "citing_paper_id": "268732776",
      "cited_paper_id": 260202961
    },
    {
      "context_text": "In particular, the field of LLM jailbreaking is concerned with automatically designing prompts that can elicit specific content (which is often objectionable or illicit) from a targeted LLM [14,23,37,48].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the concept of jailbreaking LLMs. No verifiable resources are identified.",
      "processing_time": 15.123501539230347,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263671542
    },
    {
      "context_text": "In particular, the field of LLM jailbreaking is concerned with automatically designing prompts that can elicit specific content (which is often objectionable or illicit) from a targeted LLM [14,23,37,48].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the concept of jailbreaking LLMs. No verifiable resources are identified.",
      "processing_time": 15.123501539230347,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263831566
    },
    {
      "context_text": "However, just as LLMs are suceptible to being jailbro-ken or adversarially manipulated by malicious actors [48], our method may also be vulnerable to malicious intent, potential bias, or limitations in the base models.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only potential vulnerabilities and biases in language models.",
      "processing_time": 13.22399616241455,
      "citing_paper_id": "268732776",
      "cited_paper_id": 260202961
    },
    {
      "context_text": "If there is a tie, then we return the prompt with the highest log likelihood [1].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to a generic concept of log likelihood.",
      "processing_time": 14.787986516952515,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263830433
    },
    {
      "context_text": "Similar to the findings of [3], we find that performance can degrade if the refinement is repeated too many times (i.e., K is too large), and in general, we do not recommend practitioners with small budgets to go beyond K = 5 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general finding about the performance degradation with excessive refinement steps.",
      "processing_time": 14.496278524398804,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263908890
    },
    {
      "context_text": "A particularly relevant work is [3], which uses an auxiliary LLM to iteratively construct jailbreak prompts that elicit harmful behaviors from a targeted LLM.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of an auxiliary LLM to construct jailbreak prompts. No verifiable datasets are referenced.",
      "processing_time": 17.070226907730103,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263908890
    },
    {
      "context_text": "Unlike jailbreaking [3], we observe that the optimal N and K can vary depending on the task: if the target concept is simple (e.g. a commonly seen dog), then small N and K are generally sufficient, and prioritizing N tends to be more helpful.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It discusses the variability of N and K in the context of a target concept, which is not a verifiable resource.",
      "processing_time": 19.616852521896362,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263908890
    },
    {
      "context_text": ", then 2) if you can identify the artists associated with this style, mentioning the name of the artists can help a lot, 3) if you can identify the name of the genre and the time era of this art style, mentioning those will help a lot too, 4) avoid mentioning any of the irrelevant elements such as…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific, verifiable datasets or resources. It appears to be instructions for a task rather than a citation of a dataset.",
      "processing_time": 17.866692543029785,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263908890
    },
    {
      "context_text": "To design the system prompts for the prompt engineer assistant F , we follow [3] and include the following components in the system prompt of F .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only components of a system prompt. There is no indication of a reusable dataset.",
      "processing_time": 16.354595184326172,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263908890
    },
    {
      "context_text": "Inspired by jailbreaking attacks on large language models (LLMs) [3], we design an algorithm that operates with only limited human input, is capable of generating human interpretable and editable prompts, makes minimal assumptions about the underlying T2I generative model, and generalizes across…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an algorithm and its capabilities. The context is about designing an algorithm inspired by jailbreaking attacks on LLMs.",
      "processing_time": 19.263598918914795,
      "citing_paper_id": "268732776",
      "cited_paper_id": 263908890
    },
    {
      "context_text": "Implementation Details For all of our experiments, we choose GPT-4V [20] as both the prompt engineer assistant model F and the judge D .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (GPT-4V). No datasets are referenced for training or evaluation.",
      "processing_time": 17.859477043151855,
      "citing_paper_id": "268732776",
      "cited_paper_id": null
    },
    {
      "context_text": "We also fix the T2I generator as SDXL-Turbo [27] for all of our experiments.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a model (SDXL-Turbo). No dataset names are present in the context.",
      "processing_time": 17.85394811630249,
      "citing_paper_id": "268732776",
      "cited_paper_id": null
    },
    {
      "context_text": "Video question answering [10, 11, 35] asks machines to answer the question based on the video content.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of video question answering. No verifiable resources are identified.",
      "processing_time": 15.072123765945435,
      "citing_paper_id": "269671831",
      "cited_paper_id": 3864050
    },
    {
      "context_text": "Video question answering [10, 11, 35] asks machines to answer the question based on the video content.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the task of video question answering. No verifiable resources are identified.",
      "processing_time": 15.072123765945435,
      "citing_paper_id": "269671831",
      "cited_paper_id": 104292176
    },
    {
      "context_text": "Standard video to text generation tasks include video captioning [13, 18, 38], video question answering [10, 11, 35], and video comment generation [9, 21, 22, 31, 33].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks in video-to-text generation. No dataset names are provided in the context.",
      "processing_time": 18.514893054962158,
      "citing_paper_id": "269671831",
      "cited_paper_id": 3864050
    },
    {
      "context_text": "Standard video to text generation tasks include video captioning [13, 18, 38], video question answering [10, 11, 35], and video comment generation [9, 21, 22, 31, 33].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks in video-to-text generation. No dataset names are provided in the context.",
      "processing_time": 18.514893054962158,
      "citing_paper_id": "269671831",
      "cited_paper_id": 92996193
    },
    {
      "context_text": "Standard video to text generation tasks include video captioning [13, 18, 38], video question answering [10, 11, 35], and video comment generation [9, 21, 22, 31, 33].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks in video-to-text generation. No dataset names are provided in the context.",
      "processing_time": 18.514893054962158,
      "citing_paper_id": "269671831",
      "cited_paper_id": 104292176
    },
    {
      "context_text": "Standard video to text generation tasks include video captioning [13, 18, 38], video question answering [10, 11, 35], and video comment generation [9, 21, 22, 31, 33].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks in video-to-text generation. No dataset names are provided in the context.",
      "processing_time": 18.514893054962158,
      "citing_paper_id": "269671831",
      "cited_paper_id": 211066479
    },
    {
      "context_text": "Standard video to text generation tasks include video captioning [13, 18, 38], video question answering [10, 11, 35], and video comment generation [9, 21, 22, 31, 33].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general tasks in video-to-text generation. No dataset names are provided in the context.",
      "processing_time": 18.514893054962158,
      "citing_paper_id": "269671831",
      "cited_paper_id": 235097581
    },
    {
      "context_text": "Feature-based explanation using content-based recommendation methods to provide explanation [12, 39].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for explainable recommendation.",
      "processing_time": 14.487788200378418,
      "citing_paper_id": "269671831",
      "cited_paper_id": 4844572
    },
    {
      "context_text": "For reference-based metrics, we use BLEU [23], Meteor [6], CIDEr [29], and ROUGE [17].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several metrics but does not refer to any specific datasets. Metrics are excluded according to the instructions.",
      "processing_time": 16.04174256324768,
      "citing_paper_id": "269671831",
      "cited_paper_id": 9026666
    },
    {
      "context_text": "For reference-based metrics, we use BLEU [23], Meteor [6], CIDEr [29], and ROUGE [17] to evaluate the quality of generated text.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several metrics but does not refer to any specific datasets. Metrics are excluded according to the instructions.",
      "processing_time": 16.372604370117188,
      "citing_paper_id": "269671831",
      "cited_paper_id": 9026666
    },
    {
      "context_text": "Besides, as users’ reviews and social media posts contains their opinion, some works show that such information is quite beneficial in user preference modeling and recommendation [19, 27, 30].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the use of reviews and social media posts for user preference modeling and recommendation, but does not specify any named datasets.",
      "processing_time": 25.992931842803955,
      "citing_paper_id": "269671831",
      "cited_paper_id": 47019137
    },
    {
      "context_text": "They utilize item images or social information to generate explanation sentences [2, 20, 25].",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to the use of item images or social information, which are generic data types.",
      "processing_time": 27.830681324005127,
      "citing_paper_id": "269671831",
      "cited_paper_id": 52902832
    },
    {
      "context_text": "They utilize item images or social information to generate explanation sentences [2, 20, 25].",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to the use of item images or social information, which are generic data types.",
      "processing_time": 27.830681324005127,
      "citing_paper_id": "269671831",
      "cited_paper_id": 197928119
    },
    {
      "context_text": "The preference encoder is implemented based on a deep bidirectional Transformer [ 7], where we use a learnable look-up table mapping user ID to embedding, and append it before the comment 𝑡 ’s word embedding sequence, that is: where ENC is the encoder for generating the user preference features 𝑒…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Transformer) and a model (BERT). The citation is about the implementation details of a preference encoder using a Transformer architecture.",
      "processing_time": 30.278234481811523,
      "citing_paper_id": "269671831",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "The vision encoder is initialized from 𝑉𝑖𝑇 − 𝐵 / 16 pre-trained on ImageNet [5], and the user preference encoder and text generator are initialized from 𝐵𝐸𝑅𝑇 𝑏𝑎𝑠𝑒 .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ImageNet"
      ],
      "dataset_descriptions": {
        "ImageNet": "Used to pre-train the vision encoder, specifically leveraging the large-scale hierarchical image database to initialize the model."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions ImageNet, which is a well-known dataset used for pre-training the vision encoder. No other datasets are mentioned.",
      "processing_time": 34.56875443458557,
      "citing_paper_id": "269671831",
      "cited_paper_id": 57246310
    },
    {
      "context_text": "Following LiveBot, Lv et al. [21] proposes an Embedding-based Generative Adversarial framework to bridge the gap between visual and textual content.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or framework. The context focuses on the approach rather than a particular dataset.",
      "processing_time": 28.072120428085327,
      "citing_paper_id": "269671831",
      "cited_paper_id": 92996193
    },
    {
      "context_text": "Also, some works [9, 31] introduce additional audio information, using a multi-modal and multi-task architecture to capture the relationships among comments, vision, and audio, generating comments with these information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to the use of multi-modal and multi-task architectures, which are methods, not datasets.",
      "processing_time": 30.268967866897583,
      "citing_paper_id": "269671831",
      "cited_paper_id": 211066479
    },
    {
      "context_text": "Unlike previous methods [14, 28, 41], which only use an empty set to replace 𝑡 , we further leverage the generated comments 𝑡 1 , 𝑡 2 , ... to enhance the inference stage.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 28.341294050216675,
      "citing_paper_id": "269671831",
      "cited_paper_id": 232306930
    },
    {
      "context_text": "Unlike previous methods [14, 28, 41], which only use an empty set to replace 𝑡 , we further leverage the generated comments 𝑡 1 , 𝑡 2 , ... to enhance the inference stage.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 28.341294050216675,
      "citing_paper_id": "269671831",
      "cited_paper_id": null
    },
    {
      "context_text": "Although Wu et al. [33] explores comments generation with few surrounding comments, it still ignores personal preference when selecting video clips and generating comments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach for generating comments. The focus is on the limitation of ignoring personal preferences in comment generation.",
      "processing_time": 30.264477252960205,
      "citing_paper_id": "269671831",
      "cited_paper_id": 235097581
    },
    {
      "context_text": "With the advancement of Large Language Models (LLM), LLM based multi-modal models, such as Flamingo [1], BLIP-2 [15], and miniGPT-4 [42], have demonstrated excellent capability to describe an image precisely and with details.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their capabilities. There are no verifiable resources or datasets mentioned.",
      "processing_time": 28.356948137283325,
      "citing_paper_id": "269671831",
      "cited_paper_id": null
    },
    {
      "context_text": "EICP [28] specifies 215 different personality traits as user preference.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions '215 different personality traits as user preference' which could be part of a dataset, but there is no specific dataset name provided. The term 'EICP' is mentioned but it is unclear if it is a dataset or another type of resource.",
      "processing_time": 34.784873247146606,
      "citing_paper_id": "269671831",
      "cited_paper_id": null
    },
    {
      "context_text": "• EICP [28].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation span does not provide any context about the use of a specific dataset, method, or other resource. There is insufficient information to determine the intent or type of resource.",
      "processing_time": 31.355095148086548,
      "citing_paper_id": "269671831",
      "cited_paper_id": null
    },
    {
      "context_text": "Unlike certain personalized image to text datasets [28], our Personalized VideoIC dataset does not rely on personality traits that are manually labeled by humans.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Personalized VideoIC dataset"
      ],
      "dataset_descriptions": {
        "Personalized VideoIC dataset": "Used to generate personalized video captions without relying on manually labeled personality traits, focusing on natural language generation techniques."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Personalized VideoIC dataset' as a specific dataset used in the research, contrasting it with other personalized image to text datasets. It is clearly identified and used in the research.",
      "processing_time": 37.71968054771423,
      "citing_paper_id": "269671831",
      "cited_paper_id": null
    },
    {
      "context_text": "4, we compare PVCG with two personalized image caption models – EICP [28] and SACO [41].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 25.967045068740845,
      "citing_paper_id": "269671831",
      "cited_paper_id": null
    },
    {
      "context_text": "Recently, some works [24, 28, 37, 41] generate engaging text with diverse style from image.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to generating text from images.",
      "processing_time": 62.22637867927551,
      "citing_paper_id": "269671831",
      "cited_paper_id": null
    },
    {
      "context_text": "Font generation has achieved remarkable success, producing stunning results [Jiang et al. 2017; Wang et al. 2023f, 2020 ].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers on font generation. No verifiable resources are identified.",
      "processing_time": 15.322037696838379,
      "citing_paper_id": "271177896",
      "cited_paper_id": 23763057
    },
    {
      "context_text": "Font generation has achieved remarkable success, producing stunning results [Jiang et al. 2017; Wang et al. 2023f, 2020 ].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers on font generation. No verifiable resources are identified.",
      "processing_time": 15.322037696838379,
      "citing_paper_id": "271177896",
      "cited_paper_id": 266177436
    },
    {
      "context_text": "Artistic font image generation [Gao et al. 2019; Li et al. 2022b, 2023; Wang et al. 2023d] can be defined as transferring the style of reference images to another artistic font image or a binary font source image [Yang et al. 2019a].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models for artistic font image generation.",
      "processing_time": 12.918587923049927,
      "citing_paper_id": "271177896",
      "cited_paper_id": 204402699
    },
    {
      "context_text": "Artistic font image generation [Gao et al. 2019; Li et al. 2022b, 2023; Wang et al. 2023d] can be defined as transferring the style of reference images to another artistic font image or a binary font source image [Yang et al. 2019a].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models for artistic font image generation.",
      "processing_time": 12.918587923049927,
      "citing_paper_id": "271177896",
      "cited_paper_id": 260849232
    },
    {
      "context_text": "Artistic font image generation [Gao et al. 2019; Li et al. 2022b, 2023; Wang et al. 2023d] can be defined as transferring the style of reference images to another artistic font image or a binary font source image [Yang et al. 2019a].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models for artistic font image generation.",
      "processing_time": 12.918587923049927,
      "citing_paper_id": "271177896",
      "cited_paper_id": 266177436
    },
    {
      "context_text": "The previous works have adopted methods based on patch-based texture synthesis [Yang et al. 2022, 2019b] or Generative Adversarial Networks [Li et al. 2020; Yang et al. 2019a] to ensure that the generated style aligns with the correct style distribution.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets in the text.",
      "processing_time": 16.2737717628479,
      "citing_paper_id": "271177896",
      "cited_paper_id": 214410607
    },
    {
      "context_text": "Due to the advantages of diffusion models [Ma et al. 2024; Song et al. 2020] over GANs [Dong et al. 2022; Karras et al. 2021] in terms of generating higher image quality and better training stability, text-to-image diffusion models [Chefer et al. 2023; Gal et al. 2023; Tewel et al. 2023] have…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 15.02031421661377,
      "citing_paper_id": "271177896",
      "cited_paper_id": 222140788
    },
    {
      "context_text": "Due to the advantages of diffusion models [Ma et al. 2024; Song et al. 2020] over GANs [Dong et al. 2022; Karras et al. 2021] in terms of generating higher image quality and better training stability, text-to-image diffusion models [Chefer et al. 2023; Gal et al. 2023; Tewel et al. 2023] have…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 15.02031421661377,
      "citing_paper_id": "271177896",
      "cited_paper_id": 253069389
    },
    {
      "context_text": "A series of recent works [Epstein et al. 2023; He et al. 2023b; Rombach et al. 2022; Voynov et al. 2023] have addressed this issue by introducing spatial layout conditions and attention mechanism [Guo et al. 2020; Wang et al. 2023c].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.691285133361816,
      "citing_paper_id": "271177896",
      "cited_paper_id": 226742001
    },
    {
      "context_text": "A series of recent works [Epstein et al. 2023; He et al. 2023b; Rombach et al. 2022; Voynov et al. 2023] have addressed this issue by introducing spatial layout conditions and attention mechanism [Guo et al. 2020; Wang et al. 2023c].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.691285133361816,
      "citing_paper_id": "271177896",
      "cited_paper_id": 258999106
    },
    {
      "context_text": "A series of recent works [Epstein et al. 2023; He et al. 2023b; Rombach et al. 2022; Voynov et al. 2023] have addressed this issue by introducing spatial layout conditions and attention mechanism [Guo et al. 2020; Wang et al. 2023c].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.691285133361816,
      "citing_paper_id": "271177896",
      "cited_paper_id": 259252486
    },
    {
      "context_text": "A series of recent works [Epstein et al. 2023; He et al. 2023b; Rombach et al. 2022; Voynov et al. 2023] have addressed this issue by introducing spatial layout conditions and attention mechanism [Guo et al. 2020; Wang et al. 2023c].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.691285133361816,
      "citing_paper_id": "271177896",
      "cited_paper_id": 260387426
    },
    {
      "context_text": "A series of recent works [Epstein et al. 2023; He et al. 2023b; Rombach et al. 2022; Voynov et al. 2023] have addressed this issue by introducing spatial layout conditions and attention mechanism [Guo et al. 2020; Wang et al. 2023c].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.691285133361816,
      "citing_paper_id": "271177896",
      "cited_paper_id": 266177436
    },
    {
      "context_text": "…over GANs [Dong et al. 2022; Karras et al. 2021] in terms of generating higher image quality and better training stability, text-to-image diffusion models [Chefer et al. 2023; Gal et al. 2023; Tewel et al. 2023] have achieved tremendous success in the synthesis of diverse, photorealistic images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is about the performance of text-to-image diffusion models compared to GANs.",
      "processing_time": 17.77673602104187,
      "citing_paper_id": "271177896",
      "cited_paper_id": 256416326
    },
    {
      "context_text": "…over GANs [Dong et al. 2022; Karras et al. 2021] in terms of generating higher image quality and better training stability, text-to-image diffusion models [Chefer et al. 2023; Gal et al. 2023; Tewel et al. 2023] have achieved tremendous success in the synthesis of diverse, photorealistic images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is about the performance of text-to-image diffusion models compared to GANs.",
      "processing_time": 17.77673602104187,
      "citing_paper_id": "271177896",
      "cited_paper_id": 257364757
    },
    {
      "context_text": "…over GANs [Dong et al. 2022; Karras et al. 2021] in terms of generating higher image quality and better training stability, text-to-image diffusion models [Chefer et al. 2023; Gal et al. 2023; Tewel et al. 2023] have achieved tremendous success in the synthesis of diverse, photorealistic images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The context is about the performance of text-to-image diffusion models compared to GANs.",
      "processing_time": 17.77673602104187,
      "citing_paper_id": "271177896",
      "cited_paper_id": 258436985
    },
    {
      "context_text": "However, since text-to-image models are typically trained on datasets with short text captions, they often struggle to capture all the details in dense text prompts composed of several phrases, especially when there are complex relative positional relationships [Kim et al. 2023].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only discusses a general issue with text-to-image models and their training data.",
      "processing_time": 29.43632411956787,
      "citing_paper_id": "271177896",
      "cited_paper_id": 261101003
    },
    {
      "context_text": "Unlike [Kim et al. 2023], we use the diffusion model to separately predict layout-related noise at multiple views; SDS iteratively updates the 3D representation using the gradient information computed from the noise.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (diffusion model) and a technique (SDS).",
      "processing_time": 15.951040744781494,
      "citing_paper_id": "271177896",
      "cited_paper_id": 261101003
    },
    {
      "context_text": "Since the layout of the generated image is related to the attention maps [Hertz et al. 2023; Kim et al. 2023], we dynamically modulate the multi-view attention maps in the pre-trained diffusion model according to the layout conditions to guide objects to appear in specific regions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the modulation of attention maps in a pre-trained diffusion model.",
      "processing_time": 18.90457844734192,
      "citing_paper_id": "271177896",
      "cited_paper_id": 261101003
    },
    {
      "context_text": "DenseDif-fusion [Kim et al. 2023] introduces the attention modulation and semantic segmentation map as layout conditions to guide objects to appear in specific areas without the need for additional training.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The focus is on the introduction of attention modulation and semantic segmentation maps in the DenseDif-fusion model.",
      "processing_time": 19.85010528564453,
      "citing_paper_id": "271177896",
      "cited_paper_id": 261101003
    },
    {
      "context_text": "DenseDiffusion [Kim et al. 2023] achieves layout control based on attention modulation in text-to-image generation, and states a significant correlation between the generated image layout and attention maps.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DenseDiffusion) and its application in text-to-image generation.",
      "processing_time": 25.58284854888916,
      "citing_paper_id": "271177896",
      "cited_paper_id": 261101003
    },
    {
      "context_text": "Recently, Control3D [Chen et al. 2023b] incorporates ControlNet [Zhang et al. 2023] and leverages its sketch-to-image capabilities to promote geometric controllability.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the integration of ControlNet into Control3D for geometric controllability.",
      "processing_time": 19.320059537887573,
      "citing_paper_id": "271177896",
      "cited_paper_id": 264492267
    },
    {
      "context_text": "ProlificDreamer[Wang et al. 2023b], MVDream [Shi et al. 2023], Fantasia3D [Chen et al. 2023a] use SD2.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'SD2' which could be a dataset, but there is no clear indication of its full name or specific usage in the provided citation span. The cited paper titles do not provide additional clarity.",
      "processing_time": 18.892698526382446,
      "citing_paper_id": "271177896",
      "cited_paper_id": 264492267
    },
    {
      "context_text": "ProlificDreamer[Wang et al. 2023b], MVDream [Shi et al. 2023], Fantasia3D [Chen et al. 2023a] use SD2.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'SD2' which could be a dataset, but there is no clear indication of its full name or specific usage in the provided citation span. The cited paper titles do not provide additional clarity.",
      "processing_time": 18.892698526382446,
      "citing_paper_id": "271177896",
      "cited_paper_id": 266177436
    },
    {
      "context_text": "Manyi Li Shandong University Jinan, China Xiangxu Meng Shandong University 相比现有的方法， DreamFont3D 不仅能够生成与文本一致的字体效果，其生成结果还具有更 好的可识别性，支持字体效果的定位。 Figure 1: Comparison between our proposed DreamFont3D and ProlificDreamer [Wang et al. 2023b] in the text-to-3D artistic font generation under different text prompts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It focuses on comparing methods for text-to-3D artistic font generation.",
      "processing_time": 18.42042350769043,
      "citing_paper_id": "271177896",
      "cited_paper_id": 266177436
    },
    {
      "context_text": "Recently, Anything2Glyph [Wang et al. 2023e] leverages the advantage of Stable Diffusion in generating images of any object, and uses masks to constrain the approximate skeleton-level positioning of objects within images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Anything2Glyph) and a model (Stable Diffusion).",
      "processing_time": 14.98822021484375,
      "citing_paper_id": "271177896",
      "cited_paper_id": 266177436
    },
    {
      "context_text": "…Shandong University Jinan, China Xiangxu Meng Shandong University 相比现有的方法， DreamFont3D 不仅能够生成与文本一致的字体效果，其生成结果还具有更 好的可识别性，支持字体效果的定位。 Figure 1: Comparison between our proposed DreamFont3D and ProlificDreamer [Wang et al. 2023b] in the text-to-3D artistic font generation under different text prompts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison between two methods for text-to-3D artistic font generation.",
      "processing_time": 15.928786754608154,
      "citing_paper_id": "271177896",
      "cited_paper_id": 266177436
    },
    {
      "context_text": "Due to the diversity of font structures, existing text-to-image diffusion models struggle to predict the structure of arbitrary characters based on textual descriptions [Wang et al. 2023e].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a challenge faced by existing models. No verifiable resources are identified.",
      "processing_time": 62.91086506843567,
      "citing_paper_id": "271177896",
      "cited_paper_id": 266177436
    },
    {
      "context_text": "Therefore, the previous text-to-3D methods [Jain et al. 2022; Wang et al. 2022, 2023a] following the above 2D prior optimization often cause unrecognizable font and unstable local effects.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and their limitations. The context focuses on the issues with previous text-to-3D methods, which are not directly related to personalized text generation.",
      "processing_time": 32.01388454437256,
      "citing_paper_id": "271177896",
      "cited_paper_id": 266177436
    },
    {
      "context_text": "Follow-up works, exemplified by Magic3D [Lin et al. 2023] and ProlificDreamer [Wang et al. 2023b], involve the implementation of multi-stage optimization strategies, optimizing the diffusion prior with the 3D representation simultaneously and the proposal of more effective score distillation…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on multi-stage optimization strategies and score distillation, which are methodological aspects.",
      "processing_time": 16.92263627052307,
      "citing_paper_id": "271177896",
      "cited_paper_id": 266177436
    },
    {
      "context_text": "The alignment assessment uses multi-view captioning (BLIP [Li et al. 2022a]) and Large Language Model (GPT4 [OpenAI 2023]) to measure whether the text in the captioning is consistent with the text input (from 1-5 score).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on using BLIP and GPT4 for alignment assessment, which are not datasets.",
      "processing_time": 17.341694116592407,
      "citing_paper_id": "271177896",
      "cited_paper_id": null
    },
    {
      "context_text": "GPT-4 [OpenAI 2023] provides support for writing text prompts.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (GPT-4). No verifiable resources are identified.",
      "processing_time": 13.64681363105774,
      "citing_paper_id": "271177896",
      "cited_paper_id": null
    },
    {
      "context_text": "Typically, denoising diffusion probabilistic models (DDPMs) [2, 17] utilized a forward noising process that gradually adds Gaussian noise to images and trained a reverse process that inverts the forward process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and processes. There are no verifiable resources that meet the criteria.",
      "processing_time": 28.611305475234985,
      "citing_paper_id": "258833185",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "Such cross-modal correspondences are beneﬁcial for many audio-visual tasks, such as audio-event localization [19], audio-visual parsing [10, 18], and audio-visual spatialization & localization [8, 9, 11–14].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only tasks and applications. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 17.2958562374115,
      "citing_paper_id": "258833185",
      "cited_paper_id": 220665910
    },
    {
      "context_text": "Such cross-modal correspondences are beneﬁcial for many audio-visual tasks, such as audio-event localization [19], audio-visual parsing [10, 18], and audio-visual spatialization & localization [8, 9, 11–14].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only tasks and applications. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 17.2958562374115,
      "citing_paper_id": "258833185",
      "cited_paper_id": 247518748
    },
    {
      "context_text": "Such cross-modal correspondences are beneﬁcial for many audio-visual tasks, such as audio-event localization [19], audio-visual parsing [10, 18], and audio-visual spatialization & localization [8, 9, 11–14].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only tasks and applications. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 17.2958562374115,
      "citing_paper_id": "258833185",
      "cited_paper_id": 257833572
    },
    {
      "context_text": "Such cross-modal correspondences are beneﬁcial for many audio-visual tasks, such as audio-event localization [19], audio-visual parsing [10, 18], and audio-visual spatialization & localization [8, 9, 11–14].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only tasks and applications. The cited papers' titles do not provide additional context to identify specific datasets.",
      "processing_time": 17.2958562374115,
      "citing_paper_id": "258833185",
      "cited_paper_id": 258509029
    },
    {
      "context_text": "Diffusion models have been demonstrated to be effective in many generative tasks, such as image generation [15], image restoration [16], speech generation [4], and video generation [1].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only generative tasks. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 16.943103790283203,
      "citing_paper_id": "258833185",
      "cited_paper_id": 221818900
    },
    {
      "context_text": "Diffusion models have been demonstrated to be effective in many generative tasks, such as image generation [15], image restoration [16], speech generation [4], and video generation [1].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only generative tasks. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 16.943103790283203,
      "citing_paper_id": "258833185",
      "cited_paper_id": 233241040
    },
    {
      "context_text": "For the video encoder, we apply the pre-trained X-CLIP [7] as the frozen weights.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a pre-trained model (X-CLIP) but does not refer to any specific dataset. The context is about using the model for a video encoder, not a dataset.",
      "processing_time": 19.926080465316772,
      "citing_paper_id": "258833185",
      "cited_paper_id": 250607505
    },
    {
      "context_text": "In recent years, researchers [5, 21] have tried to explore diverse diffusion models to learn a discrete representation or a discrete space from audio.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the exploration of diffusion models for learning discrete representations from audio.",
      "processing_time": 28.26461672782898,
      "citing_paper_id": "258833185",
      "cited_paper_id": 250698823
    },
    {
      "context_text": "In order to validate the effectiveness of the proposed DiffAVA, we comprehensively compare it to previous DDPM and LDM baselines: 1) DiffSound [21]: a vector-quantized variational autoencoder (VQ-VAE) based DDPM framework by learning a discrete space from audio given natural language description…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is used to describe a method for comparison.",
      "processing_time": 16.20659303665161,
      "citing_paper_id": "258833185",
      "cited_paper_id": 250698823
    },
    {
      "context_text": "In particular, the proposed DiffAVA signiﬁcantly outperforms Diff-Sound [21], the ﬁrst DDPM-based baseline on TTA generation, by 3.36 IS, and highly decreases other metrics by 0.83 KL, 3.52 FAD, and 15.47 FD.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics and comparisons with other models.",
      "processing_time": 12.367127895355225,
      "citing_paper_id": "258833185",
      "cited_paper_id": 250698823
    },
    {
      "context_text": "Since last year, researchers have explored various denoising diffusion probabilistic models (DDPMs) to learn discrete representations, such as in DiffSound [21] and Au-dioGen [5].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (DiffSound and AudioGen). No verifiable resources are identified.",
      "processing_time": 28.81899356842041,
      "citing_paper_id": "258833185",
      "cited_paper_id": 250698823
    },
    {
      "context_text": "We update the model using AdamW [16], where β 1 = 0 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (AdamW) for updating the model.",
      "processing_time": 12.8375883102417,
      "citing_paper_id": "265722909",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "In this work, we consider text-to-image diffusion models, a class of generative models that transform Gaussian noise via iterative denoising process to model data distribution p ( x ) [9].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a class of generative models. There are no verifiable resources or datasets mentioned.",
      "processing_time": 18.62380313873291,
      "citing_paper_id": "265722909",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "Since text-to-image models [4, 18, 19, 22, 27] have shown impressive re-sults, several studies have been proposed to personalize the text-to-image models using only a few images of a specific subject.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to text-to-image models. No verifiable resources are identified.",
      "processing_time": 15.512020349502563,
      "citing_paper_id": "265722909",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "Since text-to-image models [4, 18, 19, 22, 27] have shown impressive re-sults, several studies have been proposed to personalize the text-to-image models using only a few images of a specific subject.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to text-to-image models. No verifiable resources are identified.",
      "processing_time": 15.512020349502563,
      "citing_paper_id": "265722909",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "Since text-to-image models [4, 18, 19, 22, 27] have shown impressive re-sults, several studies have been proposed to personalize the text-to-image models using only a few images of a specific subject.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to text-to-image models. No verifiable resources are identified.",
      "processing_time": 15.512020349502563,
      "citing_paper_id": "265722909",
      "cited_paper_id": 257557484
    },
    {
      "context_text": "Recently, text-to-image models [18, 19, 22] have demonstrated superior performance in generating natural and high-quality images given novel text prompts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only text-to-image models. No dataset names are provided in the context.",
      "processing_time": 26.275163650512695,
      "citing_paper_id": "265722909",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "Recently, text-to-image models [18, 19, 22] have demonstrated superior performance in generating natural and high-quality images given novel text prompts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only text-to-image models. No dataset names are provided in the context.",
      "processing_time": 26.275163650512695,
      "citing_paper_id": "265722909",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "The second stream, based on DreamBooth [21], involves the method to fine-tune the pre-trained models using the text prompt with a unique identifier.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DreamBooth) for fine-tuning models. No verifiable dataset names are present.",
      "processing_time": 16.60663390159607,
      "citing_paper_id": "265722909",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Built upon DreamBooth [21], we first personalize a pre-trained text-to-image model with a class noun and a unique identifier (Section 4.1).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DreamBooth) for personalizing text-to-image models. The context focuses on the methodology rather than a dataset.",
      "processing_time": 19.095614671707153,
      "citing_paper_id": "265722909",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Specifically, we first personalize text-to-image model by updating model parameters with a unique identifier and a few reference images similar to DreamBooth [21].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It refers to a method (DreamBooth) for personalizing text-to-image models, which is not a dataset.",
      "processing_time": 19.24364972114563,
      "citing_paper_id": "265722909",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Specifically, we use images of subjects sampled from prior works [12, 21] and generate a total of 40 prompts by combining subjects and phrases.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to images of subjects sampled from prior works, which are not named.",
      "processing_time": 29.129643440246582,
      "citing_paper_id": "265722909",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Ruiz et al. [21] proposed DreamBooth, a method that fine-tunes pre-trained models using a unique identifier.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions DreamBooth, which is a method, not a dataset. No specific dataset is mentioned in the context.",
      "processing_time": 16.218879461288452,
      "citing_paper_id": "265722909",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "To generate new images of a specific subject, given only a few reference images, we leverage DreamBooth [21].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'DreamBooth' but does not refer to it as a dataset. It is described as a method for fine-tuning text-to-image diffusion models.",
      "processing_time": 18.349684476852417,
      "citing_paper_id": "265722909",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "We compare the quality of personalized text-to-image generation against two base-lines: DreamBooth [21] and Custom diffusion [12].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods. The context focuses on comparing personalized text-to-image generation methods.",
      "processing_time": 16.59148406982422,
      "citing_paper_id": "265722909",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "We evaluate the performance of our proposed method on a diverse set of subject images, comparing it to prior methods, such as DreamBooth [21], Custom Diffusion [12] and Textual Inversion [7].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is used to compare performance against prior methods.",
      "processing_time": 28.221920013427734,
      "citing_paper_id": "265722909",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "To personalize existing text-to-image models, several approaches have been proposed that learn user-defined concepts using a few given images [1, 7, 8, 12, 15, 21, 24, 28].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches for personalizing text-to-image models. No verifiable resources are identified.",
      "processing_time": 17.674049139022827,
      "citing_paper_id": "265722909",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "To personalize existing text-to-image models, several approaches have been proposed that learn user-defined concepts using a few given images [1, 7, 8, 12, 15, 21, 24, 28].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches for personalizing text-to-image models. No verifiable resources are identified.",
      "processing_time": 17.674049139022827,
      "citing_paper_id": "265722909",
      "cited_paper_id": 257631648
    },
    {
      "context_text": "To personalize existing text-to-image models, several approaches have been proposed that learn user-defined concepts using a few given images [1, 7, 8, 12, 15, 21, 24, 28].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches for personalizing text-to-image models. No verifiable resources are identified.",
      "processing_time": 17.674049139022827,
      "citing_paper_id": "265722909",
      "cited_paper_id": 258866047
    },
    {
      "context_text": "To evaluate the performance of personalized text-to-image models, we employ the DreamBench dataset [21], which consists of 30 unique subjects including various objects, live subjects, and pets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DreamBench"
      ],
      "dataset_descriptions": {
        "DreamBench": "Used to evaluate personalized text-to-image models, focusing on 30 unique subjects including various objects, live subjects, and pets."
      },
      "confidence_score": 1.0,
      "reasoning": "The context explicitly mentions the 'DreamBench dataset' as a specific resource used for evaluating personalized text-to-image models.",
      "processing_time": 22.571114540100098,
      "citing_paper_id": "265722909",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "The training of this model involves predicting the added noise ϵ to the latent representation z t at timestep t , using an additional condition c .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general description of the model training process. No verifiable resources are identified.",
      "processing_time": 17.27473735809326,
      "citing_paper_id": "265722909",
      "cited_paper_id": 257557484
    },
    {
      "context_text": "To address this issue, recent studies have investigated learning from human feedback in text-to-image generation [11, 13, 25, 26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general area of research. No verifiable resources are identified.",
      "processing_time": 28.546818017959595,
      "citing_paper_id": "265722909",
      "cited_paper_id": 257767281
    },
    {
      "context_text": "Subsequently, they utilize the learned rewards to enhance image-text alignment through techniques such as rejection sampling [11], reward-weighted learning [13, 25], and direct reward optimization via gradient [26].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only techniques and methods for enhancing image-text alignment.",
      "processing_time": 15.215919971466064,
      "citing_paper_id": "265722909",
      "cited_paper_id": 257767281
    },
    {
      "context_text": "Within this line of research, each approach is differentiated by determining the scope of weights to be learned, such as fine-tuning only the weights of the attention layer [12, 23].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. There are no clear identifiers for datasets in the given context.",
      "processing_time": 29.113598585128784,
      "citing_paper_id": "265722909",
      "cited_paper_id": 258436985
    },
    {
      "context_text": "This line of research demonstrates high controllability and has recently been expanded to learn new word embedding in various embedding spaces [1, 24, 28].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers. There are no clear identifiers for datasets, and the context is too generic.",
      "processing_time": 18.79191303253174,
      "citing_paper_id": "265722909",
      "cited_paper_id": 258866047
    },
    {
      "context_text": "We provide a more detailed explanation of conditional latent diffusion models in the supplemental material.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No verifiable resources are identified.",
      "processing_time": 28.53615164756775,
      "citing_paper_id": "265722909",
      "cited_paper_id": 263671961
    },
    {
      "context_text": "Traditional automatic metrics suffer from the one-to-many problem in open-ended generation (Liu ...Ben becomes increasingly worried for his mother and reaches out to Jesse and Isabelle for support but fails.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue with evaluation metrics in dialogue systems.",
      "processing_time": 12.557936191558838,
      "citing_paper_id": "263671864",
      "cited_paper_id": 9197196
    },
    {
      "context_text": "We use two common lexical-similarity-based metrics, BLEU (Papineni et al., 2002) and ROUGE (Lin, 2004), and two model-based metrics, BERTScore (Zhang et al., 2019) and BARTScore (Yuan et al., 2021) to 1. k = 0 indicates that there are no personalized examples in the instruction, which is a baseline for evaluation without personalization.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only metrics and models. The context focuses on evaluating personalized text generation using various metrics.",
      "processing_time": 14.066627979278564,
      "citing_paper_id": "263671864",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "Reference-based metrics evaluate the similarity between the reference and the model output based on lexical overlap (Papineni et al., 2002; Lin, 2004) or embedding distance (Zhang et al., 2019; Zhao et al., 2019).",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods for evaluating machine translation.",
      "processing_time": 12.293213844299316,
      "citing_paper_id": "263671864",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "We use two common lexical-similarity-based metrics, BLEU (Papineni et al., 2002) and ROUGE (Lin, 2004), and two model-based metrics, BERTScore (Zhang et al., 2019) and BARTScore (Yuan et al., 2021) to 1. k = 0 indicates that there are no personalized examples in the instruction, which is a baseline…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only evaluation metrics. Metrics are excluded according to the instructions.",
      "processing_time": 12.982632875442505,
      "citing_paper_id": "263671864",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "Human Evaluation for Generation Human evaluation is also used to evaluate different aspects of text quality, such as coherence (Xu et al., 2018; Peng et al., 2018), relevance (Yang et al., 2023, 2022; Jhamtani and Berg-Kirkpatrick, 2020), in-terestingness (Bae et al., 2021) and so on.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general aspects of human evaluation for text generation. No verifiable resources are identified.",
      "processing_time": 14.85924243927002,
      "citing_paper_id": "263671864",
      "cited_paper_id": 51729727
    },
    {
      "context_text": "Human Evaluation for Generation Human evaluation is also used to evaluate different aspects of text quality, such as coherence (Xu et al., 2018; Peng et al., 2018), relevance (Yang et al., 2023, 2022; Jhamtani and Berg-Kirkpatrick, 2020), in-terestingness (Bae et al., 2021) and so on.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general aspects of human evaluation for text generation. No verifiable resources are identified.",
      "processing_time": 14.85924243927002,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254877751
    },
    {
      "context_text": "Recently some studies have trained evaluation metrics on human ratings to better approximate human judgments (Sellam et al., 2020; Rei et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of training evaluation metrics on human ratings. No clear, verifiable dataset names are provided.",
      "processing_time": 16.170166015625,
      "citing_paper_id": "263671864",
      "cited_paper_id": 221819581
    },
    {
      "context_text": "... hesitantly agrees to the idea and begins working on the new series, finding solace in the creative process. et al., 2016) and have shown poor correlation with human judgment (Krishna et al., 2021; Guan et al., 2021).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing correlations with human judgment.",
      "processing_time": 13.536263465881348,
      "citing_paper_id": "263671864",
      "cited_paper_id": 232185275
    },
    {
      "context_text": "Xu et al., 2022) and search applications (Croft et al., 2001; Shi et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 16.121708869934082,
      "citing_paper_id": "263671864",
      "cited_paper_id": 250526766
    },
    {
      "context_text": "Large language models (LLMs) have recently shown impressive generative capability in many generation tasks, gaining rapid improvement in language qualities such as fluency and consistency (Ouyang et al., 2022; Bai et al., 2022; Tou-vron et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to improvements in language qualities of LLMs. No verifiable resources are identified.",
      "processing_time": 16.847960710525513,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254823489
    },
    {
      "context_text": "On Per-DOC, both plot pairs and the annotators of the validation set have no overlapping with the training set, so the matrix factorization cannot apply to this setting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Per-DOC"
      ],
      "dataset_descriptions": {
        "Per-DOC": "Used to validate the coherence of long stories generated with detailed outline control, ensuring no overlap with the training set to test generalization."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'Per-DOC' which appears to be a specific dataset used for validation in the research. The dataset is described as having no overlap with the training set, which is relevant to the methodology.",
      "processing_time": 24.451409101486206,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254877751
    },
    {
      "context_text": "Per-DOC We use human evaluation results on system generated stories from Yang et al. (2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'human evaluation results' but does not specify a dataset name. The title suggests the evaluation is part of the research work rather than a reusable dataset.",
      "processing_time": 18.759774684906006,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254877751
    },
    {
      "context_text": "We demonstrate the pointwise evaluation in the individual setting on Per-MPST and the pairwise comparison in the pairwise personalized setting on Per-DOC.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Per-MPST",
        "Per-DOC"
      ],
      "dataset_descriptions": {
        "Per-MPST": "Used for pointwise evaluation in the individual setting, assessing the performance of personalized text generation models.",
        "Per-DOC": "Used for pairwise comparison in the personalized setting, evaluating the coherence and quality of generated long stories using detailed outline control."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'Per-MPST' and 'Per-DOC' as specific datasets used for evaluation in different settings. 'Per-DOC' is likely related to the cited paper 'DOC: Improving Long Story Coherence With Detailed Outline Control'.",
      "processing_time": 33.38170552253723,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254877751
    },
    {
      "context_text": "For Per-DOC, since we only have one comparison in the instruction ( k = 1 ), we directly use this answer as the output.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only describes a methodological approach within the context of the cited paper.",
      "processing_time": 17.618616819381714,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254877751
    },
    {
      "context_text": "The two datasets Per-MPST and Per-DOC are reproduced from the existing publicly released datasets MPST (Kar et al., 2018, 2020) and DOC (Yang et al., 2023)under their licenses.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Per-MPST",
        "Per-DOC",
        "MPST",
        "DOC"
      ],
      "dataset_descriptions": {
        "Per-MPST": "Reproduced from MPST to study personalized multi-perspective story telling, focusing on generating diverse narrative perspectives.",
        "Per-DOC": "Reproduced from DOC to enhance long story coherence through detailed outline control, specifically for personalized document generation.",
        "MPST": "Original dataset used for multi-perspective story telling, providing a basis for reproducing Per-MPST for personalized narratives.",
        "DOC": "Original dataset used for improving long story coherence, serving as a foundation for reproducing Per-DOC with detailed outline control."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, Per-MPST and Per-DOC, which are derived from existing datasets MPST and DOC. These are clearly identified and relevant to the research topic of personalized text generation.",
      "processing_time": 42.2253475189209,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254877751
    },
    {
      "context_text": "In our main experiments, we use k = 3 for Per-MPST and k = 1 for Per-DOC.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only parameters for methods. No verifiable resources are identified.",
      "processing_time": 15.456147909164429,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254877751
    },
    {
      "context_text": "We implement P ER SE based on LLaMA-7b-chat and LLaMA-13b-chat, tuning them on the personalized instruction data created from the training set of Per-MPST and Per-DOC.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Per-MPST",
        "Per-DOC"
      ],
      "dataset_descriptions": {
        "Per-MPST": "Used to train personalized instruction data, focusing on improving the coherence and relevance of generated text in multi-party settings.",
        "Per-DOC": "Used to train personalized instruction data, specifically enhancing the coherence and structure of long stories through detailed outline control."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'Per-MPST' and 'Per-DOC' as specific datasets used for training personalized instruction data. These appear to be specific datasets relevant to personalized text generation.",
      "processing_time": 30.989753246307373,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254877751
    },
    {
      "context_text": "For example, Figure 1 demonstrates two stories generated by Yang et al. (2023) from the same premise.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating stories. There are no verifiable resources or datasets mentioned.",
      "processing_time": 17.584800243377686,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254877751
    },
    {
      "context_text": "We investigate the influence of joint training of different aspects on Per-DOC by training an individual model on each aspect and comparing the performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a methodological approach. The cited paper title does not provide additional information about datasets.",
      "processing_time": 18.523677825927734,
      "citing_paper_id": "263671864",
      "cited_paper_id": 254877751
    },
    {
      "context_text": "Recently, researchers have explored using large language models in evaluation metrics, such as GPTScore (Fu et al., 2023), GEMBA (Kocmi and Federmann, 2023), and InstructScore (Xu et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several evaluation metrics but does not refer to any specific datasets. The context focuses on methods and metrics rather than datasets.",
      "processing_time": 25.242039680480957,
      "citing_paper_id": "263671864",
      "cited_paper_id": 257232490
    },
    {
      "context_text": "This is also observed by Kirk et al. (2023) who claims that the aggregate fine-tuning process may not well represent all human preferences and values.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about fine-tuning processes. No verifiable resources are identified.",
      "processing_time": 25.976491689682007,
      "citing_paper_id": "263671864",
      "cited_paper_id": 257427629
    },
    {
      "context_text": "We also enhance the transparency of the personalized evaluation by introducing interpretable metrics, as suggested in Kirk et al. (2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the introduction of interpretable metrics for personalized evaluation.",
      "processing_time": 25.425476551055908,
      "citing_paper_id": "263671864",
      "cited_paper_id": 257427629
    },
    {
      "context_text": "Several recent studies have investigated LLMs’ capabilities in capturing personalization (Chen et al., 2023; Kang et al., 2023; Salemi et al., 2023) or prompting for personalized recommendations (Lyu et al., 2023; Chen, 2023; Li et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies. No clear identifiers for datasets are present.",
      "processing_time": 13.091760396957397,
      "citing_paper_id": "263671864",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "The lack of trans-parency hinders the trustworthiness and reliability of evaluation and makes it difficult to assist in the development of generative models (Leiter et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It focuses on the issue of transparency in the evaluation of generative models.",
      "processing_time": 27.587626695632935,
      "citing_paper_id": "263671864",
      "cited_paper_id": null
    },
    {
      "context_text": "We use chain-of-thought (Wei et al., 2022) to make P ER SE first generate the comment r and then output the score y based on it, which can be denoted by y = M( x , c u , e r ) and e r = M( x , c u ) .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (chain-of-thought) and a model (P ER SE).",
      "processing_time": 27.224292993545532,
      "citing_paper_id": "263671864",
      "cited_paper_id": null
    },
    {
      "context_text": "Based on those criteria, we select two famous face datasets CelebA-HQ [28] and VGGFace2 [11].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CelebA-HQ",
        "VGGFace2"
      ],
      "dataset_descriptions": {
        "CelebA-HQ": "Used to train models for high-quality face recognition, focusing on facial attributes and variations in pose and age.",
        "VGGFace2": "Applied to recognize faces across different poses and ages, enhancing the robustness of face recognition models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, CelebA-HQ and VGGFace2, which are used for recognizing faces across pose and age. These datasets are clearly identified and relevant to the research topic of personalized text generation.",
      "processing_time": 44.4588680267334,
      "citing_paper_id": "257766375",
      "cited_paper_id": 216009
    },
    {
      "context_text": "VGGFace2 [11] contains around 3 .",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "VGGFace2"
      ],
      "dataset_descriptions": {
        "VGGFace2": "Used for recognizing faces across pose and age, but the specific research context and methodology are not detailed in the provided citation."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions VGGFace2, which is a known dataset for face recognition. However, the context does not provide enough information about how it is used in the current research.",
      "processing_time": 36.74872350692749,
      "citing_paper_id": "257766375",
      "cited_paper_id": 216009
    },
    {
      "context_text": "1 and on the VGGFace2 dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "VGGFace2"
      ],
      "dataset_descriptions": {
        "VGGFace2": "Used to train and evaluate face recognition models, focusing on recognizing faces across different poses and ages."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'VGGFace2 dataset', which is a specific, verifiable dataset used for face recognition research. The title confirms it is a dataset.",
      "processing_time": 35.441187620162964,
      "citing_paper_id": "257766375",
      "cited_paper_id": 216009
    },
    {
      "context_text": "Based on those criteria, we select two famous face datasets CelebA-HQ [29] and VGGFace2 [11].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CelebA-HQ",
        "VGGFace2"
      ],
      "dataset_descriptions": {
        "CelebA-HQ": "Used to recognize faces across pose and age, focusing on high-quality images and diverse attributes for personalized text generation.",
        "VGGFace2": "Used to recognize faces across pose and age, emphasizing large-scale and diverse facial images for improving face recognition accuracy in personalized applications."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, CelebA-HQ and VGGFace2, which are used for recognizing faces across pose and age. These datasets are clearly identified and relevant to the research topic.",
      "processing_time": 45.72652053833008,
      "citing_paper_id": "257766375",
      "cited_paper_id": 216009
    },
    {
      "context_text": "For each of 50 identities in VGGFace2, we train two DreamBooth models on (1) origi-2122 Users are asked to input the numbers of good-quality and correct-identity images for each set.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "VGGFace2"
      ],
      "dataset_descriptions": {
        "VGGFace2": "Used to train DreamBooth models for recognizing faces across pose and age, focusing on personalized identity representation using high-quality images."
      },
      "confidence_score": 1.0,
      "reasoning": "VGGFace2 is mentioned as a dataset used for training models, which aligns with the context of personalized text generation.",
      "processing_time": 35.64200735092163,
      "citing_paper_id": "257766375",
      "cited_paper_id": 216009
    },
    {
      "context_text": "Combining them, [16] is an ensemble of various attacks that are commonly used as a benchmark metric, being able to break through gradient obfuscation [7] with the expectation-over-transformation technique [8].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 29.261895418167114,
      "citing_paper_id": "257766375",
      "cited_paper_id": 2645819
    },
    {
      "context_text": "Combining them, [16] is an ensemble of various attacks that are commonly used as a benchmark metric, being able to break through gradient obfuscation [7] with the expectation-over-transformation technique [8].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 29.261895418167114,
      "citing_paper_id": "257766375",
      "cited_paper_id": 3310672
    },
    {
      "context_text": "Combining them, [16] is an ensemble of various attacks that are commonly used as a benchmark metric, being able to break through gradient obfuscation [7] with the expectation-over-transformation technique [8].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 29.261895418167114,
      "citing_paper_id": "257766375",
      "cited_paper_id": 211818320
    },
    {
      "context_text": "For black-box attacks, where the adversary does not have full access to the model weights and gradients, [53] estimates the gradient using sampling methods, while [10, 14, 6] aim to synthesize a close-by example by searching for the classification boundary, then finding the direction to traverse towards a good adversarial example.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for black-box attacks but does not mention any specific datasets. The focus is on techniques and approaches rather than data sources.",
      "processing_time": 28.6981303691864,
      "citing_paper_id": "257766375",
      "cited_paper_id": 3639844
    },
    {
      "context_text": "…with different approaches started to emerge, with more notable ones including: [31, 35] being FGSM’s iterative versions, [12] limiting the adversarial perturbation’s magnitude implicitly using regularization instead of projection, [37] searching for a close-by decision boundary to cross, etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 29.657765865325928,
      "citing_paper_id": "257766375",
      "cited_paper_id": 12387176
    },
    {
      "context_text": "Inspired by DeepFakes’s prevention studies [57, 43, 56, 25, 55], we propose to pro-actively defend each user from the DreamBooth threat by injecting subtle adversarial noise into their images before publishing.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other studies on DeepFakes prevention. No verifiable resources are identified.",
      "processing_time": 29.254464626312256,
      "citing_paper_id": "257766375",
      "cited_paper_id": 211818224
    },
    {
      "context_text": "Within a few years, denoising diffusion models [23, 54, 43] have revolutionized image generation studies, allowing producing images with realistic quality and diverse content [19].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and their impact on image generation. No verifiable resources are identified.",
      "processing_time": 29.252347469329834,
      "citing_paper_id": "257766375",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "Within a few years, denoising diffusion models [23, 54, 43] have revolutionized image generation studies, allowing producing images with realistic quality and diverse content [19].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and their impact on image generation. No verifiable resources are identified.",
      "processing_time": 29.252347469329834,
      "citing_paper_id": "257766375",
      "cited_paper_id": 234357997
    },
    {
      "context_text": "Diffusion models are a type of generative models [53, 23] that decouple the role of generation into two opposing procedures: a forward process and a backward process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only generative models and their processes.",
      "processing_time": 26.990006923675537,
      "citing_paper_id": "257766375",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "Images generated from successfully disrupted DreamBooth models may have no detectable face, and we measure that rate, called Face Detection Failure Rate (FDFR), using RetinaFace detector [17].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the RetinaFace detector but does not refer to a specific dataset. The context is about using RetinaFace to measure the Face Detection Failure Rate (FDFR).",
      "processing_time": 32.11304330825806,
      "citing_paper_id": "257766375",
      "cited_paper_id": 219964874
    },
    {
      "context_text": "These models can be grouped into four main categories: auto-regressive [61], mask-prediction [13], GAN-based [48] and diffusion-based approaches, all of which show astounding qualitative and quantitative results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of models. There are no verifiable resources or datasets mentioned.",
      "processing_time": 29.667620182037354,
      "citing_paper_id": "257766375",
      "cited_paper_id": 249926846
    },
    {
      "context_text": "Large models [41, 3, 43, 47, 9] can produce photo-realistic or artistic images just from simple text description inputs.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the capability of large models to generate images from text. No verifiable resources are identified.",
      "processing_time": 30.72546911239624,
      "citing_paper_id": "257766375",
      "cited_paper_id": 253254800
    },
    {
      "context_text": "Large models [41, 3, 43, 47, 9] can produce photo-realistic or artistic images just from simple text description inputs.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the capability of large models to generate images from text. No verifiable resources are identified.",
      "processing_time": 30.72546911239624,
      "citing_paper_id": "257766375",
      "cited_paper_id": null
    },
    {
      "context_text": "However, the implementation of most prominent methods [47, 9] are not publicly available.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that implementations of methods are not publicly available.",
      "processing_time": 27.545297861099243,
      "citing_paper_id": "257766375",
      "cited_paper_id": 253254800
    },
    {
      "context_text": "Among these methods, diffusion-based models [43, 47, 9, 38, 42] have exhibited an exceptional capacity for generating high-quality and easily modifiable images, leading to their widespread adoption in text-to-image synthesis.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the capabilities of diffusion-based models in text-to-image synthesis.",
      "processing_time": 28.425577878952026,
      "citing_paper_id": "257766375",
      "cited_paper_id": 253254800
    },
    {
      "context_text": "For better trade-off be-tween efficiency and fidelity, following-up works either introduce coarse-to-fine generation process like Imagen [47] and eDiff-I [9] or work on latent space like LDM [43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the methodologies used for text-to-image generation.",
      "processing_time": 30.27860403060913,
      "citing_paper_id": "257766375",
      "cited_paper_id": 253254800
    },
    {
      "context_text": "Similar to our goals, two concurrent works, GLAZE [51] and AdvDM [33], aim to protect against personalized text-to-image diffusion models exploited without consent using image cloaking.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only concurrent works with similar goals. The context focuses on methods and approaches rather than datasets.",
      "processing_time": 30.49620223045349,
      "citing_paper_id": "257766375",
      "cited_paper_id": 256662278
    },
    {
      "context_text": "Besides, ControlNet [62] offers extra options to control the generation outputs, further boosting the power of the text-to-image models and bringing them closer to mass users.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (ControlNet) for controlling text-to-image generation outputs.",
      "processing_time": 29.627880096435547,
      "citing_paper_id": "257766375",
      "cited_paper_id": 256827727
    },
    {
      "context_text": "Besides, ControlNet [59] offers extra options to control the DSLR portrait Perturbed images in front of Eiffel Tower Clean images Personalized text-to-image",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to a method (ControlNet) and a general concept (personalized text-to-image) without naming a specific dataset.",
      "processing_time": 32.83066964149475,
      "citing_paper_id": "257766375",
      "cited_paper_id": 256827727
    },
    {
      "context_text": "Within the context of diffusion models, previous research has focused on adapting a pre-2117 trained model to create fresh images based on a particular target idea using natural language cues.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach using diffusion models and natural language cues.",
      "processing_time": 29.21998929977417,
      "citing_paper_id": "257766375",
      "cited_paper_id": null
    },
    {
      "context_text": "Alternatively, Stable Diffusion has released the pre-trained weights based on Hugging Face implementation [57] to facilitate research in the community.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only pre-trained weights and an implementation. There are no verifiable resources that meet the criteria.",
      "processing_time": 30.693060636520386,
      "citing_paper_id": "257766375",
      "cited_paper_id": null
    },
    {
      "context_text": "StableDiffusion [4], primarily based on LDM, is the first open-source large model of this type, further boosting the widespread applications of text-to-image synthesis.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their applications.",
      "processing_time": 27.539798736572266,
      "citing_paper_id": "257766375",
      "cited_paper_id": null
    },
    {
      "context_text": "It aims to translate structured biography information from the Wikipedia into a paragraph of description.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general task of translating structured biography information from Wikipedia. No clear, verifiable dataset names are provided.",
      "processing_time": 31.795648097991943,
      "citing_paper_id": "258187154",
      "cited_paper_id": 1238927
    },
    {
      "context_text": "We use two table-to-text datasets: Taobao Advertising [6] in Chinese, and WikiBio [15] in English.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Taobao Advertising",
        "WikiBio"
      ],
      "dataset_descriptions": {
        "Taobao Advertising": "Used for generating text from structured data in Chinese, focusing on advertising content to enhance user engagement and personalization.",
        "WikiBio": "Used for generating biographical text from structured data in English, enhancing the readability and coherence of Wikipedia biography entries."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, 'Taobao Advertising' and 'WikiBio', which are used for table-to-text generation in different languages.",
      "processing_time": 42.39032316207886,
      "citing_paper_id": "258187154",
      "cited_paper_id": 1238927
    },
    {
      "context_text": ", table-text pairs collected from Taobao [5] or Wikipedia [15]) and persona information (e.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "table-text pairs collected from Taobao",
        "Wikipedia"
      ],
      "dataset_descriptions": {
        "table-text pairs collected from Taobao": "Used to collect structured data for neural text generation, focusing on generating biographies from tabular information.",
        "Wikipedia": "Used as a source of structured data and textual content for training and evaluating neural text generation models in the biography domain."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'table-text pairs collected from Taobao' and 'Wikipedia', which are specific sources of data. However, these are not clearly identified as datasets with clear provenance or public accessibility.",
      "processing_time": 46.882121324539185,
      "citing_paper_id": "258187154",
      "cited_paper_id": 1238927
    },
    {
      "context_text": "We conduct our experiments on two table-to-text datasets, Taobao Advertising [6] and WikiBio [15].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Taobao Advertising",
        "WikiBio"
      ],
      "dataset_descriptions": {
        "Taobao Advertising": "Used to generate personalized text from structured advertising data, focusing on converting tabular information into natural language descriptions.",
        "WikiBio": "Applied to generate biographical text from structured Wikipedia data, emphasizing the conversion of tabular information into coherent and informative narratives."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, 'Taobao Advertising' and 'WikiBio', which are used for table-to-text experiments. These datasets are clearly named and relevant to the research topic of personalized text generation.",
      "processing_time": 46.12528896331787,
      "citing_paper_id": "258187154",
      "cited_paper_id": 1238927
    },
    {
      "context_text": "Besides, the English dataset is WikiBio, a classical benchmark in the table-to-text generation task.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WikiBio"
      ],
      "dataset_descriptions": {
        "WikiBio": "Used as a classical benchmark for table-to-text generation, focusing on generating biographical texts from structured data."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'WikiBio' as a classical benchmark for table-to-text generation, which is relevant to personalized text generation.",
      "processing_time": 35.846521615982056,
      "citing_paper_id": "258187154",
      "cited_paper_id": 1238927
    },
    {
      "context_text": "Instead, our method will allow developers to diversify the system with persona characteristics from independent tabular data (e.g., table-text pairs collected from Taobao [5] or Wikipedia [15]) and persona information (e.g., user profiles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'table-text pairs collected from Taobao' and 'Wikipedia', which are specific sources of data. However, they are not referred to as datasets, databases, or similar terms, and the context does not provide a clear identifier or specific usage.",
      "processing_time": 35.5795042514801,
      "citing_paper_id": "258187154",
      "cited_paper_id": 1238927
    },
    {
      "context_text": "…aiming at generating natural and informative context from structured tabular data [1, 2, 3, 4], has gained increasing attention for its tremendous value in many real applications such as advertising text generation on E-commerce [5, 6, 7] or headline generation on News recommendation [8, 9].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of personalized text generation. No dataset names are present in the text.",
      "processing_time": 31.78179430961609,
      "citing_paper_id": "258187154",
      "cited_paper_id": 88524997
    },
    {
      "context_text": "Instead, our method will allow developers to diversify the system with persona characteristics from independent tabular data (e.g., table-text pairs collected from Taobao [5] or Wikipedia [15]) and persona information (e.g., user proﬁles).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'table-text pairs collected from Taobao' and 'Wikipedia', which are specific sources of data. However, they are not referred to as datasets, databases, or similar terms, and the context does not provide a clear identifier or specific usage.",
      "processing_time": 36.020023584365845,
      "citing_paper_id": "258187154",
      "cited_paper_id": 88524997
    },
    {
      "context_text": "Table-to-text generation, aiming at generating natural and informative context from structured tabular data [1, 2, 3, 4], has gained increasing attention for its tremendous value in many real applications such as advertising text generation on E-commerce [5, 6, 7] or headline generation on News…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general application area of table-to-text generation. No verifiable resources are named.",
      "processing_time": 32.607553243637085,
      "citing_paper_id": "258187154",
      "cited_paper_id": 174801388
    },
    {
      "context_text": "Table-to-text generation, aiming at generating natural and informative context from structured tabular data [1, 2, 3, 4], has gained increasing attention for its tremendous value in many real applications such as advertising text generation on E-commerce [5, 6, 7] or headline generation on News…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general application area of table-to-text generation. No verifiable resources are named.",
      "processing_time": 32.607553243637085,
      "citing_paper_id": "258187154",
      "cited_paper_id": 231846815
    },
    {
      "context_text": "Previous work [12, 13, 14] tried to diversify the table-to-text generation system with content style by directly copying Fig.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to previous work on table-to-text generation systems. No clear, verifiable resources are identified.",
      "processing_time": 33.97610664367676,
      "citing_paper_id": "258187154",
      "cited_paper_id": 211020900
    },
    {
      "context_text": "Previous work [12, 13, 14] tried to diversify the table-to-text generation system with content style by directly copying Fig.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to previous work on table-to-text generation systems. No clear, verifiable resources are identified.",
      "processing_time": 33.97610664367676,
      "citing_paper_id": "258187154",
      "cited_paper_id": 232092620
    },
    {
      "context_text": ", 2020), leveraging attention mechanisms (Xu et al., 2018) or cross-modal contrastive approaches (Zhang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 35.08538365364075,
      "citing_paper_id": "251253049",
      "cited_paper_id": 8858625
    },
    {
      "context_text": "Typically, a conditional model is trained to reproduce samples from given paired image-caption datasets (Zhu et al., 2019; Tao et al., 2020), leveraging attention mechanisms (Xu et al., 2018) or cross-modal contrastive approaches (Zhang et al., 2021; Ye et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'paired image-caption datasets' but does not specify any particular dataset names. The cited papers do not provide additional specific dataset names either.",
      "processing_time": 36.81939172744751,
      "citing_paper_id": "251253049",
      "cited_paper_id": 8858625
    },
    {
      "context_text": "Typically, a conditional model is trained to reproduce samples from given paired image-caption datasets (Zhu et al., 2019; Tao et al., 2020), leveraging attention mechanisms (Xu et al., 2018) or cross-modal contrastive approaches (Zhang et al., 2021; Ye et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'paired image-caption datasets' but does not specify any particular dataset names. The cited papers do not provide additional specific dataset names either.",
      "processing_time": 36.81939172744751,
      "citing_paper_id": "251253049",
      "cited_paper_id": 91183909
    },
    {
      "context_text": "Typically, a conditional model is trained to reproduce samples from given paired image-caption datasets (Zhu et al., 2019; Tao et al., 2020), leveraging attention mechanisms (Xu et al., 2018) or cross-modal contrastive approaches (Zhang et al., 2021; Ye et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'paired image-caption datasets' but does not specify any particular dataset names. The cited papers do not provide additional specific dataset names either.",
      "processing_time": 36.81939172744751,
      "citing_paper_id": "251253049",
      "cited_paper_id": 231592822
    },
    {
      "context_text": "An encoder E learns to map images x ∈ D x into a spatial latent code z = E ( x ) , regularized through either a KL-divergence loss or through vector quantization (Van Den Oord et al., 2017; Agustsson et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the methodology of mapping images into a spatial latent code using an encoder.",
      "processing_time": 42.36338138580322,
      "citing_paper_id": "251253049",
      "cited_paper_id": 9176830
    },
    {
      "context_text": "An encoder E learns to map images x ∈ Dx into a spatial latent code z = E(x), regularized through either a KL-divergence loss or through vector quantization (Van Den Oord et al., 2017; Agustsson et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the technical aspects of the encoder and regularization techniques.",
      "processing_time": 37.16495394706726,
      "citing_paper_id": "251253049",
      "cited_paper_id": 9176830
    },
    {
      "context_text": "Manipulating images with generative networks often requires one to find a corresponding latent representation of the given image, a process referred to as inversion (Zhu et al., 2016; Xia et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and processes. The context is about generative networks and image manipulation, which does not align with the topic of personalized text generation.",
      "processing_time": 39.55011963844299,
      "citing_paper_id": "251253049",
      "cited_paper_id": 14924561
    },
    {
      "context_text": "Manipulating images with generative networks often requires one to ﬁnd a corresponding latent representation of the given image, a process referred to as inversion (Zhu et al., 2016; Xia et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the process of finding a latent representation for images using generative networks.",
      "processing_time": 38.80957746505737,
      "citing_paper_id": "251253049",
      "cited_paper_id": 14924561
    },
    {
      "context_text": "Manipulating images with generative networks often requires one to ﬁnd a corresponding latent representation of the given image, a process referred to as inversion (Zhu et al., 2016; Xia et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the process of finding a latent representation for images using generative networks.",
      "processing_time": 38.80957746505737,
      "citing_paper_id": "251253049",
      "cited_paper_id": 231603119
    },
    {
      "context_text": "Personalized models are typically found in the realms of recommendation systems (Ben-hamdi et al., 2017; Amat et al., 2018; Martinez et al., 2009; Cho et al., 2002) or in federated learning (Mansour et al., 2020; Jiang et al., 2019; Fallah et al., 2020; Shamsian et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research such as recommendation systems and federated learning. No verifiable resources are identified.",
      "processing_time": 40.054625034332275,
      "citing_paper_id": "251253049",
      "cited_paper_id": 52895470
    },
    {
      "context_text": "Personalized models are typically found in the realms of recommendation systems (Ben-hamdi et al., 2017; Amat et al., 2018; Martinez et al., 2009; Cho et al., 2002) or in federated learning (Mansour et al., 2020; Jiang et al., 2019; Fallah et al., 2020; Shamsian et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research such as recommendation systems and federated learning. No verifiable resources are identified.",
      "processing_time": 40.054625034332275,
      "citing_paper_id": "251253049",
      "cited_paper_id": 203591432
    },
    {
      "context_text": "Personalized models are typically found in the realms of recommendation systems (Ben-hamdi et al., 2017; Amat et al., 2018; Martinez et al., 2009; Cho et al., 2002) or in federated learning (Mansour et al., 2020; Jiang et al., 2019; Fallah et al., 2020; Shamsian et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research such as recommendation systems and federated learning. No verifiable resources are identified.",
      "processing_time": 40.054625034332275,
      "citing_paper_id": "251253049",
      "cited_paper_id": 211171538
    },
    {
      "context_text": "Personalized models are typically found in the realms of recommendation systems (Ben-hamdi et al., 2017; Amat et al., 2018; Martinez et al., 2009; Cho et al., 2002) or in federated learning (Mansour et al., 2020; Jiang et al., 2019; Fallah et al., 2020; Shamsian et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research such as recommendation systems and federated learning. No verifiable resources are identified.",
      "processing_time": 40.054625034332275,
      "citing_paper_id": "251253049",
      "cited_paper_id": 211296702
    },
    {
      "context_text": "Personalized models are typically found in the realms of recommendation systems (Benhamdi et al., 2017; Amat et al., 2018; Martinez et al., 2009; Cho et al., 2002) or in federated learning (Mansour et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research such as recommendation systems and federated learning. No verifiable resources are named.",
      "processing_time": 40.36319160461426,
      "citing_paper_id": "251253049",
      "cited_paper_id": 52895470
    },
    {
      "context_text": "Typical text encoder models, such as BERT, begin with a text processing step (Figure 2, left).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BERT) which is excluded according to the rules.",
      "processing_time": 38.80297803878784,
      "citing_paper_id": "251253049",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Here, c θ is realized through a BERT (Devlin et al., 2018) text encoder, with y being a text prompt.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BERT) which is excluded according to the rules.",
      "processing_time": 38.977516412734985,
      "citing_paper_id": "251253049",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Typically, a conditional model is trained to reproduce samples from given paired image-caption datasets (Zhu et al., 2019; Tao et al., 2020), leveraging attention mechanisms (Xu et al.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'paired image-caption datasets' but does not specify any particular dataset names. The citation is used to support the methodology of training conditional models.",
      "processing_time": 41.26883149147034,
      "citing_paper_id": "251253049",
      "cited_paper_id": 91183909
    },
    {
      "context_text": "We represent a new embedding vector with a new pseudo-word (Rathvon, 2004) which we denote by S∗.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving a new pseudo-word representation.",
      "processing_time": 38.61529350280762,
      "citing_paper_id": "251253049",
      "cited_paper_id": 142861440
    },
    {
      "context_text": "There, it is typical to delicately tune a model to better reconstruct specific faces or scenes (Bau et al., 2019; Roich et al., 2021; Alaluf et al., 2021; Nitzan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to model tuning techniques. No verifiable resources are identified.",
      "processing_time": 39.82384705543518,
      "citing_paper_id": "251253049",
      "cited_paper_id": 196834421
    },
    {
      "context_text": "There, it is typical to delicately tune a model to better reconstruct specific faces or scenes (Bau et al., 2019; Roich et al., 2021; Alaluf et al., 2021; Nitzan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to model tuning techniques. No verifiable resources are identified.",
      "processing_time": 39.82384705543518,
      "citing_paper_id": "251253049",
      "cited_paper_id": 235390635
    },
    {
      "context_text": "There, it is typical to delicately tune a model to better reconstruct specific faces or scenes (Bau et al., 2019; Roich et al., 2021; Alaluf et al., 2021; Nitzan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to model tuning techniques. No verifiable resources are identified.",
      "processing_time": 39.82384705543518,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": "There it is typical to apply a delicate tuning of a generative model to better reconstruct speciﬁc faces or scenes (Bau et al., 2019; Roich et al., 2021; Alaluf et al., 2021; Dinh et al., 2022; Cao et al., 2022; Nitzan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative models and their applications. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 41.07095980644226,
      "citing_paper_id": "251253049",
      "cited_paper_id": 196834421
    },
    {
      "context_text": "There it is typical to apply a delicate tuning of a generative model to better reconstruct speciﬁc faces or scenes (Bau et al., 2019; Roich et al., 2021; Alaluf et al., 2021; Dinh et al., 2022; Cao et al., 2022; Nitzan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative models and their applications. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 41.07095980644226,
      "citing_paper_id": "251253049",
      "cited_paper_id": 235390635
    },
    {
      "context_text": "There it is typical to apply a delicate tuning of a generative model to better reconstruct speciﬁc faces or scenes (Bau et al., 2019; Roich et al., 2021; Alaluf et al., 2021; Dinh et al., 2022; Cao et al., 2022; Nitzan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative models and their applications. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 41.07095980644226,
      "citing_paper_id": "251253049",
      "cited_paper_id": 244772984
    },
    {
      "context_text": "There it is typical to apply a delicate tuning of a generative model to better reconstruct speciﬁc faces or scenes (Bau et al., 2019; Roich et al., 2021; Alaluf et al., 2021; Dinh et al., 2022; Cao et al., 2022; Nitzan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative models and their applications. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 41.07095980644226,
      "citing_paper_id": "251253049",
      "cited_paper_id": 250956830
    },
    {
      "context_text": "Pivotal Tuning In the ﬁeld of GAN inversion, it has been shown (Roich et al., 2021; Bau et al., 2019) that one may largely avoid the reconstruction-editability tradeoff using a two-stage optimization process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and findings related to GAN inversion and optimization processes.",
      "processing_time": 39.527015686035156,
      "citing_paper_id": "251253049",
      "cited_paper_id": 196834421
    },
    {
      "context_text": "Pivotal Tuning In the ﬁeld of GAN inversion, it has been shown (Roich et al., 2021; Bau et al., 2019) that one may largely avoid the reconstruction-editability tradeoff using a two-stage optimization process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and findings related to GAN inversion and optimization processes.",
      "processing_time": 39.527015686035156,
      "citing_paper_id": "251253049",
      "cited_paper_id": 235390635
    },
    {
      "context_text": "In the GAN literature, this inversion is done through either an optimization-based technique (Abdal et al., 2019, 2020; Zhu et al., 2020b; Gu et al., 2020) or by using an encoder (Richardson et al., 2020; Zhu et al., 2020a; Pidhorskyi et al., 2020; Tov et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for GAN inversion, which is not directly related to datasets. No specific datasets are mentioned or used in the described research.",
      "processing_time": 41.494049072265625,
      "citing_paper_id": "251253049",
      "cited_paper_id": 209377041
    },
    {
      "context_text": "In the GAN literature, this inversion is done through either an optimization-based technique (Abdal et al., 2019, 2020; Zhu et al., 2020b; Gu et al., 2020) or by using an encoder (Richardson et al., 2020; Zhu et al., 2020a; Pidhorskyi et al., 2020; Tov et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for GAN inversion, which is not directly related to datasets. No specific datasets are mentioned or used in the described research.",
      "processing_time": 41.494049072265625,
      "citing_paper_id": "251253049",
      "cited_paper_id": 214743564
    },
    {
      "context_text": "In the GAN literature, this inversion is done through either an optimization-based technique (Abdal et al., 2019, 2020; Zhu et al., 2020b; Gu et al., 2020) or by using an encoder (Richardson et al., 2020; Zhu et al., 2020a; Pidhorskyi et al., 2020; Tov et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for GAN inversion, which is not directly related to datasets. No specific datasets are mentioned or used in the described research.",
      "processing_time": 41.494049072265625,
      "citing_paper_id": "251253049",
      "cited_paper_id": 215548657
    },
    {
      "context_text": "In the GAN literature, this inversion is done through either an optimization-based technique (Abdal et al., 2019, 2020; Zhu et al., 2020b; Gu et al., 2020) or by using an encoder (Richardson et al., 2020; Zhu et al., 2020a; Pidhorskyi et al., 2020; Tov et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for GAN inversion, which is not directly related to datasets. No specific datasets are mentioned or used in the described research.",
      "processing_time": 41.494049072265625,
      "citing_paper_id": "251253049",
      "cited_paper_id": 229212848
    },
    {
      "context_text": "In the GAN literature, this inversion is done through either an optimization-based technique (Abdal et al., 2019, 2020; Zhu et al., 2020b; Gu et al., 2020) or by using an encoder (Richardson et al., 2020; Zhu et al., 2020a; Pidhorskyi et al., 2020; Tov et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for GAN inversion, which is not directly related to datasets. No specific datasets are mentioned or used in the described research.",
      "processing_time": 41.494049072265625,
      "citing_paper_id": "251253049",
      "cited_paper_id": 231802331
    },
    {
      "context_text": "Here, we examine these choices in light of the GAN inversion literature and discover that many core premises (such as a distortion-editability tradeoff (Tov et al., 2021; Zhu et al., 2020b)) also exist in the textual embedding space.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to literature and concepts. No verifiable resources are identified.",
      "processing_time": 40.15426993370056,
      "citing_paper_id": "251253049",
      "cited_paper_id": 214743564
    },
    {
      "context_text": "Here, we examine these choices in light of the GAN inversion literature and discover that many core premises (such as a distortion-editability tradeoff (Tov et al., 2021; Zhu et al., 2020b)) also exist in the textual embedding space.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to literature and concepts. No verifiable resources are identified.",
      "processing_time": 40.15426993370056,
      "citing_paper_id": "251253049",
      "cited_paper_id": 229212848
    },
    {
      "context_text": "Here, we examine these choices in light of the GAN inversion literature and discover that many core premises (such as a distortion-editability tradeoff (Tov et al., 2021; Zhu et al., 2020b)) also exist in the textual embedding space.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to literature and concepts. No verifiable resources are identified.",
      "processing_time": 40.15426993370056,
      "citing_paper_id": "251253049",
      "cited_paper_id": 231802331
    },
    {
      "context_text": ", 2021), a recently introduced class of Denoising Diffusion Probabilistic Models (DDPMs) (Ho et al., 2020) that operate in the latent space of an autoencoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is about DDPMs and their operation in the latent space of an autoencoder.",
      "processing_time": 42.684531450271606,
      "citing_paper_id": "251253049",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "We implement our method over Latent Diffusion Models (LDMs) (Rombach et al., 2021), a recently introduced class of Denoising Diffusion Probabilistic Models (DDPMs) (Ho et al., 2020) that operate in the latent space of an autoencoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models and methods (LDMs, DDPMs) but does not reference any specific datasets. The focus is on the methodology rather than a particular dataset.",
      "processing_time": 43.16407060623169,
      "citing_paper_id": "251253049",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "We implement our method over Latent Diffusion Models (LDMs) (Rombach et al., 2021), a recently introduced class of Denoising Diffusion Probabilistic Models (DDPMs) (Ho et al., 2020) that operate in the latent space of an autoencoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models and methods (LDMs, DDPMs) but does not reference any specific datasets. The focus is on the methodology rather than a particular dataset.",
      "processing_time": 43.16407060623169,
      "citing_paper_id": "251253049",
      "cited_paper_id": 245335280
    },
    {
      "context_text": ", 2018) or cross-modal contrastive approaches (Zhang et al., 2021; Ye et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 41.46435332298279,
      "citing_paper_id": "251253049",
      "cited_paper_id": 231592822
    },
    {
      "context_text": "Progressive extensions We follow Tov et al. (2021) and consider a progressive multi-vector setup.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or setup from another paper.",
      "processing_time": 39.35106372833252,
      "citing_paper_id": "251253049",
      "cited_paper_id": 231802331
    },
    {
      "context_text": "Regularization Tov et al. (2021) observed that latent codes in the space of a GAN have increased editability when they lie closer to the code distribution which was observed during training.",
      "catation_intent": "findings",
      "resource_type": "finding",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or finding related to GANs and their latent codes.",
      "processing_time": 13.579201936721802,
      "citing_paper_id": "251253049",
      "cited_paper_id": 231802331
    },
    {
      "context_text": "Additional setups and experiments In appendix E, we consider two additional inversion setups: a pivotal tuning approach (Roich et al., 2021), where the model itself is optimized to improve reconstruction, and DALLE-2 (Ramesh et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on experimental setups and inversion approaches.",
      "processing_time": 62.7621283531189,
      "citing_paper_id": "251253049",
      "cited_paper_id": 235390635
    },
    {
      "context_text": "Additional setups In the supplementary, we consider two additional setups for inversion: a pivotal tuning approach (Roich et al., 2021; Bau et al., 2020), where the model itself is optimized to improve reconstruction, and DALLE-2 (Ramesh et al., 2022)’s bipartite inversion process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on describing different inversion setups, including pivotal tuning and DALLE-2's bipartite inversion process.",
      "processing_time": 30.99935817718506,
      "citing_paper_id": "251253049",
      "cited_paper_id": 235390635
    },
    {
      "context_text": "(Roich et al., 2021) (right). s is the guidance scale.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a guidance scale parameter. The cited paper title does not help in identifying a dataset.",
      "processing_time": 14.67929983139038,
      "citing_paper_id": "251253049",
      "cited_paper_id": 235390635
    },
    {
      "context_text": "In addition to the setups outlined in the core paper, we investigated two recent approaches to inversion: Bipartite DDIM-inversion (Ramesh et al., 2022; Dhariwal & Nichol, 2021) and pivotal tuning (Roich et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and research works.",
      "processing_time": 25.07958960533142,
      "citing_paper_id": "251253049",
      "cited_paper_id": 235390635
    },
    {
      "context_text": "Prior work has shown that this embedding space is expressive enough to capture basic image semantics (Co-hen et al., 2022; Tsimpoukelli et al., 2021).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to prior work showing the expressiveness of an embedding space.",
      "processing_time": 25.59450650215149,
      "citing_paper_id": "251253049",
      "cited_paper_id": 235658331
    },
    {
      "context_text": "Prior work has shown that this embedding space is expressive enough to capture basic image semantics (Cohen et al., 2022; Tsimpoukelli et al., 2021).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to prior work showing the expressiveness of an embedding space.",
      "processing_time": 14.966054201126099,
      "citing_paper_id": "251253049",
      "cited_paper_id": 235658331
    },
    {
      "context_text": "Choi et al. (2021) improve inversion by conditioning the denoising process on noised low-pass ﬁlter data from the target image.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'noised low-pass filter data' but does not specify a named dataset. The term is too generic and lacks a clear identifier.",
      "processing_time": 17.43313765525818,
      "citing_paper_id": "251253049",
      "cited_paper_id": 236950721
    },
    {
      "context_text": "More measured approaches freeze the model and train transformation modules to adapt its output when faced with new concepts (Zhou et al., 2021; Gao et al., 2021; Skantze & Willemsen, 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on adapting model outputs for new concepts.",
      "processing_time": 29.092110872268677,
      "citing_paper_id": "251253049",
      "cited_paper_id": 237386023
    },
    {
      "context_text": "(2021), which was pre-trained on the LAION-400M dataset (Schuhmann et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LAION-400M"
      ],
      "dataset_descriptions": {
        "LAION-400M": "Used for pre-training models, focusing on image-text pairs filtered by CLIP, enhancing multimodal understanding and generation capabilities."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions the LAION-400M dataset, which is a specific, verifiable dataset used for pre-training models.",
      "processing_time": 35.7680127620697,
      "citing_paper_id": "251253049",
      "cited_paper_id": 241033103
    },
    {
      "context_text": "We employ the publicly available 1.4 billion parameter text-to-image model of Rombach et al. (2021), which was pre-trained on the LAION-400M dataset (Schuhmann et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LAION-400M"
      ],
      "dataset_descriptions": {
        "LAION-400M": "Used to pre-train a high-resolution image synthesis model, focusing on generating images from textual descriptions using latent diffusion models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the LAION-400M dataset, which is a specific, verifiable dataset used for pre-training a text-to-image model.",
      "processing_time": 24.251769542694092,
      "citing_paper_id": "251253049",
      "cited_paper_id": 241033103
    },
    {
      "context_text": "We employ the publicly available 1.4 billion parameter text-to-image model of Rombach et al. (2021), which was pre-trained on the LAION-400M dataset (Schuhmann et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LAION-400M"
      ],
      "dataset_descriptions": {
        "LAION-400M": "Used to pre-train a high-resolution image synthesis model, focusing on generating images from textual descriptions using latent diffusion models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the LAION-400M dataset, which is a specific, verifiable dataset used for pre-training a text-to-image model.",
      "processing_time": 24.251769542694092,
      "citing_paper_id": "251253049",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "…pure image generation, a large body of work explores the use of text-based interfaces for image editing (Patashnik et al., 2021; Abdal et al., 2021; Avrahami et al., 2022b), generator domain adaptation (Gal et al., 2021; Kim et al., 2022), video manipulation (Tzaban et al., 2022; Bar-Tal et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It discusses various works on text-based interfaces for image editing, generator domain adaptation, and video manipulation, but does not reference any datasets.",
      "processing_time": 20.0498309135437,
      "citing_paper_id": "251253049",
      "cited_paper_id": 244714366
    },
    {
      "context_text": "We note that similar curation processes with larger batches are typically employed in text-conditioned generation works (Avrahami et al., 2022b; Ramesh et al., 2021; Yu et al., 2022), and that one can automate this selection process by using CLIP to Figure 9: Our words can be used with downstream…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It discusses methods and processes but does not reference any named datasets.",
      "processing_time": 27.934110164642334,
      "citing_paper_id": "251253049",
      "cited_paper_id": 244714366
    },
    {
      "context_text": "Here, we perform localized image editing using Blended Latent Diffusion (Avrahami et al., 2022a) rank images.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Blended Latent Diffusion). The context focuses on the use of the method for image editing.",
      "processing_time": 15.20992136001587,
      "citing_paper_id": "251253049",
      "cited_paper_id": 244714366
    },
    {
      "context_text": "Speciﬁcally, we consider the recent Blended Latent Diffusion (Avrahami et al., 2022a) which enables localized text-based editing of images via a mask-based blending process in the latent space of an LDM.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Blended Latent Diffusion) for text-based editing of images.",
      "processing_time": 14.323767185211182,
      "citing_paper_id": "251253049",
      "cited_paper_id": 244714366
    },
    {
      "context_text": "There it is typical to apply a delicate tuning of a generative model to better reconstruct specific faces or scenes (Bau et al., 2019; Roich et al., 2021; Alaluf et al., 2021; Dinh et al., 2022; Cao et al., 2022; Nitzan et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers that discuss generative models. No verifiable resources are identified.",
      "processing_time": 25.783535480499268,
      "citing_paper_id": "251253049",
      "cited_paper_id": 244772984
    },
    {
      "context_text": "…domain adaptation (Gal et al., 2021; Kim et al., 2022), video manipulation (Tzaban et al., 2022; Bar-Tal et al., 2022), motion synthesis (Tevet et al., 2022; Petrovich et al., 2022), style transfer (Kwon & Ye, 2021; Liu et al., 2022) and even texture synthesis for 3D objects (Michel et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various research areas and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 16.609368562698364,
      "citing_paper_id": "251253049",
      "cited_paper_id": 244773443
    },
    {
      "context_text": "…domain adaptation (Gal et al., 2021; Kim et al., 2022), video manipulation (Tzaban et al., 2022; Bar-Tal et al., 2022), motion synthesis (Tevet et al., 2022; Petrovich et al., 2022), style transfer (Kwon & Ye, 2021; Liu et al., 2022) and even texture synthesis for 3D objects (Michel et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various research areas and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 16.609368562698364,
      "citing_paper_id": "251253049",
      "cited_paper_id": 247157966
    },
    {
      "context_text": "…interfaces for image editing (Patashnik et al., 2021; Abdal et al., 2021; Avrahami et al., 2022b), generator domain adaptation (Gal et al., 2021; Kim et al., 2022), video manipulation (Tzaban et al., 2022; Bar-Tal et al., 2022), motion synthesis (Tevet et al., 2022; Petrovich et al., 2022),…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and applications in image and video manipulation.",
      "processing_time": 25.57768678665161,
      "citing_paper_id": "251253049",
      "cited_paper_id": 244909410
    },
    {
      "context_text": "…interfaces for image editing (Patashnik et al., 2021; Abdal et al., 2021; Avrahami et al., 2022b), generator domain adaptation (Gal et al., 2021; Kim et al., 2022), video manipulation (Tzaban et al., 2022; Bar-Tal et al., 2022), motion synthesis (Tevet et al., 2022; Petrovich et al., 2022),…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and applications in image and video manipulation.",
      "processing_time": 25.57768678665161,
      "citing_paper_id": "251253049",
      "cited_paper_id": 250956830
    },
    {
      "context_text": ", 2022b), generator domain adaptation (Gal et al., 2021; Kim et al., 2022), video manipulation (Tzaban et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers and methods. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 16.956660747528076,
      "citing_paper_id": "251253049",
      "cited_paper_id": 244909410
    },
    {
      "context_text": "Such guidance-dependent structure drift has also been demonstrated for GLIDE (Nichol et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions GLIDE but does not refer to it as a dataset. It is a method/model, and thus excluded.",
      "processing_time": 15.218040943145752,
      "citing_paper_id": "251253049",
      "cited_paper_id": 245335086
    },
    {
      "context_text": "More recently, impressive visual results were achieved by leveraging large scale auto-regressive (Ramesh et al., 2021; Yu et al., 2022) or diffusion models (Ramesh et al., 2022; Saharia et al., 2022; Nichol et al., 2021; Rombach et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 17.011024475097656,
      "citing_paper_id": "251253049",
      "cited_paper_id": 245335086
    },
    {
      "context_text": "More recently, impressive visual results were achieved by leveraging large scale auto-regressive (Ramesh et al., 2021; Yu et al., 2022) or diffusion models (Ramesh et al., 2022; Saharia et al., 2022; Nichol et al., 2021; Rombach et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 17.011024475097656,
      "citing_paper_id": "251253049",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Note that our method does not involve the direct optimization of the CLIP-based objective score and, as such, is not sensitive to the adversarial scoring ﬂaws outlined by Nichol et al. (2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method and a reference to a paper discussing adversarial scoring flaws.",
      "processing_time": 27.651490926742554,
      "citing_paper_id": "251253049",
      "cited_paper_id": 245335086
    },
    {
      "context_text": "Large-scale text-to-image models (Rombach et al., 2021; Ramesh et al., 2021; 2022; Nichol et al., 2021; Yu et al., 2022; Saharia et al., 2022) have demonstrated an unprecedented capability to reason over natural language descriptions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their capabilities. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 18.066226959228516,
      "citing_paper_id": "251253049",
      "cited_paper_id": 245335086
    },
    {
      "context_text": "Below, we outline the core details of applying our approach to a speciﬁc class of generative models — Latent Diffusion Models (Rombach et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Latent Diffusion Models).",
      "processing_time": 27.033365964889526,
      "citing_paper_id": "251253049",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Unless otherwise noted, we retain the original hyper-parameter choices of LDM (Rombach et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (LDM) and its hyper-parameter choices. No verifiable resources are referenced.",
      "processing_time": 18.06107997894287,
      "citing_paper_id": "251253049",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Our approach was implemented over LDM (Rombach et al., 2021), the largest publicly available text-to-image model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions LDM, which is a model, not a dataset. No datasets are explicitly mentioned or used in the described research context.",
      "processing_time": 18.060335874557495,
      "citing_paper_id": "251253049",
      "cited_paper_id": 245335280
    },
    {
      "context_text": ", 2022), style transfer (Kwon & Ye, 2021; Liu et al., 2022) and even texture synthesis for 3D objects (Michel et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research areas and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 17.390540838241577,
      "citing_paper_id": "251253049",
      "cited_paper_id": 247157966
    },
    {
      "context_text": "We ﬁnd a new pseudo-word using their approach and use it to synthesize new images by leveraging VQGAN-CLIP (Crowson et al., 2022) and CLIP-Guided Diffusion (Crowson, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to methods and models (VQGAN-CLIP and CLIP-Guided Diffusion) rather than datasets.",
      "processing_time": 20.014347553253174,
      "citing_paper_id": "251253049",
      "cited_paper_id": 248239727
    },
    {
      "context_text": "We ﬁnd a new pseudo-word using their approach and use it to synthesize new images by leveraging VQGAN-CLIP (Crowson et al., 2022) and CLIP-Guided Diffusion (Crowson, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to methods and models (VQGAN-CLIP and CLIP-Guided Diffusion) rather than datasets.",
      "processing_time": 20.014347553253174,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": "We ﬁnd a new pseudo-word using their approach and use it to synthesize new images by leveraging VQGAN-CLIP (Crowson et al., 2022) and CLIP-Guided Diffusion (Crowson, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to methods and models (VQGAN-CLIP and CLIP-Guided Diffusion) rather than datasets.",
      "processing_time": 20.014347553253174,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": "We find a new pseudo-word using their approach and use it to synthesize new images with VQGAN-CLIP (Crowson et al., 2022) and CLIP-Guided Diffusion (Crowson, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on synthesizing new images using VQGAN-CLIP and CLIP-Guided Diffusion, which are models.",
      "processing_time": 20.550382614135742,
      "citing_paper_id": "251253049",
      "cited_paper_id": 248239727
    },
    {
      "context_text": "As a second baseline, we apply the CLIP-guided models of Crowson et al . while trying to jointly minimize the CLIP-based distances to both the training set images and to the target text (VQGAN-CLIP) or by initializing the optimization with an input image from our set (Guided Diffusion).",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'training set images' and 'input image from our set', which are too generic and do not provide specific identifiers. No other datasets are mentioned.",
      "processing_time": 31.27674102783203,
      "citing_paper_id": "251253049",
      "cited_paper_id": 248239727
    },
    {
      "context_text": "Alternatively, test-time optimization can be used to explore the latent space of pre-trained generators (Crowson et al., 2022; Murdock, 2021; Crowson, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and approaches. The context is about using test-time optimization with pre-trained generators, which does not indicate the use of a specific dataset.",
      "processing_time": 28.834442138671875,
      "citing_paper_id": "251253049",
      "cited_paper_id": 248239727
    },
    {
      "context_text": "Here, we observe that when using LDM’s typical guidance (Ho & Salimans, 2021) scales ( 5 - 10 ), the denoiser network is unable to maintain the original object’s structure through prompt changes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (LDM’s typical guidance) and a model (denoiser network).",
      "processing_time": 14.285338878631592,
      "citing_paper_id": "251253049",
      "cited_paper_id": 249145348
    },
    {
      "context_text": "Re-training a model with an expanded dataset for each new concept is prohibitively expensive, and ﬁne-tuning on few examples typically leads to catastrophic forgetting (Ding et al., 2022; Li et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the challenges of re-training and fine-tuning models.",
      "processing_time": 24.893375873565674,
      "citing_paper_id": "251253049",
      "cited_paper_id": 250644432
    },
    {
      "context_text": "Re-training a model with an expanded dataset for each new concept is prohibitively expensive, and fine-tuning on few examples typically leads to catastrophic forgetting (Ding et al., 2022; Li et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the general problem of re-training and fine-tuning models.",
      "processing_time": 12.715141296386719,
      "citing_paper_id": "251253049",
      "cited_paper_id": 250644432
    },
    {
      "context_text": "…use of text-based interfaces for image editing (Patashnik et al., 2021; Abdal et al., 2021; Avrahami et al., 2022b), generator domain adaptation (Gal et al., 2021; Kim et al., 2022), video manipulation (Tzaban et al., 2022; Bar-Tal et al., 2022), motion synthesis (Tevet et al., 2022; Petrovich…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and applications. There are no clear identifiers for datasets within the text.",
      "processing_time": 13.991076231002808,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": "…use of text-based interfaces for image editing (Patashnik et al., 2021; Abdal et al., 2021; Avrahami et al., 2022b), generator domain adaptation (Gal et al., 2021; Kim et al., 2022), video manipulation (Tzaban et al., 2022; Bar-Tal et al., 2022), motion synthesis (Tevet et al., 2022; Petrovich…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and applications. There are no clear identifiers for datasets within the text.",
      "processing_time": 13.991076231002808,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": "Moving beyond pure image generation, a large body of work explores the use of text-based interfaces for image editing (Patashnik et al., 2021; Abdal et al., 2021; Avrahami et al., 2022b), generator domain adaptation (Gal et al., 2021; Kim et al., 2022), video manipulation (Tzaban et al., 2022;…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only refers to a large body of work and various methods for image and video manipulation.",
      "processing_time": 15.533643245697021,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": "Rather than training conditional models, several approaches employ test-time optimization to explore the latent spaces of a pre-trained generator (Crowson et al., 2022; Murdock, 2021; Crowson, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no verifiable resources or datasets mentioned.",
      "processing_time": 14.004135847091675,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": "Rather than training conditional models, several approaches employ test-time optimization to explore the latent spaces of a pre-trained generator (Crowson et al., 2022; Murdock, 2021; Crowson, 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. There are no verifiable resources or datasets mentioned.",
      "processing_time": 14.004135847091675,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": ", 2022), video manipulation (Tzaban et al., 2022; Bar-Tal et al., 2022), motion synthesis (Tevet et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided citation span does not mention any specific datasets, only references to papers on video manipulation and motion synthesis.",
      "processing_time": 13.508269786834717,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": "…et al., 2021; Abdal et al., 2021; Avrahami et al., 2022b), generator domain adaptation (Gal et al., 2021; Kim et al., 2022), video manipulation (Tzaban et al., 2022; Bar-Tal et al., 2022), motion synthesis (Tevet et al., 2022; Petrovich et al., 2022), style transfer (Kwon & Ye, 2021; Liu et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various research works and methods. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 15.829302549362183,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": ", 2022) and CLIP-Guided Diffusion (Crowson, 2021).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models or methods. There are no verifiable resources that meet the criteria.",
      "processing_time": 16.909605264663696,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": "These tools have been used for artistic creation, as sources of inspiration, and even to design new, physical products (Yacoubian, 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to general uses of tools in artistic creation and design.",
      "processing_time": 14.87324595451355,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": ", 2022b), generator domain adaptation (Gal et al., 2021; Kim et al., 2022) and style transfer (Kwon & Ye, 2021; Liu et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only research areas and methods. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 16.26688504219055,
      "citing_paper_id": "251253049",
      "cited_paper_id": null
    },
    {
      "context_text": "For instance, strategies for improving query formulation (Antonellis et al., 2008), data source purification (Davis, 2006; Yang et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to strategies and methods. No verifiable resources are identified.",
      "processing_time": 14.88433575630188,
      "citing_paper_id": "263909073",
      "cited_paper_id": 60666
    },
    {
      "context_text": "In the works [23], [11], a query for image retrieval is deﬁned to include objects, attributes of objects, and relations between objects.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept of a query for image retrieval. No verifiable resources are identified.",
      "processing_time": 16.261433124542236,
      "citing_paper_id": "263909073",
      "cited_paper_id": 4492210
    },
    {
      "context_text": ", 2008), data source purification (Davis, 2006; Yang et al., 2023a), and ranking optimization (Brin & Page, 1998; Song et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It refers to general concepts and methods such as data source purification and ranking optimization.",
      "processing_time": 16.91713309288025,
      "citing_paper_id": "263909073",
      "cited_paper_id": 59182972
    },
    {
      "context_text": "Given the issue of order sensitivity in in-context learning, as highlighted in the study (Liu et al., 2021), we arrange the demonstration examples in a descending sequence based on their proximity to the input prompt xt.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for arranging demonstration examples. The cited paper title does not introduce a specific dataset either.",
      "processing_time": 15.526135921478271,
      "citing_paper_id": "263909073",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "In dense retrieval, we choose the prompt xt and calculate its textual embedding Em (xt) using CLIP’s text encoder, also the text encoder in Stable Diffusion (Rombach et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 16.950611352920532,
      "citing_paper_id": "263909073",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "users using SD v1-5 (Rombach et al., 2022) and an internal fine-tuned version of SD v1-5.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'SD v1-5' which appears to be a model or method rather than a dataset. No specific dataset is mentioned.",
      "processing_time": 17.342007398605347,
      "citing_paper_id": "263909073",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "We use Stable Diffusion (SD) v1-5 [19] as our text-to-image generation model for all methods.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a model (Stable Diffusion v1-5) but does not refer to any specific dataset. The citation is used to reference the model, not a dataset.",
      "processing_time": 19.70442795753479,
      "citing_paper_id": "263909073",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "In dense retrieval, we choose the prompt x t and calculate its textual embedding Em ( x t ) us-ing CLIP’s text encoder, also the text encoder in Stable Diffusion [20].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 17.337417602539062,
      "citing_paper_id": "263909073",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "We are training increasingly large and powerful foundation models (Brown et al., 2020; Rombach et al., 2022; Gal et al., 2022) through self-supervised learning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is about training large foundation models using self-supervised learning, which does not specify any particular dataset.",
      "processing_time": 19.693021535873413,
      "citing_paper_id": "263909073",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "This technique restructures the query using personalized information to augment the performance of text-to-image generation models (Rombach et al., 2022), a major category of foundational models used for encapsulating image knowledge.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a technique and a model. The cited paper title does not help in identifying a dataset.",
      "processing_time": 18.468422889709473,
      "citing_paper_id": "263909073",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Late developments like stable-diffusion (SD) (Rombach et al., 2022) proposes to generate images effectively in latent space significantly lowering computational costs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (stable-diffusion) and its application in image synthesis.",
      "processing_time": 25.151968479156494,
      "citing_paper_id": "263909073",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "For example, [2] involves pseudo-word embeddings by a set encoder to provide personalization and Textual inversion [4] composes the concept into language sentences and performed as a personalized creation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 26.06427788734436,
      "citing_paper_id": "263909073",
      "cited_paper_id": 247939764
    },
    {
      "context_text": "For example, [2] involves pseudo-word embeddings by a set encoder to provide personalization and Textual inversion [4] composes the concept into language sentences and performed as a personalized creation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 26.06427788734436,
      "citing_paper_id": "263909073",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "DALL-E2 [18] introduces latent diffusion models to generate various images by conditioning on CLIP text latents and CLIP image embeddings generated by a prior model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the introduction of latent diffusion models and the use of CLIP text latents and image embeddings.",
      "processing_time": 29.44252920150757,
      "citing_paper_id": "263909073",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "DALL-E2 (Ramesh et al., 2022) introduces latent diffusion models to generate various images by conditioning on CLIP text latents and CLIP image embeddings generated by a prior model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. DALL-E2 and CLIP are models, not datasets.",
      "processing_time": 26.96238613128662,
      "citing_paper_id": "263909073",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "Imagen [22] discovers that a larger language model with more parameters trained on text-only data improves the quality of text-to-image generation.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a model and its performance. The context focuses on the improvement of text-to-image generation using a larger language model.",
      "processing_time": 28.984986543655396,
      "citing_paper_id": "263909073",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "Increasingly large and powerful foundation models [1, 4, 20] are trained through self-supervised learning.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of training large foundation models through self-supervised learning.",
      "processing_time": 26.753190755844116,
      "citing_paper_id": "263909073",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "[7] optimize prompt through general rewriting.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general method for optimizing prompts.",
      "processing_time": 25.349409103393555,
      "citing_paper_id": "263909073",
      "cited_paper_id": 254853701
    },
    {
      "context_text": "Such hallucination scenarios result in the decrease in terms of ROUGE-L for both Promptist [7] and General PR.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (ROUGE-L) and two methods (Promptist and General PR).",
      "processing_time": 14.848752737045288,
      "citing_paper_id": "263909073",
      "cited_paper_id": 254853701
    },
    {
      "context_text": "Promptist [7] .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not provide any context about the use of datasets, and the title of the cited paper does not mention any specific datasets.",
      "processing_time": 26.973236083984375,
      "citing_paper_id": "263909073",
      "cited_paper_id": 254853701
    },
    {
      "context_text": "Our method outperforms all baseline methods, i.e. Promptist [7] and General PR, on all metrics.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only baseline methods. The context is focused on comparing performance metrics.",
      "processing_time": 26.97045588493347,
      "citing_paper_id": "263909073",
      "cited_paper_id": 254853701
    },
    {
      "context_text": "We compare our method with two baseline methods, namely Promptist [7] and General Prompt Rewriting (General PR).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only baseline methods. There are no verifiable resources that meet the criteria.",
      "processing_time": 27.833757877349854,
      "citing_paper_id": "263909073",
      "cited_paper_id": 254853701
    },
    {
      "context_text": "We can see that Promptist [7] and General PR are slightly better than ‘Shortened Prompt’ in terms of PMS and Image-Align.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model performance comparisons. No verifiable resources are identified.",
      "processing_time": 26.94398522377014,
      "citing_paper_id": "263909073",
      "cited_paper_id": 254853701
    },
    {
      "context_text": "Moreover, an additional encoder is trained to map concept images to its textual representation by [5] and [24].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving an encoder for mapping concept images to textual representations.",
      "processing_time": 27.829450845718384,
      "citing_paper_id": "263909073",
      "cited_paper_id": 257364757
    },
    {
      "context_text": "In search systems, LLMs are used to generate query expansion terms by [10], while they are used to reformulate query by Wang et al. [26] instead.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of LLMs for query expansion and reformulation. No verifiable resources are identified.",
      "processing_time": 30.041118144989014,
      "citing_paper_id": "263909073",
      "cited_paper_id": 258546701
    },
    {
      "context_text": "Signiﬁcant research efforts [10, 29] have been made to comprehend how LPMs react to various prompts, with some studies examining the feasibility of rewriting prompts for speciﬁcity.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general research efforts and studies. There are no clear identifiers for datasets, models, or other resources.",
      "processing_time": 30.27072501182556,
      "citing_paper_id": "263909073",
      "cited_paper_id": 258546701
    },
    {
      "context_text": "These large pretrained models (LPMs) serve as efficient compressors (Delétang et al., 2023), condensing vast amounts of internet data.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only large pretrained models (LPMs) and their role in compressing internet data.",
      "processing_time": 29.748228073120117,
      "citing_paper_id": "263909073",
      "cited_paper_id": 262054258
    },
    {
      "context_text": "Given the issue of order sensitivity in in-context learning, as highlighted in the study [13], we arrange the demonstration examples in a descending sequence based on their proximity to the input prompt x t .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to arranging demonstration examples.",
      "processing_time": 27.281683921813965,
      "citing_paper_id": "263909073",
      "cited_paper_id": null
    },
    {
      "context_text": "In the way of personalized feature embedding, Li [14] et al. proposed a speaker model in 2016, which encoded user profiles as vectors, captured personalized features in the decoding stage and guided response generation, but this training method relied on feature engineering Encoding user vector,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses a method for encoding user profiles as vectors but does not reference a dataset.",
      "processing_time": 30.469666004180908,
      "citing_paper_id": "249918650",
      "cited_paper_id": 44134226
    },
    {
      "context_text": "…codes, but the model requires structural changes to the basic language model, it is difficult to adapt to downstream tasks; Subsequently, Dathathri [12] et al. proposed a PPLM model training framework, which changed the hidden state of the GPT2 language model by training a simple classifier model…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (PPLM) and a model (GPT2).",
      "processing_time": 29.726794719696045,
      "citing_paper_id": "249918650",
      "cited_paper_id": 208617790
    },
    {
      "context_text": "Researchers have extensively explored and enhanced these approaches [4, 12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only refers to general research approaches.",
      "processing_time": 28.744171380996704,
      "citing_paper_id": "269148520",
      "cited_paper_id": 24986117
    },
    {
      "context_text": "Certain studies [1, 3, 33] follow this paradigm but employ techniques like prompt learning [35] or LoRA [16] for fine-tuning the LLM and enhancing recommendation accuracy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only techniques and methods. The context focuses on the use of prompt learning and LoRA for fine-tuning LLMs, which are not datasets.",
      "processing_time": 32.593228816986084,
      "citing_paper_id": "269148520",
      "cited_paper_id": 248834570
    },
    {
      "context_text": "The existing personalization generation methods such as Textual Inversion [6] and DreamBooth [28] train extra embeddings for each user using their historical item images.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'historical item images' but does not specify a named dataset. The cited paper titles do not provide additional dataset names.",
      "processing_time": 30.451746225357056,
      "citing_paper_id": "269148520",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "To address it, we conduct a human evaluation to compare the images generated by our method PMG, Textual Inversion [6], and images without personalization.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to a method (Textual Inversion) and a human evaluation, which do not qualify as datasets.",
      "processing_time": 32.05770182609558,
      "citing_paper_id": "269148520",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "The current approaches to personalized generation, such as Textual Inversion [6] and DreamBooth [28], mainly focus on integrating new characters or image styles into a pre-trained diffusion model using a few images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (Textual Inversion and DreamBooth). The context focuses on the methodologies used for personalizing text-to-image generation.",
      "processing_time": 32.05520534515381,
      "citing_paper_id": "269148520",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "Although it can yield favorable results even without training [7, 15, 32], this approach lacks specific optimization for recommender tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach lacking optimization for recommender tasks.",
      "processing_time": 28.376712322235107,
      "citing_paper_id": "269148520",
      "cited_paper_id": 257766541
    },
    {
      "context_text": "In contrast, TANGO [10] and GILL [18] employ informative hidden embeddings but are not stable and require substantial training to align their embedding space.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (TANGO and GILL). The context is about model performance and training requirements, not dataset usage.",
      "processing_time": 31.388860940933228,
      "citing_paper_id": "269148520",
      "cited_paper_id": 258352270
    },
    {
      "context_text": "In contrast, TANGO [10] and GILL [18] employ informative hidden embeddings but are not stable and require substantial training to align their embedding space.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (TANGO and GILL). The context is about model performance and training requirements, not dataset usage.",
      "processing_time": 31.388860940933228,
      "citing_paper_id": "269148520",
      "cited_paper_id": 258959284
    },
    {
      "context_text": "For the other features, we convert them into text using a caption model (e.g. BLIP-2 [19], CLAP [5]) or using multimodal LLM (e.g. MiniGPT-4 [41], mPLUG-owl [39]) capable of processing multimodal inputs.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions models and methods (BLIP-2, CLAP, MiniGPT-4, mPLUG-owl) but does not refer to any specific datasets. The citation is about using these models to convert features into text, which is not a dataset usage.",
      "processing_time": 34.7347846031189,
      "citing_paper_id": "269148520",
      "cited_paper_id": 258352455
    },
    {
      "context_text": "As for multimodal recommendation, VIP5 [9] builds upon P5 by incorporating item images as visual features and introduces adapters to understand them.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (VIP5) that incorporates item images as visual features. No clear, verifiable dataset names are provided.",
      "processing_time": 32.0465362071991,
      "citing_paper_id": "269148520",
      "cited_paper_id": 258841635
    },
    {
      "context_text": "Following previous studies such as DreamBooth [28] and GILL [18], we use the similarity between the generated results and the preference keywords to measure the degree of personalization, which we call the preference score , and the accuracy score refers to the similarity with the target item…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and scores. The context focuses on the methodology for measuring personalization and accuracy in generated images.",
      "processing_time": 26.019904375076294,
      "citing_paper_id": "269148520",
      "cited_paper_id": 258959284
    },
    {
      "context_text": "In contrast to GILL [18], which solely relies on captions for supervision, we believe that incorporating multimodal supervision (such as real images or audios) is more meaningful and helps to correct deviations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (GILL) and a general approach to supervision. No verifiable resources are identified.",
      "processing_time": 31.37227177619934,
      "citing_paper_id": "269148520",
      "cited_paper_id": 258959284
    },
    {
      "context_text": "Inspired by GILL[18], we incorporate multimodal tokens as learnable parameters into the embedding table and then utilize a linear layer to align the embedding space of the LLM with that of the generator.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for incorporating multimodal tokens into language models.",
      "processing_time": 29.359628915786743,
      "citing_paper_id": "269148520",
      "cited_paper_id": 258959284
    },
    {
      "context_text": "The user behaviors are used to produce preference conditions, including explicit keywords in natural language (named preference keywords) by a frozen LLM and implicit embeddings (named soft preference embeddings) by a tuned LLM for multimodal bias correction [18].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes the use of user behaviors and preference conditions generated by LLMs.",
      "processing_time": 31.145797967910767,
      "citing_paper_id": "269148520",
      "cited_paper_id": 258959284
    },
    {
      "context_text": "Building upon these achievements, researchers have focused on expanding LLMs into the domain of multimodal understanding, with a particular emphasis on image and audio [21, 41].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a focus on multimodal understanding in LLMs.",
      "processing_time": 29.355839490890503,
      "citing_paper_id": "269148520",
      "cited_paper_id": 259165461
    },
    {
      "context_text": "Recommendation [29] is an important means for information retrieval and many studies aim to leverage the exceptional reasoning capabilities of LLMs for recommender systems.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the general concept of recommendation systems and the use of LLMs. There are no clear identifiers for datasets.",
      "processing_time": 32.0185604095459,
      "citing_paper_id": "269148520",
      "cited_paper_id": 261243203
    },
    {
      "context_text": "In our implementation, we utilize a diffusion model, which contains a text encoder and a U-Net [27].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model architecture. There are no verifiable resources that meet the criteria.",
      "processing_time": 30.971015214920044,
      "citing_paper_id": "269148520",
      "cited_paper_id": null
    },
    {
      "context_text": "To enable multimodal generation tasks, LLMs can be integrated with modality-specific generators such as diffusion models [14] or multimodal LLMs [22].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria.",
      "processing_time": 30.968706607818604,
      "citing_paper_id": "269148520",
      "cited_paper_id": null
    },
    {
      "context_text": "Personalized Text Generation is a key research area with applications in search, recommendation, and content creation (Fowler et al., 2015; Xue et al., 2009; Salemi et al., 2024b; Naumov et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general research areas and applications. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 32.84633207321167,
      "citing_paper_id": "275921521",
      "cited_paper_id": 12900424
    },
    {
      "context_text": "Personalized Text Generation is a key research area with applications in search, recommendation, and content creation (Fowler et al., 2015; Xue et al., 2009; Salemi et al., 2024b; Naumov et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general research areas and applications. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 32.84633207321167,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Second, LLMs often lack transparency in their judgments (Hanna and Bojar, 2021; Leiter et al., 2022; Kaster et al., 2021), as their rationales can be opaque or misaligned with human understanding.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses issues with LLMs' transparency and alignment with human understanding.",
      "processing_time": 32.34714937210083,
      "citing_paper_id": "275921521",
      "cited_paper_id": 238582870
    },
    {
      "context_text": "Second, LLMs often lack transparency in their judgments (Hanna and Bojar, 2021; Leiter et al., 2022; Kaster et al., 2021), as their rationales can be opaque or misaligned with human understanding.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses issues with LLMs' transparency and alignment with human understanding.",
      "processing_time": 32.34714937210083,
      "citing_paper_id": "275921521",
      "cited_paper_id": 245855878
    },
    {
      "context_text": "3 Additionally, we use GEMBA (Kocmi and Federmann, 2023), which prompts an LLM to generate a score for a given generated output and reference based on predefined criteria.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "GEMBA is mentioned as a tool used to prompt an LLM to generate scores for generated outputs and references, but it does not fit the criteria for a dataset. It is more likely a method or evaluation framework.",
      "processing_time": 35.120967626571655,
      "citing_paper_id": "275921521",
      "cited_paper_id": 257232490
    },
    {
      "context_text": "…2004), BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), or semantic-based metrics, such as BERTScore (Zhang et al., 2020), GEMBA (Kocmi and Federmann, 2023), and G-EVAL (Liu et al., 2023), have been used to automatically evaluate personalized text generation (Salemi et al.,…",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several evaluation metrics but does not refer to any specific datasets. The context focuses on evaluation methods rather than datasets.",
      "processing_time": 35.11919903755188,
      "citing_paper_id": "275921521",
      "cited_paper_id": 257232490
    },
    {
      "context_text": "…and Lavie, 2005) 0.47 BLEU (Papineni et al., 2002) 0.47 ROUGE-L (Lin, 2004) 0.50 neural-based metrics BERTScore (Zhang et al., 2020) 0.59 GEMBA (Kocmi and Federmann, 2023) 0.69 G-Eval (Liu et al., 2023) 0.69 ExPerT (Content/Style Average) 0.74 Table 1: The alignment between each metric with…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only evaluation metrics and scores. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 36.41331958770752,
      "citing_paper_id": "275921521",
      "cited_paper_id": 257232490
    },
    {
      "context_text": "Salemi et al. (2024b) introduced a Retrieval-Augmented Generation (RAG)-based method for personalizing LLMs and the LaMP benchmark for evaluating short-form personalized generation.",
      "catation_intent": "reusable resource",
      "resource_type": "benchmark",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions LaMP as a benchmark for evaluating personalized generation, which is relevant to the topic of personalized text generation. However, it does not specify LaMP as a dataset but rather as a benchmark.",
      "processing_time": 39.61260914802551,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "…or semantic-based metrics, such as BERTScore (Zhang et al., 2020), GEMBA (Kocmi and Federmann, 2023), and G-EVAL (Liu et al., 2023), have been used to automatically evaluate personalized text generation (Salemi et al., 2024b; Kumar et al., 2024; Li et al., 2023a) in a reference-based setting.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several evaluation metrics but does not refer to any specific datasets. The context focuses on methods and metrics rather than datasets.",
      "processing_time": 37.86583161354065,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Previous reference-based methods (Salemi et al., 2024b; Kumar et al., 2024; Li et al., 2023a) used n-gram based metrics like ROUGE, BLEU, and METEOR, but these fail to capture nuances like individual preferences, style, or context.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only n-gram based metrics which are excluded according to the instructions.",
      "processing_time": 38.157010555267334,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Evaluation of personalized text generation is inherently difficult because what constitutes a preferred output may vary significantly from person to person (Salemi et al., 2024b,a; Kumar et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the challenge of evaluating personalized text generation.",
      "processing_time": 37.61400628089905,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Among the methods that incorporate both style and content, the CONTENT/STYLE AVERAGE achieves the highest alignment (0.74), followed by CONTENT OR STYLE (0.73).",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and their performance metrics.",
      "processing_time": 37.42806673049927,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "To personalize an LLM, we utilize the Retrieval-Augmented Generation (RAG) approach introduced by Salemi et al. (2024b).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Retrieval-Augmented Generation).",
      "processing_time": 38.158851861953735,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "To personalize an LLM, we use Personalized RAG (Salemi et al., 2024b), which involves retrieving information from a user’s profile and incorporating it into the prompt.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Personalized RAG) for personalizing LLMs. No verifiable datasets are referenced.",
      "processing_time": 40.39495825767517,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "• CONTENT/STYLE AVERAGE : The score is the average of the CONTENT and STYLE scores.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only describes a scoring method which is not a verifiable resource.",
      "processing_time": 40.124340295791626,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Recent studies also explore parameter-efficient fine-tuning (Tan et al., 2024) and its integration with RAG (Salemi and Zamani, 2024a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and research works.",
      "processing_time": 11.874449729919434,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Extracting aspects from generated text has been used in tasks like fact-checking (Min et al., 2023) and coverage evaluation (Samarinas et al., 2025).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'fact-checking' and 'coverage evaluation' but does not specify any datasets. The cited papers' titles suggest a focus on evaluating factual precision and coverage in text generation, but no specific datasets are named.",
      "processing_time": 66.13451361656189,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258841470
    },
    {
      "context_text": "Extracting aspects from generated text has been used in tasks like fact-checking (Min et al., 2023) and coverage evaluation (Samarinas et al., 2025).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'fact-checking' and 'coverage evaluation' but does not specify any datasets. The cited papers' titles suggest a focus on evaluating factual precision and coverage in text generation, but no specific datasets are named.",
      "processing_time": 66.13451361656189,
      "citing_paper_id": "275921521",
      "cited_paper_id": 275342326
    },
    {
      "context_text": "Recent LLM-based methods like GEMBA (Kocmi and Feder-mann, 2023), G-Eval (Liu et al., 2023), and IN-STRUCTSCORE (Xu et al., 2023) use LLMs for scoring, often incorporating explanations and pre-defined criteria for multi-dimensional assessments, such as in UniEval (Zhong et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The context focuses on LLM-based evaluation methods for text generation.",
      "processing_time": 16.134768962860107,
      "citing_paper_id": "275921521",
      "cited_paper_id": 258841553
    },
    {
      "context_text": "First, evaluation using capable proprietary LLMs such as Gemini (Gemini-Team, 2024) or GPT-4 (OpenAI, 2024) lacks reproducibility, as they may be updated or disappeared over time.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only proprietary language models. There are no verifiable resources that meet the criteria.",
      "processing_time": 13.840197801589966,
      "citing_paper_id": "275921521",
      "cited_paper_id": 268297180
    },
    {
      "context_text": "Reference-free approaches (Wang et al., 2023, 2024) have explored using LLMs to infer user preferences, but they may struggle with accuracy, as they rely on the model’s assumptions, which may not align with the user’s true intentions (Dong et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only reference-free approaches and LLMs. No verifiable resources are identified.",
      "processing_time": 17.21800184249878,
      "citing_paper_id": "275921521",
      "cited_paper_id": 268297180
    },
    {
      "context_text": "Reference-free approaches (Wang et al., 2023, 2024) have explored using LLMs to infer user preferences, but they may struggle with accuracy, as they rely on the model’s assumptions, which may not align with the user’s true intentions (Dong et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only reference-free approaches and LLMs. No verifiable resources are identified.",
      "processing_time": 17.21800184249878,
      "citing_paper_id": "275921521",
      "cited_paper_id": null
    },
    {
      "context_text": "For example, our experiments with Gemma 2 (Gemma-Team, 2024) (27B) with the prompt presented in Figure 7 Figure 1: ExPerT pipeline: Generated and reference outputs are first decomposed into atomic aspects along with their corresponding evidences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (Gemma 2) which is excluded. No clear dataset names or identifiers are present.",
      "processing_time": 16.109352350234985,
      "citing_paper_id": "275921521",
      "cited_paper_id": 268297180
    },
    {
      "context_text": "Previous studies have shown that evaluating metrics for personalization using human judgment is inherently challenging, often leading to low agreement across annotators and studies (Wang et al., 2023; Dong et al., 2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses challenges in evaluating personalization metrics.",
      "processing_time": 14.4750337600708,
      "citing_paper_id": "275921521",
      "cited_paper_id": null
    },
    {
      "context_text": "Evaluating Personalized Text Generation is challenging, as only the user can truly assess whether a response meets their preferences (Wang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general challenge in evaluating personalized text generation.",
      "processing_time": 12.723769187927246,
      "citing_paper_id": "275921521",
      "cited_paper_id": null
    },
    {
      "context_text": "Term overlap metrics often fail to effectively capture semantic and stylistic similarities (Koh et al., 2022), which are crucial in personalized text generation (Wang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue with term overlap metrics in personalized text generation.",
      "processing_time": 15.391622543334961,
      "citing_paper_id": "275921521",
      "cited_paper_id": null
    },
    {
      "context_text": "Furthermore, the use of rubric-based methods with a personalized-trained network has been explored (Hashemi et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving a personalized-trained network.",
      "processing_time": 13.362420320510864,
      "citing_paper_id": "275921521",
      "cited_paper_id": null
    },
    {
      "context_text": "Reference-free methods, including LLMs as judges (Que et al., 2024; Zheng et al., 2023) and human-LLM collab-orations (Li et al., 2023b), have also emerged but face challenges like biased evaluation (Chen et al., 2024; Stureborg et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only reference-free methods and challenges. There are no clear identifiers for datasets.",
      "processing_time": 13.610509872436523,
      "citing_paper_id": "275921521",
      "cited_paper_id": null
    },
    {
      "context_text": "After the appearance of Transformer[9], people started to use this framework to solve dialogue problems due to its own superiority.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the Transformer framework. No verifiable resources are identified.",
      "processing_time": 15.049148797988892,
      "citing_paper_id": "261081749",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Qian et al.[8] preset the identity file of the robot, and make it consistent with the settings in the relevant Q&A, which would allow the bot to answer with certain identity characteristics.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of an identity file for a chatbot. No clear, verifiable dataset is referenced.",
      "processing_time": 14.11030387878418,
      "citing_paper_id": "261081749",
      "cited_paper_id": 51608471
    },
    {
      "context_text": "Welleck et al.[11] labeled NLI tags on the person-chat dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "person-chat dataset"
      ],
      "dataset_descriptions": {
        "person-chat dataset": "Used to label NLI tags, focusing on dialogue contexts to enhance personalized text generation through natural language inference."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'person-chat dataset' which is a specific dataset used for labeling NLI tags. The dataset is relevant to personalized text generation.",
      "processing_time": 22.726335763931274,
      "citing_paper_id": "261081749",
      "cited_paper_id": 53298765
    },
    {
      "context_text": "Referring to the work of Chang et al.[23], GPT-2 is first fine-tuned and then applied to generate synthetic text through an iterative condition generation process: the initial seed is the obtained character profile, and the LM iteratively conditions the previous output sentence to generate text .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of GPT-2 for text generation. No verifiable resources are identified.",
      "processing_time": 30.158793210983276,
      "citing_paper_id": "261081749",
      "cited_paper_id": 160025533
    },
    {
      "context_text": "Referring to the work of Chang et al.[23], GPT-2 is first fine-tuned and then applied to generate synthetic text through an iterative condition generation process: the initial seed is the obtained character profile, and the LM iteratively conditions the previous output sentence to generate text .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of GPT-2 for text generation. No verifiable resources are identified.",
      "processing_time": 30.158793210983276,
      "citing_paper_id": "261081749",
      "cited_paper_id": 231847372
    },
    {
      "context_text": "GPT-2 is able to improve classification tasks through in-domain text augmentation[22].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (GPT-2) and its capability to improve classification tasks through text augmentation.",
      "processing_time": 27.447521924972534,
      "citing_paper_id": "261081749",
      "cited_paper_id": 160025533
    },
    {
      "context_text": "GPT-2[21] is a pretrained language model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions GPT-2 as a pretrained language model, which is a method/model, not a dataset. No specific dataset is mentioned.",
      "processing_time": 16.80290198326111,
      "citing_paper_id": "261081749",
      "cited_paper_id": 160025533
    },
    {
      "context_text": "Figure 2 shows the generation process of GPT-2.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (GPT-2).",
      "processing_time": 25.571231842041016,
      "citing_paper_id": "261081749",
      "cited_paper_id": 160025533
    },
    {
      "context_text": "In this paper, for persona-sparse data, we implement text augmentation through the generation of vacant tag information, Slot-value replacement, back-translation, and TF-IDF word replacement[6], so that the generated files contain personal information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions text augmentation techniques but does not specify any named datasets. The techniques are described generically without referencing any specific, verifiable dataset.",
      "processing_time": 16.799366235733032,
      "citing_paper_id": "261081749",
      "cited_paper_id": 195873898
    },
    {
      "context_text": "Liu et al.[16] proposed a Transmitter-Receiver framework to adjust dialogue generation through reinforcement learning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or framework. The context focuses on the Transmitter-Receiver framework for dialogue generation.",
      "processing_time": 16.76066780090332,
      "citing_paper_id": "261081749",
      "cited_paper_id": 215745354
    },
    {
      "context_text": "The work most similar to ours is the work of cao et al.[19] They used the method of text augmentation, but also for the problem of limited dialogue data in persona-dense datasets, first distilling redundant information and then amplifying and editing new characters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It focuses on the method of text augmentation and the problem of limited dialogue data in persona-dense datasets.",
      "processing_time": 18.74196195602417,
      "citing_paper_id": "261081749",
      "cited_paper_id": 248299824
    },
    {
      "context_text": "For instance, full fine-tuning (FFT) of a Mistral-7B model (Jiang et al., 2023) in half-precision us-ing a standard Adam optimizer (Kingma and Ba, 2015) requires more than 60GB of GPU memory, which is not available on a consumer-grade machine.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and an optimization method. No verifiable resources are discussed.",
      "processing_time": 24.833940982818604,
      "citing_paper_id": "271218757",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "For instance, full fine-tuning (FFT) of a Mistral-7B model (Jiang et al., 2023) in half-precision us-ing a standard Adam optimizer (Kingma and Ba, 2015) requires more than 60GB of GPU memory, which is not available on a consumer-grade machine.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and an optimization method. No verifiable resources are discussed.",
      "processing_time": 24.833940982818604,
      "citing_paper_id": "271218757",
      "cited_paper_id": null
    },
    {
      "context_text": "In addition to BLEU, ROUGE, and MAUVE, which we present in the main part of the paper, we considered two alternative metrics: BERT-score (Zhang et al., 2020) and METEOR (Lavie and Agarwal, 2007), using the Huggingface implementations for both with default hyperparameters.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions metrics and their implementations but does not refer to any specific datasets. The cited paper titles do not introduce any datasets either.",
      "processing_time": 28.292693376541138,
      "citing_paper_id": "271218757",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "We provide examples in Appendix F, validate BLEU and MAUVE in a human study in Appendix K, and consider BERT-score and METEOR metrics in Appendix J.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only metrics and appendices where they are discussed.",
      "processing_time": 14.441103219985962,
      "citing_paper_id": "271218757",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "In addition, we consider the practical problem of computing requirements, and investigating the effects of parameter-efficient finetuning methods (LoRA (Hu et al., 2021), RoSA (Nikdan et al., 2024)) and of quantization.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (LoRA, RoSA) and the concept of quantization. The context focuses on computational requirements and parameter-efficient finetuning methods.",
      "processing_time": 31.737479209899902,
      "citing_paper_id": "271218757",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "We investigate the standard LoRA method (Hu et al., 2021), and the more recent Robust Adaptation (RoSA) method (Nikdan et al., 2024), which we find to be particularly effective for style transfer.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (LoRA and RoSA) used for style transfer.",
      "processing_time": 15.667614459991455,
      "citing_paper_id": "271218757",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "To measure the quality of style transfer, we use the MAUVE score (Pillutla et al., 2021), introduced to measure the degree of similarity between machine-generated and human-written text.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the MAUVE score but does not refer to a specific dataset. The MAUVE score is a metric, which is excluded according to the instructions.",
      "processing_time": 14.083436965942383,
      "citing_paper_id": "271218757",
      "cited_paper_id": 244488758
    },
    {
      "context_text": "To merge the half-precision RoSA adapters and the 4 -bit base weights, we present a new accurate merging mechanism; for each layer, we dequantize the base weights, add adapters, and quantize the result back to 4 bits using the GPTQ method (Frantar et al., 2022).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on a technique for merging weights and adapters.",
      "processing_time": 17.840588569641113,
      "citing_paper_id": "271218757",
      "cited_paper_id": 253237200
    },
    {
      "context_text": "To organize these efforts, the Language Personalization benchmark (Salemi et al., 2024) was recently introduced; however, it consists only of classification and summarization-style tasks, and does not introduce any benchmarks for long-form text generation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Language Personalization benchmark"
      ],
      "dataset_descriptions": {
        "Language Personalization benchmark": "Used to evaluate personalization in language models, focusing on classification and summarization tasks, but lacking benchmarks for long-form text generation."
      },
      "confidence_score": 0.8,
      "reasoning": "The citation mentions the 'Language Personalization benchmark' but specifies that it does not include benchmarks for long-form text generation, which is relevant to the research topic.",
      "processing_time": 22.401411294937134,
      "citing_paper_id": "271218757",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "A similar trend has been observed in OPPU (Tan et al., 2024), which also deals with personalized finetuning, but they investigate this problem in the context of text condensation, such as article titling and text paraphrasing, while Panza tackles the harder problem of long-form text generation from…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to another paper (OPPU) that investigates a similar problem in a different context. No verifiable resources are named.",
      "processing_time": 26.829906702041626,
      "citing_paper_id": "271218757",
      "cited_paper_id": 267523232
    },
    {
      "context_text": "A similar trend has been observed in OPPU (Tan et al., 2024), which also deals with personalized finetuning, but they investigate this problem in the context of text condensation, such as article titling and text paraphrasing, while Panza tackles the harder problem of long-form text generation from a shorter prompt.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between two research works. The context focuses on the methodologies and problems addressed rather than the datasets used.",
      "processing_time": 15.658743143081665,
      "citing_paper_id": "271218757",
      "cited_paper_id": 267523232
    },
    {
      "context_text": "All results are obtained through the corresponding lm-evaluation-harness framework (Gao et al., 2021), and are reported in Table 9.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a framework used for evaluation. There are no verifiable resources or datasets mentioned.",
      "processing_time": 26.166982412338257,
      "citing_paper_id": "271218757",
      "cited_paper_id": null
    },
    {
      "context_text": "(We additionally compared to the re-sults of K¨oksal et al. (2023) in Appendix H and to GPT-4o prompted with a large subset of the user’s entire email history in Appendix I.) We start with publicly available instruction-finetuned LLMs: Meta-Llama-3-8B-Instruct, Mistral-7B-Instruct-v0.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The reference to 'a large subset of the user’s entire email history' is too generic and lacks a specific identifier.",
      "processing_time": 18.280693292617798,
      "citing_paper_id": "271218757",
      "cited_paper_id": null
    },
    {
      "context_text": "Throughout, we use Mistral-7B (Jiang et al., 2023) as a running example for costs, but the techniques apply to other base LLMs with similar size.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (Mistral-7B). No datasets are referenced for training, evaluation, or any other use.",
      "processing_time": 28.616594314575195,
      "citing_paper_id": "271218757",
      "cited_paper_id": null
    },
    {
      "context_text": "BLEU ROUGE BLEU ROUGE Mistral-7B-Instruct-v0.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only metrics (BLEU, ROUGE) and a model (Mistral-7B-Instruct-v0).",
      "processing_time": 15.652263402938843,
      "citing_paper_id": "271218757",
      "cited_paper_id": null
    },
    {
      "context_text": "012 Mistral-7B-Instruct-v0.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific, verifiable dataset names or other resources. It appears to be a model name, which is excluded.",
      "processing_time": 13.779766082763672,
      "citing_paper_id": "271218757",
      "cited_paper_id": null
    },
    {
      "context_text": "In Figure 7 we show that similar performance levels can be obtained by fine-tuning various LLM backbones, when performing FFT or RoSA-RAFT across Mistral-7B-Instruct-v0.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model backbones and methods. There are no verifiable resources that meet the criteria.",
      "processing_time": 13.561333656311035,
      "citing_paper_id": "271218757",
      "cited_paper_id": null
    },
    {
      "context_text": "In addition, the recent explosion of highly performant models of the 4-8B parameter scale has made individualized personalization a viable goal (Chen et al., 2023; Kirk et al., 2024; Zhang et al., 2024b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and their capabilities. There are no verifiable resources or datasets mentioned.",
      "processing_time": 14.688005924224854,
      "citing_paper_id": "271218757",
      "cited_paper_id": null
    },
    {
      "context_text": "In 2016, J. W. Li, et.al [4] persona-grounded models for handling the issue of speaker thickness in neural response generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'persona-grounded models' but does not specify a dataset. The context is about using persona-based models to handle speaker thickness in neural response generation.",
      "processing_time": 16.37389302253723,
      "citing_paper_id": "273834648",
      "cited_paper_id": 2955580
    },
    {
      "context_text": "In 2017, Jianhua Yuan, et.al [6] described the megahit-SCIR emotional response agent “ prattling ” to the NLPCC 2017 Shared Task 4 on emotional discussion generation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'NLPCC 2017 Shared Task 4 on emotional discussion generation' but does not specify a dataset. The term 'emotional discussion generation' suggests a task or challenge rather than a specific dataset.",
      "processing_time": 19.95214033126831,
      "citing_paper_id": "273834648",
      "cited_paper_id": 7338076
    },
    {
      "context_text": "In 2018, R.M.S. Ramos, et.al [5] described the b5 corpus, a collection of controlled and free (non-topic specific) textbooks produced in different (e.g., referential or descriptive) communicative tasks, and accompanied by supplies of the personality of their authors and fresh demographics.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "b5 corpus"
      ],
      "dataset_descriptions": {
        "b5 corpus": "Used to study personality-dependent natural language understanding and generation, focusing on the impact of author personality and demographics on text production."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'b5 corpus', which is a specific dataset used for personality-dependent natural language understanding and generation. It includes textbooks with author personality and demographic information.",
      "processing_time": 22.50232458114624,
      "citing_paper_id": "273834648",
      "cited_paper_id": 21691164
    },
    {
      "context_text": "In 2018, Qiao Qian, et.al[2] designed a model consisting of three modules a profile sensor to decide whether a post should be responded to using the profile and which key should be addressed, a position sensor that forecasts a word position from which decoding should begin given a specified profile…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model design. No verifiable resources are identified.",
      "processing_time": 13.565990686416626,
      "citing_paper_id": "273834648",
      "cited_paper_id": 51608471
    },
    {
      "context_text": "In 2020, Wanqi Wu and Tetsuya et.al [3] constructed a personality identifier by using the myPersonality dataset for detecting particularity values from utterances.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "myPersonality dataset"
      ],
      "dataset_descriptions": {
        "myPersonality dataset": "Used to detect personality traits from utterances, specifically focusing on the Big Five personality traits in response generation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'myPersonality dataset' which is a specific, verifiable dataset used for detecting personality traits from utterances.",
      "processing_time": 21.92685580253601,
      "citing_paper_id": "273834648",
      "cited_paper_id": 235666838
    },
    {
      "context_text": "In 2023, Ziyi Zhou, et.al [1] developed a new model named GERP to induce emotional responses grounded on the pre-defined personality.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model named GERP. The context focuses on the development of the model rather than the use of a dataset.",
      "processing_time": 18.281672477722168,
      "citing_paper_id": "273834648",
      "cited_paper_id": 258267089
    },
    {
      "context_text": "images, these methods enhance user engagement and satisfaction, leading to more effective personalized content recommendations [6], [7], [8] and matching [9], [10], [11], [12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods and their effects on user engagement and personalized content recommendations.",
      "processing_time": 25.890364170074463,
      "citing_paper_id": "277564933",
      "cited_paper_id": 201701022
    },
    {
      "context_text": "images, these methods enhance user engagement and satisfaction, leading to more effective personalized content recommendations [6], [7], [8] and matching [9], [10], [11], [12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods and their effects on user engagement and personalized content recommendations.",
      "processing_time": 25.890364170074463,
      "citing_paper_id": "277564933",
      "cited_paper_id": 222278410
    },
    {
      "context_text": "images, these methods enhance user engagement and satisfaction, leading to more effective personalized content recommendations [6], [7], [8] and matching [9], [10], [11], [12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods and their effects on user engagement and personalized content recommendations.",
      "processing_time": 25.890364170074463,
      "citing_paper_id": "277564933",
      "cited_paper_id": 235313588
    },
    {
      "context_text": "Evaluation Metrics: We evaluate our method using several metrics: (cid:2) Structural Similarity Index Measure (SSIM) [44]: This metric evaluates image quality by comparing luminance, contrast, and structural similarity between images.",
      "catation_intent": "none",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric for evaluating image quality.",
      "processing_time": 26.14994525909424,
      "citing_paper_id": "277564933",
      "cited_paper_id": 207761262
    },
    {
      "context_text": "A CLIP text [37], [38] processes the input prompt, and its outputs E c are provided to the generation model.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CLIP) and its role in processing input prompts.",
      "processing_time": 26.79840850830078,
      "citing_paper_id": "277564933",
      "cited_paper_id": 256221409
    },
    {
      "context_text": "We utilize Stable Diffusion [40] as the image generation model, which includes an image encoder, image decoder, CLIP text encoder [37], [38], and U-Net module, respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and components of the image generation model.",
      "processing_time": 12.835575103759766,
      "citing_paper_id": "277564933",
      "cited_paper_id": 256221409
    },
    {
      "context_text": "Existing approaches can be categorized based on user preferences into user-independent [13], [14], [20] and user-dependent [21], [16].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only categories of approaches. No verifiable resources are identified.",
      "processing_time": 14.650383472442627,
      "citing_paper_id": "277564933",
      "cited_paper_id": 265609037
    },
    {
      "context_text": "Existing approaches can be categorized based on user preferences into user-independent [13], [14], [20] and user-dependent [21], [16].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only categories of approaches. No verifiable resources are identified.",
      "processing_time": 14.650383472442627,
      "citing_paper_id": "277564933",
      "cited_paper_id": 269148520
    },
    {
      "context_text": "In recent years, numerous approaches [13], [14], [15], [16], [17], [18], [19] have been proposed to generate images that more accurately align with user preferences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches for generating images aligned with user preferences.",
      "processing_time": 27.679666757583618,
      "citing_paper_id": "277564933",
      "cited_paper_id": 265609037
    },
    {
      "context_text": "In recent years, numerous approaches [13], [14], [15], [16], [17], [18], [19] have been proposed to generate images that more accurately align with user preferences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches for generating images aligned with user preferences.",
      "processing_time": 27.679666757583618,
      "citing_paper_id": "277564933",
      "cited_paper_id": 269148520
    },
    {
      "context_text": "PMG[16]designabiasedpreferenceembeddingforallusersand combineitwithalargelanguagemodeltoanalyzepreferences basedontheirhistoricalrecords.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for personalized multimodal generation using large language models.",
      "processing_time": 14.04039454460144,
      "citing_paper_id": "277564933",
      "cited_paper_id": 269148520
    },
    {
      "context_text": "PMG [16] design multimodal tokens as additional signals for all users to enhance hard preference keywords.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enhancing personalized multimodal generation.",
      "processing_time": 12.03621792793274,
      "citing_paper_id": "277564933",
      "cited_paper_id": 269148520
    },
    {
      "context_text": "SimPO [34] introduces a length normalization strategy and reward margin to directly align with human preferences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called SimPO. The context focuses on the method's features and its alignment with human preferences.",
      "processing_time": 18.046631336212158,
      "citing_paper_id": "277564933",
      "cited_paper_id": 269983560
    },
    {
      "context_text": "User preference modeling [31], [32], [33], [34], [21] captures preferences through either human feedback or analysis Authorized licensed use limited to the terms of the applicable license agreement with IEEE.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to user preference modeling. No clear, verifiable datasets are identified.",
      "processing_time": 14.010619878768921,
      "citing_paper_id": "277564933",
      "cited_paper_id": 269983560
    },
    {
      "context_text": "Baselines: We compare the proposed method with the following types of methods: non-personalized methods (General PR and SUR [47]) and personalized methods (Promptist [48] and Tailored Vision [21]): (cid:2) General PR: It utilizes ChatGPT to rewrite the input prompt, focusing solely on describing…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and baselines. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 28.81442880630493,
      "citing_paper_id": "277564933",
      "cited_paper_id": null
    },
    {
      "context_text": "(cid:2) SUR [47]: This method facilitates knowledge transfer from a large language model to a diffusion model through a knowledge distillation technique, augmenting the diffusion model’s capacity for prompt understanding and reasoning.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for knowledge transfer. There are no verifiable resources or datasets mentioned.",
      "processing_time": 14.913098096847534,
      "citing_paper_id": "277564933",
      "cited_paper_id": null
    },
    {
      "context_text": "Examples of these activities are responding to questions in the open domain [9] fact - checking [10], fact - completion [11], answering questions in the lengthy form , creating Wikipedia articles, having discourse [12], translating and modeling the language [13].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general activities and tasks. No clear identifiers for datasets are present.",
      "processing_time": 12.626460552215576,
      "citing_paper_id": "276187375",
      "cited_paper_id": 86611921
    },
    {
      "context_text": "Mixed techniques that combine non - parametric (i.e., retrieval - based) recalls with proportional recalling may be able to address some of these issues [5].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only discusses a technique combining non-parametric and proportional recalling.",
      "processing_time": 15.282637596130371,
      "citing_paper_id": "276187375",
      "cited_paper_id": null
    },
    {
      "context_text": "For content, CLIP R-Precision [24] measures semantic alignment between the generated images and input text, with higher scores reflecting better consistency.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a metric (R-Precision) used to measure semantic alignment. No dataset names are present in the citation context.",
      "processing_time": 16.31347346305847,
      "citing_paper_id": "277993813",
      "cited_paper_id": 244906179
    },
    {
      "context_text": "While prior research on neural style transfer focuses mainly on painting styles [20], [21], we expand this scope to include a broader range of visual styles, enhancing its utility for style transfer applications.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general expansion of the scope of neural style transfer. No verifiable resources are identified.",
      "processing_time": 29.565473794937134,
      "citing_paper_id": "277993813",
      "cited_paper_id": 247922246
    },
    {
      "context_text": "Prominent models such as Stable Diffusion [11], Imagen [12], and DALL-E 2 [13] have set benchmarks for generating highly detailed and faithful images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 27.352741479873657,
      "citing_paper_id": "277993813",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "B. Experimental Setting a) Baselines: We employ Stable Diffusion [11], Textual Inversion [22], Custom Diffusion [26], and DreamBooth [8] as baselines for personalizing text-to-image generation.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models used as baselines for personalizing text-to-image generation, but does not reference any specific datasets.",
      "processing_time": 16.33155345916748,
      "citing_paper_id": "277993813",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "B. Experimental Setting a) Baselines: We employ Stable Diffusion [11], Textual Inversion [22], Custom Diffusion [26], and DreamBooth [8] as baselines for personalizing text-to-image generation.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models used as baselines for personalizing text-to-image generation, but does not reference any specific datasets.",
      "processing_time": 16.33155345916748,
      "citing_paper_id": "277993813",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "B. Experimental Setting a) Baselines: We employ Stable Diffusion [11], Textual Inversion [22], Custom Diffusion [26], and DreamBooth [8] as baselines for personalizing text-to-image generation.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models used as baselines for personalizing text-to-image generation, but does not reference any specific datasets.",
      "processing_time": 16.33155345916748,
      "citing_paper_id": "277993813",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Textual Inversion [22] enhances personalization by mapping text embeddings to visual features.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method called Textual Inversion. The cited paper title confirms that Textual Inversion is a method, not a dataset.",
      "processing_time": 16.022319555282593,
      "citing_paper_id": "277993813",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "DreamBooth [8] enables effective fine-tuning with minimal data, producing consistent outputs aligned with specified styles. b) Parameter Setting: In our experiments, all images were resized to 256×256 pixels, and the experiments were conducted on an NVIDIA 4090 GPU.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DreamBooth) and experimental setup details. No verifiable datasets are referenced.",
      "processing_time": 17.77499294281006,
      "citing_paper_id": "277993813",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "To improve consistency and coherence, some studies [8]–[10] employ prior loss functions, which align generated outputs with intended content by penalizing deviations from prior knowledge of the target subject.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of prior loss functions in the context of improving consistency and coherence in generated text.",
      "processing_time": 14.01499319076538,
      "citing_paper_id": "277993813",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Custom Diffusion [26] improves image quality while maintaining stylistic coherence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Custom Diffusion) for improving image quality in text-to-image diffusion models.",
      "processing_time": 18.239623546600342,
      "citing_paper_id": "277993813",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "14 However, describing rare or ambiguously defined artistic styles using general textual expressions remains a significant challenge, as these styles often encompass intricate nuances in color palettes, textures, and other defining features [29]–[31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general challenge in describing artistic styles. No verifiable resources are identified.",
      "processing_time": 13.519455432891846,
      "citing_paper_id": "277993813",
      "cited_paper_id": 254853701
    },
    {
      "context_text": "14 However, describing rare or ambiguously defined artistic styles using general textual expressions remains a significant challenge, as these styles often encompass intricate nuances in color palettes, textures, and other defining features [29]–[31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general challenge in describing artistic styles. No verifiable resources are identified.",
      "processing_time": 13.519455432891846,
      "citing_paper_id": "277993813",
      "cited_paper_id": 267211817
    },
    {
      "context_text": "14 However, describing rare or ambiguously defined artistic styles using general textual expressions remains a significant challenge, as these styles often encompass intricate nuances in color palettes, textures, and other defining features [29]–[31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general challenge in describing artistic styles. No verifiable resources are identified.",
      "processing_time": 13.519455432891846,
      "citing_paper_id": "277993813",
      "cited_paper_id": null
    },
    {
      "context_text": "Recent advances [16]–[19] have refined high-resolution image generation by introducing innovative meth-ods.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods for high-resolution image generation. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.321022033691406,
      "citing_paper_id": "277993813",
      "cited_paper_id": 257766375
    },
    {
      "context_text": "Recent advances [16]–[19] have refined high-resolution image generation by introducing innovative meth-ods.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods for high-resolution image generation. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 16.321022033691406,
      "citing_paper_id": "277993813",
      "cited_paper_id": 268512710
    },
    {
      "context_text": "Following prior works [4], [15], the template explicitly focuses on stylistic elements present in the input image while excluding object-specific or contextual information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The context is about focusing on stylistic elements in images, which is not directly related to a dataset.",
      "processing_time": 19.45570135116577,
      "citing_paper_id": "277993813",
      "cited_paper_id": 258041269
    },
    {
      "context_text": "Text-to-image models, a subset of generative models, have rapidly evolved to convert natural language descriptions into corresponding visual representations, as demonstrated in recent works [3]–[7].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to text-to-image models. No verifiable resources are identified.",
      "processing_time": 14.004098415374756,
      "citing_paper_id": "277993813",
      "cited_paper_id": 258079316
    },
    {
      "context_text": "Rectified Flow [17] establishes direct connections be-tween data and noise to enhance the generative process, while Style Creation [18] uses perceptual and texture enhancement loss to merge multiple styles into content images, creating unique, user-tailored results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles confirm that they are about methods rather than datasets.",
      "processing_time": 25.842046976089478,
      "citing_paper_id": "277993813",
      "cited_paper_id": 261917624
    },
    {
      "context_text": "Rectified Flow [17] establishes direct connections be-tween data and noise to enhance the generative process, while Style Creation [18] uses perceptual and texture enhancement loss to merge multiple styles into content images, creating unique, user-tailored results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles confirm that they are about methods rather than datasets.",
      "processing_time": 25.842046976089478,
      "citing_paper_id": "277993813",
      "cited_paper_id": 268247980
    },
    {
      "context_text": "Attention Injection [19] further improves the efficiency and quality of personalized synthesis by optimizing feature handling through enhanced attention mechanisms.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called 'Attention Injection'. The context focuses on the improvement of personalized synthesis using this method.",
      "processing_time": 14.905658721923828,
      "citing_paper_id": "277993813",
      "cited_paper_id": 268512710
    },
    {
      "context_text": "To address these limitations, researchers have explored methods like ‘prompt optimization’ [1], [2], which leverage Visual Language Models (VLMs) to optimize textual prompts and better capture stylistic features.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on prompt optimization and VLMs, which are not datasets.",
      "processing_time": 27.076686143875122,
      "citing_paper_id": "277993813",
      "cited_paper_id": 268667428
    },
    {
      "context_text": "Generated content image consistency and content preservation Additionally, challenges such as embedding entanglement [2], including biases from backgrounds, nearby objects, or materials, can introduce artifacts, including texture inconsistencies and color mismatches, further complicating the…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general challenges and issues in text-to-image personalization.",
      "processing_time": 12.99165415763855,
      "citing_paper_id": "277993813",
      "cited_paper_id": 268667428
    },
    {
      "context_text": "…images of each category for totally 28 categories for training, to evaluate the model’s ability to capture stylistic nuances and generalize effectively in low-data scenarios. b) Style30K Dataset: Style30K Dataset [23] is a large-scale dataset of 30,000 images with distinct stylistic features.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Style30K Dataset"
      ],
      "dataset_descriptions": {
        "Style30K Dataset": "Used to evaluate the model's ability to capture stylistic nuances and generalize effectively in low-data scenarios, focusing on distinct stylistic features in 30,000 images."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Style30K Dataset' as a large-scale dataset used for evaluating the model's ability to capture stylistic nuances and generalize effectively in low-data scenarios.",
      "processing_time": 37.71184253692627,
      "citing_paper_id": "277993813",
      "cited_paper_id": 272398104
    },
    {
      "context_text": "Inspired by prompt engineering techniques in recent works [11], [27], [28], we leverage a Visual Language Model (e.g., GPT) to extract concise and descriptive style keywords from the style reference images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Visual Language Model) and a general technique (prompt engineering). No verifiable resources are identified.",
      "processing_time": 16.65553331375122,
      "citing_paper_id": "277993813",
      "cited_paper_id": null
    },
    {
      "context_text": "To make matters worse, recent works (e.g., [30, 49]) have shown that widely used metrics, such as CLIP [51] or FID [24], correlate poorly with human preferences, even for subject-agnostic de novo image generations.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only metrics (CLIP, FID) which are excluded according to the rules.",
      "processing_time": 27.08354377746582,
      "citing_paper_id": "266163420",
      "cited_paper_id": 326772
    },
    {
      "context_text": "To make matters worse, recent works (e.g., [30, 49]) have shown that widely used metrics, such as CLIP [51] or FID [24], correlate poorly with human preferences, even for subject-agnostic de novo image generations.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only metrics (CLIP, FID) which are excluded according to the rules.",
      "processing_time": 27.08354377746582,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "…methods for T2I models (personalized or not) use a combination of metrics originally designed for unconditional image generation, (e.g., FID [24] or IS [59]), and bimodal metrics such as CLIP [51] (or extensions [23, 77, 79]) which are optimized for de novo T2I generations that are not…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only metrics and models. The context focuses on evaluation metrics for text-to-image models.",
      "processing_time": 12.997733116149902,
      "citing_paper_id": "266163420",
      "cited_paper_id": 326772
    },
    {
      "context_text": "…for T2I models (personalized or not) use a combination of metrics originally designed for unconditional image generation, (e.g., FID [24] or IS [59]), and bimodal metrics such as CLIP [51] (or extensions [23, 77, 79]) which are optimized for de novo T2I generations that are not subject-driven.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only metrics and models. The cited papers do not introduce new datasets either.",
      "processing_time": 12.983370542526245,
      "citing_paper_id": "266163420",
      "cited_paper_id": 1687220
    },
    {
      "context_text": "…for T2I models (personalized or not) use a combination of metrics originally designed for unconditional image generation, (e.g., FID [24] or IS [59]), and bimodal metrics such as CLIP [51] (or extensions [23, 77, 79]) which are optimized for de novo T2I generations that are not subject-driven.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only metrics and models. The cited papers do not introduce new datasets either.",
      "processing_time": 12.983370542526245,
      "citing_paper_id": "266163420",
      "cited_paper_id": 233296711
    },
    {
      "context_text": "…for T2I models (personalized or not) use a combination of metrics originally designed for unconditional image generation, (e.g., FID [24] or IS [59]), and bimodal metrics such as CLIP [51] (or extensions [23, 77, 79]) which are optimized for de novo T2I generations that are not subject-driven.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only metrics and models. The cited papers do not introduce new datasets either.",
      "processing_time": 12.983370542526245,
      "citing_paper_id": "266163420",
      "cited_paper_id": 258079316
    },
    {
      "context_text": "…for T2I models (personalized or not) use a combination of metrics originally designed for unconditional image generation, (e.g., FID [24] or IS [59]), and bimodal metrics such as CLIP [51] (or extensions [23, 77, 79]) which are optimized for de novo T2I generations that are not subject-driven.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only metrics and models. The cited papers do not introduce new datasets either.",
      "processing_time": 12.983370542526245,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "For, we we can restrict nouns associated with [food] to specific (e.g., detectable [31]) food items.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to 'specific food items'. No clear, verifiable resource is identified.",
      "processing_time": 13.964114904403687,
      "citing_paper_id": "266163420",
      "cited_paper_id": 4492210
    },
    {
      "context_text": "There is a vast literature and accompanying datasets concerning objective multimodal captioning of images [13, 29, 31, 33, 40, 48, 62, 64], 3D objects and scenes [1, 3, 4, 14, 43, 70], or even more subjective bi-modal data concerning e.g., visually grounded emotions [5, 7, 44], or dynamic actions…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions various types of datasets but does not specify any particular dataset names. It refers to general categories of datasets, which do not meet the criteria for inclusion.",
      "processing_time": 16.646400213241577,
      "citing_paper_id": "266163420",
      "cited_paper_id": 4492210
    },
    {
      "context_text": "There is a vast literature and accompanying datasets concerning objective multimodal captioning of images [13, 29, 31, 33, 40, 48, 62, 64], 3D objects and scenes [1, 3, 4, 14, 43, 70], or even more subjective bi-modal data concerning e.g., visually grounded emotions [5, 7, 44], or dynamic actions…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions various types of datasets but does not specify any particular dataset names. It refers to general categories of datasets, which do not meet the criteria for inclusion.",
      "processing_time": 16.646400213241577,
      "citing_paper_id": "266163420",
      "cited_paper_id": 252917726
    },
    {
      "context_text": "Besides the many existing methods and corresponding data (e.g., [28, 34–37, 65, 71] specializing in editing/describing such characteristics - the derived invariance to such attributes eases the evaluation between the input/output subject (by assessing if such characteristics remained unchanged).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not provide specific dataset names, only references to methods and data. The cited papers' titles do not help in identifying specific datasets.",
      "processing_time": 15.564756155014038,
      "citing_paper_id": "266163420",
      "cited_paper_id": 12275803
    },
    {
      "context_text": "Besides the many existing methods and corresponding data (e.g., [28, 34–37, 65, 71] specializing in editing/describing such characteristics - the derived invariance to such attributes eases the evaluation between the input/output subject (by assessing if such characteristics remained unchanged).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not provide specific dataset names, only references to methods and data. The cited papers' titles do not help in identifying specific datasets.",
      "processing_time": 15.564756155014038,
      "citing_paper_id": "266163420",
      "cited_paper_id": 226281395
    },
    {
      "context_text": "To make matters worse, humans exhibit a heightened critical awareness of nuanced distortions or inaccuracies in representations of human faces [10, 12].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about human perception of facial representations.",
      "processing_time": 11.969287633895874,
      "citing_paper_id": "266163420",
      "cited_paper_id": 22727274
    },
    {
      "context_text": "Secondarily, we wish to highlight the potential of leveraging more powerful open-source, non-personalized T2I systems (e.g., SDXL [49]) in combination with well-curated data (e.g., CelebAMask-HQ [36]) to assist personalized generators.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CelebAMask-HQ"
      ],
      "dataset_descriptions": {
        "CelebAMask-HQ": "Used to assist personalized text-to-image generation by providing well-curated data for facial image manipulation, enhancing the diversity and interactivity of generated images."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'CelebAMask-HQ' as an example of well-curated data that can be used in combination with powerful T2I systems to assist personalized generators.",
      "processing_time": 24.05003309249878,
      "citing_paper_id": "266163420",
      "cited_paper_id": 198967908
    },
    {
      "context_text": "The Dynamic Textual Inversion ( DTI ) module inverts the foreground-masked identity image (found in CelebAMask-HQ [36]) into textual embeddings, S ∗ ( left ).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CelebAMask-HQ"
      ],
      "dataset_descriptions": {
        "CelebAMask-HQ": "Used to train the DTI module by providing foreground-masked identity images, focusing on generating textual embeddings for personalized text generation."
      },
      "confidence_score": 1.0,
      "reasoning": "CelebAMask-HQ is mentioned as a source of masked identity images used for training the DTI module. It is a specific dataset with a clear name and is directly used in the research.",
      "processing_time": 24.167757272720337,
      "citing_paper_id": "266163420",
      "cited_paper_id": 198967908
    },
    {
      "context_text": "Equipped with the above prompt-based part of Stellar, we further couple these prompts with high-resolution human-portraying images existing in CelebAMask-HQ’s [36].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CelebAMask-HQ"
      ],
      "dataset_descriptions": {
        "CelebAMask-HQ": "Used to provide high-resolution human-portraying images for facial image manipulation, enhancing the diversity and interactivity of the generated outputs."
      },
      "confidence_score": 1.0,
      "reasoning": "CelebAMask-HQ is mentioned as a source of high-resolution human-portraying images used in conjunction with prompts for facial image manipulation.",
      "processing_time": 23.166111707687378,
      "citing_paper_id": "266163420",
      "cited_paper_id": 198967908
    },
    {
      "context_text": "More-over, Stellar’s prompts are paired to 400 unique human identities, selected from CelebAMask-HQ [36, 37]; and all paired items come with rich meta-annotations promoting a rigorous evaluation of personalized T2I systems, as described in the following paragraphs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CelebAMask-HQ"
      ],
      "dataset_descriptions": {
        "CelebAMask-HQ": "Used to select 400 unique human identities for pairing with prompts, enhancing the evaluation of personalized text-to-image systems through rich meta-annotations."
      },
      "confidence_score": 1.0,
      "reasoning": "CelebAMask-HQ is mentioned as a source of human identities used in the research, which is relevant for personalized text-to-image generation.",
      "processing_time": 23.67761254310608,
      "citing_paper_id": "266163420",
      "cited_paper_id": 198967908
    },
    {
      "context_text": "In summary, we introduce 1 a large-scale multimodal dataset, Stellar , with prompts of imaginary human-centric depictions, grounding publicly available images of celebrities [36].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Stellar"
      ],
      "dataset_descriptions": {
        "Stellar": "Introduced as a large-scale multimodal dataset with prompts of imaginary human-centric depictions, using publicly available images of celebrities for training and evaluation."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'Stellar', which appears to be a specific, named dataset. However, the description is brief and does not provide detailed usage information.",
      "processing_time": 22.861114740371704,
      "citing_paper_id": "266163420",
      "cited_paper_id": 198967908
    },
    {
      "context_text": "Our metric uses a face detector [15] to isolate the identity’s face in both input and generated images.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a face detector but does not refer to a specific dataset. The cited paper title suggests a method or tool rather than a dataset.",
      "processing_time": 15.243093967437744,
      "citing_paper_id": "266163420",
      "cited_paper_id": 219964874
    },
    {
      "context_text": "…datasets concerning objective multimodal captioning of images [13, 29, 31, 33, 40, 48, 62, 64], 3D objects and scenes [1, 3, 4, 14, 43, 70], or even more subjective bi-modal data concerning e.g., visually grounded emotions [5, 7, 44], or dynamic actions predicated on visual stimuli [47].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions various types of datasets but does not specify any particular dataset names. The references are too generic and do not meet the criteria for inclusion.",
      "processing_time": 18.197517156600952,
      "citing_paper_id": "266163420",
      "cited_paper_id": 220714131
    },
    {
      "context_text": "…datasets concerning objective multimodal captioning of images [13, 29, 31, 33, 40, 48, 62, 64], 3D objects and scenes [1, 3, 4, 14, 43, 70], or even more subjective bi-modal data concerning e.g., visually grounded emotions [5, 7, 44], or dynamic actions predicated on visual stimuli [47].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions various types of datasets but does not specify any particular dataset names. The references are too generic and do not meet the criteria for inclusion.",
      "processing_time": 18.197517156600952,
      "citing_paper_id": "266163420",
      "cited_paper_id": 231639297
    },
    {
      "context_text": "…datasets concerning objective multimodal captioning of images [13, 29, 31, 33, 40, 48, 62, 64], 3D objects and scenes [1, 3, 4, 14, 43, 70], or even more subjective bi-modal data concerning e.g., visually grounded emotions [5, 7, 44], or dynamic actions predicated on visual stimuli [47].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions various types of datasets but does not specify any particular dataset names. The references are too generic and do not meet the criteria for inclusion.",
      "processing_time": 18.197517156600952,
      "citing_paper_id": "266163420",
      "cited_paper_id": 248227685
    },
    {
      "context_text": "…CLIP-based metrics and human-preference [30, 49], and the fact that subjective quantities such as an image’s aesthetic value are intrinsically hard to compute [5]; all the above metrics are not designed to take into account the additional image portraying the subject that is driving the generation.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses metrics and subjective qualities. No clear identifiers for datasets are present.",
      "processing_time": 15.551666259765625,
      "citing_paper_id": "266163420",
      "cited_paper_id": 231639297
    },
    {
      "context_text": "Applications ranging from creating de novo fictional images [53, 55, 58] to editing them via text [11, 83], or similarly manipulating higher-dimensional visual representations (e.g., video [22, 42, 67, 74] or 3D objects [6, 52, 60, 82]); have vastly pushed the envelope for computer-aided creativity…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 14.59062647819519,
      "citing_paper_id": "266163420",
      "cited_paper_id": 232035663
    },
    {
      "context_text": "Applications ranging from creating de novo fictional images [53, 55, 58] to editing them via text [11, 83], or similarly manipulating higher-dimensional visual representations (e.g., video [22, 42, 67, 74] or 3D objects [6, 52, 60, 82]); have vastly pushed the envelope for computer-aided creativity…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 14.59062647819519,
      "citing_paper_id": "266163420",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "Applications ranging from creating de novo fictional images [53, 55, 58] to editing them via text [11, 83], or similarly manipulating higher-dimensional visual representations (e.g., video [22, 42, 67, 74] or 3D objects [6, 52, 60, 82]); have vastly pushed the envelope for computer-aided creativity…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only applications and methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 14.59062647819519,
      "citing_paper_id": "266163420",
      "cited_paper_id": 254408758
    },
    {
      "context_text": "For example, metrics such as CLIP T [73] and CLIP-Score [23] attempt to evaluate holistically the semantic alignment between a sentence and a given image.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only metrics (CLIP T and CLIP-Score) which are excluded according to the rules.",
      "processing_time": 17.96397352218628,
      "citing_paper_id": "266163420",
      "cited_paper_id": 233296711
    },
    {
      "context_text": "For example, metrics such as CLIP T [73] and CLIP-Score [23] attempt to evaluate holistically the semantic alignment between a sentence and a given image.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only metrics (CLIP T and CLIP-Score) which are excluded according to the rules.",
      "processing_time": 17.96397352218628,
      "citing_paper_id": "266163420",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "Despite that, many recent and indispensable metrics for de novo text-to-image systems exist [23, 51, 62]; such metrics are typically blind to fundamental aspects that affect the overall performance and quality of personalized, subject-driven generators.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general metrics for evaluating text-to-image systems. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 18.99153232574463,
      "citing_paper_id": "266163420",
      "cited_paper_id": 233296711
    },
    {
      "context_text": "Despite that, many recent and indispensable metrics for de novo text-to-image systems exist [23, 51, 62]; such metrics are typically blind to fundamental aspects that affect the overall performance and quality of personalized, subject-driven generators.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general metrics for evaluating text-to-image systems. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 18.99153232574463,
      "citing_paper_id": "266163420",
      "cited_paper_id": 252917726
    },
    {
      "context_text": "Despite that, many recent and indispensable metrics for de novo text-to-image systems exist [23, 51, 62]; such metrics are typically blind to fundamental aspects that affect the overall performance and quality of personalized, subject-driven generators.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general metrics for evaluating text-to-image systems. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 18.99153232574463,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "Efficient and stable training for the larger SDXL is achieved using Low-Rank Adaptation (LoRA) [26] weight offsets (Fig.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (LoRA) for adapting large language models. The context is about training stability and efficiency, not about dataset usage.",
      "processing_time": 19.257492780685425,
      "citing_paper_id": "266163420",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "Additionally, we finetune the UNet backbone of SDXL using LoRA weight-offsets [26] for efficient and stable training ( middle bottom ).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (LoRA) for fine-tuning a model. No verifiable datasets are referenced.",
      "processing_time": 18.45402693748474,
      "citing_paper_id": "266163420",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "…and accompanying datasets concerning objective multimodal captioning of images [13, 29, 31, 33, 40, 48, 62, 64], 3D objects and scenes [1, 3, 4, 14, 43, 70], or even more subjective bi-modal data concerning e.g., visually grounded emotions [5, 7, 44], or dynamic actions predicated on visual…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation span mentions various types of datasets but does not specify any particular dataset names. It refers to general categories of data such as 'objective multimodal captioning of images', '3D objects and scenes', and 'subjective bi-modal data'. No specific dataset names are provided.",
      "processing_time": 32.64191198348999,
      "citing_paper_id": "266163420",
      "cited_paper_id": 244908764
    },
    {
      "context_text": "…and accompanying datasets concerning objective multimodal captioning of images [13, 29, 31, 33, 40, 48, 62, 64], 3D objects and scenes [1, 3, 4, 14, 43, 70], or even more subjective bi-modal data concerning e.g., visually grounded emotions [5, 7, 44], or dynamic actions predicated on visual…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation span mentions various types of datasets but does not specify any particular dataset names. It refers to general categories of data such as 'objective multimodal captioning of images', '3D objects and scenes', and 'subjective bi-modal data'. No specific dataset names are provided.",
      "processing_time": 32.64191198348999,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "Such personalized models have recently started to emerge [19, 57, 66, 73] as a natural and powerful extension of de novo image generators [49, 56], inspiring radically novel applications.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to personalized models and their applications. No verifiable resources are identified.",
      "processing_time": 25.78279447555542,
      "citing_paper_id": "266163420",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Such personalized models have recently started to emerge [19, 57, 66, 73] as a natural and powerful extension of de novo image generators [49, 56], inspiring radically novel applications.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to personalized models and their applications. No verifiable resources are identified.",
      "processing_time": 25.78279447555542,
      "citing_paper_id": "266163420",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Such personalized models have recently started to emerge [19, 57, 66, 73] as a natural and powerful extension of de novo image generators [49, 56], inspiring radically novel applications.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to personalized models and their applications. No verifiable resources are identified.",
      "processing_time": 25.78279447555542,
      "citing_paper_id": "266163420",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "Capitalizing on the remarkable capabilities and modularity shown recently by T2I models [49, 54, 56, 58], powerful extensions personalizing their output generations have emerged.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to models and their capabilities. There are no verifiable resources or datasets mentioned.",
      "processing_time": 26.273319005966187,
      "citing_paper_id": "266163420",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "…sharing multimodal deep learning models trained with internet scale data, comprised of billions of textual tokens and images (e.g., [49, 51, 56]), have given rise to an unprecedented explosion of novel solutions for many long-standing problems at the intersection of computer vision and…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only generic references to 'internet scale data' and 'billions of textual tokens and images'. No specific, verifiable datasets are named.",
      "processing_time": 29.518288612365723,
      "citing_paper_id": "266163420",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Similar to existing research [19, 57], our architecture relies on large pre-trained T2I diffusion models [49, 56] tapping on their excellent capacity for prompt-guided image generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only pre-trained models and their capabilities. No verifiable resources are identified.",
      "processing_time": 26.270427942276,
      "citing_paper_id": "266163420",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Similar to existing research [19, 57], our architecture relies on large pre-trained T2I diffusion models [49, 56] tapping on their excellent capacity for prompt-guided image generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only pre-trained models and their capabilities. No verifiable resources are identified.",
      "processing_time": 26.270427942276,
      "citing_paper_id": "266163420",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "…fictional images [53, 55, 58] to editing them via text [11, 83], or similarly manipulating higher-dimensional visual representations (e.g., video [22, 42, 67, 74] or 3D objects [6, 52, 60, 82]); have vastly pushed the envelope for computer-aided creativity and further de-mocratized this field…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It discusses various applications of AI in generating and editing visual content but does not reference any particular dataset.",
      "processing_time": 29.133141040802002,
      "citing_paper_id": "266163420",
      "cited_paper_id": 247292765
    },
    {
      "context_text": "Comparison of Stellar with existing datasets focusing on personalized, or de novo (Parti [81]), image generations.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'existing datasets' without naming them, which is too generic.",
      "processing_time": 27.90642476081848,
      "citing_paper_id": "266163420",
      "cited_paper_id": 249926846
    },
    {
      "context_text": "DreamBooth [57] 35 40 ✗ ✗ CustomConcept101 [32] 617 101 ✗ ✗ Parti [81] 1 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models or methods. The titles of the cited papers do not provide additional context to identify datasets.",
      "processing_time": 28.687987565994263,
      "citing_paper_id": "266163420",
      "cited_paper_id": 249926846
    },
    {
      "context_text": "DreamBooth [57] 35 40 ✗ ✗ CustomConcept101 [32] 617 101 ✗ ✗ Parti [81] 1 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models or methods. The titles of the cited papers do not provide additional context to identify datasets.",
      "processing_time": 28.687987565994263,
      "citing_paper_id": "266163420",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "DreamBooth [57] 35 40 ✗ ✗ CustomConcept101 [32] 617 101 ✗ ✗ Parti [81] 1 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models or methods. The titles of the cited papers do not provide additional context to identify datasets.",
      "processing_time": 28.687987565994263,
      "citing_paper_id": "266163420",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Even if one is to lift the constraint of coupling the descriptions of images to specific individuals [32, 57, 81], there is yet no common ground for building large-scale collections of textual prompts in natural language that can be deemed applicable for generating i) interesting fictional…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses the challenge of building large-scale collections of textual prompts but does not name any particular dataset.",
      "processing_time": 29.762139558792114,
      "citing_paper_id": "266163420",
      "cited_paper_id": 249926846
    },
    {
      "context_text": "Even if one is to lift the constraint of coupling the descriptions of images to specific individuals [32, 57, 81], there is yet no common ground for building large-scale collections of textual prompts in natural language that can be deemed applicable for generating i) interesting fictional…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses the challenge of building large-scale collections of textual prompts but does not name any particular dataset.",
      "processing_time": 29.762139558792114,
      "citing_paper_id": "266163420",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Even if one is to lift the constraint of coupling the descriptions of images to specific individuals [32, 57, 81], there is yet no common ground for building large-scale collections of textual prompts in natural language that can be deemed applicable for generating i) interesting fictional…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses the challenge of building large-scale collections of textual prompts but does not name any particular dataset.",
      "processing_time": 29.762139558792114,
      "citing_paper_id": "266163420",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Recent personalized datasets (e.g., [32, 57, 81]) are not focused on human-centric actions, cover few subjects, and/or lack rich meta-annotations accompanying the paired prompts/images.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'personalized datasets' but does not provide specific names. It only describes general characteristics and limitations of such datasets.",
      "processing_time": 28.144049882888794,
      "citing_paper_id": "266163420",
      "cited_paper_id": 249926846
    },
    {
      "context_text": "Recent personalized datasets (e.g., [32, 57, 81]) are not focused on human-centric actions, cover few subjects, and/or lack rich meta-annotations accompanying the paired prompts/images.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'personalized datasets' but does not provide specific names. It only describes general characteristics and limitations of such datasets.",
      "processing_time": 28.144049882888794,
      "citing_paper_id": "266163420",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Recent personalized datasets (e.g., [32, 57, 81]) are not focused on human-centric actions, cover few subjects, and/or lack rich meta-annotations accompanying the paired prompts/images.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'personalized datasets' but does not provide specific names. It only describes general characteristics and limitations of such datasets.",
      "processing_time": 28.144049882888794,
      "citing_paper_id": "266163420",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Starting with the pi-oneering works of Gal et. al [19] and Ruiz et. al [57], personalized networks with admirable capabilities have started to appear.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to pioneering works and personalized networks. No verifiable resources are identified.",
      "processing_time": 28.16270422935486,
      "citing_paper_id": "266163420",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "In all the experiments we evaluate along StellarNet, DreamBooth (DB) [57], Textual Inversion (TI) [19], and ELITE [73].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several methods/models (DreamBooth, Textual Inversion, ELITE) but does not refer to any specific datasets. The context focuses on evaluating these methods, not on using datasets.",
      "processing_time": 32.13479208946228,
      "citing_paper_id": "266163420",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "In all the experiments we evaluate along StellarNet, DreamBooth (DB) [57], Textual Inversion (TI) [19], and ELITE [73].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several methods/models (DreamBooth, Textual Inversion, ELITE) but does not refer to any specific datasets. The context focuses on evaluating these methods, not on using datasets.",
      "processing_time": 32.13479208946228,
      "citing_paper_id": "266163420",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "…efforts make it easy to find vast quantities of objective captioning data for images (e.g., [33, 62]); however, curating images of individuals performing fictional actions accompanied by textual descriptions is practically impossible given the open-ended and imaginary nature of this task [57].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to the general availability of objective captioning data for images and the difficulty of curating specific types of image-text pairs.",
      "processing_time": 31.302552223205566,
      "citing_paper_id": "266163420",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Orthogonally to these metrics, unimodal (vision-based) metrics, such as the Aesthetic-Score [62], try to quantify the aesthetic quality of a given image.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a metric called 'Aesthetic-Score'. No datasets are referenced for use in the research context.",
      "processing_time": 29.998514890670776,
      "citing_paper_id": "266163420",
      "cited_paper_id": 252917726
    },
    {
      "context_text": "Current efforts make it easy to find vast quantities of objective captioning data for images (e.g., [33, 62]); however, curating images of individuals performing fictional actions accompanied by textual descriptions is practically impossible given the open-ended and imaginary nature of this task…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to the general availability of objective captioning data for images, which is too generic.",
      "processing_time": 30.39628005027771,
      "citing_paper_id": "266163420",
      "cited_paper_id": 252917726
    },
    {
      "context_text": "We quantitatively compare our proposed metrics with metrics typically used in existing T2I studies (Aesthetic Score [62], CLIP I [51], DreamSim [18], CLIP T [51], HPSv1 [77], HPSv2 [76], ImageReward [79] and PickScore [30]) over the entire Stellar Dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Stellar Dataset"
      ],
      "dataset_descriptions": {
        "Stellar Dataset": "Used to quantitatively compare proposed metrics with existing metrics in text-to-image generation studies, focusing on aesthetic and perceptual quality assessments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Stellar Dataset' which is a specific dataset used for quantitative comparison of metrics in text-to-image generation studies.",
      "processing_time": 35.82889199256897,
      "citing_paper_id": "266163420",
      "cited_paper_id": 252917726
    },
    {
      "context_text": "We quantitatively compare our proposed metrics with metrics typically used in existing T2I studies (Aesthetic Score [62], CLIP I [51], DreamSim [18], CLIP T [51], HPSv1 [77], HPSv2 [76], ImageReward [79] and PickScore [30]) over the entire Stellar Dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Stellar Dataset"
      ],
      "dataset_descriptions": {
        "Stellar Dataset": "Used to quantitatively compare proposed metrics with existing metrics in text-to-image generation studies, focusing on aesthetic and perceptual quality assessments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Stellar Dataset' which is a specific dataset used for quantitative comparison of metrics in text-to-image generation studies.",
      "processing_time": 35.82889199256897,
      "citing_paper_id": "266163420",
      "cited_paper_id": 258079316
    },
    {
      "context_text": "We quantitatively compare our proposed metrics with metrics typically used in existing T2I studies (Aesthetic Score [62], CLIP I [51], DreamSim [18], CLIP T [51], HPSv1 [77], HPSv2 [76], ImageReward [79] and PickScore [30]) over the entire Stellar Dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Stellar Dataset"
      ],
      "dataset_descriptions": {
        "Stellar Dataset": "Used to quantitatively compare proposed metrics with existing metrics in text-to-image generation studies, focusing on aesthetic and perceptual quality assessments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Stellar Dataset' which is a specific dataset used for quantitative comparison of metrics in text-to-image generation studies.",
      "processing_time": 35.82889199256897,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "We quantitatively compare our proposed metrics with metrics typically used in existing T2I studies (Aesthetic Score [62], CLIP I [51], DreamSim [18], CLIP T [51], HPSv1 [77], HPSv2 [76], ImageReward [79] and PickScore [30]) over the entire Stellar Dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Stellar Dataset"
      ],
      "dataset_descriptions": {
        "Stellar Dataset": "Used to quantitatively compare proposed metrics with existing metrics in text-to-image generation studies, focusing on aesthetic and perceptual quality assessments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Stellar Dataset' which is a specific dataset used for quantitative comparison of metrics in text-to-image generation studies.",
      "processing_time": 35.82889199256897,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "DiffusionDB [72] is a large-scale dataset that includes user prompts that are not personalized and typically contain multiple complex modifiers (e.g., famous painters, photographic techniques, etc.), resulting in obscure, not natural language.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DiffusionDB"
      ],
      "dataset_descriptions": {
        "DiffusionDB": "Used to study non-personalized, complex user prompts in text-to-image generative models, focusing on the impact of multiple modifiers on prompt clarity and naturalness."
      },
      "confidence_score": 1.0,
      "reasoning": "DiffusionDB is explicitly mentioned as a dataset and described with specific characteristics relevant to the research context.",
      "processing_time": 35.35650968551636,
      "citing_paper_id": "266163420",
      "cited_paper_id": 253116574
    },
    {
      "context_text": "More recently, works like ELITE [73], or similar ones( [20, 27]), have lifted this bottleneck by learning more general and robust mappings between visual and textual embeddings capable of generalizing simultaneously to many individual inputs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models or methods. The citation is about learning mappings between visual and textual embeddings, which is not directly related to the topic of personalized text generation.",
      "processing_time": 32.32683825492859,
      "citing_paper_id": "266163420",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "More recently, works like ELITE [73], or similar ones( [20, 27]), have lifted this bottleneck by learning more general and robust mappings between visual and textual embeddings capable of generalizing simultaneously to many individual inputs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models or methods. The citation is about learning mappings between visual and textual embeddings, which is not directly related to the topic of personalized text generation.",
      "processing_time": 32.32683825492859,
      "citing_paper_id": "266163420",
      "cited_paper_id": 257952647
    },
    {
      "context_text": "Those latter masks are helpful for evaluation purposes and for training modern T2I generators where background-free grounding images typically result in qualitatively superior generations [73].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to 'background-free grounding images'. No clear, verifiable dataset names are provided.",
      "processing_time": 30.399630308151245,
      "citing_paper_id": "266163420",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "To achieve the above goal efficiently and overcome the need for per-subject optimization, we incorporate an encoder-based inversion technique (similar to [20, 73]).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or technique. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 29.467081308364868,
      "citing_paper_id": "266163420",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "Following recent works [20, 73], originally inspired by GAN-Inversion techniques [78], we also aim to derive a latent representation for the provided subject image, I , in the pre-trained word-embedding space of a T2I model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only techniques and models. There are no clear identifiers for datasets.",
      "processing_time": 13.43380856513977,
      "citing_paper_id": "266163420",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "…deep learning models trained with internet scale data, comprised of billions of textual tokens and images (e.g., [49, 51, 56]), have given rise to an unprecedented explosion of novel solutions for many long-standing problems at the intersection of computer vision and natural language [8, 80].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only generic references to internet-scale data. No multi-word proper nouns, acronyms, or hyphenated names with digits are present.",
      "processing_time": 31.787033796310425,
      "citing_paper_id": "266163420",
      "cited_paper_id": 259243718
    },
    {
      "context_text": "Moreover, we advise proper content moderation and relevant regulation [25] to prevent malpractice.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only advises on content moderation and regulation.",
      "processing_time": 28.454538345336914,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "These applications include personalized story-telling via character animation of specific individuals, aiding people to attend otherwise inaccessible real-world events virtually, or simply lifting the burden to capture photographs physically [17, 21, 68].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It describes potential applications of personalized text generation but does not reference any datasets used for these purposes.",
      "processing_time": 30.904359102249146,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "…in evaluative standards underscores the need for personalization systems focused on human-driven generations to adhere to a higher level of precision and accuracy, as human faces are not just scrutinized more closely but also evoke stronger emotional responses [69] upon perceived inaccuracies [39].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It discusses the importance of precision and accuracy in personalization systems, particularly in generating human faces.",
      "processing_time": 31.271042108535767,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "Specifically, we utilize CLIP T [51], to independently measure the similarity between the prompt and both the input and output images.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CLIP). There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 30.378028869628906,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "…publicly sharing multimodal deep learning models trained with internet scale data, comprised of billions of textual tokens and images (e.g., [49, 51, 56]), have given rise to an unprecedented explosion of novel solutions for many long-standing problems at the intersection of computer vision and…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It refers to internet-scale data but does not provide a named dataset.",
      "processing_time": 29.745689630508423,
      "citing_paper_id": "266163420",
      "cited_paper_id": null
    },
    {
      "context_text": "(3) Architecture approaches [26, 31] dynamically expand the network to mitigate forgetting for different tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only architectural approaches for lifelong learning.",
      "processing_time": 27.269899368286133,
      "citing_paper_id": "276961342",
      "cited_paper_id": 3693512
    },
    {
      "context_text": "For non-continual methods Textual Inversion, DreamBooth and Custom Diffusion, we apply two different continual learning strategies, EWC [10] and LwF [12].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and strategies. The context is focused on applying continual learning strategies to non-continual methods.",
      "processing_time": 30.896279096603394,
      "citing_paper_id": "276961342",
      "cited_paper_id": 4704285
    },
    {
      "context_text": "(1) Regularization methods [10, 12, 32] address catastrophic forgetting by imposing a regularization constraint to important parameters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only regularization methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 30.713992834091187,
      "citing_paper_id": "276961342",
      "cited_paper_id": 4704285
    },
    {
      "context_text": "(1) Regularization methods [10, 12, 32] address catastrophic forgetting by imposing a regularization constraint to important parameters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only regularization methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 30.713992834091187,
      "citing_paper_id": "276961342",
      "cited_paper_id": 10409742
    },
    {
      "context_text": "Text-to-Image (T2I) diffusion models [17, 18, 21, 23] have emerged as a promising approach in the field of generative artificial intelligence, enabling the creation of high-quality images from textual descriptions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a class of models (T2I diffusion models). There are no verifiable resources or datasets mentioned.",
      "processing_time": 31.557981491088867,
      "citing_paper_id": "276961342",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "Imagen [23] leverages pre-trained large language models to provide rich textual information for image generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a method or model (large language models) used for image generation. No verifiable dataset is referenced.",
      "processing_time": 31.771793127059937,
      "citing_paper_id": "276961342",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "By harnessing the capabilities of T2I diffusion models, diffusion customization allows for the generation of user-defined concepts, achieving impressive results [4, 11, 13, 14, 22, 29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the capabilities of T2I diffusion models and the concept of diffusion customization. No verifiable resources are named.",
      "processing_time": 32.30248951911926,
      "citing_paper_id": "276961342",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "By harnessing the capabilities of T2I diffusion models, diffusion customization allows for the generation of user-defined concepts, achieving impressive results [4, 11, 13, 14, 22, 29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the capabilities of T2I diffusion models and the concept of diffusion customization. No verifiable resources are named.",
      "processing_time": 32.30248951911926,
      "citing_paper_id": "276961342",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "By harnessing the capabilities of T2I diffusion models, diffusion customization allows for the generation of user-defined concepts, achieving impressive results [4, 11, 13, 14, 22, 29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the capabilities of T2I diffusion models and the concept of diffusion customization. No verifiable resources are named.",
      "processing_time": 32.30248951911926,
      "citing_paper_id": "276961342",
      "cited_paper_id": 266052536
    },
    {
      "context_text": "DreamBooth [22] proposes a class-specific prior preservation loss to safeguard prior knowledge and conducts fine-tuning of all parameters of Stable Diffusion.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DreamBooth) and a model (Stable Diffusion).",
      "processing_time": 31.099234342575073,
      "citing_paper_id": "276961342",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "We follow the settings of previous work [11, 22] and select 18 concepts for customization, which contains person, pets, cartoon characters, etc.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a set of concepts used for customization. No clear, verifiable dataset names are provided.",
      "processing_time": 31.752431869506836,
      "citing_paper_id": "276961342",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "To evaluate the quality of the generated images, we follow previous work [11, 22] and adopt Image-alignment (IA, the visual similarity of generated images with the target concept, using similarity in CLIP [19] image feature space) and Text-alignment (TA, using text-image similarity in CLIP feature…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to metrics (IA and TA) and a model (CLIP), which are excluded according to the instructions.",
      "processing_time": 33.19686794281006,
      "citing_paper_id": "276961342",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Existing methods [4, 11, 14, 22, 29] primarily focus on how to personalize these concepts collectively.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to existing methods. No verifiable resources are identified.",
      "processing_time": 31.548035621643066,
      "citing_paper_id": "276961342",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Existing methods [4, 11, 14, 22, 29] primarily focus on how to personalize these concepts collectively.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to existing methods. No verifiable resources are identified.",
      "processing_time": 31.548035621643066,
      "citing_paper_id": "276961342",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "Diffusion customization [4, 11, 13–15, 22, 29] aims to generate user-defined concepts under various contexts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general concept of generating user-defined concepts under various contexts. No verifiable resources are identified.",
      "processing_time": 33.32188820838928,
      "citing_paper_id": "276961342",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Diffusion customization [4, 11, 13–15, 22, 29] aims to generate user-defined concepts under various contexts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general concept of generating user-defined concepts under various contexts. No verifiable resources are identified.",
      "processing_time": 33.32188820838928,
      "citing_paper_id": "276961342",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "Diffusion customization [4, 11, 13–15, 22, 29] aims to generate user-defined concepts under various contexts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general concept of generating user-defined concepts under various contexts. No verifiable resources are identified.",
      "processing_time": 33.32188820838928,
      "citing_paper_id": "276961342",
      "cited_paper_id": 266052536
    },
    {
      "context_text": "We compare our method with four different baselines, Textual Inversion [4], Dream-Booth [22], Custom Diffusion [11] and Continual Diffusion [24].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only model names. No verifiable resources are identified.",
      "processing_time": 34.72566771507263,
      "citing_paper_id": "276961342",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Continual customization [3, 24, 25] aims to personalize concepts in a sequential manner.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of continual customization. There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 36.3090238571167,
      "citing_paper_id": "276961342",
      "cited_paper_id": 273532312
    },
    {
      "context_text": "Dong et al. [3] introduce concept consolidation loss and an elastic weight aggregation module to address concept forgetting and neglect.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and concepts. The context is focused on introducing a method to address concept forgetting and neglect in text-to-image diffusion models.",
      "processing_time": 38.4849853515625,
      "citing_paper_id": "276961342",
      "cited_paper_id": 273532312
    },
    {
      "context_text": "Recently, prompt learning [6, 28, 30] emerges as a kind of efficient methods to address catastrophic forgetting.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 37.60107207298279,
      "citing_paper_id": "276961342",
      "cited_paper_id": 276742376
    },
    {
      "context_text": "The users’ perceived workload is tested by the task load index (NASA-TLX) [15], which was developed by NASA.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions NASA-TLX, which is a method for measuring perceived workload, not a dataset. It does not fit the criteria for a verifiable resource as defined.",
      "processing_time": 39.8761043548584,
      "citing_paper_id": "265066909",
      "cited_paper_id": 6292200
    },
    {
      "context_text": "Task-oriented topics aim to complete certain tasks for users in a specific domain, such as restaurant recommendation, and location query, which makes it valuable for real-world business [24, 43].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only task-oriented topics which are not datasets.",
      "processing_time": 37.35551047325134,
      "citing_paper_id": "265066909",
      "cited_paper_id": 27290051
    },
    {
      "context_text": "These chatbot systems engage users in conversational dialogues, providing valuable information and support in various scenarios, including commercial transactions and emotional support[8, 9, 37, 44].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions chatbot systems engaging users in conversational dialogues, which aligns with the topic of personalized text generation. However, the context does not explicitly mention any specific datasets.",
      "processing_time": 41.33080077171326,
      "citing_paper_id": "265066909",
      "cited_paper_id": 208248357
    },
    {
      "context_text": "These chatbot systems engage users in conversational dialogues, providing valuable information and support in various scenarios, including commercial transactions and emotional support[8, 9, 37, 44].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions chatbot systems engaging users in conversational dialogues, which aligns with the topic of personalized text generation. However, the context does not explicitly mention any specific datasets.",
      "processing_time": 41.33080077171326,
      "citing_paper_id": "265066909",
      "cited_paper_id": 237941100
    },
    {
      "context_text": "These chatbot systems engage users in conversational dialogues, providing valuable information and support in various scenarios, including commercial transactions and emotional support[8, 9, 37, 44].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions chatbot systems engaging users in conversational dialogues, which aligns with the topic of personalized text generation. However, the context does not explicitly mention any specific datasets.",
      "processing_time": 41.33080077171326,
      "citing_paper_id": "265066909",
      "cited_paper_id": 252780132
    },
    {
      "context_text": "However, multi-turn natural language understanding still remains extremely challenging, requiring the system to comprehend the conversation context and reply in an informative and coincident manner [2, 10, 39, 42].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the challenge of multi-turn natural language understanding. No verifiable resources are named.",
      "processing_time": 39.33081865310669,
      "citing_paper_id": "265066909",
      "cited_paper_id": 209445099
    },
    {
      "context_text": "However, multi-turn natural language understanding still remains extremely challenging, requiring the system to comprehend the conversation context and reply in an informative and coincident manner [2, 10, 39, 42].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the challenge of multi-turn natural language understanding. No verifiable resources are named.",
      "processing_time": 39.33081865310669,
      "citing_paper_id": "265066909",
      "cited_paper_id": 221971391
    },
    {
      "context_text": "One approach to tackle the previously mentioned issue is to develop enhancements to the model’s context understanding, multi-step reasoning capabilities, and consistency [23, 39, 42].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers that discuss model enhancements.",
      "processing_time": 37.89947462081909,
      "citing_paper_id": "265066909",
      "cited_paper_id": 221971391
    },
    {
      "context_text": "Previous studies on prompt engineering have addressed these challenges by providing effective strategies for prompting [4, 25, 33, 34].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous studies on prompt engineering. No verifiable resources are identified.",
      "processing_time": 39.67566514015198,
      "citing_paper_id": "265066909",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "Previous studies on prompt engineering have addressed these challenges by providing effective strategies for prompting [4, 25, 33, 34].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous studies on prompt engineering. No verifiable resources are identified.",
      "processing_time": 39.67566514015198,
      "citing_paper_id": "265066909",
      "cited_paper_id": 257079092
    },
    {
      "context_text": "Previous studies on prompt engineering have addressed these challenges by providing effective strategies for prompting [4, 25, 33, 34].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to previous studies on prompt engineering. No verifiable resources are identified.",
      "processing_time": 39.67566514015198,
      "citing_paper_id": "265066909",
      "cited_paper_id": null
    },
    {
      "context_text": "Large language models (LLMs), such as GPT and LLaMA, have revolutionized AI prototyping [11, 18, 32, 35, 40].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only large language models. No verifiable resources are identified.",
      "processing_time": 38.71989631652832,
      "citing_paper_id": "265066909",
      "cited_paper_id": 247447133
    },
    {
      "context_text": "Large language models (LLMs), such as GPT and LLaMA, have revolutionized AI prototyping [11, 18, 32, 35, 40].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only large language models. No verifiable resources are identified.",
      "processing_time": 38.71989631652832,
      "citing_paper_id": "265066909",
      "cited_paper_id": 256868430
    },
    {
      "context_text": "Large language models (LLMs), such as GPT and LLaMA, have revolutionized AI prototyping [11, 18, 32, 35, 40].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only large language models. No verifiable resources are identified.",
      "processing_time": 38.71989631652832,
      "citing_paper_id": "265066909",
      "cited_paper_id": 261378072
    },
    {
      "context_text": "It has been fine-tuned to handle a wide range of topics and adapt to various conversational styles, making it an ideal tool for applications such as customer support, virtual assistants, and chatbot development [3, 16, 30].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of a fine-tuned model. No verifiable resources are identified.",
      "processing_time": 39.67227911949158,
      "citing_paper_id": "265066909",
      "cited_paper_id": 257235906
    },
    {
      "context_text": "[17] introduces a visual prompt tuning for vision models.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for visual prompt tuning.",
      "processing_time": 37.89343762397766,
      "citing_paper_id": "265066909",
      "cited_paper_id": null
    },
    {
      "context_text": "The social presence is measured by the social presence questionnaire designed by Harms and Biocca’s [14].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a questionnaire but does not refer to a specific dataset. The questionnaire is a method or tool, not a dataset.",
      "processing_time": 39.862464904785156,
      "citing_paper_id": "265066909",
      "cited_paper_id": null
    },
    {
      "context_text": "…Poole introduced four essential aspects of personalized information systems: the information itself (content), how the information is presented (user interface), the media through which information is delivered (channel), and what users can do with the system (functionality) (Fan & Poole, 2006).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only aspects of personalized information systems. No verifiable resources are identified.",
      "processing_time": 39.6680703163147,
      "citing_paper_id": "59540906",
      "cited_paper_id": 418729
    },
    {
      "context_text": "Studies in fields such as marketing, computer science, and HCI, among others, have proposed many definitions of personalization (Fan & Poole, 2006; Tuzhilin, 2009).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to studies proposing definitions of personalization.",
      "processing_time": 38.86386704444885,
      "citing_paper_id": "59540906",
      "cited_paper_id": 418729
    },
    {
      "context_text": "Therefore, providing different news content based on algorithmic computation is key for the design of a news system that meets the needs of news readers (Beam, 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept of algorithmic computation in news systems.",
      "processing_time": 39.316221952438354,
      "citing_paper_id": "59540906",
      "cited_paper_id": 819096
    },
    {
      "context_text": "This pattern aligns with the findings from research on users ’ perception of algorithms, which found that people lost trust when they found errors in an algorithm (Dietvorst, Simmons, & Massey, 2015).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a finding about user perception of algorithms.",
      "processing_time": 38.70914340019226,
      "citing_paper_id": "59540906",
      "cited_paper_id": 1646733
    },
    {
      "context_text": "It is known to be more effective at engaging and persuading the audience when the message is tailored (Hawkins, Kreuter, Resnicow, Fishbein, & Dijkstra, 2008; Rimer & Kreuter, 2006; Roberto, Krieger, & Beam, 2009).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general findings about the effectiveness of tailored messages.",
      "processing_time": 39.03412318229675,
      "citing_paper_id": "59540906",
      "cited_paper_id": 3416650
    },
    {
      "context_text": "It is known to be more effective at engaging and persuading the audience when the message is tailored (Hawkins, Kreuter, Resnicow, Fishbein, & Dijkstra, 2008; Rimer & Kreuter, 2006; Roberto, Krieger, & Beam, 2009).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general findings about the effectiveness of tailored messages.",
      "processing_time": 39.03412318229675,
      "citing_paper_id": "59540906",
      "cited_paper_id": 143407414
    },
    {
      "context_text": "…personalization is to frame information in a context that is meaningful to the recipient in order to increase attention, interest, and motivation (Hawkins et al., 2008), the practice of blocking out certain information might mislead news readers on perceiving the importance of issues that have…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept of personalization in communication. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 42.18465828895569,
      "citing_paper_id": "59540906",
      "cited_paper_id": 3416650
    },
    {
      "context_text": "It limits the interaction between people with diverse perspectives and opinions and the opportunity to solve problems via deliberative processes (Bozdag & van den Hoven, 2015).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It discusses the impact of filter bubbles on democratic processes.",
      "processing_time": 40.381553173065186,
      "citing_paper_id": "59540906",
      "cited_paper_id": 14246611
    },
    {
      "context_text": "Despite the growing interest in news personalization, previous research has mainly focused on finding and filtering relevant content in the constantly evolving streams of information (Kalyanaraman & Sundar, 2006; Kizilcec, 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general research trends in news personalization.",
      "processing_time": 39.016152143478394,
      "citing_paper_id": "59540906",
      "cited_paper_id": 18933022
    },
    {
      "context_text": "Algorithms are playing an increasingly influential role in diverse user-facing services due to their capacity to compute large amounts of data and present personalized information based on the profiles and preferences of users (Kizilcec, 2016; Napoli, 2014; Pariser, 2011).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to algorithms and their influence on personalized information. No verifiable resources are identified.",
      "processing_time": 41.564044713974,
      "citing_paper_id": "59540906",
      "cited_paper_id": 18933022
    },
    {
      "context_text": "From various research perspectives, the key quality of personalization is that it provides “ a means to know what there is to know and how to know ” the information that corresponds to an individual ’ s specific interests and needs (Gillespie, 2014; Lavie, Sela, Oppenheim, Inbar, & Meyer, 2010).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts about personalization. No verifiable resources are identified.",
      "processing_time": 40.114323139190674,
      "citing_paper_id": "59540906",
      "cited_paper_id": 30673212
    },
    {
      "context_text": "…always influenced journalism (Pavlik, 2000), the latest changes in the news production process are largely influenced by the use of algorithms (Van Dalen, 2012), which are able to make autonomous decisions and generate content that is indiscernible from that of human journalists (Clerwall, 2014;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to the influence of algorithms in journalism. No verifiable resources are identified.",
      "processing_time": 40.95922064781189,
      "citing_paper_id": "59540906",
      "cited_paper_id": 60848654
    },
    {
      "context_text": "…2000), the latest changes in the news production process are largely influenced by the use of algorithms (Van Dalen, 2012), which are able to make autonomous decisions and generate content that is indiscernible from that of human journalists (Clerwall, 2014; Nicholas Diakopoulos, 2014; Dörr, 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only discusses the influence of algorithms in news production. No verifiable resources are identified.",
      "processing_time": 41.289658069610596,
      "citing_paper_id": "59540906",
      "cited_paper_id": 145565198
    },
    {
      "context_text": "…2000), the latest changes in the news production process are largely influenced by the use of algorithms (Van Dalen, 2012), which are able to make autonomous decisions and generate content that is indiscernible from that of human journalists (Clerwall, 2014; Nicholas Diakopoulos, 2014; Dörr, 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only discusses the influence of algorithms in news production. No verifiable resources are identified.",
      "processing_time": 41.289658069610596,
      "citing_paper_id": "59540906",
      "cited_paper_id": 157695530
    },
    {
      "context_text": "In Clerwall’s study, the scores for the algorithmgenerated news were higher in criteria related to credibility and trustworthiness, while human-generated news was significantly more pleasant and less boring to read (Clerwall, 2014).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between algorithm-generated and human-generated news. No clear, verifiable dataset is referenced.",
      "processing_time": 41.838324546813965,
      "citing_paper_id": "59540906",
      "cited_paper_id": 145565198
    },
    {
      "context_text": "To produce appropriate evaluation criteria for scoring, we reviewed the metrics found in previous studies on perceived news value (Clerwall, 2014; Sundar, 1999).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous studies on perceived news value. No verifiable resources are identified.",
      "processing_time": 40.9552583694458,
      "citing_paper_id": "59540906",
      "cited_paper_id": 145565198
    },
    {
      "context_text": "To produce appropriate evaluation criteria for scoring, we reviewed the metrics found in previous studies on perceived news value (Clerwall, 2014; Sundar, 1999).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to previous studies on perceived news value. No verifiable resources are identified.",
      "processing_time": 40.9552583694458,
      "citing_paper_id": "59540906",
      "cited_paper_id": 145589047
    },
    {
      "context_text": "A few prior studies have compared how people measure the news value of algorithm-generated news in comparison with the value of human-generated news (Clerwall, 2014).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between algorithm-generated and human-generated news. No clear, verifiable dataset names are provided.",
      "processing_time": 42.17031383514404,
      "citing_paper_id": "59540906",
      "cited_paper_id": 145565198
    },
    {
      "context_text": "While technology has always influenced journalism (Pavlik, 2000), the latest changes in the news production process are largely influenced by the use of algorithms (Van Dalen, 2012), which are able to make autonomous decisions and generate content that is indiscernible from that of human journalists (Clerwall, 2014; Nicholas Diakopoulos, 2014; Dörr, 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general references to the influence of technology and algorithms in journalism. No verifiable resources are identified.",
      "processing_time": 42.16799759864807,
      "citing_paper_id": "59540906",
      "cited_paper_id": 157695530
    },
    {
      "context_text": "In news media, algorithms can add different layers of stories and therefore create varying types of news content depending on readers ’ interests and choices (Hamilton & Turner, 2009).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It discusses the impact of algorithms on news content personalization but does not reference any particular dataset.",
      "processing_time": 42.64751696586609,
      "citing_paper_id": "59540906",
      "cited_paper_id": null
    },
    {
      "context_text": "We developed the system using a Ruby on Rails framework that crawls the live streaming data from a sports news service in JSON format and generates narratives in natural language using the algorithm solution introduced in our previous research (Kim & Lee, 2015).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a system for generating narratives from live streaming sports news data, but does not name a specific dataset.",
      "processing_time": 43.41228103637695,
      "citing_paper_id": "59540906",
      "cited_paper_id": null
    },
    {
      "context_text": "The framing of an event can be quantifiably measured using a dynamic weighting system (Kim & Lee, 2015).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for measuring event framing.",
      "processing_time": 39.011427879333496,
      "citing_paper_id": "59540906",
      "cited_paper_id": null
    },
    {
      "context_text": "In our previous research, we proposed a five-step algorithmic news generation framework as shown in Figure 2 (Kim & Lee, 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a framework for news generation.",
      "processing_time": 39.010308027267456,
      "citing_paper_id": "59540906",
      "cited_paper_id": null
    },
    {
      "context_text": "Studies have shown that appropriate recommendation reasons may improve user acceptance of recommendation results [2,3] and also help to enhance user experience in terms of transparency, trustworthiness, recognizability, effectiveness, and satisfaction of the system [4,5,6].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general findings about recommendation systems and user experience.",
      "processing_time": 39.82877159118652,
      "citing_paper_id": "260956406",
      "cited_paper_id": 28780910
    },
    {
      "context_text": "Recommendation systems [1] are intended to model users’ interests and provide them with personalized recommendations based on their historical behavior.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept of recommendation systems. There are no verifiable resources or specific datasets mentioned.",
      "processing_time": 42.14555048942566,
      "citing_paper_id": "260956406",
      "cited_paper_id": 195767143
    },
    {
      "context_text": "…that since 2017, the research on text generation for explainable recommendations has been combined with machine learning, sentiment analysis, and matrix decomposition [12-13], while relying on new technologies such as knowledge maps to address the long-standing cold start problem in this field.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not mention any specific datasets, only general methods and approaches. The context is too vague to identify a specific, verifiable dataset.",
      "processing_time": 42.399399757385254,
      "citing_paper_id": "260956406",
      "cited_paper_id": 218872004
    },
    {
      "context_text": "…about the tendencies of subjective texts with emotional overtones, making it possible to improve the accuracy of recommendations while generating high-quality text explanations to effectively gain the trust of users and increase the persuasiveness and satisfaction of the recommendation system [11].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts about improving recommendation systems through text generation.",
      "processing_time": 40.08028268814087,
      "citing_paper_id": "260956406",
      "cited_paper_id": null
    },
    {
      "context_text": "Earlier methods utilize discrete attribute information about users and items to generate reviews (Tang et al., 2016; Dong et al., 2017; Ni et al., 2017; Zang and Wan, 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 42.395716190338135,
      "citing_paper_id": "271088888",
      "cited_paper_id": 2765857
    },
    {
      "context_text": "Earlier methods utilize discrete attribute information about users and items to generate reviews (Tang et al., 2016; Dong et al., 2017; Ni et al., 2017; Zang and Wan, 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 42.395716190338135,
      "citing_paper_id": "271088888",
      "cited_paper_id": 16282767
    },
    {
      "context_text": "For example, Tang et al. (Tang et al., 2016) utilize user/item IDs, and rating as input information, and use the RNN-based decoder for generating reviews.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions the use of user/item IDs and ratings as input information for generating reviews using an RNN-based decoder. However, no specific dataset name is provided.",
      "processing_time": 43.80188298225403,
      "citing_paper_id": "271088888",
      "cited_paper_id": 16282767
    },
    {
      "context_text": "Recent works consider using the text information to help generating reviews, such as item titles, and historical reviews of users/items, etc (Ni and McAuley, 2018; Li and Tuzhilin, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions using text information for generating reviews but does not specify any named datasets. The context is too generic to identify specific datasets.",
      "processing_time": 42.137415170669556,
      "citing_paper_id": "271088888",
      "cited_paper_id": 29161455
    },
    {
      "context_text": "Ni et al. (Ni and McAuley, 2018) propose ExpansionNet, which also integrates phrase information from item titles and review summaries into the encoder for generating reviews.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (ExpansionNet) and its application but does not reference any specific dataset. The focus is on the model and its capabilities rather than a particular dataset.",
      "processing_time": 43.20637559890747,
      "citing_paper_id": "271088888",
      "cited_paper_id": 29161455
    },
    {
      "context_text": "Most existing methods are based on the encoder-decoder neural network framework (Li et al., 2019, 2020; Kim et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 42.87754487991333,
      "citing_paper_id": "271088888",
      "cited_paper_id": 189762150
    },
    {
      "context_text": "Most existing methods are based on the encoder-decoder neural network framework (Li et al., 2019, 2020; Kim et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 42.87754487991333,
      "citing_paper_id": "271088888",
      "cited_paper_id": 222133992
    },
    {
      "context_text": "Online e-commerce platforms (e.g., Amazon.com) usually offer users opportunities to share reviews for items they have purchased (Sun et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a general practice on e-commerce platforms.",
      "processing_time": 41.53079152107239,
      "citing_paper_id": "271088888",
      "cited_paper_id": 215873485
    },
    {
      "context_text": "During the training process, we utilize the Low-Rank Adaptation (LoRA) (Hu et al., 2021) for Parameter-Efficient Fine-Tuning (PEFT), which can greatly reduce the number of trainable parameters.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a method (LoRA) for parameter-efficient fine-tuning but does not reference any specific datasets.",
      "processing_time": 40.927873849868774,
      "citing_paper_id": "271088888",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "And, we conduct the SFT training based on PyTorch and PEFT library (Man-grulkar et al., 2022) and use the LoRA (Hu et al., 2021) with a rank equal to 8.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only libraries and methods used for training. No verifiable datasets are referenced.",
      "processing_time": 41.52667713165283,
      "citing_paper_id": "271088888",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "Later, pairing spoken and sung sequences with Dynamic Time Warping (DTW) was proposed in [8], followed by a 2-step procedure in [9], in which the music information is extracted from the audio of actual singing performances (called templates) instead of using a music score.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and procedures. No verifiable resources are identified.",
      "processing_time": 40.70981740951538,
      "citing_paper_id": "145927666",
      "cited_paper_id": 3000900
    },
    {
      "context_text": "[22] Masanori Morise, Fumiya Yokomori, and Kenji Ozawa, “World: a vocoder-based high-quality speech synthesis system for real-time applications,” IEICE TRANSACTIONS on Information and Systems, vol. 99, no. 7, pp. 1877–1884, 2016.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (vocoder-based speech synthesis system) and its application. No verifiable resources are identified.",
      "processing_time": 43.388641595840454,
      "citing_paper_id": "145927666",
      "cited_paper_id": 4413279
    },
    {
      "context_text": "[22] Masanori Morise, Fumiya Yokomori, and Kenji Ozawa, “World: a vocoder-based high-quality speech synthesis system for real-time applications,” IEICE TRANSACTIONS on Information and Systems, vol. 99, no. 7, pp. 1877–1884, 2016.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (vocoder-based speech synthesis system) and its application. No verifiable resources are identified.",
      "processing_time": 43.388641595840454,
      "citing_paper_id": "145927666",
      "cited_paper_id": 15164445
    },
    {
      "context_text": "• We use Spectral Autocorrelation (SAC) [3] for pitch/voicing extraction and WORLD vocoding [4] (using MGC and BAP features).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions tools and methods (Spectral Autocorrelation and WORLD vocoding) but does not reference any specific datasets.",
      "processing_time": 41.803110122680664,
      "citing_paper_id": "145927666",
      "cited_paper_id": 4413279
    },
    {
      "context_text": "The template pitch contour is extracted from the acappella with a robust estimator for singing voice, SAC [23].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'SAC' which could be a method or tool, but there are no specific datasets mentioned. The cited papers do not clarify the presence of a dataset.",
      "processing_time": 44.28266954421997,
      "citing_paper_id": "145927666",
      "cited_paper_id": 4413279
    },
    {
      "context_text": "The template pitch contour is extracted from the acappella with a robust estimator for singing voice, SAC [23].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'SAC' which could be a method or tool, but there are no specific datasets mentioned. The cited papers do not clarify the presence of a dataset.",
      "processing_time": 44.28266954421997,
      "citing_paper_id": "145927666",
      "cited_paper_id": 15164445
    },
    {
      "context_text": "The framework follows the main TSTS configuration proposed in [10] and [11], except that the input speech is generated by a TTS system based on [21].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and systems. The context is about the configuration of a framework and the use of a TTS system, which are not datasets.",
      "processing_time": 45.51927328109741,
      "citing_paper_id": "145927666",
      "cited_paper_id": 11952750
    },
    {
      "context_text": "The framework follows the main TSTS configuration proposed in [10] and [11], except that the input speech is generated by a TTS system based on [21].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and systems. The context is about the configuration of a framework and the use of a TTS system, which are not datasets.",
      "processing_time": 45.51927328109741,
      "citing_paper_id": "145927666",
      "cited_paper_id": 21464874
    },
    {
      "context_text": "In [3], [4], and [5] there are extensive studies of this work addressing additional aspects such as F0 and duration modeling or even on the inverse task (singing to speech transformation) [6].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies and models. The titles of the cited papers also do not indicate the use of specific datasets.",
      "processing_time": 44.024858713150024,
      "citing_paper_id": "145927666",
      "cited_paper_id": 12190278
    },
    {
      "context_text": "In [3], [4], and [5] there are extensive studies of this work addressing additional aspects such as F0 and duration modeling or even on the inverse task (singing to speech transformation) [6].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to studies and models. The titles of the cited papers also do not indicate the use of specific datasets.",
      "processing_time": 44.024858713150024,
      "citing_paper_id": "145927666",
      "cited_paper_id": 38629149
    },
    {
      "context_text": "A mobile application using a phonetic-based alignment version of this approach was also presented in [10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or application. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 42.612406969070435,
      "citing_paper_id": "145927666",
      "cited_paper_id": 21464874
    },
    {
      "context_text": "We can also find in [7] a method based on training F0 and spectral envelope transformations from singing data using a single vowel.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'singing data' but does not specify a named dataset. The reference is to a method, not a specific dataset.",
      "processing_time": 42.85974478721619,
      "citing_paper_id": "145927666",
      "cited_paper_id": 40740503
    },
    {
      "context_text": "During the training of the two models, data augmentation using the MUSAN corpus [26] and the RIR dataset [27] was applied.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MUSAN",
        "RIR"
      ],
      "dataset_descriptions": {
        "MUSAN": "Used for data augmentation during model training, providing music, speech, and noise samples to enhance the robustness of the models.",
        "RIR": "Used for data augmentation during model training, providing room impulse response samples to simulate realistic acoustic environments."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the MUSAN corpus and the RIR dataset for data augmentation during model training. Both are specific, verifiable datasets.",
      "processing_time": 54.49521040916443,
      "citing_paper_id": "267068678",
      "cited_paper_id": 15676318
    },
    {
      "context_text": "In the visualization, the open-source toolkit Resemblyzer [29] was applied where the cosine similarity between the speaker embedding vectors were computed as the similarity score.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of Resemblyzer, which is a toolkit, not a dataset. No datasets are explicitly mentioned or used according to the given context.",
      "processing_time": 43.18382716178894,
      "citing_paper_id": "267068678",
      "cited_paper_id": 22987563
    },
    {
      "context_text": "ECAPA-TDNN [25] combined with cosine distance was applied in our ASV evaluation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions ECAPA-TDNN, which is a method/model, not a dataset. No datasets are explicitly mentioned or used in the context provided.",
      "processing_time": 43.7744677066803,
      "citing_paper_id": "267068678",
      "cited_paper_id": 218630075
    },
    {
      "context_text": "Among them, the personalized speech generation techniques, including text-to-speech synthesis (TTS) [1] and voice conversion (VC) [2] facilitate generating the speech of a target speaker in high speaker similarity, raising the potential security risks concerning the voice privacy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only techniques and methods. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 42.873802185058594,
      "citing_paper_id": "267068678",
      "cited_paper_id": 221090498
    },
    {
      "context_text": "Among them, the personalized speech generation techniques, including text-to-speech synthesis (TTS) [1] and voice conversion (VC) [2] facilitate generating the speech of a target speaker in high speaker similarity, raising the potential security risks concerning the voice privacy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only techniques and methods. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 42.873802185058594,
      "citing_paper_id": "267068678",
      "cited_paper_id": 244908340
    },
    {
      "context_text": "Finally, a flow-based decoder followed by a HiFi-GAN [13] generator is applied to generate the speech in both the TTS and VC flows.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions HiFi-GAN but does not refer to it as a dataset. It is used as a method for generating speech in the context of text-to-speech (TTS) and voice conversion (VC) flows.",
      "processing_time": 46.71126985549927,
      "citing_paper_id": "267068678",
      "cited_paper_id": 222291664
    },
    {
      "context_text": "The H/ASP model was trained on the VoxCeleb2 dataset [16] and obtained an EER of 1.967% on the test subset of the multi-language LibriSpeech (MLS) dataset [17].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "VoxCeleb2",
        "LibriSpeech (MLS)"
      ],
      "dataset_descriptions": {
        "VoxCeleb2": "Used to train the H/ASP model, focusing on speaker verification tasks using a large-scale dataset of celebrity speech.",
        "LibriSpeech (MLS)": "Used to evaluate the H/ASP model, specifically testing its performance on a multilingual subset of the LibriSpeech dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two datasets, VoxCeleb2 and LibriSpeech (MLS), both of which are used in the training and evaluation of the H/ASP model.",
      "processing_time": 58.355408906936646,
      "citing_paper_id": "267068678",
      "cited_paper_id": 226202134
    },
    {
      "context_text": "…adversarial perturbation has been exploited to attack the models of face image recognition [5], speech recognition [6], speaker identification [7,8], speaker verification [9, 10] and so on, successfully misleading the models to make wrong predictions without altering the perceptions of the…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only adversarial attacks on various models. No verifiable resources are identified.",
      "processing_time": 13.800910949707031,
      "citing_paper_id": "267068678",
      "cited_paper_id": 226976076
    },
    {
      "context_text": "…has been exploited to attack the models of face image recognition [5], speech recognition [6], speaker identification [7,8], speaker verification [9, 10] and so on, successfully misleading the models to make wrong predictions without altering the perceptions of the original face images and…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only various applications of adversarial attacks. No clear, verifiable datasets are referenced.",
      "processing_time": 42.83086800575256,
      "citing_paper_id": "267068678",
      "cited_paper_id": 234778100
    },
    {
      "context_text": "To be specific, as detailed in [1], the TTS-related module is composed of an encoder followed by an alignment generation module.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a module structure in a TTS system. No verifiable resources are identified.",
      "processing_time": 42.84476828575134,
      "citing_paper_id": "267068678",
      "cited_paper_id": 244908340
    },
    {
      "context_text": "For details, readers are suggested to read [1].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not provide any specific information about datasets or resources used. It only suggests reading another paper for details.",
      "processing_time": 41.75653433799744,
      "citing_paper_id": "267068678",
      "cited_paper_id": 244908340
    },
    {
      "context_text": "In our white-box protection experiments, the YourTTS model trained with the configuration of Exp.4 as illustrated in [1] was employed for both adversarial speech generation and evaluation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (YourTTS) and an experimental configuration. No verifiable dataset names are present.",
      "processing_time": 43.761693716049194,
      "citing_paper_id": "267068678",
      "cited_paper_id": 244908340
    },
    {
      "context_text": "Currently, in personalized speech generation models, the speaker modeling is mainly built on extracting speaker attributes with a separate speaker encoder, e.g., [1, 11].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach to speaker modeling in personalized speech generation.",
      "processing_time": 41.775310754776,
      "citing_paper_id": "267068678",
      "cited_paper_id": 244908340
    },
    {
      "context_text": "YourTTS [1] is selected to be our white-box speech generation model, which can perform both zero-shot TTS and VC.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions YourTTS as a model for speech generation, not as a dataset. No specific datasets are mentioned.",
      "processing_time": 42.59150838851929,
      "citing_paper_id": "267068678",
      "cited_paper_id": 244908340
    },
    {
      "context_text": "In our ASV evaluations, the official trials on the libri-test dataset as provided by VoicePri-vacy Challenge 2022 [24] were adopted.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "libri-test dataset"
      ],
      "dataset_descriptions": {
        "libri-test dataset": "Used for ASV evaluations, specifically adopting the official trials provided by the VoicePrivacy Challenge 2022 to assess system performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'libri-test dataset' which is part of the VoicePrivacy Challenge 2022. It is a specific dataset used for ASV evaluations.",
      "processing_time": 51.11343431472778,
      "citing_paper_id": "267068678",
      "cited_paper_id": 253062025
    },
    {
      "context_text": "…have had a profound impact on various natural language processing applications, and LLMs are now being used for complex tasks such as automatic translation, question answering, document summarization, and content generation in diverse fields, including healthcare, education, and science [4–8].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of LLMs. No verifiable resources are identified.",
      "processing_time": 43.16369819641113,
      "citing_paper_id": "272444877",
      "cited_paper_id": 231632658
    },
    {
      "context_text": "…have had a profound impact on various natural language processing applications, and LLMs are now being used for complex tasks such as automatic translation, question answering, document summarization, and content generation in diverse fields, including healthcare, education, and science [4–8].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of LLMs. No verifiable resources are identified.",
      "processing_time": 43.16369819641113,
      "citing_paper_id": "272444877",
      "cited_paper_id": 257262719
    },
    {
      "context_text": "Li et al. [18] reviewed search-augmented text generation and other notable approaches for various text-generation tasks, including dialog-response They experimented with four separate testbeds based on the aforementioned basic capabilities for evaluating RAG in English and Chinese. dialog-response…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'testbeds' but does not specify any named datasets. The term 'testbeds' is too generic and lacks a specific identifier.",
      "processing_time": 44.64774131774902,
      "citing_paper_id": "272444877",
      "cited_paper_id": 246472929
    },
    {
      "context_text": "Zhao et al. [16] introduced practical RAG applications and benchmarks by catego-rizing the fundamental processes of RAG and investigating various search and generator augmentation methodologies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methodologies and applications of RAG. There are no clear identifiers for datasets in the text.",
      "processing_time": 43.98014974594116,
      "citing_paper_id": "272444877",
      "cited_paper_id": 268091298
    },
    {
      "context_text": "The RAG module was employed to enhance answers to user prompts by retrieving semantically Zhao et al. [16] introduced practical RAG applications and benchmarks by categorizing the fundamental processes of RAG and investigating various search and generator augmentation methodologies. agent…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (RAG) and its applications. The cited paper title confirms the focus on methods rather than datasets.",
      "processing_time": 45.21376442909241,
      "citing_paper_id": "272444877",
      "cited_paper_id": 268091298
    },
    {
      "context_text": "This study demonstrates that a QA system leveraging RAG can be customized for speci ﬁ c domains by indexing text corpora. including documents modified or deleted by individuals logged into the personalized database, there is no need to retrain or fine-tune",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses a QA system and personalized databases but does not provide names or identifiers for datasets.",
      "processing_time": 44.643601417541504,
      "citing_paper_id": "272444877",
      "cited_paper_id": 270843326
    },
    {
      "context_text": "We also implemented MongoDB [30] to The ﬁ rst is an SQL database that stores personalized documents and information based on the identity of an individual. store the chat history of QAs and generate the previous messages in a conversation.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to storing personalized documents and chat history using MongoDB, which is a database system, not a dataset.",
      "processing_time": 45.720024824142456,
      "citing_paper_id": "272444877",
      "cited_paper_id": null
    },
    {
      "context_text": "An easy method for implementing RAG is to employ LangChain (0.2.8) [31], a powerful framework that integrates external tools to create an environment.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a framework called LangChain. There are no verifiable resources that meet the criteria.",
      "processing_time": 43.974567890167236,
      "citing_paper_id": "272444877",
      "cited_paper_id": null
    },
    {
      "context_text": "…to make RAGs more active and build a personalized semantic space for successful answer This is accomplished through a system called the tagging box [29], which allows users to map the text from a part of a document of interest to tagged keywords and save it as a personal archive. generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method or tool called 'tagging box' but does not provide a dataset name.",
      "processing_time": 45.4797089099884,
      "citing_paper_id": "272444877",
      "cited_paper_id": null
    },
    {
      "context_text": "…conjunction with LLMs can e ﬀ ectively improve the search performance for a speci ﬁ c topic. accomplished through a system called the tagging box [29], which allows users to map the text from a part of a document of Li et al. [18] reviewed search-augmented text generation and other notable…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a system called 'tagging box' and a review of search-augmented text generation. No verifiable datasets are identified.",
      "processing_time": 46.37790822982788,
      "citing_paper_id": "272444877",
      "cited_paper_id": null
    },
    {
      "context_text": "…generation approaches for language learning primarily retrieve and manipulate text to create fixed types of exercises, such as gap fill and multiple-choice exercises (Agarwal and Mannem, 2011; Perez and Cuadros, 2017; Heck and Meurers, 2022), which are limited by the richness of the corpus.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'corpus' but does not specify a named dataset. The term 'corpus' is too generic and lacks a specific identifier.",
      "processing_time": 45.2205126285553,
      "citing_paper_id": "259075310",
      "cited_paper_id": 3038382
    },
    {
      "context_text": "…generation approaches for language learning primarily retrieve and manipulate text to create fixed types of exercises, such as gap fill and multiple-choice exercises (Agarwal and Mannem, 2011; Perez and Cuadros, 2017; Heck and Meurers, 2022), which are limited by the richness of the corpus.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'corpus' but does not specify a named dataset. The term 'corpus' is too generic and lacks a specific identifier.",
      "processing_time": 45.2205126285553,
      "citing_paper_id": "259075310",
      "cited_paper_id": 250390433
    },
    {
      "context_text": "The two baselines perform poorly on BLEU, METEOR, and KC-Coverage metrics, particularly for unseen data.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. The context focuses on performance metrics rather than data sources.",
      "processing_time": 43.74183106422424,
      "citing_paper_id": "259075310",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "Evaluation metrics include reference-based BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005), KC-Coverage which is the percentage of target knowledge components (words) that appear in the outputs, D-MAE which is the mean absolute error between the input difficulty and output difficulty, Invalid which is the percentage of exercises that have grammar errors detected using an automatic tool 3 .",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and methods. The context is focused on describing various metrics used for evaluating machine translation and personalized text generation systems.",
      "processing_time": 46.227662324905396,
      "citing_paper_id": "259075310",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "Evaluation metrics include reference-based BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005), KC-Coverage which is the percentage of target knowledge components (words) that appear in the outputs, D-MAE which is the mean absolute error between the input difficulty and output…",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only evaluation metrics. The cited paper titles do not introduce any datasets either.",
      "processing_time": 44.235376834869385,
      "citing_paper_id": "259075310",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "…been done for automatically generating text-based exercises or questions for educational purposes in second language learning (Heck and Meurers, 2022; Perez and Cuadros, 2017), mathematics (Polozov et al., 2015; Zhou and Huang, 2019; Wang et al., 2021), and computer science (Susanti et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research. The cited papers' titles suggest a focus on math word problem generation, but do not provide specific dataset names.",
      "processing_time": 46.94619965553284,
      "citing_paper_id": "259075310",
      "cited_paper_id": 11767561
    },
    {
      "context_text": "…been done for automatically generating text-based exercises or questions for educational purposes in second language learning (Heck and Meurers, 2022; Perez and Cuadros, 2017), mathematics (Polozov et al., 2015; Zhou and Huang, 2019; Wang et al., 2021), and computer science (Susanti et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research. The cited papers' titles suggest a focus on math word problem generation, but do not provide specific dataset names.",
      "processing_time": 46.94619965553284,
      "citing_paper_id": "259075310",
      "cited_paper_id": 209387630
    },
    {
      "context_text": "…been done for automatically generating text-based exercises or questions for educational purposes in second language learning (Heck and Meurers, 2022; Perez and Cuadros, 2017), mathematics (Polozov et al., 2015; Zhou and Huang, 2019; Wang et al., 2021), and computer science (Susanti et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research. The cited papers' titles suggest a focus on math word problem generation, but do not provide specific dataset names.",
      "processing_time": 46.94619965553284,
      "citing_paper_id": "259075310",
      "cited_paper_id": 237485277
    },
    {
      "context_text": "Knowledge Tracing (Corbett and Anderson, 1994) is the technique to estimate students’ knowledge mastery s from their practiced exercises ( e ) and responses ( r ): Early KT approaches model f KT as variants of logistic regression, such as Item Response Theory (IRT) and Additive Factor Model (AFM) (Cen et al., 2008), or probabilistic models such as Bayesian Knowledge Tracing (Corbett and Anderson, 1994) and its variants (Yudelson et al., 2013; Käser et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses various models and methods for knowledge tracing but does not mention any specific datasets. The focus is on the methodologies and models used in the field.",
      "processing_time": 46.06705188751221,
      "citing_paper_id": "259075310",
      "cited_paper_id": 18754233
    },
    {
      "context_text": "Knowledge Tracing (Corbett and Anderson, 1994) is the technique to estimate students’ knowledge mastery s from their practiced exercises ( e ) and responses ( r ): Early KT approaches model f KT as variants of logistic regression, such as Item Response Theory (IRT) and Additive Factor Model (AFM) (Cen et al., 2008), or probabilistic models such as Bayesian Knowledge Tracing (Corbett and Anderson, 1994) and its variants (Yudelson et al., 2013; Käser et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses various models and methods for knowledge tracing but does not mention any specific datasets. The focus is on the methodologies and models used in the field.",
      "processing_time": 46.06705188751221,
      "citing_paper_id": "259075310",
      "cited_paper_id": 19228797
    },
    {
      "context_text": "…( r ): Early KT approaches model f KT as variants of logistic regression, such as Item Response Theory (IRT) and Additive Factor Model (AFM) (Cen et al., 2008), or probabilistic models such as Bayesian Knowledge Tracing (Corbett and Anderson, 1994) and its variants (Yudelson et al., 2013;…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 45.009016036987305,
      "citing_paper_id": "259075310",
      "cited_paper_id": 18754233
    },
    {
      "context_text": "Knowledge Tracing (Corbett and Anderson, 1994) is the technique to estimate students’ knowledge mastery s from their practiced exercises ( e ) and responses ( r ): Early KT approaches model f KT as variants of logistic regression, such as Item Response Theory (IRT) and Additive Factor Model (AFM)…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The focus is on the technique of Knowledge Tracing and its variants.",
      "processing_time": 45.45193290710449,
      "citing_paper_id": "259075310",
      "cited_paper_id": 19228797
    },
    {
      "context_text": "…KT approaches model f KT as variants of logistic regression, such as Item Response Theory (IRT) and Additive Factor Model (AFM) (Cen et al., 2008), or probabilistic models such as Bayesian Knowledge Tracing (Corbett and Anderson, 1994) and its variants (Yudelson et al., 2013; Käser et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 45.465409994125366,
      "citing_paper_id": "259075310",
      "cited_paper_id": 19228797
    },
    {
      "context_text": "…KT approaches model f KT as variants of logistic regression, such as Item Response Theory (IRT) and Additive Factor Model (AFM) (Cen et al., 2008), or probabilistic models such as Bayesian Knowledge Tracing (Corbett and Anderson, 1994) and its variants (Yudelson et al., 2013; Käser et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 45.465409994125366,
      "citing_paper_id": "259075310",
      "cited_paper_id": 27572397
    },
    {
      "context_text": "Piech et al. (2015) proposed the first Deep Knowledge Tracing model based on Recurrent Neural Networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (Deep Knowledge Tracing) and its underlying technology (Recurrent Neural Networks).",
      "processing_time": 16.422426223754883,
      "citing_paper_id": "259075310",
      "cited_paper_id": 19228797
    },
    {
      "context_text": "Then, we propose an approach (§ 4) that marries knowledge tracing (KT; Corbett and Anderson (1994)), a technique for estimating students’ mastery states of knowledge components from their learning history, with a controlled text generation model that generates the next exercise based on instructor…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (knowledge tracing) and a general approach to text generation. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 46.78716588020325,
      "citing_paper_id": "259075310",
      "cited_paper_id": 19228797
    },
    {
      "context_text": "We denote our DKT model jointly trained with the LM-based exercise generator as DKT LM and compare it with the following base-lines: 1) Ensemble (Osika et al., 2018) which is one of the winning methods of the SLAM challenge that combines a RNN and a GBDT classifier.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing a DKT model with an ensemble method from a cited paper.",
      "processing_time": 46.35975980758667,
      "citing_paper_id": "259075310",
      "cited_paper_id": 46940529
    },
    {
      "context_text": "We present the results in Table 1, where we can see that DKT outperforms the Ensemble model when only text features are used, and our best model DKT LM ,τ =2 outperforms DKT on all metrics.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model performance comparisons. There are no clear identifiers for datasets in the text.",
      "processing_time": 45.00822138786316,
      "citing_paper_id": "259075310",
      "cited_paper_id": 46940529
    },
    {
      "context_text": "The cross-entropy loss for a single student’s history of N interactions is computed as: We adopt the regularization strategy proposed by Yeung and Yeung (2018) to stabilize training: where L r 1 ensures that only the states of relevant knowledge components are updated, and L r 2 pe-nalizes the…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a regularization strategy. No verifiable resources are identified.",
      "processing_time": 43.96485447883606,
      "citing_paper_id": "259075310",
      "cited_paper_id": 46941428
    },
    {
      "context_text": "5 and 6) to alleviate such inconsistencies (Yeung and Yeung, 2018), which we found can reduce the variance of simulation results and improve KT performance (Appendix C).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach to improve knowledge tracing performance.",
      "processing_time": 43.962910652160645,
      "citing_paper_id": "259075310",
      "cited_paper_id": 46941428
    },
    {
      "context_text": "After that, various architectures have been applied to model different characteristics of learning, such as self-attention (Pandey and Karypis, 2019; Shin et al., 2021), memory networks (Ab-delrahman and Wang, 2019), and graph neural networks (Tong et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various architectures and models. No verifiable resources are identified.",
      "processing_time": 44.61452007293701,
      "citing_paper_id": "259075310",
      "cited_paper_id": 195891353
    },
    {
      "context_text": "After that, various architectures have been applied to model different characteristics of learning, such as self-attention (Pandey and Karypis, 2019; Shin et al., 2021), memory networks (Ab-delrahman and Wang, 2019), and graph neural networks (Tong et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various architectures and models. No verifiable resources are identified.",
      "processing_time": 44.61452007293701,
      "citing_paper_id": "259075310",
      "cited_paper_id": 231915098
    },
    {
      "context_text": "Existing CTG approaches can be broadly classified into three types: directly training a class-conditional language model (CCLM) (Keskar et al., 2019; Ziegler et al., 2019; Ficler and Goldberg, 2017), guiding a model via an attribute discrimi-nator (Dathathri et al., 2020; Liu et al., 2020), or…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 44.61109662055969,
      "citing_paper_id": "259075310",
      "cited_paper_id": 202660943
    },
    {
      "context_text": "For the exercise generator, we fine-tune a pre-trained BART-base 5 https://huggingface.co/docs/transformers/index (Lewis et al., 2020) for up to 10 epochs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions fine-tuning a pre-trained BART-base model but does not reference any specific dataset. The citation is primarily about the model and its training process.",
      "processing_time": 46.776352405548096,
      "citing_paper_id": "259075310",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "Another related line of research studies exercise recommendation to customize learning content based on individual ca-a pabilities and goals (Wu et al., 2020; Huang et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only related research on exercise recommendation. No clear identifiers for datasets are present.",
      "processing_time": 45.68627309799194,
      "citing_paper_id": "259075310",
      "cited_paper_id": 225159510
    },
    {
      "context_text": "This is analogous to the relationship of knowledge components, which has been shown helpful in knowledge tracing (Tong et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach related to knowledge tracing.",
      "processing_time": 44.60889720916748,
      "citing_paper_id": "259075310",
      "cited_paper_id": 231915098
    },
    {
      "context_text": "This can be regarded as the relationship between knowledge components, which is demonstrated effective in knowledge tracing (Tong et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach in knowledge tracing.",
      "processing_time": 45.1910617351532,
      "citing_paper_id": "259075310",
      "cited_paper_id": 231915098
    },
    {
      "context_text": "We follow Srivastava and Goodman (2021) to improve its novelty using a repetition penalty during the generation, but this results in far more invalid exercises (1.7%).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving novelty in text generation.",
      "processing_time": 44.604572057724,
      "citing_paper_id": "259075310",
      "cited_paper_id": 235368201
    },
    {
      "context_text": "Recently, Srivastava and Goodman (2021) proposed an adaptive question generation model that connects question difficulty with student knowledge.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its application. No verifiable resources are identified.",
      "processing_time": 46.49554777145386,
      "citing_paper_id": "259075310",
      "cited_paper_id": 235368201
    },
    {
      "context_text": "Besides them, some Question Generation (QG) approaches have been proposed for educational purposes (Zhao et al., 2022; Wang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches for question generation in educational contexts.",
      "processing_time": 46.20306134223938,
      "citing_paper_id": "259075310",
      "cited_paper_id": 237485277
    },
    {
      "context_text": "Besides them, some Question Generation (QG) approaches have been proposed for educational purposes (Zhao et al., 2022; Wang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general approaches for question generation in educational contexts.",
      "processing_time": 46.20306134223938,
      "citing_paper_id": "259075310",
      "cited_paper_id": 247762874
    },
    {
      "context_text": "Drawing inspiration from Lu et al. (2022), we use lookahead heuristics that incorporate future estimates into the decoding process.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for constrained text generation.",
      "processing_time": 45.88439178466797,
      "citing_paper_id": "259075310",
      "cited_paper_id": 245218671
    },
    {
      "context_text": "Empirical studies have shown various benefits of adaptive learning, such as improved student learning outcomes (Bailey et al., 2018; Holthaus et al., 2019), lower dropout rates (Daines et al., 2016), and increased instructor satisfaction (Yarnall et al., 2016).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general findings from empirical studies. No dataset names are present in the text.",
      "processing_time": 48.018380641937256,
      "citing_paper_id": "259075310",
      "cited_paper_id": 251308055
    },
    {
      "context_text": "ComFusion will finetune specific pretrained diffusion models, e.g. , Stable Diffusion [29], which consists of an auto-encoder (encoder E and a decoder D ), text-encoder Γ , and a denoising model ϵ θ architectured with UNET [30].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and architectures. No verifiable resources are identified.",
      "processing_time": 47.56727886199951,
      "citing_paper_id": "267751132",
      "cited_paper_id": 3719281
    },
    {
      "context_text": "ComFusion will finetune specific pretrained diffusion models, e.g. , Stable Diffusion [29], which consists of an auto-encoder (encoder E and a decoder D ), text-encoder Γ , and a denoising model ϵ θ architectured with UNET [30].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and architectures. No verifiable resources are identified.",
      "processing_time": 47.56727886199951,
      "citing_paper_id": "267751132",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Early studies in training generative models in few-shot setting focus on alleviating mode collapse [23, 35, 39] for generative adversarial networks [7, 8, 13–15, 22, 42].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative models and mode collapse issues. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 49.25091004371643,
      "citing_paper_id": "267751132",
      "cited_paper_id": 201669163
    },
    {
      "context_text": "Early studies in training generative models in few-shot setting focus on alleviating mode collapse [23, 35, 39] for generative adversarial networks [7, 8, 13–15, 22, 42].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative models and mode collapse issues. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 49.25091004371643,
      "citing_paper_id": "267751132",
      "cited_paper_id": 250607546
    },
    {
      "context_text": "Early studies in training generative models in few-shot setting focus on alleviating mode collapse [23, 35, 39] for generative adversarial networks [7, 8, 13–15, 22, 42].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative models and mode collapse issues. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 49.25091004371643,
      "citing_paper_id": "267751132",
      "cited_paper_id": 253760983
    },
    {
      "context_text": "Early studies in training generative models in few-shot setting focus on alleviating mode collapse [23, 35, 39] for generative adversarial networks [7, 8, 13–15, 22, 42].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only generative models and mode collapse issues. The cited papers' titles do not introduce any specific datasets either.",
      "processing_time": 49.25091004371643,
      "citing_paper_id": "267751132",
      "cited_paper_id": 263792502
    },
    {
      "context_text": "Both TI [4] and XTI [14] consistently struggle to accurately depict specific scenes described in the input prompts.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (TI and XTI) and their performance issues. No verifiable resources are identified.",
      "processing_time": 48.8208909034729,
      "citing_paper_id": "267751132",
      "cited_paper_id": 220968925
    },
    {
      "context_text": "CD [7] • XTI [14] : Following original setting in [14], XTI adopts a reduced learning rate of 0 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (XTI) and a reference to a learning rate setting. There are no verifiable resources or datasets mentioned.",
      "processing_time": 49.66938853263855,
      "citing_paper_id": "267751132",
      "cited_paper_id": 220968925
    },
    {
      "context_text": "Images generated by DreamBooth [11], TI [4],CD [7],XTI [14],ELITE [15], Break-A-Scene [1], and our proposed ComFusion in multiple specific scenes from a single instance image. indicated by the CLIP-T score, with the increase in the number of instance images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods for image generation. The context focuses on comparing different techniques using a metric called CLIP-T score.",
      "processing_time": 49.78873801231384,
      "citing_paper_id": "267751132",
      "cited_paper_id": 220968925
    },
    {
      "context_text": "It’s noteworthy that existing personalization methods, such as DreamBooth [11], TI [4], CD [7], and XTI [14] typically require multiple images as input, in contrast to Break-A-Scene [1] and ELITE [15], which leverage a single image with a mask indicating the target concept.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 49.09063792228699,
      "citing_paper_id": "267751132",
      "cited_paper_id": 220968925
    },
    {
      "context_text": "This [11], TI [4],CD [7],XTI [14],ELITE [15], Break-A-Scene [1], and our proposed ComFusion in multiple specific scenes from a single instance image.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models or methods. There are no clear identifiers for datasets.",
      "processing_time": 48.574225425720215,
      "citing_paper_id": "267751132",
      "cited_paper_id": 220968925
    },
    {
      "context_text": "• Extended Textual-Inversion (XTI) [14]: Building on TI [4], XTI inverts input images into a set of token embeddings, one per layer, demonstrating faster, more expressive, and precise results than TI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (XTI) and a comparison to another method (TI).",
      "processing_time": 49.39326739311218,
      "citing_paper_id": "267751132",
      "cited_paper_id": 220968925
    },
    {
      "context_text": "In contrast, CLIP [27] is at the forefront of image-text cross-modality pretraining.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CLIP) which is not included as per instructions.",
      "processing_time": 49.39198303222656,
      "citing_paper_id": "267751132",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "…θ is trained on the latent to produce subject latent based on the textual condition source from Γ( T ) , where T is the user-provided prompt providing the information ( e.g. , subject classes, instance attributes, scenes) of the generated images and Γ denotes the pretrained CLIP text encoder [27].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions using a pretrained CLIP text encoder but does not specify a dataset. The context focuses on the methodology and the use of a pretrained model rather than a specific dataset.",
      "processing_time": 51.28985953330994,
      "citing_paper_id": "267751132",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "CLIP-I [27] and DINO score [3] were used to evaluate instance fidelity by measuring the similarity between generated images and instance images, and the alignment between textual scene with generated images are measured by CLIP-T [27].",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions CLIP-I and CLIP-T, which are evaluation methods, not datasets. No specific datasets are mentioned or used in the context.",
      "processing_time": 16.419312953948975,
      "citing_paper_id": "267751132",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "In stream of diffusion-based generators, personalized T2I generation methods can be classified into two categories: The first stream involves the integration of additional modules ( e.g. , [16, 26, 43]) with a pretrained base model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 50.30799913406372,
      "citing_paper_id": "267751132",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "In stream of diffusion-based generators, personalized T2I generation methods can be classified into two categories: The first stream involves the integration of additional modules ( e.g. , [16, 26, 43]) with a pretrained base model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 50.30799913406372,
      "citing_paper_id": "267751132",
      "cited_paper_id": 256827727
    },
    {
      "context_text": "All methods were applied using a pre-trained Stable Diffusion (SD) checkpoint 1.5 [29].",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a pre-trained Stable Diffusion checkpoint, which is a model, not a dataset. No datasets are explicitly mentioned or used in the given context.",
      "processing_time": 51.46696877479553,
      "citing_paper_id": "267751132",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Diffuion-Based Text-to-Image Generation : The field of Text-to-Image (T2I) generation has recently witnessed remarkable advancements [11, 18, 32, 36, 37, 43], predominantly led by pre-trained diffusion models such as Stable Diffusion [29], DALLE [28], Imagen [32] and etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 50.13514947891235,
      "citing_paper_id": "267751132",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Diffuion-Based Text-to-Image Generation : The field of Text-to-Image (T2I) generation has recently witnessed remarkable advancements [11, 18, 32, 36, 37, 43], predominantly led by pre-trained diffusion models such as Stable Diffusion [29], DALLE [28], Imagen [32] and etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 50.13514947891235,
      "citing_paper_id": "267751132",
      "cited_paper_id": 247778989
    },
    {
      "context_text": "Diffuion-Based Text-to-Image Generation : The field of Text-to-Image (T2I) generation has recently witnessed remarkable advancements [11, 18, 32, 36, 37, 43], predominantly led by pre-trained diffusion models such as Stable Diffusion [29], DALLE [28], Imagen [32] and etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 50.13514947891235,
      "citing_paper_id": "267751132",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "Diffuion-Based Text-to-Image Generation : The field of Text-to-Image (T2I) generation has recently witnessed remarkable advancements [11, 18, 32, 36, 37, 43], predominantly led by pre-trained diffusion models such as Stable Diffusion [29], DALLE [28], Imagen [32] and etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 50.13514947891235,
      "citing_paper_id": "267751132",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "Diffuion-Based Text-to-Image Generation : The field of Text-to-Image (T2I) generation has recently witnessed remarkable advancements [11, 18, 32, 36, 37, 43], predominantly led by pre-trained diffusion models such as Stable Diffusion [29], DALLE [28], Imagen [32] and etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 50.13514947891235,
      "citing_paper_id": "267751132",
      "cited_paper_id": 256827727
    },
    {
      "context_text": "Diffuion-Based Text-to-Image Generation : The field of Text-to-Image (T2I) generation has recently witnessed remarkable advancements [11, 18, 32, 36, 37, 43], predominantly led by pre-trained diffusion models such as Stable Diffusion [29], DALLE [28], Imagen [32] and etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 50.13514947891235,
      "citing_paper_id": "267751132",
      "cited_paper_id": 257427461
    },
    {
      "context_text": "In large-scale pretrained T2I models like Stable Diffusion [29], models trained on a vast array of image-text pairs demonstrate proficiency in generating novel images based on combinations of random texts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to models and their capabilities.",
      "processing_time": 50.42947793006897,
      "citing_paper_id": "267751132",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Recently, this field of T2I personalization has attracted significant attention from the academic community with many works [1, 2, 9, 19, 33, 38, 40, 41] leveraging the capabilities of advanced diffusion-based T2I models [28, 29, 32].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to works and models. No verifiable resources are identified.",
      "processing_time": 50.77912449836731,
      "citing_paper_id": "267751132",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Recently, this field of T2I personalization has attracted significant attention from the academic community with many works [1, 2, 9, 19, 33, 38, 40, 41] leveraging the capabilities of advanced diffusion-based T2I models [28, 29, 32].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to works and models. No verifiable resources are identified.",
      "processing_time": 50.77912449836731,
      "citing_paper_id": "267751132",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "Recently, this field of T2I personalization has attracted significant attention from the academic community with many works [1, 2, 9, 19, 33, 38, 40, 41] leveraging the capabilities of advanced diffusion-based T2I models [28, 29, 32].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to works and models. No verifiable resources are identified.",
      "processing_time": 50.77912449836731,
      "citing_paper_id": "267751132",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "Recently, this field of T2I personalization has attracted significant attention from the academic community with many works [1, 2, 9, 19, 33, 38, 40, 41] leveraging the capabilities of advanced diffusion-based T2I models [28, 29, 32].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to works and models. No verifiable resources are identified.",
      "processing_time": 50.77912449836731,
      "citing_paper_id": "267751132",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Recently, this field of T2I personalization has attracted significant attention from the academic community with many works [1, 2, 9, 19, 33, 38, 40, 41] leveraging the capabilities of advanced diffusion-based T2I models [28, 29, 32].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to works and models. No verifiable resources are identified.",
      "processing_time": 50.77912449836731,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "L total is employed to finetune the train-able parameters of text-encoder Γ and UNET ϵ θ based on pretrained Stable Diffusion [29].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and architectures. The citation is focused on the methodology of fine-tuning parameters using a loss function.",
      "processing_time": 52.380133628845215,
      "citing_paper_id": "267751132",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Personalized Text-to-Image Generation : Given a small set of images of the subject concept, personalized T2I generation [1, 5, 9, 10, 12, 19, 24, 28, 31–34, 38, 40, 41] aims to generate new images according to the text descriptions while maintaining the identity of the subject concept.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general description of personalized text-to-image generation. No verifiable resources are named.",
      "processing_time": 51.659242391586304,
      "citing_paper_id": "267751132",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "Personalized Text-to-Image Generation : Given a small set of images of the subject concept, personalized T2I generation [1, 5, 9, 10, 12, 19, 24, 28, 31–34, 38, 40, 41] aims to generate new images according to the text descriptions while maintaining the identity of the subject concept.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general description of personalized text-to-image generation. No verifiable resources are named.",
      "processing_time": 51.659242391586304,
      "citing_paper_id": "267751132",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Personalized Text-to-Image Generation : Given a small set of images of the subject concept, personalized T2I generation [1, 5, 9, 10, 12, 19, 24, 28, 31–34, 38, 40, 41] aims to generate new images according to the text descriptions while maintaining the identity of the subject concept.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general description of personalized text-to-image generation. No verifiable resources are named.",
      "processing_time": 51.659242391586304,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258546711
    },
    {
      "context_text": "3 with DreamBooth [31], Textual-Inversion(TI) [9], Custom-Diffusion (CD) [19], Extended Textual-Inversion (XTI) [40], ELITE [41], and Break-A-Scene [2].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.17909836769104,
      "citing_paper_id": "267751132",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "3 with DreamBooth [31], Textual-Inversion(TI) [9], Custom-Diffusion (CD) [19], Extended Textual-Inversion (XTI) [40], ELITE [41], and Break-A-Scene [2].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.17909836769104,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "In contrast, the second category [2, 9, 19, 31] infocuses on finetuning the pretrained model with a select set of images, employing various regularization techniques and training strategies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods and strategies for fine-tuning pretrained models.",
      "processing_time": 51.01943230628967,
      "citing_paper_id": "267751132",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "In contrast, the second category [2, 9, 19, 31] infocuses on finetuning the pretrained model with a select set of images, employing various regularization techniques and training strategies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods and strategies for fine-tuning pretrained models.",
      "processing_time": 51.01943230628967,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "This challenge has sparked interest in the rapidly evolving field of personalized T2I generation [9, 19, 24, 31, 38].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general interest in personalized T2I generation. No verifiable resources are identified.",
      "processing_time": 52.373979568481445,
      "citing_paper_id": "267751132",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Recent finetuning-based methods [19, 40] focus on how to design training strategy to update core parameters of T2I model for subject concepts on user-provided 4-6 images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach to fine-tuning text-to-image models. No verifiable resources are identified.",
      "processing_time": 52.79355764389038,
      "citing_paper_id": "267751132",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Finetuning : Various methods employ diverse training strategies to optimize different modules within pretrained models [9, 19, 31].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and strategies for finetuning pretrained models.",
      "processing_time": 51.270593881607056,
      "citing_paper_id": "267751132",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "DreamBooth [31] 3.1% 3.8% TI [9] 0.3% 0.0% CD [19] 6.2% 1.0% XTI [40] 0.3% 1.8% ELITE [41] 0.0% 11.1% Break-A-Scene [2] 34.5% 20.2% Ours 55.6% 62.1%",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only model performance comparisons. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 53.06869316101074,
      "citing_paper_id": "267751132",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "DreamBooth [31] 3.1% 3.8% TI [9] 0.3% 0.0% CD [19] 6.2% 1.0% XTI [40] 0.3% 1.8% ELITE [41] 0.0% 11.1% Break-A-Scene [2] 34.5% 20.2% Ours 55.6% 62.1%",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only model performance comparisons. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 53.06869316101074,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "Following DreamBooth [31] and CD [19], we evaluate those methods on two dimensions including instance fidelity and scene fidelity.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation dimensions. No verifiable resources are identified.",
      "processing_time": 51.64934706687927,
      "citing_paper_id": "267751132",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "31], TI [9],CD [19],XTI [40],ELITE [41], Break-A-Scene [2], and our proposed ComFusion in multiple specific scenes from a single instance image.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (TI, CD, XTI, ELITE, Break-A-Scene, ComFusion) but does not refer to any specific datasets. The focus is on comparing different approaches in generating multiple specific scenes from a single instance image.",
      "processing_time": 58.25140142440796,
      "citing_paper_id": "267751132",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "31], TI [9],CD [19],XTI [40],ELITE [41], Break-A-Scene [2], and our proposed ComFusion in multiple specific scenes from a single instance image.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (TI, CD, XTI, ELITE, Break-A-Scene, ComFusion) but does not refer to any specific datasets. The focus is on comparing different approaches in generating multiple specific scenes from a single instance image.",
      "processing_time": 58.25140142440796,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "DisenBooth [5] uses weak denoising and contrastive embedding auxiliary tuning objectives for personalization.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for personalization in text-to-image generation.",
      "processing_time": 51.83070707321167,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258546711
    },
    {
      "context_text": "The images, generated by existing leading meth-ods [2, 31] and our proposed approach.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for generating images. There are no verifiable resources or datasets mentioned.",
      "processing_time": 52.61933207511902,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "Contrasting with existing methods [2, 31] , which often face challenges in simultaneously preserving instance fidelity and scene fidelity, ComFusion skillfully composites the instance image with textual prompts and fuses the visual details of the subject instance with the textual variations of the…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and challenges. The context focuses on the capabilities of ComFusion compared to existing methods.",
      "processing_time": 53.2450008392334,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "Recently, finetuning diffusion-based text-to-image model with a few images has also been explored in [2, 31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers exploring fine-tuning of models.",
      "processing_time": 51.81775212287903,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "Images generated by Break-A-Scene [2] maintain instance fidelity while may fail to composite subject instance in specific scenes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or tool called 'Break-A-Scene'. The context focuses on the capabilities and limitations of this method.",
      "processing_time": 54.3898286819458,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "Break-A-Scene [2] utilizes the subject concept’s mask and employs a two-stage process for personalized T2I generation using a single image.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for personalized text-to-image generation.",
      "processing_time": 51.9976167678833,
      "citing_paper_id": "267751132",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "Following DreamBooth [11], we use DINO score [2], and CLIP-I [8] to evaluate instance fidelity, and use CLIP-T [8] to evaluate the scene fidelity.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models and methods (DINO score, CLIP-I, CLIP-T) but does not reference any specific datasets. The context is focused on evaluation metrics rather than data sources.",
      "processing_time": 55.7524356842041,
      "citing_paper_id": "267751132",
      "cited_paper_id": 263792502
    },
    {
      "context_text": "• CLIP-T [11]: This metric evaluates the alignment between the textual prompts and the image [8] embeddings, thereby assessing the fidelity of the input scene as represented in the generated images.",
      "catation_intent": "none",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (CLIP-T) and a general reference to image embeddings. No verifiable datasets are identified.",
      "processing_time": 54.125927209854126,
      "citing_paper_id": "267751132",
      "cited_paper_id": 263792502
    },
    {
      "context_text": "• CLIP-I [11]: Measures the average pairwise cosine similarity between CLIP [8] embeddings of generated and real images.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for measuring similarity using CLIP embeddings.",
      "processing_time": 52.155911445617676,
      "citing_paper_id": "267751132",
      "cited_paper_id": 263792502
    },
    {
      "context_text": "Text-guided human pose generation [23, 69, 51, 29, 26] has made significant progress by combining large-scale language models with generative techniques.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general progress in text-guided human pose generation. No dataset names are present in the text.",
      "processing_time": 54.122528076171875,
      "citing_paper_id": "280296439",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Text-guided human pose generation [23, 69, 51, 29, 26] has made significant progress by combining large-scale language models with generative techniques.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general progress in text-guided human pose generation. No dataset names are present in the text.",
      "processing_time": 54.122528076171875,
      "citing_paper_id": "280296439",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "Text-guided human pose generation [23, 69, 51, 29, 26] has made significant progress by combining large-scale language models with generative techniques.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general progress in text-guided human pose generation. No dataset names are present in the text.",
      "processing_time": 54.122528076171875,
      "citing_paper_id": "280296439",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "Text-guided human pose generation [23, 69, 51, 29, 26] has made significant progress by combining large-scale language models with generative techniques.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general progress in text-guided human pose generation. No dataset names are present in the text.",
      "processing_time": 54.122528076171875,
      "citing_paper_id": "280296439",
      "cited_paper_id": 259262201
    },
    {
      "context_text": "Text-guided human pose generation [23, 69, 51, 29, 26] has made significant progress by combining large-scale language models with generative techniques.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general progress in text-guided human pose generation. No dataset names are present in the text.",
      "processing_time": 54.122528076171875,
      "citing_paper_id": "280296439",
      "cited_paper_id": 264935374
    },
    {
      "context_text": "Early GAN pipelines, such as PG 2 [44], SGW-GAN[13], and FD-GAN [17], attempted to merge a reference image with a target pose, but often suffered from blurred textures and poor handling of large structural deformations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses GAN pipelines but does not mention any specific datasets. The focus is on the methodologies and their limitations.",
      "processing_time": 52.89373850822449,
      "citing_paper_id": "280296439",
      "cited_paper_id": 30484693
    },
    {
      "context_text": "Early GAN pipelines, such as PG 2 [44], SGW-GAN[13], and FD-GAN [17], attempted to merge a reference image with a target pose, but often suffered from blurred textures and poor handling of large structural deformations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses GAN pipelines but does not mention any specific datasets. The focus is on the methodologies and their limitations.",
      "processing_time": 52.89373850822449,
      "citing_paper_id": "280296439",
      "cited_paper_id": 52941531
    },
    {
      "context_text": "Early GAN pipelines, such as PG 2 [44], SGW-GAN[13], and FD-GAN [17], attempted to merge a reference image with a target pose, but often suffered from blurred textures and poor handling of large structural deformations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses GAN pipelines but does not mention any specific datasets. The focus is on the methodologies and their limitations.",
      "processing_time": 52.89373850822449,
      "citing_paper_id": "280296439",
      "cited_paper_id": 53093005
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 30484693
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 52941531
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 53093005
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 235731535
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 248986248
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 250113850
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 254043959
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 268041236
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 268876071
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 270226625
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 271161859
    },
    {
      "context_text": "Pose-guided person image synthesis [44, 13, 17, 59, 72, 30, 68, 43, 21, 25, 5, 37] aims to render photorealistic images of a given individual under a specified pose and has become central to virtual try-on, character animation, and data augmentation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the general concept of pose-guided person image synthesis. No verifiable resources are named.",
      "processing_time": 17.90997576713562,
      "citing_paper_id": "280296439",
      "cited_paper_id": 276117223
    },
    {
      "context_text": "In parallel, the OpenPose engine [8] detects 18 anatomical landmarks, producing a keypoint vector where each ( x i , y i ) gives the joint pixel coordinates i .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the OpenPose engine but does not refer to a specific dataset. OpenPose is a method for pose estimation, not a dataset.",
      "processing_time": 53.88513398170471,
      "citing_paper_id": "280296439",
      "cited_paper_id": 198169848
    },
    {
      "context_text": "In Figure 3, to effectively train and evaluate our FashionPose framework, we construct PoseCap , an enriched corpus of over 40k image caption keypoint pairs derived from the DeepFashion dataset [39], chosen for its rich clothing diversity and reliable annotations.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DeepFashion"
      ],
      "dataset_descriptions": {
        "DeepFashion": "Used to construct PoseCap, an enriched corpus of over 40k image caption keypoint pairs, to train and evaluate the FashionPose framework, leveraging its rich clothing diversity and reliable annotations."
      },
      "confidence_score": 1.0,
      "reasoning": "PoseCap is constructed from the DeepFashion dataset, which is used to train and evaluate the FashionPose framework. DeepFashion is chosen for its rich clothing diversity and reliable annotations.",
      "processing_time": 63.19103288650513,
      "citing_paper_id": "280296439",
      "cited_paper_id": 206593370
    },
    {
      "context_text": "From Figure 4, we qualitatively compare our method with eight recent pose-guided person-image generators, namely ADGAN [46], PISE [78], GFLA [53], DPTN [82], CASD [84], NTED [52], PIDM [7], and PCDMs [62].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (ADGAN, PISE, GFLA, DPTN, CASD, NTED, PIDM, PCDMs) but does not refer to any specific datasets. The citation intent is to compare methods, not to use datasets.",
      "processing_time": 59.515111684799194,
      "citing_paper_id": "280296439",
      "cited_paper_id": 211677243
    },
    {
      "context_text": "From Figure 4, we qualitatively compare our method with eight recent pose-guided person-image generators, namely ADGAN [46], PISE [78], GFLA [53], DPTN [82], CASD [84], NTED [52], PIDM [7], and PCDMs [62].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (ADGAN, PISE, GFLA, DPTN, CASD, NTED, PIDM, PCDMs) but does not refer to any specific datasets. The citation intent is to compare methods, not to use datasets.",
      "processing_time": 59.515111684799194,
      "citing_paper_id": "280296439",
      "cited_paper_id": 214693045
    },
    {
      "context_text": "From Figure 4, we qualitatively compare our method with eight recent pose-guided person-image generators, namely ADGAN [46], PISE [78], GFLA [53], DPTN [82], CASD [84], NTED [52], PIDM [7], and PCDMs [62].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (ADGAN, PISE, GFLA, DPTN, CASD, NTED, PIDM, PCDMs) but does not refer to any specific datasets. The citation intent is to compare methods, not to use datasets.",
      "processing_time": 59.515111684799194,
      "citing_paper_id": "280296439",
      "cited_paper_id": 232148091
    },
    {
      "context_text": "From Figure 4, we qualitatively compare our method with eight recent pose-guided person-image generators, namely ADGAN [46], PISE [78], GFLA [53], DPTN [82], CASD [84], NTED [52], PIDM [7], and PCDMs [62].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (ADGAN, PISE, GFLA, DPTN, CASD, NTED, PIDM, PCDMs) but does not refer to any specific datasets. The citation intent is to compare methods, not to use datasets.",
      "processing_time": 59.515111684799194,
      "citing_paper_id": "280296439",
      "cited_paper_id": 247292104
    },
    {
      "context_text": "From Figure 4, we qualitatively compare our method with eight recent pose-guided person-image generators, namely ADGAN [46], PISE [78], GFLA [53], DPTN [82], CASD [84], NTED [52], PIDM [7], and PCDMs [62].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (ADGAN, PISE, GFLA, DPTN, CASD, NTED, PIDM, PCDMs) but does not refer to any specific datasets. The citation intent is to compare methods, not to use datasets.",
      "processing_time": 59.515111684799194,
      "citing_paper_id": "280296439",
      "cited_paper_id": 248157334
    },
    {
      "context_text": "From Figure 4, we qualitatively compare our method with eight recent pose-guided person-image generators, namely ADGAN [46], PISE [78], GFLA [53], DPTN [82], CASD [84], NTED [52], PIDM [7], and PCDMs [62].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (ADGAN, PISE, GFLA, DPTN, CASD, NTED, PIDM, PCDMs) but does not refer to any specific datasets. The citation intent is to compare methods, not to use datasets.",
      "processing_time": 59.515111684799194,
      "citing_paper_id": "280296439",
      "cited_paper_id": 251224247
    },
    {
      "context_text": "From Figure 4, we qualitatively compare our method with eight recent pose-guided person-image generators, namely ADGAN [46], PISE [78], GFLA [53], DPTN [82], CASD [84], NTED [52], PIDM [7], and PCDMs [62].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (ADGAN, PISE, GFLA, DPTN, CASD, NTED, PIDM, PCDMs) but does not refer to any specific datasets. The citation intent is to compare methods, not to use datasets.",
      "processing_time": 59.515111684799194,
      "citing_paper_id": "280296439",
      "cited_paper_id": 253761291
    },
    {
      "context_text": "From Figure 4, we qualitatively compare our method with eight recent pose-guided person-image generators, namely ADGAN [46], PISE [78], GFLA [53], DPTN [82], CASD [84], NTED [52], PIDM [7], and PCDMs [62].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several methods/models (ADGAN, PISE, GFLA, DPTN, CASD, NTED, PIDM, PCDMs) but does not refer to any specific datasets. The citation intent is to compare methods, not to use datasets.",
      "processing_time": 59.515111684799194,
      "citing_paper_id": "280296439",
      "cited_paper_id": 263830081
    },
    {
      "context_text": "Subsequent work explored two major directions: (i) latent editing, as demonstrated by GANSpace [20] and QC-StyleGAN [47], which expose interpretable latent directions without retraining; and (ii) unified conditioning, typified by ImagPose [59], which fuses image-and feature-level pose cues through…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers are about GAN-based techniques, not datasets.",
      "processing_time": 54.10308384895325,
      "citing_paper_id": "280296439",
      "cited_paper_id": 214802845
    },
    {
      "context_text": "Subsequent work explored two major directions: (i) latent editing, as demonstrated by GANSpace [20] and QC-StyleGAN [47], which expose interpretable latent directions without retraining; and (ii) unified conditioning, typified by ImagPose [59], which fuses image-and feature-level pose cues through…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers are about GAN-based techniques, not datasets.",
      "processing_time": 54.10308384895325,
      "citing_paper_id": "280296439",
      "cited_paper_id": 254221091
    },
    {
      "context_text": "Adversarial frameworks such as PoseGAN [38] further enhance realism by resolving pose ambiguity and occlusion through discriminative learning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (PoseGAN).",
      "processing_time": 51.4239068031311,
      "citing_paper_id": "280296439",
      "cited_paper_id": 219980285
    },
    {
      "context_text": "The decoder performs 50 DDIM[65] iterations (noise schedule of { α t } omitted for brevity); a classifier-free guidance weight γ = 1 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DDIM) and parameters used in the decoding process.",
      "processing_time": 53.222925424575806,
      "citing_paper_id": "280296439",
      "cited_paper_id": 222140788
    },
    {
      "context_text": "In parallel, multimodal representation learning has advanced to the point where natural language prompts can be mapped reliably to pose structures via CLIP [51].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CLIP) for mapping natural language prompts to pose structures.",
      "processing_time": 53.604690074920654,
      "citing_paper_id": "280296439",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "First, every image passes through a YOLOX detector [18].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions YOLOX but does not refer to it as a dataset. It is clearly a method or model used for object detection.",
      "processing_time": 54.61682987213135,
      "citing_paper_id": "280296439",
      "cited_paper_id": 236088010
    },
    {
      "context_text": "5 [54]+Control blocks, ensuring a fair text-only comparison.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only refers to control blocks for a fair text-only comparison.",
      "processing_time": 54.366342544555664,
      "citing_paper_id": "280296439",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Transformer-based methods, including TEMOS [50] and T2M-GPT [77], utilize causal self-attention to model long-range dependencies and generate diverse, linguistically aligned motion outputs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers also do not provide additional information about datasets.",
      "processing_time": 54.35208868980408,
      "citing_paper_id": "280296439",
      "cited_paper_id": 248476220
    },
    {
      "context_text": "Transformer-based methods, including TEMOS [50] and T2M-GPT [77], utilize causal self-attention to model long-range dependencies and generate diverse, linguistically aligned motion outputs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers also do not provide additional information about datasets.",
      "processing_time": 54.35208868980408,
      "citing_paper_id": "280296439",
      "cited_paper_id": 255942203
    },
    {
      "context_text": "Besides TIPS [55], we re-implement ControlNet [79] by feeding only the pose captions into Stable Diffusion v1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 53.226529359817505,
      "citing_paper_id": "280296439",
      "cited_paper_id": 251040605
    },
    {
      "context_text": "Besides TIPS [55], we re-implement ControlNet [79] by feeding only the pose captions into Stable Diffusion v1.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 53.226529359817505,
      "citing_paper_id": "280296439",
      "cited_paper_id": 256827727
    },
    {
      "context_text": "We evaluate on the DF-PASS benchmark [55], whose 40,488 captioned images allow a fully text-guided protocol poses must be produced from captions alone, with no keypoint input.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "DF-PASS"
      ],
      "dataset_descriptions": {
        "DF-PASS": "Used to evaluate text-induced pose synthesis, focusing on generating poses from captions without keypoint input, containing 40,488 captioned images."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'DF-PASS benchmark' which is a specific dataset used for evaluating text-induced pose synthesis. It is clearly identified and used in the research context.",
      "processing_time": 62.60393500328064,
      "citing_paper_id": "280296439",
      "cited_paper_id": 251040605
    },
    {
      "context_text": "Diffusion-based pipelines such as MotionDiffuse [81] and Text2Human [27] can translate free-form sentences into temporally coherent motion sequences while capturing fine-grained semantics.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models or methods. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 54.36028814315796,
      "citing_paper_id": "280296439",
      "cited_paper_id": 251953565
    },
    {
      "context_text": "Works such as MotionDiffuse [81], Text2Human [27], and PoseScript [11] illustrate the feasibility of text to pose generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions works that demonstrate the feasibility of text to pose generation, but does not specify the use of any datasets. The cited papers are methods/models, not datasets.",
      "processing_time": 56.22284722328186,
      "citing_paper_id": "280296439",
      "cited_paper_id": 251953565
    },
    {
      "context_text": "Works such as MotionDiffuse [81], Text2Human [27], and PoseScript [11] illustrate the feasibility of text to pose generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions works that demonstrate the feasibility of text to pose generation, but does not specify the use of any datasets. The cited papers are methods/models, not datasets.",
      "processing_time": 56.22284722328186,
      "citing_paper_id": "280296439",
      "cited_paper_id": 253080823
    },
    {
      "context_text": "A frozen DINO-v2[49] encoder f DINO (vision transformer) produces appearance tokens , where 256 is the token length and 768 the channel dimension.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (DINO-v2) which is excluded according to the rules.",
      "processing_time": 54.35858511924744,
      "citing_paper_id": "280296439",
      "cited_paper_id": 258170077
    },
    {
      "context_text": "Second is unified representation learning: MotionGPT [26] demonstrates that discretizing 3D poses into motion tokens and treating them as a foreign language facilitates zero-shot transfer across domains.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (MotionGPT) and a concept (unified representation learning).",
      "processing_time": 54.85383224487305,
      "citing_paper_id": "280296439",
      "cited_paper_id": 259262201
    },
    {
      "context_text": "Early GAN-based solutions suffered from training instability and blurred textures, whereas recent diffusion frameworks most notably progressive refinements such as progressive conditional diffusion models (PCDMs) [62] have substantially improved perceptual quality and pose alignment.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the improvement of image synthesis techniques using PCDMs.",
      "processing_time": 27.631696224212646,
      "citing_paper_id": "280296439",
      "cited_paper_id": 263830081
    },
    {
      "context_text": "First is fine-grained controllability: recent methods such as Act-as-You-Wish [29] introduce semantic control graphs that decompose sentences into verbs, actions, and modifiers, enabling localized motion editing.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for fine-grained control of motion diffusion models.",
      "processing_time": 53.54787850379944,
      "citing_paper_id": "280296439",
      "cited_paper_id": 264935374
    },
    {
      "context_text": "Beyond motion generation, recent diffusion frameworks in related domains have demonstrated strong capabilities in structure-aware synthesis [58, 16], adaptive ensemble modeling [70], and temporally consistent portrait video generation [71].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 55.018028020858765,
      "citing_paper_id": "280296439",
      "cited_paper_id": 270063742
    },
    {
      "context_text": "Beyond motion generation, recent diffusion frameworks in related domains have demonstrated strong capabilities in structure-aware synthesis [58, 16], adaptive ensemble modeling [70], and temporally consistent portrait video generation [71].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 55.018028020858765,
      "citing_paper_id": "280296439",
      "cited_paper_id": 270226636
    },
    {
      "context_text": "Beyond motion generation, recent diffusion frameworks in related domains have demonstrated strong capabilities in structure-aware synthesis [58, 16], adaptive ensemble modeling [70], and temporally consistent portrait video generation [71].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 55.018028020858765,
      "citing_paper_id": "280296439",
      "cited_paper_id": 271244829
    },
    {
      "context_text": "Beyond motion generation, recent diffusion frameworks in related domains have demonstrated strong capabilities in structure-aware synthesis [58, 16], adaptive ensemble modeling [70], and temporally consistent portrait video generation [71].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 55.018028020858765,
      "citing_paper_id": "280296439",
      "cited_paper_id": 273001409
    },
    {
      "context_text": "Moreover, rich-context alignment and retrieval-augmented strategies have shown promise in improving semantic coherence in story-level generation [61].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only strategies and methods. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 26.689884424209595,
      "citing_paper_id": "280296439",
      "cited_paper_id": 270878382
    },
    {
      "context_text": "…demonstrated by GANSpace [20] and QC-StyleGAN [47], which expose interpretable latent directions without retraining; and (ii) unified conditioning, typified by ImagPose [59], which fuses image-and feature-level pose cues through cross-view attention to enhance structural control and generalization.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the methodologies used for pose-guided person generation.",
      "processing_time": 55.30079674720764,
      "citing_paper_id": "280296439",
      "cited_paper_id": 276117223
    },
    {
      "context_text": "…[63] introduces a framework for fine-grained fashion design by decomposing garment attributes into layout, color, and style tokens, while Long-Term TalkingFace [60] incorporates motion priors and temporal memory modules to ensure consistent facial synthesis across long video sequences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on describing the methodologies used in the cited papers.",
      "processing_time": 54.97378611564636,
      "citing_paper_id": "280296439",
      "cited_paper_id": 276317891
    },
    {
      "context_text": "Finally, the pretrained IC-Light [80] relighter enforces consistent global illumination, yielding the photorealistic result on the right. most existing pipelines still require an explicit pose input before image synthesis, leaving illumination either fixed or addressed only by post-hoc editing.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (IC-Light) and a general discussion about image synthesis pipelines.",
      "processing_time": 54.989290952682495,
      "citing_paper_id": "280296439",
      "cited_paper_id": 277677790
    },
    {
      "context_text": "Finally, the system applies a lightweight, diffusion-based relighting module IC-Light [80] which adjusts the global illumination based on the same input prompt.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (IC-Light) for adjusting global illumination. No verifiable datasets are referenced.",
      "processing_time": 55.47051405906677,
      "citing_paper_id": "280296439",
      "cited_paper_id": 277677790
    },
    {
      "context_text": "IC-Light [80] emphasises that photorealism deteriorates if lighting is inconsistent with scene semantics.",
      "catation_intent": "findings",
      "resource_type": "finding",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or finding about photorealism and lighting consistency.",
      "processing_time": 54.030028343200684,
      "citing_paper_id": "280296439",
      "cited_paper_id": 277677790
    },
    {
      "context_text": "Recent extensions further expand this controllability: IMAGGarment-1 [63] introduces a framework for fine-grained fashion design by decomposing garment attributes into layout, color, and style tokens, while Long-Term TalkingFace [60] incorporates motion priors and temporal memory modules to ensure…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'IMAGGarment-1' as a framework for fine-grained fashion design, which is not a dataset but a method or tool. No other specific datasets are mentioned.",
      "processing_time": 57.61388158798218,
      "citing_paper_id": "280296439",
      "cited_paper_id": 277857630
    },
    {
      "context_text": "Previous models such as GAN [10]–[19], VAE [20]–[23], Autoregressive [24], [25], Flow [26], [27] were adopted to model the dataset distribution, and then synthesize new realistic images through sampling from the modeled distribution.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions various models (GAN, VAE, Autoregressive, Flow) but does not specify any particular dataset. The focus is on the models and their application in synthesizing new realistic images.",
      "processing_time": 57.931504011154175,
      "citing_paper_id": "267365273",
      "cited_paper_id": 13995862
    },
    {
      "context_text": "Previous models such as GAN [10]–[19], VAE [20]–[23], Autoregressive [24], [25], Flow [26], [27] were adopted to model the dataset distribution, and then synthesize new realistic images through sampling from the modeled distribution.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions various models (GAN, VAE, Autoregressive, Flow) but does not specify any particular dataset. The focus is on the models and their application in synthesizing new realistic images.",
      "processing_time": 57.931504011154175,
      "citing_paper_id": "267365273",
      "cited_paper_id": 211146177
    },
    {
      "context_text": "Previous models such as GAN [10]–[19], VAE [20]–[23], Autoregressive [24], [25], Flow [26], [27] were adopted to model the dataset distribution, and then synthesize new realistic images through sampling from the modeled distribution.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions various models (GAN, VAE, Autoregressive, Flow) but does not specify any particular dataset. The focus is on the models and their application in synthesizing new realistic images.",
      "processing_time": 57.931504011154175,
      "citing_paper_id": "267365273",
      "cited_paper_id": 229297973
    },
    {
      "context_text": "Previous models such as GAN [10]–[19], VAE [20]–[23], Autoregressive [24], [25], Flow [26], [27] were adopted to model the dataset distribution, and then synthesize new realistic images through sampling from the modeled distribution.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions various models (GAN, VAE, Autoregressive, Flow) but does not specify any particular dataset. The focus is on the models and their application in synthesizing new realistic images.",
      "processing_time": 57.931504011154175,
      "citing_paper_id": "267365273",
      "cited_paper_id": 266736230
    },
    {
      "context_text": "Our utilized Stable Diffusion Model [4] consists of a CLIP text encoder [5], an AutoVAE [61] and a latent U-Net [62] module.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions components of a model (Stable Diffusion Model, CLIP text encoder, AutoVAE, latent U-Net) but does not reference any specific datasets. The cited papers do not introduce datasets either.",
      "processing_time": 58.704368114471436,
      "citing_paper_id": "267365273",
      "cited_paper_id": 173990382
    },
    {
      "context_text": "Our utilized Stable Diffusion Model [4] consists of a CLIP text encoder [5], an AutoVAE [61] and a latent U-Net [62] module.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions components of a model (Stable Diffusion Model, CLIP text encoder, AutoVAE, latent U-Net) but does not reference any specific datasets. The cited papers do not introduce datasets either.",
      "processing_time": 58.704368114471436,
      "citing_paper_id": "267365273",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "Our utilized Stable Diffusion Model [4] consists of a CLIP text encoder [5], an AutoVAE [61] and a latent U-Net [62] module.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions components of a model (Stable Diffusion Model, CLIP text encoder, AutoVAE, latent U-Net) but does not reference any specific datasets. The cited papers do not introduce datasets either.",
      "processing_time": 58.704368114471436,
      "citing_paper_id": "267365273",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "(4) Inference Recipe : During sampling time, we employ a DDIM sampler [65] with diffusion steps T = 50 and the classifier-guidance [66] with the guidance scale w = 7 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context is about the inference process using a DDIM sampler and classifier-guidance, which are not datasets.",
      "processing_time": 57.01290822029114,
      "citing_paper_id": "267365273",
      "cited_paper_id": 222140788
    },
    {
      "context_text": "Based on these, text-driven image manipulation [28]–[30] has achieved significant progress using GANs by combining text representations such as CLIP [5].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 55.28912091255188,
      "citing_paper_id": "267365273",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "Based on these, text-driven image manipulation [28]–[30] has achieved significant progress using GANs by combining text representations such as CLIP [5].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 55.28912091255188,
      "citing_paper_id": "267365273",
      "cited_paper_id": null
    },
    {
      "context_text": "Conditioned on the text embedding of the text encoder [5], these diffusion-based models are optimized by a simple denoising loss and can generate a new image by sampling Gaussian noise and a text prompt.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to a text encoder and diffusion-based models. No verifiable resource names are present.",
      "processing_time": 55.93108797073364,
      "citing_paper_id": "267365273",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "Except for ID representation, FaceStudio [56] deployed a CLIP vision encoder [5] to extract the structure features.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CLIP vision encoder) and a tool (FaceStudio).",
      "processing_time": 55.469860315322876,
      "citing_paper_id": "267365273",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "…Text-to-Image (T2I) models, such as the Stable Diffusion Model [4], have demonstrated an impressive ability to generate diverse, high-quality, and semantic-fidelity images using text prompts alone, thanks to image-aligned language encoders [5] and diffusion-based generative models [6], [7].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the capabilities of T2I models and their components.",
      "processing_time": 55.916898250579834,
      "citing_paper_id": "267365273",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "Inspired by the GAN In-version [46], recent diffusion-based personalized generation works can be divided into three categories: (1) Fine-Tuning T2I model : DreamBooth [9] fine-tunes all weight of the T2I model on a set of images with the same ID and marks it as the specific token.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methods and models, which are not considered datasets.",
      "processing_time": 54.99858236312866,
      "citing_paper_id": "267365273",
      "cited_paper_id": 231603119
    },
    {
      "context_text": "Existing methods either directly blended the latent code of objects [39], [40] to the generated background, or failed to understand the scenes correctly [41], which results in the obvious artifacts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and their limitations. There are no verifiable resources or datasets mentioned.",
      "processing_time": 55.27538514137268,
      "citing_paper_id": "267365273",
      "cited_paper_id": 244714366
    },
    {
      "context_text": "In the following sections, we first give an introduction of the pre-trained Stable Diffusion Model [4], and we then provide the details of our method.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a pre-trained model. No verifiable resources are identified.",
      "processing_time": 54.51459550857544,
      "citing_paper_id": "267365273",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Recent advanced diffusion models [6], [7] have shown excellent diversity and fidelity in text-to-image synthesis [4], [24], [31]–[34].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 54.7711341381073,
      "citing_paper_id": "267365273",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Recent advanced diffusion models [6], [7] have shown excellent diversity and fidelity in text-to-image synthesis [4], [24], [31]–[34].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 54.7711341381073,
      "citing_paper_id": "267365273",
      "cited_paper_id": 255372955
    },
    {
      "context_text": "(1) Target T2I Model : Unless otherwise specified, we utilize Stable Diffusion 1.4 [4] with default hyper parameters as the pre-trained diffusion-based T2I model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a pre-trained model (Stable Diffusion 1.4) but does not refer to any specific dataset. The citation is about using a model, not a dataset.",
      "processing_time": 57.9277503490448,
      "citing_paper_id": "267365273",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "C V ] 22 M a r 2024 R ECENTLY, Text-to-Image (T2I) models, such as the Stable Diffusion Model [4], have demonstrated an impressive ability to generate diverse, high-quality, and semantic-fidelity images using text prompts alone, thanks to image-aligned language encoders [5] and diffusion-based…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the capabilities of T2I models and their components.",
      "processing_time": 56.13574838638306,
      "citing_paper_id": "267365273",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "We adopt a frozen CLIP model [33] in the Stable Diffusion Model as the text encoder network.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (CLIP) used as a text encoder. No dataset names are present in the citation context.",
      "processing_time": 56.74721550941467,
      "citing_paper_id": "267365273",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "(1) Ob-jective Metrics : We select Prompt (CLIP alignment score [33] between text and image), ID (ID feature similarity score [67]), and Detect (face detection rate [67]).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only metrics and methods. The context focuses on objective metrics used for evaluation, which are not considered datasets.",
      "processing_time": 56.31942653656006,
      "citing_paper_id": "267365273",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "To further solve this problem, some work [42]–[45] adopted attention-based methods to manipulate target objects, but fail to balance the trade-off between content diversity and identity accuracy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and their limitations. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.33481287956238,
      "citing_paper_id": "267365273",
      "cited_paper_id": 251252882
    },
    {
      "context_text": "To further solve this problem, some work [42]–[45] adopted attention-based methods to manipulate target objects, but fail to balance the trade-off between content diversity and identity accuracy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and their limitations. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.33481287956238,
      "citing_paper_id": "267365273",
      "cited_paper_id": 257557738
    },
    {
      "context_text": "BootPIG [48] are combined to manipulate multi-concept interactions [8] or saving fine-tuning time and parameter amount [49]–[52].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.14124417304993,
      "citing_paper_id": "267365273",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "BootPIG [48] are combined to manipulate multi-concept interactions [8] or saving fine-tuning time and parameter amount [49]–[52].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.14124417304993,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258078844
    },
    {
      "context_text": "BootPIG [48] are combined to manipulate multi-concept interactions [8] or saving fine-tuning time and parameter amount [49]–[52].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.14124417304993,
      "citing_paper_id": "267365273",
      "cited_paper_id": 267212094
    },
    {
      "context_text": "BootPIG [48] are combined to manipulate multi-concept interactions [8] or saving fine-tuning time and parameter amount [49]–[52].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods or models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.14124417304993,
      "citing_paper_id": "267365273",
      "cited_paper_id": 268183380
    },
    {
      "context_text": "The previous methods for this task have two problems that need to be addressed: (1) Attention Overfit: Their fine-tuning strategies [8], [9], such as Texural Inversion [1] and ProSpect [2], tend to fit the whole target image rather than the ID-related face region, which entangle face layout and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on issues with attention mechanisms in fine-tuning strategies.",
      "processing_time": 56.13948321342468,
      "citing_paper_id": "267365273",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "…Fine-Tuning : DreamBooth [9] (learns a unique identifier and fine-tunes the diffusion model to learn from a set of images) and Custom Diffusion [8] (retrieves images with similar captions of the target concept and optimizes the cross-attention module with a modifier token); (2) Token…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on fine-tuning techniques for text-to-image diffusion models.",
      "processing_time": 56.33082699775696,
      "citing_paper_id": "267365273",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Custom Diffusion [8] and DreamBooth [9] tend to overly mimic the training image and fail to maintain identity when combined with other text prompts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods. The context focuses on the performance of Custom Diffusion and DreamBooth, which are not datasets.",
      "processing_time": 57.58929800987244,
      "citing_paper_id": "267365273",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Previous meth-ods [8], [50] differentiated the K and V features calculated from the same ID embedding P as position information and object texture features, which is not appropriate for manipulating facial attributes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 55.91054105758667,
      "citing_paper_id": "267365273",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Although DreamBooth [9] and Custom Diffusion [8] successfully generate the image of interaction of human and concept, the generated identities fail to maintain the ID consistency with the target images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods. The context focuses on the limitations of the models in maintaining identity consistency.",
      "processing_time": 56.55878472328186,
      "citing_paper_id": "267365273",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "On the other hand, methods such as Celeb Basis [3] and FastComposer [58] exhibit poor semantic fidelity and limited diversity in their generated outputs. propose a new metric for face personalized generation which is denoted as ID (P) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and a proposed metric. No verifiable resources are identified.",
      "processing_time": 55.61651802062988,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258740710
    },
    {
      "context_text": "FastComposer [58] used a delayed subject conditioning strategy to avoid subject overfitting, but they only focus on faces and fail to interact with other objects such as “sofa” as shown in Fig.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (FastComposer) and its limitations. No verifiable resources are identified.",
      "processing_time": 56.3240909576416,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258740710
    },
    {
      "context_text": "…textual conditioning space with several per-stage textual token embeddings), and Celeb Basis [3] (builds a well-defined face basis module to constrict the face manifold); (3) Tuning Free : FastComposer [58] (deploys a delayed subject conditioning strategy to achieve tuning-free image generation).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited paper title confirms that FastComposer is a method, not a dataset.",
      "processing_time": 57.18107533454895,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258740710
    },
    {
      "context_text": "In the experiments compared with FastComposer [58], The generated images by FastComposer predominantly feature the faces of the target IDs, occupying a significant portion of the images and it seems like that the characters are directly pasted into the picture, resulting in a disharmonious…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a comparison with a method called FastComposer. No verifiable datasets are referenced.",
      "processing_time": 56.3208281993866,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258740710
    },
    {
      "context_text": "However, evaluating the ID without the essence of T2I generation (i.e., Prompt-Image ] and Prospect [2] struggle to generate images that accurately reflect the semantics of “white hair“.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods. The context focuses on the limitations of certain models in generating images that reflect specific attributes.",
      "processing_time": 27.757187843322754,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258887639
    },
    {
      "context_text": "Due to attention overfit, Textual Inversion [1], Prospect [2] show poor Prompt-Image alignment.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or models. The context focuses on the performance of Textual Inversion and Prospect, which are methods, not datasets.",
      "processing_time": 58.321183919906616,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258887639
    },
    {
      "context_text": "…two problems that need to be addressed: (1) Attention Overfit: Their fine-tuning strategies [8], [9], such as Texural Inversion [1] and ProSpect [2], tend to fit the whole target image rather than the ID-related face region, which entangle face layout and background information into the ID…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on attention overfit issues in fine-tuning strategies.",
      "processing_time": 56.97946524620056,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258887639
    },
    {
      "context_text": "(2) Token Optimization : Textual Inversion [1], ProSpect [2], and Celeb Basis [3] optimize the text embedding of special tokens to map the specific ID into the T2I model, where the T2I model is fixed in the optimization process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on optimizing text embeddings for personalization in T2I models.",
      "processing_time": 57.35783314704895,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258887639
    },
    {
      "context_text": "Textual Inversion [1] and Prospect [2] tend to overfit the input image, so they fail to interact with other concepts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods (Textual Inversion and ProSpect). The context focuses on the overfitting issue of these methods.",
      "processing_time": 58.32868504524231,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258887639
    },
    {
      "context_text": "Attention Overfit : As shown in the activation maps of Textural Inversion [1] and ProSpect [2], their “V*” attention nearly takes over the whole images, which means the learned embeddings try to encode both the human faces and ID-unrelated information in the reference images, such as the face…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the behavior of attention mechanisms in certain models.",
      "processing_time": 56.963154792785645,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258887639
    },
    {
      "context_text": "Prospect [2] represents an image as a collection of textual token embeddings which could offer better disentanglement and controllability in editing images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model called ProSpect. No verifiable datasets are referenced.",
      "processing_time": 56.723514556884766,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258887639
    },
    {
      "context_text": "…(2) Token Optimization : Textual Inversion [1] (learns a pseudo-word for a concept within a limited number of images for optimization), ProSpect [2] (expands the textual conditioning space with several per-stage textual token embeddings), and Celeb Basis [3] (builds a well-defined face basis…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'ProSpect' but does not refer to it as a dataset. It is described as a method for expanding the textual conditioning space in diffusion models.",
      "processing_time": 58.32540559768677,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258887639
    },
    {
      "context_text": "Previous work has shown that the CLIP text embedding space is expressive enough to capture image semantics [1], [2].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that CLIP text embedding space captures image semantics. No verifiable resources are identified.",
      "processing_time": 57.15962290763855,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258887639
    },
    {
      "context_text": "This improvement is from two reasons: (1) Attention Overfit Alleviation: our face-wise attention loss is able to alleviate the attention overfit problem of previous methods such as DreamBooth [9], Prospect [2], and Texutal Inversion [1].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the improvement of attention overfit alleviation compared to previous methods.",
      "processing_time": 57.89728236198425,
      "citing_paper_id": "267365273",
      "cited_paper_id": 258887639
    },
    {
      "context_text": "For this, Celeb Basis [3] adopts a pre-trained face recognition model and a face ID basis to obtain an ID representation for one single face image, and Face0 [55] learned to project the embeddings of recognition models to the context space of Stable Diffusion.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers do not provide additional information about datasets.",
      "processing_time": 56.70236110687256,
      "citing_paper_id": "267365273",
      "cited_paper_id": 259138505
    },
    {
      "context_text": "While PhotoMaker [59] proposed an ID-oriented dataset that includes diverse scenarios and fine-tuning part of the Transformer [60] layers in the image encoder to mitigate contextual information loss.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions an 'ID-oriented dataset' but does not provide a specific name or identifier. The context suggests the dataset is used for customizing realistic human photos, but the name is too generic.",
      "processing_time": 59.708441972732544,
      "citing_paper_id": "267365273",
      "cited_paper_id": 266052536
    },
    {
      "context_text": "Although PhotoMaker [59] and IP-Adapter-FaceID [68] could generate the target ID under different scenes and actions, they can not handle complex actions (e.g., “sit on a chair”) and accurate facial attribute controlling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods. The context focuses on the capabilities and limitations of the models.",
      "processing_time": 57.3475923538208,
      "citing_paper_id": "267365273",
      "cited_paper_id": 266052536
    },
    {
      "context_text": "Using our ID embedding method for Stable Diffusion XL. InstantID [57] tends to generate a face photo of target ID. PhotoMaker [59] and IP-Adapter-FaceID [68] can not achieve fine-grained text guided facial attribute controlling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 57.34615349769592,
      "citing_paper_id": "267365273",
      "cited_paper_id": 266052536
    },
    {
      "context_text": "Using our ID embedding method for Stable Diffusion XL. InstantID [57] tends to generate a face photo of target ID. PhotoMaker [59] and IP-Adapter-FaceID [68] can not achieve fine-grained text guided facial attribute controlling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 57.34615349769592,
      "citing_paper_id": "267365273",
      "cited_paper_id": 266999462
    },
    {
      "context_text": "16, we compare with the SOTA methods InstantID [57], PhotoMaker [59], and IP-Adapter-FaceID [68].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models or methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.89157819747925,
      "citing_paper_id": "267365273",
      "cited_paper_id": 266052536
    },
    {
      "context_text": "16, we compare with the SOTA methods InstantID [57], PhotoMaker [59], and IP-Adapter-FaceID [68].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models or methods. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 57.89157819747925,
      "citing_paper_id": "267365273",
      "cited_paper_id": 266999462
    },
    {
      "context_text": "InstantID [57] handled image generation in various styles by designing a learnable IdentityNet to grasp strong semantics.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (IdentityNet) for image generation. No verifiable resources are referenced.",
      "processing_time": 57.554686307907104,
      "citing_paper_id": "267365273",
      "cited_paper_id": 266999462
    },
    {
      "context_text": "(2) Previous Personalized Methods : Methods like Celeb Basis [3], Textural Inversion [1] and InstantID [57] mainly emphasize how to preserve the characteristics of the person and achieve global control over the generated images through text modifications.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on describing previous methods for personalized image generation.",
      "processing_time": 57.34329295158386,
      "citing_paper_id": "267365273",
      "cited_paper_id": 266999462
    },
    {
      "context_text": "InstantID [57] can only generate the face photo and fails to manipulate other actions or facial attributes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (InstantID) and its limitations. No verifiable resources are referenced.",
      "processing_time": 57.73211479187012,
      "citing_paper_id": "267365273",
      "cited_paper_id": 266999462
    },
    {
      "context_text": "Thanks to the powerful capabilities of diffusion in T2I generation, works [35]–[37] achieve state-of-the-art text based image editing quality over diverse datasets, often surpassing GANs.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that the works achieve state-of-the-art results over diverse datasets. No clear, verifiable dataset names are provided.",
      "processing_time": 58.82435965538025,
      "citing_paper_id": "267365273",
      "cited_paper_id": 268248909
    },
    {
      "context_text": "Further studies enrich user modeling by inferring linguistic attributes such as emotion, sentiment, and topics from diverse sources [14, 16].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts of user modeling and linguistic attributes. The cited papers' titles suggest a focus on affective text and sentiment analysis, but do not specify datasets.",
      "processing_time": 60.14421892166138,
      "citing_paper_id": "273500577",
      "cited_paper_id": 27282405
    },
    {
      "context_text": "Further studies enrich user modeling by inferring linguistic attributes such as emotion, sentiment, and topics from diverse sources [14, 16].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts of user modeling and linguistic attributes. The cited papers' titles suggest a focus on affective text and sentiment analysis, but do not specify datasets.",
      "processing_time": 60.14421892166138,
      "citing_paper_id": "273500577",
      "cited_paper_id": 198317027
    },
    {
      "context_text": "We will evaluate our framework on two widely adopted recommendation benchmarks will be used (Table 1), Movielens-1M [3] for movie recommendation, and Recipe [9]",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Movielens-1M",
        "Recipe"
      ],
      "dataset_descriptions": {
        "Movielens-1M": "Used to evaluate the recommendation framework for movie recommendations, focusing on user preferences and rating predictions.",
        "Recipe": "Used to evaluate the recommendation framework for recipe recommendations, focusing on generating personalized recipes based on user history."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, Movielens-1M and Recipe, which are used for evaluating the recommendation framework. Both datasets are relevant to personalized text generation.",
      "processing_time": 69.46219491958618,
      "citing_paper_id": "273500577",
      "cited_paper_id": 202120896
    },
    {
      "context_text": "Large Language Models (LLMs) possess a unique capability to understand and generate complex text, making them ideal for capturing nuanced user preferences and enhancing item descriptions in recommendation systems [6, 20].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the capabilities of Large Language Models (LLMs).",
      "processing_time": 56.70513033866882,
      "citing_paper_id": "273500577",
      "cited_paper_id": 265149820
    },
    {
      "context_text": "Text representations offer significant advantages for depicting user preferences [17, 20].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to text representations for depicting user preferences.",
      "processing_time": 56.70368242263794,
      "citing_paper_id": "273500577",
      "cited_paper_id": 270563652
    },
    {
      "context_text": "This versatility arises from the natural language’s ability to richly and effectively describe almost any type of item and user interest [7, 17, 20].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general capability of natural language. No verifiable resources are identified.",
      "processing_time": 57.320040225982666,
      "citing_paper_id": "273500577",
      "cited_paper_id": 270563652
    },
    {
      "context_text": "[17] introduce a hybrid framework that combines Large Language Models with traditional recommendation systems, using “interest clusters” to manage interactions and refine user interest exploration.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach combining Large Language Models with recommendation systems.",
      "processing_time": 57.14918828010559,
      "citing_paper_id": "273500577",
      "cited_paper_id": 270563652
    },
    {
      "context_text": "This depth aids in uncovering interests in niche or long-tail content that traditional data like purchase histories or viewing patterns might not capture, ensuring that users with unique interests receive relevant recommendations [17].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general data types like purchase histories or viewing patterns. No verifiable resource names are provided.",
      "processing_time": 58.07825541496277,
      "citing_paper_id": "273500577",
      "cited_paper_id": 270563652
    },
    {
      "context_text": "…RAG facilitates the enrichment of user profiles by synthesizing information from a broader corpus, including user activities and their relationships with other entities in complex networks [8, 21], thereby deepening the understanding of user needs and enhancing the personalization of content.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It discusses the use of RAG for enriching user profiles but does not specify any dataset.",
      "processing_time": 58.81466865539551,
      "citing_paper_id": "273500577",
      "cited_paper_id": 271746016
    },
    {
      "context_text": "Previously, many state-of-the-art techniques for character generation have been proposed in the Few-shot Font Generation (FFG) task. pix2pix [9], an image-to-image translation generative adversarial network (GAN) [6], is widely used in this area.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Few-shot Font Generation (FFG)' as a task but does not specify a dataset. It refers to methods (pix2pix, GAN) rather than datasets.",
      "processing_time": 59.8396635055542,
      "citing_paper_id": "273186033",
      "cited_paper_id": 6200260
    },
    {
      "context_text": "Previously, many state-of-the-art techniques for character generation have been proposed in the Few-shot Font Generation (FFG) task. pix2pix [9], an image-to-image translation generative adversarial network (GAN) [6], is widely used in this area.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Few-shot Font Generation (FFG)' as a task but does not specify a dataset. It refers to methods (pix2pix, GAN) rather than datasets.",
      "processing_time": 59.8396635055542,
      "citing_paper_id": "273186033",
      "cited_paper_id": 10319744
    },
    {
      "context_text": "Similar end-to-end font generation methods [1, 14, 15, 29, 31] have been proposed with different improvements and have proven that image-to-image translation is effective in generating any kind of Chinese font or other logographic languages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models for font generation. There are no clear identifiers for datasets in the text.",
      "processing_time": 58.648841381073,
      "citing_paper_id": "273186033",
      "cited_paper_id": 218763388
    },
    {
      "context_text": "Similar end-to-end font generation methods [1, 14, 15, 29, 31] have been proposed with different improvements and have proven that image-to-image translation is effective in generating any kind of Chinese font or other logographic languages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models for font generation. There are no clear identifiers for datasets in the text.",
      "processing_time": 58.648841381073,
      "citing_paper_id": "273186033",
      "cited_paper_id": 233168962
    },
    {
      "context_text": "Similar end-to-end font generation methods [1, 14, 15, 29, 31] have been proposed with different improvements and have proven that image-to-image translation is effective in generating any kind of Chinese font or other logographic languages.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models for font generation. There are no clear identifiers for datasets in the text.",
      "processing_time": 58.648841381073,
      "citing_paper_id": "273186033",
      "cited_paper_id": 257757256
    },
    {
      "context_text": "Based on these models, several works [13, 18, 22, 23, 26, 27] achieve state-of-the-art generation quality over highly diverse datasets.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that the works achieve state-of-the-art generation quality over 'highly diverse datasets'. This is too generic to identify specific datasets.",
      "processing_time": 59.693647623062134,
      "citing_paper_id": "273186033",
      "cited_paper_id": 219708245
    },
    {
      "context_text": "Based on these models, several works [13, 18, 22, 23, 26, 27] achieve state-of-the-art generation quality over highly diverse datasets.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that the works achieve state-of-the-art generation quality over 'highly diverse datasets'. This is too generic to identify specific datasets.",
      "processing_time": 59.693647623062134,
      "citing_paper_id": "273186033",
      "cited_paper_id": 231979499
    },
    {
      "context_text": "In addition, with the development of Denoising Diffusion Probabilistic Models (DDPMs) [7], DDPMs have become a new and probably a more efficient solution for FFG.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DDPMs).",
      "processing_time": 56.694756507873535,
      "citing_paper_id": "273186033",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "In our study, we leverage a U-net [20] model as the backbone model and incorporate the methodology of DDPMs [7].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a U-net model and DDPMs but does not refer to any specific datasets. The focus is on the methodology and model architecture.",
      "processing_time": 27.491758823394775,
      "citing_paper_id": "273186033",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "Denoising Diffusion Probabilistic Models (DDPMs) [7] generate samples that match the data after a certain amount of time.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DDPMs). There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 59.08411979675293,
      "citing_paper_id": "273186033",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "Denoising Diffusion Implicit Models (DDIMs) [25] are iterative implicit probabilistic models that are more efficient and have the same training procedure as DDPMs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 58.814505100250244,
      "citing_paper_id": "273186033",
      "cited_paper_id": 222140788
    },
    {
      "context_text": "While DG-Font [31] and CF-Font [29] utilized completely different methods, feature deformation skip connection modules, to transform the low-level feature of content images and preserve the pattern of character including strokes and radicals.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles confirm that they are about font generation methods, not datasets.",
      "processing_time": 59.51026439666748,
      "citing_paper_id": "273186033",
      "cited_paper_id": 233168962
    },
    {
      "context_text": "While DG-Font [31] and CF-Font [29] utilized completely different methods, feature deformation skip connection modules, to transform the low-level feature of content images and preserve the pattern of character including strokes and radicals.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles confirm that they are about font generation methods, not datasets.",
      "processing_time": 59.51026439666748,
      "citing_paper_id": "273186033",
      "cited_paper_id": 257757256
    },
    {
      "context_text": "In Figure 7, we compare our generations with some state-of-the-art few-shot font generation tools, CF-Font [29], DG-Font [31], Fontdiffuser [32], and LF-Font [14].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several tools/models (CF-Font, DG-Font, Fontdiffuser, LF-Font) but does not refer to any specific datasets. The citation intent is to compare the performance of these tools.",
      "processing_time": 61.27465534210205,
      "citing_paper_id": "273186033",
      "cited_paper_id": 233168962
    },
    {
      "context_text": "In Figure 7, we compare our generations with some state-of-the-art few-shot font generation tools, CF-Font [29], DG-Font [31], Fontdiffuser [32], and LF-Font [14].",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions several tools/models (CF-Font, DG-Font, Fontdiffuser, LF-Font) but does not refer to any specific datasets. The citation intent is to compare the performance of these tools.",
      "processing_time": 61.27465534210205,
      "citing_paper_id": "273186033",
      "cited_paper_id": 257757256
    },
    {
      "context_text": "Similar inversion techniques are also implemented in various image generation models [3, 4, 17].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only image generation models. No dataset names are present in the citation context.",
      "processing_time": 58.810736417770386,
      "citing_paper_id": "273186033",
      "cited_paper_id": 234357997
    },
    {
      "context_text": "We employ a fine-tuning process primarily based on the LORA [8] method to adapt our model to new styles, including some digital fonts.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a method (LORA) but does not refer to any specific dataset. The focus is on the adaptation of a model to new styles using the LORA method.",
      "processing_time": 60.239052534103394,
      "citing_paper_id": "273186033",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "The Low-Rank Adaptation of Large Language Models (LoRA) [8] is a fine-tuning technique that speeds up the training process of large models while reducing memory consumption.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for fine-tuning large language models.",
      "processing_time": 58.2766809463501,
      "citing_paper_id": "273186033",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "Textual Inversion [5] is a process used to derive new concepts from a limited set of example images.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called Textual Inversion. No verifiable resources are identified.",
      "processing_time": 59.513110876083374,
      "citing_paper_id": "273186033",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "We choose Calliffusion [12] as the baseline model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'Calliffusion' as a baseline model, which is a method, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 60.70941972732544,
      "citing_paper_id": "273186033",
      "cited_paper_id": 258967805
    },
    {
      "context_text": "While for pure Chinese calligraphy, Calliffusion [12] and CalliPaint [11] showed that, with a small amount of training data and a very simple DDPM structure, Chinese calligraphy can be generated and is hard to distinguish whether it is generated by machine or not by human beings.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Calliffusion' and 'CalliPaint' but does not refer to them as datasets. They are described as methods or models for generating Chinese calligraphy. No specific datasets are mentioned.",
      "processing_time": 62.59875988960266,
      "citing_paper_id": "273186033",
      "cited_paper_id": 258967805
    },
    {
      "context_text": "While for pure Chinese calligraphy, Calliffusion [12] and CalliPaint [11] showed that, with a small amount of training data and a very simple DDPM structure, Chinese calligraphy can be generated and is hard to distinguish whether it is generated by machine or not by human beings.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Calliffusion' and 'CalliPaint' but does not refer to them as datasets. They are described as methods or models for generating Chinese calligraphy. No specific datasets are mentioned.",
      "processing_time": 62.59875988960266,
      "citing_paper_id": "273186033",
      "cited_paper_id": 265609355
    },
    {
      "context_text": "LoRA is a more common technique and it has not only been used in the computer vision field [16, 21, 24] but also in Natural Language Processing [2, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only techniques and fields of application. No verifiable resources are identified.",
      "processing_time": 60.50204372406006,
      "citing_paper_id": "273186033",
      "cited_paper_id": 259847576
    },
    {
      "context_text": "LoRA is a more common technique and it has not only been used in the computer vision field [16, 21, 24] but also in Natural Language Processing [2, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only techniques and fields of application. No verifiable resources are identified.",
      "processing_time": 60.50204372406006,
      "citing_paper_id": "273186033",
      "cited_paper_id": 262084134
    },
    {
      "context_text": "LoRA is a more common technique and it has not only been used in the computer vision field [16, 21, 24] but also in Natural Language Processing [2, 10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only techniques and fields of application. No verifiable resources are identified.",
      "processing_time": 60.50204372406006,
      "citing_paper_id": "273186033",
      "cited_paper_id": 264128197
    },
    {
      "context_text": "These challenges emphasize the necessity of addressing the limitations of generic LLMs to ensure reliable, personalized, and responsible explainable recommender systems [5].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the limitations of generic LLMs. There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 61.617361068725586,
      "citing_paper_id": "266521273",
      "cited_paper_id": 231802467
    },
    {
      "context_text": "These models possess unique characteristics, including reasoning ability and natural language text generation, making them attractive candidates for providing explanations in recommender systems [6].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general characteristics of models. There are no verifiable resources or specific datasets mentioned.",
      "processing_time": 61.27122211456299,
      "citing_paper_id": "266521273",
      "cited_paper_id": null
    },
    {
      "context_text": "As for embedding-based methods, traditional approaches (Li et al., 2016b; Al-Rfou et al., 2016) attempt to exploit user ID information, while DHAP (Ma et al., 2021) embed user dialogue history as implicit profiles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on embedding-based methods and their use of user ID information and dialogue history.",
      "processing_time": 52.554354190826416,
      "citing_paper_id": "264590708",
      "cited_paper_id": 1473130
    },
    {
      "context_text": "(1) Word-Overlap Level : BLEU(Papineni et al., 2002) and Rouge (Lin and Och, 2004) are classical metrics that compare the similarity between the generated responses and golden responses, where we use ChatGPT-generated responses as the ground truth.",
      "catation_intent": "none",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions metrics (BLEU and ROUGE) but does not refer to any specific datasets. The context is about evaluating machine translation quality, which is not directly related to personalized text generation.",
      "processing_time": 53.426904916763306,
      "citing_paper_id": "264590708",
      "cited_paper_id": 1586456
    },
    {
      "context_text": "Other datasets, such as the Stanford Politeness Corpus (SPC) (Niu and Bansal, 2018), the TCFC dataset (Wu et al., 2020) for formal language style, and the synthetic polite conversational data by Mukherjee et al.(Mukherjee et al., 2023), do exist but have limitations such as noise, low-resource…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Stanford Politeness Corpus (SPC)",
        "TCFC dataset",
        "synthetic polite conversational data"
      ],
      "dataset_descriptions": {
        "Stanford Politeness Corpus (SPC)": "Used to study politeness in dialogue, focusing on linguistic markers of politeness in various contexts.",
        "TCFC dataset": "Used to analyze formal language style, specifically examining stylistic variations in written communication.",
        "synthetic polite conversational data": "Used to generate and evaluate polite conversational responses, focusing on the impact of synthetic data on model performance."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions three datasets: SPC, TCFC, and synthetic polite conversational data. These are specific datasets used for studying politeness and formal language styles, which are relevant to personalized text generation.",
      "processing_time": 74.59242653846741,
      "citing_paper_id": "264590708",
      "cited_paper_id": 13690180
    },
    {
      "context_text": "Other datasets, such as the Stanford Politeness Corpus (SPC) (Niu and Bansal, 2018), the TCFC dataset (Wu et al., 2020) for formal language style, and the synthetic polite conversational data by Mukherjee et al.(Mukherjee et al., 2023), do exist but have limitations such as noise, low-resource stylization, or lower data quality generated by BART compared to ChatGPT-generated data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Stanford Politeness Corpus (SPC)",
        "TCFC dataset",
        "synthetic polite conversational data"
      ],
      "dataset_descriptions": {
        "Stanford Politeness Corpus (SPC)": "Used to study politeness in dialogue, focusing on linguistic markers and their impact on perceived politeness in text-based communication.",
        "TCFC dataset": "Used to analyze formal language style, specifically examining stylistic elements in text to improve formality in generated responses.",
        "synthetic polite conversational data": "Used to generate polite conversational data, focusing on improving the quality and naturalness of machine-generated polite dialogues."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions three datasets: SPC, TCFC, and synthetic polite conversational data. These are specific datasets used in the field of text generation, particularly for politeness and formal language styles.",
      "processing_time": 76.38807606697083,
      "citing_paper_id": "264590708",
      "cited_paper_id": 13690180
    },
    {
      "context_text": "Other datasets, such as the Stanford Politeness Corpus (SPC) (Niu and Bansal, 2018), the TCFC dataset (Wu et al., 2020) for formal language style, and the synthetic polite conversational data by Mukherjee et al.(Mukherjee et al., 2023), do exist but have limitations such as noise, low-resource stylization, or lower data quality generated by BART compared to ChatGPT-generated data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Stanford Politeness Corpus (SPC)",
        "TCFC dataset",
        "synthetic polite conversational data"
      ],
      "dataset_descriptions": {
        "Stanford Politeness Corpus (SPC)": "Used to study politeness in dialogue, focusing on linguistic markers and their impact on perceived politeness in text-based communication.",
        "TCFC dataset": "Used to analyze formal language style, specifically examining stylistic elements in text to improve formality in generated responses.",
        "synthetic polite conversational data": "Used to generate polite conversational data, focusing on improving the quality and naturalness of machine-generated polite dialogues."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions three datasets: SPC, TCFC, and synthetic polite conversational data. These are specific datasets used in the field of text generation, particularly for politeness and formal language styles.",
      "processing_time": 76.38807606697083,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258378197
    },
    {
      "context_text": "However they primarily focus on concrete identifiable facts and background information, e.g., age, job, location , neglecting the multifaceted dimensions of personality (Moore et al., 2017; Ahn et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general aspects of personality and background information. No verifiable resources are identified.",
      "processing_time": 51.996936559677124,
      "citing_paper_id": "264590708",
      "cited_paper_id": 113562250
    },
    {
      "context_text": "Moreover, the GPT2 model (Radford et al., 2019) is leveraged as the decoder p ϕ ( r | C, z ) , where θ, θ ′ and ϕ represent the trainable parameters of the posterior encoder, prior encoder, and decoder respectively.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the GPT2 model which is a method, not a dataset.",
      "processing_time": 51.813217639923096,
      "citing_paper_id": "264590708",
      "cited_paper_id": 160025533
    },
    {
      "context_text": "The encoder in our model is implemented using the BERT model 8 , while the decoder is based on DialoGPT-medium 9 (Zhang et al., 2020) We train our model on the training data for 20 epochs using a learning rate of 5e-5 and the AdamW optimizer and utilize greedy strategy in the generation.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions training data but does not specify a named dataset. The cited papers refer to models, not datasets.",
      "processing_time": 51.51856327056885,
      "citing_paper_id": "264590708",
      "cited_paper_id": 207869708
    },
    {
      "context_text": "In the category of text-description-based meth-ods, early works (Wolf et al., 2019; Song et al., 2020, 2021a) primarily focus on promoting persona consistency through pre-trained language models, while recent advancements borrow knowledge-enhance techniques (Liu et al., 2022b; Fu et al., 2022; Jang…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and models. No verifiable resources are identified.",
      "processing_time": 51.815208435058594,
      "citing_paper_id": "264590708",
      "cited_paper_id": 208006638
    },
    {
      "context_text": "Other methods for personalized dialogue generation often rely on user embeddings derived from social media platforms like Reddit (Qian et al., 2021; Ma et al., 2021; Huang et al., 2022; Zhong et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and platforms. The cited paper titles do not introduce any new datasets either.",
      "processing_time": 52.288389682769775,
      "citing_paper_id": "264590708",
      "cited_paper_id": 221969995
    },
    {
      "context_text": "Other methods for personalized dialogue generation often rely on user embeddings derived from social media platforms like Reddit (Qian et al., 2021; Ma et al., 2021; Huang et al., 2022; Zhong et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and platforms. The cited paper titles do not introduce any new datasets either.",
      "processing_time": 52.288389682769775,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247693734
    },
    {
      "context_text": "Other methods for personalized dialogue generation often rely on user embeddings derived from social media platforms like Reddit (Qian et al., 2021; Ma et al., 2021; Huang et al., 2022; Zhong et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and platforms. The cited paper titles do not introduce any new datasets either.",
      "processing_time": 52.288389682769775,
      "citing_paper_id": "264590708",
      "cited_paper_id": 252918698
    },
    {
      "context_text": "Challenges like limited resources or evolving technology may arise, yet your role as a librarian illuminate the path, bringing forth the treasures of knowledge to those who seek it Figure 1: Top: previous methods model personas by user embedding derived from user posts ( e.g., in Reddit ) or a series of text descriptions.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to user posts in Reddit and text descriptions. The cited paper title suggests a dataset, but it is not mentioned in the citation context.",
      "processing_time": 54.06997275352478,
      "citing_paper_id": "264590708",
      "cited_paper_id": 221969995
    },
    {
      "context_text": "Recently, energy-based models (EBMs) have emerged as a flexible generative framework capable of handling diverse configurations (Khalifa et al., 2021; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 52.3376898765564,
      "citing_paper_id": "264590708",
      "cited_paper_id": 229348988
    },
    {
      "context_text": "As a result, many recent works leverage EBMs to model complex distributions (Pang and Wu, 2021; Yu et al., 2022) and incorporate multiple constraints and attributes (Nie et al., 2021; Pang and Wu, 2021; Qin et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.48828601837158,
      "citing_paper_id": "264590708",
      "cited_paper_id": 235826029
    },
    {
      "context_text": "As a result, many recent works leverage EBMs to model complex distributions (Pang and Wu, 2021; Yu et al., 2022) and incorporate multiple constraints and attributes (Nie et al., 2021; Pang and Wu, 2021; Qin et al., 2022; Liu et al., 2022a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 52.48828601837158,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247058662
    },
    {
      "context_text": "For example, Mix-and-Match (Mireshghal-lah et al., 2022) employs EBMs to combine arbitrary black-box scorers for guiding text generation, while COLD (Qin et al., 2022) utilizes the energy function to impose arbitrary constraints during the decoding process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on describing the methodologies used in the cited papers.",
      "processing_time": 52.13686466217041,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247058662
    },
    {
      "context_text": "(3) Fluency : To assess the fluency of the generated responses, the negative log-likelihood of the generated responses according to the GPT2-XL 6 is used as the fluency score (Chen et al., 2023; Qin et al., 2022).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of GPT2-XL for scoring fluency. No verifiable resources are identified.",
      "processing_time": 52.430010080337524,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247058662
    },
    {
      "context_text": "(3) Fluency : To assess the fluency of the generated responses, the negative log-likelihood of the generated responses according to the GPT2-XL 6 is used as the fluency score (Chen et al., 2023; Qin et al., 2022).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of GPT2-XL for scoring fluency. No verifiable resources are identified.",
      "processing_time": 52.430010080337524,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "Recent personalized dialogue methods often rely on text descriptions (Song et al., 2019; Wolf et al., 2019; Xu et al., 2022; Chen et al., 2023) to model user profiles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for modeling user profiles in personalized dialogue systems.",
      "processing_time": 51.553935050964355,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247411350
    },
    {
      "context_text": "Recent personalized dialogue methods often rely on text descriptions (Song et al., 2019; Wolf et al., 2019; Xu et al., 2022; Chen et al., 2023) to model user profiles.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for modeling user profiles in personalized dialogue systems.",
      "processing_time": 51.553935050964355,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "Therefore, personalization in dialogue systems has the potential to enhance user trust and enrich interaction experiences with Artificial Intelligence (AI) agents (Choung et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept of personalization in dialogue systems. No verifiable resources are identified.",
      "processing_time": 52.273762226104736,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247628267
    },
    {
      "context_text": "More recently, contrastive learning (Huang et al., 2022), refined retrieval (Zhong et al., 2022) and CVAE-based clustering (Tang et al., 2023) are explored to enhance the personalization performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 52.27786827087402,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247693734
    },
    {
      "context_text": "More recently, contrastive learning (Huang et al., 2022), refined retrieval (Zhong et al., 2022) and CVAE-based clustering (Tang et al., 2023) are explored to enhance the personalization performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 52.27786827087402,
      "citing_paper_id": "264590708",
      "cited_paper_id": 252918698
    },
    {
      "context_text": "More recently, contrastive learning (Huang et al., 2022), refined retrieval (Zhong et al., 2022) and CVAE-based clustering (Tang et al., 2023) are explored to enhance the personalization performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 52.27786827087402,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "MSP: life is like a bright sand, constantly changing and dark.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It appears to be a metaphorical statement about life, which is not relevant to extracting datasets.",
      "processing_time": 53.02222037315369,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247693734
    },
    {
      "context_text": "MSP (Zhong et al., 2022): MSP is a user embedding-based method that enhances personalized dialogue generation by retrieving similar conversations from other users.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions MSP as a method, not a dataset. No specific dataset is referenced in the citation context.",
      "processing_time": 51.539788484573364,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247693734
    },
    {
      "context_text": "Analyzing the tables, we observe that BOB and MSP tend to overlook the content of the dialogue, leading to repetitive and incoherent responses.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses issues with methods (BOB and MSP).",
      "processing_time": 50.56624698638916,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247693734
    },
    {
      "context_text": "(Additional case studies can be found in Appendix E) In this specific case, we observe that BOB and MSP tend to overlook the contextual information from the dialogue history, such as references to \"weather\" and \"ocean,\" resulting in repetitive and incoherent responses.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses issues with models (BOB and MSP) in handling dialogue history.",
      "processing_time": 51.92210268974304,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247693734
    },
    {
      "context_text": "(2) User-embedding-based methods : Our second set of baselines includes MSP (Zhong et al., 2022), and CLV (Tang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods (MSP and CLV). The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 52.816850662231445,
      "citing_paper_id": "264590708",
      "cited_paper_id": 247693734
    },
    {
      "context_text": "(2) User-embedding-based methods : Our second set of baselines includes MSP (Zhong et al., 2022), and CLV (Tang et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods (MSP and CLV). The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 52.816850662231445,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "Studies in behavioral psychology reveal that humans have a natural tendency to attribute human-like traits to non-human entities (Qu et al., 2023; Gu et al., 2022, 2021) during interaction (Epley et al., 2007; Airenti, 2018).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies in behavioral psychology. There are no clear identifiers for datasets, models, or other resources.",
      "processing_time": 52.80732464790344,
      "citing_paper_id": "264590708",
      "cited_paper_id": 254591615
    },
    {
      "context_text": "…and Bansal, 2018), the TCFC dataset (Wu et al., 2020) for formal language style, and the synthetic polite conversational data by Mukherjee et al.(Mukherjee et al., 2023), do exist but have limitations such as noise, low-resource stylization, or lower data quality generated by BART compared to…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TCFC",
        "synthetic polite conversational data by Mukherjee et al."
      ],
      "dataset_descriptions": {
        "TCFC": "Used to train models for formal language style transfer, addressing limitations such as noise and low-resource stylization.",
        "synthetic polite conversational data by Mukherjee et al.": "Used to generate polite conversational data, highlighting issues with data quality when compared to other methods."
      },
      "confidence_score": 0.85,
      "reasoning": "The context mentions three specific datasets: 'TCFC', 'synthetic polite conversational data by Mukherjee et al.', and 'BART'. However, 'BART' is excluded as it is a model, not a dataset. 'TCFC' and 'synthetic polite conversational data by Mukherjee et al.' are included as they are specific datasets used for style transfer and polite conversation generation.",
      "processing_time": 76.58588600158691,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258378197
    },
    {
      "context_text": "Human Evaluation Metrics Consistent with prior studies (Tang et al., 2023; Chen et al., 2023), we conduct human evaluations on 100 randomly selected test samples.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to '100 randomly selected test samples' which is too generic.",
      "processing_time": 52.44132471084595,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "Human Evaluation Metrics Consistent with prior studies (Tang et al., 2023; Chen et al., 2023), we conduct human evaluations on 100 randomly selected test samples.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to '100 randomly selected test samples' which is too generic.",
      "processing_time": 52.44132471084595,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "To ensure a fair comparison, we randomly select personas from the Per-sonaChat dataset (Zhang et al., 2018) as conversation topics when generating our data, and feed the topics as personas input to BOB, CLV and LMEDR during training.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PersonaChat"
      ],
      "dataset_descriptions": {
        "PersonaChat": "Used to generate conversation topics and train models (BOB, CLV, LMEDR) by providing personas as input, ensuring a fair comparison in personalized dialogue generation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the PersonaChat dataset for generating conversation topics and training models. The dataset is clearly identified and used in a specific research context.",
      "processing_time": 60.924347162246704,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "To ensure a fair comparison, we randomly select personas from the Per-sonaChat dataset (Zhang et al., 2018) as conversation topics when generating our data, and feed the topics as personas input to BOB, CLV and LMEDR during training.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PersonaChat"
      ],
      "dataset_descriptions": {
        "PersonaChat": "Used to generate conversation topics and train models (BOB, CLV, LMEDR) by providing personas as input, ensuring a fair comparison in personalized dialogue generation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the use of the PersonaChat dataset for generating conversation topics and training models. The dataset is clearly identified and used in a specific research context.",
      "processing_time": 60.924347162246704,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "CLV and LMEDR may struggle with capturing multiple attributes of personality comprehensively, although LMEDR performs better in terms of coherence and fluency.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods (CLV and LMEDR). No verifiable resources are identified.",
      "processing_time": 52.434791564941406,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "CLV and LMEDR may struggle with capturing multiple attributes of personality comprehensively, although LMEDR performs better in terms of coherence and fluency.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods (CLV and LMEDR). No verifiable resources are identified.",
      "processing_time": 52.434791564941406,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "CLV: life in alabama is like magic , where the land down under is a beautiful sight to see. it’s a blend of the best , the best of the best.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific, verifiable datasets or resources. It appears to be a poetic or lyrical statement rather than a reference to a dataset.",
      "processing_time": 52.98334741592407,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "CLV (Tang et al., 2023): CLV utilizes a CVAE architecture to cluster dense persona descriptions into sparse categories.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CVAE) and a concept (persona descriptions).",
      "processing_time": 51.79813742637634,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "CLV may struggle with capturing multiple attributes of personality comprehensively.",
      "catation_intent": "research work",
      "resource_type": "limitation",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a potential limitation of CLV in capturing multiple personality attributes.",
      "processing_time": 51.795275926589966,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "(4) Diversity : We measure the diversity of the generated responses using the Distinct metrics and the self BLEU score (sBLEU) as proposed in (Tang et al., 2023; Liu et al., 2022a).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only metrics (Distinct metrics and sBLEU) which are excluded according to the instructions.",
      "processing_time": 52.204527378082275,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "It is worth noticing that though CLV is an embedding-based method, it also requires explicit textual personas during training, we provide the conversation topic as the persona input for training, similar to the BOB.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses a method (CLV) and mentions 'explicit textual personas' but does not provide a named dataset.",
      "processing_time": 53.91832518577576,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "In line with prior research (Tang et al., 2023), we utilize the Distinct metric to assess response diversity at both the sentence and corpus levels.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Distinct metric but does not refer to any specific dataset. The metric is used to assess response diversity, which is not a dataset but a method for evaluation.",
      "processing_time": 54.125420331954956,
      "citing_paper_id": "264590708",
      "cited_paper_id": 258823272
    },
    {
      "context_text": "It aims to endow chatbot agents with human-like traits, enabling more realistic interactions (Li et al., 2016b; Zhang et al., 2018; Wolf et al., 2019; Song et al., 2021a; Li et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing human-like traits in chatbots.",
      "processing_time": 51.928009271621704,
      "citing_paper_id": "264590708",
      "cited_paper_id": 259370601
    },
    {
      "context_text": "We calculate the Fleiss Kappa value of 0.63, indicating substantial agreement among the annotators (Gwet, 2014).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a statistical measure of inter-annotator agreement.",
      "processing_time": 51.47801089286804,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "Leveraging the capabilities of ChatGPT in generating single-attribute data (Coda-Forno et al., 2023) and multi-turn conversations (Xu et al., 2023), we designed instruction templates to prompt ChatGPT to simulate two-person conversations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the capabilities of ChatGPT in generating data and simulating conversations.",
      "processing_time": 51.935949087142944,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "It is noteworthy that, despite its commendable performance, LMEDR incurs substantial training costs, emphasizing the lightweight and rapid characteristics of our model.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It focuses on the performance and training costs of LMEDR, which is not a dataset.",
      "processing_time": 53.86210489273071,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "LMEDR: Alabama is a land of the free , where the sun shines bright and the sky is blue.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific, verifiable datasets or resources. It appears to be a statement or a phrase rather than a reference to a dataset.",
      "processing_time": 53.33304762840271,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "LMEDR (Chen et al., 2023): LMEDR employs the BART-large model (Lewis et al., 2020) and incorporates memorize entailment and discourse relations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions LMEDR, which is a method or model, and does not refer to a specific dataset. No dataset names are mentioned in the context.",
      "processing_time": 53.64632320404053,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "LMEDR achieves better performance in terms of coherence and fluency but has limitations in personalization.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (LMEDR) and its performance characteristics. There are no verifiable resources or datasets mentioned.",
      "processing_time": 53.853376626968384,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "Baselines For comparison, we select the following baselines: (1) Text-description-based meth-ods : We compare with BOB (Song et al., 2021a) and LMEDR (Chen et al., 2023), both are strong text-description-based personalized models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods used as baselines for comparison.",
      "processing_time": 51.50997233390808,
      "citing_paper_id": "264590708",
      "cited_paper_id": null
    },
    {
      "context_text": "…understanding and generation in e-commerce intelligent recommendation based on Transformer pre-training model in the field of large language model, analyzes the current development status of large language model, and discusses the application advantages of [2]BERT, Transformer and other models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited paper title also does not provide any additional information about datasets.",
      "processing_time": 52.77488708496094,
      "citing_paper_id": "267938269",
      "cited_paper_id": 258887872
    },
    {
      "context_text": "When the model parameters break through a certain scale, the performance is significantly improved, and [1]LLM begins to show emergence ability and generalization ability.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about model performance. No verifiable resources are identified.",
      "processing_time": 52.090821743011475,
      "citing_paper_id": "267938269",
      "cited_paper_id": 267198502
    },
    {
      "context_text": "[8]The user has clicked or purchased the product in the history, and then recommends the product that the user is interested in again based on the historical behavior data of the user, in which the user behavior sequence data plays an important role.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'historical behavior data' and 'user behavior sequence data', which are too generic and lack specific identifiers.",
      "processing_time": 54.64100432395935,
      "citing_paper_id": "267938269",
      "cited_paper_id": 267583021
    },
    {
      "context_text": "From Figure 3, we can see that it follows the popular Embedding&MLP paradigm, where the previous click item and associated features are first embedded in a low-dimensional vector and then input into the MLP[9].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The context is about the architecture of a model, not the data used.",
      "processing_time": 53.102622747421265,
      "citing_paper_id": "267938269",
      "cited_paper_id": 267638578
    },
    {
      "context_text": "Several studies have expanded their approach by incorporating supplementary features, such as keywords (Zhang et al., 2018a), entities (Qi et al., 2021), categories (Wu et al., 2019a), topics (Wu et al., 2019c), location (Xun et al., 2021), popularity (Tavakolifard et al., 2013), and others.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only lists various features that have been incorporated into different studies.",
      "processing_time": 52.57045817375183,
      "citing_paper_id": "266229273",
      "cited_paper_id": 656562
    },
    {
      "context_text": "Several studies have expanded their approach by incorporating supplementary features, such as keywords (Zhang et al., 2018a), entities (Qi et al., 2021), categories (Wu et al., 2019a), topics (Wu et al., 2019c), location (Xun et al., 2021), popularity (Tavakolifard et al., 2013), and others.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only lists various features that have been incorporated into different studies.",
      "processing_time": 52.57045817375183,
      "citing_paper_id": "266229273",
      "cited_paper_id": 237940272
    },
    {
      "context_text": "For verbaliz-able control codes such as keywords, topics, or entities, an approach is to make the corresponding tokens as the hard prompts of inputs during inference (Keskar et al., 2019; Fan et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context is about using control codes as hard prompts in inputs during inference.",
      "processing_time": 53.11428236961365,
      "citing_paper_id": "266229273",
      "cited_paper_id": 22716243
    },
    {
      "context_text": "Furthermore, inspired by the evaluation metrics for generative models in the computer vision domain, such as Fr´echet Inception Distance (Heusel et al., 2017) and Fr´echet Video Distance (Unterthiner et al., 2018), we quantify results by measuring the distance between the style features of generated data S g and reference data S r .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only evaluation metrics and generative models. No verifiable resources are identified.",
      "processing_time": 52.06540870666504,
      "citing_paper_id": "266229273",
      "cited_paper_id": 54458806
    },
    {
      "context_text": "…metrics for generative models in the computer vision domain, such as Fr´echet Inception Distance (Heusel et al., 2017) and Fr´echet Video Distance (Unterthiner et al., 2018), we quantify results by measuring the distance between the style features of generated data S g and reference data S r .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only metrics and methods. The reference data and generated data are not named datasets.",
      "processing_time": 52.43177151679993,
      "citing_paper_id": "266229273",
      "cited_paper_id": 54458806
    },
    {
      "context_text": "To train TrRM, we employ negative sampling techniques (Zheng et al., 2018; An et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and techniques.",
      "processing_time": 50.826971769332886,
      "citing_paper_id": "266229273",
      "cited_paper_id": 196186167
    },
    {
      "context_text": "Unlike previous work, which solely learns textual representations from in-domain data (Wu et al., 2019b; An et al., 2019; Wang et al., 2020), recent research has started exploring pre-training techniques for news recommendation (Wu et al., 2021; Li et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general references to in-domain data and pre-training techniques. No verifiable resources are identified.",
      "processing_time": 52.869952917099,
      "citing_paper_id": "266229273",
      "cited_paper_id": 196186167
    },
    {
      "context_text": "…approaches involve disen-tangling text into content and attributes in the latent space for manipulation (Yi et al., 2020; Li et al., 2020), editing based on sentence templates (Madaan et al., 2020; Li et al., 2018), and creating pseudo-parallel data (Jin et al., 2019; Nikolov and Hahnloser, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No verifiable resources are identified.",
      "processing_time": 51.81094479560852,
      "citing_paper_id": "266229273",
      "cited_paper_id": 198899669
    },
    {
      "context_text": "…attributes, such as keywords (He, 2021), specified entities (Dong et al., 2021), document diction (Dathathri et al., 2020), topics (Keskar et al., 2019), sentiments (Chan et al., 2021a), humor (Amin and Burghardt, 2020), authorship (Syed et al., 2020), and social bias (Barikeri et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various attributes and aspects of personalized text generation. No clear, verifiable datasets are identified.",
      "processing_time": 53.14133143424988,
      "citing_paper_id": "266229273",
      "cited_paper_id": 202719307
    },
    {
      "context_text": "Previous work has explored various attributes, such as keywords (He, 2021), specified entities (Dong et al., 2021), document diction (Dathathri et al., 2020), topics (Keskar et al., 2019), sentiments (Chan et al., 2021a), humor (Amin and Burghardt, 2020), authorship (Syed et al., 2020), and social…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various attributes explored in previous work. No clear, verifiable datasets are identified.",
      "processing_time": 52.6623055934906,
      "citing_paper_id": "266229273",
      "cited_paper_id": 208617790
    },
    {
      "context_text": "(Hu and Li, 2021), aiming to edit the existing text to possess desired attributes without considering contextual information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for editing text attributes.",
      "processing_time": 51.0107159614563,
      "citing_paper_id": "266229273",
      "cited_paper_id": 230433941
    },
    {
      "context_text": "Alternatively, some works learn continuous representations of target attributes, known as soft prompts , to enable the control over general attributes (Li and Liang, 2021; Yu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or approaches. The context focuses on the technique of using soft prompts for controlling attributes in text generation.",
      "processing_time": 53.73895716667175,
      "citing_paper_id": "266229273",
      "cited_paper_id": 230433941
    },
    {
      "context_text": "• Paraphrase Generation: We utilize the PAWS 50 (Paraphrase Adversaries from Word Scrambling) and MRPC (Microsoft Research Paraphrase Corpus) 51 datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PAWS",
        "MRPC"
      ],
      "dataset_descriptions": {
        "PAWS": "Used to generate paraphrases by adversarially scrambling words, enhancing the robustness of paraphrase detection models.",
        "MRPC": "Utilized to evaluate paraphrase identification, focusing on sentence pairs annotated for semantic equivalence."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions two specific datasets, PAWS and MRPC, which are used for paraphrase generation. Both are clearly identified and relevant to the topic of personalized text generation.",
      "processing_time": 64.39002346992493,
      "citing_paper_id": "279994613",
      "cited_paper_id": 16639476
    },
    {
      "context_text": "To ensure trustworthy and scalable deployment in real-world settings, future work should also consider model transparency, regulatory compliance, and human-in-the-loop oversight strategies 39,40 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It focuses on future considerations for AI deployment, such as transparency, compliance, and oversight.",
      "processing_time": 54.15849947929382,
      "citing_paper_id": "279994613",
      "cited_paper_id": 169577694
    },
    {
      "context_text": "To ensure trustworthy and scalable deployment in real-world settings, future work should also consider model transparency, regulatory compliance, and human-in-the-loop oversight strategies 39,40 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It focuses on future considerations for AI deployment, such as transparency, compliance, and oversight.",
      "processing_time": 54.15849947929382,
      "citing_paper_id": "279994613",
      "cited_paper_id": 276839200
    },
    {
      "context_text": "At lower readability levels, the ability to convey biomedical information in accessible and age-appropriate language is essential for reducing comprehension disparities among low-literacy populations, including children, older adults, and non-native speakers 21,24,25 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts related to health literacy and population health outcomes.",
      "processing_time": 51.98315119743347,
      "citing_paper_id": "279994613",
      "cited_paper_id": 172136697
    },
    {
      "context_text": "At lower readability levels, the ability to convey biomedical information in accessible and age-appropriate language is essential for reducing comprehension disparities among low-literacy populations, including children, older adults, and non-native speakers 21,24,25 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts related to health literacy and population health outcomes.",
      "processing_time": 51.98315119743347,
      "citing_paper_id": "279994613",
      "cited_paper_id": 257803126
    },
    {
      "context_text": "At lower readability levels, the ability to convey biomedical information in accessible and age-appropriate language is essential for reducing comprehension disparities among low-literacy populations, including children, older adults, and non-native speakers 21,24,25 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general concepts related to health literacy and population health outcomes.",
      "processing_time": 51.98315119743347,
      "citing_paper_id": "279994613",
      "cited_paper_id": 277549219
    },
    {
      "context_text": "Policies such as Open Medical Records and initiatives such as Blue Button 7,8 exemplify ongoing efforts to democratize access to medical information and promote transparency, engagement, and shared decision-making 9 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only policies and initiatives. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 52.8176965713501,
      "citing_paper_id": "279994613",
      "cited_paper_id": 207536026
    },
    {
      "context_text": "Policies such as Open Medical Records and initiatives such as Blue Button 7,8 exemplify ongoing efforts to democratize access to medical information and promote transparency, engagement, and shared decision-making 9 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only policies and initiatives. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 52.8176965713501,
      "citing_paper_id": "279994613",
      "cited_paper_id": 264334422
    },
    {
      "context_text": "Policies such as Open Medical Records and initiatives such as Blue Button 7,8 exemplify ongoing efforts to democratize access to medical information and promote transparency, engagement, and shared decision-making 9 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only policies and initiatives. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 52.8176965713501,
      "citing_paper_id": "279994613",
      "cited_paper_id": null
    },
    {
      "context_text": "Policies such as Open Medical Records and initiatives such as Blue Button 7,8 exemplify ongoing efforts to democratize access to medical information and promote transparency, engagement, and shared decision-making 9 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only policies and initiatives. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 52.8176965713501,
      "citing_paper_id": "279994613",
      "cited_paper_id": null
    },
    {
      "context_text": "This level of semantic elaboration can support communication not only with patients but also with caregivers, educators, and multidisciplinary teams involved in long-term condition management 27,28 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts related to patient education and communication.",
      "processing_time": 51.58944082260132,
      "citing_paper_id": "279994613",
      "cited_paper_id": 229351463
    },
    {
      "context_text": "Instruction Tuning enhances LLMs by training them on NLP tasks formatted as natural language instructions, enabling models to generate structured responses 43 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general approach to instruction tuning. No verifiable resources are named.",
      "processing_time": 52.44620871543884,
      "citing_paper_id": "279994613",
      "cited_paper_id": 237416585
    },
    {
      "context_text": "Recent advances 43–45 highlight the benefits of instruction learning for adaptability across tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of instruction learning. No verifiable resources are identified.",
      "processing_time": 52.43349647521973,
      "citing_paper_id": "279994613",
      "cited_paper_id": 237416585
    },
    {
      "context_text": "Recent advances 43–45 highlight the benefits of instruction learning for adaptability across tasks.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of instruction learning. No verifiable resources are identified.",
      "processing_time": 52.43349647521973,
      "citing_paper_id": "279994613",
      "cited_paper_id": 264744285
    },
    {
      "context_text": "In our study, we adopt a FLAN-style instruction fine-tuning method 43 to train models on task-specific instructions for MedReadCtrl.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a training method. The cited paper title also does not provide additional information about datasets.",
      "processing_time": 52.541101932525635,
      "citing_paper_id": "279994613",
      "cited_paper_id": 237416585
    },
    {
      "context_text": "MTSamples 49 provides a rich collection of medical transcription reports across numerous specialties, allowing models to further generalize and evaluate simplification performance in an unseen, clinically varied setting.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MTSamples"
      ],
      "dataset_descriptions": {
        "MTSamples": "Used to evaluate model performance in simplifying clinical notes across various medical specialties, focusing on generalization and unseen clinical scenarios."
      },
      "confidence_score": 1.0,
      "reasoning": "MTSamples is a specific, named dataset that is used for evaluating the generalization and simplification performance of models in a clinically varied setting.",
      "processing_time": 59.395583152770996,
      "citing_paper_id": "279994613",
      "cited_paper_id": 245425088
    },
    {
      "context_text": "Our results demonstrate that LLAMA3-MedReadCtrl meaningfully advances this goal by enabling large language models to dynamically control text readability while preserving content quality and relevance—a capability critical for patient education, informed consent, and shared decision-making 2,3 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (LLAMA3-MedReadCtrl) and its capabilities. No verifiable resources are identified.",
      "processing_time": 53.85794234275818,
      "citing_paper_id": "279994613",
      "cited_paper_id": 246098480
    },
    {
      "context_text": "Our results demonstrate that LLAMA3-MedReadCtrl meaningfully advances this goal by enabling large language models to dynamically control text readability while preserving content quality and relevance—a capability critical for patient education, informed consent, and shared decision-making 2,3 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (LLAMA3-MedReadCtrl) and its capabilities. No verifiable resources are identified.",
      "processing_time": 53.85794234275818,
      "citing_paper_id": "279994613",
      "cited_paper_id": 269030019
    },
    {
      "context_text": "In healthcare, this transformation has the potential to fundamentally redefine clinical care by tailoring interactions and information delivery to meet the unique needs, preferences, and comprehension levels of individual patients 2–4 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses the potential impact of AI in healthcare.",
      "processing_time": 52.82120728492737,
      "citing_paper_id": "279994613",
      "cited_paper_id": 246098480
    },
    {
      "context_text": "In healthcare, this transformation has the potential to fundamentally redefine clinical care by tailoring interactions and information delivery to meet the unique needs, preferences, and comprehension levels of individual patients 2–4 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses the potential impact of AI in healthcare.",
      "processing_time": 52.82120728492737,
      "citing_paper_id": "279994613",
      "cited_paper_id": null
    },
    {
      "context_text": "In healthcare, this transformation has the potential to fundamentally redefine clinical care by tailoring interactions and information delivery to meet the unique needs, preferences, and comprehension levels of individual patients 2–4 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses the potential impact of AI in healthcare.",
      "processing_time": 52.82120728492737,
      "citing_paper_id": "279994613",
      "cited_paper_id": null
    },
    {
      "context_text": "However, the benefits of these policies are often limited by the patient’s ability to comprehend complex medical records and health-related information 10 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue regarding patient comprehension of medical records.",
      "processing_time": 50.977787733078,
      "citing_paper_id": "279994613",
      "cited_paper_id": 252282839
    },
    {
      "context_text": "The README dataset 15 contains extensive pairs of medical jargon 48 and their corresponding lay definitions, making it ideal for training models to convert complex medical jargon into patient-friendly language in seen settings.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "README"
      ],
      "dataset_descriptions": {
        "README": "Used to train models to convert complex medical jargon into patient-friendly language, focusing on seen settings and leveraging extensive pairs of jargon and lay definitions."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the README dataset, which is a specific, verifiable dataset containing pairs of medical jargon and lay definitions. It is used for training models to convert medical jargon into patient-friendly language.",
      "processing_time": 61.99561595916748,
      "citing_paper_id": "279994613",
      "cited_paper_id": 252846393
    },
    {
      "context_text": "The README dataset 15 contains extensive pairs of medical jargon 48 and their corresponding lay definitions, making it ideal for training models to convert complex medical jargon into patient-friendly language in seen settings.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "README"
      ],
      "dataset_descriptions": {
        "README": "Used to train models to convert complex medical jargon into patient-friendly language, focusing on seen settings and leveraging extensive pairs of jargon and lay definitions."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the README dataset, which is a specific, verifiable dataset containing pairs of medical jargon and lay definitions. It is used for training models to convert medical jargon into patient-friendly language.",
      "processing_time": 61.99561595916748,
      "citing_paper_id": "279994613",
      "cited_paper_id": 266551049
    },
    {
      "context_text": "This technique has been used to transform English-centric LLMs into open-ended chat models with GPT-like performance by leveraging distilled data from GPT itself 44 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a technique involving distilled data from GPT. No clear, verifiable dataset names are provided.",
      "processing_time": 53.40665030479431,
      "citing_paper_id": "279994613",
      "cited_paper_id": 254877310
    },
    {
      "context_text": "LLMs excel at complex medical reasoning and content generation, and their growing integration into healthcare systems offers the promise of scalable, personalized patient education and support 12–14 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general capabilities of LLMs in healthcare. No verifiable resources are identified.",
      "processing_time": 53.01930618286133,
      "citing_paper_id": "279994613",
      "cited_paper_id": 257532815
    },
    {
      "context_text": "LLMs excel at complex medical reasoning and content generation, and their growing integration into healthcare systems offers the promise of scalable, personalized patient education and support 12–14 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general capabilities of LLMs in healthcare. No verifiable resources are identified.",
      "processing_time": 53.01930618286133,
      "citing_paper_id": "279994613",
      "cited_paper_id": 276212530
    },
    {
      "context_text": "This form of semantic simplification aligns with plain language principles and supports comprehension among young patients or caregivers with limited background knowledge 12 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to semantic simplification principles.",
      "processing_time": 52.12424063682556,
      "citing_paper_id": "279994613",
      "cited_paper_id": 257532815
    },
    {
      "context_text": "This adaptability is especially crucial in healthcare, where demographic and socioeconomic factors significantly influence patients’ health literacy and comprehension 21 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general factors influencing health literacy and comprehension.",
      "processing_time": 51.26971697807312,
      "citing_paper_id": "279994613",
      "cited_paper_id": 257803126
    },
    {
      "context_text": "Effective communication in healthcare hinges not only on clinical accuracy but also on the ability to convey information in a manner aligned with patients’ literacy levels and comprehension needs 5,6 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, models, or methods. It focuses on the importance of communication in healthcare and the alignment with patients' literacy levels and comprehension needs.",
      "processing_time": 55.119234800338745,
      "citing_paper_id": "279994613",
      "cited_paper_id": 258221707
    },
    {
      "context_text": "Effective communication in healthcare hinges not only on clinical accuracy but also on the ability to convey information in a manner aligned with patients’ literacy levels and comprehension needs 5,6 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, models, or methods. It focuses on the importance of communication in healthcare and the alignment with patients' literacy levels and comprehension needs.",
      "processing_time": 55.119234800338745,
      "citing_paper_id": "279994613",
      "cited_paper_id": 268266688
    },
    {
      "context_text": "At lower grade levels—especially Grades 2 and 5, where health literacy challenges are most acute—MedReadCtrl outperforms GPT-4 in clarity, fluency, and clinical accuracy (Table 2, Figure 2).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only compares MedReadCtrl and GPT-4 in terms of performance metrics.",
      "processing_time": 54.00142741203308,
      "citing_paper_id": "279994613",
      "cited_paper_id": 258221707
    },
    {
      "context_text": "These capabilities are essential for patient-facing technologies, such as discharge instruction portals, caregiver education tools, and AI-powered chatbots, which must adapt content to diverse comprehension needs in real-world settings 5,6,9 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general capabilities required for patient-facing technologies. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 53.95203232765198,
      "citing_paper_id": "279994613",
      "cited_paper_id": 258221707
    },
    {
      "context_text": "These capabilities are essential for patient-facing technologies, such as discharge instruction portals, caregiver education tools, and AI-powered chatbots, which must adapt content to diverse comprehension needs in real-world settings 5,6,9 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general capabilities required for patient-facing technologies. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 53.95203232765198,
      "citing_paper_id": "279994613",
      "cited_paper_id": 264334422
    },
    {
      "context_text": "These capabilities are essential for patient-facing technologies, such as discharge instruction portals, caregiver education tools, and AI-powered chatbots, which must adapt content to diverse comprehension needs in real-world settings 5,6,9 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general capabilities required for patient-facing technologies. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 53.95203232765198,
      "citing_paper_id": "279994613",
      "cited_paper_id": 268266688
    },
    {
      "context_text": "At its core, a key challenge for AI in healthcare is to maximize its communicative effectiveness with humans—empowering patients, improving engagement, and ultimately advancing patient-centered care 5,6 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It focuses on the challenges and goals of AI in healthcare, particularly in enhancing communication and patient-centered care.",
      "processing_time": 54.864460945129395,
      "citing_paper_id": "279994613",
      "cited_paper_id": 258221707
    },
    {
      "context_text": "At its core, a key challenge for AI in healthcare is to maximize its communicative effectiveness with humans—empowering patients, improving engagement, and ultimately advancing patient-centered care 5,6 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It focuses on the challenges and goals of AI in healthcare, particularly in enhancing communication and patient-centered care.",
      "processing_time": 54.864460945129395,
      "citing_paper_id": "279994613",
      "cited_paper_id": 268266688
    },
    {
      "context_text": "Second, our study focused on three NLG tasks—text simplification, paraphrase generation, and semantic entailment generation—which, while representative, do not encompass the full range of document styles and discourse types seen in clinical communication (e.g., patient-provider dialogues 42 ).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general tasks and a reference to clinical communication styles. No clear, verifiable datasets are identified.",
      "processing_time": 53.55833721160889,
      "citing_paper_id": "279994613",
      "cited_paper_id": 261046857
    },
    {
      "context_text": "Fine-tuning on synthetic instruction-following data with varied structure, along with task-grounded prompt engineering strategies 33,34 , may also improve adherence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to synthetic instruction-following data, which is too generic and not a named, specific dataset.",
      "processing_time": 54.670392751693726,
      "citing_paper_id": "279994613",
      "cited_paper_id": 261049152
    },
    {
      "context_text": "Fine-tuning on synthetic instruction-following data with varied structure, along with task-grounded prompt engineering strategies 33,34 , may also improve adherence.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to synthetic instruction-following data, which is too generic and not a named, specific dataset.",
      "processing_time": 54.670392751693726,
      "citing_paper_id": "279994613",
      "cited_paper_id": 266844311
    },
    {
      "context_text": "Unlike traditional supervised fine-tuning (SFT), which relies on manual annotation or synthetic data for readability control, instruction tuning provides a more generalizable approach 33 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between instruction tuning and traditional supervised fine-tuning methods.",
      "processing_time": 52.1911404132843,
      "citing_paper_id": "279994613",
      "cited_paper_id": 261049152
    },
    {
      "context_text": "Reinforcement learning with human feedback (RLHF) 32 , especially when combined with preference models that penalize redundant or overly medicalized outputs, may further refine generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RLHF) and a general approach to refining text generation. No verifiable resources are identified.",
      "processing_time": 53.935569763183594,
      "citing_paper_id": "279994613",
      "cited_paper_id": 261076002
    },
    {
      "context_text": "In future iterations, human-annotated readability and stylistic preference healthcare data can inform reward modeling under RLHF frameworks, enabling more precise alignment with user expectations and literacy needs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'human-annotated readability and stylistic preference healthcare data' but does not provide a specific, identifiable dataset name. The reference is too generic and lacks a clear identifier.",
      "processing_time": 55.64831066131592,
      "citing_paper_id": "279994613",
      "cited_paper_id": 261076002
    },
    {
      "context_text": "MedReadCtrl transforms this into: “She does have some pain in the area where her legs and hips meet, on both sides,” offering a precise yet accessible explanation that would better support health comprehension in community education portals, post-visit instructions, or telehealth consultations 9 .",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or tool (MedReadCtrl) and its application. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 55.29788875579834,
      "citing_paper_id": "279994613",
      "cited_paper_id": 264334422
    },
    {
      "context_text": "Notably, MedReadCtrl maintains semantic fidelity even when simplifying technical content, avoiding jargon while preserving intent—an essential property for equitable, patient-centered care delivery 9 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It focuses on the properties of MedReadCtrl, which is a method or tool, not a dataset.",
      "processing_time": 54.842020988464355,
      "citing_paper_id": "279994613",
      "cited_paper_id": 264334422
    },
    {
      "context_text": "This progression illustrates the model’s ability to integrate both linguistic complexity and communicative intent—an essential capability for generating documentation templates and educational materials tailored to adolescents, caregivers, or patients managing long-term conditions 9 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general capability of a model. There are no verifiable resources or specific datasets mentioned.",
      "processing_time": 53.35258078575134,
      "citing_paper_id": "279994613",
      "cited_paper_id": 264334422
    },
    {
      "context_text": "By enabling personalized content generation tailored to varying health literacy levels, the system addresses longstanding gaps in patient-centered communication and equitable access to medical information 9 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It focuses on the concept of personalized content generation and its impact on health literacy.",
      "processing_time": 53.69276571273804,
      "citing_paper_id": "279994613",
      "cited_paper_id": 264334422
    },
    {
      "context_text": "However, existing efforts in controllable text generation are largely limited to binary simplification, complication, or style-transfer tasks 15–19 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses the limitations of existing efforts in controllable text generation.",
      "processing_time": 53.45934748649597,
      "citing_paper_id": "279994613",
      "cited_paper_id": 266551049
    },
    {
      "context_text": "However, existing efforts in controllable text generation are largely limited to binary simplification, complication, or style-transfer tasks 15–19 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses the limitations of existing efforts in controllable text generation.",
      "processing_time": 53.45934748649597,
      "citing_paper_id": "279994613",
      "cited_paper_id": null
    },
    {
      "context_text": "However, existing efforts in controllable text generation are largely limited to binary simplification, complication, or style-transfer tasks 15–19 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses the limitations of existing efforts in controllable text generation.",
      "processing_time": 53.45934748649597,
      "citing_paper_id": "279994613",
      "cited_paper_id": null
    },
    {
      "context_text": "Theemergence of large language models (LLMs) introduces unprecedented opportunities to bridge this communication gap 11 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the emergence of large language models (LLMs). There is no indication of a reusable resource, findings, or specific research work.",
      "processing_time": 54.77900791168213,
      "citing_paper_id": "279994613",
      "cited_paper_id": 269354751
    },
    {
      "context_text": "Future iterations could incorporate multidimensional control signals—encoding not only readability grade but also length, tone, or reader type—within the prompt structure 31 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a suggestion for future work involving multidimensional control signals.",
      "processing_time": 51.56113314628601,
      "citing_paper_id": "279994613",
      "cited_paper_id": 270711489
    },
    {
      "context_text": "As large language models are increasingly deployed in clinical education tools, caregiver interfaces, and remote health portals, systems like MedReadCtrl can serve as foundational infrastructure for safe, comprehensible, and inclusive medical AI communication 38 .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a system (MedReadCtrl) which is not a dataset. The context focuses on the application of large language models in medical settings.",
      "processing_time": 55.19380855560303,
      "citing_paper_id": "279994613",
      "cited_paper_id": 273749420
    },
    {
      "context_text": "These improvements are more than stylistic; they translate directly into better comprehension for patients who may otherwise misinterpret discharge instructions, medication labels, or follow-up plans 23 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the impact of improved text generation on patient comprehension.",
      "processing_time": 51.92291188240051,
      "citing_paper_id": "279994613",
      "cited_paper_id": 274163373
    },
    {
      "context_text": "Moreover, limitations such as evaluation bias, domain contamination, and interpretability issues have been documented in prior work 35–37 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general issues such as evaluation bias, domain contamination, and interpretability issues.",
      "processing_time": 52.828969955444336,
      "citing_paper_id": "279994613",
      "cited_paper_id": 274234014
    },
    {
      "context_text": "Moreover, limitations such as evaluation bias, domain contamination, and interpretability issues have been documented in prior work 35–37 .",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general issues such as evaluation bias, domain contamination, and interpretability issues.",
      "processing_time": 52.828969955444336,
      "citing_paper_id": "279994613",
      "cited_paper_id": 276106991
    },
    {
      "context_text": "Additionally, incorporating fact-checking frameworks 30 to validate outputs against trusted references before generation may improve accuracy in sensitive clinical scenarios.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a fact-checking framework. No clear, verifiable dataset names are present.",
      "processing_time": 51.916528940200806,
      "citing_paper_id": "279994613",
      "cited_paper_id": 275931918
    },
    {
      "context_text": "Haudek et al.[13]demonstrated that machine evaluation is a useful complement to expert evaluation, and the results of the machine evaluation are relatively more rigorous, stable, objective, and fair.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the evaluation methods and their outcomes.",
      "processing_time": 51.361100912094116,
      "citing_paper_id": "267024706",
      "cited_paper_id": 225016068
    },
    {
      "context_text": "…of artificial intelligence technology[6], mining students' behavioral characteristics, dynamic analysis of students' learning situation, process visualization through multimodal data analysis, and timely feedback of the diagnostic results, so as to achieve dynamic evaluation presentation [7].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only describes a general application of AI technology in educational settings.",
      "processing_time": 52.657700061798096,
      "citing_paper_id": "267024706",
      "cited_paper_id": null
    },
    {
      "context_text": "…reports involves the application of a variety of technologies such as NLP (Natural Language Processing), sentiment analysis, AIGC technology[3] (AI automatic content generation), etc., among which AIGC technology has a wide range of applications in the field of content generation, for…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only refers to general technologies and applications.",
      "processing_time": 51.908121824264526,
      "citing_paper_id": "267024706",
      "cited_paper_id": null
    },
    {
      "context_text": "Only by accurately acquiring multimodal learning data can teaching be targeted for improvement [14], and multimodal data collection is the basis for acquiring learning conditions.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to multimodal data collection in a general sense.",
      "processing_time": 52.817251443862915,
      "citing_paper_id": "267024706",
      "cited_paper_id": null
    },
    {
      "context_text": "Advancements in universal text-generation technology prompt researchers to explore more anthropopathic text-generation methods, such as context-based text generation [56], personalized text generation [86], topic-aware text generation [133], emotional text generation [66], knowledgeenhanced text generation [147], and visual text generation [26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various types of text generation methods. No verifiable resources are identified.",
      "processing_time": 52.64058184623718,
      "citing_paper_id": "229377215",
      "cited_paper_id": 665667
    },
    {
      "context_text": "Advancements in universal text-generation technology prompt researchers to explore more anthropopathic text-generation methods, such as context-based text generation [56], personalized text generation [86], topic-aware text generation [133], emotional text generation [66], knowledgeenhanced text generation [147], and visual text generation [26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various types of text generation methods. No verifiable resources are identified.",
      "processing_time": 52.64058184623718,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53287752
    },
    {
      "context_text": "[26] leverage the conditional GAN (CGAN) model to generate high-quality image descriptions in three aspects, including naturalness, semantic relevance, and diversity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (CGAN) and its application. No verifiable resources are identified.",
      "processing_time": 53.23479866981506,
      "citing_paper_id": "229377215",
      "cited_paper_id": 665667
    },
    {
      "context_text": "[26] Conditional GAN (CGAN) CNN captures information in an image, and LSTM generates the relevant descriptions; the discriminator evaluates the quality of generated descriptions",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the architecture and functionality of the CGAN model.",
      "processing_time": 53.628552198410034,
      "citing_paper_id": "229377215",
      "cited_paper_id": 665667
    },
    {
      "context_text": "[89] LSTM + CNN CNN and LSTM, respectively, encode the image and the question into vectors to capture the semantic information, and then another LSTM generates corresponding answers",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is focused on the architecture and approach used for answering questions about images.",
      "processing_time": 53.803609132766724,
      "citing_paper_id": "229377215",
      "cited_paper_id": 738850
    },
    {
      "context_text": "[89] combine CNN with LSTM to answer questions about the given image.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method combining CNN with LSTM for answering questions about images.",
      "processing_time": 52.08262276649475,
      "citing_paper_id": "229377215",
      "cited_paper_id": 738850
    },
    {
      "context_text": "[10] introduce a RNN-based VAE text-generation model that assigns whole sentences with distributed latent vectors.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RNN-based VAE text-generation model).",
      "processing_time": 52.46027326583862,
      "citing_paper_id": "229377215",
      "cited_paper_id": 748227
    },
    {
      "context_text": "[142] propose an image caption model utilizing attention mechanism to extract the most important information in images to generate more accurate and detailed image description.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a method for generating image captions using visual attention.",
      "processing_time": 52.07374882698059,
      "citing_paper_id": "229377215",
      "cited_paper_id": 1055111
    },
    {
      "context_text": "[162] GRU + Emotional embedding Emotion category embedding captures emotional information and the internal emotion memory balances the grammaticality and the expression degree of emotions",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating emotional conversations using GRU and emotional embeddings.",
      "processing_time": 52.29808282852173,
      "citing_paper_id": "229377215",
      "cited_paper_id": 2024574
    },
    {
      "context_text": "Researchers have also made some fine-tuning to GAN’s structure to generate discrete data, e.g., the Wasserstein GAN model [3].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (Wasserstein GAN).",
      "processing_time": 51.873334884643555,
      "citing_paper_id": "229377215",
      "cited_paper_id": 2057420
    },
    {
      "context_text": "[71] present a speaker model that encodes user profile into vectors to capture personalized features and guide the response generation during the decode stage.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for encoding user profiles into vectors.",
      "processing_time": 51.87100291252136,
      "citing_paper_id": "229377215",
      "cited_paper_id": 2955580
    },
    {
      "context_text": "[71] RNN + Speaker model The speaker model encodes each individual speaker into a vector to capture characteristics; Generating personal responses matching a specific user",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes a method for encoding speakers in a neural conversation model.",
      "processing_time": 53.28249549865723,
      "citing_paper_id": "229377215",
      "cited_paper_id": 2955580
    },
    {
      "context_text": "[71] propose persona-based models to solve the problem of speaker consistency in dialogue systems.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model for improving speaker consistency in dialogue systems.",
      "processing_time": 52.07571196556091,
      "citing_paper_id": "229377215",
      "cited_paper_id": 2955580
    },
    {
      "context_text": "Besides, The application fields from image to text generation include image captioning [91], visual question answering [2], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general application areas of image-to-text generation.",
      "processing_time": 52.071526288986206,
      "citing_paper_id": "229377215",
      "cited_paper_id": 3527896
    },
    {
      "context_text": "Using a large amount of data to train the LSTM language model in an unsupervised way, the contextual word vector of each word can be obtained to demonstrate strong results across discriminative natural language understanding (NLU) tasks [94, 104].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'a large amount of data' but does not specify a named dataset. The cited papers do not provide additional specific dataset names.",
      "processing_time": 54.112144947052,
      "citing_paper_id": "229377215",
      "cited_paper_id": 3626819
    },
    {
      "context_text": "Using a large amount of data to train the LSTM language model in an unsupervised way, the contextual word vector of each word can be obtained to demonstrate strong results across discriminative natural language understanding (NLU) tasks [94, 104].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'a large amount of data' but does not specify a named dataset. The cited papers do not provide additional specific dataset names.",
      "processing_time": 54.112144947052,
      "citing_paper_id": "229377215",
      "cited_paper_id": 9447219
    },
    {
      "context_text": "[113] Hierarchical context embedding Embedding the word sequences in each context sentences at the low-level and embedding the sentence sequences in the historical dialogues at the top-level to efficiently capture the context information",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for embedding word sequences and sentence sequences in dialogues.",
      "processing_time": 52.59337592124939,
      "citing_paper_id": "229377215",
      "cited_paper_id": 6126582
    },
    {
      "context_text": "[113] use Hierarchical Recurrent Encoder-Decoder (HRED) model to hierarchically encode the dialogue history and guide the generation of replies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (HRED). The context focuses on the methodology and model architecture rather than data sources.",
      "processing_time": 54.09502458572388,
      "citing_paper_id": "229377215",
      "cited_paper_id": 6126582
    },
    {
      "context_text": "The application of text generation from text-to-text includes machine translation [22], dialogue system [115], text summarization [111], reading comprehension [51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of text generation. No dataset names are present in the text.",
      "processing_time": 53.247018337249756,
      "citing_paper_id": "229377215",
      "cited_paper_id": 6203757
    },
    {
      "context_text": "The application of text generation from text-to-text includes machine translation [22], dialogue system [115], text summarization [111], reading comprehension [51], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of text generation. No dataset names are present in the text.",
      "processing_time": 53.247018337249756,
      "citing_paper_id": "229377215",
      "cited_paper_id": 7356547
    },
    {
      "context_text": "[40] achieve the goal of transferring the emotion of reviews from positive/negative to negative/positive through multi-task learning and adversarial training.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for style transfer in text. No verifiable resources are identified.",
      "processing_time": 52.971648931503296,
      "citing_paper_id": "229377215",
      "cited_paper_id": 6484065
    },
    {
      "context_text": "[40] GRU + Multi-task learning Multi-decoder Seq2seq module generates outputs with different styles and style embedding module augments the encoded representations",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating text with different styles using a multi-decoder Seq2seq module.",
      "processing_time": 53.872702836990356,
      "citing_paper_id": "229377215",
      "cited_paper_id": 6484065
    },
    {
      "context_text": "PERSONA CHAT [151] Personalized dataset A personalized dialogue dataset where two parts of every conversation are given a group of profile information",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PERSONA CHAT"
      ],
      "dataset_descriptions": {
        "PERSONA CHAT": "Used to train personalized dialogue agents, focusing on incorporating profile information into conversations to enhance personalization and engagement."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'PERSONA CHAT' as a personalized dialogue dataset, which is relevant to the topic of personalized text generation.",
      "processing_time": 58.81930875778198,
      "citing_paper_id": "229377215",
      "cited_paper_id": 6869582
    },
    {
      "context_text": "[151] present a high-quality personalized dialogue dataset named PERSONA CHAT.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PERSONA CHAT"
      ],
      "dataset_descriptions": {
        "PERSONA CHAT": "Used to train and evaluate personalized dialogue agents, focusing on incorporating personal information into conversations to enhance user engagement and interaction."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset named 'PERSONA CHAT' which is relevant to personalized dialogue systems.",
      "processing_time": 58.32575798034668,
      "citing_paper_id": "229377215",
      "cited_paper_id": 6869582
    },
    {
      "context_text": "Zhang et al. [151] present a high-quality personalized dialogue dataset named PERSONA CHAT.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PERSONA CHAT"
      ],
      "dataset_descriptions": {
        "PERSONA CHAT": "Used to develop and evaluate personalized dialogue systems, focusing on incorporating user profiles into conversational interactions."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset named 'PERSONA CHAT' which is used for personalizing dialogue agents.",
      "processing_time": 58.665982723236084,
      "citing_paper_id": "229377215",
      "cited_paper_id": 6869582
    },
    {
      "context_text": "The matching degree is calculated with multiple reference texts and the best-matching one is selected as the final METEOR score.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a metric (METEOR) which is not included as per instructions.",
      "processing_time": 52.95706009864807,
      "citing_paper_id": "229377215",
      "cited_paper_id": 7164502
    },
    {
      "context_text": "METEOR.",
      "catation_intent": "none",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "METEOR is a metric, not a dataset, and thus does not meet the criteria for inclusion.",
      "processing_time": 52.38321232795715,
      "citing_paper_id": "229377215",
      "cited_paper_id": 7164502
    },
    {
      "context_text": "METEOR [8] calculates the precision and recall of unigrams between generated texts and reference texts.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a metric (METEOR) which is excluded according to the instructions.",
      "processing_time": 53.23967003822327,
      "citing_paper_id": "229377215",
      "cited_paper_id": 7164502
    },
    {
      "context_text": "Ubuntu Dialogue Corpus [82] Context-based dataset A multi-turn dialogue dataset extracted from the Ubuntu chat logs",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Ubuntu Dialogue Corpus"
      ],
      "dataset_descriptions": {
        "Ubuntu Dialogue Corpus": "Used to research unstructured multi-turn dialogue systems, focusing on context-based interactions extracted from Ubuntu chat logs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset, 'Ubuntu Dialogue Corpus', which is a multi-turn dialogue dataset extracted from Ubuntu chat logs. The cited paper title confirms it is a dataset.",
      "processing_time": 60.515052318573,
      "citing_paper_id": "229377215",
      "cited_paper_id": 8379583
    },
    {
      "context_text": "Ubuntu Dialogue Corpus(17) [82] is another large multi-turn dialogue dataset containing almost one million conversations extracted from the Ubuntu chat logs that is a great help for training context-sensitive technical dialogue systems.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Ubuntu Dialogue Corpus"
      ],
      "dataset_descriptions": {
        "Ubuntu Dialogue Corpus": "Used to train context-sensitive technical dialogue systems, leveraging almost one million conversations extracted from Ubuntu chat logs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the Ubuntu Dialogue Corpus as a large multi-turn dialogue dataset, which is relevant for training context-sensitive technical dialogue systems.",
      "processing_time": 58.31675982475281,
      "citing_paper_id": "229377215",
      "cited_paper_id": 8379583
    },
    {
      "context_text": "The Attention mechanism is first applied to the Seq2seq model to fulfill machine translation tasks [5], and now has gradually become an important part of text-generation models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the application of the Attention mechanism in Seq2seq models for machine translation and text generation.",
      "processing_time": 54.04912042617798,
      "citing_paper_id": "229377215",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "Since this framework has no limitation of the length of input/output sequences, it has been widely used in text generation, including machine translation [22], text summarization [111], and dialogue system [129].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of the framework in text generation tasks.",
      "processing_time": 52.375508308410645,
      "citing_paper_id": "229377215",
      "cited_paper_id": 12300158
    },
    {
      "context_text": "The Graph Transformer model computes the hidden representations of each node in a graph by attending over its neighbors following a self-attention strategy to leverage the relational structure of knowledge graph.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model and its methodology. The cited paper title 'Attention is All you Need' is about a method, not a dataset.",
      "processing_time": 55.58113098144531,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Since Transformer was put forward, the various models based on it have achieved excellent performance in various NLP tasks, such as BERT [60] and GPT [106], making significant impact on the whole research area of NLP.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their impact on NLP tasks. No verifiable datasets are referenced.",
      "processing_time": 53.66348314285278,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Since Transformer was put forward, the various models based on it have achieved excellent performance in various NLP tasks, such as BERT [60] and GPT [106], making significant impact on the whole research area of NLP.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their impact on NLP tasks. No verifiable datasets are referenced.",
      "processing_time": 53.66348314285278,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "By this means, the Conditional Transformer Language (CTRL) model learns the relationship between the control codes and the text that follows to determine the generated text under the desired condition controlled by the specific code.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (CTRL) and its functionality. No verifiable resources are identified.",
      "processing_time": 52.71039342880249,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "GPT adopts the typical pre-training and fine-tuning training framework, with Transformer decoder as the feature extractor.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model architecture and training framework.",
      "processing_time": 50.66971254348755,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Faced with other problems of RNN, including the inability to effectively capture long-term dependencies, the vulnerability to the problem of gradient vanishing or exploding, and the lack of parallel computing capability, the Transformer model is proposed, which adopts self-attention mechanism to replace the sequential structure in RNN.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only discusses the limitations of RNNs and the introduction of the Transformer model.",
      "processing_time": 53.291152477264404,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "After that, Transformer has become a standard structure for many NLP tasks, giving a big boost to the development of the NLP field.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the impact of the Transformer model on NLP tasks.",
      "processing_time": 52.54970145225525,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "In addition to the GPT series that only contain Transformer decoders, researchers also explore the Seq2seq pre-training for unconditional text generation to jointly train encoders and decoders for better generation performance, including MASS [120], UniLM [34], BART [68], T5 [108], and so on.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 53.681315660476685,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Due to the powerful performance of Transformer, more and more researchers begin to use it for knowledge understanding.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of the Transformer model. No verifiable resources are identified.",
      "processing_time": 53.28858995437622,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "The self-attention modules in Transformer are used to encode the product attributes, the relevant knowledge, and the specific user categories into semantic vector representations, and perform deep semantic interaction to capture semantic features for the decoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of Transformer self-attention modules. No verifiable resources are identified.",
      "processing_time": 53.6757926940918,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "After the GNMT system, Google proposes the Transformer model for the machine translation task, which completely abandons the common network structure in RNN, and only adopts the attention mechanism to carry out sequence modeling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the Transformer model and its application in machine translation.",
      "processing_time": 52.33336639404297,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Recent pre-trained language models based on large Transformer architectures prove the ability of both big models and big data to improve language representation and generation performance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only refers to large Transformer architectures and big data in general.",
      "processing_time": 52.57168912887573,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Transformer is gradually replacing the mainstream position of LSTM in NLP.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a shift in technology from LSTM to Transformer in NLP.",
      "processing_time": 52.83574414253235,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Transformer has shown excellent performance in various NLP tasks since it was proposed and has great development potential.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the Transformer model and its performance in NLP tasks.",
      "processing_time": 52.53075098991394,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Due to the parallelization of the Attention module, Transformer has powerful parallel computing capacity and broad application prospect.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only discusses the capabilities of the Transformer model.",
      "processing_time": 51.11682057380676,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Each sentence in the memory is independently encoded with a Transformer encoder, and the same Transformer is used to encode the dialogue context.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Transformer encoder) which is excluded according to the instructions.",
      "processing_time": 52.79532599449158,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Specifically, the Transformer model is an encoder-decoder structure, only consisting of Attention modules and feed forward neural networks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the architecture of the Transformer model.",
      "processing_time": 51.45221138000488,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "To address this problem, Google proposes a new sequence modeling model, the Transformer model [126], which abandons the sequence structure in RNN and just contains Attention modules.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (Transformer).",
      "processing_time": 50.53915596008301,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "In addition to RNN, Dinan et al. [32] combine Transformer and Memory Network to build an open-domain knowledge-based dialogue system.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the combination of Transformer and Memory Network for building a dialogue system.",
      "processing_time": 53.6267364025116,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Zhao et al. [156] introduce the hierarchical interaction between the context and external document knowledge to capture the most important parts in the document and context using the multi-head attention module in Transformer for selecting the most appropriate response.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Transformer) and a concept (multi-head attention).",
      "processing_time": 53.17875528335571,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Specifically, with the help of the recurrent neural networks (RNN) [36], attention mechanism, generative adversarial networks (GAN) [47], reinforcement learning (RL), Variational Autoencoder (VAE) [63], and Transformer [126], the generated text becomesmore coherent, logical and emotionally harmonious, which is more suitable for offering assistance in every aspect of people’s lives.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 53.79303693771362,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "In the encoding stage, external conditions can be encoded by various techniques, such as RNN and Transformer, and served as the input of the decoder together with the original input to control the generation process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria.",
      "processing_time": 53.376802921295166,
      "citing_paper_id": "229377215",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "BLEU contains many variants, such as SentBLEU [80], Δ BLEU [41], NIST [33], and so on.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions various metrics but does not refer to any specific dataset. Metrics are excluded according to the instructions.",
      "processing_time": 52.54209756851196,
      "citing_paper_id": "229377215",
      "cited_paper_id": 14067706
    },
    {
      "context_text": "NIST is a typical variant of BLEU, which improves BLEU’s evaluation accuracy by assigning higher weights to low-frequency n -gram (e.g., more informative) and imposing length penalties.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (BLEU) and its variant (NIST). These are excluded as per instructions.",
      "processing_time": 54.179407596588135,
      "citing_paper_id": "229377215",
      "cited_paper_id": 14067706
    },
    {
      "context_text": "The TranE algorithm [9] is proposed to transform structured triples into low dimensional vector representations and is widely used in knowledge-enhanced text-generation systems.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the TranE algorithm but does not refer to any specific dataset. The algorithm is described as being used in knowledge-enhanced text-generation systems, but no dataset is explicitly mentioned.",
      "processing_time": 55.57945442199707,
      "citing_paper_id": "229377215",
      "cited_paper_id": 14941970
    },
    {
      "context_text": "The pretrained language models are first introduced into NLP for word embedding [96].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the introduction of pretrained language models for word embedding.",
      "processing_time": 52.52025508880615,
      "citing_paper_id": "229377215",
      "cited_paper_id": 16447573
    },
    {
      "context_text": "Researchers carry out manyworks on text generation with multi-modal data as inputs, such as generating description/caption for a given image [83], conducting QA with images [119], and communicating based on the content of a given image [28].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only refers to general types of tasks involving multi-modal data.",
      "processing_time": 53.78240418434143,
      "citing_paper_id": "229377215",
      "cited_paper_id": 18347865
    },
    {
      "context_text": "[144] Reinforcement Learning + Persona embedding Embedding user-specific information into vector representation; RL mechanism optimizes three rewards – topic coherent, informative and grammatical, to generate more personalized responses",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The focus is on the use of reinforcement learning and persona embedding for personalized dialogue generation.",
      "processing_time": 54.3929169178009,
      "citing_paper_id": "229377215",
      "cited_paper_id": 21669082
    },
    {
      "context_text": "[144] present the attention-based hierarchical encoder-decoder architecture via RL to realize personalized dialogue generation, which defines three types of reward mechanisms, including topic coherence, mutual information, and language model to force the text-generation model to generate topic-relevance and coherent dialogue responses.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for personalized dialogue generation using reinforcement learning.",
      "processing_time": 52.19923710823059,
      "citing_paper_id": "229377215",
      "cited_paper_id": 21669082
    },
    {
      "context_text": "[153] utilize the smooth approximation algorithm to approximate the output of generator.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or algorithm.",
      "processing_time": 51.07708120346069,
      "citing_paper_id": "229377215",
      "cited_paper_id": 29797603
    },
    {
      "context_text": "[153] attempt to combine the LSTM and convolutional neural network (CNN) to generate realistic text using the idea of adversarial training.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method combining LSTM and CNN for text generation.",
      "processing_time": 52.40626263618469,
      "citing_paper_id": "229377215",
      "cited_paper_id": 29797603
    },
    {
      "context_text": "[84] Autoencoder + Multi-task learning Training a response-generation model on a small personalized dialogue data, and then training an autoencoder model with non-conversational data; Sharing parameters of the two models to obtain the personalized dialogue model",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "personalized dialogue data"
      ],
      "dataset_descriptions": {
        "personalized dialogue data": "Used to train a response-generation model, focusing on speaker-role adaptation in neural conversation models through multi-task learning."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'personalized dialogue data' which is domain-qualified and relevant to the research topic of personalized text generation.",
      "processing_time": 59.273293018341064,
      "citing_paper_id": "229377215",
      "cited_paper_id": 31298398
    },
    {
      "context_text": "[84] trains a dialogue model to predict responses given previous contexts and an autoencoder model with large volumes of non-conversational personal data to model the rolespecific characteristics of different users.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'large volumes of non-conversational personal data' but does not specify a named dataset. The reference is too generic and lacks a specific identifier.",
      "processing_time": 55.06179141998291,
      "citing_paper_id": "229377215",
      "cited_paper_id": 31298398
    },
    {
      "context_text": "[84] train a dialogue model to predict responses given previous contexts and an autoencoder model with large volumes of non-conversational personal data to model the role-specific characteristics of different users.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The context mentions training a dialogue model and using an autoencoder model with large volumes of non-conversational personal data, but does not specify a named dataset.",
      "processing_time": 54.89613890647888,
      "citing_paper_id": "229377215",
      "cited_paper_id": 31298398
    },
    {
      "context_text": "[52] use an additional neural network to capture the highlevel personalized information based on the personality traits.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for capturing personalized information using personality traits.",
      "processing_time": 52.39615273475647,
      "citing_paper_id": "229377215",
      "cited_paper_id": 34405847
    },
    {
      "context_text": "[163] Knowledge-based dataset A commonsense conversation dataset containing one-turn post-response pairs with corresponding commonsense knowledge graphs",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Knowledge-based dataset"
      ],
      "dataset_descriptions": {
        "Knowledge-based dataset": "Used to train models for generating commonsense-aware conversations, focusing on one-turn post-response pairs with associated knowledge graphs."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset with a clear name and purpose, which is relevant to personalized text generation.",
      "processing_time": 58.45106911659241,
      "citing_paper_id": "229377215",
      "cited_paper_id": 51608183
    },
    {
      "context_text": "There have beenmany text-generation researches, focusing on the dialogue systems [32, 163], combined with knowledge bases.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general research areas and the combination with knowledge bases.",
      "processing_time": 52.38831686973572,
      "citing_paper_id": "229377215",
      "cited_paper_id": 51608183
    },
    {
      "context_text": "There have beenmany text-generation researches, focusing on the dialogue systems [32, 163], combined with knowledge bases.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general research areas and the combination with knowledge bases.",
      "processing_time": 52.38831686973572,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53218829
    },
    {
      "context_text": "[163] produce a knowledge-based dialogue model (CCM) that leverages two graph attention mechanisms to promote dialogue understanding and knowledgeable responses generating.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CCM) and its components. The focus is on the model and its mechanisms, not on a particular dataset.",
      "processing_time": 55.53332567214966,
      "citing_paper_id": "229377215",
      "cited_paper_id": 51608183
    },
    {
      "context_text": "[163] produce two graph attention mechanisms, static graph attention and dynamic graph attention, respectively, to promote dialogue understanding and knowledgeable responses generating.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for improving dialogue understanding and response generation.",
      "processing_time": 52.15651774406433,
      "citing_paper_id": "229377215",
      "cited_paper_id": 51608183
    },
    {
      "context_text": "[163] present a commonsense conversation dataset(25) containing one-turn post-response pairs with the corresponding commonsense knowledge graphs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "commonsense conversation dataset"
      ],
      "dataset_descriptions": {
        "commonsense conversation dataset": "Used to generate commonsense-aware conversations, focusing on one-turn post-response pairs with associated knowledge graphs."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions a specific dataset with a clear name and purpose, which is relevant to personalized text generation.",
      "processing_time": 58.44191336631775,
      "citing_paper_id": "229377215",
      "cited_paper_id": 51608183
    },
    {
      "context_text": "[163] Knowledge graph attention Graph attention mechanisms integrate commonsense information from the knowledge based on the dialogue history; Generating more appropriate and informative responses",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (graph attention mechanisms) and a general reference to commonsense information and dialogue history.",
      "processing_time": 54.34864926338196,
      "citing_paper_id": "229377215",
      "cited_paper_id": 51608183
    },
    {
      "context_text": "[38] RNN + Topic embedding Assigning each topic with different weight to maintain a multi-topic coverage vector and updating them in the decoding process in order",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for topic-to-essay generation using RNNs and topic embeddings.",
      "processing_time": 54.002708435058594,
      "citing_paper_id": "229377215",
      "cited_paper_id": 51609716
    },
    {
      "context_text": "[38] develop a multi-topic-aware LSTM (MTA-LSTM) model to generate a paragraph-level text under target multiple topic words.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (MTA-LSTM) and a general task (paragraph-level text generation).",
      "processing_time": 54.50367856025696,
      "citing_paper_id": "229377215",
      "cited_paper_id": 51609716
    },
    {
      "context_text": "[132] propose the SentiGANwith multiple generators and one multi-class discriminator to enhance the sentiment accuracy and quality of generated texts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called SentiGAN. The context focuses on the method's purpose and structure.",
      "processing_time": 54.490925550460815,
      "citing_paper_id": "229377215",
      "cited_paper_id": 51609768
    },
    {
      "context_text": "[48] present an incremental encoding schema to mine hidden information in the story context and graph, and a contextual attention mechanism to encode knowledge graph into vectors.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the incremental encoding schema and contextual attention mechanism.",
      "processing_time": 54.0032434463501,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52136077
    },
    {
      "context_text": "[6] incorporate topic and semantic similarity constraints into the decoding objective of dialogue systems to encourage the generation of more topic-relevant and content words in responses.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving dialogue systems.",
      "processing_time": 51.98396849632263,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52159416
    },
    {
      "context_text": "CMU DoG [164] Knowledge-based dataset A document grounded conversation dataset where each conversation are about contents of a specified document",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CMU DoG"
      ],
      "dataset_descriptions": {
        "CMU DoG": "Used to train and evaluate models for document-grounded conversations, focusing on the ability to generate responses based on the content of a specified document."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'CMU DoG' as a dataset for document-grounded conversations, which fits the criteria for a specific, verifiable dataset.",
      "processing_time": 60.9825758934021,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52307098
    },
    {
      "context_text": "CMU DoG(23) [164] is a document grounded conversation dataset where each conversation is followed by specified documents about popular movies extracted from Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CMU DoG"
      ],
      "dataset_descriptions": {
        "CMU DoG": "Used to train models for document-grounded conversations, focusing on generating responses based on Wikipedia articles about popular movies."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions CMU DoG as a document-grounded conversation dataset, which is relevant to personalized text generation as it involves conversations based on specific documents.",
      "processing_time": 60.210580587387085,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52307098
    },
    {
      "context_text": "CMU DoG 23 [164] is a document grounded conversation dataset where each conversation is followed by specified documents about popular movies extracted from Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CMU DoG 23"
      ],
      "dataset_descriptions": {
        "CMU DoG 23": "Used to train and evaluate document-grounded conversation models, focusing on conversations linked to Wikipedia articles about popular movies."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'CMU DoG 23' as a document-grounded conversation dataset, which fits the criteria for a specific, verifiable dataset.",
      "processing_time": 61.30451965332031,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52307098
    },
    {
      "context_text": "CMU DoG 23 [164] is a document grounded conversation dataset where each conversation is followed by specified documents about popular movies extracted from Wikipedia articles.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CMU DoG 23"
      ],
      "dataset_descriptions": {
        "CMU DoG 23": "Used to train and evaluate document-grounded conversation models, focusing on conversations linked to Wikipedia articles about popular movies."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'CMU DoG 23' as a document-grounded conversation dataset, which fits the criteria for a specific, verifiable dataset.",
      "processing_time": 61.30451965332031,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53218829
    },
    {
      "context_text": "The knowledge text descriptions are embed into vectors by word embedding average or BERT model, which are concatenated with traditional word embeddings to enhance the understanding of the technical term in dialogue history.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to word embedding methods and BERT, which are excluded as they are models/methods.",
      "processing_time": 55.33122181892395,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Among numerous works, the BERTmodel [60] and the GPTmodel [106] receive the most attention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions BERT and GPT models but does not refer to any specific datasets. The context is about models receiving attention, not about using datasets.",
      "processing_time": 54.797624349594116,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Among numerous works, the BERT model [60] and the GPT model [106] receive the most attention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions BERT and GPT models but does not refer to any specific datasets. The context is about models receiving attention, not about dataset usage.",
      "processing_time": 54.78523302078247,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Just adding a specific output layer rather than adjusting the model’s structure, the pre-trained BERT model can be fine-tuned to achieve the state-of-the-art performance in many NLU tasks, such as text classification.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT for fine-tuning in NLU tasks.",
      "processing_time": 53.61231207847595,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In the knowledge distillation stage, the generated sequences of word logits by the teacher BERT model contains information from both backward and forward contexts, providing sequence-level global guidance.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (BERT) which is excluded according to the rules.",
      "processing_time": 53.18286728858948,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "The fine-tuned BERT model is applied to get the aspect and aspect sentiment polarity from the reviews.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of a BERT model for aspect and sentiment analysis.",
      "processing_time": 53.37597060203552,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "The training objective of POINTER is to generate a complete text sequence with a set of keywords as constraints, which is similar to the masked language modeling (MLM) objective in BERT, so pre-trained BERT is used to initialize the model training to boost the generation performance.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERT for initializing model training. BERT is a model, not a dataset.",
      "processing_time": 54.78438448905945,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Subsequently, a lot of work is done to optimize the pre-training process of BERT to further improve the ability of language representation, among which the most typical work includes XLnet [146], RoBERTa [81], and ELECTRA [25].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 54.08603262901306,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Subsequently, a lot of work is done to optimize the pre-training process of BERT to further improve the ability of language representation, among which the most typical work includes XLnet [146], RoBERTa [81], and ELECTRA [25].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 54.08603262901306,
      "citing_paper_id": "229377215",
      "cited_paper_id": null
    },
    {
      "context_text": "Based on this dataset, they propose an efficient BERT-based response selection model, CoBERT, using multi-hop co-attention to learn higher-level interactive matching.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'this dataset' but does not provide a specific name. The cited paper title is about BERT, which is a model, not a dataset.",
      "processing_time": 55.309518575668335,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "BERT learns bidirectional representations of massive textual data by conditioning on both the forward and back-ward sequential contexts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the BERT model and its training methodology. BERT itself is a model, not a dataset.",
      "processing_time": 54.13461494445801,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "The Conditional Masked Language Modeling (C-MLM) task is proposed to enable pre-trained BERT with additional conditional input by randomly masking tokens only in the target sequence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (C-MLM) and a model (BERT).",
      "processing_time": 53.293641567230225,
      "citing_paper_id": "229377215",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "[35] introduce a Topical Hierarchical Recurrent Encoder Decoder (THRED) model to generate contextual and topic-aware responses.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (THRED). The context is about introducing a model for generating topic-aware responses.",
      "processing_time": 53.97422170639038,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53217693
    },
    {
      "context_text": "[35] HRED + LDA + Topic embedding Combining topic and context information to produce not only contextual but also topic-aware responses",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The focus is on combining topic and context information for response generation.",
      "processing_time": 53.812668323516846,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53217693
    },
    {
      "context_text": "Wizard of Wikipedia 24 [32] is another open-domain dataset whose conversations are directly grounded with knowledge retrieved from Wikipedia.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wizard of Wikipedia"
      ],
      "dataset_descriptions": {
        "Wizard of Wikipedia": "Used to train conversational agents that incorporate Wikipedia knowledge, focusing on generating contextually relevant and informative responses in open-domain conversations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Wizard of Wikipedia' as an open-domain dataset used for conversations grounded with Wikipedia knowledge, which is relevant to personalized text generation.",
      "processing_time": 59.90498661994934,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53218829
    },
    {
      "context_text": "Wizard of Wikipedia(24) [32] is another open-domain dataset whose conversations are directly grounded with knowledge retrieved from Wikipedia.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wizard of Wikipedia"
      ],
      "dataset_descriptions": {
        "Wizard of Wikipedia": "Used to train conversational agents that incorporate Wikipedia knowledge, focusing on generating contextually relevant and informative responses in open-domain conversations."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Wizard of Wikipedia' as an open-domain dataset used for conversations grounded with Wikipedia knowledge, which is relevant to personalized text generation.",
      "processing_time": 59.70506501197815,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53218829
    },
    {
      "context_text": "[32] combine Transformer and Memory Network to build an open-domain knowledge-based dialogue system.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a combination of Transformer and Memory Network models. The title 'Wizard of Wikipedia' suggests the use of Wikipedia as a knowledge source, but it is not explicitly mentioned as a dataset in the citation.",
      "processing_time": 57.040424823760986,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53218829
    },
    {
      "context_text": "Wizard of Wikipedia [32] Knowledge-based dataset A knowledge-grounded dataset with conversations directly grounded with knowledge retrieved from Wikipedia",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wizard of Wikipedia"
      ],
      "dataset_descriptions": {
        "Wizard of Wikipedia": "Used to train knowledge-powered conversational agents, focusing on grounding conversations with factual information from Wikipedia articles."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Wizard of Wikipedia' as a knowledge-grounded dataset with conversations directly grounded with knowledge from Wikipedia, which fits the criteria for a dataset.",
      "processing_time": 59.52961492538452,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53218829
    },
    {
      "context_text": "[32] Transformer + Memory Network Memory Network retrieves knowledge about the dialogue from the memory and Transformer encodes and decodes the text representations to generate responses; Conducting knowledgeable discussions on open-domain topics",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The focus is on the combination of Transformer and Memory Network for generating knowledgeable responses.",
      "processing_time": 54.44934034347534,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53218829
    },
    {
      "context_text": "[86] build a personalized goal-oriented dialog system for the restaurant reservation task.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a task (restaurant reservation). No clear, verifiable resource names are provided.",
      "processing_time": 53.61609888076782,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53287752
    },
    {
      "context_text": "[39] train an unsupervised image captioning model to generate image captions without the paired image-sentence datasets.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions training an unsupervised image captioning model but does not specify any dataset names. The reference is to a method or approach rather than a specific dataset.",
      "processing_time": 54.83237051963806,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53771922
    },
    {
      "context_text": "[70] convert visual QA question into a machine reading comprehension problem combined with the large-scale external knowledge base to realize the knowledge-based visual QA.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions an 'external knowledge base' but does not specify a name. No other specific datasets are mentioned.",
      "processing_time": 52.48081922531128,
      "citing_paper_id": "229377215",
      "cited_paper_id": 53955763
    },
    {
      "context_text": "[159] propose a trait fusion module to capture the persona information of each speaker.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for capturing persona information in dialogue generation.",
      "processing_time": 52.698379039764404,
      "citing_paper_id": "229377215",
      "cited_paper_id": 59316441
    },
    {
      "context_text": "[159] propose the persona aware attention mechanism to control the attention weights of context vectors under integrated persona vectors and the persona-aware bias to estimate the generation distribution for personalized dialogue responses generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for personalized dialogue generation.",
      "processing_time": 52.09405183792114,
      "citing_paper_id": "229377215",
      "cited_paper_id": 59316441
    },
    {
      "context_text": "However, when the weight of the specific feature is too large,Weighted Decoding risks going off-distribution, thus generating unanticipated words [112].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model (Weighted Decoding). There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 54.82075643539429,
      "citing_paper_id": "229377215",
      "cited_paper_id": 67855999
    },
    {
      "context_text": "[72] propose the User-aware Sequence Network (USN), to generate a summary for a user’s review according to his preference on different aspects or writing style.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (User-aware Sequence Network) for personalized review summarization.",
      "processing_time": 53.386913776397705,
      "citing_paper_id": "229377215",
      "cited_paper_id": 69778590
    },
    {
      "context_text": "[77] present the Persona-Aware Tips-generation model (PATG),",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model called 'Persona-Aware Tips-generation model (PATG)'. No verifiable datasets are referenced.",
      "processing_time": 54.62536430358887,
      "citing_paper_id": "229377215",
      "cited_paper_id": 70350032
    },
    {
      "context_text": "[18] introduce a Knowledge-based Personalized (KOBE) product description-generation model, which fuses product aspects, user categories, and knowledge base to generate informative and personalized product descriptions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a model (KOBE) but does not explicitly reference a dataset. The context focuses on the model's capabilities rather than a specific dataset.",
      "processing_time": 54.62242317199707,
      "citing_paper_id": "229377215",
      "cited_paper_id": 88524997
    },
    {
      "context_text": "[18] propose a personalized product description-generation model by leveraging neural networks combined with the knowledge base.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a 'knowledge base' but does not specify a named, verifiable dataset. The term 'knowledge base' is too generic and lacks a specific identifier.",
      "processing_time": 55.01648688316345,
      "citing_paper_id": "229377215",
      "cited_paper_id": 88524997
    },
    {
      "context_text": "[18] provide a personalized and knowledge-based product description dataset named TaoDescribe, collecting from Taobao,(20) a large Chinese shopping website.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TaoDescribe"
      ],
      "dataset_descriptions": {
        "TaoDescribe": "Used to generate personalized product descriptions in e-commerce, focusing on integrating knowledge-based information from a large Chinese shopping website."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset named TaoDescribe, which is relevant to personalized text generation in e-commerce.",
      "processing_time": 57.71856164932251,
      "citing_paper_id": "229377215",
      "cited_paper_id": 88524997
    },
    {
      "context_text": "TaoDescribe [18] Personalized dataset A personalized product description dataset including product basic information, in which each pair is labeled with knowledge and user category attributes",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "personalized product description dataset"
      ],
      "dataset_descriptions": {
        "personalized product description dataset": "Used to generate personalized product descriptions in e-commerce, incorporating knowledge and user category attributes to enhance user experience and relevance."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions a 'personalized product description dataset' with specific attributes, which fits the criteria for a dataset. The title confirms the dataset's use in personalized product description generation.",
      "processing_time": 62.05837941169739,
      "citing_paper_id": "229377215",
      "cited_paper_id": 88524997
    },
    {
      "context_text": "[65] study the problem of generating paragraphs with multiple sentences given only a short title.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general problem statement about text generation.",
      "processing_time": 52.047487020492554,
      "citing_paper_id": "229377215",
      "cited_paper_id": 102354588
    },
    {
      "context_text": "[149] propose a personalized sentence-generation model based on GAN.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for personalized sentence generation using GANs.",
      "processing_time": 53.3300564289093,
      "citing_paper_id": "229377215",
      "cited_paper_id": 127953732
    },
    {
      "context_text": "[134] propose an entity linking module to decide the optimal entity in the input question for selecting knowledge triples from external KG, which will be encoded as common words by the LSTM.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for entity linking and knowledge triple selection.",
      "processing_time": 53.15517449378967,
      "citing_paper_id": "229377215",
      "cited_paper_id": 131777931
    },
    {
      "context_text": "[156] introduce the hierarchical interaction between the context and external document knowledge to capture the most important parts in the document and context using themulti-head attentionmodule in Transformer for selecting themost appropriate response.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for response selection in chatbots.",
      "processing_time": 52.96943426132202,
      "citing_paper_id": "229377215",
      "cited_paper_id": 184487709
    },
    {
      "context_text": "[97] propose the DialKG Walker model that learns the symbolic transitions of dialog contexts as structured traversals over KG, and the graph decoder that attends on viable KG paths to predict the most relevant entities in the KG, by associating these entities with the dialogue context and entities mentioned in the previous turn.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its methodology. The context focuses on the model's ability to traverse knowledge graphs and predict relevant entities.",
      "processing_time": 55.21885824203491,
      "citing_paper_id": "229377215",
      "cited_paper_id": 196176000
    },
    {
      "context_text": "[85] propose the Seq2SentiSeqmodel, which adopts the Gaussian Kernel layer to incorporate the numeric sentiment intensity value into the decoder, to finely control the sentiment intensity of generated text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (Seq2SentiSeq) and its components. The context focuses on the model's architecture and functionality rather than data sources.",
      "processing_time": 55.876582622528076,
      "citing_paper_id": "229377215",
      "cited_paper_id": 196192573
    },
    {
      "context_text": "Yang et al. [143] fuse external knowledge into topic-to-essay-generation systems to provide background information for essay generation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation mentions fusing external knowledge into topic-to-essay-generation systems but does not specify a dataset. The context does not provide enough detail to identify a specific, verifiable dataset.",
      "processing_time": 55.205050468444824,
      "citing_paper_id": "229377215",
      "cited_paper_id": 196197006
    },
    {
      "context_text": "[78] generate vector representations of external knowledge using the multihead attention mechanism and then incorporates them to encode knowledge utterances span in the multi-turn dialogue.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for incorporating external knowledge into dialogues.",
      "processing_time": 53.08334922790527,
      "citing_paper_id": "229377215",
      "cited_paper_id": 196210081
    },
    {
      "context_text": "However, existing knowledge-enhanced text-generation systems are mainly based on the structured knowledge graph or unstructured knowledge base built in advance [78, 98], which cannot perform real-time knowledge selection and fusion from crowdsourced data and usually cover several specific domains.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts about knowledge graphs and knowledge bases. No verifiable resources are identified.",
      "processing_time": 54.21661639213562,
      "citing_paper_id": "229377215",
      "cited_paper_id": 196210081
    },
    {
      "context_text": "[17] endow the poetry generator with the ability to express the specific sentiment (e.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general capability of a poetry generator. No verifiable resources are identified.",
      "processing_time": 54.09712767601013,
      "citing_paper_id": "229377215",
      "cited_paper_id": 199466228
    },
    {
      "context_text": "[137] optimize the unlikelihood training objective for training text-generation models more efficiently.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for training text-generation models.",
      "processing_time": 52.76003885269165,
      "citing_paper_id": "229377215",
      "cited_paper_id": 199551982
    },
    {
      "context_text": "[90] perform intermediate fine-tuning on the story data to adapt the pre-trained GPT-2 model to the domain of stories, and then fine-tune on the target story-generation dataset with a multi-task learning objective to generate grammatical and stylistic consistency stories.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'story data' and 'target story-generation dataset', which are domain-qualified data phrases. However, they lack specific identifiers and are not clearly named datasets.",
      "processing_time": 55.924402952194214,
      "citing_paper_id": "229377215",
      "cited_paper_id": 201666118
    },
    {
      "context_text": "[160] propose to interpret the contextual utterances and leverage the external commonsense knowledge to enhance the emotion detection performance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for enhancing emotion detection using external commonsense knowledge.",
      "processing_time": 53.58285117149353,
      "citing_paper_id": "229377215",
      "cited_paper_id": 202734183
    },
    {
      "context_text": "[75] develop the TATGM model, which adopts a sequential VAE to learn the structural features of text and a topic model to extract the semantic features of text to generate different expressions of the same structure in different topics.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (TATGM) and its components. The context focuses on the model's architecture and purpose rather than a particular dataset.",
      "processing_time": 55.98182487487793,
      "citing_paper_id": "229377215",
      "cited_paper_id": 202763690
    },
    {
      "context_text": "[15] propose the Variational Multi-modal Inferring tree (VarMI-tree) to model the lexical and syntactic diversities by inferring their latent variables in an approximate posterior inference guided by a visual semantic prior.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (VarMI-tree) and its application to diverse image captioning.",
      "processing_time": 54.62347149848938,
      "citing_paper_id": "229377215",
      "cited_paper_id": 202770245
    },
    {
      "context_text": "[19] propose a data-to-text-generation model, which extracts entities appear in the data field and links them toWikidata as external knowledge to form the temporary memory.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Wikidata"
      ],
      "dataset_descriptions": {
        "Wikidata": "Used as an external knowledge base to link extracted entities from data fields, enhancing the temporary memory in a data-to-text generation model."
      },
      "confidence_score": 0.8,
      "reasoning": "The context mentions 'Wikidata' as a source of external knowledge, which is a specific, verifiable resource. However, it does not mention a traditional dataset, but rather a knowledge base.",
      "processing_time": 63.64120316505432,
      "citing_paper_id": "229377215",
      "cited_paper_id": 202780757
    },
    {
      "context_text": "[14] embed and mix the user-level and sentence-level information into multimodal latent distributions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for embedding and mixing user-level and sentence-level information.",
      "processing_time": 54.286290645599365,
      "citing_paper_id": "229377215",
      "cited_paper_id": 202788651
    },
    {
      "context_text": "[49] extract entities from external KG and adopt TransE to get vectors of them.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (TransE) and a general reference to 'external KG'. No verifiable dataset names are provided.",
      "processing_time": 55.579633712768555,
      "citing_paper_id": "229377215",
      "cited_paper_id": 204735695
    },
    {
      "context_text": "The backbone of the Adapter-Bot is a pre-trained conversational model such as DialoGPT [154], providing the ability of response generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DialoGPT as a pre-trained conversational model but does not indicate it is a dataset. It is a model used for response generation.",
      "processing_time": 55.95572853088379,
      "citing_paper_id": "229377215",
      "cited_paper_id": 207869708
    },
    {
      "context_text": "The Plug and Play Language Model (PPLM) [29] allows anyone to flexibly plug in one or more simple attribute models representing the desired control objective into a large, unconditional LM.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (PPLM) for controlled text generation. The citation is about the method itself, not a dataset.",
      "processing_time": 55.959078788757324,
      "citing_paper_id": "229377215",
      "cited_paper_id": 208617790
    },
    {
      "context_text": "29 These data are the embodiment of human intelligence and can be used as the source of external knowledge of text-generation systems.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to 'data' in a general sense, which is not specific enough to be considered a dataset.",
      "processing_time": 56.24182939529419,
      "citing_paper_id": "229377215",
      "cited_paper_id": 208617790
    },
    {
      "context_text": "[62] propose to keep track of the prior and posterior distribution over knowledge using laten variables to improve the knowledge selection accuracy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for improving knowledge selection accuracy in dialogue systems.",
      "processing_time": 54.53953957557678,
      "citing_paper_id": "229377215",
      "cited_paper_id": 211146411
    },
    {
      "context_text": "[12] leverage topic models to enhance PPLMwith an unlabeled collection of documents.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions an 'unlabeled collection of documents' but does not provide a specific name or identifier for this collection. It is a generic reference and does not meet the criteria for inclusion.",
      "processing_time": 57.33817481994629,
      "citing_paper_id": "229377215",
      "cited_paper_id": 221293335
    },
    {
      "context_text": "[158] propose a pre-trained language model-based response-generation model with a knowledge selection module, which formalize knowledge selection as a sequence prediction process.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for knowledge-grounded dialogue generation using pre-trained language models.",
      "processing_time": 54.97561311721802,
      "citing_paper_id": "229377215",
      "cited_paper_id": 224705337
    },
    {
      "context_text": "[122] first propose the Sequence-to-Sequence (Seq2seq) learning model, which is a generalized framework for converting one sequence to another.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Seq2seq).",
      "processing_time": 54.016141414642334,
      "citing_paper_id": "229377215",
      "cited_paper_id": null
    },
    {
      "context_text": "With regard to mere recommendation, we compare with two traditional methods in addition to NETE and PETER: PMF (Salakhutdinov and Mnih, 2007) conducts probabilistic matrix factorization in latent space.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context is about comparing recommendation methods, including PMF, which is a method, not a dataset.",
      "processing_time": 56.68775510787964,
      "citing_paper_id": "248780017",
      "cited_paper_id": 467086
    },
    {
      "context_text": "Such systems aim to provide high-quality recommendations and simultaneously generate explanations for the recommendations (Zhang et al., 2014; Zhang and Chen, 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the concept of generating explanations for recommendations. No verifiable resources are identified.",
      "processing_time": 55.53408741950989,
      "citing_paper_id": "248780017",
      "cited_paper_id": 3331952
    },
    {
      "context_text": "Such systems aim to provide high-quality recommendations and simultaneously generate explanations for the recommendations (Zhang et al., 2014; Zhang and Chen, 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the concept of generating explanations for recommendations. No verifiable resources are identified.",
      "processing_time": 55.53408741950989,
      "citing_paper_id": "248780017",
      "cited_paper_id": 13752895
    },
    {
      "context_text": "Explanation sentences can either be generated by filling predefined templates (Zhang et al., 2014; Wang et al., 2018) or through flexible natural language approaches such as Attn2Seq (Dong et al., 2017), based on recurrent neural networks, and PETER (Li et al., 2021a), which is powered by a…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 54.85958480834961,
      "citing_paper_id": "248780017",
      "cited_paper_id": 3331952
    },
    {
      "context_text": "Multimodal Transformer make latent factor models interpretable by aligning each latent dimension with the explicit meaning (Zhang et al., 2014; Chen et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the interpretability of latent factor models using multimodal transformers.",
      "processing_time": 56.07064986228943,
      "citing_paper_id": "248780017",
      "cited_paper_id": 3331952
    },
    {
      "context_text": "To provide appropriate explanations, feature-based (Zhang et al., 2014), graph-based (Xian et al., 2019, 2020; Geng et al., 2022; Fu et al., 2020), sentence-based (Chen et al., 2019a; Li et al., 2020, 2021a, 2022), causality-based (Tan et al., 2021, 2022; Xu et al., 2021a,b) Inputs : User A, Item…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 55.78130555152893,
      "citing_paper_id": "248780017",
      "cited_paper_id": 3331952
    },
    {
      "context_text": "To provide appropriate explanations, feature-based (Zhang et al., 2014), graph-based (Xian et al., 2019, 2020; Geng et al., 2022; Fu et al., 2020), sentence-based (Chen et al., 2019a; Li et al., 2020, 2021a, 2022), causality-based (Tan et al., 2021, 2022; Xu et al., 2021a,b) Inputs : User A, Item…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 55.78130555152893,
      "citing_paper_id": "248780017",
      "cited_paper_id": 224280561
    },
    {
      "context_text": "Generate Explanations for Recommendation Explainable recommendation has been an important task in both research and industry (Zhang and Chen, 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general task in recommendation systems.",
      "processing_time": 54.11212992668152,
      "citing_paper_id": "248780017",
      "cited_paper_id": 13752895
    },
    {
      "context_text": "…l ∈ [0 , L − 1] , the encoded sequence S l +1 can be computed as follows (specifically S L denotes the final-layer output): Here, W Q , W K , W V ∈ R d × d h are weight matrices for projecting query, key, and value respectively (Vaswani et al., 2017), d h = d/h is the dimensionality for each head.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only weight matrices and dimensions related to the Transformer model. The cited paper 'Attention is All you Need' is a methodological paper introducing the Transformer architecture.",
      "processing_time": 56.987465381622314,
      "citing_paper_id": "248780017",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Trans-former (Vaswani et al., 2017) treats user and item IDs as words and trains on the explanation generation task with a vanilla Transformer structure through language modeling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Transformer) and a task (explanation generation).",
      "processing_time": 55.0313777923584,
      "citing_paper_id": "248780017",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Explanation sentences can either be generated by filling predefined templates (Zhang et al., 2014; Wang et al., 2018) or through flexible natural language approaches such as Attn2Seq (Dong et al., 2017), based on recurrent neural networks, and PETER (Li et al., 2021a), which is powered by a personalized Transformer.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions several methods/models but does not refer to any specific datasets. The focus is on explaining different approaches to generating text, particularly product reviews.",
      "processing_time": 55.513407945632935,
      "citing_paper_id": "248780017",
      "cited_paper_id": 17865105
    },
    {
      "context_text": "…can either be generated by filling predefined templates (Zhang et al., 2014; Wang et al., 2018) or through flexible natural language approaches such as Attn2Seq (Dong et al., 2017), based on recurrent neural networks, and PETER (Li et al., 2021a), which is powered by a personalized Transformer.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.075318574905396,
      "citing_paper_id": "248780017",
      "cited_paper_id": 17865105
    },
    {
      "context_text": "…can either be generated by filling predefined templates (Zhang et al., 2014; Wang et al., 2018) or through flexible natural language approaches such as Attn2Seq (Dong et al., 2017), based on recurrent neural networks, and PETER (Li et al., 2021a), which is powered by a personalized Transformer.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.075318574905396,
      "citing_paper_id": "248780017",
      "cited_paper_id": 229924402
    },
    {
      "context_text": "For the performance comparison, we consider several baselines with regard to the task of explanation generation: Attn2Seq (Dong et al., 2017) learns to encode attributes into vectors, and then invokes an attention mechanism to generate reviews conditioned on the attribute vector.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Attn2Seq) and its application to generate reviews from attributes.",
      "processing_time": 54.14252543449402,
      "citing_paper_id": "248780017",
      "cited_paper_id": 17865105
    },
    {
      "context_text": "To introduce visual signals into the Transformer structure, we follow the idea of VQ-VAEs (van den Oord et al., 2017) to encode an image I ∈ H × W × 3 into a sequence of discrete patch-level visual tokens z q ∈ R h × w × d , where H and W is the original size of the input image, h · w is the number…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (VQ-VAEs) for encoding images into discrete visual tokens. No verifiable datasets are referenced.",
      "processing_time": 54.81432747840881,
      "citing_paper_id": "248780017",
      "cited_paper_id": 20282961
    },
    {
      "context_text": "In recent years, numerous neural models have been proposed to explain recommendations based on user reviews (Chen et al., 2019c,a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only neural models for recommendation based on user reviews.",
      "processing_time": 52.70102643966675,
      "citing_paper_id": "248780017",
      "cited_paper_id": 197928119
    },
    {
      "context_text": "…explanations, feature-based (Zhang et al., 2014), graph-based (Xian et al., 2019, 2020; Geng et al., 2022; Fu et al., 2020), sentence-based (Chen et al., 2019a; Li et al., 2020, 2021a, 2022), causality-based (Tan et al., 2021, 2022; Xu et al., 2021a,b) Inputs : User A, Item 1, Feat. word:…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various types of explanations and input features. No clear, verifiable resource names are provided.",
      "processing_time": 54.39201760292053,
      "citing_paper_id": "248780017",
      "cited_paper_id": 197928119
    },
    {
      "context_text": "There have also been attempts to generate purely visual explanations (Chen et al., 2019b; Tangseng and Okatani, 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers that discuss generating visual explanations.",
      "processing_time": 52.79477834701538,
      "citing_paper_id": "248780017",
      "cited_paper_id": 197928119
    },
    {
      "context_text": "we adopt VQ-GAN (Esser et al., 2021) as the visual encoder and decoder in our framework.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions VQ-GAN but does not refer to it as a dataset. It is used as a method for visual encoding and decoding.",
      "processing_time": 54.0704665184021,
      "citing_paper_id": "248780017",
      "cited_paper_id": 229297973
    },
    {
      "context_text": "To ensure better representative ability of the visual encoder used in METER, the three components (i.e., encoder, decoder, and visual codebook) of VQ-GAN are first pre-trained on the collected images of the two datasets.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'two datasets' but does not provide specific names. The citation is about pre-training components of VQ-GAN on collected images, which suggests the use of datasets, but without specific identifiers.",
      "processing_time": 56.54099225997925,
      "citing_paper_id": "248780017",
      "cited_paper_id": 229297973
    },
    {
      "context_text": "To balance efficiency and perceptual quality, we adopt VQ-GAN (Esser et al., 2021) as the visual encoder and decoder in our framework.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions VQ-GAN but does not refer to it as a dataset. It is used as a method for visual encoding and decoding in the framework.",
      "processing_time": 54.286582231521606,
      "citing_paper_id": "248780017",
      "cited_paper_id": 229297973
    },
    {
      "context_text": "The maximum text length n of the explanation sequence is set to 15 , while the length of the visual token sequence m is set to 256 , and the standard image size for VQ-GAN is set to 256 × 256 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only technical parameters for a model. There are no verifiable resources or datasets mentioned.",
      "processing_time": 52.96935844421387,
      "citing_paper_id": "248780017",
      "cited_paper_id": 229297973
    },
    {
      "context_text": "PETER (Li et al., 2021a) is a simple and effective framework that attempts to use the IDs to predict the words in the target explanation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or framework called PETER. The context does not provide information about a dataset being used.",
      "processing_time": 53.77307367324829,
      "citing_paper_id": "248780017",
      "cited_paper_id": 229924402
    },
    {
      "context_text": "We adopt a similar masking strategy as Li et al. (2021a): the user & item IDs both can attend to all tokens in the sequence, while other non-ID tokens (including feature words, text tokens, and visual tokens) all retain the traditional causal attention masking in order to avoid any leakage of…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a masking strategy from a cited paper. No verifiable resources are identified.",
      "processing_time": 52.72331762313843,
      "citing_paper_id": "248780017",
      "cited_paper_id": 229924402
    },
    {
      "context_text": "…explanations, feature-based (Zhang et al., 2014), graph-based (Xian et al., 2019, 2020; Geng et al., 2022; Fu et al., 2020), sentence-based (Chen et al., 2019a; Li et al., 2020, 2021a, 2022), causality-based (Tan et al., 2021, 2022; Xu et al., 2021a,b) Inputs : User A, Item 1, Feat. word: floors",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 53.38234734535217,
      "citing_paper_id": "248780017",
      "cited_paper_id": 229924402
    },
    {
      "context_text": "…explanations, feature-based (Zhang et al., 2014), graph-based (Xian et al., 2019, 2020; Geng et al., 2022; Fu et al., 2020), sentence-based (Chen et al., 2019a; Li et al., 2020, 2021a, 2022), causality-based (Tan et al., 2021, 2022; Xu et al., 2021a,b) Inputs : User A, Item 1, Feat. word: floors",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 53.38234734535217,
      "citing_paper_id": "248780017",
      "cited_paper_id": 237278204
    },
    {
      "context_text": "…explanations, feature-based (Zhang et al., 2014), graph-based (Xian et al., 2019, 2020; Geng et al., 2022; Fu et al., 2020), sentence-based (Chen et al., 2019a; Li et al., 2020, 2021a, 2022), causality-based (Tan et al., 2021, 2022; Xu et al., 2021a,b) Inputs : User A, Item 1, Feat. word: floors",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 53.38234734535217,
      "citing_paper_id": "248780017",
      "cited_paper_id": 246863587
    },
    {
      "context_text": "…explanations, feature-based (Zhang et al., 2014), graph-based (Xian et al., 2019, 2020; Geng et al., 2022; Fu et al., 2020), sentence-based (Chen et al., 2019a; Li et al., 2020, 2021a, 2022), causality-based (Tan et al., 2021, 2022; Xu et al., 2021a,b) Inputs : User A, Item 1, Feat. word: floors",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only various methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 53.38234734535217,
      "citing_paper_id": "248780017",
      "cited_paper_id": 246904359
    },
    {
      "context_text": "Among them, PETER (Li et al., 2021a) is a representative sentence-based method that directly generates explanation sentences for given user–item pairs based on Personalized Transformer.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions PETER, which is a method, not a dataset. No other datasets are mentioned in the context.",
      "processing_time": 52.565701961517334,
      "citing_paper_id": "248780017",
      "cited_paper_id": 229924402
    },
    {
      "context_text": "This is in line with the spirit of the context token prediction module in Li et al. (2021a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to a method or model in another paper.",
      "processing_time": 51.951953411102295,
      "citing_paper_id": "248780017",
      "cited_paper_id": 229924402
    },
    {
      "context_text": "Recently, DALL-E (Ramesh et al., 2021) merges text and visual tokens as a single stream of data and employs a universal Transformer to autoregressively model the multimodal stream.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (DALL-E) and its capabilities. No verifiable resources are identified.",
      "processing_time": 52.86757183074951,
      "citing_paper_id": "248780017",
      "cited_paper_id": 232035663
    },
    {
      "context_text": "VidLanKD (Tang et al., 2021) further solves the shortcomings of Tan and Bansal (2020) by first learning a multimodal teacher model",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or model called VidLanKD. The citation is focused on describing the method and its improvements over previous work.",
      "processing_time": 53.887354612350464,
      "citing_paper_id": "248780017",
      "cited_paper_id": 235743020
    },
    {
      "context_text": "[28] propose to diversify the outputs by optimizing diversity-augmented objective in beam search.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for diversifying outputs in neural sequence models.",
      "processing_time": 51.403944969177246,
      "citing_paper_id": "215754550",
      "cited_paper_id": 44614
    },
    {
      "context_text": "Earlier attempts using the knowledge graph mainly focus on answering questions with a single clue retrieved from the knowledge graph [1, 2, 9, 10].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to knowledge graphs. There are no clear, verifiable resource names that meet the criteria.",
      "processing_time": 53.32691264152527,
      "citing_paper_id": "215754550",
      "cited_paper_id": 1849689
    },
    {
      "context_text": "Earlier attempts using the knowledge graph mainly focus on answering questions with a single clue retrieved from the knowledge graph [1, 2, 9, 10].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to knowledge graphs. There are no clear, verifiable resource names that meet the criteria.",
      "processing_time": 53.32691264152527,
      "citing_paper_id": "215754550",
      "cited_paper_id": 12938495
    },
    {
      "context_text": "In the second RL stage, we use the policy gradient (Williams, 1992) to train the score predictor.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (policy gradient) rather than a dataset. No specific dataset is referenced in the context.",
      "processing_time": 51.72555899620056,
      "citing_paper_id": "215754550",
      "cited_paper_id": 2332513
    },
    {
      "context_text": "We use Adam optimizer (Kingma and Ba, 2015) to train the models.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the Adam optimizer, which is a method, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 52.21204662322998,
      "citing_paper_id": "215754550",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "With the idea of reducing the frequency of highfrequency text and increasing the frequency of low-frequency text, various methods [16, 19, 22, 35] have been used to increase the diversity of text generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for increasing text generation diversity.",
      "processing_time": 51.219377756118774,
      "citing_paper_id": "215754550",
      "cited_paper_id": 7287895
    },
    {
      "context_text": "[34] incorporate topic information into the Seq2Seq framework to generate informative and interesting responses for chatbots.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for incorporating topic information into a Seq2Seq framework.",
      "processing_time": 52.20634746551514,
      "citing_paper_id": "215754550",
      "cited_paper_id": 9514751
    },
    {
      "context_text": "on answering questions with a single clue retrieved from the knowledge graph (Hao et al., 2017; Bordes et al., 2014a,b; Dong et al., 2015).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for question answering using a knowledge graph.",
      "processing_time": 51.71723008155823,
      "citing_paper_id": "215754550",
      "cited_paper_id": 12926055
    },
    {
      "context_text": "Transformer (Vaswani et al., 2017): both the encoder and decoder use three-layer multi-head self-attention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the Transformer model architecture. No dataset names are present in the citation span.",
      "processing_time": 52.5479850769043,
      "citing_paper_id": "215754550",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "The generation module is designed to generate advertisement text based on the keyword sub-graph, which is developed on the basis of Transformer (Vaswani et al., 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (Transformer). No verifiable resources are identified.",
      "processing_time": 51.880897998809814,
      "citing_paper_id": "215754550",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Xing et al. (2017) incorporate topic information into the seq2seq framework to generate informative and interesting responses for chatbots.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for incorporating topic information into a seq2seq framework.",
      "processing_time": 51.384538412094116,
      "citing_paper_id": "215754550",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "[30] apply a multi-task learning approach for improving product title compression with user search log data.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "user search log data"
      ],
      "dataset_descriptions": {
        "user search log data": "Used to improve product title compression through multi-task learning, focusing on enhancing the relevance and brevity of product titles."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'user search log data' which is a domain-qualified data phrase. However, it does not specify a named dataset.",
      "processing_time": 61.0751268863678,
      "citing_paper_id": "215754550",
      "cited_paper_id": 19208846
    },
    {
      "context_text": "Ni and McAuley (2018) aims at generating personalized reviews by expanding short phrases with aspect-level information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions personalized review generation but does not specify any dataset names. The context is about the methodology and goals of the research rather than the data used.",
      "processing_time": 53.528812408447266,
      "citing_paper_id": "215754550",
      "cited_paper_id": 29161455
    },
    {
      "context_text": "ExpansionNet (Ni and McAuley, 2018): Another seq2seq based method aiming at personalized text generation, which calculates two attention scores between decoder hidden state and the word embedding of words in user query.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (ExpansionNet) for personalized text generation.",
      "processing_time": 51.86906909942627,
      "citing_paper_id": "215754550",
      "cited_paper_id": 29161455
    },
    {
      "context_text": "[29] propose a statistical framework that generates product descriptions from product attributes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating product descriptions.",
      "processing_time": 51.17806625366211,
      "citing_paper_id": "215754550",
      "cited_paper_id": 36574384
    },
    {
      "context_text": "[37] use large-scale commonsense knowledge in conversation generation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a general reference to 'large-scale commonsense knowledge'. No clear, verifiable dataset is identified.",
      "processing_time": 53.54015111923218,
      "citing_paper_id": "215754550",
      "cited_paper_id": 51608183
    },
    {
      "context_text": "[12, 31] use user clicks feedback information to guide the generation of advertisement text.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'user clicks feedback information' which is used to guide the generation of advertisement text. However, there is no specific dataset name mentioned.",
      "processing_time": 53.53263211250305,
      "citing_paper_id": "215754550",
      "cited_paper_id": 86611657
    },
    {
      "context_text": "This encoder applies GCN to aggregate the neighboring information and uses the gate mechanism in LSTM [11] to decide which part of the aggregated information should be transmitted into the next layer in the update of both node and global representation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models.",
      "processing_time": 49.93930411338806,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "where H l is the hidden states of the l-th layer in the graph, ad j is the normalized adjacency matrix following the setting of GCN [14], g is the global representation of the graph learned with attentive pooling in [18].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to methods and models.",
      "processing_time": 50.78868341445923,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "To make use of the graph structure that links the input words, we propose to add a GatedGCN layer used in the association module before the Transformer encoder.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (GatedGCN layer) and a model (Transformer encoder).",
      "processing_time": 52.57915782928467,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "Both the GatedGCN and the Transformer encoder have two layers, while the decoder has three layers.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only model architectures. There are no verifiable resources or datasets mentioned.",
      "processing_time": 51.98703217506409,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "GCN can combine semantic information and topological structure information to encode features.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only describes a capability of GCN.",
      "processing_time": 52.23440909385681,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "However, the PMI score only concerns the global historical co-occurrence knowledge, while our method not only makes use of the PMI score via the edge weight in the GCN component in the association module but also considers the semantic information of the keywords encoded in the graph representations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (PMI score) and a model component (GCN). There are no clear identifiers for datasets.",
      "processing_time": 54.28290033340454,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "As for the graph structure in the generation module, after replacing the GatedGCN with the normal Transformer encode layer(Graph Structure) in the generation module, the BLEU score drop by 1.35.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a change in model architecture and its impact on performance.",
      "processing_time": 52.09777283668518,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "Graph Encoder: We propose a Gated Graph convolutional neural networks (GatedGCN) with gated attentive pooling as the graph encoder, which is calculated as follows:\n?",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (GatedGCN) and its components. There are no verifiable resources or datasets mentioned.",
      "processing_time": 54.05493450164795,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "The gate mechanism of LSTM can select out important information between the two layers of GCN.\nScore Predictor: After we get the global graph representations, we score the candidates with the score predictor:\n𝑠𝑐𝑜𝑟𝑒 = 𝑤 ( [𝑔𝐿 ; 𝑣𝑐 ]) (5)\nwhere 𝑔𝐿 is the global representation of the last layer, 𝑣𝑐 is the embedding of the candidate word𝑤𝑐 , [; ] means concatenation, and 𝑤 ∈ 𝑅ℎ is a learnable parameter matrix.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only discusses the methodology of using LSTM and GCN for scoring candidates.",
      "processing_time": 52.398881673812866,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "For a fair comparison, the generation module of our model is obtained by replacing the first layer in the Transformer encoder with the mentioned GatedGCN, which has parameters of the same scale as Transformer.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a modification to a model architecture. There are no verifiable resources or datasets mentioned.",
      "processing_time": 52.94254446029663,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "𝑙 , 𝐻 𝑙−1) (2)\n𝑔𝑙 = 𝐴𝑡𝑡𝑛𝑃𝑜𝑜𝑙𝑖𝑛𝑔(𝐻 𝑙 ) (3)\n𝑔𝑙 = 𝐿𝑆𝑇𝑀 (𝑔𝑙−1, 𝑔𝑙 ) (4)\nwhere 𝐻 𝑙 is the hidden states of the 𝑙-th layer in the graph, 𝑎𝑑 𝑗 is the normalized adjacency matrix following the setting of GCN [14], 𝑔 is the global representation of the graph learned with attentive pooling in [18].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only mathematical operations and model components. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 53.326446771621704,
      "citing_paper_id": "215754550",
      "cited_paper_id": null
    },
    {
      "context_text": "We frame QG as a neural sequence-to-sequence task similar to [8] where an encoder reads input text and decoder produces question by predicting one word at a time.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to question generation.",
      "processing_time": 51.367748975753784,
      "citing_paper_id": "249538264",
      "cited_paper_id": 2172129
    },
    {
      "context_text": "Question Generation Previous research has focused on training neural Seq2Seq models [8, 41, 15] on supervised full QA datasets such as SQuAD [29].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SQuAD"
      ],
      "dataset_descriptions": {
        "SQuAD": "Used to train and evaluate neural Seq2Seq models for question generation, focusing on reading comprehension tasks and the ability to generate questions from given passages."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'SQuAD' as a supervised full QA dataset used for training neural Seq2Seq models. SQuAD is a well-known dataset in the field of question answering.",
      "processing_time": 62.81733775138855,
      "citing_paper_id": "249538264",
      "cited_paper_id": 2172129
    },
    {
      "context_text": "Question Generation Previous research has focused on training neural Seq2Seq models [8, 41, 15] on supervised full QA datasets such as SQuAD [29].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "SQuAD"
      ],
      "dataset_descriptions": {
        "SQuAD": "Used to train and evaluate neural Seq2Seq models for question generation, focusing on reading comprehension tasks and the ability to generate questions from given passages."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'SQuAD' as a supervised full QA dataset used for training neural Seq2Seq models. SQuAD is a well-known dataset in the field of question answering.",
      "processing_time": 62.81733775138855,
      "citing_paper_id": "249538264",
      "cited_paper_id": 207880647
    },
    {
      "context_text": "Additionally a common set of 20 examples are annotated by all annotators and we record an inter-annotator agreement of 0.75 which shows substantial agreement according to Landis and Koch [19].",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for measuring inter-annotator agreement.",
      "processing_time": 51.8331093788147,
      "citing_paper_id": "249538264",
      "cited_paper_id": 11077516
    },
    {
      "context_text": "75 which shows substantial agreement according to Landis and Koch [19].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, model, or method. It only references a measure of agreement.",
      "processing_time": 51.56052112579346,
      "citing_paper_id": "249538264",
      "cited_paper_id": 11077516
    },
    {
      "context_text": "Question Generation\nWe evaluate the generation quality of three models - T5-QG, BART-QG, BART-ML-QG using standard language generation metrics: BLEU1-4 [27] and ROUGE-L [32] on the test set of 40 examples.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions evaluation metrics (BLEU1-4 and ROUGE-L) but does not specify any datasets. The context focuses on evaluating model performance rather than using a specific dataset.",
      "processing_time": 54.96359324455261,
      "citing_paper_id": "249538264",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "We evaluate the generation quality of three models - T5-QG, BART-QG, BART-ML-QG using standard language generation metrics: BLEU1-4 [27] and ROUGE-L [32] on the test set of 40 examples.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions standard language generation metrics but does not specify any datasets. The context focuses on evaluating model performance using metrics rather than datasets.",
      "processing_time": 52.94005346298218,
      "citing_paper_id": "249538264",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "• Well-formedness: We train a BERT binary classifier to predict whether a question is well-formed or ill-formed on Google Well-formedness dataset [9].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Google Well-formedness dataset"
      ],
      "dataset_descriptions": {
        "Google Well-formedness dataset": "Used to train a BERT binary classifier for predicting question well-formedness, focusing on the syntactic and semantic structure of questions."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'Google Well-formedness dataset' which is a specific, verifiable dataset used for training a BERT binary classifier to predict question well-formedness.",
      "processing_time": 62.33432340621948,
      "citing_paper_id": "249538264",
      "cited_paper_id": 52111971
    },
    {
      "context_text": "Existing work mainly focuses on non-personalized hints created using template-based methods [2, 22].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to non-personalized hints created using template-based methods.",
      "processing_time": 52.482346296310425,
      "citing_paper_id": "249538264",
      "cited_paper_id": 58772416
    },
    {
      "context_text": "In this paper, we propose a novel automated personalized feedback system based on deep-learning based Transformer models [40, 20] to address the above-mentioned problems.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 52.90107083320618,
      "citing_paper_id": "249538264",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "In this paper, we propose a novel automated personalized feedback system based on deep-learning based Transformer models [40, 20] to address the above-mentioned problems.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 52.90107083320618,
      "citing_paper_id": "249538264",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "BERTScore uses pre-trained BERT [6] contextualised embeddings and computes overall similarity using weighted mean of cosine similarity between their tokens.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the method BERTScore which uses BERT embeddings. BERT itself is a model, not a dataset.",
      "processing_time": 53.71833157539368,
      "citing_paper_id": "249538264",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "Then it matches the components with gold answers using similarity-based Transformers [40], and classifies them into various error categories (such as missing explanation, incorrect main answer, and so on).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Transformers) and a tool (BERTScore).",
      "processing_time": 52.264147996902466,
      "citing_paper_id": "249538264",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "Algorithm 1 Personalized Feedback Generation in Korbit ITS Require: Exercise problem Q, reference answers R ≡ {sir}mi=1, incorrect student answer ss, Cause-Effect\nExtractor θCE , BERTScore model θBS, BERTScore similarity threshold τBS, Question Generator θQG.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. BERTScore is referenced but it is a method, not a dataset.",
      "processing_time": 53.385887145996094,
      "citing_paper_id": "249538264",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "First we find the reference solution sr closest to student solution ss using BERTScore similarity.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERTScore but does not refer to it as a dataset. It is used as a method for evaluating text generation.",
      "processing_time": 52.94820594787598,
      "citing_paper_id": "249538264",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "We experiment with two pre-trained Transformers: BART [20] and T5 [28].",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions pre-trained models BART and T5, which are not datasets but models. No specific datasets are mentioned.",
      "processing_time": 52.682475328445435,
      "citing_paper_id": "249538264",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "We experiment with two pre-trained Transformers: BART [20] and T5 [28].",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions pre-trained models BART and T5, which are not datasets but models. No specific datasets are mentioned.",
      "processing_time": 52.682475328445435,
      "citing_paper_id": "249538264",
      "cited_paper_id": 204960716
    },
    {
      "context_text": "BERTScore has been used as an evaluation metric for image captioning [40], summarization ([21]), machine translation ([37]) etc.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERTScore as an evaluation metric but does not refer to any specific dataset. BERTScore is a method/metric, not a dataset.",
      "processing_time": 54.29484724998474,
      "citing_paper_id": "249538264",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "BERTScore has been used as an evaluation metric for image captioning [40], summarization ([21]), machine translation ([37]) etc.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERTScore as an evaluation metric but does not refer to any specific dataset. BERTScore is a method/metric, not a dataset.",
      "processing_time": 54.29484724998474,
      "citing_paper_id": "249538264",
      "cited_paper_id": 235352574
    },
    {
      "context_text": "BERTScore has been used as an evaluation metric for image captioning [40], summarization ([21]), machine translation ([37]) etc. BERTScore returns a score (0− 1) between student and reference cause/effect.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of BERTScore as an evaluation metric. BERTScore itself is a method, not a dataset.",
      "processing_time": 54.058269739151,
      "citing_paper_id": "249538264",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "To detect the error type, we match student cause-effect text with reference solution using BERTScore [40].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions BERTScore but does not refer to it as a dataset. It is used as a method for evaluating text generation.",
      "processing_time": 53.145987033843994,
      "citing_paper_id": "249538264",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "structures to derive sentence embeddings from BERT and have been shown to perform extremely well in common STS tasks and transfer learning tasks [30].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the performance of Sentence-BERT in STS tasks and transfer learning tasks.",
      "processing_time": 52.928993940353394,
      "citing_paper_id": "249538264",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "• Sentence Embeddings: We use Sentence-BERT [30] to extract 768 dimensional embeddings from question.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions using Sentence-BERT to extract embeddings but does not refer to any specific dataset. Sentence-BERT is a method, not a dataset.",
      "processing_time": 53.68942070007324,
      "citing_paper_id": "249538264",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "The input features to the regression model are -\n• Sentence Embeddings: We use Sentence-BERT [30] to extract 768 dimensional embeddings from question.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions Sentence-BERT for extracting sentence embeddings but does not refer to a specific dataset. Sentence-BERT is a method/model, not a dataset.",
      "processing_time": 54.05394220352173,
      "citing_paper_id": "249538264",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "The Sentence-BERT uses siamese and triplet network\nstructures to derive sentence embeddings from BERT and have been shown to perform extremely well in common STS tasks and transfer learning tasks [30].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the performance of Sentence-BERT in STS tasks and transfer learning tasks.",
      "processing_time": 55.35181140899658,
      "citing_paper_id": "249538264",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "• Fluency: We finetune a GPT-2 LM [3] on the 300 original hand-written questions (Section 3.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions '300 original hand-written questions' but does not specify a dataset name. This appears to be a custom dataset created for the study, which is excluded based on the rules.",
      "processing_time": 56.50007200241089,
      "citing_paper_id": "249538264",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "QG in a few-shot setting under limited data has also been explored recently for multi-hop QG [39, 12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The citation does not mention any specific datasets, only a research direction. The context is too vague to identify a specific, verifiable dataset.",
      "processing_time": 53.54080653190613,
      "citing_paper_id": "249538264",
      "cited_paper_id": 220045416
    },
    {
      "context_text": "ITS are a low-cost alternative to conventional classroom teaching, and shown to be more effective for tutoring students [34, 35].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to studies comparing learning outcomes. No verifiable resources are identified.",
      "processing_time": 52.80733609199524,
      "citing_paper_id": "249538264",
      "cited_paper_id": 233289583
    },
    {
      "context_text": "A recent work by Srivastava and Goodman [33] generates personalized questions according to the student’s level by proposing a difficulty-controllable QG model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating personalized questions.",
      "processing_time": 51.3055682182312,
      "citing_paper_id": "249538264",
      "cited_paper_id": 235368201
    },
    {
      "context_text": "To select the best hint from the ones available, the ITS uses a personalized ML model by looking at student performance and responses on the exercise [16].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a personalized ML model. No clear, verifiable dataset names are present.",
      "processing_time": 53.02553987503052,
      "citing_paper_id": "249538264",
      "cited_paper_id": 237684656
    },
    {
      "context_text": "(3) and (4) to construct the chit-chat posts to rank, and use three commonly-used ranking metrics AUC , MRR , and NDCG @5 [11, 30].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only ranking metrics which are excluded according to the instructions.",
      "processing_time": 51.6907684803009,
      "citing_paper_id": "251518223",
      "cited_paper_id": 1981391
    },
    {
      "context_text": "[18], we compute a hard attention β j ∈ {0, 1} with GumbelSoftmax [10], which eliminates noise and simplifies the information we give the generator to control text generation better:",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (GumbelSoftmax) used for controlling text generation. No verifiable datasets are referenced.",
      "processing_time": 54.18018293380737,
      "citing_paper_id": "251518223",
      "cited_paper_id": 2428314
    },
    {
      "context_text": "These methods not only increase the probability that a user adopts a recommended item, but can also help users make a better decision, which significantly increases user trust and satisfaction [3, 40].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and their effects on user adoption and trust.",
      "processing_time": 51.899718046188354,
      "citing_paper_id": "251518223",
      "cited_paper_id": 3331952
    },
    {
      "context_text": "Pioneering works in this line often output text by filling predefined templates [8, 14, 40] or retrieving from the existing text (e.g., user reviews) [31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. No verifiable resources are identified.",
      "processing_time": 52.35267210006714,
      "citing_paper_id": "251518223",
      "cited_paper_id": 3331952
    },
    {
      "context_text": "Pioneering works in this line often output text by filling predefined templates [8, 14, 40] or retrieving from the existing text (e.g., user reviews) [31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. No verifiable resources are identified.",
      "processing_time": 52.35267210006714,
      "citing_paper_id": "251518223",
      "cited_paper_id": 53629366
    },
    {
      "context_text": "Pioneering works in this line often output text by filling predefined templates [8, 14, 40] or retrieving from the existing text (e.g., user reviews) [31].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. No verifiable resources are identified.",
      "processing_time": 52.35267210006714,
      "citing_paper_id": "251518223",
      "cited_paper_id": 69392767
    },
    {
      "context_text": "…or generate informative or attractive text to improve recommendation experience, such as review-based textual explanations about why specific items are recommended [3, 4, 16, 31, 40], personalized item summarization [33], and conversations for efficiently collecting user feedback [2, 5, 27, 42].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and applications related to personalized text generation in recommendation systems.",
      "processing_time": 52.55728888511658,
      "citing_paper_id": "251518223",
      "cited_paper_id": 3331952
    },
    {
      "context_text": "…or generate informative or attractive text to improve recommendation experience, such as review-based textual explanations about why specific items are recommended [3, 4, 16, 31, 40], personalized item summarization [33], and conversations for efficiently collecting user feedback [2, 5, 27, 42].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and applications related to personalized text generation in recommendation systems.",
      "processing_time": 52.55728888511658,
      "citing_paper_id": "251518223",
      "cited_paper_id": 47012216
    },
    {
      "context_text": "…or generate informative or attractive text to improve recommendation experience, such as review-based textual explanations about why specific items are recommended [3, 4, 16, 31, 40], personalized item summarization [33], and conversations for efficiently collecting user feedback [2, 5, 27, 42].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and applications related to personalized text generation in recommendation systems.",
      "processing_time": 52.55728888511658,
      "citing_paper_id": "251518223",
      "cited_paper_id": 53629366
    },
    {
      "context_text": "…or generate informative or attractive text to improve recommendation experience, such as review-based textual explanations about why specific items are recommended [3, 4, 16, 31, 40], personalized item summarization [33], and conversations for efficiently collecting user feedback [2, 5, 27, 42].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general concepts and applications related to personalized text generation in recommendation systems.",
      "processing_time": 52.55728888511658,
      "citing_paper_id": "251518223",
      "cited_paper_id": 234789923
    },
    {
      "context_text": "The first category makes the chatbot more human-like by assigning them a consistent personality of different forms, such as key-value attributes [22], detailed description sentences [38] and chatting habits [21, 25].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'key-value attributes', 'detailed description sentences', and 'chatting habits' as methods to make chatbots more human-like. However, no specific dataset names are mentioned.",
      "processing_time": 55.85191059112549,
      "citing_paper_id": "251518223",
      "cited_paper_id": 6869582
    },
    {
      "context_text": "The first category makes the chatbot more human-like by assigning them a consistent personality of different forms, such as key-value attributes [22], detailed description sentences [38] and chatting habits [21, 25].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'key-value attributes', 'detailed description sentences', and 'chatting habits' as methods to make chatbots more human-like. However, no specific dataset names are mentioned.",
      "processing_time": 55.85191059112549,
      "citing_paper_id": "251518223",
      "cited_paper_id": 221969995
    },
    {
      "context_text": "First, generating human-like chit-chat has been shown effective in engaging users in human-computer interaction [38].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to human-computer interaction.",
      "processing_time": 50.901111364364624,
      "citing_paper_id": "251518223",
      "cited_paper_id": 6869582
    },
    {
      "context_text": "Many methods have been proposed to generate personalized text to facilitate recommendation, such as textual explanation generation for recommendation [3, 4, 16, 39], E-commerce review summarization [36], product description generation [33], and news headline generation [1].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only references methods and applications of personalized text generation.",
      "processing_time": 52.775233030319214,
      "citing_paper_id": "251518223",
      "cited_paper_id": 13752895
    },
    {
      "context_text": ", generating various responses that are tailored to the profile of the end-users [12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to personalization in goal-oriented dialog.",
      "processing_time": 52.06995368003845,
      "citing_paper_id": "251518223",
      "cited_paper_id": 29473470
    },
    {
      "context_text": "The second category focuses on modeling the preference of users [12, 24, 37], i.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a category of research focus. No verifiable resources are identified.",
      "processing_time": 52.543365478515625,
      "citing_paper_id": "251518223",
      "cited_paper_id": 29473470
    },
    {
      "context_text": "Some works model the dialog strategy of which attribute to ask and what item to recommendation [5, 27].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts about dialog strategies and recommendations. No verifiable resources are identified.",
      "processing_time": 52.68136382102966,
      "citing_paper_id": "251518223",
      "cited_paper_id": 47012216
    },
    {
      "context_text": "Some works model the dialog strategy of which attribute to ask and what item to recommendation [5, 27].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts about dialog strategies and recommendations. No verifiable resources are identified.",
      "processing_time": 52.68136382102966,
      "citing_paper_id": "251518223",
      "cited_paper_id": 234789923
    },
    {
      "context_text": "In particular, we train the matching model fine-tuned on BERT [6].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT but does not indicate it is a dataset. BERT is a model, not a dataset, and thus should not be included.",
      "processing_time": 53.65925145149231,
      "citing_paper_id": "251518223",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "In this paper, we set f as NAML [35], which is a widely-used news recommendation model that well balances efficiency and accuracy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions NAML as a model, not a dataset. There are no other specific, verifiable datasets mentioned in the context.",
      "processing_time": 53.18481516838074,
      "citing_paper_id": "251518223",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "Then, for the backbone models, We choose NAML and NRMS [34, 35], which are two methods commonly used in news recommendation tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions methods (NAML and NRMS) but does not refer to any specific datasets. The context is about choosing models for news recommendation tasks.",
      "processing_time": 54.48821568489075,
      "citing_paper_id": "251518223",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "The Crowding-Sourcing method brings the gain of 2.8 and 2.1 of AUC on NAML and NRMS, respectively.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions NAML and NRMS, which are likely models or methods rather than datasets. There is no clear indication of a specific, verifiable dataset being used.",
      "processing_time": 54.84827136993408,
      "citing_paper_id": "251518223",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "The unsupervised model Rec is not able to distinguish the user interest in the chit-chat post thoroughly, as it lacks the knowledge of the mapping of news and chit-chat posts, while the weakly supervised methods Single Worker and Crowd-Sourcing can alleviate this issue and give rise to the AUC score on NAML and NRMS.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the performance of different models on news recommendation tasks.",
      "processing_time": 53.40796113014221,
      "citing_paper_id": "251518223",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "In the following section, we use Per to denote NAML-Crowd-Sourcing.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. 'Per' and 'NAML-Crowd-Sourcing' are likely methods or models, not datasets.",
      "processing_time": 54.84118938446045,
      "citing_paper_id": "251518223",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "Most news recommendation models encode only the news headlines [34, 35], since users decide whether to click a news article based only on the headline, i.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general practice in news recommendation models. No verifiable resources are identified.",
      "processing_time": 52.80851173400879,
      "citing_paper_id": "251518223",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "In this paper, we set 𝑓 as NAML [35], which is a widely-used news recommendation model that well balances efficiency and accuracy.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions NAML as a model, not a dataset. There are no other specific, verifiable datasets mentioned in the context.",
      "processing_time": 53.173537254333496,
      "citing_paper_id": "251518223",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "[42] leverage knowledge graphs or reviews as external knowledge.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of knowledge graphs or reviews as external knowledge. No clear, verifiable dataset names are provided.",
      "processing_time": 54.64763164520264,
      "citing_paper_id": "251518223",
      "cited_paper_id": 220404390
    },
    {
      "context_text": "To achieve this goal, many pioneering works have been proposed to give explanations by the knowledge graph [20, 41] or generate informative or attractive text to improve recommendation experience, such as reviewbased textual explanations about why specific items are recommended [3, 4, 16, 31, 40], personalized item summarization [33], and conversations for efficiently collecting user feedback [2, 5, 27, 42].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It discusses various methods and approaches but does not reference any named datasets.",
      "processing_time": 53.16744375228882,
      "citing_paper_id": "251518223",
      "cited_paper_id": 220404390
    },
    {
      "context_text": "Based on the dataset, some methods have been proposed, and most of them adopt different variants of Memory Network [24, 37] for modeling user preference.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not provide a specific dataset name, only a reference to 'the dataset' without further details. The citation is more focused on methods and models rather than a specific dataset.",
      "processing_time": 55.41053295135498,
      "citing_paper_id": "251518223",
      "cited_paper_id": 224770745
    },
    {
      "context_text": "The second category focuses on modeling the preference of users [12, 24, 37], i.e., generating various responses that are tailored to the profile of the end-users [12].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to user preferences and personalized responses. No clear, verifiable dataset names are present.",
      "processing_time": 54.14895939826965,
      "citing_paper_id": "251518223",
      "cited_paper_id": 224770745
    },
    {
      "context_text": "We optimize the generation module following UMPG and optimize the retrieve module using Eqs.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only modules and equations. There are no verifiable resources or datasets mentioned.",
      "processing_time": 52.657947301864624,
      "citing_paper_id": "251518223",
      "cited_paper_id": 236980280
    },
    {
      "context_text": "It is optimized using the reinforcement learning method UMPG to maximize the reward R (Eq.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reinforcement learning method. The context is too limited to infer the use of any datasets.",
      "processing_time": 53.299158334732056,
      "citing_paper_id": "251518223",
      "cited_paper_id": 236980280
    },
    {
      "context_text": "We use the pre-trained model UniLM [7] as the backbone for g (k) , and utilize the reinforcement learning method UMPG [32] to efficiently and effectively optimize g (k) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on using pre-trained models and reinforcement learning methods.",
      "processing_time": 53.304229974746704,
      "citing_paper_id": "251518223",
      "cited_paper_id": 236980280
    },
    {
      "context_text": "We use the pre-trained model UniLM [7] as the backbone for 𝑔 ( 𝑘 ) , and utilize the reinforcement learning method UMPG [32] to efficiently and effectively optimize 𝑔 ( 𝑘 ) .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited paper title does not introduce any new dataset names.",
      "processing_time": 53.05492544174194,
      "citing_paper_id": "251518223",
      "cited_paper_id": 236980280
    },
    {
      "context_text": "We use UMPG here because it can be integrated seamlessly with pre-trained language models, and largely increase the training efficiency.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a method or model (UMPG) that is used to enhance pre-trained language models. There are no clear identifiers for datasets.",
      "processing_time": 55.0391161441803,
      "citing_paper_id": "251518223",
      "cited_paper_id": 236980280
    },
    {
      "context_text": "[32] to computeRchat based onwhether a generated token matches the corresponding token in a pseudo-groundtruth chit-chat post.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating generated text. No verifiable resources are identified.",
      "processing_time": 52.4626190662384,
      "citing_paper_id": "251518223",
      "cited_paper_id": 236980280
    },
    {
      "context_text": "Then, we use the non-personalized chit-chat generation model as the base model to train the personalized UniLM model with the reinforcement learning method UMPG [32] to maximize the reward R (Eq.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (UMPG) and a general reference to a non-personalized chit-chat generation model. No verifiable datasets are identified.",
      "processing_time": 55.77293658256531,
      "citing_paper_id": "251518223",
      "cited_paper_id": 236980280
    },
    {
      "context_text": "It not only increases the probability that a user reads the news, but also provides a novel way for expanding users’ reading interest and handling information cocoons [13].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general discussion about algorithmic news recommendation and information cocoons.",
      "processing_time": 52.243515491485596,
      "citing_paper_id": "251518223",
      "cited_paper_id": 247592257
    },
    {
      "context_text": "Neural code generation has generated an intense recent interest in NLP, using Transformer models [31] in particular for code completion [3, 4, 7, 21, 25, 26], code synthesis from examples [6], natural language to code [2, 6, 7], code feature summarization [1, 16, 18, 19, 23, 32], code search [9, 10], unit test generation [29] and even bug fixing [8] and detection [33].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various applications of neural code generation. No dataset names are present in the text.",
      "processing_time": 53.067893981933594,
      "citing_paper_id": "251503272",
      "cited_paper_id": 1129667
    },
    {
      "context_text": "Neural code generation has generated an intense recent interest in NLP, using Transformer models [31] in particular for code completion [3, 4, 7, 21, 25, 26], code synthesis from examples [6], natural language to code [2, 6, 7], code feature summarization [1, 16, 18, 19, 23, 32], code search [9, 10], unit test generation [29] and even bug fixing [8] and detection [33].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various applications of neural code generation. No dataset names are present in the text.",
      "processing_time": 53.067893981933594,
      "citing_paper_id": "251503272",
      "cited_paper_id": 196177632
    },
    {
      "context_text": "Neural code generation has generated an intense recent interest in NLP, using Transformer models [31] in particular for code completion [3, 4, 7, 21, 25, 26], code synthesis from examples [6], natural language to code [2, 6, 7], code feature summarization [1, 16, 18, 19, 23, 32], code search [9, 10], unit test generation [29] and even bug fixing [8] and detection [33].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various applications of neural code generation. No dataset names are present in the text.",
      "processing_time": 53.067893981933594,
      "citing_paper_id": "251503272",
      "cited_paper_id": 202712680
    },
    {
      "context_text": "Neural code generation has generated an intense recent interest in NLP, using Transformer models [31] in particular for code completion [3, 4, 7, 21, 25, 26], code synthesis from examples [6], natural language to code [2, 6, 7], code feature summarization [1, 16, 18, 19, 23, 32], code search [9, 10], unit test generation [29] and even bug fixing [8] and detection [33].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various applications of neural code generation. No dataset names are present in the text.",
      "processing_time": 53.067893981933594,
      "citing_paper_id": "251503272",
      "cited_paper_id": 207971106
    },
    {
      "context_text": "Neural code generation has generated an intense recent interest in NLP, using Transformer models [31] in particular for code completion [3, 4, 7, 21, 25, 26], code synthesis from examples [6], natural language to code [2, 6, 7], code feature summarization [1, 16, 18, 19, 23, 32], code search [9, 10], unit test generation [29] and even bug fixing [8] and detection [33].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various applications of neural code generation. No dataset names are present in the text.",
      "processing_time": 53.067893981933594,
      "citing_paper_id": "251503272",
      "cited_paper_id": 235165921
    },
    {
      "context_text": "Much of the previous literature on personalized models focuses on client-side training to keep data on device [20, 24], and most work is in the domain of search query completion [11], natural language completion [20], or even automated speech recognition [24].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general domains of application for personalized models. No verifiable resources are named.",
      "processing_time": 53.07600998878479,
      "citing_paper_id": "251503272",
      "cited_paper_id": 13742826
    },
    {
      "context_text": "Much of the previous literature on personalized models focuses on client-side training to keep data on device [20, 24], and most work is in the domain of search query completion [11], natural language completion [20], or even automated speech recognition [24].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general domains of application for personalized models. No verifiable resources are named.",
      "processing_time": 53.07600998878479,
      "citing_paper_id": "251503272",
      "cited_paper_id": 67350953
    },
    {
      "context_text": "The current dominant paradigm in Natural Language Processing (NLP) modeling is to pre-train a large transformer model [30] on a large corpus and then fine-tune it on a particular task of interest.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a general practice in NLP modeling.",
      "processing_time": 52.59218168258667,
      "citing_paper_id": "251503272",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Next, we remove licensing information and comments using regex, then tokenize the corpus using gensim [22] tokenizer (with lowercase setting).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes preprocessing steps using a tokenizer from gensim.",
      "processing_time": 52.41583514213562,
      "citing_paper_id": "251503272",
      "cited_paper_id": 18593743
    },
    {
      "context_text": "For the same task, LACT [27] uses Latent Dirichlet Allocation (LDA), and recently neural text classification with word embeddings has been used [14] to categorize similar software projects.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the use of LDA and neural text classification with word embeddings, which are methods, not datasets.",
      "processing_time": 56.09546947479248,
      "citing_paper_id": "251503272",
      "cited_paper_id": 46939411
    },
    {
      "context_text": "Figure 2b shows the Lightweight fine-tuning - Embeddings and Output Layer (L-EO) design, where most of the model parameters are frozen (displayed in gray), and we allow only the embedding and output layers parameters to be fine-tuned, following the approach in [17].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for fine-tuning pretrained transformers. No verifiable resources are identified.",
      "processing_time": 53.0613317489624,
      "citing_paper_id": "251503272",
      "cited_paper_id": 232168936
    },
    {
      "context_text": "[29] as our baseline model m, which is a BART transformer model pretrained on source code and English, and fine-tuned on Java unit test generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a BART transformer model but does not refer to any specific dataset. The focus is on the model and its fine-tuning task.",
      "processing_time": 54.524263858795166,
      "citing_paper_id": "251503272",
      "cited_paper_id": 235165921
    },
    {
      "context_text": "These projects belong to the validation set of the open dataset Methods2Test [29].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Methods2Test"
      ],
      "dataset_descriptions": {
        "Methods2Test": "Used as a validation set for unit test case generation experiments, focusing on the effectiveness of transformer models in generating test cases."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions 'Methods2Test' as an open dataset, which is a specific, verifiable resource. It is used as a validation set for unit test case generation experiments.",
      "processing_time": 61.532689332962036,
      "citing_paper_id": "251503272",
      "cited_paper_id": 235165921
    },
    {
      "context_text": "[29], and an important contribution to the understanding optimization in a deployment scenario.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only refers to a contribution to understanding optimization in a deployment scenario.",
      "processing_time": 53.94117784500122,
      "citing_paper_id": "251503272",
      "cited_paper_id": 235165921
    },
    {
      "context_text": "Transformer models are also increasingly the baseline architecture used for code generation tasks, such as writing methods from natural language description [2, 5, 7], or generating test cases from the focal method under test [29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of transformer models for code generation tasks. No verifiable resources are identified.",
      "processing_time": 53.75210642814636,
      "citing_paper_id": "251503272",
      "cited_paper_id": 235165921
    },
    {
      "context_text": "[5] used an adaptive method to sample from latent semantic human representations [6] to find prototypes of emotional speech by adapting the latent representation of a GST Tacotron model [7].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers do not introduce any datasets either.",
      "processing_time": 52.74117970466614,
      "citing_paper_id": "247778917",
      "cited_paper_id": 4349820
    },
    {
      "context_text": "[5] used an adaptive method to sample from latent semantic human representations [6] to find prototypes of emotional speech by adapting the latent representation of a GST Tacotron model [7].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers do not introduce any datasets either.",
      "processing_time": 52.74117970466614,
      "citing_paper_id": "247778917",
      "cited_paper_id": 233739719
    },
    {
      "context_text": "In order to learn prosodic variation, we extend our model with a bank of Global Style Tokens (GST) [7], which extracts style embeddings from encoded spectrogram frames.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Global Style Tokens) for extracting style embeddings. The cited paper title confirms that the focus is on a method rather than a dataset.",
      "processing_time": 56.000192642211914,
      "citing_paper_id": "247778917",
      "cited_paper_id": 4349820
    },
    {
      "context_text": "To prevent the GSTs from learning speaker-dependent features in presence of SpeakerNet embeddings, an additional adversarial loss is proposed as follows.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving SpeakerNet embeddings and an adversarial loss.",
      "processing_time": 52.259864807128906,
      "citing_paper_id": "247778917",
      "cited_paper_id": 4349820
    },
    {
      "context_text": "As GST encoder an 8-layer convolutional network was used with the same architecture as the Posterior Encoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model architecture. No verifiable resources are identified.",
      "processing_time": 52.07857966423035,
      "citing_paper_id": "247778917",
      "cited_paper_id": 4349820
    },
    {
      "context_text": "Van Rijn et al. [5] used an adaptive method to sample from latent semantic human representations [6] to find prototypes of emotional speech by adapting the latent representation of a GST Tacotron model [7].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the adaptive method and the GST Tactron model, which are not datasets.",
      "processing_time": 54.833674907684326,
      "citing_paper_id": "247778917",
      "cited_paper_id": 4349820
    },
    {
      "context_text": "Requirements for participation include a minimal age of 18 years, 99% or higher approval rate on at least 5,000 previous tasks on AMT, residency in the US and wearing headphones [17].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only requirements for participants in a study using Amazon Mechanical Turk (AMT).",
      "processing_time": 53.1723952293396,
      "citing_paper_id": "247778917",
      "cited_paper_id": 7355407
    },
    {
      "context_text": "A large body of psychological research has shown that people actively make inferences about faces, including the personality, age, or background of the person [3, 4, 5, 6, 7].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general psychological research findings. No verifiable resources are identified.",
      "processing_time": 52.269495248794556,
      "citing_paper_id": "247778917",
      "cited_paper_id": 17498620
    },
    {
      "context_text": "A large body of psychological research has shown that people actively make inferences about faces, including the personality, age, or background of the person [3, 4, 5, 6, 7].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general psychological research findings. No verifiable resources are identified.",
      "processing_time": 52.269495248794556,
      "citing_paper_id": "247778917",
      "cited_paper_id": 24938914
    },
    {
      "context_text": "[1] and used embeddings from a speaker verification network as speaker representation: because they can be trained on noisy speech of thousands of speakers, do not require transcripts, can extract speaker embeddings for unseen voices, and the obtained voice prototypes can be reused in future models if trained on the same pretrained speaker verification network.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses the use of embeddings from a speaker verification network, which is a method or model, not a dataset.",
      "processing_time": 55.19448900222778,
      "citing_paper_id": "247778917",
      "cited_paper_id": 48363067
    },
    {
      "context_text": "In the last few years, multi-speaker text-to-speech (TTS) models have been proposed that can create entirely new high-quality voices [1, 2].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the development of multi-speaker TTS models. No verifiable resources are identified.",
      "processing_time": 53.69314217567444,
      "citing_paper_id": "247778917",
      "cited_paper_id": 48363067
    },
    {
      "context_text": "In the last few years, multi-speaker text-to-speech (TTS) models have been proposed that can create entirely new high-quality voices [1, 2].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the development of multi-speaker TTS models. No verifiable resources are identified.",
      "processing_time": 53.69314217567444,
      "citing_paper_id": "247778917",
      "cited_paper_id": 243861060
    },
    {
      "context_text": "[1] demonstrated that an independently trained speaker encoder network trained on a speaker verification task is able to produce useful conditioning for a multi-speaker text-to-speech model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model for training a speaker encoder network.",
      "processing_time": 52.03289437294006,
      "citing_paper_id": "247778917",
      "cited_paper_id": 48363067
    },
    {
      "context_text": "[4] used an interactive evolutionary algorithm to allow users to create sounds that express intentions and emotions for a social robot.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for creating sounds for social robots.",
      "processing_time": 50.90406680107117,
      "citing_paper_id": "247778917",
      "cited_paper_id": 209322955
    },
    {
      "context_text": "The principal components were computed on SpeakerNet embeddings extracted on a single utterance of the 45,825 speakers present in the train, dev and test partitions of the English CommonVoice dataset [11] and account for 25.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "English CommonVoice dataset"
      ],
      "dataset_descriptions": {
        "English CommonVoice dataset": "Used to extract SpeakerNet embeddings from a single utterance of 45,825 speakers across train, dev, and test partitions, focusing on principal component analysis."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'English CommonVoice dataset' which is a specific, verifiable dataset used for extracting SpeakerNet embeddings.",
      "processing_time": 61.80209922790527,
      "citing_paper_id": "247778917",
      "cited_paper_id": 209376338
    },
    {
      "context_text": "As opposed to using static images, we use Wav2Lip [12] to synchronize the lips to the voice so that the resulting stimulus sounds more natural.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Wav2Lip) for lip synchronization. No verifiable datasets are referenced.",
      "processing_time": 54.23466777801514,
      "citing_paper_id": "247778917",
      "cited_paper_id": 221266065
    },
    {
      "context_text": "S D\n] 2\n9 M\nar 2\n02 2\n(iv) convolutional Posterior Encoder, (v) Monotonic Alignment Search (MAS) and Stochastic Duration Predictor (SDP) modules learning to align input characters to encoded spectrogram frames, (vi) high-fidelity GAN vocoder based on the HiFi-GAN [10] architecture.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only components of a model architecture. HiFi-GAN is a model, not a dataset.",
      "processing_time": 54.10923624038696,
      "citing_paper_id": "247778917",
      "cited_paper_id": 222291664
    },
    {
      "context_text": "(iv) convolutional Posterior Encoder, (v) Monotonic Alignment Search (MAS) and Stochastic Duration Predictor (SDP) modules learning to align input characters to encoded spectrogram frames, (vi) high-fidelity GAN vocoder based on the HiFi-GAN [10] architecture.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and architectures. HiFi-GAN is a model, not a dataset.",
      "processing_time": 53.49627208709717,
      "citing_paper_id": "247778917",
      "cited_paper_id": 222291664
    },
    {
      "context_text": "Here we use humans to search the speaker latent space in a trained TTS model that uses speaker embeddings from a stateof-the-art speaker verification model [3].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to a method (speaker verification model) and a task (searching the speaker latent space in a TTS model).",
      "processing_time": 56.28024649620056,
      "citing_paper_id": "247778917",
      "cited_paper_id": 225066732
    },
    {
      "context_text": "We use the pretrained speaker verification network SpeakerNet-M [3] as speaker embeddings.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a pretrained network (SpeakerNet-M) but does not refer to a dataset. The citation is about using a method/model, not a dataset.",
      "processing_time": 54.5770800113678,
      "citing_paper_id": "247778917",
      "cited_paper_id": 225066732
    },
    {
      "context_text": "[2] that does not rely on transfer learning from the speaker verification task, but jointly learns a distribution over speaker embeddings, also allowing for sampling a novel voice.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for speaker generation. There are no verifiable resources or datasets mentioned.",
      "processing_time": 53.66582465171814,
      "citing_paper_id": "247778917",
      "cited_paper_id": 243861060
    },
    {
      "context_text": "VITS is an end-to-end architecture with the following components (see Figure 1A): (i) text frontend composed of text normalization followed by a grapheme-tophoneme model utilizing IPA characters (International Phonetic Alphabet) [9], (ii) transformer-based Text Encoder with a projection layer used to construct prior distribution, (iii) Normalizing Flow greatly improving the flexibility of prior latent space, ar X iv :2 20 3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only components of an architecture. There are no verifiable resources that meet the criteria.",
      "processing_time": 53.66296696662903,
      "citing_paper_id": "247778917",
      "cited_paper_id": null
    },
    {
      "context_text": "VITS is an end-to-end architecture with the following components (see Figure 1A): (i) text frontend composed of text normalization followed by a grapheme-tophoneme model utilizing IPA characters (International Phonetic Alphabet) [9], (ii) transformer-based Text Encoder with a projection layer used to construct prior distribution, (iii) Normalizing Flow greatly improving the flexibility of prior latent space,\nar X\niv :2\n20 3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only components of an architecture. There are no verifiable resources that meet the criteria.",
      "processing_time": 53.66851854324341,
      "citing_paper_id": "247778917",
      "cited_paper_id": null
    },
    {
      "context_text": "We used toonify [14] and three additional art portrait styles from Ai Gahaku2: OR, EX3 and ROO or P00 (see example in figure 1C).",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Ai Gahaku' and specific art portrait styles, but does not refer to them as datasets, databases, or similar resources. They appear to be tools or methods for generating art portraits.",
      "processing_time": 56.61926317214966,
      "citing_paper_id": "247778917",
      "cited_paper_id": null
    },
    {
      "context_text": "We used toonify [20] and three additional art portrait styles from Ai Gahaku[21]: OR, EX3, and ROO or P00 (see example in figure 1C).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Ai Gahaku' and specific art portrait styles (OR, EX3, ROO, P00) but does not refer to them as datasets. They are likely tools or styles used for generating images.",
      "processing_time": 57.159098863601685,
      "citing_paper_id": "247778917",
      "cited_paper_id": null
    },
    {
      "context_text": "We applied transfer learning from the publicly available VCTK checkpoint [16] and the training was continued using two NVIDIA V100 GPUs.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "VCTK"
      ],
      "dataset_descriptions": {
        "VCTK": "Used as a starting point for transfer learning, specifically to initialize the model before continuing training on the target task using two NVIDIA V100 GPUs."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions a checkpoint from VCTK, which is a dataset, but it does not provide a clear usage description or specific research context. The primary focus is on the method (transfer learning) and hardware used.",
      "processing_time": 64.22314476966858,
      "citing_paper_id": "247778917",
      "cited_paper_id": null
    },
    {
      "context_text": "To evaluate general abilities, we used prominent benchmarks such as MMLU [61] for text-only generation, POPE [62], and MMBench [63] for visual question answering.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions benchmarks but does not specify the use of any datasets. MMLU, POPE, and MMBench are excluded as they are benchmark suites, not datasets.",
      "processing_time": 55.35448455810547,
      "citing_paper_id": "278171225",
      "cited_paper_id": 221516475
    },
    {
      "context_text": "To evaluate general abilities, we used prominent benchmarks such as MMLU [61] for text-only generation, POPE [62], and MMBench [63] for visual question answering.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions benchmarks but does not specify the use of any datasets. MMLU, POPE, and MMBench are excluded as they are benchmark suites, not datasets.",
      "processing_time": 55.35448455810547,
      "citing_paper_id": "278171225",
      "cited_paper_id": null
    },
    {
      "context_text": "Conversely, soft prompt learning [22, 23], which introduce learnable tokens to encode new concepts while keeping the model frozen, is effective for personalized image understanding tasks [19].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (soft prompt learning) and its application to personalized image understanding tasks.",
      "processing_time": 53.55893802642822,
      "citing_paper_id": "278171225",
      "cited_paper_id": 233296808
    },
    {
      "context_text": "Consequently, numerous PEFT methods have been introduced to optimize a small subset of parameters (or introduce extra parameters) for downstream tasks [22, 44, 45].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only parameter-efficient fine-tuning (PEFT) methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 55.71619129180908,
      "citing_paper_id": "278171225",
      "cited_paper_id": 233296808
    },
    {
      "context_text": "Consequently, numerous PEFT methods have been introduced to optimize a small subset of parameters (or introduce extra parameters) for downstream tasks [22, 44, 45].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only parameter-efficient fine-tuning (PEFT) methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 55.71619129180908,
      "citing_paper_id": "278171225",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "In the domain of LLMs, prompt tuning (or soft-prompts) has emerged as an effective approach to adapt pretrained language models for various tasks, such as tool utilization [23] and text classification [22].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on prompt tuning and its applications, without referencing any particular dataset.",
      "processing_time": 54.38840293884277,
      "citing_paper_id": "278171225",
      "cited_paper_id": 233296808
    },
    {
      "context_text": "Large Language Models (LLMs) [26–29] and text-to-image models [30–34] have made tremendous progress recently, demonstrating extensive knowledge and excelling at text and image generation, respectively.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general advancements in LLMs and text-to-image models. No verifiable resources are identified.",
      "processing_time": 54.170926332473755,
      "citing_paper_id": "278171225",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Large Language Models (LLMs) [26–29] and text-to-image models [30–34] have made tremendous progress recently, demonstrating extensive knowledge and excelling at text and image generation, respectively.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general advancements in LLMs and text-to-image models. No verifiable resources are identified.",
      "processing_time": 54.170926332473755,
      "citing_paper_id": "278171225",
      "cited_paper_id": 255942528
    },
    {
      "context_text": "Large Language Models (LLMs) [26–29] and text-to-image models [30–34] have made tremendous progress recently, demonstrating extensive knowledge and excelling at text and image generation, respectively.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general advancements in LLMs and text-to-image models. No verifiable resources are identified.",
      "processing_time": 54.170926332473755,
      "citing_paper_id": "278171225",
      "cited_paper_id": 257219404
    },
    {
      "context_text": "Additionally, we randomly sample 100 easy-negative examples from LAION-5B [58], which remain consistent across all concepts.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LAION-5B"
      ],
      "dataset_descriptions": {
        "LAION-5B": "Used to sample easy-negative examples for training, ensuring consistency across different concepts in the personalized text generation model."
      },
      "confidence_score": 1.0,
      "reasoning": "LAION-5B is a specific, large-scale dataset used for training image-text models, and it is explicitly mentioned as a source of negative examples.",
      "processing_time": 60.55690312385559,
      "citing_paper_id": "278171225",
      "cited_paper_id": 252917726
    },
    {
      "context_text": "For negative images, we retrieve them from LAION-5B [58] based on the average CLIP Image Similarity [55] score between retrieved images and the mean feature representation of positive examples.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LAION-5B"
      ],
      "dataset_descriptions": {
        "LAION-5B": "Used to retrieve negative images for training image-text models, focusing on image similarity scores and mean feature representations."
      },
      "confidence_score": 1.0,
      "reasoning": "LAION-5B is a specific, large-scale dataset used for retrieving negative images based on image similarity scores.",
      "processing_time": 59.45050621032715,
      "citing_paper_id": "278171225",
      "cited_paper_id": 252917726
    },
    {
      "context_text": "Similar to other ablation studiesin the main paper, this study aims to analyze the effect of varying the number of “soft-1 most similar images from LAION-5B [58].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LAION-5B"
      ],
      "dataset_descriptions": {
        "LAION-5B": "Used to retrieve 'soft-1 most similar images' for analyzing the effect of varying the number of similar images in the study, focusing on image-text model training."
      },
      "confidence_score": 1.0,
      "reasoning": "LAION-5B is mentioned as a dataset used for retrieving similar images, which is relevant to the research context of analyzing the effect of varying the number of similar images.",
      "processing_time": 64.00098156929016,
      "citing_paper_id": "278171225",
      "cited_paper_id": 252917726
    },
    {
      "context_text": "Personalization techniques have been extensively studied for LLMs [7–11] and image generation models [12–18], demonstrating significant progress in these individual domains.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general progress in personalization techniques for LLMs and image generation models.",
      "processing_time": 53.48937177658081,
      "citing_paper_id": "278171225",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "For image generation personalization, [12, 18] utilize negative examples as regularization to prevent model forgetting of class-level information.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach using negative examples for regularization.",
      "processing_time": 52.3986759185791,
      "citing_paper_id": "278171225",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "This observation aligns with previous work [23–25] which suggests that tokens optimized for one specific task may lack semantic relevance for other tasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about task-specific tokens.",
      "processing_time": 51.49549651145935,
      "citing_paper_id": "278171225",
      "cited_paper_id": 256627601
    },
    {
      "context_text": "This phenomenon aligns with prior work [23–25] suggesting that optimized textual representations for one task might not be interpretable.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept about textual representations. No verifiable resources are identified.",
      "processing_time": 53.203229665756226,
      "citing_paper_id": "278171225",
      "cited_paper_id": 256627601
    },
    {
      "context_text": "In image generation, prior work demonstrated that prompt tuning can effectively encode visual concepts for personalization [13, 24, 25].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the technique of prompt tuning for personalization in image generation.",
      "processing_time": 52.927573442459106,
      "citing_paper_id": "278171225",
      "cited_paper_id": 256627601
    },
    {
      "context_text": "In image generation, prior work demonstrated that prompt tuning can effectively encode visual concepts for personalization [13, 24, 25].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the technique of prompt tuning for personalization in image generation.",
      "processing_time": 52.927573442459106,
      "citing_paper_id": "278171225",
      "cited_paper_id": 268030731
    },
    {
      "context_text": "In image generation, researchers typically fine-tune either the entire model or specific components to incorporate visual knowledge [12, 14–16, 24, 42, 43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches in image generation. No verifiable resources are identified.",
      "processing_time": 53.644015073776245,
      "citing_paper_id": "278171225",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "In image generation, researchers typically fine-tune either the entire model or specific components to incorporate visual knowledge [12, 14–16, 24, 42, 43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches in image generation. No verifiable resources are identified.",
      "processing_time": 53.644015073776245,
      "citing_paper_id": "278171225",
      "cited_paper_id": 268030731
    },
    {
      "context_text": "In image generation, researchers typically fine-tune either the entire model or specific components to incorporate visual knowledge [12, 14–16, 24, 42, 43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches in image generation. No verifiable resources are identified.",
      "processing_time": 53.644015073776245,
      "citing_paper_id": "278171225",
      "cited_paper_id": 270380175
    },
    {
      "context_text": "Motivated by this, in our approach, we retrieve hard-negative images, but unlike prior work [50, 51], we use them as “soft positive” images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. No verifiable resources are identified.",
      "processing_time": 52.90837383270264,
      "citing_paper_id": "278171225",
      "cited_paper_id": 257913352
    },
    {
      "context_text": "SuTI [50] and COTI [51] leverage negative images that are visually similar to personalized objects to establish a better initialization that facilitates easier adaptation to the target personalized object.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'negative images' but does not specify a dataset name. The cited paper titles do not help disambiguate any dataset names.",
      "processing_time": 54.75979423522949,
      "citing_paper_id": "278171225",
      "cited_paper_id": 257913352
    },
    {
      "context_text": "…positive training samples [17, 52, 53], and (2) leveraging hard-negative samples as an initialization, in which we first train on these negative images, then add an additional step to fine-tune the results with a limited number of positive examples to enhance personalization [50, 51, 54].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 53.8163743019104,
      "citing_paper_id": "278171225",
      "cited_paper_id": 257913352
    },
    {
      "context_text": "…positive training samples [17, 52, 53], and (2) leveraging hard-negative samples as an initialization, in which we first train on these negative images, then add an additional step to fine-tune the results with a limited number of positive examples to enhance personalization [50, 51, 54].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 53.8163743019104,
      "citing_paper_id": "278171225",
      "cited_paper_id": 258999486
    },
    {
      "context_text": "For instance, as [19] highlights, personalized Vision-Language Models like LLaVA [37] can still produce hallucinations (e.g., pro-“A • A serene beach with golden sand and clear blue water.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 53.62945055961609,
      "citing_paper_id": "278171225",
      "cited_paper_id": 258179774
    },
    {
      "context_text": "As we chose Chameleon [1] as our base model, we named our method Yo’Chameleon, with Yo (short for Your ) adopted from Yo’LLaVA’s [19] personalization of LLaVA [37].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 53.55355620384216,
      "citing_paper_id": "278171225",
      "cited_paper_id": 258179774
    },
    {
      "context_text": "…the training samples: (1) data augmentation (e.g., background inpainting) to treat augmented images as additional positive training samples [17, 52, 53], and (2) leveraging hard-negative samples as an initialization, in which we first train on these negative images, then add an additional step…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses general methods for data augmentation and leveraging hard-negative samples, but no named datasets are referenced.",
      "processing_time": 54.49234342575073,
      "citing_paper_id": "278171225",
      "cited_paper_id": 259287552
    },
    {
      "context_text": "Sample of 10 out of 100 captions used for generating the background with Stable Diffusion-XL [60] viding an incorrect date of birth for a person when asked).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a sample of captions used for generating backgrounds with a model.",
      "processing_time": 54.14217019081116,
      "citing_paper_id": "278171225",
      "cited_paper_id": 259341735
    },
    {
      "context_text": "For data augmentation, we first use SAM [59] to extract the foreground of the subjects, then randomly resize the subject to 30–70% of the 512x512 image size, and inpaint the background using Stable Diffusion-XL [60].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context describes a method for data augmentation using SAM and Stable Diffusion-XL, but does not mention any specific datasets. The cited papers are methods, not datasets.",
      "processing_time": 55.07569146156311,
      "citing_paper_id": "278171225",
      "cited_paper_id": 259341735
    },
    {
      "context_text": "Recent work by [19, 20] proposes personalizing vision-language models through soft prompts to enable recognition and discussion of user-specific objects.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for personalizing vision-language models.",
      "processing_time": 52.453129529953,
      "citing_paper_id": "278171225",
      "cited_paper_id": 268553866
    },
    {
      "context_text": "Similarly, our approach inherits the limitations of its underlying models, in this case, Chameleon/Anole [1, 57].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models. The context focuses on the limitations of the models Chameleon and Anole.",
      "processing_time": 54.13446927070618,
      "citing_paper_id": "278171225",
      "cited_paper_id": 271050462
    },
    {
      "context_text": "While Chameleon was not originally published with image generation capabilities, we use the checkpoint from Anole [57], which recovered these capabilities through fine-tuning on an image generation dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'image generation dataset' but does not provide a specific name. The name 'Anole' is a model, not a dataset.",
      "processing_time": 54.70278882980347,
      "citing_paper_id": "278171225",
      "cited_paper_id": 271050462
    },
    {
      "context_text": "Vision-language models [35–40] have emerged as a bridge between these modalities, capable of processing image-text inputs and generating textual outputs.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to vision-language models. No specific, verifiable datasets are named.",
      "processing_time": 54.13389730453491,
      "citing_paper_id": "278171225",
      "cited_paper_id": 273507856
    },
    {
      "context_text": "Vision-language models [35–40] have emerged as a bridge between these modalities, capable of processing image-text inputs and generating textual outputs.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to vision-language models. No specific, verifiable datasets are named.",
      "processing_time": 54.13389730453491,
      "citing_paper_id": "278171225",
      "cited_paper_id": null
    },
    {
      "context_text": "The ability to process both visual and textual information within a single system—as demonstrated by models like GPT-4o [2] and Gemini [4]—has streamlined user interactions and improved query comprehension.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their capabilities. There are no verifiable resources or datasets mentioned.",
      "processing_time": 53.31879949569702,
      "citing_paper_id": "278171225",
      "cited_paper_id": null
    },
    {
      "context_text": "…social media platforms such as Reddit and Twitter provide us with good opportunities to build a large scale of collections of naturally occurring conversations (Xifra and Grau, 2010; De Choudhury and De, 2014; Schrading et al., 2015) and also make it possible to provide consistent personalities.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions social media platforms as sources of conversation data but does not specify any named datasets. The reference to Reddit and Twitter is generic and lacks specific dataset identifiers.",
      "processing_time": 55.36409044265747,
      "citing_paper_id": "234757004",
      "cited_paper_id": 1578178
    },
    {
      "context_text": "There are also several dialog datasets that focus on chit-chat scenarios, such as PERSONA-CHAT dataset (Zhang et al., 2018), Reddit dataset (Al-Rfou et al., 2016), Twitter dataset (Li et al., 2016b) and PersonalDialog dataset (Zheng et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PERSONA-CHAT",
        "Reddit dataset",
        "Twitter dataset",
        "PersonalDialog"
      ],
      "dataset_descriptions": {
        "PERSONA-CHAT": "Used to train dialogue systems for generating personalized responses, focusing on incorporating persona information into conversations.",
        "Reddit dataset": "Used to train dialogue systems for generating casual and diverse conversations, focusing on the variety of topics and user interactions.",
        "Twitter dataset": "Used to train dialogue systems for generating short, informal conversations, focusing on the dynamic and fast-paced nature of social media interactions.",
        "PersonalDialog": "Used to train dialogue systems for generating personalized and engaging conversations, focusing on user-specific contexts and preferences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific dialog datasets that are used for chit-chat scenarios, which are directly relevant to personalized text generation.",
      "processing_time": 75.71437644958496,
      "citing_paper_id": "234757004",
      "cited_paper_id": 3147007
    },
    {
      "context_text": "There are also several dialog datasets that focus on chit-chat scenarios, such as PERSONA-CHAT dataset (Zhang et al., 2018), Reddit dataset (Al-Rfou et al., 2016), Twitter dataset (Li et al., 2016b) and PersonalDialog dataset (Zheng et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PERSONA-CHAT",
        "Reddit dataset",
        "Twitter dataset",
        "PersonalDialog"
      ],
      "dataset_descriptions": {
        "PERSONA-CHAT": "Used to train dialogue systems for generating personalized responses, focusing on incorporating persona information into conversations.",
        "Reddit dataset": "Used to train dialogue systems for generating casual and diverse conversations, focusing on the variety of topics and user interactions.",
        "Twitter dataset": "Used to train dialogue systems for generating short, informal conversations, focusing on the dynamic and fast-paced nature of social media interactions.",
        "PersonalDialog": "Used to train dialogue systems for generating personalized and engaging conversations, focusing on user-specific contexts and preferences."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific dialog datasets that are used for chit-chat scenarios, which are directly relevant to personalized text generation.",
      "processing_time": 75.71437644958496,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7287895
    },
    {
      "context_text": "…pairs with respondents’ proﬁle and posting histories, with related information from proﬁle and histories in blue and red respectively. models are often trained over conversations spoken by different people, ignoring their personality (Li et al., 2016b; Wei et al., 2019; Zhang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses the training of models over conversations but does not name any particular dataset.",
      "processing_time": 54.2506787776947,
      "citing_paper_id": "234757004",
      "cited_paper_id": 3147007
    },
    {
      "context_text": "…pairs with respondents’ proﬁle and posting histories, with related information from proﬁle and histories in blue and red respectively. models are often trained over conversations spoken by different people, ignoring their personality (Li et al., 2016b; Wei et al., 2019; Zhang et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses the training of models over conversations but does not name any particular dataset.",
      "processing_time": 54.2506787776947,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7287895
    },
    {
      "context_text": "Li et al. (2016b) introduced the Speaker Model and the Speaker-Addressee Model that encoded user-id information into an additional vector and fed it into the decoder to capture the identity of the speakers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on describing the models used for encoding user-id information.",
      "processing_time": 54.716989517211914,
      "citing_paper_id": "234757004",
      "cited_paper_id": 3147007
    },
    {
      "context_text": "Li et al. (2016b) introduced the Speaker Model and the Speaker-Addressee Model that encoded user-id information into an additional vector and fed it into the decoder to capture the identity of the speakers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on describing the models used for encoding user-id information.",
      "processing_time": 54.716989517211914,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7287895
    },
    {
      "context_text": "14% increase in PC-Score, similar to Li et al. (2016b).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a performance metric (PC-Score) and a reference to another paper. No verifiable resources are identified.",
      "processing_time": 54.97241687774658,
      "citing_paper_id": "234757004",
      "cited_paper_id": 3147007
    },
    {
      "context_text": "14% increase in PC-Score, similar to Li et al. (2016b).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a performance metric (PC-Score) and a reference to another paper. No verifiable resources are identified.",
      "processing_time": 54.97241687774658,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7287895
    },
    {
      "context_text": "• Speaker Models: Similar to (Li et al., 2016b), we employed an additional vector to model the respondent A .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a method or model for dialogue generation.",
      "processing_time": 53.319700717926025,
      "citing_paper_id": "234757004",
      "cited_paper_id": 3147007
    },
    {
      "context_text": "• Speaker Models: Similar to (Li et al., 2016b), we employed an additional vector to model the respondent A .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a method or model for dialogue generation.",
      "processing_time": 53.319700717926025,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7287895
    },
    {
      "context_text": "We also used BLEU (Papineni et al., 2002; Li et al., 2016a; Gal-ley et al., 2015) with n -grams (n= 1 ) to measure how many n-grams in generated responses overlap with those in reference responses.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the metric BLEU which is excluded as per instructions.",
      "processing_time": 52.63563299179077,
      "citing_paper_id": "234757004",
      "cited_paper_id": 3147007
    },
    {
      "context_text": "We also used BLEU (Papineni et al., 2002; Li et al., 2016a; Gal-ley et al., 2015) with n -grams (n= 1 ) to measure how many n-grams in generated responses overlap with those in reference responses.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the metric BLEU which is excluded as per instructions.",
      "processing_time": 52.63563299179077,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7287895
    },
    {
      "context_text": "Despite the recent successes on building chit-chat agents using data-driven approaches (Ritter et al., 2011; Banchs and Li, 2012; Serban et al., 2016; Li et al., 2016c; Parthasarathi and Pineau, 2018), lack of a consistent personality is still one of the common issues.",
      "catation_intent": "findings",
      "resource_type": "gap",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The context discusses the issue of lack of consistent personality in chit-chat agents, which is a finding or gap in the field.",
      "processing_time": 56.73982524871826,
      "citing_paper_id": "234757004",
      "cited_paper_id": 3147007
    },
    {
      "context_text": "Despite the recent successes on building chit-chat agents using data-driven approaches (Ritter et al., 2011; Banchs and Li, 2012; Serban et al., 2016; Li et al., 2016c; Parthasarathi and Pineau, 2018), lack of a consistent personality is still one of the common issues.",
      "catation_intent": "findings",
      "resource_type": "gap",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The context discusses the issue of lack of consistent personality in chit-chat agents, which is a finding or gap in the field.",
      "processing_time": 56.73982524871826,
      "citing_paper_id": "234757004",
      "cited_paper_id": 6126582
    },
    {
      "context_text": "Despite the recent successes on building chit-chat agents using data-driven approaches (Ritter et al., 2011; Banchs and Li, 2012; Serban et al., 2016; Li et al., 2016c; Parthasarathi and Pineau, 2018), lack of a consistent personality is still one of the common issues.",
      "catation_intent": "findings",
      "resource_type": "gap",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. The context discusses the issue of lack of consistent personality in chit-chat agents, which is a finding or gap in the field.",
      "processing_time": 56.73982524871826,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7287895
    },
    {
      "context_text": "Unlike task-oriented dialog agents that focus on completing speciﬁc tasks (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Lowe et al., 2015), chit-chat agents need to dynamically interact with people, understand the meaning of human conversations (Hovy and Yang, 2021), and thereby make…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to task-oriented dialog agents and chit-chat agents. The cited papers do not introduce new datasets in the context provided.",
      "processing_time": 55.71845746040344,
      "citing_paper_id": "234757004",
      "cited_paper_id": 5932528
    },
    {
      "context_text": "Unlike task-oriented dialog agents that focus on completing speciﬁc tasks (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Lowe et al., 2015), chit-chat agents need to dynamically interact with people, understand the meaning of human conversations (Hovy and Yang, 2021), and thereby make…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to task-oriented dialog agents and chit-chat agents. The cited papers do not introduce new datasets in the context provided.",
      "processing_time": 55.71845746040344,
      "citing_paper_id": "234757004",
      "cited_paper_id": 8379583
    },
    {
      "context_text": "Unlike task-oriented dialog agents that focus on completing speciﬁc tasks (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Lowe et al., 2015), chit-chat agents need to dynamically interact with people, understand the meaning of human conversations (Hovy and Yang, 2021), and thereby make…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to task-oriented dialog agents and chit-chat agents. The cited papers do not introduce new datasets in the context provided.",
      "processing_time": 55.71845746040344,
      "citing_paper_id": "234757004",
      "cited_paper_id": 10565222
    },
    {
      "context_text": "With the development of recent large scale social media data and the success of sequence to sequence framework (Serban et al., 2016; Shang et al., 2015; Sutskever et al., 2014), several personalized response generation models have been proposed, and we can only mention a few here due to space…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and frameworks. No verifiable resources are identified.",
      "processing_time": 53.50843524932861,
      "citing_paper_id": "234757004",
      "cited_paper_id": 6126582
    },
    {
      "context_text": "With the development of recent large scale social media data and the success of sequence to sequence framework (Serban et al., 2016; Shang et al., 2015; Sutskever et al., 2014), several personalized response generation models have been proposed, and we can only mention a few here due to space…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and frameworks. No verifiable resources are identified.",
      "processing_time": 53.50843524932861,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7356547
    },
    {
      "context_text": "Evaluation Metrics Most response generation models utilize perplexity, BLEU (Papineni et al., 2002) and recently BERTScore (Zhang et al., 2019) and Moverscore (Zhao et al., 2019) for evaluation (Serban et al., 2016; Xing et al., 2018).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics and models. No verifiable resources are identified.",
      "processing_time": 53.11497640609741,
      "citing_paper_id": "234757004",
      "cited_paper_id": 6126582
    },
    {
      "context_text": "Perplexity is used to measure how the outputs ﬁt test data (Vinyals and Le, 2015; Serban et al., 2016).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (perplexity) used to evaluate model performance.",
      "processing_time": 53.105878591537476,
      "citing_paper_id": "234757004",
      "cited_paper_id": 6126582
    },
    {
      "context_text": "14% increase in PC-Score, similar to Li et al. (2016b). However, because the user set is quite large, the performance",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a performance metric and a reference to a user set size. There are no clear identifiers for datasets.",
      "processing_time": 54.95698642730713,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7287895
    },
    {
      "context_text": "With the development of recent large scale social media data and the success of sequence to sequence framework (Serban et al., 2016; Shang et al., 2015; Sutskever et al., 2014), several personalized response generation models have been proposed, and we can only mention a few here due to space limits.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and frameworks. There are no clear identifiers for datasets.",
      "processing_time": 54.062171459198,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7356547
    },
    {
      "context_text": "…the development of recent large scale social media data and the success of sequence to sequence framework (Serban et al., 2016; Shang et al., 2015; Sutskever et al., 2014), several personalized response generation models have been proposed, and we can only mention a few here due to space limits.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to models and frameworks. No verifiable resources are identified.",
      "processing_time": 53.903918981552124,
      "citing_paper_id": "234757004",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Unlike task-oriented dialog agents that focus on completing specific tasks (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Lowe et al., 2015),",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to task-oriented dialog agents. The cited paper title suggests a potential dataset, but it is not mentioned in the citation context.",
      "processing_time": 55.349048376083374,
      "citing_paper_id": "234757004",
      "cited_paper_id": 8379583
    },
    {
      "context_text": ", 2019) for evaluation (Serban et al., 2016; Xing et al., 2018).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other papers. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.578988790512085,
      "citing_paper_id": "234757004",
      "cited_paper_id": 14247119
    },
    {
      "context_text": "Kottur et al. (2017) further extended these speaker models into multi-turn conversations.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an extension of speaker models into multi-turn conversations.",
      "processing_time": 52.78591704368591,
      "citing_paper_id": "234757004",
      "cited_paper_id": 20956365
    },
    {
      "context_text": "To evaluate persona consistency between user comments and generated sentences, Madotto et al. proposed consistency C score using sequence classiﬁcation model trained on Dialog NLI dataset (Welleck et al., 2019), a corpus based on Persona dataset, with NLI annotation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Dialog NLI dataset",
        "Persona dataset"
      ],
      "dataset_descriptions": {
        "Dialog NLI dataset": "Used to train a sequence classification model for evaluating persona consistency between user comments and generated sentences, focusing on natural language inference annotations.",
        "Persona dataset": "Provided the basis for the Dialog NLI dataset, containing persona information used to annotate natural language inference examples."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'Dialog NLI dataset' and the 'Persona dataset'. Both are specific datasets used for training a sequence classification model to evaluate persona consistency.",
      "processing_time": 68.19648051261902,
      "citing_paper_id": "234757004",
      "cited_paper_id": 53298765
    },
    {
      "context_text": "…between generated sentences and given user comments, Madotto et al. proposed consistency score using NLI models pre-trained on Dialog NLI dataset (Welleck et al., 2019), which is a corpus based on Persona dataset, with NLI annotation be-tween persona description sentences and dialogues utterance.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Dialog NLI dataset"
      ],
      "dataset_descriptions": {
        "Dialog NLI dataset": "Used to train NLI models for evaluating consistency between generated sentences and user comments, focusing on natural language inference in dialogue contexts."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions the Dialog NLI dataset, which is a corpus used for training NLI models. It is derived from the Persona dataset, but the Persona dataset itself is not directly used in this research.",
      "processing_time": 63.858360290527344,
      "citing_paper_id": "234757004",
      "cited_paper_id": 53298765
    },
    {
      "context_text": "We used AdamW (Loshchilov and Hutter, 2018) as our optimizer with an initial learning rate of 5e-5 and a linear decay learning rate schedule.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions AdamW as an optimizer, which is a method, not a dataset. No datasets are mentioned.",
      "processing_time": 53.50952363014221,
      "citing_paper_id": "234757004",
      "cited_paper_id": 53592270
    },
    {
      "context_text": ", 2016b) and PersonalDialog dataset (Zheng et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PersonalDialog dataset"
      ],
      "dataset_descriptions": {
        "PersonalDialog dataset": "Used to generate personalized dialogues with diversified traits, focusing on enhancing conversational diversity and personalization in chatbot interactions."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'PersonalDialog dataset' which is a specific, verifiable dataset used in personalized dialogue generation research.",
      "processing_time": 59.35411977767944,
      "citing_paper_id": "234757004",
      "cited_paper_id": 59316441
    },
    {
      "context_text": "The PersonalDialog dataset (PD) (Zheng et al., 2020), collected from a Chinese social media Weibo, con-",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PersonalDialog"
      ],
      "dataset_descriptions": {
        "PersonalDialog": "Used to generate personalized dialogues, focusing on diversified traits in conversations collected from Chinese social media Weibo."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset, PersonalDialog (PD), which is used for personalized dialogue generation. The dataset is clearly identified and its source is specified.",
      "processing_time": 60.05965971946716,
      "citing_paper_id": "234757004",
      "cited_paper_id": 59316441
    },
    {
      "context_text": "Models with lower perplexity scores are found to demonstrate better performance to generate grammatical and fluent responses (Xie et al., 2019; Zheng et al., 2020).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their performance metrics. The context is about evaluating model performance, not using a particular dataset.",
      "processing_time": 54.88149285316467,
      "citing_paper_id": "234757004",
      "cited_paper_id": 59316441
    },
    {
      "context_text": "ating personalization, Zheng et al. (2020) proposed to measure the accuracy of predicting personality traits by firstly training classifiers for different personality traits such as gender and age.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of training classifiers for personality traits. No verifiable resource names are provided.",
      "processing_time": 54.443949460983276,
      "citing_paper_id": "234757004",
      "cited_paper_id": 59316441
    },
    {
      "context_text": "• Generative Memory Network w/ Profile: We designed a memory network model to incorporate user profiles P by doing attention over user attributes (Zheng et al., 2020) .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for incorporating user profiles into a generative memory network.",
      "processing_time": 53.5549955368042,
      "citing_paper_id": "234757004",
      "cited_paper_id": 59316441
    },
    {
      "context_text": "PD denotes the PersonalDialog dataset (Zheng et al., 2020).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PersonalDialog"
      ],
      "dataset_descriptions": {
        "PersonalDialog": "Used to generate personalized dialogues with diversified traits, focusing on enhancing conversational diversity and personalization in dialogue systems."
      },
      "confidence_score": 1.0,
      "reasoning": "The context clearly identifies 'PersonalDialog' as a dataset, which is used for personalized dialogue generation.",
      "processing_time": 58.3901481628418,
      "citing_paper_id": "234757004",
      "cited_paper_id": 59316441
    },
    {
      "context_text": "Recently, there are a few works using meta-learning and re-inforcement learning to enhance mutual persona perception Madotto et al. (2019); Kim et al. (2020); Majumder et al. (2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches. No dataset names are present in the text.",
      "processing_time": 53.88495349884033,
      "citing_paper_id": "234757004",
      "cited_paper_id": 165163819
    },
    {
      "context_text": "We only released raw data from pushshift.io( Baumgartner et al. (2020)), and open-sourced our scripts for preprocessing user attributes and models for reproducibility.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Pushshift Reddit Dataset"
      ],
      "dataset_descriptions": {
        "Pushshift Reddit Dataset": "Used to provide raw data for preprocessing user attributes, supporting reproducibility of models and scripts in the study."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'raw data from pushshift.io', which is a specific dataset. The cited paper title confirms it is a dataset.",
      "processing_time": 60.49470114707947,
      "citing_paper_id": "234757004",
      "cited_paper_id": 210868223
    },
    {
      "context_text": "Detoxification methods in QAC can be broadly classified into three categories: rule-based methods [6, 13, 16, 38], learning-based approaches [4, 13, 18, 37, 44], and reinforcement learning-based techniques [28, 29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of detoxification methods in QAC. No verifiable resources are identified.",
      "processing_time": 54.51579308509827,
      "citing_paper_id": "278912096",
      "cited_paper_id": 273563
    },
    {
      "context_text": "Detoxification methods in QAC can be broadly classified into three categories: rule-based methods [6, 13, 16, 38], learning-based approaches [4, 13, 18, 37, 44], and reinforcement learning-based techniques [28, 29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of detoxification methods in QAC. No verifiable resources are identified.",
      "processing_time": 54.51579308509827,
      "citing_paper_id": "278912096",
      "cited_paper_id": 220486718
    },
    {
      "context_text": "Detoxification methods in QAC can be broadly classified into three categories: rule-based methods [6, 13, 16, 38], learning-based approaches [4, 13, 18, 37, 44], and reinforcement learning-based techniques [28, 29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of detoxification methods in QAC. No verifiable resources are identified.",
      "processing_time": 54.51579308509827,
      "citing_paper_id": "278912096",
      "cited_paper_id": 269565799
    },
    {
      "context_text": "Detoxification methods in QAC can be broadly classified into three categories: rule-based methods [6, 13, 16, 38], learning-based approaches [4, 13, 18, 37, 44], and reinforcement learning-based techniques [28, 29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of detoxification methods in QAC. No verifiable resources are identified.",
      "processing_time": 54.51579308509827,
      "citing_paper_id": "278912096",
      "cited_paper_id": null
    },
    {
      "context_text": "Detoxification methods in QAC can be broadly classified into three categories: rule-based methods [6, 13, 16, 38], learning-based approaches [4, 13, 18, 37, 44], and reinforcement learning-based techniques [28, 29].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only categories of detoxification methods in QAC. No verifiable resources are identified.",
      "processing_time": 54.51579308509827,
      "citing_paper_id": "278912096",
      "cited_paper_id": null
    },
    {
      "context_text": "In detail, we compare our model with statistical methods such as MPC [3], generative models that do not incorporate personalized capturing, like Gen [32], and generative models that introduce personalized capturing but lack hierarchical capturing, such as and Trie-NLG [31].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 53.553895711898804,
      "citing_paper_id": "278912096",
      "cited_paper_id": 1623913
    },
    {
      "context_text": "In detail, we compare our model with statistical methods such as MPC [3], generative models that do not incorporate personalized capturing, like Gen [32], and generative models that introduce personalized capturing but lack hierarchical capturing, such as and Trie-NLG [31].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 53.553895711898804,
      "citing_paper_id": "278912096",
      "cited_paper_id": 221012566
    },
    {
      "context_text": "In detail, we compare our model with statistical methods such as MPC [3], generative models that do not incorporate personalized capturing, like Gen [32], and generative models that introduce personalized capturing but lack hierarchical capturing, such as and Trie-NLG [31].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 53.553895711898804,
      "citing_paper_id": "278912096",
      "cited_paper_id": null
    },
    {
      "context_text": "Early methods for QAC relied on association rules [11] and co-occurrence information [10, 17] such as Most Popular Completion (MPC) [3] which suggests the most popular queries starting with the given prefix.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.63532328605652,
      "citing_paper_id": "278912096",
      "cited_paper_id": 1623913
    },
    {
      "context_text": "Early methods for QAC relied on association rules [11] and co-occurrence information [10, 17] such as Most Popular Completion (MPC) [3] which suggests the most popular queries starting with the given prefix.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.63532328605652,
      "citing_paper_id": "278912096",
      "cited_paper_id": 5077306
    },
    {
      "context_text": "Early methods for QAC relied on association rules [11] and co-occurrence information [10, 17] such as Most Popular Completion (MPC) [3] which suggests the most popular queries starting with the given prefix.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.63532328605652,
      "citing_paper_id": "278912096",
      "cited_paper_id": 9522695
    },
    {
      "context_text": "In contrast to previous methods relying on a query candidate pool, sequence-to-sequence generation methods are applied in query auto-completion [8, 40], leading to better handling of unseen prefixes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. The context focuses on the application of sequence-to-sequence generation methods in query auto-completion.",
      "processing_time": 55.4941725730896,
      "citing_paper_id": "278912096",
      "cited_paper_id": 5045941
    },
    {
      "context_text": "The details of BLEU can be found in Papineni et al.’s work [34].",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions BLEU, which is a metric, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 53.86518955230713,
      "citing_paper_id": "278912096",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "Some studies have focused on detoxification in free-form generation by detoxifying clean datasets [15, 30], refining the decoding process [5, 24], or employing reinforcement learning-based approaches [27, 41].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. No verifiable resources are identified.",
      "processing_time": 54.061994791030884,
      "citing_paper_id": "278912096",
      "cited_paper_id": 208617790
    },
    {
      "context_text": "Some studies have focused on detoxification in free-form generation by detoxifying clean datasets [15, 30], refining the decoding process [5, 24], or employing reinforcement learning-based approaches [27, 41].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. No verifiable resources are identified.",
      "processing_time": 54.061994791030884,
      "citing_paper_id": "278912096",
      "cited_paper_id": 259064099
    },
    {
      "context_text": "Some studies have focused on detoxification in free-form generation by detoxifying clean datasets [15, 30], refining the decoding process [5, 24], or employing reinforcement learning-based approaches [27, 41].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. No verifiable resources are identified.",
      "processing_time": 54.061994791030884,
      "citing_paper_id": "278912096",
      "cited_paper_id": null
    },
    {
      "context_text": "There are also some works that focus on non-toxic text generation for long texts by detoxifying clean datasets [15], refining the decoding process [5, 24], or introducing reinforcement learning based approaches [27, 41].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods and approaches for non-toxic text generation.",
      "processing_time": 53.86016011238098,
      "citing_paper_id": "278912096",
      "cited_paper_id": 208617790
    },
    {
      "context_text": "There are also some works that focus on non-toxic text generation for long texts by detoxifying clean datasets [15], refining the decoding process [5, 24], or introducing reinforcement learning based approaches [27, 41].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods and approaches for non-toxic text generation.",
      "processing_time": 53.86016011238098,
      "citing_paper_id": "278912096",
      "cited_paper_id": 259064099
    },
    {
      "context_text": "Some attempts [6, 16] have fallen short of meeting the requirements for flexible prefixes, while others [28, 29] tend to produce unrelated, non-toxic text.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to other works that discuss challenges in generating text with flexible prefixes and producing non-toxic text.",
      "processing_time": 55.06340289115906,
      "citing_paper_id": "278912096",
      "cited_paper_id": 220486718
    },
    {
      "context_text": "Some attempts [6, 16] have fallen short of meeting the requirements for flexible prefixes, while others [28, 29] tend to produce unrelated, non-toxic text.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to other works that discuss challenges in generating text with flexible prefixes and producing non-toxic text.",
      "processing_time": 55.06340289115906,
      "citing_paper_id": "278912096",
      "cited_paper_id": 269565799
    },
    {
      "context_text": "As for the solution to detoxifying QAC, traditional methods involve user feedback, filter toxic contents by the rule or conduct generation upon limited query templates [6, 13, 16, 38].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.887065410614014,
      "citing_paper_id": "278912096",
      "cited_paper_id": 220486718
    },
    {
      "context_text": "As for the solution to detoxifying QAC, traditional methods involve user feedback, filter toxic contents by the rule or conduct generation upon limited query templates [6, 13, 16, 38].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.887065410614014,
      "citing_paper_id": "278912096",
      "cited_paper_id": null
    },
    {
      "context_text": "As for the solution to detoxifying QAC, traditional methods involve user feedback, filter toxic contents by the rule or conduct generation upon limited query templates [6, 13, 16, 38].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods and approaches. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.887065410614014,
      "citing_paper_id": "278912096",
      "cited_paper_id": null
    },
    {
      "context_text": "The recent development of the generative pre-trained language model [1, 46] has inspired a new surge of interest in QAC generation [14, 26, 28, 45].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to generative pre-trained language models and QAC generation. No verifiable resources are identified.",
      "processing_time": 55.20512819290161,
      "citing_paper_id": "278912096",
      "cited_paper_id": 220730038
    },
    {
      "context_text": "The recent development of the generative pre-trained language model [1, 46] has inspired a new surge of interest in QAC generation [14, 26, 28, 45].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to generative pre-trained language models and QAC generation. No verifiable resources are identified.",
      "processing_time": 55.20512819290161,
      "citing_paper_id": "278912096",
      "cited_paper_id": 265150332
    },
    {
      "context_text": "To characterize personalized features, some previous studies [2, 45, 46] tried to encode the user’s behavior into a vector and then feed it into a decoder.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach to encoding user behavior. No verifiable resources are identified.",
      "processing_time": 54.34042000770569,
      "citing_paper_id": "278912096",
      "cited_paper_id": 220730038
    },
    {
      "context_text": "Traditional methods [2, 45, 46] address this factor in a coarse-grained manner by encoding all behaviors into one or several vectors, which are then used for decoding.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general methods for encoding behaviors. No verifiable resources are identified.",
      "processing_time": 54.337937355041504,
      "citing_paper_id": "278912096",
      "cited_paper_id": 220730038
    },
    {
      "context_text": "Inspired by the success of the attention mechanism [19, 39] in various NLP tasks, transformer-based QAC models [32, 45] have been shown to be more robust to noise and can generate more diverse results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 54.68136715888977,
      "citing_paper_id": "278912096",
      "cited_paper_id": 221012566
    },
    {
      "context_text": "Inspired by the success of the attention mechanism [19, 39] in various NLP tasks, transformer-based QAC models [32, 45] have been shown to be more robust to noise and can generate more diverse results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional dataset information.",
      "processing_time": 54.68136715888977,
      "citing_paper_id": "278912096",
      "cited_paper_id": 237941022
    },
    {
      "context_text": "We adopt an encoder-decoder architecture [32] as the core implementation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an architectural choice.",
      "processing_time": 52.68408465385437,
      "citing_paper_id": "278912096",
      "cited_paper_id": 221012566
    },
    {
      "context_text": "In other fields, capturing approaches vary: some [43] model the same sequence twice, while others [42] incorporate short-term pattern capture within the decoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only modeling approaches. No verifiable resources are identified.",
      "processing_time": 53.854475259780884,
      "citing_paper_id": "278912096",
      "cited_paper_id": 224280529
    },
    {
      "context_text": "In other fields, capturing approaches vary: some [43] model the same sequence twice, while others [42] incorporate short-term pattern capture within the decoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only modeling approaches. No verifiable resources are identified.",
      "processing_time": 53.854475259780884,
      "citing_paper_id": "278912096",
      "cited_paper_id": 236150308
    },
    {
      "context_text": "The GLM can be implemented in two architectures: an encoder-decoder [25] model and a decoder-only [9] model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model architectures. There are no verifiable resources that meet the criteria.",
      "processing_time": 54.34291625022888,
      "citing_paper_id": "278912096",
      "cited_paper_id": 228954221
    },
    {
      "context_text": "Some other works [1, 31] introduced additional knowledge from common web-pages or candidate queries.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to 'common web-pages or candidate queries'. No clear, verifiable datasets are identified.",
      "processing_time": 55.47594499588013,
      "citing_paper_id": "278912096",
      "cited_paper_id": 265150332
    },
    {
      "context_text": "Some other works [1, 31] introduced additional knowledge from common web-pages or candidate queries.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to 'common web-pages or candidate queries'. No clear, verifiable datasets are identified.",
      "processing_time": 55.47594499588013,
      "citing_paper_id": "278912096",
      "cited_paper_id": null
    },
    {
      "context_text": "Recent study [28, 29] can generate non-toxic queries without considering the relevance between the prefix and the completions (i.e. the model tends to generate irrelevant completions when the prefix is toxic).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model for detoxifying query auto-completion.",
      "processing_time": 54.46566414833069,
      "citing_paper_id": "278912096",
      "cited_paper_id": 269565799
    },
    {
      "context_text": "But the provided queries should literally be related to prefix, contain fewer grammatical and spelling errors, and avoid politically or sexually sensitive content (which can be defined as detoxification [28, 29]).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a concept of detoxification which is not a dataset.",
      "processing_time": 54.66392159461975,
      "citing_paper_id": "278912096",
      "cited_paper_id": 269565799
    },
    {
      "context_text": "Currently, numerous studies in the QAC field are conducted us-ing offline datasets [29] or through nearline experiments [45].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The citation mentions 'offline datasets' but does not provide specific names or identifiers. The term is too generic and lacks the necessary specificity to be included.",
      "processing_time": 56.04528546333313,
      "citing_paper_id": "278912096",
      "cited_paper_id": 269565799
    },
    {
      "context_text": "In QAC industry applications, the standard approach to handling toxic candidate queries involves leveraging a discriminative model or a grammatical error correction model [20, 21] for post-processing.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods. The context focuses on the use of models for post-processing in QAC industry applications.",
      "processing_time": 55.732688426971436,
      "citing_paper_id": "278912096",
      "cited_paper_id": 269761580
    },
    {
      "context_text": "To improve the grasp of user search intent, personalized information is brought into play such as search session information [31] and user behavior [2].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts like 'search session information' and 'user behavior'. No verifiable resources are identified.",
      "processing_time": 55.51149106025696,
      "citing_paper_id": "278912096",
      "cited_paper_id": null
    },
    {
      "context_text": "(2) LDPO exceeds LaD w/o AD by 0.0563 and 8.3 % in UAmaxT and UProb, demonstrating the detoxification capabilities of DPO-related methods.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only performance metrics and methods. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 55.505165815353394,
      "citing_paper_id": "278912096",
      "cited_paper_id": null
    },
    {
      "context_text": "This is different from DPO-related algorithms [22, 36], which require the generated result to be relatively better than the reference model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison to DPO-related algorithms. There are no verifiable resources or datasets mentioned.",
      "processing_time": 55.50281763076782,
      "citing_paper_id": "278912096",
      "cited_paper_id": null
    },
    {
      "context_text": "STSB is a collection of English datasets, which have been utilized in the *SEM and SemEval STS shared tasks spanning from 2012 to 2017 [44].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "STSB"
      ],
      "dataset_descriptions": {
        "STSB": "Used in SEM and SemEval STS shared tasks from 2012 to 2017, focusing on semantic textual similarity across multiple languages and years."
      },
      "confidence_score": 0.9,
      "reasoning": "STSB is mentioned as a collection of datasets used in SEM and SemEval STS shared tasks, which aligns with the criteria for a dataset.",
      "processing_time": 64.61636471748352,
      "citing_paper_id": "277596340",
      "cited_paper_id": 4421747
    },
    {
      "context_text": "1) Dataset: The Semantic Textual Similarity Benchmark (STSB) [44] is selected in this section as it provides a wide range of human annotation scores rather than limiting the annotations to binary or categorical labels.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Semantic Textual Similarity Benchmark (STSB)"
      ],
      "dataset_descriptions": {
        "Semantic Textual Similarity Benchmark (STSB)": "Used to evaluate semantic textual similarity with a wide range of human annotation scores, providing nuanced data for training and evaluating personalized text generation models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the STSB dataset, which is used for semantic textual similarity tasks. It is relevant to personalized text generation as it involves human annotations of text similarity.",
      "processing_time": 66.82490921020508,
      "citing_paper_id": "277596340",
      "cited_paper_id": 4421747
    },
    {
      "context_text": "The evaluation rubrics from established Semantic Textual Similarity (STS) literature such as [4], [43], [44] are used in the Initial Prompt: • 0 means the the pair of texts are on different topics; • 0.2 means the the pair of texts are not equivalent, but are on the same topic; • 0.4 means the the…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'established Semantic Textual Similarity (STS) literature' but does not specify any particular dataset names. The cited papers are about STS tasks but do not provide specific dataset names in the given context.",
      "processing_time": 58.4550998210907,
      "citing_paper_id": "277596340",
      "cited_paper_id": 4421747
    },
    {
      "context_text": "The evaluation rubrics from established Semantic Textual Similarity (STS) literature such as [4], [43], [44] are used in the Initial Prompt: • 0 means the the pair of texts are on different topics; • 0.2 means the the pair of texts are not equivalent, but are on the same topic; • 0.4 means the the…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'established Semantic Textual Similarity (STS) literature' but does not specify any particular dataset names. The cited papers are about STS tasks but do not provide specific dataset names in the given context.",
      "processing_time": 58.4550998210907,
      "citing_paper_id": "277596340",
      "cited_paper_id": 10241043
    },
    {
      "context_text": "The development of semantic text embedding models, including Bidirectional Encoder Representations from Transformers (BERT) [13], has facilitated the development of embedding-based metrics like BERTScore [14].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and metrics. BERT and BERTScore are excluded as they are models/metrics, not datasets.",
      "processing_time": 56.255841970443726,
      "citing_paper_id": "277596340",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "The Instruct-QA dataset encompasses three different information-seeking Question-Answering tasks (the overall statistics of these three datasets are shown in Table I.), including: • Open-domain QA task: Natural Questions dataset [46] with queries from Google search engine.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Instruct-QA dataset",
        "Natural Questions dataset"
      ],
      "dataset_descriptions": {
        "Instruct-QA dataset": "Used to encompass three information-seeking QA tasks, including open-domain QA, to evaluate and train models on diverse question types.",
        "Natural Questions dataset": "Used as part of the open-domain QA task within the Instruct-QA dataset, providing queries from the Google search engine for training and evaluation."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the 'Instruct-QA dataset' and the 'Natural Questions dataset'. Both are specific datasets used in the research.",
      "processing_time": 69.97505354881287,
      "citing_paper_id": "277596340",
      "cited_paper_id": 173990818
    },
    {
      "context_text": "LLMs exhibit instruction following and in-context learning capabilities, enabling them to perform designated tasks by interpreting examples or instructions embedded within prompts, without necessitating weight updates or retraining [35].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the capabilities of large language models. No verifiable resources are identified.",
      "processing_time": 55.01674556732178,
      "citing_paper_id": "277596340",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "RAGs based on a standardized prompt template are used to generate the answers for the queries with 4 different LLMs including FlanT5-xxl [48] with 11B parameters, Alpaca-7b [49], GPT3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their parameters. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 55.40303325653076,
      "citing_paper_id": "277596340",
      "cited_paper_id": 253018554
    },
    {
      "context_text": "The extensive use of generative models like GPT [16] has further highlighted the capabilities of LLMs in various aspects, including natural language understanding, instruction-following, and in-context learning [2], [4].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only generative models and their capabilities. No verifiable resources are identified.",
      "processing_time": 54.8614342212677,
      "citing_paper_id": "277596340",
      "cited_paper_id": 257532815
    },
    {
      "context_text": "The extensive use of generative models like GPT [16] has further highlighted the capabilities of LLMs in various aspects, including natural language understanding, instruction-following, and in-context learning [2], [4].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only generative models and their capabilities. No verifiable resources are identified.",
      "processing_time": 54.8614342212677,
      "citing_paper_id": "277596340",
      "cited_paper_id": 270226640
    },
    {
      "context_text": "In [40] the authors propose to prompt LLMs to retrieve appropriate demonstrations based on the candidates’ relevance in solving specific problems.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for prompting LLMs. There are no clear identifiers for datasets in the context.",
      "processing_time": 55.32444667816162,
      "citing_paper_id": "277596340",
      "cited_paper_id": 258564230
    },
    {
      "context_text": "For instance, INSTRUCTSCORE [7] aims to produce high-quality scores and detailed diagnostic reports for candidate texts by iteratively fine-tuning the 7B LLaMA model [30] using both explicit human instructions and automatic feedback from GPT-4 on identified failure modes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The focus is on the INSTRUCTSCORE system and its use of LLaMA and GPT-4.",
      "processing_time": 56.46848106384277,
      "citing_paper_id": "277596340",
      "cited_paper_id": 258841553
    },
    {
      "context_text": "However, the automatic evaluation of text generation quality across diverse tasks, especially for free-form text responses, remains a significant challenge [1], [7], [8].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the challenge of evaluating text generation quality.",
      "processing_time": 53.80276679992676,
      "citing_paper_id": "277596340",
      "cited_paper_id": 258841553
    },
    {
      "context_text": "More importantly, prompting strategies can serve as effective tools in mitigating inherent biases [23].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to 'prompting strategies'. No verifiable resources are identified.",
      "processing_time": 55.08479046821594,
      "citing_paper_id": "277596340",
      "cited_paper_id": 259129398
    },
    {
      "context_text": "LLM-as-a-Judge frameworks have been used to evaluate various Natural Language Processing (NLP) and Natural Language Understanding (NLU) tasks including Retrieval-Augmented Generation (RAG) [20], code comprehension [21], machine translation [22] and more general open-ended tasks [23].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only tasks and frameworks. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 55.23636865615845,
      "citing_paper_id": "277596340",
      "cited_paper_id": 259129398
    },
    {
      "context_text": "LLM-as-a-Judge frameworks have been used to evaluate various Natural Language Processing (NLP) and Natural Language Understanding (NLU) tasks including Retrieval-Augmented Generation (RAG) [20], code comprehension [21], machine translation [22] and more general open-ended tasks [23].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only tasks and frameworks. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 55.23636865615845,
      "citing_paper_id": "277596340",
      "cited_paper_id": 260379087
    },
    {
      "context_text": "LLM-as-a-Judge frameworks have been used to evaluate various Natural Language Processing (NLP) and Natural Language Understanding (NLU) tasks including Retrieval-Augmented Generation (RAG) [20], code comprehension [21], machine translation [22] and more general open-ended tasks [23].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only tasks and frameworks. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 55.23636865615845,
      "citing_paper_id": "277596340",
      "cited_paper_id": 269188036
    },
    {
      "context_text": "[37] proposes capturing human preferences through human-provided labels, querying LLMs to draft initial scoring criteria via in-context learning, and refining the best-performing criteria through self-improvement.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for capturing human preferences and refining scoring criteria using LLMs.",
      "processing_time": 54.937309980392456,
      "citing_paper_id": "277596340",
      "cited_paper_id": 262464745
    },
    {
      "context_text": "Supervised fine-tuning (SFT) is a widely used method to enhance the evaluation abilities of judge LLMs [27]–[29].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (SFT) for enhancing judge LLMs. No verifiable resources are identified.",
      "processing_time": 55.33255648612976,
      "citing_paper_id": "277596340",
      "cited_paper_id": 263829791
    },
    {
      "context_text": "However, even advanced LLMs such as GPT4 encounter challenges like conceptual confusion [26].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a challenge faced by LLMs. The cited paper title suggests a focus on evaluation criteria for NLG, which does not indicate the use of a specific dataset.",
      "processing_time": 58.128565311431885,
      "citing_paper_id": "277596340",
      "cited_paper_id": 267750948
    },
    {
      "context_text": "For improving the quality of hallucination judges, Wang et al. [33] propose to use both supervised fine-tuning and fine-tuning with Directed Preference Optimization (DPO) [34] in a multiple-evidence setting.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches. The context focuses on the use of supervised fine-tuning and DPO in a multiple-evidence setting.",
      "processing_time": 56.495938301086426,
      "citing_paper_id": "277596340",
      "cited_paper_id": 271270693
    },
    {
      "context_text": "Additionally, Jung et al. [42] propose the Cascaded Selective Evaluation method, which begins with a smaller, cost-effective model to make initial judgments, assesses its confidence, and escalates to a stronger model only when necessary.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating models.",
      "processing_time": 53.27825450897217,
      "citing_paper_id": "277596340",
      "cited_paper_id": 271516195
    },
    {
      "context_text": "Among these, the most adopted are RAGAS [18] and Continuous-Eval (CE) [19].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods or tools. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 54.37168502807617,
      "citing_paper_id": "277596340",
      "cited_paper_id": null
    },
    {
      "context_text": "2) Experimental protocol: In this study, we select two widely used LLM-as-a-judge frameworks as our baselines: RAGAS [18] and Continuous-Eval (CE) [19].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only frameworks used as baselines. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 54.9111111164093,
      "citing_paper_id": "277596340",
      "cited_paper_id": null
    },
    {
      "context_text": "Several LLM-as-a-Judge frameworks, such as RAGAS [18] and Continuous-Eval (CE) [19], have gained widespread adoption for the evaluation of Question Answering (QA) systems.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only frameworks for evaluating QA systems. There are no verifiable resources that meet the criteria.",
      "processing_time": 54.522379875183105,
      "citing_paper_id": "277596340",
      "cited_paper_id": null
    },
    {
      "context_text": "We used BLSTM as the embedding-to-FPtag model and set the number of hidden layers and hidden size to 1 and 1024, respectively.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (BLSTM) and its configuration. No verifiable resources are identified.",
      "processing_time": 54.214699506759644,
      "citing_paper_id": "247595086",
      "cited_paper_id": 1856462
    },
    {
      "context_text": ", 2020), we use a bidirectional long short-term memory (BLSTM) (Graves and Schmidhuber, 2005) as an embedding-to-FPtag model and a cross entropy loss.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and a method. The context focuses on the use of a BLSTM model and a cross entropy loss function.",
      "processing_time": 56.08452129364014,
      "citing_paper_id": "247595086",
      "cited_paper_id": 1856462
    },
    {
      "context_text": "In this paper, following the previous work of (Yamazaki et al., 2020), we use a bidirectional long short-term memory (BLSTM) (Graves and Schmidhuber, 2005) as an embedding-to-FPtag model and a cross entropy loss.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of BLSTM for an embedding-to-FPtag model.",
      "processing_time": 55.89522337913513,
      "citing_paper_id": "247595086",
      "cited_paper_id": 1856462
    },
    {
      "context_text": "In this paper, following the previous work of (Yamazaki et al., 2020), we use a bidirectional long short-term memory (BLSTM) (Graves and Schmidhuber, 2005) as an embedding-to-FPtag model and a cross entropy loss.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of BLSTM for an embedding-to-FPtag model.",
      "processing_time": 55.89522337913513,
      "citing_paper_id": "247595086",
      "cited_paper_id": 229373521
    },
    {
      "context_text": "In addition, it is known that the position (Shriberg, 1996) and words (Elisabeth, 1994; Watanabe and Shirahata, 2019) of FPs differ from speaker to speaker.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research findings about the position and words of FPs (Filler Phrases) differing from speaker to speaker.",
      "processing_time": 56.7314727306366,
      "citing_paper_id": "247595086",
      "cited_paper_id": 8781744
    },
    {
      "context_text": "In addition, it is known that the position (Shriberg, 1996) and words (Elisabeth, 1994; Watanabe and Shirahata, 2019) of FPs differ from speaker to speaker.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research findings about the position and words of FPs (Filler Phrases) differing from speaker to speaker.",
      "processing_time": 56.7314727306366,
      "citing_paper_id": "247595086",
      "cited_paper_id": 62654138
    },
    {
      "context_text": "Disfluency includes filled pauses (FPs), rephrases, and word fragments (Elisabeth, 1994), and it is known that the tendency to use them varies from speaker to speaker (Shriberg, 1996; Elisabeth, 1994; Watanabe and Shirahata, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses disfluencies in speech but does not mention any specific datasets. The cited papers are theoretical or descriptive studies rather than datasets.",
      "processing_time": 54.42301058769226,
      "citing_paper_id": "247595086",
      "cited_paper_id": 8781744
    },
    {
      "context_text": "Disfluency includes filled pauses (FPs), rephrases, and word fragments (Elisabeth, 1994), and it is known that the tendency to use them varies from speaker to speaker (Shriberg, 1996; Elisabeth, 1994; Watanabe and Shirahata, 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses disfluencies in speech but does not mention any specific datasets. The cited papers are theoretical or descriptive studies rather than datasets.",
      "processing_time": 54.42301058769226,
      "citing_paper_id": "247595086",
      "cited_paper_id": 62654138
    },
    {
      "context_text": "(Tomalin et al., 2015) also predicted FP word and position simultaneously using a lattice-based n-gram model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for predicting filled pause (FP) word and position. No verifiable resources are identified.",
      "processing_time": 55.43132710456848,
      "citing_paper_id": "247595086",
      "cited_paper_id": 15800462
    },
    {
      "context_text": "Disfluency generation aims to generate human-like disfluent texts (Qader et al., 2018; Yang et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of disfluency generation. No verifiable resources are identified.",
      "processing_time": 54.60149145126343,
      "citing_paper_id": "247595086",
      "cited_paper_id": 52956095
    },
    {
      "context_text": "Disfluency generation aims to generate human-like disfluent texts (Qader et al., 2018; Yang et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the concept of disfluency generation. No verifiable resources are identified.",
      "processing_time": 54.60149145126343,
      "citing_paper_id": "247595086",
      "cited_paper_id": 223798991
    },
    {
      "context_text": "(Qader et al., 2018) proposed an algorithm using a probabilistic model to generate disfluent sentences from fluent sentences, but the prediction of FP words is simple.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an algorithm and a method for generating disfluent sentences.",
      "processing_time": 53.77309465408325,
      "citing_paper_id": "247595086",
      "cited_paper_id": 52956095
    },
    {
      "context_text": "They are also important to facilitate communication: speakers can indicate that they are searching for words (Clark and Fox Tree, 2002), and listeners can understand the word quickly (Fox Tree and Schrock, 1999).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to research findings about discourse markers in spontaneous speech.",
      "processing_time": 53.07763385772705,
      "citing_paper_id": "247595086",
      "cited_paper_id": 96426372
    },
    {
      "context_text": "They play an important role in speech generation: planning (Maclay and Osgood, 1959) and monitoring (Levelt, 1983).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to speech generation processes.",
      "processing_time": 52.94844079017639,
      "citing_paper_id": "247595086",
      "cited_paper_id": 204981295
    },
    {
      "context_text": "We construct a model that consists of two modules: a word embedding model and an embedding-to-FPtag model (Yamazaki et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 54.5696120262146,
      "citing_paper_id": "247595086",
      "cited_paper_id": 229373521
    },
    {
      "context_text": "A previous study (Yamazaki et al., 2020) used fastText (Bojanowski et al., 2017), which is a lightweight model that generates word representations, as the word embedding model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions fastText as a word embedding model but does not refer to it as a dataset. No other datasets are mentioned.",
      "processing_time": 54.41477847099304,
      "citing_paper_id": "247595086",
      "cited_paper_id": 229373521
    },
    {
      "context_text": "(Yamazaki et al., 2020) reported that simultaneously predicting positions and words improves performance.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological finding about improving performance in prediction tasks.",
      "processing_time": 53.148481369018555,
      "citing_paper_id": "247595086",
      "cited_paper_id": 229373521
    },
    {
      "context_text": "In this evaluation, for a word embedding model, we used fastText which is the conventional model in (Yamazaki et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'fastText' but it is described as a model, not a dataset. No datasets are explicitly mentioned or used according to the given text.",
      "processing_time": 55.493682861328125,
      "citing_paper_id": "247595086",
      "cited_paper_id": 229373521
    },
    {
      "context_text": "A previous study (Yamazaki et al., 2020) used fastText (Bojanowski et al.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (fastText). The context is too limited to infer the use of a dataset.",
      "processing_time": 54.59817337989807,
      "citing_paper_id": "247595086",
      "cited_paper_id": 229373521
    },
    {
      "context_text": "In addition, a number of studies have created an external module to predict FPs for FP-included speech synthesis (Wester et al., 2015; Gustafson et al., 2021; Cong et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies that created an external module for predicting fillers in speech synthesis.",
      "processing_time": 54.32572078704834,
      "citing_paper_id": "247595086",
      "cited_paper_id": 235490460
    },
    {
      "context_text": "In addition, a number of studies have created an external module to predict FPs for FP-included speech synthesis (Wester et al., 2015; Gustafson et al., 2021; Cong et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to studies that created an external module for predicting fillers in speech synthesis.",
      "processing_time": 54.32572078704834,
      "citing_paper_id": "247595086",
      "cited_paper_id": 238700218
    },
    {
      "context_text": "The use of FPs influences the perception of the speaker’s personality for listeners (Gustafson et al., 2021).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to the influence of fillers on personality perception.",
      "processing_time": 53.34958052635193,
      "citing_paper_id": "247595086",
      "cited_paper_id": 238700218
    },
    {
      "context_text": "Bow-man et al. [22] propose a variation autoencoder (VAE) based method to generate sentences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating sentences using a VAE.",
      "processing_time": 52.97161841392517,
      "citing_paper_id": "256316527",
      "cited_paper_id": 748227
    },
    {
      "context_text": "Personalized opening sentence generation falls into the area of data-to-text generation [9], [12], [14], [15], [21], [22].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research. No dataset names are present in the text.",
      "processing_time": 53.564265966415405,
      "citing_paper_id": "256316527",
      "cited_paper_id": 748227
    },
    {
      "context_text": "Personalized opening sentence generation falls into the area of data-to-text generation [9], [12], [14], [15], [21], [22].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research. No dataset names are present in the text.",
      "processing_time": 53.564265966415405,
      "citing_paper_id": "256316527",
      "cited_paper_id": 13936837
    },
    {
      "context_text": "Personalized opening sentence generation falls into the area of data-to-text generation [9], [12], [14], [15], [21], [22].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research. No dataset names are present in the text.",
      "processing_time": 53.564265966415405,
      "citing_paper_id": "256316527",
      "cited_paper_id": 201070608
    },
    {
      "context_text": "• CoNet [25].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called CoNet. The context is too limited to infer the use of any datasets.",
      "processing_time": 54.02954649925232,
      "citing_paper_id": "256316527",
      "cited_paper_id": 5013313
    },
    {
      "context_text": "We compare our model with three state-of-the-arts where first two do not have topic planning while PHVM does: • Seq2Seq+Attention [27].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (Seq2Seq+Attention).",
      "processing_time": 52.3717885017395,
      "citing_paper_id": "256316527",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "We compare our model with three state-of-the-arts where ﬁrst two do not have topic planning while PHVM does: • Seq2Seq+Attention [27].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (Seq2Seq+Attention).",
      "processing_time": 52.10413837432861,
      "citing_paper_id": "256316527",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "At this time, L KL vanishes and the model cannot generate context-aware sentences [21].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological issue related to model training.",
      "processing_time": 51.916264295578,
      "citing_paper_id": "256316527",
      "cited_paper_id": 13936837
    },
    {
      "context_text": "• CVAE [21].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not provide enough context to identify a specific dataset. The title suggests a method or model rather than a dataset.",
      "processing_time": 53.1234712600708,
      "citing_paper_id": "256316527",
      "cited_paper_id": 13936837
    },
    {
      "context_text": "…follow the design in [21] and use empirical lower bound (ELBO) as the loss: where L SG contains two parts: the loss from KL divergence L KL and, the loss of reconstructing S i based on the context c, i.e. , L pred : We design β as a dynamic weight on L KL for mitigating KL vanishing problem [21].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methodological aspects of the research.",
      "processing_time": 51.72927689552307,
      "citing_paper_id": "256316527",
      "cited_paper_id": 13936837
    },
    {
      "context_text": "For SG, we follow the design in [21] and use empirical lower bound (ELBO) as the loss: where L SG contains two parts: the loss from KL divergence L KL and, the loss of reconstructing S i based on the context c, i.e. , L pred : We design β as a dynamic weight on L KL for mitigating KL vanishing…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the loss function and model design.",
      "processing_time": 51.4910409450531,
      "citing_paper_id": "256316527",
      "cited_paper_id": 13936837
    },
    {
      "context_text": "A follow-up [21] introduces a context prior to generate sentences with given contexts, e.g. , topics.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating sentences with given contexts.",
      "processing_time": 51.870569705963135,
      "citing_paper_id": "256316527",
      "cited_paper_id": 13936837
    },
    {
      "context_text": "As in [21], we design two networks, i.e. , posterior network and prior network, to approximate the posterior q θ ( z | x, c ) and prior p φ ( z | c ) where enc ( S n − 1 ) is the encoded vector of S n − 1 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the design of two networks. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.243004322052,
      "citing_paper_id": "256316527",
      "cited_paper_id": 13936837
    },
    {
      "context_text": "PHVM [14] adapts the model in [21] for generating product descriptions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model adaptation for generating product descriptions.",
      "processing_time": 51.57645034790039,
      "citing_paper_id": "256316527",
      "cited_paper_id": 13936837
    },
    {
      "context_text": "In SG, we design a conditional VAE [21] for sentence generation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (conditional VAE).",
      "processing_time": 51.37154173851013,
      "citing_paper_id": "256316527",
      "cited_paper_id": 13936837
    },
    {
      "context_text": "We build SG on top of a conditional variational autoencoder (CVAE) for its capability to generate controlled sentences [21].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CVAE). The context focuses on the use of CVAE for generating controlled sentences, which is a methodological approach rather than a dataset.",
      "processing_time": 56.43638777732849,
      "citing_paper_id": "256316527",
      "cited_paper_id": 13936837
    },
    {
      "context_text": "Following its design, matrix is designed for both interaction layer and ﬁne-tune MLP. • DDTCTR [26].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or tool (DDTCTR). There are no clear identifiers for datasets in the provided context.",
      "processing_time": 54.35118293762207,
      "citing_paper_id": "256316527",
      "cited_paper_id": 32893704
    },
    {
      "context_text": "This question belongs to the research on data-to-text generation [9]–[13].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general reference to data-to-text generation research.",
      "processing_time": 52.09411334991455,
      "citing_paper_id": "256316527",
      "cited_paper_id": 52153976
    },
    {
      "context_text": "A few [11], [13], [15] generate sentences on multiple topics, yet they arrange topics in a generic order e.g. , for ﬂuency, without considering user-speciﬁc features.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach to generating sentences on multiple topics without user-specific features.",
      "processing_time": 52.79943060874939,
      "citing_paper_id": "256316527",
      "cited_paper_id": 52153976
    },
    {
      "context_text": "A few [11], [13], [15] generate sentences on multiple topics, yet they arrange topics in a generic order e.g. , for ﬂuency, without considering user-speciﬁc features.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach to generating sentences on multiple topics without user-specific features.",
      "processing_time": 52.79943060874939,
      "citing_paper_id": "256316527",
      "cited_paper_id": 201070608
    },
    {
      "context_text": "Other applications of text generation include controllable poetry generation [12], data-to-summary generation [13], etc.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of text generation. No verifiable resources are identified.",
      "processing_time": 52.441938400268555,
      "citing_paper_id": "256316527",
      "cited_paper_id": 52153976
    },
    {
      "context_text": "Many customers are reluctant to inquire on insurance products [6], and a tedious FAQ even scare potential buyers away [7].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses customer behavior regarding insurance products.",
      "processing_time": 52.87098979949951,
      "citing_paper_id": "256316527",
      "cited_paper_id": 64318990
    },
    {
      "context_text": "Many customers are reluctant to inquire on insurance products [6], and a tedious FAQ even scare potential buyers away [7].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only discusses customer behavior regarding insurance products.",
      "processing_time": 52.87098979949951,
      "citing_paper_id": "256316527",
      "cited_paper_id": null
    },
    {
      "context_text": "• BLEU score: it is a widely used metric for measuring the overlap between the ground truth and generated sentences [14], [15].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BLEU score, which is a metric, not a dataset. No datasets are mentioned in the citation span.",
      "processing_time": 52.69822549819946,
      "citing_paper_id": "256316527",
      "cited_paper_id": 201070608
    },
    {
      "context_text": "• Similarity/Coverage: We adopt the metric used in [14], [15] to measure the consistency between (a) predicted topic sequence and the ground truth and (b) generated sentence and the target sentence.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric for measuring consistency. No dataset names are present in the citation span.",
      "processing_time": 53.10174870491028,
      "citing_paper_id": "256316527",
      "cited_paper_id": 201070608
    },
    {
      "context_text": "One is the ads description from [15] and the other is the insurance data collected from an online insurance platform.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions two types of data but does not provide specific, identifiable dataset names. The ads description and insurance data are too generic and lack clear provenance.",
      "processing_time": 54.36399269104004,
      "citing_paper_id": "256316527",
      "cited_paper_id": 201070608
    },
    {
      "context_text": "…user embedding u into the attention unit to calculate the tuned vector, i.e. , Att CMU n Afterwards, the output Att CMU n is concatenated with u and sent into the MLP to calculate the probability on recommended topics, i.e. , Following [11], [15], we use beam search to generate the topic sequence.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the technical details of the model architecture and generation process.",
      "processing_time": 53.53490328788757,
      "citing_paper_id": "256316527",
      "cited_paper_id": 201070608
    },
    {
      "context_text": "• PHVM [15].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation does not provide enough context to identify a specific dataset. The title suggests a method or model rather than a dataset.",
      "processing_time": 52.85520100593567,
      "citing_paper_id": "256316527",
      "cited_paper_id": 201070608
    },
    {
      "context_text": "That is, these auxiliary behaviors on the same online insurance platform share similar user representations and are thus transferable to topic recommendation [16], [17].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only auxiliary behaviors on an online insurance platform. No clear, verifiable dataset names are provided.",
      "processing_time": 53.38210582733154,
      "citing_paper_id": "256316527",
      "cited_paper_id": 235306313
    },
    {
      "context_text": "(ii) Opening sentences is important in promoting ﬁnal conversions (senior agents vs senior agents (controlled)). are crucial to raise user interests, which may eventually convert into sales [8].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only discusses the importance of opening sentences in sales conversations.",
      "processing_time": 52.967637062072754,
      "citing_paper_id": "256316527",
      "cited_paper_id": null
    },
    {
      "context_text": "The insurance industry is increasingly utilizing digital platforms for cost-effective product marketing and sales [1].",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to a general trend in the insurance industry.",
      "processing_time": 52.14160752296448,
      "citing_paper_id": "256316527",
      "cited_paper_id": null
    },
    {
      "context_text": "(3) We measure the degree of factual consistency and the coverage by calculating the mean of ROUGE (Lin, 2004)-1, -2 and -",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric (ROUGE) which is excluded according to the instructions.",
      "processing_time": 52.54005002975464,
      "citing_paper_id": "236460075",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Then injecting the user preferences learned by NAML to the proposed headline generator also gets the highest ROUGE scores with either way of the incorporation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to methods and evaluation metrics but does not cite any dataset by name.",
      "processing_time": 53.609370946884155,
      "citing_paper_id": "236460075",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Then injecting the user preferences learned by NAML to the proposed headline generator also gets the highest ROUGE scores with either way of the incorporation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to methods and evaluation metrics but does not cite any dataset by name.",
      "processing_time": 53.609370946884155,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "Then injecting the user preferences learned by NAML to the proposed headline generator also gets the highest ROUGE scores with either way of the incorporation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to methods and evaluation metrics but does not cite any dataset by name.",
      "processing_time": 53.609370946884155,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "For personalized head-line generation, we evaluate the generation quality using F1 ROUGE (Lin, 2004) 4",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a metric (F1 ROUGE) which is excluded according to the instructions.",
      "processing_time": 53.00320219993591,
      "citing_paper_id": "236460075",
      "cited_paper_id": 964287
    },
    {
      "context_text": "L” indicate F scores of ROUGE-1, -2, and -",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only evaluation metrics (ROUGE-1, ROUGE-2).",
      "processing_time": 52.998292207717896,
      "citing_paper_id": "236460075",
      "cited_paper_id": 964287
    },
    {
      "context_text": "(2) PG+RL-ROUGE (Xu et al., 2019) extends Pointer-Gen with as a reinforcement learning framework which generates sensational headlines by considering ROUGE-L score as rewards.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Pointer-Gen) and a metric (ROUGE-L). The cited papers do not introduce any datasets either.",
      "processing_time": 54.848556995391846,
      "citing_paper_id": "236460075",
      "cited_paper_id": 964287
    },
    {
      "context_text": "(2) PG+RL-ROUGE (Xu et al., 2019) extends Pointer-Gen with as a reinforcement learning framework which generates sensational headlines by considering ROUGE-L score as rewards.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Pointer-Gen) and a metric (ROUGE-L). The cited papers do not introduce any datasets either.",
      "processing_time": 54.848556995391846,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202540017
    },
    {
      "context_text": "Then, proposed methods can take prevailing matching metrics, e.g., ROUGE, BLEU and etc., to verify the performance.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. No datasets are referenced or used in the context provided.",
      "processing_time": 52.99283409118652,
      "citing_paper_id": "236460075",
      "cited_paper_id": 964287
    },
    {
      "context_text": "For personalized headline generation, we evaluate the generation quality using F1 ROUGE (Lin, 2004) 4 including unigram",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a metric (F1 ROUGE) which is excluded. The focus is on evaluating generation quality, not on a dataset.",
      "processing_time": 55.013899087905884,
      "citing_paper_id": "236460075",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Word embeddings are 300 -dimension and initialized by the Glove (Pennington et al., 2014) while the size of position embeddings at sentence level is 100 .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions GloVe but does not indicate it is used as a dataset. It is referenced as a method for initializing word embeddings.",
      "processing_time": 53.19992160797119,
      "citing_paper_id": "236460075",
      "cited_paper_id": 1957433
    },
    {
      "context_text": "10, and Adam (Kingma and Ba, 2014) is used for model optimization where we sample 16 sequences for Monte Carlo search.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only optimization methods and sampling techniques.",
      "processing_time": 51.13612222671509,
      "citing_paper_id": "236460075",
      "cited_paper_id": 6628106
    },
    {
      "context_text": "Among them, content-based recommendations (Okura et al., 2017; Liu et al., 2010; Li et al., 2011; Lian et al., 2018; Wang et al., 2018; Wu et al., 2019a,b) perform user and news matching on a learned hidden space, and user representation is learned based on historical clicked news contents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for personalized news recommendation but does not mention any specific datasets. The focus is on the methodologies and models used for user and news matching.",
      "processing_time": 54.56130385398865,
      "citing_paper_id": "236460075",
      "cited_paper_id": 7299043
    },
    {
      "context_text": "Among them, content-based recommendations (Okura et al., 2017; Liu et al., 2010; Li et al., 2011; Lian et al., 2018; Wang et al., 2018; Wu et al., 2019a,b) perform user and news matching on a learned hidden space, and user representation is learned based on historical clicked news contents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for personalized news recommendation but does not mention any specific datasets. The focus is on the methodologies and models used for user and news matching.",
      "processing_time": 54.56130385398865,
      "citing_paper_id": "236460075",
      "cited_paper_id": 19919625
    },
    {
      "context_text": "Among them, content-based recommendations (Okura et al., 2017; Liu et al., 2010; Li et al., 2011; Lian et al., 2018; Wang et al., 2018; Wu et al., 2019a,b) perform user and news matching on a learned hidden space, and user representation is learned based on historical clicked news contents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for personalized news recommendation but does not mention any specific datasets. The focus is on the methodologies and models used for user and news matching.",
      "processing_time": 54.56130385398865,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "Among them, content-based recommendations (Okura et al., 2017; Liu et al., 2010; Li et al., 2011; Lian et al., 2018; Wang et al., 2018; Wu et al., 2019a,b) perform user and news matching on a learned hidden space, and user representation is learned based on historical clicked news contents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for personalized news recommendation but does not mention any specific datasets. The focus is on the methodologies and models used for user and news matching.",
      "processing_time": 54.56130385398865,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196471084
    },
    {
      "context_text": "Among them, content-based recommendations (Okura et al., 2017; Liu et al., 2010; Li et al., 2011; Lian et al., 2018; Wang et al., 2018; Wu et al., 2019a,b) perform user and news matching on a learned hidden space, and user representation is learned based on historical clicked news contents.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses methods for personalized news recommendation but does not mention any specific datasets. The focus is on the methodologies and models used for user and news matching.",
      "processing_time": 54.56130385398865,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "Recently, stylized headlines generation were proposed to output eye-catching headlines by implicit style transfer (Shen et al., 2017b; Fu et al., 2018; Prabhumoye et al., 2018) or style-oriented super-visions (Shu et al., 2018; Zhang et al., 2018; Xu et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for generating stylized headlines. No verifiable resources are identified.",
      "processing_time": 53.50264549255371,
      "citing_paper_id": "236460075",
      "cited_paper_id": 13959787
    },
    {
      "context_text": "Recently, stylized headlines generation were proposed to output eye-catching headlines by implicit style transfer (Shen et al., 2017b; Fu et al., 2018; Prabhumoye et al., 2018) or style-oriented super-visions (Shu et al., 2018; Zhang et al., 2018; Xu et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and approaches for generating stylized headlines. No verifiable resources are identified.",
      "processing_time": 53.50264549255371,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202540017
    },
    {
      "context_text": "…has been considered as specialized text summarization (Luo et al., 2019; Jia et al., 2020), from which both extractive (Dorr et al., 2003; Alfonseca et al., 2013) and abstrac-tive summarization (Sun et al., 2015; Takase et al., 2016; Tan et al., 2017; Gavrilov et al., 2019; See et al.,…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies and methods. The cited paper title 'HEADY: News headline abstraction through event pattern clustering' suggests a method rather than a dataset.",
      "processing_time": 56.93530774116516,
      "citing_paper_id": "236460075",
      "cited_paper_id": 16997286
    },
    {
      "context_text": "News headline generation (Dorr et al., 2003; Lopy-rev, 2015; Alfonseca et al., 2013; Tan et al., 2017; See et al., 2017; Zhang et al., 2018; Xu et al., 2019; Murao et al., 2019; Gavrilov et al., 2019; Gu et al., 2020; Song et al., 2020), conventionally considered as a paradigm of challenging text…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies on news headline generation. No clear, verifiable datasets are identified.",
      "processing_time": 54.104657888412476,
      "citing_paper_id": "236460075",
      "cited_paper_id": 16997286
    },
    {
      "context_text": "News headline generation (Dorr et al., 2003; Lopy-rev, 2015; Alfonseca et al., 2013; Tan et al., 2017; See et al., 2017; Zhang et al., 2018; Xu et al., 2019; Murao et al., 2019; Gavrilov et al., 2019; Gu et al., 2020; Song et al., 2020), conventionally considered as a paradigm of challenging text…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies on news headline generation. No clear, verifiable datasets are identified.",
      "processing_time": 54.104657888412476,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202540017
    },
    {
      "context_text": "Extractive methods select a subset of actual sentences in original article, which may derive inco-herent summary (Alfonseca et al., 2013).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context is about extractive summarization methods and their potential issues.",
      "processing_time": 54.090977907180786,
      "citing_paper_id": "236460075",
      "cited_paper_id": 16997286
    },
    {
      "context_text": "Under the neural framework, the news representation is usually modeled by a news encoder that encodes news title, news body or other attributes via various neural structures (Okura et al., 2017; Wang et al., 2018; Wu et al., 2019a; An et al., 2019; Wu et al., 2019a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses neural frameworks and news encoders but does not mention any specific datasets. The cited papers' titles also do not provide clear evidence of specific datasets being used.",
      "processing_time": 55.20595955848694,
      "citing_paper_id": "236460075",
      "cited_paper_id": 19919625
    },
    {
      "context_text": "Under the neural framework, the news representation is usually modeled by a news encoder that encodes news title, news body or other attributes via various neural structures (Okura et al., 2017; Wang et al., 2018; Wu et al., 2019a; An et al., 2019; Wu et al., 2019a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses neural frameworks and news encoders but does not mention any specific datasets. The cited papers' titles also do not provide clear evidence of specific datasets being used.",
      "processing_time": 55.20595955848694,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "Under the neural framework, the news representation is usually modeled by a news encoder that encodes news title, news body or other attributes via various neural structures (Okura et al., 2017; Wang et al., 2018; Wu et al., 2019a; An et al., 2019; Wu et al., 2019a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses neural frameworks and news encoders but does not mention any specific datasets. The cited papers' titles also do not provide clear evidence of specific datasets being used.",
      "processing_time": 55.20595955848694,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196186167
    },
    {
      "context_text": "Under the neural framework, the news representation is usually modeled by a news encoder that encodes news title, news body or other attributes via various neural structures (Okura et al., 2017; Wang et al., 2018; Wu et al., 2019a; An et al., 2019; Wu et al., 2019a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses neural frameworks and news encoders but does not mention any specific datasets. The cited papers' titles also do not provide clear evidence of specific datasets being used.",
      "processing_time": 55.20595955848694,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196471084
    },
    {
      "context_text": "Under the neural framework, the news representation is usually modeled by a news encoder that encodes news title, news body or other attributes via various neural structures (Okura et al., 2017; Wang et al., 2018; Wu et al., 2019a; An et al., 2019; Wu et al., 2019a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context discusses neural frameworks and news encoders but does not mention any specific datasets. The cited papers' titles also do not provide clear evidence of specific datasets being used.",
      "processing_time": 55.20595955848694,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "The ﬁrst group consists of various user modeling meth-ods, which are all SOTA neural-based news recommendation methods: (1) EBNR (Okura et al., 2017) learns user representations by aggregating their browsed news with GRU.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (EBNR) and its application in news recommendation. No verifiable dataset names are present.",
      "processing_time": 54.66584396362305,
      "citing_paper_id": "236460075",
      "cited_paper_id": 19919625
    },
    {
      "context_text": "The user representation is generated by engraving the high-level aspects over their clicked news sequences using sequential (Okura et al., 2017; An et al., 2019) or attentive modules (Wu et al., 2019b,a), in which every news is encoded by the news encoder in advance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models for news recommendation. No verifiable resources are identified.",
      "processing_time": 53.416075468063354,
      "citing_paper_id": "236460075",
      "cited_paper_id": 19919625
    },
    {
      "context_text": "The user representation is generated by engraving the high-level aspects over their clicked news sequences using sequential (Okura et al., 2017; An et al., 2019) or attentive modules (Wu et al., 2019b,a), in which every news is encoded by the news encoder in advance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models for news recommendation. No verifiable resources are identified.",
      "processing_time": 53.416075468063354,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "The user representation is generated by engraving the high-level aspects over their clicked news sequences using sequential (Okura et al., 2017; An et al., 2019) or attentive modules (Wu et al., 2019b,a), in which every news is encoded by the news encoder in advance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models for news recommendation. No verifiable resources are identified.",
      "processing_time": 53.416075468063354,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196186167
    },
    {
      "context_text": "The user representation is generated by engraving the high-level aspects over their clicked news sequences using sequential (Okura et al., 2017; An et al., 2019) or attentive modules (Wu et al., 2019b,a), in which every news is encoded by the news encoder in advance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models for news recommendation. No verifiable resources are identified.",
      "processing_time": 53.416075468063354,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196471084
    },
    {
      "context_text": "The user representation is generated by engraving the high-level aspects over their clicked news sequences using sequential (Okura et al., 2017; An et al., 2019) or attentive modules (Wu et al., 2019b,a), in which every news is encoded by the news encoder in advance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models for news recommendation. No verifiable resources are identified.",
      "processing_time": 53.416075468063354,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "Third, it is reported that the second way of injecting user interests gets the best performance on most of the user modeling methods, e.g., EBNR, DKN and NAML.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the performance of user interest injection methods in news recommendation systems.",
      "processing_time": 54.43230986595154,
      "citing_paper_id": "236460075",
      "cited_paper_id": 19919625
    },
    {
      "context_text": "Third, it is reported that the second way of injecting user interests gets the best performance on most of the user modeling methods, e.g., EBNR, DKN and NAML.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the performance of user interest injection methods in news recommendation systems.",
      "processing_time": 54.43230986595154,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "Third, it is reported that the second way of injecting user interests gets the best performance on most of the user modeling methods, e.g., EBNR, DKN and NAML.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the performance of user interest injection methods in news recommendation systems.",
      "processing_time": 54.43230986595154,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "For instance, NAML achieves the best performance in news recommendation by learning news and user representations from multiple views, i.e., obtaining 66 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (NAML) and its performance in news recommendation. No verifiable resources are identified.",
      "processing_time": 54.42914152145386,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "For instance, NAML achieves the best performance in news recommendation by learning news and user representations from multiple views, i.e., obtaining 66 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (NAML) and its performance in news recommendation. No verifiable resources are identified.",
      "processing_time": 54.42914152145386,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "(6) NAML (Wu et al., 2019a) proposes multi-view learning in user representation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or model called NAML. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 54.42229223251343,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "(6) NAML (Wu et al., 2019a) proposes multi-view learning in user representation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or model called NAML. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 54.42229223251343,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196471084
    },
    {
      "context_text": "(6) NAML (Wu et al., 2019a) proposes multi-view learning in user representation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or model called NAML. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 54.42229223251343,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "Deep models (Lian et al., 2018; Wang et al., 2018; Wu et al., 2019b,a), recently, demonstrated significant improvements because of their capabilities in representation learning on both user-side and news-side data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only deep models and their capabilities in representation learning. No verifiable resources are identified.",
      "processing_time": 53.76795506477356,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "Deep models (Lian et al., 2018; Wang et al., 2018; Wu et al., 2019b,a), recently, demonstrated significant improvements because of their capabilities in representation learning on both user-side and news-side data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only deep models and their capabilities in representation learning. No verifiable resources are identified.",
      "processing_time": 53.76795506477356,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196471084
    },
    {
      "context_text": "Deep models (Lian et al., 2018; Wang et al., 2018; Wu et al., 2019b,a), recently, demonstrated significant improvements because of their capabilities in representation learning on both user-side and news-side data.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only deep models and their capabilities in representation learning. No verifiable resources are identified.",
      "processing_time": 53.76795506477356,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "Table 3: A case study on personalized headline generation for two different users by personalized (NAML+HG) and non-personalized (Pointer-Gen).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on comparing personalized and non-personalized headline generation approaches.",
      "processing_time": 54.6820547580719,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "Table 3: A case study on personalized headline generation for two different users by personalized (NAML+HG) and non-personalized (Pointer-Gen).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on comparing personalized and non-personalized headline generation approaches.",
      "processing_time": 54.6820547580719,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "Uruguay v. Peru, Copa America and Gold Cup, Game threads and how to watch user B written headline : Venezuelan migrants to Peru face danger and discrimination NAML+HG for user B : Stricter entry requirements on Venezuelan migrants and refugees .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only news headlines and user-generated content. The cited papers are about neural news recommendation systems, which do not introduce specific datasets.",
      "processing_time": 55.40928387641907,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "Uruguay v. Peru, Copa America and Gold Cup, Game threads and how to watch user B written headline : Venezuelan migrants to Peru face danger and discrimination NAML+HG for user B : Stricter entry requirements on Venezuelan migrants and refugees .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only news headlines and user-generated content. The cited papers are about neural news recommendation systems, which do not introduce specific datasets.",
      "processing_time": 55.40928387641907,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "(4) NRMS (Wu et al., 2019c) conducts neural news recommendation with multi-head self-attention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (NRMS) and its application in neural news recommendation, but does not specify any dataset. The context is focused on the method itself rather than a dataset.",
      "processing_time": 56.20682883262634,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "(4) NRMS (Wu et al., 2019c) conducts neural news recommendation with multi-head self-attention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (NRMS) and its application in neural news recommendation, but does not specify any dataset. The context is focused on the method itself rather than a dataset.",
      "processing_time": 56.20682883262634,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196471084
    },
    {
      "context_text": "(4) NRMS (Wu et al., 2019c) conducts neural news recommendation with multi-head self-attention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (NRMS) and its application in neural news recommendation, but does not specify any dataset. The context is focused on the method itself rather than a dataset.",
      "processing_time": 56.20682883262634,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "(3) NPA (Wu et al., 2019b) proposes personalized attention module in both news and user encoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'NPA' which is a method or model, not a dataset. No specific dataset is mentioned or used in the context provided.",
      "processing_time": 54.66965413093567,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "(3) NPA (Wu et al., 2019b) proposes personalized attention module in both news and user encoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'NPA' which is a method or model, not a dataset. No specific dataset is mentioned or used in the context provided.",
      "processing_time": 54.66965413093567,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196471084
    },
    {
      "context_text": "(3) NPA (Wu et al., 2019b) proposes personalized attention module in both news and user encoder.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'NPA' which is a method or model, not a dataset. No specific dataset is mentioned or used in the context provided.",
      "processing_time": 54.66965413093567,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "Original Headline: Venezuelans rush to Peru before new requirements take effect Pointer-Gen : Venezuelans rush to Peru user A written headline : New requirements set to take effect causes Venezuelans to rush to Peru NAML+HG for user A : Peru has stricter entry requirements for escaping Venezuelans on that inﬂux.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only news headlines and user-generated content. No verifiable resources are identified.",
      "processing_time": 53.21508860588074,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "Original Headline: Venezuelans rush to Peru before new requirements take effect Pointer-Gen : Venezuelans rush to Peru user A written headline : New requirements set to take effect causes Venezuelans to rush to Peru NAML+HG for user A : Peru has stricter entry requirements for escaping Venezuelans on that inﬂux.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only news headlines and user-generated content. No verifiable resources are identified.",
      "processing_time": 53.21508860588074,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "To further comprehend our task and the proposed framework, we demonstrate interesting cases from two representative methods, namely one non-personalized method Pointer-Gen (PG) and one personalized method NAML+HG which utilizes the second user interests injection (c.f. Fig.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods (Pointer-Gen and NAML+HG). The cited papers also do not provide additional context about datasets.",
      "processing_time": 55.24584245681763,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196181724
    },
    {
      "context_text": "To further comprehend our task and the proposed framework, we demonstrate interesting cases from two representative methods, namely one non-personalized method Pointer-Gen (PG) and one personalized method NAML+HG which utilizes the second user interests injection (c.f. Fig.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods (Pointer-Gen and NAML+HG). The cited papers also do not provide additional context about datasets.",
      "processing_time": 55.24584245681763,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202774468
    },
    {
      "context_text": "Inspired by the tremendous success of personalized news recommendation (An et al., 2019; Wang et al., 2018; Li et al., 2010; Zheng et al., 2018) where the ultimate goal is to learn users’ reading interests and deliver the right news to them, a plausible solu-tion to this question could be producing…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to personalized news recommendation systems. No verifiable resources are identified.",
      "processing_time": 53.50225615501404,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196186167
    },
    {
      "context_text": "(5) LSTUR (An et al., 2019) models long-and shor-term user representations based on user ID embedding and sequential encoding, individually.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (LSTUR) and its components. The context focuses on the model's architecture and user representation mechanisms.",
      "processing_time": 55.348615646362305,
      "citing_paper_id": "236460075",
      "cited_paper_id": 196186167
    },
    {
      "context_text": "News headline generation (Dorr et al., 2003; Lopyrev, 2015; Alfonseca et al., 2013; Tan et al., 2017; See et al., 2017; Zhang et al., 2018; Xu et al., 2019; Murao et al., 2019; Gavrilov et al., 2019; Gu et al., 2020; Song et al., 2020), conventionally considered as a paradigm of challenging text summarization task, has been extensively explored for decades.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies on news headline generation. No verifiable resources are identified.",
      "processing_time": 53.97457504272461,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202540017
    },
    {
      "context_text": "…content vendors such as Google News, TopBuzz, and etc (LaRocque, 2003) propels a new research direction that how to decorate the headline as an irre-sistible invitation to users for reading through the article (Xu et al., 2019) since more readings may ac-quaint more revenue of these platforms.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only content vendors and a general research direction. There are no clear identifiers for datasets.",
      "processing_time": 53.9714138507843,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202540017
    },
    {
      "context_text": "To this end, speciﬁed stylized headline generation techniques were proposed, such as question headline (Zhang et al., 2018), sensational headline (Xu et al., 2019) generation, and so on (Shu et al., 2018; Gu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only techniques and methods for generating stylized headlines. No verifiable resources are identified.",
      "processing_time": 54.19136023521423,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202540017
    },
    {
      "context_text": ", 2018), sensational headline (Xu et al., 2019) generation, and so on (Shu et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'sensational headline generation' which is related to personalized text generation. However, no specific dataset names are mentioned.",
      "processing_time": 54.18888258934021,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202540017
    },
    {
      "context_text": "etc (LaRocque, 2003) propels a new research direction that how to decorate the headline as an irresistible invitation to users for reading through the article (Xu et al., 2019) since more readings may acquaint more revenue of these platforms.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a research direction and a method for generating headlines.",
      "processing_time": 52.45003795623779,
      "citing_paper_id": "236460075",
      "cited_paper_id": 202540017
    },
    {
      "context_text": "…text summarization (Luo et al., 2019; Jia et al., 2020), from which both extractive (Dorr et al., 2003; Alfonseca et al., 2013) and abstrac-tive summarization (Sun et al., 2015; Takase et al., 2016; Tan et al., 2017; Gavrilov et al., 2019; See et al., 2017) approaches prevailed for decades.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various summarization approaches and methods. No verifiable resources are identified.",
      "processing_time": 53.50083875656128,
      "citing_paper_id": "236460075",
      "cited_paper_id": 211043910
    },
    {
      "context_text": "The recent year escalation of online content vendors such as Google News, TopBuzz, and etc (LaRocque, 2003) propels a new research direction that how to decorate the headline as an irre-sistible invitation to users for reading through the article (Xu et al., 2019) since more readings may ac-quaint…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general trends in online content. There are no clear identifiers for datasets, models, or other resources.",
      "processing_time": 54.72378921508789,
      "citing_paper_id": "236460075",
      "cited_paper_id": null
    },
    {
      "context_text": "Sojasingarayar [7] proposed to use LSTMs with an Attention mechanism in a Reinforcement Learning fashion to train a Conversational agent with manually annotated data.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'manually annotated data' but does not specify a named dataset. The context is about training a conversational agent using LSTMs and an attention mechanism.",
      "processing_time": 55.50099277496338,
      "citing_paper_id": "257587780",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "A deep neural network called an encoder-decoder, also called a Seq2Seq network, is used to generate text [13].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Seq2Seq network).",
      "processing_time": 52.26456069946289,
      "citing_paper_id": "257587780",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "LSTMs were created to solve issues arising because of long-term reliance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (LSTMs).",
      "processing_time": 51.89068865776062,
      "citing_paper_id": "257587780",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "The first part deals with generating text responses using a Seq2Seq Model using LSTMs [13] [15].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is about using a Seq2Seq model with LSTMs, which are methods, not datasets.",
      "processing_time": 55.675217628479004,
      "citing_paper_id": "257587780",
      "cited_paper_id": 7961699
    },
    {
      "context_text": "Generative Adversarial Networks (GANs) have been proposed by Liu and Tuzel [6] to learn multi-domain data by using constraints like weight sharing.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (GANs). The context is about the methodology and not about data usage.",
      "processing_time": 54.18092465400696,
      "citing_paper_id": "257587780",
      "cited_paper_id": 10627900
    },
    {
      "context_text": "Bahdanau et al. [8] enhanced existing Seq2Seq models by proposing attention mechanisms which are state-of-the-art approaches for Neural Machine Translation tasks.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (attention mechanism) used in neural machine translation.",
      "processing_time": 52.85827159881592,
      "citing_paper_id": "257587780",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "The decoder can discretely scan the input sequence during decoding, thanks to the attention approach by Bahdanau et al. [8].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method (attention approach) from the cited paper.",
      "processing_time": 52.67574715614319,
      "citing_paper_id": "257587780",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "Both BST and StyleTransformer [24] are used for Sentiment Style Transfer tasks and they generate stylized responses with the help of style-specific decoders.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 53.97309327125549,
      "citing_paper_id": "257587780",
      "cited_paper_id": 13959787
    },
    {
      "context_text": "Both BST and StyleTransformer [24] are used for Sentiment Style Transfer tasks and they generate stylized responses with the help of style-specific decoders.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The cited papers' titles do not introduce any datasets either.",
      "processing_time": 53.97309327125549,
      "citing_paper_id": "257587780",
      "cited_paper_id": 153313581
    },
    {
      "context_text": "BST [23] 2018 MT Encoder, Multiple BiLSTM decoders, CNN classifier Sentiment Style Transfer Personal Style Transfer Yelp, Gender, Political slant",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Yelp",
        "Gender",
        "Political slant"
      ],
      "dataset_descriptions": {
        "Yelp": "Used for sentiment style transfer, specifically to alter the sentiment of reviews while preserving content.",
        "Gender": "Used for personal style transfer, focusing on altering gender-related language in text.",
        "Political slant": "Used for political style transfer, specifically to change the political bias in text while maintaining the original meaning."
      },
      "confidence_score": 0.7,
      "reasoning": "The context mentions 'Yelp, Gender, Political slant' which are likely datasets used for sentiment and style transfer experiments. However, they are not clearly identified as specific datasets.",
      "processing_time": 69.79210782051086,
      "citing_paper_id": "257587780",
      "cited_paper_id": 13959787
    },
    {
      "context_text": "BST [23] is a style classifier model that employs back translation-based methods to rephrase sentences using an English to French Neural Machine Translation network architecture.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and a method. The context focuses on the use of a style classifier model and a neural machine translation network, which are not datasets.",
      "processing_time": 56.23321604728699,
      "citing_paper_id": "257587780",
      "cited_paper_id": 13959787
    },
    {
      "context_text": "We have defined sentence similarity using Soft Cosine [16] over standard Cosine Similarity because the latter checks for semantic similarity rather than synonymity.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for calculating sentence similarity.",
      "processing_time": 51.85258078575134,
      "citing_paper_id": "257587780",
      "cited_paper_id": 14713935
    },
    {
      "context_text": "A conversational Chatbot is an intelligent program but isn't the same as a human agent, so it doesn't always understand the context of the dialogue and its selection of answers may be limited based on its knowledge base [1].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to a chatbot's limitations.",
      "processing_time": 51.855180501937866,
      "citing_paper_id": "257587780",
      "cited_paper_id": 51973914
    },
    {
      "context_text": "We have used the ConvAI2 dataset [14] for training our Conversation AI algorithm, which is a Seq2Seq model, to generate textual responses upon user input.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "ConvAI2"
      ],
      "dataset_descriptions": {
        "ConvAI2": "Used to train a Seq2Seq model for generating textual responses, focusing on improving conversational intelligence through user input interactions."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the ConvAI2 dataset, which is used for training a Seq2Seq model to generate textual responses. The dataset is clearly identified and its usage is specific to the research context.",
      "processing_time": 62.01120853424072,
      "citing_paper_id": "257587780",
      "cited_paper_id": 59553505
    },
    {
      "context_text": "Parallel datasets, first introduced in HybridST [26], were used to create a paired collection of raw and stylized responses that could be used to train and develop a stylized AI.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'parallel datasets' but does not provide a specific name. The term 'parallel datasets' is too generic and lacks a clear identifier.",
      "processing_time": 54.82484793663025,
      "citing_paper_id": "257587780",
      "cited_paper_id": 80628279
    },
    {
      "context_text": "StyleTransformer [24] 2019 Transformer encoder, Transformer decoder, Transformer discriminator Sentiment Style Transfer Yelp",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'Yelp' in the context of sentiment style transfer, which suggests the use of Yelp reviews as a dataset. However, 'Yelp' is not explicitly identified as a dataset in the citation span.",
      "processing_time": 57.884679079055786,
      "citing_paper_id": "257587780",
      "cited_paper_id": 153313581
    },
    {
      "context_text": "The vocabulary generation and expansion pipeline can be optimized to some extent because although the word embedding approach is good, techniques like hierarchical clustering [27] tend to perform better in neural language models.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (hierarchical clustering) for vocabulary expansion in neural language models.",
      "processing_time": 53.541935443878174,
      "citing_paper_id": "257587780",
      "cited_paper_id": 203180740
    },
    {
      "context_text": "According to Kuang [9], using a vanilla Seq2Seq model for building a Chatbot lacks the capabilities to produce innovative and intelligent responses.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Seq2Seq model). The context focuses on the limitations of a vanilla Seq2Seq model in producing innovative and intelligent responses for chatbots.",
      "processing_time": 57.144089698791504,
      "citing_paper_id": "257587780",
      "cited_paper_id": 246862580
    },
    {
      "context_text": "Kuang [9] also proposed a similar network to develop an intelligent Chatbot based on deep learning but it lacked human-like response generation capabilities and suffered problems like the repetition of short-length and high-frequency data and loss of context in longer conversations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation discusses a method or model for developing an intelligent chatbot, but does not mention any specific datasets.",
      "processing_time": 53.015695333480835,
      "citing_paper_id": "257587780",
      "cited_paper_id": 246862580
    },
    {
      "context_text": "We utilized NLTK’s (Natural Language Toolkit) PUNKT tokenizer for tokenizing all phrases in our dataset and WordNet Lemmatizer [21] to convert all tokens in a sentence to their root form.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions tools (NLTK’s PUNKT tokenizer and WordNet Lemmatizer) but does not reference any specific datasets. The focus is on the preprocessing steps using these tools.",
      "processing_time": 55.89133167266846,
      "citing_paper_id": "257587780",
      "cited_paper_id": null
    },
    {
      "context_text": "A few studies have explored creative personalization of image captions (Shuster et al., 2019; Anantha Ra-makrishnan et al., 2025), but these approaches relied on explicit style inputs, making them dependent on user-provided style descriptions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only approaches and methods. The focus is on the reliance of existing methods on explicit style inputs.",
      "processing_time": 54.15156388282776,
      "citing_paper_id": "279251122",
      "cited_paper_id": 53022581
    },
    {
      "context_text": "Early approaches, like F IG CAP and the initial version of S CI C AP , relied solely on figure images as input (Chen et al., 2020; Hsu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions methods (F IG CAP and S CI C AP) but does not refer to any specific datasets. The context is about the input type (figure images) used in these methods.",
      "processing_time": 56.38757371902466,
      "citing_paper_id": "279251122",
      "cited_paper_id": 214604370
    },
    {
      "context_text": "Figures like bar charts or line charts are widely used by scientists, companies, and governments to communicate key insights (Kim et al., 2021; Fara-hani et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general usage of figures like bar charts or line charts. No verifiable resources are identified.",
      "processing_time": 54.147507190704346,
      "citing_paper_id": "279251122",
      "cited_paper_id": 231648047
    },
    {
      "context_text": "Captions—text placed next to these figures—are known to be crucial for helping readers understand and remember the figure’s message (Tang et al., 2023; Kantharaj et al., 2022a; Meng et al., 2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the importance of captions for understanding figures. No verifiable resources are named.",
      "processing_time": 53.93910050392151,
      "citing_paper_id": "279251122",
      "cited_paper_id": 247446806
    },
    {
      "context_text": "Captions—text placed next to these figures—are known to be crucial for helping readers understand and remember the figure’s message (Tang et al., 2023; Kantharaj et al., 2022a; Meng et al., 2024).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only the importance of captions for understanding figures. No verifiable resources are named.",
      "processing_time": 53.93910050392151,
      "citing_paper_id": "279251122",
      "cited_paper_id": 266755649
    },
    {
      "context_text": "Researchers soon realized this was insufficient and began incorporating additional context, such as figure-mentioning paragraphs and even the document’s title or abstract (Huang et al., 2023; Yang et al., 2024; Stokes et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods or approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.47998023033142,
      "citing_paper_id": "279251122",
      "cited_paper_id": 251280109
    },
    {
      "context_text": "Researchers soon realized this was insufficient and began incorporating additional context, such as figure-mentioning paragraphs and even the document’s title or abstract (Huang et al., 2023; Yang et al., 2024; Stokes et al., 2022).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general methods or approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.47998023033142,
      "citing_paper_id": "279251122",
      "cited_paper_id": 257205967
    },
    {
      "context_text": "Many models have been developed to generate high-quality captions to help authors compose captions more easily (Hsu et al., 2021; Huang et al., 2023; Liu et al., 2022; Masry et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and their development for generating captions.",
      "processing_time": 52.31711959838867,
      "citing_paper_id": "279251122",
      "cited_paper_id": 257205967
    },
    {
      "context_text": "Although studies noted that users often need captions tailored to their style or domain (Hsu et al., 2025; Huang et al., 2023), none of these approaches explicitly provided source-target pairs that capture the specific generation context needed for models to learn personalized styles.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general observations about the need for personalized styles in caption generation.",
      "processing_time": 52.96229887008667,
      "citing_paper_id": "279251122",
      "cited_paper_id": 257205967
    },
    {
      "context_text": "For example, L A MP included tasks such as news headline generation and email subject creation—relying exclusively on text-based inputs and profiles (Salemi et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions tasks like news headline generation and email subject creation, which are relevant to personalized text generation, but does not specify a dataset name.",
      "processing_time": 54.23342990875244,
      "citing_paper_id": "279251122",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "Benchmarks like L A MP (Salemi et al., 2024) (L A nguage Models Personalization) and L ONG L A MP (Kumar et al., 2024) were created to study how LLMs can tailor text for specific contexts.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions benchmarks LAMP and LONG-LAMP, which are not datasets but rather suites used for evaluating personalization in language models. No specific, reusable datasets are mentioned.",
      "processing_time": 55.8576238155365,
      "citing_paper_id": "279251122",
      "cited_paper_id": 258298303
    },
    {
      "context_text": "For example, the S CI C AP Challenges in 2023 and 2024 invited global teams to generate captions for scientific figures in arXiv papers (Hsu et al., 2025; Kim et al., 2025).",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions challenges but does not specify any datasets. The challenges are likely part of a competition or benchmark, which is excluded according to the instructions.",
      "processing_time": 54.839078426361084,
      "citing_paper_id": "279251122",
      "cited_paper_id": 275336716
    },
    {
      "context_text": "We evaluated four LLMs on personalized caption generation using L A MP-C AP : (i) GPT-4o (Hurst et al., 2024), (ii) Llama 4 Scout (MetaAI, 2025), (iii) Gemini 2.5 Flash Preview (DeepMind, 2024), and (iv) GPT-4.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "L A MP-C AP"
      ],
      "dataset_descriptions": {
        "L A MP-C AP": "Used to evaluate four LLMs on personalized caption generation, focusing on the models' ability to generate contextually relevant captions."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'L A MP-C AP' which appears to be a specific dataset or benchmark used for evaluating personalized caption generation. However, the name is not a clear, verifiable resource and lacks specific details or provenance.",
      "processing_time": 64.4150881767273,
      "citing_paper_id": "279251122",
      "cited_paper_id": null
    },
    {
      "context_text": "We evaluated four LLMs on personalized caption generation using L A MP-C AP : (i) GPT-4o (Hurst et al., 2024), (ii) Llama 4 Scout (MetaAI, 2025), (iii) Gemini 2.5 Flash Preview (DeepMind, 2024), and (iv) GPT-4.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "L A MP-C AP"
      ],
      "dataset_descriptions": {
        "L A MP-C AP": "Used to evaluate four LLMs on personalized caption generation, focusing on the models' ability to generate contextually relevant captions."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'L A MP-C AP' which appears to be a specific dataset or benchmark used for evaluating personalized caption generation. However, the name is not a clear, verifiable resource and lacks specific details or provenance.",
      "processing_time": 64.4150881767273,
      "citing_paper_id": "279251122",
      "cited_paper_id": null
    },
    {
      "context_text": "Also , remove any prefix that indicates figure index such as ' Caption:', ' Below is an example from arXiv paper 1105.0392, showing the response from the \"Llama-4 Scout\" model with \"All Profile\" configuration, before and after cleaning: RAW OUTPUT The following is the raw output before cleaning: Based on the provided elements, I will generate a caption for the Target Figure.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a process of generating a caption for a figure using a model, but no dataset names are provided.",
      "processing_time": 54.23528838157654,
      "citing_paper_id": "279251122",
      "cited_paper_id": null
    },
    {
      "context_text": "Early approaches mainly relied on GAN-based architectures [26, 38, 3, 39, 37, 18, 35, 13, 17, 14] to solve this problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions GAN-based architectures but does not specify any datasets. The cited papers are about GANs for text-to-image synthesis but do not mention specific datasets in the given context.",
      "processing_time": 56.296900272369385,
      "citing_paper_id": "259165446",
      "cited_paper_id": 1277217
    },
    {
      "context_text": "Early approaches mainly relied on GAN-based architectures [26, 38, 3, 39, 37, 18, 35, 13, 17, 14] to solve this problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions GAN-based architectures but does not specify any datasets. The cited papers are about GANs for text-to-image synthesis but do not mention specific datasets in the given context.",
      "processing_time": 56.296900272369385,
      "citing_paper_id": "259165446",
      "cited_paper_id": 1563370
    },
    {
      "context_text": "Early approaches mainly relied on GAN-based architectures [26, 38, 3, 39, 37, 18, 35, 13, 17, 14] to solve this problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions GAN-based architectures but does not specify any datasets. The cited papers are about GANs for text-to-image synthesis but do not mention specific datasets in the given context.",
      "processing_time": 56.296900272369385,
      "citing_paper_id": "259165446",
      "cited_paper_id": 8858625
    },
    {
      "context_text": "Early approaches mainly relied on GAN-based architectures [26, 38, 3, 39, 37, 18, 35, 13, 17, 14] to solve this problem.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context mentions GAN-based architectures but does not specify any datasets. The cited papers are about GANs for text-to-image synthesis but do not mention specific datasets in the given context.",
      "processing_time": 56.296900272369385,
      "citing_paper_id": "259165446",
      "cited_paper_id": 54482423
    },
    {
      "context_text": "For the text condition, we randomly select 100 textual descriptions from the MS COCO [19] captions that describe scenes of real images.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "MS COCO"
      ],
      "dataset_descriptions": {
        "MS COCO": "Used to select 100 textual descriptions for the text condition, focusing on scene descriptions of real images to study personalized text generation."
      },
      "confidence_score": 1.0,
      "reasoning": "MS COCO is a well-known dataset used for image captioning and other vision-language tasks. The context indicates it is used for selecting textual descriptions.",
      "processing_time": 60.50792074203491,
      "citing_paper_id": "259165446",
      "cited_paper_id": 14113767
    },
    {
      "context_text": "To simulate the visual condition processing in real scenarios, we adopt face image masks from CelebAMask-HQ [16] as our visual condition.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CelebAMask-HQ"
      ],
      "dataset_descriptions": {
        "CelebAMask-HQ": "Used to provide face image masks as visual conditions, simulating real scenarios in facial image manipulation."
      },
      "confidence_score": 1.0,
      "reasoning": "CelebAMask-HQ is a specific dataset used for providing face image masks as visual conditions in the research.",
      "processing_time": 59.70351457595825,
      "citing_paper_id": "259165446",
      "cited_paper_id": 198967908
    },
    {
      "context_text": "DDIM [32] has shown DDPM [9] can be reformulated as,",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is about reformulating DDPM using DDIM, which are not datasets.",
      "processing_time": 54.57637643814087,
      "citing_paper_id": "259165446",
      "cited_paper_id": 222140788
    },
    {
      "context_text": "To be specific, we first inverse the visual condition back to every diffusion step {1:T} space by solving Ordinary Differential Equations (ODE) via Euler integration following DDIMs [32].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DDIMs) which is not a dataset.",
      "processing_time": 53.08482813835144,
      "citing_paper_id": "259165446",
      "cited_paper_id": 222140788
    },
    {
      "context_text": "In recent years, Diffusion probabilistic models (DPMs) [9, 32, 2, 23, 33, 11, 36] have gradually become one of the most active and mainstream methods for vision generation tasks due to their impressive results and ability to support cross-modal synthesis mainly based on classifier-free conditional generation [10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 53.94787836074829,
      "citing_paper_id": "259165446",
      "cited_paper_id": 222140788
    },
    {
      "context_text": "In recent years, Diffusion probabilistic models (DPMs) [9, 32, 2, 23, 33, 11, 36] have gradually become one of the most active and mainstream methods for vision generation tasks due to their impressive results and ability to support cross-modal synthesis mainly based on classifier-free conditional generation [10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 53.94787836074829,
      "citing_paper_id": "259165446",
      "cited_paper_id": 231979499
    },
    {
      "context_text": "DDIM [32] has shown DDPM [9] can be reformulated as,\nxt−1 = √ αt−1( xt − √ 1− αt tθ(xt)√ αt\n)︸ ︷︷ ︸ “predicted x0”\n+ √ 1− αt−1 − σ2t tθ(xt)︸ ︷︷ ︸\n“direction pointing to xt”\n+ σt ︸︷︷︸ random noise , (3)\nwhere θ is the implemented model (usually U-net [28]), and, σt = η √ (1− αt−1)/(1− αt) √ 1− αt/αt−1, (4)\nas the factor controlling randomness during denoising.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on explaining a mathematical formulation and model architecture.",
      "processing_time": 53.9509437084198,
      "citing_paper_id": "259165446",
      "cited_paper_id": 222140788
    },
    {
      "context_text": "Here we use Celeba64 pre-trained DDIM [32] model, inverse pictures of pure white and pure gray by solving ODE to obtain their intermediate steps.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to a pre-trained model and a method for generating images, but no dataset is explicitly used or referenced.",
      "processing_time": 55.57071661949158,
      "citing_paper_id": "259165446",
      "cited_paper_id": 222140788
    },
    {
      "context_text": "Specifically, the diffusion model benefits from the stochasticity in the random walk trajectory of the Markov process to ensure image quality during denoising [32, 42].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (diffusion model).",
      "processing_time": 52.231022119522095,
      "citing_paper_id": "259165446",
      "cited_paper_id": 222140788
    },
    {
      "context_text": "Diffusion-based text-to-image generation methods [27, 22, 30, 24, 25, 8] have achieved state-of-the-art results and become a primary choice of backbone for a multimodal conditional generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.556352376937866,
      "citing_paper_id": "259165446",
      "cited_paper_id": 244714856
    },
    {
      "context_text": "Diffusion-based text-to-image generation methods [27, 22, 30, 24, 25, 8] have achieved state-of-the-art results and become a primary choice of backbone for a multimodal conditional generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 54.556352376937866,
      "citing_paper_id": "259165446",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Although we benefit a lot from explicitly utilizing the visual condition and variable size of LDM input, these can bring limitations in some scenarios.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses limitations of Latent Diffusion Models (LDM).",
      "processing_time": 52.864137411117554,
      "citing_paper_id": "259165446",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "We first design a qualitative experiment on Celeba64 pre-trained model to explore the internal diffusion phenomenon within the image during the denoising process, then try a quantitative experiment on LDM [27] to explore properties exhibited during the denoising process.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Celeba64"
      ],
      "dataset_descriptions": {
        "Celeba64": "Used to train and evaluate a pre-trained model, exploring internal diffusion phenomena during the denoising process in high-resolution image synthesis."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'Celeba64' and 'LDM', but 'LDM' is likely a method or model, not a dataset. 'Celeba64' is a specific dataset used for training and evaluating models.",
      "processing_time": 64.31566119194031,
      "citing_paper_id": "259165446",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "We implement our method and baselines on pre-trained T2I Stable Diffusion model [27] sd-v1-4, with default configuration condition scale set 7.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a pre-trained model (sd-v1-4) but does not refer to any specific dataset. The model is used for image synthesis, which is not directly related to personalized text generation.",
      "processing_time": 56.6798939704895,
      "citing_paper_id": "259165446",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Latent Diffusion Models (LDM).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (Latent Diffusion Models). No verifiable resources are identified.",
      "processing_time": 53.873743295669556,
      "citing_paper_id": "259165446",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "However, existing literature conditioned on text-vision input first extracts the semantic information of given visual images (usually in a few-shot manner) via pre-trained vision-language models [27, 24], and then integrates the processed semantic visual representations into the T2I base model in the form of additional textual conditioning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of pre-trained vision-language models. No verifiable datasets are referenced.",
      "processing_time": 54.07426691055298,
      "citing_paper_id": "259165446",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Since LDM eliminates high-frequency details in the perceptual compression stage, and the reconstruction error of latent space will be enlarged accordingly, it is difficult to maintain the reconstruction ability for extremely small-size images.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only discusses technical aspects of Latent Diffusion Models (LDM).",
      "processing_time": 53.615477561950684,
      "citing_paper_id": "259165446",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Different from Diffusion Probabilistic Models (DPMs) that perform denoising operations in the pixel space, the LDM-based [27] model performs the diffusion process in the latent space of an auto-encoder [6] to generate high-quality results at a faster speed and turn DPMs into more flexible conditional image generators by augmenting DPMs’ UNet backbone [28] with the cross-attention mechanism [34].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The focus is on the technical aspects of Latent Diffusion Models (LDMs) and their improvements over Diffusion Probabilistic Models (DPMs).",
      "processing_time": 58.00187039375305,
      "citing_paper_id": "259165446",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Text-to-image (T2I) diffusion models, such as LDM [27], Imagen [30], DALL-E 2 [24], GLIDE [22], and CDCD [43], have made significant progress in generating high-quality images based on text prompts, which allow users to create semantically consistent images via textual descriptions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and their capabilities. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 54.68044352531433,
      "citing_paper_id": "259165446",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "This branch of methods [29, 41, 12, 21, 15] usually fine-tune pre-trained T2I models.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to fine-tuning pre-trained T2I models. No verifiable resources are identified.",
      "processing_time": 54.795732498168945,
      "citing_paper_id": "259165446",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "This branch of methods [29, 41, 12, 21, 15] usually fine-tune pre-trained T2I models.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general reference to fine-tuning pre-trained T2I models. No verifiable resources are identified.",
      "processing_time": 54.795732498168945,
      "citing_paper_id": "259165446",
      "cited_paper_id": 256827727
    },
    {
      "context_text": "A recent novel approach, DreamBooth [29], binds the visual concept to a special ’Rare-token Identifier’ and synthesizes images by implanting unique identifiers in prompts when inferencing.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DreamBooth) and a concept ('Rare-token Identifier'). No verifiable datasets are referenced.",
      "processing_time": 55.286054372787476,
      "citing_paper_id": "259165446",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "We follow the same evaluation metrics as in previous works [7, 29, 5],",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics from previous works. No verifiable resources are identified.",
      "processing_time": 53.224520444869995,
      "citing_paper_id": "259165446",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "We perform a comparison on current SOTA works incorporating the visual condition into pre-trained T2I models: DreamBooth [29] based on the code1, TI [7], and UGM [1].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on comparing different models for text-to-image generation.",
      "processing_time": 54.00371766090393,
      "citing_paper_id": "259165446",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "To further improve user controllability, recent works [29, 1, 5] seek to incorporate additional visual conditioning into the T2I models, extending the model input from pure text to multiple text-vision",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach to incorporating visual conditioning into text-to-image models.",
      "processing_time": 53.379929065704346,
      "citing_paper_id": "259165446",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "From the perspective of conditional generation, our proposed TV2I task is a generalization to [29, 5, 7, 1].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other papers. There are no clear identifiers for datasets in the given context.",
      "processing_time": 53.99924063682556,
      "citing_paper_id": "259165446",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "22% of the votes) in terms of condition correspondence compared to the three methods, where the second best one, DreamBooth [29] only gets 10.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of methods. No dataset names are present in the citation span.",
      "processing_time": 53.63615298271179,
      "citing_paper_id": "259165446",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Additionally, DreamBooth [29] uses a small number of reference images to optimize a large number of parameters may lead to collapse and over-fitting.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DreamBooth) and potential issues with overfitting. No verifiable resources are identified.",
      "processing_time": 55.003053426742554,
      "citing_paper_id": "259165446",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "DreamBooth [29] introduces a rare-token identifier along with a class-prior for a more specific few-shot visual concept by finetuning pre-trained T2I model to obtain the ability to generate specific objects in results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DreamBooth) and a general approach to fine-tuning models. No verifiable datasets are referenced.",
      "processing_time": 55.517733097076416,
      "citing_paper_id": "259165446",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Similar to ControlNet, the T2I-Adapter [21] differs mainly in the “learnable branch” network structure and other details.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model (T2I-Adapter). The context is focused on comparing network structures and details, not on the use of datasets.",
      "processing_time": 56.57291030883789,
      "citing_paper_id": "259165446",
      "cited_paper_id": 256827727
    },
    {
      "context_text": "For example, ControlNet [41] extends the pre-trained large diffusion model with a trainable copy branch to support additional visual input conditions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (ControlNet) that extends a pre-trained model. No verifiable resources are identified.",
      "processing_time": 55.0285918712616,
      "citing_paper_id": "259165446",
      "cited_paper_id": 256827727
    },
    {
      "context_text": "These works [5, 20, 7, 4] are probably the most relevant to our task.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There is no information about the actual use of datasets in the given context.",
      "processing_time": 55.03125,
      "citing_paper_id": "259165446",
      "cited_paper_id": 258556958
    },
    {
      "context_text": "We downsampled an audio to 16kHz and trimmed leading and trailing silence using Librosa (McFee et al., 2015).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of Librosa for audio processing but does not reference any specific dataset. Librosa is a software toolkit, not a dataset.",
      "processing_time": 55.272414684295654,
      "citing_paper_id": "235359041",
      "cited_paper_id": 33504
    },
    {
      "context_text": "In addition, We apply spectral normalization (Miyato et al., 2018) in all the Model MOS (↑) MCD (↓) WER (↓)",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (spectral normalization).",
      "processing_time": 52.583064794540405,
      "citing_paper_id": "235359041",
      "cited_paper_id": 3366315
    },
    {
      "context_text": "In addition, We apply spectral normalization (Miyato et al., 2018) In addition, we train our models with a minibatch size of 48 for StyleSpeech and 20 for Meta-StyleSpeech using the Adam optimizer.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and training parameters. The cited papers are about methods, not datasets.",
      "processing_time": 53.74355697631836,
      "citing_paper_id": "235359041",
      "cited_paper_id": 3366315
    },
    {
      "context_text": "In addition, We apply spectral normalization (Miyato et al., 2018) In addition, we train our models with a minibatch size of 48 for StyleSpeech and 20 for Meta-StyleSpeech using the Adam optimizer.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and training parameters. The cited papers are about methods, not datasets.",
      "processing_time": 53.74355697631836,
      "citing_paper_id": "235359041",
      "cited_paper_id": 3633127
    },
    {
      "context_text": "Similar to the idea of Miyato & Koyama (2018), the output of the style discriminator is then computed as: where V ∈ R N × M is a linear layer and w 0 and b 0 are learnable parameters.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context is focused on the technical details of a style discriminator.",
      "processing_time": 54.7493839263916,
      "citing_paper_id": "235359041",
      "cited_paper_id": 3633127
    },
    {
      "context_text": "In this regard, some of the few-shot generative models have utilized meta-learning for improved generalization (Rezende et al., 2016; Bartunov & Vetrov, 2018; Clouˆatre & Demers, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses the use of meta-learning in few-shot generative models but does not mention any specific datasets. The cited papers' titles also do not provide clear evidence of specific datasets.",
      "processing_time": 56.675585985183716,
      "citing_paper_id": "235359041",
      "cited_paper_id": 4865465
    },
    {
      "context_text": "In this regard, some of the few-shot generative models have utilized meta-learning for improved generalization (Rezende et al., 2016; Bartunov & Vetrov, 2018; Clouˆatre & Demers, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses the use of meta-learning in few-shot generative models but does not mention any specific datasets. The cited papers' titles also do not provide clear evidence of specific datasets.",
      "processing_time": 56.675585985183716,
      "citing_paper_id": "235359041",
      "cited_paper_id": 5985692
    },
    {
      "context_text": "In this regard, some of the few-shot generative models have utilized meta-learning for improved generalization (Rezende et al., 2016; Bartunov & Vetrov, 2018; Clouˆatre & Demers, 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses the use of meta-learning in few-shot generative models but does not mention any specific datasets. The cited papers' titles also do not provide clear evidence of specific datasets.",
      "processing_time": 56.675585985183716,
      "citing_paper_id": "235359041",
      "cited_paper_id": 57721163
    },
    {
      "context_text": "Bartunov & Vetrov (2018) developed a hierarchical Variational Autoencoder for few-shot image generation, while Reed et al. (2018) pro-pose the extension of Pixel-CNN with neural attention for few-shot auto-regressive density modeling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on describing the development of generative models.",
      "processing_time": 54.293198585510254,
      "citing_paper_id": "235359041",
      "cited_paper_id": 4865465
    },
    {
      "context_text": "For one-shot image generalization, Rezende et al. (2016) propose sequential generative models that are built on the principles of feedback and the attention mechanism.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for one-shot image generalization using generative models.",
      "processing_time": 53.792824268341064,
      "citing_paper_id": "235359041",
      "cited_paper_id": 5985692
    },
    {
      "context_text": "2) GT mel ( oracle ) : This is the speech synthesized by MelGAN vocoder using Ground-Truth mel-spectrogram.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method for synthesizing speech using a MelGAN vocoder and ground-truth mel-spectrograms, which are not considered datasets.",
      "processing_time": 56.95599412918091,
      "citing_paper_id": "235359041",
      "cited_paper_id": 10319744
    },
    {
      "context_text": "We use MelGAN (Kumar et al., 2019) as the vocoder to convert the generated mel-spectrograms into audio waveforms.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions MelGAN, which is a model, not a dataset. There are no specific datasets mentioned in the citation span.",
      "processing_time": 54.11162447929382,
      "citing_paper_id": "235359041",
      "cited_paper_id": 10319744
    },
    {
      "context_text": "The discriminator loss function of D s then becomes The discriminator loss follows LS-GAN (Mao et al., 2017), which replace the binary cross-entropy terms of the original GAN (Goodfellow et al., 2014) objective with least squares loss functions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only loss functions and GAN-related methods.",
      "processing_time": 52.716930866241455,
      "citing_paper_id": "235359041",
      "cited_paper_id": 10319744
    },
    {
      "context_text": "The learning rate of generator and mel-style encoder follows Vaswani et al. (2017), while the learning rate of discriminator is ﬁxed as 0.0002.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references a method for setting learning rates.",
      "processing_time": 51.80744552612305,
      "citing_paper_id": "235359041",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "…of the TTS models aim to synthe-size high quality speech of a single speaker from the given text (Oord et al., 2016; Wang et al., 2017; Shen et al., 2018; Ren et al., 2019; 2020) and have been extended to support multi speakers (Gibiansky et al., 2017; Ping et al., 2017; Chen et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles also do not provide additional dataset information.",
      "processing_time": 55.01978325843811,
      "citing_paper_id": "235359041",
      "cited_paper_id": 21010143
    },
    {
      "context_text": "…of the TTS models aim to synthe-size high quality speech of a single speaker from the given text (Oord et al., 2016; Wang et al., 2017; Shen et al., 2018; Ren et al., 2019; 2020) and have been extended to support multi speakers (Gibiansky et al., 2017; Ping et al., 2017; Chen et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The cited papers' titles also do not provide additional dataset information.",
      "processing_time": 55.01978325843811,
      "citing_paper_id": "235359041",
      "cited_paper_id": 26100519
    },
    {
      "context_text": "Text-to-Speech Neural TTS models have shown a rapid progress, including WaveNet (Oord et al., 2016), Deep-Voice1, 2, 3 (Arik et al., 2017; Gibiansky et al., 2017; Ping et al., 2017), Char2Wav (Sotelo et al., 2017) and Tacotron1, 2 (Wang et al., 2017; Shen et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not refer to any specific datasets. The context is focused on describing various Text-to-Speech models and their contributions.",
      "processing_time": 55.93689465522766,
      "citing_paper_id": "235359041",
      "cited_paper_id": 21010143
    },
    {
      "context_text": "Text-to-Speech Neural TTS models have shown a rapid progress, including WaveNet (Oord et al., 2016), Deep-Voice1, 2, 3 (Arik et al., 2017; Gibiansky et al., 2017; Ping et al., 2017), Char2Wav (Sotelo et al., 2017) and Tacotron1, 2 (Wang et al., 2017; Shen et al., 2018).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not refer to any specific datasets. The context is focused on describing various Text-to-Speech models and their contributions.",
      "processing_time": 55.93689465522766,
      "citing_paper_id": "235359041",
      "cited_paper_id": 26100519
    },
    {
      "context_text": "3) Deep-voice3 (Ping et al., 2017): This is a multi speaker TTS model which learns a look-up table to map embeddings for different speaker identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (Deep-voice3) and its functionality. No verifiable datasets are referenced.",
      "processing_time": 55.19625282287598,
      "citing_paper_id": "235359041",
      "cited_paper_id": 26100519
    },
    {
      "context_text": "Moreover, GMVAE-Tacotron (Hsu et al., 2019) present a variational approach with Gaussian Mixture prior in style modeling.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (GMVAE-Tacotron).",
      "processing_time": 53.48443937301636,
      "citing_paper_id": "235359041",
      "cited_paper_id": 52986403
    },
    {
      "context_text": "6) Multi-speaker FS2 + d -vector : This is same as 5) Multi-speaker FS2 ( vanilla ) except that the style vector is extracted from a pre-trained speaker veriﬁcation model as suggested in Jia et al. (2018) GMVAE 2.85 ± 0.12 3.01 ± 0.12 2 .91 ± 0.16 3.11 ± 0.10 0 .629 0.695 0.748 0.765 20.75% 30.49% 28.33% 46.15% Multi-speaker FS2( vanilla ) 3.14 ± 0.17 3.63 ± 0.16 3.31 ± 0.14 3.36 ± 0.12 0.713 0.735 0.775 0.773 64.80% 73.80% 72.60% 81.40% Multi-speaker FS2+ d -vector 1.85 ± 0.12 2 .08 ± 0.16 2.11 ± 0.16 2.12 ± 0.14 0.601 0.603 0.619 0.616 2.40% 3.80% 5.60% 5.60% StyleSpeech 3.32 ± 0.16 4.13 ± 0.16 3.50 ± 0.10 3.46 ± 0.12 0.725 0.756 0.791 0.795 77.60% 85.00% 83.46% 85.19% Meta-StyleSpeech 3.66 ± 0.13 4.19 ± 0.14 3.43 ± 0.14 3.81 ± 0.12 0.738 0.779 0.813 0.815 82.60% 90.20% 88.66% 91.20% two additional discriminators to guide the generator.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets.",
      "processing_time": 53.46138000488281,
      "citing_paper_id": "235359041",
      "cited_paper_id": 52986403
    },
    {
      "context_text": "Datasets We train StyleSpeech and Meta-StyleSpeech on LibriTTS dataset (Zen et al., 2019), which is a multi-speaker English corpus derived from LibriSpeech (Panay-otov et al., 2015).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LibriTTS"
      ],
      "dataset_descriptions": {
        "LibriTTS": "Used to train StyleSpeech and Meta-StyleSpeech models, focusing on multi-speaker English speech synthesis. The dataset provides a rich corpus for developing personalized text-to-speech systems."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the LibriTTS dataset, which is a multi-speaker English corpus derived from LibriSpeech. It is used for training StyleSpeech and Meta-StyleSpeech models.",
      "processing_time": 64.64664912223816,
      "citing_paper_id": "235359041",
      "cited_paper_id": 52986403
    },
    {
      "context_text": "Datasets We train StyleSpeech and Meta-StyleSpeech on LibriTTS dataset (Zen et al., 2019), which is a multi-speaker English corpus derived from LibriSpeech (Panay-otov et al., 2015).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LibriTTS"
      ],
      "dataset_descriptions": {
        "LibriTTS": "Used to train StyleSpeech and Meta-StyleSpeech models, focusing on multi-speaker English speech synthesis. The dataset provides a rich corpus for developing personalized text-to-speech systems."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the LibriTTS dataset, which is a multi-speaker English corpus derived from LibriSpeech. It is used for training StyleSpeech and Meta-StyleSpeech models.",
      "processing_time": 64.64664912223816,
      "citing_paper_id": "235359041",
      "cited_paper_id": 102352475
    },
    {
      "context_text": "We can see that while StyleSpeech clearly better separates the style vectors when compared with GMVAE, Meta-StyleSpeech trained with meta-learning achieves even better clustered style vectors.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria.",
      "processing_time": 53.95577669143677,
      "citing_paper_id": "235359041",
      "cited_paper_id": 52986403
    },
    {
      "context_text": "4) GMVAE (Hsu et al., 2019): This is a multi-speaker TTS model based on the Tacotron with a variational approach using Gaussian Mixture prior.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (GMVAE) and its components. There are no verifiable resources that meet the criteria.",
      "processing_time": 55.616854190826416,
      "citing_paper_id": "235359041",
      "cited_paper_id": 52986403
    },
    {
      "context_text": "Our model is inspired by Karras et al. (2019) proposed for image generation, that are shown to generate surprisingly realistic photos of human faces.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (StyleGAN) for image generation. The context focuses on the inspiration for the model architecture rather than the use of a dataset.",
      "processing_time": 56.315956115722656,
      "citing_paper_id": "235359041",
      "cited_paper_id": 54482423
    },
    {
      "context_text": "A popular approach is to train the model on a large multi-speakers dataset and then ﬁne-tune the whole model (Chen et al., 2019; Arik et al., 2018) or only parts of the model (Moss et al., 2020; Zhang et al., 2020; Chen et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions a 'large multi-speakers dataset' but does not provide a specific name. The cited papers do not clarify the dataset name either.",
      "processing_time": 55.175551652908325,
      "citing_paper_id": "235359041",
      "cited_paper_id": 211044093
    },
    {
      "context_text": "A popular approach is to train the model on a large multi-speakers dataset and then ﬁne-tune the whole model (Chen et al., 2019; Arik et al., 2018) or only parts of the model (Moss et al., 2020; Zhang et al., 2020; Chen et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions a 'large multi-speakers dataset' but does not provide a specific name. The cited papers do not clarify the dataset name either.",
      "processing_time": 55.175551652908325,
      "citing_paper_id": "235359041",
      "cited_paper_id": 218595851
    },
    {
      "context_text": "A popular approach is to train the model on a large multi-speakers dataset and then ﬁne-tune the whole model (Chen et al., 2019; Arik et al., 2018) or only parts of the model (Moss et al., 2020; Zhang et al., 2020; Chen et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions a 'large multi-speakers dataset' but does not provide a specific name. The cited papers do not clarify the dataset name either.",
      "processing_time": 55.175551652908325,
      "citing_paper_id": "235359041",
      "cited_paper_id": 232075892
    },
    {
      "context_text": "A popular approach to handle this challenge is to pre-train the model on a large dataset consisting of the speech from many speakers and ﬁne-tune the model with a few audio samples of a target speaker (Chen et al., 2019; Arik et al., 2018; Chen et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to a large dataset and a few audio samples, which are too generic.",
      "processing_time": 55.04042887687683,
      "citing_paper_id": "235359041",
      "cited_paper_id": 232075892
    },
    {
      "context_text": "A popular approach to handle this challenge is to pre-train the model on a large dataset consisting of the speech from many speakers and fine-tune the model with a few audio samples of a target speaker (Chen et al., 2019; Arik et al., 2018; Chen et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It only refers to a large dataset in a generic way.",
      "processing_time": 54.26380372047424,
      "citing_paper_id": "235359041",
      "cited_paper_id": 232075892
    },
    {
      "context_text": ", 2018) or only parts of the model (Moss et al., 2020; Zhang et al., 2020; Chen et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to parts of models. No verifiable resources are identified.",
      "processing_time": 53.98459315299988,
      "citing_paper_id": "235359041",
      "cited_paper_id": 232075892
    },
    {
      "context_text": "For instance, Sordoni et al. [63] tackle the challenge of context-based dialogue response generation by embedding all words and phrases in the dialogue history into continuous representations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating conversational responses.",
      "processing_time": 52.616859436035156,
      "citing_paper_id": "202539583",
      "cited_paper_id": 94285
    },
    {
      "context_text": "Instead of simple single-round visual Q&A, Das et al. [16] implement a visual dialogue system to communicate with people in multiple rounds about a given image.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or system for visual dialogue.",
      "processing_time": 52.19137907028198,
      "citing_paper_id": "202539583",
      "cited_paper_id": 1820614
    },
    {
      "context_text": "Researchers carry out a lot work of text generation with multi-modal data as inputs, such as generating description/caption for a given image [41], conducting Q&A with images [62], and communicating based on the content of a given image [16].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions text generation with multi-modal data but does not specify any named datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 54.95995736122131,
      "citing_paper_id": "202539583",
      "cited_paper_id": 1820614
    },
    {
      "context_text": "Researchers carry out a lot work of text generation with multi-modal data as inputs, such as generating description/caption for a given image [41], conducting Q&A with images [62], and communicating based on the content of a given image [16].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions text generation with multi-modal data but does not specify any named datasets. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 54.95995736122131,
      "citing_paper_id": "202539583",
      "cited_paper_id": 51606047
    },
    {
      "context_text": "[90] GRU + Emotional embedding Emotion category embedding captures emotional information from the dialogue history and the internal emotion memory balances the grammaticality and the expression degree of emotions; Generating context relevant, grammatical correct and emotionally consistent dialogue content",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It focuses on the method of using GRU and emotional embeddings for generating emotionally consistent dialogues.",
      "processing_time": 55.434839963912964,
      "citing_paper_id": "202539583",
      "cited_paper_id": 2024574
    },
    {
      "context_text": "Li et al. [38] present a speaker model which encodes user profiles (e.g., speaking style, background information etc.) into vectors so as to capture personalized characteristics and guide the response generation during the decode stage.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for encoding user profiles into vectors for personalized response generation.",
      "processing_time": 54.04609775543213,
      "citing_paper_id": "202539583",
      "cited_paper_id": 2955580
    },
    {
      "context_text": "o. 1, Article 1. Publication date: January 2016. c-TextGen: Conditional Text Generation for Harmonious Human-Machine Interaction 1:23 RNN model cannot capture the long-distance dependence. Guo et al. [28] propose the LeakGAN model to generate long texts. „e generator in LeakGAN model has a hierarchical RL structure, consisting of the Manager module and the Worker module. „e Manager module receives a f",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (LeakGAN) and its components. There are no verifiable resources or datasets mentioned.",
      "processing_time": 55.42734384536743,
      "citing_paper_id": "202539583",
      "cited_paper_id": 3389583
    },
    {
      "context_text": "Chen et al. [11] publish another high-quality emotional dialogue dataset collecting from telescripts and dialogues in Facebook, named EmotionLines 13 , including 29,245 utterances of 2,000 dialogues.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "EmotionLines"
      ],
      "dataset_descriptions": {
        "EmotionLines": "Used to collect and analyze emotional dialogues from telescripts and Facebook, focusing on multi-party conversations to enhance personalized text generation models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific dataset named 'EmotionLines' with clear details about its content and size, which is relevant to personalized text generation.",
      "processing_time": 60.44325876235962,
      "citing_paper_id": "202539583",
      "cited_paper_id": 3526062
    },
    {
      "context_text": "…collect a large amount of publicly available information on the Internet, which was then used to automate compiling books 3 . above method of Parker belongs to the text-to-text generation method [25], which takes existing text as input and automatically generates the new, coherent text as output.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes a method for text-to-text generation.",
      "processing_time": 53.86836838722229,
      "citing_paper_id": "202539583",
      "cited_paper_id": 4942873
    },
    {
      "context_text": "…that has taken place in multi-rounds dialogues. ability to consider previous utterances is the Using the context information (dialogue history) to transform the weights of recurrent units in RNN to effectively capture high-dimensional context core to build active and engaging dialogue systems [9].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the importance of using dialogue history in dialogue systems.",
      "processing_time": 53.19228529930115,
      "citing_paper_id": "202539583",
      "cited_paper_id": 5523008
    },
    {
      "context_text": "Since this framework has no limitation of the length of input and output sequences, it has been widely used in the text generation task, including machine translation [12], text summarization [58], dialogue systems [68], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general applications of the framework in text generation tasks. No verifiable resources are identified.",
      "processing_time": 54.764501094818115,
      "citing_paper_id": "202539583",
      "cited_paper_id": 5590763
    },
    {
      "context_text": "Since this framework has no limitation of the length of input and output sequences, it has been widely used in the text generation task, including machine translation [12], text summarization [58], dialogue systems [68], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general applications of the framework in text generation tasks. No verifiable resources are identified.",
      "processing_time": 54.764501094818115,
      "citing_paper_id": "202539583",
      "cited_paper_id": 12300158
    },
    {
      "context_text": "Since this framework has no limitation of the length of input and output sequences, it has been widely used in the text generation task, including machine translation [12], text summarization [58], dialogue systems [68], and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general applications of the framework in text generation tasks. No verifiable resources are identified.",
      "processing_time": 54.764501094818115,
      "citing_paper_id": "202539583",
      "cited_paper_id": null
    },
    {
      "context_text": "e application of text generation from text to text includes machine translation [12], text summarization [58], reading comprehension [29], etc.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of text generation. No dataset names are present in the text.",
      "processing_time": 54.28591179847717,
      "citing_paper_id": "202539583",
      "cited_paper_id": 5590763
    },
    {
      "context_text": "e application of text generation from text to text includes machine translation [12], text summarization [58], reading comprehension [29], etc.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of text generation. No dataset names are present in the text.",
      "processing_time": 54.28591179847717,
      "citing_paper_id": "202539583",
      "cited_paper_id": null
    },
    {
      "context_text": "Serban et al. [59] use Hierarchical Recurrent Encoder-Decoder ( HRED ) model to hierarchically encode the dialogue history for capturing the context information and guiding the generation of replies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (HRED) and its application in dialogue systems.",
      "processing_time": 53.85710024833679,
      "citing_paper_id": "202539583",
      "cited_paper_id": 6126582
    },
    {
      "context_text": "Machine evaluation metrics, such as BLEU [54] and METEOR [6], perform well in the evaluation of machine translation tasks. evaluate the generated results according to the word overlap rate between the generated text and the standard answer.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions evaluation metrics BLEU and METEOR but does not refer to any specific datasets. The focus is on the performance of these metrics in evaluating machine translation tasks.",
      "processing_time": 55.807390451431274,
      "citing_paper_id": "202539583",
      "cited_paper_id": 7164502
    },
    {
      "context_text": "the LSTM language model in an unsupervised way, the contextual word vector of each word can be obtained to demonstrate strong results across discriminative natural language understanding (NLU) tasks [94] [104]. Recent pre-trained language models based on large Transformer architectures prove the ability of both big models and big data to improve language representation and generation performance. Tra",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general references to 'big data' and 'large Transformer architectures'. No verifiable resource names are provided.",
      "processing_time": 55.43909502029419,
      "citing_paper_id": "202539583",
      "cited_paper_id": 9447219
    },
    {
      "context_text": "Xing et al. [76] propose a topic-aware Seq2seq ( TA-Seq2Seq ) model to generate informative and interesting responses for chatbots, which incorporates topic information of the dialogue history extracted by the pre-trained LDA model, followed by a joint attention mechanism for generation guidance.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and methodology. The focus is on the TA-Seq2Seq model and its components.",
      "processing_time": 55.28503704071045,
      "citing_paper_id": "202539583",
      "cited_paper_id": 9514751
    },
    {
      "context_text": "Attention mechanism is applied to the Seq2seq model to fulfill machine translation tasks in the beginning which achieves the best results [4].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (attention mechanism in Seq2seq model).",
      "processing_time": 53.87102818489075,
      "citing_paper_id": "202539583",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "[77] leverage the aention mechanism to extend the HRED model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (attention mechanism) used to extend a model (HRED).",
      "processing_time": 54.785232067108154,
      "citing_paper_id": "202539583",
      "cited_paper_id": 14247119
    },
    {
      "context_text": "[77] introduce a aention-based multi-turn response generation model to nd the most import information in the dialogue context.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model for response generation. No verifiable resources are identified.",
      "processing_time": 54.394750356674194,
      "citing_paper_id": "202539583",
      "cited_paper_id": 14247119
    },
    {
      "context_text": "Serban et al. [60] attach the latent variable to the hierarchical dialogue model to assign the generative model with multiple levels of variability to generate meaningful and diverse responses. attach a high-dimensional latent variable to each sentence in the dialogue history and then generates…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for generating dialogues using a hierarchical latent variable encoder-decoder model.",
      "processing_time": 54.78065776824951,
      "citing_paper_id": "202539583",
      "cited_paper_id": 14857825
    },
    {
      "context_text": "Yan et al. [80] concatenate the context dialogue sentences and the input straightway while others leverage hierarchical models to firstly capture contextual information in each sentence and then integrate them to capture contextual information in the whole dialogue process [60].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and approaches for generating dialogues.",
      "processing_time": 53.34243702888489,
      "citing_paper_id": "202539583",
      "cited_paper_id": 14857825
    },
    {
      "context_text": "Jaech et al. [32] utilize the context information to transform weights of the recurrent layer in RNN.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for adapting RNNs using context information.",
      "processing_time": 53.7982382774353,
      "citing_paper_id": "202539583",
      "cited_paper_id": 19096382
    },
    {
      "context_text": "…development of universal text generation technology, researchers turn to concentrate on more anthropomorphic text generation technology, such as context-based text generation [32], personalized text generation [43], topic-aware text generation [72], and knowledge-enhanced text generation [83].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only types of text generation technologies. No verifiable resources are identified.",
      "processing_time": 54.273152351379395,
      "citing_paper_id": "202539583",
      "cited_paper_id": 19096382
    },
    {
      "context_text": "…development of universal text generation technology, researchers turn to concentrate on more anthropomorphic text generation technology, such as context-based text generation [32], personalized text generation [43], topic-aware text generation [72], and knowledge-enhanced text generation [83].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only types of text generation technologies. No verifiable resources are identified.",
      "processing_time": 54.273152351379395,
      "citing_paper_id": "202539583",
      "cited_paper_id": 261514205
    },
    {
      "context_text": "[35] HRED + Speaker model Combing the HRED and speaker model to beer capture context-related information and user personalized features; Generating personal and context relevant responses",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The focus is on combining HRED and speaker models for personalized responses.",
      "processing_time": 55.1683669090271,
      "citing_paper_id": "202539583",
      "cited_paper_id": 20956365
    },
    {
      "context_text": "the same author. RL can control the quality of generated content through different policies or rewards, so researchers consider incorporating it to implement personalized text generation. Yang et al. [144] present the attention-based hierarchical encoder-decoder architecture via RL to realize personalized dialogue generation, which defines three types of reward mechanisms, includingtopic coherence, mut",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'personalized dialogue generation' and 'reward mechanisms', indicating the use of a specific method rather than a dataset. No specific dataset names are mentioned.",
      "processing_time": 55.84994411468506,
      "citing_paper_id": "202539583",
      "cited_paper_id": 21669082
    },
    {
      "context_text": "fine-tuned Respectively using massive generic dialogue data and a small-scale personalized dialogue data to pre-trained and fine-tune the dialogue model to generate personalized responses Yang et al. [144] Reinforcement Learning + Persona embedding Embedding user-specific information into vector representation; RL mechanism optimizes three rewards – topic coherent, informative and grammatical, to gener",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "massive generic dialogue data",
        "small-scale personalized dialogue data"
      ],
      "dataset_descriptions": {
        "massive generic dialogue data": "Used to pre-train the dialogue model, focusing on generating general conversational responses before personalization.",
        "small-scale personalized dialogue data": "Used to fine-tune the pre-trained model, focusing on incorporating user-specific information to generate personalized responses."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'massive generic dialogue data' and 'small-scale personalized dialogue data', which are domain-qualified data phrases. However, they lack specific identifiers. No other specific datasets are mentioned.",
      "processing_time": 69.46644330024719,
      "citing_paper_id": "202539583",
      "cited_paper_id": 21669082
    },
    {
      "context_text": "Choudhary et al. [13] observe that topic information can be divided into multiple domains (e.g., games, sports, movies), and thus they utilize domain classifiers to capture domain information from the dialogue history for generating domain-relevant responses.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the use of domain classifiers to capture domain information from dialogue history, but does not specify a named dataset. The reference is more about the method or approach rather than a specific dataset.",
      "processing_time": 56.65588045120239,
      "citing_paper_id": "202539583",
      "cited_paper_id": 28896855
    },
    {
      "context_text": "[52] build an assistive system helping users to write reviews.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general task of building an assistive system for writing reviews.",
      "processing_time": 54.056143045425415,
      "citing_paper_id": "202539583",
      "cited_paper_id": 29161455
    },
    {
      "context_text": "Instead of encoding personalized features into vector representations directly, Herzig et al. [30] use an additional neural network to capture the high-level personality-based information. additional layer implicitly influences the decoding hidden state to ensure that the personalized features are…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for incorporating personality traits into neural response generation.",
      "processing_time": 54.05224561691284,
      "citing_paper_id": "202539583",
      "cited_paper_id": 34405847
    },
    {
      "context_text": "oal of sampling-based decoding strategies is to reduce repetitions and increase the diversity of the generated content, by utilizing stochastic decisions in the generation process. The Top-k sampling [37] samples from the next-token distribution after having filtered this distribution to keep only the top�tokens, while the Top-p sampling [53], also known as nucleus sampling, samples from the top token",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only sampling methods. No verifiable resources are identified.",
      "processing_time": 53.60055422782898,
      "citing_paper_id": "202539583",
      "cited_paper_id": 44134226
    },
    {
      "context_text": "ention module. A long article usually spans many topics, while a simple text summary usually cannot cover all topics. To generate text summaries of specific topics of interest to users, Krishnaet al. [67] propose to generate multi summarizations for a given article according to different topics. With an article and a topic of ACM Trans. Intell. Syst. Technol., Vol. 1, No. 1, Article . Publication date",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses a method for generating topic-oriented summaries but does not reference any particular dataset used for this purpose.",
      "processing_time": 55.970552921295166,
      "citing_paper_id": "202539583",
      "cited_paper_id": 44160625
    },
    {
      "context_text": "get topic information, CNN to capture the dialogue information, and RL to optimize the model with specific evaluation metric; Generating coherent, diverse, and informative text summaries Feng et al. [38] RNN + Topic embedding Assigning each topic with different weight to maintain a multi-topic coverage vector and updating them in the decoding process in order interest as input, the proposed pointer-g",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It focuses on methods and models used for generating text summaries and maintaining multi-topic coverage.",
      "processing_time": 55.34094452857971,
      "citing_paper_id": "202539583",
      "cited_paper_id": 51609716
    },
    {
      "context_text": "es) to provide the fine-grained guidance for the generator. They adopt domain classifiers to capture domain information from the dialogue history for generating domain-relevant responses. Feng et al. [38] develop a multi-topic-aware LSTM (MTA-LSTM) model to generate a paragraph-level text under target multiple topic words. In the MTA-LSTM model, each topic will be assigned with different weights to ma",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of domain classifiers and topic-aware models for generating text.",
      "processing_time": 55.70408487319946,
      "citing_paper_id": "202539583",
      "cited_paper_id": 51609716
    },
    {
      "context_text": "xtracted from the Ubuntu chat logs PERSONA CHAT [151] Personalized dataset A personalized dialogue dataset where two parts of every conversation are given a group of profile information Humeau et al. [92] Personalized dataset A profile-based dialogue dataset; Extracting personalized characteristics from users’ posts in REDDIT TaoDescribe [18] Personalized dataset A personalized product description dat",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PERSONA CHAT",
        "REDDIT TaoDescribe"
      ],
      "dataset_descriptions": {
        "PERSONA CHAT": "Used to train personalized dialogue agents, focusing on incorporating user profiles into conversations to enhance personalization.",
        "REDDIT TaoDescribe": "Used to extract personalized characteristics from users' posts, enhancing the ability to generate personalized dialogues and product descriptions."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions specific personalized dialogue datasets, which are relevant to the topic of personalized text generation.",
      "processing_time": 66.16883325576782,
      "citing_paper_id": "202539583",
      "cited_paper_id": 52167799
    },
    {
      "context_text": "CHAT18. In each dialogue, two parts of the conversation are given a group of profile information, and the whole dialogue process is conducted around these personalized characteristics. Humeau et al. [92] build an authoritative profile-based dialogue dataset using conversations collecting from REDDIT19. The personalized characteristics are extracted from users’ social posts, providing a new opportunit",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "REDDIT19"
      ],
      "dataset_descriptions": {
        "REDDIT19": "Used to build a profile-based dialogue dataset, where personalized characteristics are extracted from users' social posts to conduct dialogues with personalized traits."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions a dataset built from Reddit conversations, which is relevant to personalized text generation. The dataset is described as profile-based and used for dialogues with personalized characteristics.",
      "processing_time": 63.51258587837219,
      "citing_paper_id": "202539583",
      "cited_paper_id": 52167799
    },
    {
      "context_text": "In the past two years, the pre-training and fine-tuning research mode has been studied extensively in NLP, among which the BERT model [18] and the GPT model [56], all based on the Transformer model, receive the most attention.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their popularity in NLP research.",
      "processing_time": 53.86233568191528,
      "citing_paper_id": "202539583",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "[20] HRED + LDA + Topic embedding Combining topic and context information to produce not only contextual but also topic-aware responses",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The focus is on combining topic and context information for response generation.",
      "processing_time": 55.12578320503235,
      "citing_paper_id": "202539583",
      "cited_paper_id": 53217693
    },
    {
      "context_text": "eneration and image understanding. By understanding image content and corresponding questions at the same time, visual QA technology can generate answers of questions related to the images. Li et al. [70] convert visual QA question into a machine reading comprehension problem combined with the large-scale external knowledge base to realize the knowledge-based visual QA. WiththerapiddevelopmentofNLPtec",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for converting visual QA questions into a machine reading comprehension problem.",
      "processing_time": 54.87994980812073,
      "citing_paper_id": "202539583",
      "cited_paper_id": 53955763
    },
    {
      "context_text": "As to the diversified text generation, Jiang et al. [33] introduce another loss function to improve the cross-entropy in the traditional RNN model, namely Frequency-Aware Cross-Entropy ( FACE ).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Frequency-Aware Cross-Entropy) used to improve text generation diversity.",
      "processing_time": 55.32212018966675,
      "citing_paper_id": "202539583",
      "cited_paper_id": 67855963
    },
    {
      "context_text": "tribution of generated words will be narrowed down, thus improving the rationality of generated content. Consequently, the VAE is widely used in topic-aware text generation. For instance, Wang et al. [135] propose a topic-guided variational autoencoder(TGVAE)methodtogeneratenaturallanguagetextundertheguidanceofthedesignated topic. Specifically, TGVAE generates a Gaussian mixture model (GMM) for latent",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses a method (TGVAE) and its application in topic-aware text generation, but no dataset names are provided.",
      "processing_time": 56.432459592819214,
      "citing_paper_id": "202539583",
      "cited_paper_id": 81982679
    },
    {
      "context_text": "Chen et al. [10] realize a personalized produce description generation model using neural networks combined with the knowledge base.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions a 'knowledge base' but does not specify a named, verifiable dataset. The term 'knowledge base' is too generic and lacks a specific identifier.",
      "processing_time": 56.185057401657104,
      "citing_paper_id": "202539583",
      "cited_paper_id": 88524997
    },
    {
      "context_text": "Li et al. [39] propose a RL-based dialogue model combined with an emotional editor module to generate emotional, topic-relevant and meaningful dialogue responses. emotional editor module selects the template sentences according to the emotion and topic information in the dialogue history and the RL…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RL-based dialogue model with an emotional editor module).",
      "processing_time": 54.758445501327515,
      "citing_paper_id": "202539583",
      "cited_paper_id": 119304814
    },
    {
      "context_text": "tic decisions in the generation process. The Top-k sampling [37] samples from the next-token distribution after having filtered this distribution to keep only the top�tokens, while the Top-p sampling [53], also known as nucleus sampling, samples from the top tokens with a cumulative probability just above a threshold �. The above decoding strategies are aiming at making the distribution of generated w",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only decoding strategies for text generation. No verifiable resources are identified.",
      "processing_time": 54.75552988052368,
      "citing_paper_id": "202539583",
      "cited_paper_id": 127986954
    },
    {
      "context_text": "020. Conditional Text Generation for Harmonious Human-Machine Interaction 31 for unconditional text generation to jointly train encoders and decoders for better generation performance, including MASS [120], UniLM [34], BART [68], T5 [108] and so on. For example, MASS combines the pre-training of encoder and decoder to reconstruct a sentence fragment, which masks a piece of tokens of input sentences ran",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods used for text generation. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 55.55293655395508,
      "citing_paper_id": "202539583",
      "cited_paper_id": 146808476
    },
    {
      "context_text": "nal Text Generation for Harmonious Human-Machine Interaction 31 for unconditional text generation to jointly train encoders and decoders for better generation performance, including MASS [120], UniLM [34], BART [68], T5 [108] and so on. For example, MASS combines the pre-training of encoder and decoder to reconstruct a sentence fragment, which masks a piece of tokens of input sentences randomly in the",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on describing various models used for unconditional text generation.",
      "processing_time": 55.133586168289185,
      "citing_paper_id": "202539583",
      "cited_paper_id": 147704286
    },
    {
      "context_text": "ved as the input of the decoder to generate knowledgeable responses. Due to the powerful performance of Transformer, more and more researchers begin to use it for knowledge understanding. Zhao et al. [156] introduce the hierarchical interaction between the context and external document knowledge to capture the most important parts in the document and context using the multi-head attention module in Tra",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of Transformer and a method for knowledge understanding. No verifiable resources are identified.",
      "processing_time": 55.38875484466553,
      "citing_paper_id": "202539583",
      "cited_paper_id": 184487709
    },
    {
      "context_text": "ributes, the relevant knowledge, and the specific user categories into semantic vector representations, and perform deep semantic interaction to capture semantic features for the decoder. Yang et al. [143] fuse external knowledge into topic-to-essay generation systems to provide background information for essay generation. The memory-augmented neural model selects knowledge concepts and then stores the",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methods and models for integrating knowledge into text generation systems.",
      "processing_time": 55.12488055229187,
      "citing_paper_id": "202539583",
      "cited_paper_id": 196197006
    },
    {
      "context_text": "l knowledge of text generation systems. However, existing knowledge-enhanced text generation systems are mainly based on the structured knowledge graph or unstructured knowledge base built in advance [78][98], which cannot perform real-time knowledge selection and fusion from crowdsourced data and usually cover several specific domains. Crowd intelligence data covers a wide range of domains and dynami",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only general references to structured knowledge graphs and unstructured knowledge bases. No specific, verifiable datasets are named.",
      "processing_time": 55.68744993209839,
      "citing_paper_id": "202539583",
      "cited_paper_id": 196210081
    },
    {
      "context_text": "external document knowledge to capture the most important parts in the document and context using the multi-head attention module in Transformer for selecting the most appropriate response. Li et al. [78] generate vector representations of external knowledge using the multi-head attention mechanism and then incorporates them to encode knowledge utterances span in the multi-turn dialogue. The decoder f",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is focused on the use of multi-head attention in Transformers for generating vector representations of external knowledge in dialogues.",
      "processing_time": 56.22499060630798,
      "citing_paper_id": "202539583",
      "cited_paper_id": 196210081
    },
    {
      "context_text": "iverse captions of given images are generated. Previous works usually generate latent variables for entire input sentences, ignoring information about the substructures in the sentences. Aneja et al. [1] develop the SeqCVAE model, which learns a latent space for every word to capture the ‘intention’ about how to complete the sentence. The data-dependent transition model captures the ‘intention’, a re",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (SeqCVAE) and its functionality. No verifiable resources are identified.",
      "processing_time": 55.533395767211914,
      "citing_paper_id": "202539583",
      "cited_paper_id": 201327983
    },
    {
      "context_text": "s. The most straightforward way to incorporate pre-trained language models to CTG systems is to modify the model architecture for extra conditional inputs or condition-specific finetuning. Mao et al. [90] perform intermediate fine-tuning on the story data to adapt the pre-trained GPT-2 model to the domain of stories, and then fine-tune on the target story generation dataset with a multi-task learning",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "story data",
        "target story generation dataset"
      ],
      "dataset_descriptions": {
        "story data": "Used for intermediate fine-tuning to adapt the pre-trained GPT-2 model to the domain of stories, enhancing the model's ability to generate coherent narratives.",
        "target story generation dataset": "Used for final fine-tuning with multi-task learning to improve the performance of the model on specific story generation tasks, focusing on targeted common sense grounding."
      },
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'story data' and 'target story generation dataset', which are domain-qualified data phrases. However, no specific dataset names are provided.",
      "processing_time": 71.55063319206238,
      "citing_paper_id": "202539583",
      "cited_paper_id": 201666118
    },
    {
      "context_text": "ion, which makes it difficult to distinguish which part of latent variables controls the structure and which part controls the semantics of natural language. In order to solve this problem, Li et al. [75] develop the TATGM model, which adopts a sequential VAE to learn the structural features of text and a topic model to extract the semantic features of text to generate different expressions of the sam",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (TATGM) and its components (sequential VAE, topic model). No verifiable resources are identified.",
      "processing_time": 57.0189745426178,
      "citing_paper_id": "202539583",
      "cited_paper_id": 202763690
    },
    {
      "context_text": "ining on latent variables, instead of assuming that latent variables subject to a simple Gaussian distribution to fit the real data distribution and improve the generation ability of VAE. Chan et al. [14] embed and mix the user-level and sentence-level information into multimodal latent distributions. The mixed distribution is then regarded as the prior distribution of WAE, and extended to the Gaussia",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methods and models, but no dataset names are provided.",
      "processing_time": 55.737531661987305,
      "citing_paper_id": "202539583",
      "cited_paper_id": 202788651
    },
    {
      "context_text": "lated document, encode them into vectors by TransE, and concatenate them with the internal vectors of NMT embeddings as the decoder input to enhance the quality of generated translations. Gune et al. [49] extract entities from external KG and adopt TransE to get vectors of them. The knowledge vectors are then fed into the separate multi-head attention channel to generate coherent text summaries. The a",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methods and models such as TransE and NMT, but these are not datasets.",
      "processing_time": 55.97973346710205,
      "citing_paper_id": "202539583",
      "cited_paper_id": 204735695
    },
    {
      "context_text": "arbitrary length of the input sentence, these additional conditional inputs can be injected into the pre-trained model without changing the model architecture to affect the generated text. Chenet al. [21] leverage the idea of model distilling for better text generation performance. The Conditional Masked Language Modeling (C-MLM) task is proposed to enable pre-trained BERT with additional conditional",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited paper title confirms the focus on model distillation and text generation, not on datasets.",
      "processing_time": 56.95511865615845,
      "citing_paper_id": "202539583",
      "cited_paper_id": 218915023
    },
    {
      "context_text": "ware representation of the source sentence through the attention mechanism. It is identified that pronoun is the key information captured by the model. In the field of machine translation, Kanget al. [58] proposed to select contextual sentences dynamically for each source sentence to be translated. The Context Scorer module is used to score each context sentence based on the currently translated sourc",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for dynamic context selection in neural machine translation.",
      "processing_time": 55.28588271141052,
      "citing_paper_id": "202539583",
      "cited_paper_id": 222272091
    },
    {
      "context_text": "In [83], Young et al. propose a dialogue model integrating a large commonsense knowledge base to retrieve commonsense knowledge about concepts appeared in the dialogue. retrieved knowledge and dialogue context are encoded respectively to guide the response generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a 'large commonsense knowledge base' but does not specify a name. The focus is on the method of integrating commonsense knowledge into dialogue systems.",
      "processing_time": 56.47150659561157,
      "citing_paper_id": "202539583",
      "cited_paper_id": 261514205
    },
    {
      "context_text": "[17] propose a Q&A model, called TraCRNet, to achieve the goal of open-domain query answering.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model called TraCRNet. There are no verifiable resources or datasets mentioned.",
      "processing_time": 56.13840913772583,
      "citing_paper_id": "202539583",
      "cited_paper_id": 266003912
    },
    {
      "context_text": "d reasons. Zhong et al. suggest that persona plays an important role in empathetic conversations, and first present a novel large-scale multi-domain dataset for persona-based empathetic conversations [161]. Based on this dataset, they propose an efficient BERT-based response selection model, CoBERT, using multi-hop co-attention to learn higher-level interactive matching. External knowledge can provide",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "novel large-scale multi-domain dataset for persona-based empathetic conversations"
      ],
      "dataset_descriptions": {
        "novel large-scale multi-domain dataset for persona-based empathetic conversations": "Used to train and evaluate a BERT-based response selection model, CoBERT, focusing on persona-based empathetic conversations and multi-hop co-attention for interactive matching."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions a 'novel large-scale multi-domain dataset for persona-based empathetic conversations' which is relevant to personalized text generation. The dataset is used to train and evaluate a BERT-based response selection model.",
      "processing_time": 70.42336416244507,
      "citing_paper_id": "202539583",
      "cited_paper_id": 271403894
    },
    {
      "context_text": "Similarly, Clark et al. [14] propose a text generation model in stories, treating entity representations extracted from dialogue history as context.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for text generation in stories using entity representations from dialogue history.",
      "processing_time": 56.257336139678955,
      "citing_paper_id": "202539583",
      "cited_paper_id": null
    },
    {
      "context_text": "Nenkova et al. [40] used the word frequency as a feature of the summarization.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a feature used in summarization. No verifiable resource is identified.",
      "processing_time": 56.033530712127686,
      "citing_paper_id": "146121098",
      "cited_paper_id": 86903
    },
    {
      "context_text": "Ritter et al. [49] took the reply generation problem as a translation problem, in which the process of generating replies was regarded to translate the query into corresponding replies.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach to reply generation.",
      "processing_time": 55.36859917640686,
      "citing_paper_id": "146121098",
      "cited_paper_id": 780171
    },
    {
      "context_text": "Vinyals et al. [60] proposed a generation model based on deep RNN architecture.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a model/method. The context is about proposing a generation model based on deep RNN architecture.",
      "processing_time": 57.006470680236816,
      "citing_paper_id": "146121098",
      "cited_paper_id": 1169492
    },
    {
      "context_text": "The theme of [50] from Facebook was attention-based NN to generate sentence summarization.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating sentence summarization using attention-based neural networks.",
      "processing_time": 55.82936382293701,
      "citing_paper_id": "146121098",
      "cited_paper_id": 1918428
    },
    {
      "context_text": "Socher et al. introduced a model that recognized objects in images even when there was no training data available in the object class [52].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a model and its capability. The context is about zero-shot learning, which is a method, not a dataset.",
      "processing_time": 57.31191611289978,
      "citing_paper_id": "146121098",
      "cited_paper_id": 2808203
    },
    {
      "context_text": "It was found that matching only from the perspective of words could not achieve good results, so Zhou et al. proposed matching through multiple levels (word level and utterance level), and its multi-dimensional thinking provided direction for the following papers [71].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach for response selection in human-computer conversation.",
      "processing_time": 55.882463216781616,
      "citing_paper_id": "146121098",
      "cited_paper_id": 2867243
    },
    {
      "context_text": "Ren et al. [48] used neural networks and visual semantic embedding and not included intermediate stages, such as object construction and image segmentation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the use of neural networks and visual semantic embedding, which are not datasets.",
      "processing_time": 57.33446907997131,
      "citing_paper_id": "146121098",
      "cited_paper_id": 2950705
    },
    {
      "context_text": "Mo et al. and Yang et al. made use of the idea of transfer learning [38; 65].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the concept of transfer learning.",
      "processing_time": 54.83469915390015,
      "citing_paper_id": "146121098",
      "cited_paper_id": 2963092
    },
    {
      "context_text": "Pasunuru et al. also used reinforcement learning to generate the summarization of the article [44].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (reinforcement learning) used for summarization.",
      "processing_time": 55.72289061546326,
      "citing_paper_id": "146121098",
      "cited_paper_id": 4940548
    },
    {
      "context_text": "Cao et al. [5] used the attention mechanism to weight the sentences.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only the use of an attention mechanism. The context is too limited to infer the presence of a dataset.",
      "processing_time": 56.87590169906616,
      "citing_paper_id": "146121098",
      "cited_paper_id": 8244856
    },
    {
      "context_text": "In [29], dual encoder model was proposed by Lowe et al. for semantic representation of context and reply content.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a model. The title of the cited paper suggests a dataset, but it is not mentioned in the citation context.",
      "processing_time": 56.99690270423889,
      "citing_paper_id": "146121098",
      "cited_paper_id": 8379583
    },
    {
      "context_text": "Nallapati et al. [39] not only included work on sentence compression, but also presented a new data set about document into a multi-sentence.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions a 'new data set' but does not provide a specific name. The title of the cited paper suggests the dataset is related to abstractive text summarization, but no specific name is given.",
      "processing_time": 59.52748107910156,
      "citing_paper_id": "146121098",
      "cited_paper_id": 8928715
    },
    {
      "context_text": "GAN[15] proposed by Goodfellow consists of two parts: one generator and one discriminator.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the GAN model and its components.",
      "processing_time": 55.244868993759155,
      "citing_paper_id": "146121098",
      "cited_paper_id": 10319744
    },
    {
      "context_text": "Wen et al. [62] constructed a task-oriented dialogue system by using a modular neural generation model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for constructing a task-oriented dialogue system.",
      "processing_time": 55.42800688743591,
      "citing_paper_id": "146121098",
      "cited_paper_id": 10565222
    },
    {
      "context_text": "Ma et al. applied CNN to VQA tasks [32] and provided an end-to-end convolutional framework for learning not only images and problem representations, but also the modal interactions between them to generate answers.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (CNN) applied to VQA tasks. The context focuses on the methodology and the interaction between images and questions.",
      "processing_time": 57.827128171920776,
      "citing_paper_id": "146121098",
      "cited_paper_id": 11216909
    },
    {
      "context_text": "Sordoni et al. and Vinyals et al. [53; 59] began to apply RNN to construct the dialogue model, and applied the neural network method to the end-to-end dialogue model for the first time.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the application of RNNs and neural networks to dialogue models.",
      "processing_time": 55.92074394226074,
      "citing_paper_id": "146121098",
      "cited_paper_id": 12300158
    },
    {
      "context_text": "Kiros et al. [19] introduced the neural language model of multimodal constraint and used CNN to learn the word representation and image features together.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a method (neural language model of multimodal constraint) and its application (learning word representation and image features together) but does not reference a specific dataset.",
      "processing_time": 57.673447132110596,
      "citing_paper_id": "146121098",
      "cited_paper_id": 12365096
    },
    {
      "context_text": "To address this problem, researchers have made some fine-tuning to GAN's structure, which brings hope for the generation of discrete data [2; 22].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only adjustments to GAN's structure. No verifiable resources are identified.",
      "processing_time": 55.926658630371094,
      "citing_paper_id": "146121098",
      "cited_paper_id": 13943041
    },
    {
      "context_text": "Noh et al. [42] used an independent parametric predictive network with a GRU with the question as input and a fully connected layer generating as output.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving a GRU and a fully connected layer.",
      "processing_time": 55.45361328125,
      "citing_paper_id": "146121098",
      "cited_paper_id": 14420812
    },
    {
      "context_text": "Review generation belongs to data-to-text natural language generation [14].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to data-to-text natural language generation.",
      "processing_time": 55.4813346862793,
      "citing_paper_id": "146121098",
      "cited_paper_id": 16946362
    },
    {
      "context_text": "The study in [36] is the pioneering application of RNN for the construction of language models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the use of RNNs for language modeling.",
      "processing_time": 55.008641958236694,
      "citing_paper_id": "146121098",
      "cited_paper_id": 17048224
    },
    {
      "context_text": "[10] proposed an attention-enhanced attribute-tosequence model to generate product reviews for given attribute information, such as users, products, and ratings.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions an attention-enhanced attribute-to-sequence model for generating product reviews but does not specify any dataset names. The focus is on the method rather than a specific dataset.",
      "processing_time": 57.320258140563965,
      "citing_paper_id": "146121098",
      "cited_paper_id": 17865105
    },
    {
      "context_text": "[51] used the model similar to [10] and added loss terms to generate more compliant comments.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and loss terms. No verifiable resources are identified.",
      "processing_time": 55.3547682762146,
      "citing_paper_id": "146121098",
      "cited_paper_id": 17865105
    },
    {
      "context_text": "The model was composed of two subnetworks: sentence depth RNN and image depth CNN. Kulkarni et al. [21] introduced an automatic natural language description generation system based on image, which used a lot of statistical information of text data and computer vision recognition algorithm.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for generating image descriptions. No clear, verifiable dataset names are provided.",
      "processing_time": 55.629931688308716,
      "citing_paper_id": "146121098",
      "cited_paper_id": 18124397
    },
    {
      "context_text": "Within the field of recommender systems, a promising application is to estimate (or generate) personalized reviews that a user would write about a product, to discover their nuanced opinions about each of its individual aspects [41].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions personalized review generation but does not specify any dataset names. The cited paper title suggests the use of aspect-aware representations but does not mention a specific dataset.",
      "processing_time": 56.46270179748535,
      "citing_paper_id": "146121098",
      "cited_paper_id": 29161455
    },
    {
      "context_text": "Ni et al. [41] designed a review generation model that could make use of user and project information as well as auxiliary text input and aspect perception knowledge.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model and its capabilities. The context focuses on the method and its application rather than a particular dataset.",
      "processing_time": 55.896225452423096,
      "citing_paper_id": "146121098",
      "cited_paper_id": 29161455
    },
    {
      "context_text": "Joshi et al. [18] published the dataset of task-oriented dialogue system, in which each conversation contained the user's personalized information, providing data support for subsequent research.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "task-oriented dialogue system dataset"
      ],
      "dataset_descriptions": {
        "task-oriented dialogue system dataset": "Used to provide data support for research on personalized text generation, specifically containing conversations with users' personalized information."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions a specific dataset published by Joshi et al. that contains task-oriented dialogues with personalized user information, which is directly relevant to personalized text generation.",
      "processing_time": 63.26900577545166,
      "citing_paper_id": "146121098",
      "cited_paper_id": 29473470
    },
    {
      "context_text": "Zhang et al. used LSTM as generator and CNN as discriminator to implement the task of text generation [70].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods used for text generation.",
      "processing_time": 53.783979415893555,
      "citing_paper_id": "146121098",
      "cited_paper_id": 29797603
    },
    {
      "context_text": "Considering the lack of dialogue data with user personalized characteristics, Luan et al. [30] applied the multi-task learning mechanism to the personalized reply generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the application of multi-task learning for personalized reply generation but does not specify a dataset name. The context is too generic to identify a specific dataset.",
      "processing_time": 55.68375587463379,
      "citing_paper_id": "146121098",
      "cited_paper_id": 31298398
    },
    {
      "context_text": "Luo et al. [31] made use of a variant of RNN--memory network to realize the task-oriented personalized dialogue system.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RNN--memory network) used for a personalized dialogue system.",
      "processing_time": 54.78963875770569,
      "citing_paper_id": "146121098",
      "cited_paper_id": 53287752
    },
    {
      "context_text": "In addition, the memory network, a variant of RNN, was proposed to store the current user's dialogue context and similar user's conversation history with external memory module [31].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (memory network) and its purpose (storing dialogue context and conversation history).",
      "processing_time": 55.0820574760437,
      "citing_paper_id": "146121098",
      "cited_paper_id": 53287752
    },
    {
      "context_text": "Several studies focused on a specific topic and schema such as WEATHERGOV (Liang et al., 2009) and ROBOCUP (Chen and Mooney, 2008), Rotowire (Wiseman et al., 2017), Wikibio (Lebret et al., 2016, Biographies), E2E (Novikova et al., 2016, Restau-rants).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WEATHERGOV",
        "ROBOCUP",
        "Rotowire",
        "Wikibio",
        "E2E"
      ],
      "dataset_descriptions": {
        "WEATHERGOV": "Used to generate weather reports from structured data, focusing on semantic correspondences with less supervision.",
        "ROBOCUP": "Used to generate sports commentaries from game data, testing grounded language acquisition in a sports context.",
        "Rotowire": "Used to generate basketball game summaries from box scores, focusing on natural language generation from structured data.",
        "Wikibio": "Used to generate biographical texts from Wikipedia infoboxes, focusing on text generation in the biography domain.",
        "E2E": "Used to generate personalized restaurant reviews, focusing on evaluating the effectiveness of neural models in generating coherent and contextually appropriate text."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets that are used for text generation tasks, which align with the research topic of personalized text generation.",
      "processing_time": 73.73608016967773,
      "citing_paper_id": "280026233",
      "cited_paper_id": 238873
    },
    {
      "context_text": "Several studies focused on a specific topic and schema such as WEATHERGOV (Liang et al., 2009) and ROBOCUP (Chen and Mooney, 2008), Rotowire (Wiseman et al., 2017), Wikibio (Lebret et al., 2016, Biographies), E2E (Novikova et al., 2016, Restau-rants).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WEATHERGOV",
        "ROBOCUP",
        "Rotowire",
        "Wikibio",
        "E2E"
      ],
      "dataset_descriptions": {
        "WEATHERGOV": "Used to generate weather reports from structured data, focusing on semantic correspondences with less supervision.",
        "ROBOCUP": "Used to generate sports commentaries from game data, testing grounded language acquisition in a sports context.",
        "Rotowire": "Used to generate basketball game summaries from box scores, focusing on natural language generation from structured data.",
        "Wikibio": "Used to generate biographical texts from Wikipedia infoboxes, focusing on text generation in the biography domain.",
        "E2E": "Used to generate personalized restaurant reviews, focusing on evaluating the effectiveness of neural models in generating coherent and contextually appropriate text."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets that are used for text generation tasks, which align with the research topic of personalized text generation.",
      "processing_time": 73.73608016967773,
      "citing_paper_id": "280026233",
      "cited_paper_id": 1238927
    },
    {
      "context_text": "Several studies focused on a specific topic and schema such as WEATHERGOV (Liang et al., 2009) and ROBOCUP (Chen and Mooney, 2008), Rotowire (Wiseman et al., 2017), Wikibio (Lebret et al., 2016, Biographies), E2E (Novikova et al., 2016, Restau-rants).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WEATHERGOV",
        "ROBOCUP",
        "Rotowire",
        "Wikibio",
        "E2E"
      ],
      "dataset_descriptions": {
        "WEATHERGOV": "Used to generate weather reports from structured data, focusing on semantic correspondences with less supervision.",
        "ROBOCUP": "Used to generate sports commentaries from game data, testing grounded language acquisition in a sports context.",
        "Rotowire": "Used to generate basketball game summaries from box scores, focusing on natural language generation from structured data.",
        "Wikibio": "Used to generate biographical texts from Wikipedia infoboxes, focusing on text generation in the biography domain.",
        "E2E": "Used to generate personalized restaurant reviews, focusing on evaluating the effectiveness of neural models in generating coherent and contextually appropriate text."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets that are used for text generation tasks, which align with the research topic of personalized text generation.",
      "processing_time": 73.73608016967773,
      "citing_paper_id": "280026233",
      "cited_paper_id": 2488088
    },
    {
      "context_text": "Several studies focused on a specific topic and schema such as WEATHERGOV (Liang et al., 2009) and ROBOCUP (Chen and Mooney, 2008), Rotowire (Wiseman et al., 2017), Wikibio (Lebret et al., 2016, Biographies), E2E (Novikova et al., 2016, Restau-rants).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WEATHERGOV",
        "ROBOCUP",
        "Rotowire",
        "Wikibio",
        "E2E"
      ],
      "dataset_descriptions": {
        "WEATHERGOV": "Used to generate weather reports from structured data, focusing on semantic correspondences with less supervision.",
        "ROBOCUP": "Used to generate sports commentaries from game data, testing grounded language acquisition in a sports context.",
        "Rotowire": "Used to generate basketball game summaries from box scores, focusing on natural language generation from structured data.",
        "Wikibio": "Used to generate biographical texts from Wikipedia infoboxes, focusing on text generation in the biography domain.",
        "E2E": "Used to generate personalized restaurant reviews, focusing on evaluating the effectiveness of neural models in generating coherent and contextually appropriate text."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets that are used for text generation tasks, which align with the research topic of personalized text generation.",
      "processing_time": 73.73608016967773,
      "citing_paper_id": "280026233",
      "cited_paper_id": 13530374
    },
    {
      "context_text": "Several studies focused on a specific topic and schema such as WEATHERGOV (Liang et al., 2009) and ROBOCUP (Chen and Mooney, 2008), Rotowire (Wiseman et al., 2017), Wikibio (Lebret et al., 2016, Biographies), E2E (Novikova et al., 2016, Restau-rants).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "WEATHERGOV",
        "ROBOCUP",
        "Rotowire",
        "Wikibio",
        "E2E"
      ],
      "dataset_descriptions": {
        "WEATHERGOV": "Used to generate weather reports from structured data, focusing on semantic correspondences with less supervision.",
        "ROBOCUP": "Used to generate sports commentaries from game data, testing grounded language acquisition in a sports context.",
        "Rotowire": "Used to generate basketball game summaries from box scores, focusing on natural language generation from structured data.",
        "Wikibio": "Used to generate biographical texts from Wikipedia infoboxes, focusing on text generation in the biography domain.",
        "E2E": "Used to generate personalized restaurant reviews, focusing on evaluating the effectiveness of neural models in generating coherent and contextually appropriate text."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions several datasets that are used for text generation tasks, which align with the research topic of personalized text generation.",
      "processing_time": 73.73608016967773,
      "citing_paper_id": "280026233",
      "cited_paper_id": 23892230
    },
    {
      "context_text": "Existing literature has explored techniques to generate descriptions for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.97000789642334,
      "citing_paper_id": "280026233",
      "cited_paper_id": 311011
    },
    {
      "context_text": "Existing literature has explored techniques to generate descriptions for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.97000789642334,
      "citing_paper_id": "280026233",
      "cited_paper_id": 244119798
    },
    {
      "context_text": "…et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Ud-din, 2022; Wang et al., 2022b; Dvivedi et al., 2024; Luo et al., 2024)…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers and code documentation. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.81606078147888,
      "citing_paper_id": "280026233",
      "cited_paper_id": 311011
    },
    {
      "context_text": "…requirements, existing work (Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017; Pasupat and Liang, 2015; Ye et al., 2023;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. The cited paper title 'The Code2Text Challenge: Text Generation in Source Libraries' suggests a challenge or competition, which is excluded unless specific datasets are named.",
      "processing_time": 58.22829604148865,
      "citing_paper_id": "280026233",
      "cited_paper_id": 311011
    },
    {
      "context_text": "We use the ROUGE scores (ROUGE-1, ROUGE-2, and ROUGE-L) (Lin, 2004), BERTScore (Zhang et al., 2019), and G-EVAL (Liu et al., 2023a) to evaluate our model’s performance with regard to the ground-truth description content.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions evaluation metrics (ROUGE, BERTScore, G-EVAL) but does not refer to any specific datasets. These metrics are used to evaluate model performance, not to provide data for training or analysis.",
      "processing_time": 57.65073204040527,
      "citing_paper_id": "280026233",
      "cited_paper_id": 964287
    },
    {
      "context_text": "We use the ROUGE scores (ROUGE-1, ROUGE-2, and ROUGE-L) (Lin, 2004), BERTScore (Zhang et al., 2019), and G-EVAL (Liu et al., 2023a) to evaluate our model’s performance with regard to the ground-truth description content.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions evaluation metrics (ROUGE, BERTScore, G-EVAL) but does not refer to any specific datasets. These metrics are used to evaluate model performance, not to provide data for training or analysis.",
      "processing_time": 57.65073204040527,
      "citing_paper_id": "280026233",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "Rule et al. (2018a) reported that among one million computational notebooks on Github, 25% of them have no comment.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a statistic about computational notebooks on Github. There are no verifiable resources or datasets mentioned.",
      "processing_time": 54.744017601013184,
      "citing_paper_id": "280026233",
      "cited_paper_id": 5048947
    },
    {
      "context_text": "Publicly shared notebooks on GitHub are often ill-documented (Rule et al., 2018b) and do not have many tables, thus are not suitable for this task.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses the quality of notebooks on GitHub, which is not a dataset.",
      "processing_time": 54.507320404052734,
      "citing_paper_id": "280026233",
      "cited_paper_id": 5048947
    },
    {
      "context_text": "Publicly shared notebooks on GitHub are often ill-documented (Rule et al., 2018b) and do not have many tables, thus are not suitable for this task.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses the quality of notebooks on GitHub, which is not a dataset.",
      "processing_time": 54.507320404052734,
      "citing_paper_id": "280026233",
      "cited_paper_id": 209532167
    },
    {
      "context_text": "The main contributions of our work are: (Li et al., 2021; Liu et al., 2018; Parikh et al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.77165079116821,
      "citing_paper_id": "280026233",
      "cited_paper_id": 7672408
    },
    {
      "context_text": "The main contributions of our work are: (Li et al., 2021; Liu et al., 2018; Parikh et al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.77165079116821,
      "citing_paper_id": "280026233",
      "cited_paper_id": 174797747
    },
    {
      "context_text": "The main contributions of our work are: (Li et al., 2021; Liu et al., 2018; Parikh et al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.77165079116821,
      "citing_paper_id": "280026233",
      "cited_paper_id": 216056509
    },
    {
      "context_text": "The main contributions of our work are: (Li et al., 2021; Liu et al., 2018; Parikh et al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.77165079116821,
      "citing_paper_id": "280026233",
      "cited_paper_id": 216641852
    },
    {
      "context_text": "The main contributions of our work are: (Li et al., 2021; Liu et al., 2018; Parikh et al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.77165079116821,
      "citing_paper_id": "280026233",
      "cited_paper_id": 244119798
    },
    {
      "context_text": "The main contributions of our work are: (Li et al., 2021; Liu et al., 2018; Parikh et al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.77165079116821,
      "citing_paper_id": "280026233",
      "cited_paper_id": 265045103
    },
    {
      "context_text": "…has explored techniques to generate descriptions for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a; Ding and Xu,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers exploring techniques for generating descriptions for code snippets or table outputs.",
      "processing_time": 54.23601222038269,
      "citing_paper_id": "280026233",
      "cited_paper_id": 7672408
    },
    {
      "context_text": "…2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017; Pasupat and Liang, 2015; Ye et al., 2023; Zhang et al., 2024; Guo et al., 2024) only focuses Figure 1: An example in our…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided citation span does not mention any specific datasets, models, or methods. It appears to be a list of references without context about their usage.",
      "processing_time": 54.69822454452515,
      "citing_paper_id": "280026233",
      "cited_paper_id": 8822680
    },
    {
      "context_text": "…Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017; Pasupat and Liang, 2015; Ye et al., 2023; Zhang et al., 2024; Guo et al., 2024) only focuses Figure 1: An example in our proposed NBDESCRIB dataset,…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "NBDESCRIB dataset"
      ],
      "dataset_descriptions": {
        "NBDESCRIB dataset": "Used to train and evaluate models for compositional semantic parsing on semi-structured tables, focusing on the ability to handle complex queries and table structures."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions 'NBDESCRIB dataset' which appears to be a specific dataset used in the research context. No other datasets are mentioned.",
      "processing_time": 63.04668045043945,
      "citing_paper_id": "280026233",
      "cited_paper_id": 9027681
    },
    {
      "context_text": "Another task similar to table-to-text is table question answering (Pasupat and Liang, 2015; Wang et al., 2018; Nan et al., 2022; Cheng et al., 2021; Ye et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only tasks and methods. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 54.202022075653076,
      "citing_paper_id": "280026233",
      "cited_paper_id": 9027681
    },
    {
      "context_text": "Another task similar to table-to-text is table question answering (Pasupat and Liang, 2015; Wang et al., 2018; Nan et al., 2022; Cheng et al., 2021; Ye et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only tasks and methods. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 54.202022075653076,
      "citing_paper_id": "280026233",
      "cited_paper_id": 52012400
    },
    {
      "context_text": "Another task similar to table-to-text is table question answering (Pasupat and Liang, 2015; Wang et al., 2018; Nan et al., 2022; Cheng et al., 2021; Ye et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only tasks and methods. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 54.202022075653076,
      "citing_paper_id": "280026233",
      "cited_paper_id": 232478685
    },
    {
      "context_text": "Another task similar to table-to-text is table question answering (Pasupat and Liang, 2015; Wang et al., 2018; Nan et al., 2022; Cheng et al., 2021; Ye et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only tasks and methods. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 54.202022075653076,
      "citing_paper_id": "280026233",
      "cited_paper_id": 237091377
    },
    {
      "context_text": "Another task similar to table-to-text is table question answering (Pasupat and Liang, 2015; Wang et al., 2018; Nan et al., 2022; Cheng et al., 2021; Ye et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only tasks and methods. The cited papers' titles do not provide additional dataset names.",
      "processing_time": 54.202022075653076,
      "citing_paper_id": "280026233",
      "cited_paper_id": 256416408
    },
    {
      "context_text": "Evaluation Results: We conducted Wilcoxon tests (Woolson, 2007) with a significance level of 0.05 to compare the performance of Ground Truth against CodeT5-Large, GPT-3, and GPT-4o in the Cor-rectness, Orientation, and Readability dimensions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only statistical tests and models. No verifiable resources are identified.",
      "processing_time": 53.21875619888306,
      "citing_paper_id": "280026233",
      "cited_paper_id": 30088448
    },
    {
      "context_text": "This aligns with the DUC (Dang, 2005) quality question on structure and coherence, which states that \"the summary should be well-structured and well-organized, building from sentence to sentence to form a coherent body of information about a topic.\"",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions DUC (Dang, 2005) but does not refer to it as a dataset. It is used to describe a quality question on structure and coherence in summarization.",
      "processing_time": 56.537978410720825,
      "citing_paper_id": "280026233",
      "cited_paper_id": 61825275
    },
    {
      "context_text": "We align this dimension with the DUC quality question of structure and coherence whereby the description should be well-structured and well-organized.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a quality question from DUC, which is not a dataset but a conference or evaluation framework.",
      "processing_time": 55.186140298843384,
      "citing_paper_id": "280026233",
      "cited_paper_id": 61825275
    },
    {
      "context_text": "According to the DUC (Dang, 2005) quality guidelines, sentences in the summary \"should have no formatting problems, capitalization errors, or obvious grammatical errors (e.g., fragments, missing components) that make the text difficult to read.\"",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions DUC quality guidelines but does not refer to a specific dataset. It is more about summarization quality standards.",
      "processing_time": 53.45810866355896,
      "citing_paper_id": "280026233",
      "cited_paper_id": 61825275
    },
    {
      "context_text": "Furthermore, although we have automatic evaluation metrics such as ROUGE and BERTScore, the correctness of the generated texts is primarily evaluated through human evaluation, which is accurate but not efficient.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only evaluation metrics. The cited paper title 'BERTScore: Evaluating Text Generation with BERT' confirms that BERTScore is a metric, not a dataset.",
      "processing_time": 56.45430874824524,
      "citing_paper_id": "280026233",
      "cited_paper_id": 127986044
    },
    {
      "context_text": "Chen et al. (2019); Gupta et al. (2020) attempted to verify whether a provided textual statement is entailed or refuted by the given table.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TabFact"
      ],
      "dataset_descriptions": {
        "TabFact": "Used to verify textual statements against tabular data, focusing on entailment and refutation. The dataset supports research into table-based fact verification methodologies."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions fact verification using tables, which aligns with the 'TabFact' dataset. No other specific datasets are mentioned.",
      "processing_time": 60.98589587211609,
      "citing_paper_id": "280026233",
      "cited_paper_id": 198917339
    },
    {
      "context_text": "Chen et al. (2019); Gupta et al. (2020) attempted to verify whether a provided textual statement is entailed or refuted by the given table.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TabFact"
      ],
      "dataset_descriptions": {
        "TabFact": "Used to verify textual statements against tabular data, focusing on entailment and refutation. The dataset supports research into table-based fact verification methodologies."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions fact verification using tables, which aligns with the 'TabFact' dataset. No other specific datasets are mentioned.",
      "processing_time": 60.98589587211609,
      "citing_paper_id": "280026233",
      "cited_paper_id": 209053721
    },
    {
      "context_text": "Chen et al. (2019); Gupta et al. (2020) attempted to verify whether a provided textual statement is entailed or refuted by the given table.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "TabFact"
      ],
      "dataset_descriptions": {
        "TabFact": "Used to verify textual statements against tabular data, focusing on entailment and refutation. The dataset supports research into table-based fact verification methodologies."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions fact verification using tables, which aligns with the 'TabFact' dataset. No other specific datasets are mentioned.",
      "processing_time": 60.98589587211609,
      "citing_paper_id": "280026233",
      "cited_paper_id": 218614095
    },
    {
      "context_text": "Differing from Wang et al. (2020), where their qualitative coding stopped at the tabular data level, and our analysis goes deep to the granularity of the cell, the cell be used to explain beyond the adjacent code cell whose output is the table: we annotate these cells’ purposes and types of content.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses methodological differences in analysis granularity but does not reference any named datasets.",
      "processing_time": 53.849921226501465,
      "citing_paper_id": "280026233",
      "cited_paper_id": 201093978
    },
    {
      "context_text": "Typical datasets include CodeSearchNet (Husain et al., 2019) and some datasets collected from GitHub (Kanade et al., 2019) or BigQuery (Yue Wang, 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CodeSearchNet"
      ],
      "dataset_descriptions": {
        "CodeSearchNet": "Used to evaluate semantic code search, focusing on the effectiveness of models in retrieving relevant code snippets from a large corpus of code."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'CodeSearchNet' and 'datasets collected from GitHub' and 'BigQuery'. CodeSearchNet is a specific dataset, while the others are generic references to data sources.",
      "processing_time": 62.307639360427856,
      "citing_paper_id": "280026233",
      "cited_paper_id": 202712680
    },
    {
      "context_text": "Typical datasets include CodeSearchNet (Husain et al., 2019) and some datasets collected from GitHub (Kanade et al., 2019) or BigQuery (Yue Wang, 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "CodeSearchNet"
      ],
      "dataset_descriptions": {
        "CodeSearchNet": "Used to evaluate semantic code search, focusing on the effectiveness of models in retrieving relevant code snippets from a large corpus of code."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'CodeSearchNet' and 'datasets collected from GitHub' and 'BigQuery'. CodeSearchNet is a specific dataset, while the others are generic references to data sources.",
      "processing_time": 62.307639360427856,
      "citing_paper_id": "280026233",
      "cited_paper_id": 209532167
    },
    {
      "context_text": "Pyramid Evaluation: We employ an automatic evaluation method based on pyramid evaluation (PyrEval) (Gao et al., 2019) to assess the faithfulness of generation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'pyramid evaluation' but does not refer to a specific dataset. It is used to describe an evaluation method.",
      "processing_time": 53.08723211288452,
      "citing_paper_id": "280026233",
      "cited_paper_id": 209053721
    },
    {
      "context_text": "Recently, LLMs have been applied to the CDG task such as CodeLlama (Roziere et al., 2023), CuBERT (Kanade et al., 2019), CodeBERT (Feng et al., 2020), GraphCodeBERT (Guo et al., 2020) or GPT (Svyatkovskiy et al., 2020; Lu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not refer to any specific datasets. The context is focused on the application of large language models to code generation tasks.",
      "processing_time": 54.455243825912476,
      "citing_paper_id": "280026233",
      "cited_paper_id": 209532167
    },
    {
      "context_text": "Recently, LLMs have been applied to the CDG task such as CodeLlama (Roziere et al., 2023), CuBERT (Kanade et al., 2019), CodeBERT (Feng et al., 2020), GraphCodeBERT (Guo et al., 2020) or GPT (Svyatkovskiy et al., 2020; Lu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not refer to any specific datasets. The context is focused on the application of large language models to code generation tasks.",
      "processing_time": 54.455243825912476,
      "citing_paper_id": "280026233",
      "cited_paper_id": 211171605
    },
    {
      "context_text": "Recently, LLMs have been applied to the CDG task such as CodeLlama (Roziere et al., 2023), CuBERT (Kanade et al., 2019), CodeBERT (Feng et al., 2020), GraphCodeBERT (Guo et al., 2020) or GPT (Svyatkovskiy et al., 2020; Lu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not refer to any specific datasets. The context is focused on the application of large language models to code generation tasks.",
      "processing_time": 54.455243825912476,
      "citing_paper_id": "280026233",
      "cited_paper_id": 218673683
    },
    {
      "context_text": "Recently, LLMs have been applied to the CDG task such as CodeLlama (Roziere et al., 2023), CuBERT (Kanade et al., 2019), CodeBERT (Feng et al., 2020), GraphCodeBERT (Guo et al., 2020) or GPT (Svyatkovskiy et al., 2020; Lu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not refer to any specific datasets. The context is focused on the application of large language models to code generation tasks.",
      "processing_time": 54.455243825912476,
      "citing_paper_id": "280026233",
      "cited_paper_id": 221761146
    },
    {
      "context_text": "Recently, LLMs have been applied to the CDG task such as CodeLlama (Roziere et al., 2023), CuBERT (Kanade et al., 2019), CodeBERT (Feng et al., 2020), GraphCodeBERT (Guo et al., 2020) or GPT (Svyatkovskiy et al., 2020; Lu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not refer to any specific datasets. The context is focused on the application of large language models to code generation tasks.",
      "processing_time": 54.455243825912476,
      "citing_paper_id": "280026233",
      "cited_paper_id": 231855531
    },
    {
      "context_text": "Recently, LLMs have been applied to the CDG task such as CodeLlama (Roziere et al., 2023), CuBERT (Kanade et al., 2019), CodeBERT (Feng et al., 2020), GraphCodeBERT (Guo et al., 2020) or GPT (Svyatkovskiy et al., 2020; Lu et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several models and methods but does not refer to any specific datasets. The context is focused on the application of large language models to code generation tasks.",
      "processing_time": 54.455243825912476,
      "citing_paper_id": "280026233",
      "cited_paper_id": 261100919
    },
    {
      "context_text": "Description is found essential for data scientists to share or reuse code (Zhang et al., 2020; Chattopadhyay et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts about collaboration and computational notebooks in data science.",
      "processing_time": 52.599921464920044,
      "citing_paper_id": "280026233",
      "cited_paper_id": 210839751
    },
    {
      "context_text": "Description is found essential for data scientists to share or reuse code (Zhang et al., 2020; Chattopadhyay et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general concepts about collaboration and computational notebooks in data science.",
      "processing_time": 52.599921464920044,
      "citing_paper_id": "280026233",
      "cited_paper_id": 210927488
    },
    {
      "context_text": "Moreover, while the same code-table output pair could serve different purposes under different user requirements, existing work (Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided citation span does not mention any specific datasets, only references to other works. There is no clear indication of a reusable resource being used.",
      "processing_time": 53.95859670639038,
      "citing_paper_id": "280026233",
      "cited_paper_id": 216056509
    },
    {
      "context_text": "Moreover, while the same code-table output pair could serve different purposes under different user requirements, existing work (Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided citation span does not mention any specific datasets, only references to other works. There is no clear indication of a reusable resource being used.",
      "processing_time": 53.95859670639038,
      "citing_paper_id": "280026233",
      "cited_paper_id": 265045103
    },
    {
      "context_text": "…for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a; Ding and Xu, 2023; Cm et al., 2023), achieving satisfying performance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to various studies. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.08095979690552,
      "citing_paper_id": "280026233",
      "cited_paper_id": 216641852
    },
    {
      "context_text": "…for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a; Ding and Xu, 2023; Cm et al., 2023), achieving satisfying performance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to various studies. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.08095979690552,
      "citing_paper_id": "280026233",
      "cited_paper_id": 258532956
    },
    {
      "context_text": "…for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a; Ding and Xu, 2023; Cm et al., 2023), achieving satisfying performance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to various studies. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.08095979690552,
      "citing_paper_id": "280026233",
      "cited_paper_id": 263609483
    },
    {
      "context_text": "…for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a; Ding and Xu, 2023; Cm et al., 2023), achieving satisfying performance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to various studies. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.08095979690552,
      "citing_paper_id": "280026233",
      "cited_paper_id": 265045103
    },
    {
      "context_text": "…for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a; Ding and Xu, 2023; Cm et al., 2023), achieving satisfying performance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to various studies. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.08095979690552,
      "citing_paper_id": "280026233",
      "cited_paper_id": null
    },
    {
      "context_text": "…for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a; Ding and Xu, 2023; Cm et al., 2023), achieving satisfying performance.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to various studies. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.08095979690552,
      "citing_paper_id": "280026233",
      "cited_paper_id": null
    },
    {
      "context_text": "Some recent works explore encoder-decoder models such as PLBART (Ahmad et al., 2021), CodeT5 (Yue Wang, 2021), and TreeBERT (Jiang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions models (PLBART, CodeT5, TreeBERT) but does not refer to any specific datasets. The context is about using these models for program understanding and generation, which is related to personalized text generation but does not mention datasets.",
      "processing_time": 58.02561807632446,
      "citing_paper_id": "280026233",
      "cited_paper_id": 232185260
    },
    {
      "context_text": "Some recent works explore encoder-decoder models such as PLBART (Ahmad et al., 2021), CodeT5 (Yue Wang, 2021), and TreeBERT (Jiang et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions models (PLBART, CodeT5, TreeBERT) but does not refer to any specific datasets. The context is about using these models for program understanding and generation, which is related to personalized text generation but does not mention datasets.",
      "processing_time": 58.02561807632446,
      "citing_paper_id": "280026233",
      "cited_paper_id": 235195882
    },
    {
      "context_text": "On the other side, Kaggle allows community members to vote up and down on uploaded note-books, and findings show that the highly-voted notebooks are of good quality and quantity for code documentation (Wang et al., 2021a; Liu et al., 2021).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a platform (Kaggle) and the quality of notebooks. No verifiable resources are identified.",
      "processing_time": 54.20789813995361,
      "citing_paper_id": "280026233",
      "cited_paper_id": 233004676
    },
    {
      "context_text": "On the other side, Kaggle allows community members to vote up and down on uploaded note-books, and findings show that the highly-voted notebooks are of good quality and quantity for code documentation (Wang et al., 2021a; Liu et al., 2021).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a platform (Kaggle) and the quality of notebooks. No verifiable resources are identified.",
      "processing_time": 54.20789813995361,
      "citing_paper_id": "280026233",
      "cited_paper_id": 233987023
    },
    {
      "context_text": "…2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017; Pasupat and Liang, 2015; Ye et al., 2023; Zhang et al., 2024; Guo et al., 2024) only…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. There is no indication of dataset usage or specific data sources.",
      "processing_time": 53.66753387451172,
      "citing_paper_id": "280026233",
      "cited_paper_id": 233004676
    },
    {
      "context_text": "…Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Ud-din, 2022; Wang et al., 2022b; Dvivedi et al., 2024; Luo et al., 2024) (2020b) proposed an open domain table-to-text…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers and code documentation. There are no clear identifiers for datasets.",
      "processing_time": 53.419012784957886,
      "citing_paper_id": "280026233",
      "cited_paper_id": 233004676
    },
    {
      "context_text": "…descriptions for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a; Ding and Xu, 2023; Cm et al., 2023), achieving…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. There are no clear identifiers for datasets, and the context focuses on methods and findings rather than reusable resources.",
      "processing_time": 55.419995069503784,
      "citing_paper_id": "280026233",
      "cited_paper_id": 233004676
    },
    {
      "context_text": "In recent years, computational notebooks like Jupyter have become popular among data scientists and machine learning researchers for documenting ideas, writing code, and visualizing results in a single document (Wang et al., 2021a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only computational notebooks like Jupyter. No verifiable resources are identified.",
      "processing_time": 52.830209732055664,
      "citing_paper_id": "280026233",
      "cited_paper_id": 233987023
    },
    {
      "context_text": "…under different user requirements, existing work (Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017; Pasupat and Liang,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works. There is no clear indication of a reusable resource being discussed.",
      "processing_time": 53.643935203552246,
      "citing_paper_id": "280026233",
      "cited_paper_id": 235782694
    },
    {
      "context_text": "…techniques to generate descriptions for code snippets or table outputs independently (Richardson et al., 2017; Li et al., 2021; Liu et al., 2018; Wang et al., 2021b; Liu et al., 2021; Wang et al., 2024; Parikh et al., 2020a; An et al., 2022; Zhao et al., 2023b,a; Ding and Xu, 2023; Cm et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various papers. No clear identifiers for datasets are present.",
      "processing_time": 52.967129945755005,
      "citing_paper_id": "280026233",
      "cited_paper_id": 237100969
    },
    {
      "context_text": "Besides, unlike other integrated development environments (IDEs) such as Visual Studio, data scientists working in computational notebooks often write concise descriptions, typically less than 100 words(Wang et al., 2022a).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about computational notebooks. No verifiable resources are identified.",
      "processing_time": 52.79112195968628,
      "citing_paper_id": "280026233",
      "cited_paper_id": 237940127
    },
    {
      "context_text": "…al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017; Pasupat and Liang, 2015; Ye et al., 2023; Zhang et al., 2024; Guo et al., 2024) only focuses Figure 1:…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various studies. There is no clear indication of a reusable resource being used.",
      "processing_time": 53.64987874031067,
      "citing_paper_id": "280026233",
      "cited_paper_id": 252089836
    },
    {
      "context_text": "However, the raw data cannot be directly used due to the large amount of noise (Mondal et al., 2023; Lin et al., 2022).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific, verifiable datasets. It only refers to 'raw data' without providing a specific name or identifier.",
      "processing_time": 53.64173769950867,
      "citing_paper_id": "280026233",
      "cited_paper_id": 253553511
    },
    {
      "context_text": "However, the raw data cannot be directly used due to the large amount of noise (Mondal et al., 2023; Lin et al., 2022).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific, verifiable datasets. It only refers to 'raw data' without providing a specific name or identifier.",
      "processing_time": 53.64173769950867,
      "citing_paper_id": "280026233",
      "cited_paper_id": 265055617
    },
    {
      "context_text": "…et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017; Pasupat and Liang, 2015; Ye et al., 2023; Zhang et al., 2024; Guo et al., 2024) only focuses Figure 1: An example in our proposed NBDESCRIB dataset, which targets generating…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "NBDESCRIB"
      ],
      "dataset_descriptions": {
        "NBDESCRIB": "Used to generate personalized descriptions, focusing on decomposing evidence and questions for table-based reasoning, enhancing the accuracy and relevance of generated text."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'NBDESCRIB dataset' as a specific dataset used for generating descriptions, which aligns with the topic of personalized text generation.",
      "processing_time": 61.61344051361084,
      "citing_paper_id": "280026233",
      "cited_paper_id": 256416408
    },
    {
      "context_text": "…of our work are: (Li et al., 2021; Liu et al., 2018; Parikh et al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works and code documentation. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.49359750747681,
      "citing_paper_id": "280026233",
      "cited_paper_id": 256615816
    },
    {
      "context_text": "…same code-table output pair could serve different purposes under different user requirements, existing work (Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works. There is no indication of a reusable dataset or resource.",
      "processing_time": 53.47045350074768,
      "citing_paper_id": "280026233",
      "cited_paper_id": 256615816
    },
    {
      "context_text": "Llama3 (Touvron et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions Llama3, which is a model, not a dataset. No datasets are mentioned in the citation context.",
      "processing_time": 52.94824171066284,
      "citing_paper_id": "280026233",
      "cited_paper_id": 257219404
    },
    {
      "context_text": "However, research has shown that many data scientists still neglect to write appropriate descriptions for their code in notebooks, especially for code output ( i.e . table), as they feel writing description will slow down their coding process (Ramasamy et al., 2023).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general observation about data scientists' behavior.",
      "processing_time": 52.2865686416626,
      "citing_paper_id": "280026233",
      "cited_paper_id": 257669023
    },
    {
      "context_text": "…work are: (Li et al., 2021; Liu et al., 2018; Parikh et al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et al., 2017; An et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works and code documentation. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.920286893844604,
      "citing_paper_id": "280026233",
      "cited_paper_id": 258532956
    },
    {
      "context_text": "…pair could serve different purposes under different user requirements, existing work (Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works. There are no clear identifiers for datasets, and the context does not provide enough information to infer the use of any specific datasets.",
      "processing_time": 56.417545795440674,
      "citing_paper_id": "280026233",
      "cited_paper_id": 258532956
    },
    {
      "context_text": "For the Readability dimension which considers whether the generated description is a valid English sentence, Ground Truth outperforms all models once again: CodeT5-Large (V = 4363, p = 1.40e-7), GPT-3 (V = 4030, p = 3.81e-14), GPT-4o (V = 4451, p = 3.01e-10), Llama3 (V = 4556, p = 2.38e-13), and CodeLlama (V = 4573, p = 1.62-15).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model comparisons. The context focuses on evaluating model performance on readability.",
      "processing_time": 53.11229991912842,
      "citing_paper_id": "280026233",
      "cited_paper_id": 261100919
    },
    {
      "context_text": "We manually check 50 examples of CodeT5, GPT-4o, GPT-3, Llama3, and CodeLlama3 models used in our user study and label the type of errors made.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to models and a user study, which do not qualify as datasets.",
      "processing_time": 54.28876709938049,
      "citing_paper_id": "280026233",
      "cited_paper_id": 261100919
    },
    {
      "context_text": "As shown in the example in Table 4, even though CodeT5-Large, GPT-4o, GPT-3, Llama3, and CodeLlama3 are capable of generating key-words such as ”highest” based on the ”Extreme” guideline, it remains difficult to produce accurate text content based on the variables in the table.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and their capabilities. There are no verifiable resources or datasets mentioned.",
      "processing_time": 53.434629678726196,
      "citing_paper_id": "280026233",
      "cited_paper_id": 261100919
    },
    {
      "context_text": "CodeLlama3 Coherence The overall quality of all sentences working together.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general statement about sentence coherence. No verifiable resources are identified.",
      "processing_time": 53.20622396469116,
      "citing_paper_id": "280026233",
      "cited_paper_id": 261100919
    },
    {
      "context_text": "For example, GPT-3, Llama3, and CodeLlama3 produce text related to “Difference”, “Extreme”, or “Distribution”, but not “Trend” in the example from Table 7.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (GPT-3, Llama3, CodeLlama3). The context focuses on the output of these models rather than the use of a dataset.",
      "processing_time": 56.50409412384033,
      "citing_paper_id": "280026233",
      "cited_paper_id": 261100919
    },
    {
      "context_text": "The re-sults indicate significant differences in the Correct-ness dimension, where Ground Truth outperforms CodeT5-Large (V = 5628, p = 1.74e-30), GPT-3 (V = 5635, p = 5.46e-31), GPT-4o (V = 5647, p = 4.79e-30), Llama3 (V = 5732, p = 3.32e-30), and CodeLlama (V = 5948, p = 1.27e-30).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model comparisons. There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 53.57938528060913,
      "citing_paper_id": "280026233",
      "cited_paper_id": 261100919
    },
    {
      "context_text": "We utilized three types of models: a fine-tuned encoder-decoder-based CodeT5, the popular decoder-only LLMs (an off-the-shelf GPT-4o, Llama3, CodeLlama3), and a fine-tuned GPT-3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and architectures. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 53.71189594268799,
      "citing_paper_id": "280026233",
      "cited_paper_id": 261100919
    },
    {
      "context_text": "Similarly, in the Orientation dimension, Ground Truth surpasses CodeT5-Large (V = 3567, p = 1.59e-20), GPT-3 (V = 3731, p = 1.77e-20), GPT-4o (V = 3559, p = 1.82e-20), Llama3 (V = 3722, p = 1.89e-20), and CodeLlama (V = 3883, p = 1.33e-20).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model comparisons. There are no verifiable resources or datasets mentioned.",
      "processing_time": 52.91857933998108,
      "citing_paper_id": "280026233",
      "cited_paper_id": 261100919
    },
    {
      "context_text": "…different purposes under different user requirements, existing work (Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to various works. There is no clear indication of a reusable resource being discussed.",
      "processing_time": 53.74833822250366,
      "citing_paper_id": "280026233",
      "cited_paper_id": 263609483
    },
    {
      "context_text": "…2021; Liu et al., 2018; Parikh et al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et al., 2017; An et al., 2022; Liu et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There is no indication of a reusable resource being cited.",
      "processing_time": 53.59169864654541,
      "citing_paper_id": "280026233",
      "cited_paper_id": 263609483
    },
    {
      "context_text": "…al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Ud-din, 2022; Wang et…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There is no clear indication of a reusable resource being used.",
      "processing_time": 54.022298097610474,
      "citing_paper_id": "280026233",
      "cited_paper_id": 266162524
    },
    {
      "context_text": "…An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017; Pasupat and Liang, 2015; Ye et al., 2023; Zhang et al., 2024; Guo et al., 2024) only focuses Figure 1: An example in our proposed NBDESCRIB dataset, which targets generating high-fidelity and personalized…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "NBDESCRIB dataset"
      ],
      "dataset_descriptions": {
        "NBDESCRIB dataset": "Used to generate high-fidelity and personalized text, focusing on controlled table-to-text generation with scientific reasoning."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions 'NBDESCRIB dataset' as a specific dataset used for generating high-fidelity and personalized text. The context indicates that this dataset is used in the research for personalized text generation.",
      "processing_time": 62.46034860610962,
      "citing_paper_id": "280026233",
      "cited_paper_id": 266162524
    },
    {
      "context_text": "…2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Ud-din, 2022; Wang et al., 2022b; Dvivedi et al., 2024; Luo et al., 2024) (2020b) proposed an open domain table-to-text dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'an open domain table-to-text dataset' but does not provide a specific name or identifier. The cited papers are about code documentation generation, which suggests the dataset might be related to this domain, but there is no explicit name given.",
      "processing_time": 58.17454767227173,
      "citing_paper_id": "280026233",
      "cited_paper_id": 266348364
    },
    {
      "context_text": "…2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Ud-din, 2022; Wang et al., 2022b; Dvivedi et al., 2024; Luo et al., 2024) (2020b) proposed an open domain table-to-text dataset.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'an open domain table-to-text dataset' but does not provide a specific name or identifier. The cited papers are about code documentation generation, which suggests the dataset might be related to this domain, but there is no explicit name given.",
      "processing_time": 58.17454767227173,
      "citing_paper_id": "280026233",
      "cited_paper_id": 268032490
    },
    {
      "context_text": "…et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Ud-din, 2022; Wang et al., 2022b;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There is no clear indication of a reusable resource being used.",
      "processing_time": 54.19453310966492,
      "citing_paper_id": "280026233",
      "cited_paper_id": 267759856
    },
    {
      "context_text": "…2018; Parikh et al., 2020a; Dhingra et al., 2019; Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers and code documentation. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.473469257354736,
      "citing_paper_id": "280026233",
      "cited_paper_id": 268032490
    },
    {
      "context_text": "…Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017; Pasupat and Liang, 2015; Ye et al., 2023; Zhang et al., 2024; Guo et al., 2024) only focuses Figure 1: An example in our proposed NBDESCRIB dataset, which targets generating high-fidelity and…",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "NBDESCRIB"
      ],
      "dataset_descriptions": {
        "NBDESCRIB": "Used to generate high-fidelity descriptions, focusing on personalized text generation. The dataset is designed to support the creation of detailed and accurate textual content."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'NBDESCRIB dataset' as a specific dataset used for generating high-fidelity descriptions. The dataset is clearly named and appears to be relevant to the topic of personalized text generation.",
      "processing_time": 63.453869104385376,
      "citing_paper_id": "280026233",
      "cited_paper_id": 268032490
    },
    {
      "context_text": "This brevity poses challenges for large language models (LLMs), such as GPT and LLaMA, limiting their ability to generate accurate markdown descriptions(Park and Choi, 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only large language models and their limitations. There are no verifiable resources or datasets mentioned.",
      "processing_time": 54.014484167099,
      "citing_paper_id": "280026233",
      "cited_paper_id": null
    },
    {
      "context_text": "…2023a; Ding and Xu, 2023; Cm et al., 2023; Zhang et al., 2024; Guo et al., 2024; Min et al., 2024) or code documentation (Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Ud-din, 2022; Wang et al., 2022b; Dvivedi et al., 2024; Luo et al., 2024) (2020b) proposed an open domain…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works or code documentation. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 54.66721963882446,
      "citing_paper_id": "280026233",
      "cited_paper_id": null
    },
    {
      "context_text": "…work (Zhao et al., 2023b; Chen et al., 2020; Zhao et al., 2023a; Ding and Xu, 2023; Cm et al., 2023; Muller et al., 2021; Richardson et al., 2017; An et al., 2022; Liu et al., 2021; Khan and Uddin, 2022; Koehn and Knowles, 2017; Pasupat and Liang, 2015; Ye et al., 2023; Zhang et al., 2024; Guo…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other research works. There are no clear identifiers for datasets, models, or methods.",
      "processing_time": 54.45972466468811,
      "citing_paper_id": "280026233",
      "cited_paper_id": null
    },
    {
      "context_text": "They can produce expressive and diverse speech via zero-shot in-context learning [13].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a capability of producing expressive and diverse speech via zero-shot in-context learning.",
      "processing_time": 53.41900944709778,
      "citing_paper_id": "272424176",
      "cited_paper_id": 13490401
    },
    {
      "context_text": "Transcribing : We employ a two-pass Transducer-based end-to-end ASR model [20] to transcribe speech segments.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a method (ASR model) but does not reference any specific dataset. The cited paper title confirms it is about a method, not a dataset.",
      "processing_time": 54.79242539405823,
      "citing_paper_id": "272424176",
      "cited_paper_id": 201667597
    },
    {
      "context_text": "We train a frame-wise TDNN-based voice activity detection (VAD) model [18] to accurately detect speech segments from the Mel spectrogram with a frameshift of 25ms.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions training a VAD model but does not reference any specific dataset. The cited paper title confirms the method but does not introduce a dataset.",
      "processing_time": 54.08810257911682,
      "citing_paper_id": "272424176",
      "cited_paper_id": 212650062
    },
    {
      "context_text": "[28].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The citation span is too short to extract any meaningful information about datasets or their usage.",
      "processing_time": 50.975728034973145,
      "citing_paper_id": "272424176",
      "cited_paper_id": 218971783
    },
    {
      "context_text": "Compared to the conventional TTS approach[14, 15], we achieve studio-level speech synthesis with much less training data, e.g. zero-shot voice cloning for non-studio user-generated content (UGC) scenario and few-shot speaker adaptation with 1 hour for professional user-generated content (PUGC)…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses training data requirements but does not name any particular dataset.",
      "processing_time": 53.44894814491272,
      "citing_paper_id": "272424176",
      "cited_paper_id": 219531522
    },
    {
      "context_text": "This module is composed of two models: a music source separation model to remove the background music [16] and a speech enhancement model [17] for speech denoising.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions two models but does not refer to any specific datasets. The cited papers are about models, not datasets.",
      "processing_time": 53.22097444534302,
      "citing_paper_id": "272424176",
      "cited_paper_id": 238634774
    },
    {
      "context_text": "This module is composed of two models: a music source separation model to remove the background music [16] and a speech enhancement model [17] for speech denoising.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions two models but does not refer to any specific datasets. The cited papers are about models, not datasets.",
      "processing_time": 53.22097444534302,
      "citing_paper_id": "272424176",
      "cited_paper_id": 253553270
    },
    {
      "context_text": "Text-to-speech synthesis (TTS) has been playing a critical role in intelligent interaction [1, 2], e.g., virtual assistants, chatbots, and AI content creation, e.g. video dubbing [3, 4].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general applications of TTS technology. No verifiable resources are identified.",
      "processing_time": 53.4416069984436,
      "citing_paper_id": "272424176",
      "cited_paper_id": 244130481
    },
    {
      "context_text": "Text-to-speech synthesis (TTS) has been playing a critical role in intelligent interaction [1, 2], e.g., virtual assistants, chatbots, and AI content creation, e.g. video dubbing [3, 4].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only general applications of TTS technology. No verifiable resources are identified.",
      "processing_time": 53.4416069984436,
      "citing_paper_id": "272424176",
      "cited_paper_id": 266818441
    },
    {
      "context_text": "The training objective is defined as: Moreover, to better generate the Mel spectrogram, we apply the Classifier-Free Guidance (CFG [32]) technique.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Classifier-Free Guidance).",
      "processing_time": 52.171738386154175,
      "citing_paper_id": "272424176",
      "cited_paper_id": 249145348
    },
    {
      "context_text": "This refined dataset serves for training a BigVGAN-V2-based neural vocoder [35].",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a 'refined dataset' but does not provide a specific name or identifier. The cited paper title confirms BigVGAN is a model, not a dataset.",
      "processing_time": 55.47094202041626,
      "citing_paper_id": "272424176",
      "cited_paper_id": 249538510
    },
    {
      "context_text": "We randomly select 40 unseen clean audio prompt (20 in Mandarin and 20 in English), and then manually add background noise at various SNR levels, 20 dB, 10 dB, and 0 dB to them, following the method in [36].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It describes a method for adding background noise to clean audio prompts, which is not a dataset but a process.",
      "processing_time": 54.69287610054016,
      "citing_paper_id": "272424176",
      "cited_paper_id": 251307839
    },
    {
      "context_text": "Speaker Clustering : Due to the lack of speaker information, we perform spectral clustering on speaker embeddings [19] of all speech segments.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to a method (spectral clustering) applied to speaker embeddings, which is part of a toolkit (Wespeaker).",
      "processing_time": 55.6473548412323,
      "citing_paper_id": "272424176",
      "cited_paper_id": 253237382
    },
    {
      "context_text": "The large language models trained with massive speech data have shown impressive performance in speech generation, such as VALL-E [8], TorToiSe [9], BASE-TTS [10], Seed-TTS [11], CosyVoice [12], etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only lists models and methods used for speech generation.",
      "processing_time": 53.18764853477478,
      "citing_paper_id": "272424176",
      "cited_paper_id": 257378493
    },
    {
      "context_text": "The large language models trained with massive speech data have shown impressive performance in speech generation, such as VALL-E [8], TorToiSe [9], BASE-TTS [10], Seed-TTS [11], CosyVoice [12], etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific, verifiable datasets. It only lists models and methods used for speech generation.",
      "processing_time": 53.18764853477478,
      "citing_paper_id": "272424176",
      "cited_paper_id": 258676394
    },
    {
      "context_text": "This sequence can be reconstructed back via the Mel codec decoder, and predicted from semantic tokens via a multi-stream LM [34] with a “delay pattern”.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (multi-stream LM) and a concept (delay pattern). There are no verifiable resources that meet the criteria.",
      "processing_time": 54.859864234924316,
      "citing_paper_id": "272424176",
      "cited_paper_id": 259108357
    },
    {
      "context_text": "Subsequently, we employ a super-resolution neural vocoder [29] to generate high-sampling-rate (48 kHz) audio from the Mel spectrogram.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (super-resolution neural vocoder) used for generating high-sampling-rate audio.",
      "processing_time": 53.593745946884155,
      "citing_paper_id": "272424176",
      "cited_paper_id": 261822707
    },
    {
      "context_text": "The filtering is conducted from three aspects: • Speech quality: we estimate the overall speech quality using DNSMOS [21], and keep only speech segments with the DNSMOS P.835 OVRL score [22] higher than 3.3.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions DNSMOS and P.835 OVRL score, which are metrics or methods, not datasets. No specific datasets are mentioned.",
      "processing_time": 54.10885167121887,
      "citing_paper_id": "272424176",
      "cited_paper_id": 262480519
    },
    {
      "context_text": "Finally, we follow [24] to quantize this sequence into the discrete sequence with a frameshift of 40ms and a codebook of 16,384 codewords.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method for quantizing sequences. No dataset names are present in the citation context.",
      "processing_time": 53.423532485961914,
      "citing_paper_id": "272424176",
      "cited_paper_id": 270257988
    },
    {
      "context_text": "As shown in Figure 3(d), we first follow [33] to train a streamable CNN-based GAN-based Mel codec to learn a multi-stream discrete representation, i.e. each frame consisting of multiple tokens to preserve sufficient acoustic details.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for training a codec. The context focuses on the technical approach rather than the data used.",
      "processing_time": 54.099199295043945,
      "citing_paper_id": "272424176",
      "cited_paper_id": 272366525
    },
    {
      "context_text": "Fr´echet Inception Distance (FID) [157] quantifies the statistical similarity between generated and real image distributions through Inception-V3 [158].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset. It refers to a metric (FID) and a model (Inception-V3), which are excluded according to the instructions.",
      "processing_time": 54.82489252090454,
      "citing_paper_id": "269635322",
      "cited_paper_id": 326772
    },
    {
      "context_text": "For the reverse process, a crucial result [11] shows that the reverse diffusion process also follows an SDE: where ¯ w denotes reverse-time Wiener increments, and ∇ x log p t ( x ) is a score function.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a mathematical result about reverse diffusion processes.",
      "processing_time": 52.17717385292053,
      "citing_paper_id": "269635322",
      "cited_paper_id": 3897405
    },
    {
      "context_text": "Inspired by coached active learning [85, 86], which uses anchor concepts for optimization guidance, Compositional Inversion [87] employs a set of semantically related tokens as anchors to constrain the token embedding search.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers are about coached active learning, which is a method, not a dataset.",
      "processing_time": 54.614216566085815,
      "citing_paper_id": "269635322",
      "cited_paper_id": 6767966
    },
    {
      "context_text": "Inspired by coached active learning [85, 86], which uses anchor concepts for optimization guidance, Compositional Inversion [87] employs a set of semantically related tokens as anchors to constrain the token embedding search.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and approaches. The cited papers are about coached active learning, which is a method, not a dataset.",
      "processing_time": 54.614216566085815,
      "citing_paper_id": "269635322",
      "cited_paper_id": 8278351
    },
    {
      "context_text": "Each model makes its own noise prediction, and the final noise output is a composite created through mask-guided concatenation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for combining model outputs.",
      "processing_time": 51.66043734550476,
      "citing_paper_id": "269635322",
      "cited_paper_id": 9791192
    },
    {
      "context_text": "For subject fidelity in face generation, we detect faces in both the generated and target images using MTCNN [160] and calculate the pairwise identity similarity using FaceNet [161].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions MTCNN and FaceNet, which are methods/models, not datasets. No datasets are explicitly mentioned or used in the described methodology.",
      "processing_time": 53.85466170310974,
      "citing_paper_id": "269635322",
      "cited_paper_id": 10585115
    },
    {
      "context_text": "For subject fidelity in face generation, we detect faces in both the generated and target images using MTCNN [160] and calculate the pairwise identity similarity using FaceNet [161].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions MTCNN and FaceNet, which are methods/models, not datasets. No datasets are explicitly mentioned or used in the described methodology.",
      "processing_time": 53.85466170310974,
      "citing_paper_id": "269635322",
      "cited_paper_id": 206592766
    },
    {
      "context_text": "An obvious benefit is that one can readily leverage large-scale human-centric datasets [67, 102, 103] and utilize pre-trained models in well-developed areas, like face landmark detection [104] and face recognition [105].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'large-scale human-centric datasets' but does not specify any particular dataset names. The cited papers do not provide additional specific dataset names either.",
      "processing_time": 54.57495355606079,
      "citing_paper_id": "269635322",
      "cited_paper_id": 13689658
    },
    {
      "context_text": "An obvious benefit is that one can readily leverage large-scale human-centric datasets [67, 102, 103] and utilize pre-trained models in well-developed areas, like face landmark detection [104] and face recognition [105].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'large-scale human-centric datasets' but does not specify any particular dataset names. The cited papers do not provide additional specific dataset names either.",
      "processing_time": 54.57495355606079,
      "citing_paper_id": "269635322",
      "cited_paper_id": 214728393
    },
    {
      "context_text": "An obvious benefit is that one can readily leverage large-scale human-centric datasets [67, 102, 103] and utilize pre-trained models in well-developed areas, like face landmark detection [104] and face recognition [105].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'large-scale human-centric datasets' but does not specify any particular dataset names. The cited papers do not provide additional specific dataset names either.",
      "processing_time": 54.57495355606079,
      "citing_paper_id": "269635322",
      "cited_paper_id": 244908314
    },
    {
      "context_text": "The W + Adapter [53] constructs a mapping network and residual cross-attention modules to transform the facial features from the StyleGAN [108] W + space into the text embedding space of Stable Diffusion.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 53.847381591796875,
      "citing_paper_id": "269635322",
      "cited_paper_id": 54482423
    },
    {
      "context_text": "Originating from discrete-time Markov chains in Denoising Diffusion Probabilistic Model (DDPM) [10], the forward process applies Gaussian noise corruption over T steps: where x t denotes the noised data at diffusion step t , ϵ ∼ N (0 , I ) is the standard Gaussian noise vector that corrupts the…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Denoising Diffusion Probabilistic Model). There are no verifiable resources or datasets mentioned.",
      "processing_time": 54.72520136833191,
      "citing_paper_id": "269635322",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "A common approach is to employ an encoder, leveraging pre-trained models such as CLIP [42] and BLIP [43].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions pre-trained models CLIP and BLIP but does not refer to any specific datasets. The context is about using these models as encoders, which is a methodological approach.",
      "processing_time": 55.98329281806946,
      "citing_paper_id": "269635322",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "The text alignment metrics quantify how precisely generated outputs reflect prompt semantics: CLIP-T measures semantic alignment using the cosine similarity between CLIP [42] embed-dings of generated images and their text prompts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (CLIP) for measuring semantic alignment. The citation is used to reference the method, not a dataset.",
      "processing_time": 55.141979455947876,
      "citing_paper_id": "269635322",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "Mix-of-Show [25] fuses the LoRA [110] weights with the same optimization objective.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is about combining LoRA weights, which is a method, not a dataset.",
      "processing_time": 54.651244163513184,
      "citing_paper_id": "269635322",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "Mix-of-Show [25] fuses the LoRA [110] weights with the same optimization objective.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The citation is about combining LoRA weights, which is a method, not a dataset.",
      "processing_time": 54.651244163513184,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258960192
    },
    {
      "context_text": "Such datasets are more accessible, including collections like LAION [66] and LAION-FACE [67].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LAION",
        "LAION-FACE"
      ],
      "dataset_descriptions": {
        "LAION": "Used for general facial representation learning, focusing on visual-linguistic data to enhance model performance in understanding and generating text related to images.",
        "LAION-FACE": "Used for facial representation learning, specifically focusing on face-related data to improve model accuracy in generating text about faces."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions 'LAION' and 'LAION-FACE' as specific collections, which are likely datasets given the cited paper's focus on visual-linguistic representation learning.",
      "processing_time": 65.49777364730835,
      "citing_paper_id": "269635322",
      "cited_paper_id": 244908314
    },
    {
      "context_text": "This conditional paradigm directly enables the applications of PCS. Leading text-to-image systems, such as Stable Diffusion (SD) [15] and DALLE [17], are widely adopted to empower users in controlling customized content through text instructions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on the application of text-to-image systems, which are not considered datasets.",
      "processing_time": 54.90658164024353,
      "citing_paper_id": "269635322",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "This conditional paradigm directly enables the applications of PCS. Leading text-to-image systems, such as Stable Diffusion (SD) [15] and DALLE [17], are widely adopted to empower users in controlling customized content through text instructions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on the application of text-to-image systems, which are not considered datasets.",
      "processing_time": 54.90658164024353,
      "citing_paper_id": "269635322",
      "cited_paper_id": 261705666
    },
    {
      "context_text": "This conditional paradigm directly enables the applications of PCS. Leading text-to-image systems, such as Stable Diffusion (SD) [15] and DALLE [17], are widely adopted to empower users in controlling customized content through text instructions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on the application of text-to-image systems, which are not considered datasets.",
      "processing_time": 54.90658164024353,
      "citing_paper_id": "269635322",
      "cited_paper_id": 275994148
    },
    {
      "context_text": "Building upon the unconditional framework, conditional synthesis is formalized through extended score matching: where the conditioning signal c can be integrated via multiple synergistic mechanisms, such as cross-modal attention [15] and spatial modulation [16].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on conditional synthesis and score matching mechanisms.",
      "processing_time": 53.60108304023743,
      "citing_paper_id": "269635322",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "This formulation enables generation by integrating backward from x T ∼ N (0 , I ) to x 0 , conditioned on learned score estimates.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method for generation. No dataset names are present in the text.",
      "processing_time": 53.4354510307312,
      "citing_paper_id": "269635322",
      "cited_paper_id": 246411402
    },
    {
      "context_text": "This formulation enables generation by integrating backward from x T ∼ N (0 , I ) to x 0 , conditioned on learned score estimates.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method for generation. No dataset names are present in the text.",
      "processing_time": 53.4354510307312,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266999462
    },
    {
      "context_text": "This continuous perspective subsumes DDPMs as special cases while enabling adaptive noise scheduling strategies such as variance-preserving (VP) and variance-exploding (VE) schedules through strategic choices of f and g [9].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methods and models.",
      "processing_time": 51.76699876785278,
      "citing_paper_id": "269635322",
      "cited_paper_id": 249240415
    },
    {
      "context_text": "Modern diffusion modeling has evolved into a sophisticated framework that unifies discrete and continuous generative paradigms through stochastic differential equations (SDEs) [8], ordinary differential equations (ODEs) [8, 9].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context is focused on the evolution of diffusion modeling techniques.",
      "processing_time": 53.69640851020813,
      "citing_paper_id": "269635322",
      "cited_paper_id": 249240415
    },
    {
      "context_text": "These limitations motivate the derivation of deterministic sampling trajectories through probability flow ordinary differential equations (ODEs) [8, 9], obtained by eliminating the stochastic term from the SDE formulation: The ODE’s deterministic nature arises from two synergistic components: the…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses methodological aspects of generative models.",
      "processing_time": 52.37443280220032,
      "citing_paper_id": "269635322",
      "cited_paper_id": 249240415
    },
    {
      "context_text": "Re-Imagen [97] introduces a retrieval-augmented generative approach, which leverages features from text-image pairs retrieved via a specific prompt.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'text-image pairs' but does not specify a dataset name. The cited paper title confirms the method but does not introduce a specific dataset.",
      "processing_time": 54.82687425613403,
      "citing_paper_id": "269635322",
      "cited_paper_id": 252596087
    },
    {
      "context_text": "This tuned model then utilize Score Distillation Sampling (SDS) [136] to train a 3D Neural Radiance Field (NeRF) model [137] for each specific prompt [138, 139].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets in the provided text.",
      "processing_time": 54.06816101074219,
      "citing_paper_id": "269635322",
      "cited_paper_id": 252596091
    },
    {
      "context_text": "This tuned model then utilize Score Distillation Sampling (SDS) [136] to train a 3D Neural Radiance Field (NeRF) model [137] for each specific prompt [138, 139].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets in the provided text.",
      "processing_time": 54.06816101074219,
      "citing_paper_id": "269635322",
      "cited_paper_id": null
    },
    {
      "context_text": "This enabling 5-10x faster sampling than SDEs through adaptive ODE solvers like DPM-Solver [12] and DPM-Solver++ [13].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and solvers. The context is about improving sampling speed in diffusion models.",
      "processing_time": 53.68090581893921,
      "citing_paper_id": "269635322",
      "cited_paper_id": 253254916
    },
    {
      "context_text": "…of learnable parameters θ ′ , the commonly adopted options include token embeddings [7, 18], the entire diffusion model [4, 19], specific subsets of parameters [20, 21, 22], or introducing new parameters such as adapters [23, 24], and LoRA [25, 26, 27], which will be discussed in Section 3.1.3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 52.99679613113403,
      "citing_paper_id": "269635322",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "…of learnable parameters θ ′ , the commonly adopted options include token embeddings [7, 18], the entire diffusion model [4, 19], specific subsets of parameters [20, 21, 22], or introducing new parameters such as adapters [23, 24], and LoRA [25, 26, 27], which will be discussed in Section 3.1.3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 52.99679613113403,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257901164
    },
    {
      "context_text": "…of learnable parameters θ ′ , the commonly adopted options include token embeddings [7, 18], the entire diffusion model [4, 19], specific subsets of parameters [20, 21, 22], or introducing new parameters such as adapters [23, 24], and LoRA [25, 26, 27], which will be discussed in Section 3.1.3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 52.99679613113403,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258960192
    },
    {
      "context_text": "…of learnable parameters θ ′ , the commonly adopted options include token embeddings [7, 18], the entire diffusion model [4, 19], specific subsets of parameters [20, 21, 22], or introducing new parameters such as adapters [23, 24], and LoRA [25, 26, 27], which will be discussed in Section 3.1.3.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 52.99679613113403,
      "citing_paper_id": "269635322",
      "cited_paper_id": 268064742
    },
    {
      "context_text": "This paradigm directly optimizes pre-trained model components, such as the text encoder, U-Net blocks, and transformer layers [4, 19, 20, 21, 22].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only model components. There are no verifiable resources that meet the criteria.",
      "processing_time": 53.37235713005066,
      "citing_paper_id": "269635322",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "[20] focuses on identifying and fine-tuning critical parameters, particularly the key-value projections in cross-attention layers, to achieve a balance of visual fidelity and storage efficiency.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses model parameters and their tuning.",
      "processing_time": 52.17628359794617,
      "citing_paper_id": "269635322",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Similar strategies are found in other works [20, 65] which train a single model by reconstructing the appearance of every SoI.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general strategy for training a model. No verifiable resources are identified.",
      "processing_time": 53.667133808135986,
      "citing_paper_id": "269635322",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Custom-101 [20] is the latest released dataset by the authors of Custom Diffusion [20], which comprises 101 subjects to provide a broader scope of evaluation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Custom-101"
      ],
      "dataset_descriptions": {
        "Custom-101": "Used to evaluate multi-concept customization in text-to-image diffusion models, providing a broader scope of 101 subjects for comprehensive assessment."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Custom-101' as a dataset comprising 101 subjects for evaluation, which is relevant to personalized text generation.",
      "processing_time": 62.03761029243469,
      "citing_paper_id": "269635322",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Nor-mally, the construction of the unique modifier can be divided into three categories: Plain text [4, 20, 21, 24, 19].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only refers to categories of plain text, which is too generic.",
      "processing_time": 54.18159079551697,
      "citing_paper_id": "269635322",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "For instance, Custom Diffusion [20] proposes a constrained optimization method to merge the cross-attention key-value projection weights with the goal of maximizing reconstruction performance for each subject.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for customizing text-to-image diffusion models.",
      "processing_time": 52.818439960479736,
      "citing_paper_id": "269635322",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "Custom-10 [20] used in Custom Diffusion [20] evaluates 10 subjects, each with 20 specific test prompts, and includes tests for multi-subject composition with 5 pairs of subjects and 8 prompts for each pair.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Custom-10"
      ],
      "dataset_descriptions": {
        "Custom-10": "Used to evaluate multi-subject composition in text-to-image diffusion, testing 10 subjects with 20 prompts each and 5 pairs of subjects with 8 prompts per pair."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions 'Custom-10' which appears to be a specific dataset used for evaluating a method. It is described with specific details about the number of subjects and prompts.",
      "processing_time": 63.35493087768555,
      "citing_paper_id": "269635322",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "For example, BLIP-Diffusion [57] utilizes the pre-trained BLIP2 [62] that encodes multimodal inputs including the SoI reference and a class noun.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets.",
      "processing_time": 53.131081104278564,
      "citing_paper_id": "269635322",
      "cited_paper_id": 256390509
    },
    {
      "context_text": "This approach leverages powerful multi-modal encoder architectures (e.g., BLIP-2 [62]) to jointly embed visual and textual subject descriptors.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions BLIP-2 but does not refer to it as a dataset. It is described as an architecture, which is excluded according to the rules.",
      "processing_time": 54.93730092048645,
      "citing_paper_id": "269635322",
      "cited_paper_id": 256390509
    },
    {
      "context_text": "More-over, the mask can stitch specific feature maps to construct more informative semantic patterns [47, 76, 63].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other papers. There are no clear identifiers for datasets, models, or methods.",
      "processing_time": 53.89195990562439,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "Later, ELITE [47] specifically targets image personalization by combining the global reference features with text embedding while incorporating local features that exclude irrelevant backgrounds.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (ELITE) for personalized text generation. The context focuses on the methodology and approach rather than a specific dataset.",
      "processing_time": 55.33808255195618,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "Current methodologies can be categorized into four primary approaches: Concatenation-based Fusion [47, 46, 5, 48, 49, 50].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methodologies. No dataset names are present in the text.",
      "processing_time": 53.186654806137085,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257219968
    },
    {
      "context_text": "Current methodologies can be categorized into four primary approaches: Concatenation-based Fusion [47, 46, 5, 48, 49, 50].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methodologies. No dataset names are present in the text.",
      "processing_time": 53.186654806137085,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258740710
    },
    {
      "context_text": "Current methodologies can be categorized into four primary approaches: Concatenation-based Fusion [47, 46, 5, 48, 49, 50].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methodologies. No dataset names are present in the text.",
      "processing_time": 53.186654806137085,
      "citing_paper_id": "269635322",
      "cited_paper_id": 259316083
    },
    {
      "context_text": "In addition, some works [88, 34] regularize learnable token offsets relative to pre-trained CLIP embeddings.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving CLIP embeddings.",
      "processing_time": 52.15764904022217,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257364757
    },
    {
      "context_text": "Multimodal Encoder Fusion [57, 58, 59, 60, 61].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only multimodal encoder fusion techniques. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.64991641044617,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257557302
    },
    {
      "context_text": "Multimodal Encoder Fusion [57, 58, 59, 60, 61].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only multimodal encoder fusion techniques. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.64991641044617,
      "citing_paper_id": "269635322",
      "cited_paper_id": 263620748
    },
    {
      "context_text": "Multimodal Encoder Fusion [57, 58, 59, 60, 61].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only multimodal encoder fusion techniques. The cited paper titles do not provide additional context to identify specific datasets.",
      "processing_time": 54.64991641044617,
      "citing_paper_id": "269635322",
      "cited_paper_id": 269005949
    },
    {
      "context_text": "Additionally, UMM-Diffusion [61] designs a multi-modal encoder that produces fused features based on the reference image and text prompt.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (UMM-Diffusion) and its components. The context focuses on the design of a multi-modal encoder, which is a method, not a dataset.",
      "processing_time": 56.98790526390076,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257557302
    },
    {
      "context_text": "2 Contrasstive Learning MS-Diffusion [56] Multiple Subjects PTA SD Attention-based Operation ReVersion [115] High-level Semantic TTF SD Regularization Inv-ReVersion [200] High-level Semantic TTF SD 1.5 Regularization CusConcept [201] High-level Semantic TTF SD 2.1 Regularization ADI [117]…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 53.7036828994751,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257687552
    },
    {
      "context_text": "ReVer-sion [115] intends to invert object relations from references.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or tool called ReVer-sion. The title confirms it is a method for relation inversion, not a dataset.",
      "processing_time": 55.34374690055847,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257687552
    },
    {
      "context_text": "Dream-Booth3D [140] structures the process into three phases: initializing and optimizing a NeRF from a DreamBooth model, rendering multi-view images, and fine-tuning a secondary DreamBooth for the final 3D NeRF refinement.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model (DreamBooth3D). The context describes the process and phases of the method, not the use of a dataset.",
      "processing_time": 56.043631076812744,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257687714
    },
    {
      "context_text": "…SD 1.5 Randomness Erasing HiPer [166] Object TTF SD Token Embedding Enhancement P+ [18] Object TTF SD 1.4 Token Embedding Enhancement Unet-finetune [23] Object TTF SD Parameter-efficient Fine-tuning Jia et al. [76] Object TTF Imagen Mask-assisted Generation; Regularization COTI [83] Object TTF SD…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 53.97369980812073,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257901164
    },
    {
      "context_text": "Recent advanced methods have introduced parameter-efficient techniques into PCS, such as LoRA [25, 26, 27, 34, 35, 36] and adapter modules [23, 24], which inject small, trainable components into the base model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses parameter-efficient techniques in personalized content synthesis (PCS) but does not mention any specific datasets. The cited papers' titles also do not indicate the use of specific datasets.",
      "processing_time": 55.49324440956116,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257901164
    },
    {
      "context_text": "Recent advanced methods have introduced parameter-efficient techniques into PCS, such as LoRA [25, 26, 27, 34, 35, 36] and adapter modules [23, 24], which inject small, trainable components into the base model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses parameter-efficient techniques in personalized content synthesis (PCS) but does not mention any specific datasets. The cited papers' titles also do not indicate the use of specific datasets.",
      "processing_time": 55.49324440956116,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258960192
    },
    {
      "context_text": "Recent advanced methods have introduced parameter-efficient techniques into PCS, such as LoRA [25, 26, 27, 34, 35, 36] and adapter modules [23, 24], which inject small, trainable components into the base model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context discusses parameter-efficient techniques in personalized content synthesis (PCS) but does not mention any specific datasets. The cited papers' titles also do not indicate the use of specific datasets.",
      "processing_time": 55.49324440956116,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266163420
    },
    {
      "context_text": "Additionally, methods like adapters [23, 24] and LoRA variants [25, 26, 27, 34, 35, 36] are increasingly utilized in personalized generation for parameter-efficient fine-tuning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for personalized generation. No verifiable resources are identified.",
      "processing_time": 53.5227484703064,
      "citing_paper_id": "269635322",
      "cited_paper_id": 257901164
    },
    {
      "context_text": "Additionally, methods like adapters [23, 24] and LoRA variants [25, 26, 27, 34, 35, 36] are increasingly utilized in personalized generation for parameter-efficient fine-tuning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for personalized generation. No verifiable resources are identified.",
      "processing_time": 53.5227484703064,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258960192
    },
    {
      "context_text": "Additionally, methods like adapters [23, 24] and LoRA variants [25, 26, 27, 34, 35, 36] are increasingly utilized in personalized generation for parameter-efficient fine-tuning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches for personalized generation. No verifiable resources are identified.",
      "processing_time": 53.5227484703064,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266163420
    },
    {
      "context_text": "In addition to these token-level refinement approaches, the field continues to evolve with novel techniques such as Instruct-Booth’s reinforcement learning framework [93] and gradient-free evolutionary optimization [94].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and techniques. The context focuses on describing novel approaches in the field.",
      "processing_time": 53.52463459968567,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258078921
    },
    {
      "context_text": "…Jia et al. [76] Object TTF Imagen Mask-assisted Generation; Regularization COTI [83] Object TTF SD 2.0 Data Augmentation Gradient-Free TI [94] Object TTF SD Evolutionary Strategy PerSAM [44] Object TTF SD Mask-assisted Generation DisenBooth [77] Object TTF SD 2.1 Regularization NeTI [30]…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific, verifiable dataset names. It mentions various methods and models, but no datasets are explicitly named or described.",
      "processing_time": 54.481423139572144,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258078921
    },
    {
      "context_text": "Notable examples, such as ChatGPT [1] and text-to-image diffusion Fig.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or systems. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 54.14524483680725,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258447166
    },
    {
      "context_text": "In addition, the layout indicated by the pixel mask can be incorporated into the attention modules as a super-vision signal [5, 22, 38, 63, 45, 72, 37] to adjust the attention’s concentration adaptively.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to attention mechanisms and supervision signals. No verifiable resources are identified.",
      "processing_time": 53.86485958099365,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258740710
    },
    {
      "context_text": "In addition, the layout indicated by the pixel mask can be incorporated into the attention modules as a super-vision signal [5, 22, 38, 63, 45, 72, 37] to adjust the attention’s concentration adaptively.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to attention mechanisms and supervision signals. No verifiable resources are identified.",
      "processing_time": 53.86485958099365,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "In addition, the layout indicated by the pixel mask can be incorporated into the attention modules as a super-vision signal [5, 22, 38, 63, 45, 72, 37] to adjust the attention’s concentration adaptively.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to attention mechanisms and supervision signals. No verifiable resources are identified.",
      "processing_time": 53.86485958099365,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265498829
    },
    {
      "context_text": "Fastcomposer [5], Subject-Diffusion [63], and λ -eclipse [112] place each subject feature in its corresponding place-holder in the text embedding, ensuring a seamless and efficient combination.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods. The context focuses on the methodologies used for multi-subject image generation.",
      "processing_time": 54.347387075424194,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258740710
    },
    {
      "context_text": "1 Given a few reference images of a subject (e.g., a cat [4] or face [5]), PCS aims to generate new renditions of the subject that align with user-defined textual prompts.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept of 'reference images' which is too generic.",
      "processing_time": 53.50423455238342,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258740710
    },
    {
      "context_text": "In addition to these explicit attention weights modification methods, many researchers [5, 22, 38, 63, 45, 72, 37] employ localization supervision in the cross-attention module.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.3403525352478,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258740710
    },
    {
      "context_text": "In addition to these explicit attention weights modification methods, many researchers [5, 22, 38, 63, 45, 72, 37] employ localization supervision in the cross-attention module.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.3403525352478,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "In addition to these explicit attention weights modification methods, many researchers [5, 22, 38, 63, 45, 72, 37] employ localization supervision in the cross-attention module.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and approaches. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 54.3403525352478,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265498829
    },
    {
      "context_text": "…Extra Conditions TTF SD Shape and Texture Control Viewpoint Control [122] Extra Conditions TTF SDXL 3D Feature Incorporation Prompt-Free Diffusion [204] Extra Conditions PTA SD 2.0 Reference Feature Injection Uni-ControlNet [205] Extra Conditions PTA SD Multi-feature Injection ViscoNet [206]…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 53.23451280593872,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258887939
    },
    {
      "context_text": "…Conditions TTF SDXL 3D Feature Incorporation Prompt-Free Diffusion [204] Extra Conditions PTA SD 2.0 Reference Feature Injection Uni-ControlNet [205] Extra Conditions PTA SD Multi-feature Injection ViscoNet [206] Extra Conditions PTA SD Multi-feature Injection Context Diffusion [207] Extra…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 54.00255560874939,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258888112
    },
    {
      "context_text": "Based on this strategy, plenty of studies [44, 32, 38, 45, 34, 35, 37, 74, 75] choose to discard the pixels of the background area so that the reconstruction loss can focus on the targeted object and exclude irrelevant disturbances.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general strategy for handling background areas in image processing. No verifiable resources are identified.",
      "processing_time": 54.47831678390503,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "Based on this strategy, plenty of studies [44, 32, 38, 45, 34, 35, 37, 74, 75] choose to discard the pixels of the background area so that the reconstruction loss can focus on the targeted object and exclude irrelevant disturbances.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general strategy for handling background areas in image processing. No verifiable resources are identified.",
      "processing_time": 54.47831678390503,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265050824
    },
    {
      "context_text": "Based on this strategy, plenty of studies [44, 32, 38, 45, 34, 35, 37, 74, 75] choose to discard the pixels of the background area so that the reconstruction loss can focus on the targeted object and exclude irrelevant disturbances.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general strategy for handling background areas in image processing. No verifiable resources are identified.",
      "processing_time": 54.47831678390503,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265498829
    },
    {
      "context_text": "Based on this strategy, plenty of studies [44, 32, 38, 45, 34, 35, 37, 74, 75] choose to discard the pixels of the background area so that the reconstruction loss can focus on the targeted object and exclude irrelevant disturbances.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a general strategy for handling background areas in image processing. No verifiable resources are identified.",
      "processing_time": 54.47831678390503,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266163420
    },
    {
      "context_text": "Also, these two parts can be simultaneously optimized with different learning rates [38, 39].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to other papers. No verifiable resources are identified.",
      "processing_time": 53.285181760787964,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "Also, these two parts can be simultaneously optimized with different learning rates [38, 39].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to other papers. No verifiable resources are identified.",
      "processing_time": 53.285181760787964,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266436022
    },
    {
      "context_text": "Multiple methods [37, 38, 39] have started using combined weight fine-tuning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 53.957775354385376,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "Multiple methods [37, 38, 39] have started using combined weight fine-tuning.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 53.957775354385376,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266436022
    },
    {
      "context_text": "For instance, the SoI-specific mask [44, 32, 38, 45, 34, 35] contributes to the effective exclusion of the influence of the background.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a method or technique (SoI-specific mask) used in image processing. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.09126305580139,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "For instance, the SoI-specific mask [44, 32, 38, 45, 34, 35] contributes to the effective exclusion of the influence of the background.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a method or technique (SoI-specific mask) used in image processing. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.09126305580139,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265498829
    },
    {
      "context_text": "For instance, the SoI-specific mask [44, 32, 38, 45, 34, 35] contributes to the effective exclusion of the influence of the background.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only a method or technique (SoI-specific mask) used in image processing. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 56.09126305580139,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266163420
    },
    {
      "context_text": "COMCAT [96] introduces a low-rank approximation of attention matrices, which drastically reduces storage requirements to 6 MB while maintaining high fidelity in the outputs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions COMCAT but does not refer to it as a dataset. It describes a method for compressing attention matrices in vision models.",
      "processing_time": 54.31225562095642,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258959444
    },
    {
      "context_text": "For example, Mix-of-Show [25] designs region-aware cross-attention where the feature map is initially generated by the global prompt and replaced with distinct regional features corresponding to each entity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context focuses on the design of a method called Mix-of-Show, which involves region-aware cross-attention.",
      "processing_time": 55.91174650192261,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258960192
    },
    {
      "context_text": "This approach often addresses the limitations where token embeddings alone struggle to capture complex semantics uncovered in the pre-training data [25, 95].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to 'pre-training data'. No clear, verifiable resource names are provided.",
      "processing_time": 54.2840576171875,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258960192
    },
    {
      "context_text": "VICO [71] inserts a new attention layer where a binary mask is deployed to selectively obscure the attention map between the noisy latent and the reference image features.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (ViCo) and its components. The citation is focused on describing a part of the method rather than using a dataset.",
      "processing_time": 55.905752182006836,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258999614
    },
    {
      "context_text": "On the other hand, VICO [71] empirically finds that the end-of-text token <|EOT|> keeps the semantic consistency of SoI.",
      "catation_intent": "findings",
      "resource_type": "finding",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method or finding about the end-of-text token <|EOT|> in the context of semantic consistency.",
      "processing_time": 54.94092392921448,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258999614
    },
    {
      "context_text": "In addition, there is evidence [87, 76, 71] suggesting that the unique modifier dominates in the cross-attention layers compared to the other context tokens, leading to the absence of other semantic appearances.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only findings about the behavior of cross-attention layers in a model.",
      "processing_time": 53.43446588516235,
      "citing_paper_id": "269635322",
      "cited_paper_id": 258999614
    },
    {
      "context_text": "Face0 [107] crops the face region to extract refined embeddings and concatenates them with text features.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method for extracting and concatenating face and text features.",
      "processing_time": 53.75770425796509,
      "citing_paper_id": "269635322",
      "cited_paper_id": 259138505
    },
    {
      "context_text": "In avatar rendering, PAS [145] generates 3D body poses configurable by avatar settings, StyleAvatar3D [146] facilitates 3D avatar generation based on images, and Avatar-Booth [147] employs dual fine-tuned diffusion models for separate face and body generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions tools and methods for 3D avatar generation but does not reference any specific datasets.",
      "processing_time": 52.816269397735596,
      "citing_paper_id": "269635322",
      "cited_paper_id": 259187900
    },
    {
      "context_text": "DVAR [90] improves training efficiency by proposing a clear stopping criterion by removing all randomness to indicate the convergence.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DVAR) for improving training efficiency. There are no verifiable resources or datasets mentioned.",
      "processing_time": 54.65367603302002,
      "citing_paper_id": "269635322",
      "cited_paper_id": 259262648
    },
    {
      "context_text": "[92] Object TTF LDM Negative Prompt Fine-tuning DVAR [90] Object TTF SD 1.5 Randomness Erasing HiPer [166] Object TTF SD Token Embedding Enhancement P+ [18] Object TTF SD 1.4 Token Embedding Enhancement Unet-finetune [23] Object TTF SD Parameter-efficient Fine-tuning Jia et al. [76] Object TTF…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets.",
      "processing_time": 53.42397665977478,
      "citing_paper_id": "269635322",
      "cited_paper_id": 259262648
    },
    {
      "context_text": "Similarly, DreamIdentity [48] leverages the existing knowledge of celebrities embedded in large-scale pre-trained diffusion model to generate both the source image and the edited face image.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or tool called 'DreamIdentity'. The context focuses on the use of a pre-trained model for generating images, which is not a dataset.",
      "processing_time": 56.286797761917114,
      "citing_paper_id": "269635322",
      "cited_paper_id": 259316083
    },
    {
      "context_text": "Cross-attention Fusion [51, 52, 6, 53, 54, 55, 56].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only cross-attention fusion methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.432398319244385,
      "citing_paper_id": "269635322",
      "cited_paper_id": 260886966
    },
    {
      "context_text": "Cross-attention Fusion [51, 52, 6, 53, 54, 55, 56].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only cross-attention fusion methods. The cited paper titles do not provide additional context to identify datasets.",
      "processing_time": 54.432398319244385,
      "citing_paper_id": "269635322",
      "cited_paper_id": 274251363
    },
    {
      "context_text": "For example, IP-Adapter [51] introduces decoupled cross-attention layers that maintain separate query projections for image and text features.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (IP-Adapter) and its components. The context focuses on the architecture and functionality of IP-Adapter.",
      "processing_time": 55.31461834907532,
      "citing_paper_id": "269635322",
      "cited_paper_id": 260886966
    },
    {
      "context_text": "In contrast, SuTI [52] first applies TTF methods to generate synthetic pairwise samples, which can be used for training the PTA network.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (TTF) and a network (PTA). The context is about the methodology and not about using a specific dataset.",
      "processing_time": 55.50144076347351,
      "citing_paper_id": "269635322",
      "cited_paper_id": 261705666
    },
    {
      "context_text": "These methods aim to address key challenges in PCS, like enhancing subject fidelity, minimizing the interference of redundant semantics, enhancing generalization, and avoiding overfitting.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general challenges in personalized content synthesis (PCS). No verifiable resources are identified.",
      "processing_time": 54.06011486053467,
      "citing_paper_id": "269635322",
      "cited_paper_id": 261705666
    },
    {
      "context_text": "These methods aim to address key challenges in PCS, like enhancing subject fidelity, minimizing the interference of redundant semantics, enhancing generalization, and avoiding overfitting.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general challenges in personalized content synthesis (PCS). No verifiable resources are identified.",
      "processing_time": 54.06011486053467,
      "citing_paper_id": "269635322",
      "cited_paper_id": 274166550
    },
    {
      "context_text": "Further, Customiza-tion Assistant [58] and KOSMOS-G [60] replace the text encoder of Stable Diffusion with a pre-trained MLLM to output a fused feature based on the reference and context description.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the integration of a pre-trained multimodal large language model into an image generation system.",
      "processing_time": 55.48924922943115,
      "citing_paper_id": "269635322",
      "cited_paper_id": 263620748
    },
    {
      "context_text": "MotionDirector [134] utilizes spatial and temporal losses to facilitate learning across these dimensions.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called MotionDirector. The context focuses on the use of spatial and temporal losses, which are part of the methodology.",
      "processing_time": 55.80550527572632,
      "citing_paper_id": "269635322",
      "cited_paper_id": 263909602
    },
    {
      "context_text": "With the rising popularity of video generation [123], video personalization has also begun to attract attention.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general trend in video generation and personalization.",
      "processing_time": 52.845484256744385,
      "citing_paper_id": "269635322",
      "cited_paper_id": 264172934
    },
    {
      "context_text": "This follows the tending that high-quality captions in the training set could assist in further improvement of accurate text control [41].",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not mention any specific dataset names, only a general reference to 'training set'. No clear, verifiable resource is identified.",
      "processing_time": 54.7504448890686,
      "citing_paper_id": "269635322",
      "cited_paper_id": 264403242
    },
    {
      "context_text": "Another application, 360-degree panorama customization [151], is also emerging as a potential tool for personalization in the digital imaging realm.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It refers to a method or application for customizing 360-degree panoramas.",
      "processing_time": 54.51526880264282,
      "citing_paper_id": "269635322",
      "cited_paper_id": 264590753
    },
    {
      "context_text": "…et al. [222] Attack and Defense TTF SD backdoor attack Continual Diffusion [223] Others TTF SD Continual Learning SVGCustomization [150] Others TTF SD 1.5 Fine-tuning and Alignment StitchDiffusion [151] Others TTF LDM Parameter-efficient Fine-tuning MC-TI [224] Others TTF SD 1.5 Regularization",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 54.0419921875,
      "citing_paper_id": "269635322",
      "cited_paper_id": 264590753
    },
    {
      "context_text": "Additional conditions in personalization tasks may include adjusting the layout [69], transforming sketches [121], controlling viewpoint [113, 122], or modifying poses [6].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various conditions in personalization tasks. No verifiable resources are identified.",
      "processing_time": 53.49425506591797,
      "citing_paper_id": "269635322",
      "cited_paper_id": 264815845
    },
    {
      "context_text": "CustomNet [113] and MIGC [114] train a PTA network that supports location control for each subject.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models (CustomNet, MIGC). The context focuses on the methodology and capabilities of these models rather than the datasets used.",
      "processing_time": 55.9106969833374,
      "citing_paper_id": "269635322",
      "cited_paper_id": 264815845
    },
    {
      "context_text": "This capability allows DDPMs to function as general-purpose generative engines, producing high-quality outputs from random noise vectors.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only describes a capability of DDPMs.",
      "processing_time": 54.03198599815369,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265050824
    },
    {
      "context_text": "This capability allows DDPMs to function as general-purpose generative engines, producing high-quality outputs from random noise vectors.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only describes a capability of DDPMs.",
      "processing_time": 54.03198599815369,
      "citing_paper_id": "269635322",
      "cited_paper_id": 268064742
    },
    {
      "context_text": "Face-Diffuser [79] determines the mask through augmentation from the noise predicted by both a pre-trained text-to-image diffusion model and a PTA personalized model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the use of a pre-trained text-to-image diffusion model and a PTA personalized model, which are not datasets.",
      "processing_time": 56.897412061691284,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265281113
    },
    {
      "context_text": "Similarly, a study by [91] shows layered activation insight to learn distinct attributes by selectively activating the tokens within their respective scopes.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or approach. The context is about activation insights and token selection, which are methodological aspects.",
      "processing_time": 55.09684658050537,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265295502
    },
    {
      "context_text": "Animate124 [143] and Dream-in-4D [144] integrate video diffusion for 4D dynamic scene support within the 3D optimization process.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Animate124' and 'Dream-in-4D', but these are not datasets. They are methods or tools for generating 4D dynamic scenes. No specific datasets are mentioned.",
      "processing_time": 56.6824996471405,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265445614
    },
    {
      "context_text": "Animate124 [143] and Dream-in-4D [144] integrate video diffusion for 4D dynamic scene support within the 3D optimization process.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Animate124' and 'Dream-in-4D', but these are not datasets. They are methods or tools for generating 4D dynamic scenes. No specific datasets are mentioned.",
      "processing_time": 56.6824996471405,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265466231
    },
    {
      "context_text": "Additionally, several studies [125, 124, 54, 126] have explored the PTA framework.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a framework (PTA). No verifiable resources are identified.",
      "processing_time": 53.80750489234924,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265498336
    },
    {
      "context_text": "Additionally, several studies [125, 124, 54, 126] have explored the PTA framework.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a framework (PTA). No verifiable resources are identified.",
      "processing_time": 53.80750489234924,
      "citing_paper_id": "269635322",
      "cited_paper_id": 274251363
    },
    {
      "context_text": "Furthermore, StyleAligned [99] focuses on maintaining stylistic consistency across a batch of images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model called StyleAligned. The context is about maintaining stylistic consistency in image generation, which is not directly related to personalized text generation.",
      "processing_time": 56.51936674118042,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265608730
    },
    {
      "context_text": "…Injection ViscoNet [206] Extra Conditions PTA SD Multi-feature Injection Context Diffusion [207] Extra First-frame Conditioned Pipeline VMC [129] Video TTF Show-1 Parameter-efficient Fine-tuning SAVE [128] Video TTF VDM Attention-based Operation Customizing Motion [133] Video TTF ZeroScope…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 54.27310252189636,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265608824
    },
    {
      "context_text": "Additionally, VMC [129] removes the background information during training prompt construction.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a method (VMC) and a general process of removing background information during training prompt construction.",
      "processing_time": 54.704920530319214,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265608824
    },
    {
      "context_text": "A common approach is to fine-tune the video diffusion model by reconstructing the action clip [127, 128, 129, 130, 131, 132, 133].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for fine-tuning video diffusion models. No verifiable resources are identified.",
      "processing_time": 54.321364879608154,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265608824
    },
    {
      "context_text": "In the following Section 3.1.1 and Section 3.1.2, we will detail these principles respectively.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, models, or methods. It only refers to sections in the document where principles will be detailed.",
      "processing_time": 54.522467851638794,
      "citing_paper_id": "269635322",
      "cited_paper_id": 265659109
    },
    {
      "context_text": "In the following Section 3.1.1 and Section 3.1.2, we will detail these principles respectively.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The provided context does not mention any specific datasets, models, or methods. It only refers to sections in the document where principles will be detailed.",
      "processing_time": 54.522467851638794,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266999462
    },
    {
      "context_text": "Some research works [6, 46] propose to average or stack features extracted from multiple references to form a composite SoI representation.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for averaging or stacking features from multiple references.",
      "processing_time": 53.06469535827637,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266053833
    },
    {
      "context_text": "Stellar [35] specifically targets human-centric evaluation, featuring 20,000 prompts on 400 human identities.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Stellar"
      ],
      "dataset_descriptions": {
        "Stellar": "Used to evaluate human-centric personalized text-to-image methods, featuring 20,000 prompts on 400 human identities to assess model performance in generating images based on human descriptions."
      },
      "confidence_score": 1.0,
      "reasoning": "The citation mentions 'Stellar' as a dataset with 20,000 prompts on 400 human identities, which is relevant to personalized text generation.",
      "processing_time": 62.04625582695007,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266163420
    },
    {
      "context_text": "Stellar [35] develops six human-centric metrics including soft-penalized CLIP text score, Identity Preservation Score, Attribute Preservation Score, Stability of Identity Score, Grounding Objects Accuracy, and Relation Fidelity Score.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only metrics and scores which are excluded according to the instructions.",
      "processing_time": 53.09152173995972,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266163420
    },
    {
      "context_text": "…[198] Multiple Subjects TTF SD 2.1 Mask-assisted Generation; Attention-based Operation AnyDoor [78] Multiple Mask-assisted Generation Emu2 [199] Multiple Subjects PTA SDXL In-Context Learning SSR-Encoder [55] Multiple Subjects PTA SD 1.5 Attention-based Operation λ -eclipse [112] Multiple…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific, verifiable dataset names. It mentions models and methods, but no datasets that meet the criteria.",
      "processing_time": 54.338034868240356,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266374640
    },
    {
      "context_text": "Similarly, DreamTuner [39] pre-trains a subject encoder that outputs diffusion conditions for accurate reconstruction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DreamTuner) and its functionality. No verifiable resources are identified.",
      "processing_time": 54.51165819168091,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266436022
    },
    {
      "context_text": "DreamTuner [39] designs a self-subject-attention layer to further refine the subject identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called DreamTuner. The context focuses on the method's design and functionality.",
      "processing_time": 54.508519649505615,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266436022
    },
    {
      "context_text": "DreamTuner [39] further refines this approach by designing an attention layer that effectively integrates features from different parts of the image.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DreamTuner) and its approach to integrating features from different parts of an image.",
      "processing_time": 55.298750162124634,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266436022
    },
    {
      "context_text": "…[69] Extra Conditions TTF SD Attention-based Operation SwapAnything [203] Extra Conditions TTF SD 2.1 Mask-assisted Generation PE-VITON [202] Extra Conditions TTF SD Shape and Texture Control Viewpoint Control [122] Extra Conditions TTF SDXL 3D Feature Incorporation Prompt-Free…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not contain any specific, verifiable dataset names. It mentions various methods and models, but no datasets that meet the criteria.",
      "processing_time": 55.05709481239319,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266550896
    },
    {
      "context_text": "…ADI [117] High-level Semantic TTF SD 2.1 Mask-assisted Generation PhotoSwap [118] Extra Conditions TTF SD 2.1 Attention-based Operation PE-VITON [202] Extra Conditions TTF SD Shape and Texture Control Layout-Control [69] Extra Conditions TTF SD Attention-based Operation SwapAnything [203] Extra…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and models. The cited paper title does not help in identifying any datasets.",
      "processing_time": 54.498658895492554,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266550896
    },
    {
      "context_text": "This is also found in another work [33] that the learnable token embeddings deviate significantly from the distribution of the initial embedding.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a deviation in token embeddings. No verifiable resources are identified.",
      "processing_time": 53.8877694606781,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266551699
    },
    {
      "context_text": "And [33] optimizes the learnable token towards the mean textual embedding of 691 well-known names.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable dataset. It refers to '691 well-known names' which is too generic and lacks a clear identifier.",
      "processing_time": 55.4376916885376,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266551699
    },
    {
      "context_text": "Subsequent works [18, 30, 31, 32, 33] aim to address these limitations through different strategies, which are summarized in Section 5.1.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to subsequent works addressing limitations. No verifiable resources are identified.",
      "processing_time": 54.491591930389404,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266551699
    },
    {
      "context_text": "Learnable token embedding [7, 18, 30, 31, 32, 33].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to learnable token embeddings. No verifiable resources are identified.",
      "processing_time": 54.288865089416504,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266551699
    },
    {
      "context_text": "To achieve this goal, this approach combines large-scale pretraining with reference-aware architectures to enable single-pass personalization, as shown in Fig.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general approach combining large-scale pretraining and reference-aware architectures.",
      "processing_time": 54.64006042480469,
      "citing_paper_id": "269635322",
      "cited_paper_id": 266999462
    },
    {
      "context_text": "The process involves leveraging sophisticated methods from 2D personalization, such as parameter-efficient fine-tuning [81], data augmentation [80, 81], and attention manipulation [124, 54, 81].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 55.09382247924805,
      "citing_paper_id": "269635322",
      "cited_paper_id": 267035298
    },
    {
      "context_text": "The process involves leveraging sophisticated methods from 2D personalization, such as parameter-efficient fine-tuning [81], data augmentation [80, 81], and attention manipulation [124, 54, 81].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and techniques. The cited papers' titles do not provide additional information about datasets.",
      "processing_time": 55.09382247924805,
      "citing_paper_id": "269635322",
      "cited_paper_id": 274251363
    },
    {
      "context_text": "Such concept composition is also used in other works [63, 80, 81].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other works. There is no indication of a reusable resource or dataset being used.",
      "processing_time": 54.91678261756897,
      "citing_paper_id": "269635322",
      "cited_paper_id": 267035298
    },
    {
      "context_text": "Building on this strategy, StyleBoost [84] introduces an auxiliary style-specific data to separate content and aesthetic adaptation.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'style-specific data' but does not provide a specific, identifiable dataset name. The term is too generic and lacks a clear identifier.",
      "processing_time": 55.55143857002258,
      "citing_paper_id": "269635322",
      "cited_paper_id": 267202776
    },
    {
      "context_text": "…DreamVideo [135] Video TTF ModelScope Disentanglement Approach MotionCrafter [211] Video TTF VDM Disentanglement Approach Customize-A-Video [212] Video Mask-assisted Generation Anti-DreamBooth [148] Attack and Defense TTF SD 2.1 Perturbation Learning Concept Censorship [149] Attack and…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 54.9384651184082,
      "citing_paper_id": "269635322",
      "cited_paper_id": 267782887
    },
    {
      "context_text": "The complexities of this task have been thoroughly analyzed in another survey [120].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to a survey that analyzes the complexities of a task.",
      "processing_time": 55.10733079910278,
      "citing_paper_id": "269635322",
      "cited_paper_id": 267960812
    },
    {
      "context_text": "TTF meth-ods dynamically adjust model parameters for each new subject during inference, prioritizing visual fidelity at the cost of computational overhead.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and their characteristics.",
      "processing_time": 52.88261365890503,
      "citing_paper_id": "269635322",
      "cited_paper_id": 268064742
    },
    {
      "context_text": "…[196] Multiple Subjects TTF SD 1.5 Attention-based Operation MultiBooth [64] Multiple Subjects TTF SD 1.5 Mask-assisted Generation Matsuda et al. [197] Multiple Subjects TTF LDM Mask-assisted Generation MagicTailor [198] Multiple Subjects TTF SD 2.1 Mask-assisted Generation; Attention-based…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on describing different approaches and techniques used in personalized text-to-image generation.",
      "processing_time": 55.74916696548462,
      "citing_paper_id": "269635322",
      "cited_paper_id": 268527573
    },
    {
      "context_text": "…Multiple Subjects PTA SD 1.5 Attention-based Operation; Mask-assisted Generation IDAdapter [192] Face PTA SD 2.1 Mixed Facial Features Infinite-ID [193] Face PTA SDXL Reference Feature Injection Face2Diffusion [162] Face PTA SD Multi-feature Injection FreeCure [194] Face PTA SD 1.5; SDXL…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 54.92482542991638,
      "citing_paper_id": "269635322",
      "cited_paper_id": 268531420
    },
    {
      "context_text": "…Enhancement Prospect [31] Object MoA [191] Face; Multiple Subjects PTA SD 1.5 Attention-based Operation; Mask-assisted Generation IDAdapter [192] Face PTA SD 2.1 Mixed Facial Features Infinite-ID [193] Face PTA SDXL Reference Feature Injection Face2Diffusion [162] Face PTA SD Multi-feature…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited paper title confirms that the focus is on a method (IDAdapter) rather than a dataset.",
      "processing_time": 56.342231035232544,
      "citing_paper_id": "269635322",
      "cited_paper_id": 268537084
    },
    {
      "context_text": "Hybrid Fusion [63, 64].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other papers. There is no information about the usage of datasets in the given context.",
      "processing_time": 55.55300164222717,
      "citing_paper_id": "269635322",
      "cited_paper_id": 269293816
    },
    {
      "context_text": "Mask-assisted Generation MC2 [196] Multiple Subjects TTF SD 1.5 Attention-based Operation MultiBooth [64] Multiple Subjects TTF SD 1.5 Mask-assisted Generation Matsuda et al. [197] Multiple Subjects TTF LDM Mask-assisted Generation MagicTailor [198] Multiple Subjects TTF SD 2.1 Mask-assisted…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. The context is focused on describing different approaches to mask-assisted generation in image synthesis from text.",
      "processing_time": 56.456289768218994,
      "citing_paper_id": "269635322",
      "cited_paper_id": 269293816
    },
    {
      "context_text": "Diptych Prompting [101] utilizes an inpainting mechanism to draw another image with the same style of the reference part.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method or technique called 'inpainting'. No verifiable resources are identified.",
      "processing_time": 55.19145703315735,
      "citing_paper_id": "269635322",
      "cited_paper_id": 274235061
    },
    {
      "context_text": "…Feature Injection Face2Diffusion [162] Face PTA SD Multi-feature Injection FreeCure [194] Face PTA SD 1.5; SDXL Mask-assisted Generation Omni-ID [195] Face PTA FLUX Face representation enhancement Custom Diffusion [20] Multiple Subjects TTF SD 1.4 Parameter-efficient Fine-tuning; Constrained…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited paper title 'Omni-ID: Holistic Identity Representation Designed for Generative Tasks' confirms that the focus is on a method rather than a dataset.",
      "processing_time": 58.45272755622864,
      "citing_paper_id": "269635322",
      "cited_paper_id": 274763217
    },
    {
      "context_text": "[163] decouples the conditional guidance into two separate processes, which allows for the distinct handling of subject fidelity and textual alignment.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. There are no verifiable resources or datasets mentioned.",
      "processing_time": 55.386284828186035,
      "citing_paper_id": "269635322",
      "cited_paper_id": null
    },
    {
      "context_text": "In contrast, ROUGE is a commonly-used metric for text summarization.",
      "catation_intent": "none",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions ROUGE as a metric, which is excluded according to the instructions. No datasets are mentioned.",
      "processing_time": 54.71822118759155,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "We report the F-measure, which is the geometric mean of the precision and recall of ROUGE-1 and ROUGE-L.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics (ROUGE-1 and ROUGE-L).",
      "processing_time": 54.68480587005615,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "It is worth noting that the previous re-rank settings usually use ROUGE score (Lin 2004) to evaluate the saliency of a candidate template.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions ROUGE score but does not refer to a specific dataset. ROUGE is a metric, not a dataset, and thus should not be included.",
      "processing_time": 56.11415648460388,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "For ROUGE score, all ROUGE-1 scores are pretty high since subjects in KKday contain a lot of proper nouns like place names to describe the products.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only discusses the ROUGE-1 score and the nature of the subjects in KKday, which is not a specific dataset but rather a description of content.",
      "processing_time": 58.232359886169434,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Qualitative Results BLEU and ROUGE Scores Table 3 presents the results of BLEU scores and ROUGE scores, which manifests that TemPEST consistently outperforms the baselines in terms of BLEU scores, i.e., TemPEST synthesizes subjects that are closer to the ground truth references.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only evaluation metrics (BLEU and ROUGE). These metrics are excluded as per the instructions.",
      "processing_time": 55.6943244934082,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Qualitative Results BLEU and ROUGE Scores Table 3 presents the results of BLEU scores and ROUGE scores, which manifests that TemPEST consistently outperforms the baselines in terms of BLEU scores, i.e., TemPEST synthesizes subjects that are closer to the ground truth references.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only evaluation metrics (BLEU and ROUGE). These metrics are excluded as per the instructions.",
      "processing_time": 55.6943244934082,
      "citing_paper_id": "214423113",
      "cited_paper_id": 7139779
    },
    {
      "context_text": "Note that the ROUGE-L scores are comparatively low in this task since the subjects in KKday are succinct and the place names do not need to appear consecutively in certain order to be informative.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset names, only a general reference to 'KKday' which appears to be a domain or task rather than a dataset. No clear, verifiable resource is identified.",
      "processing_time": 57.675989389419556,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "For relevance between generated and reference sentences, we adopt BLEU (Kishore Papineni and Zhu 2002) and ROUGE (Lin 2004).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BLEU and ROUGE, which are evaluation metrics, not datasets. No datasets are mentioned.",
      "processing_time": 54.963656187057495,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "For relevance between generated and reference sentences, we adopt BLEU (Kishore Papineni and Zhu 2002) and ROUGE (Lin 2004).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BLEU and ROUGE, which are evaluation metrics, not datasets. No datasets are mentioned.",
      "processing_time": 54.963656187057495,
      "citing_paper_id": "214423113",
      "cited_paper_id": 7139779
    },
    {
      "context_text": "Finally, our proposed TemPEST is slightly less than BiSET in ROUGE-L.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison of performance metrics between two models.",
      "processing_time": 54.490710973739624,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "However, using a ROUGE score captures only word-level similarity.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a metric (ROUGE) which is excluded.",
      "processing_time": 54.780343770980835,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Hence, S2S+Att performs even poorer than Lead -1 in terms of ROUGE-L, which also justify the reason why we adopt template-based summarization methods.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a performance metric (ROUGE-L) and a method (template-based summarization).",
      "processing_time": 56.0380961894989,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "For instance, when generating EDM subject lines for the product of tour packages, subjects contain “one day tour” returns high ROUGE score since similar words often appear in subjects.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a general concept of generating EDM subject lines for tour packages, which is not a specific dataset.",
      "processing_time": 56.8674590587616,
      "citing_paper_id": "214423113",
      "cited_paper_id": 964287
    },
    {
      "context_text": "Inspired by the research in selective mechanism (Zhou et al. 2017; Wang, Quan, and Wang 2019), we propose a novel soft Tem plate-based P ersonalized E DM S ubject generation (TemPEST) module for personalized summarization.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to research papers and a proposed method. No verifiable resources are identified.",
      "processing_time": 55.617931842803955,
      "citing_paper_id": "214423113",
      "cited_paper_id": 1770102
    },
    {
      "context_text": "Inspired by the research in selective mechanism (Zhou et al. 2017; Wang, Quan, and Wang 2019), we propose a novel soft Template-based Personalized EDM Subject generation (TemPEST) module for personalized summarization.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method or model. The context focuses on the proposed TemPEST module inspired by selective mechanisms.",
      "processing_time": 56.35788106918335,
      "citing_paper_id": "214423113",
      "cited_paper_id": 1770102
    },
    {
      "context_text": "Each description contains 885 Traditional Chinese characters on average and is tok-enized by CKIP (Sproat and Emerson 2003).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'CKIP' which is a tool for tokenization, not a dataset. No specific dataset is mentioned.",
      "processing_time": 55.49142503738403,
      "citing_paper_id": "214423113",
      "cited_paper_id": 2776693
    },
    {
      "context_text": "With the advance of deep learning, autoencoders have become popular to model the users’ preference (Wang, Wang, and Yeung 2015; Wu et al. 2016; Li and She 2017; Ma et al. 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the use of autoencoders in modeling user preferences. No verifiable resources are identified.",
      "processing_time": 56.35411238670349,
      "citing_paper_id": "214423113",
      "cited_paper_id": 4833213
    },
    {
      "context_text": "With the advance of deep learning, autoencoders have become popular to model the users’ preference (Wang, Wang, and Yeung 2015; Wu et al. 2016; Li and She 2017; Ma et al. 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the use of autoencoders in modeling user preferences. No verifiable resources are identified.",
      "processing_time": 56.35411238670349,
      "citing_paper_id": "214423113",
      "cited_paper_id": 13480063
    },
    {
      "context_text": "With the advance of deep learning, autoencoders have become popular to model the users’ preference (Wang, Wang, and Yeung 2015; Wu et al. 2016; Li and She 2017; Ma et al. 2019).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only the use of autoencoders in modeling user preferences. No verifiable resources are identified.",
      "processing_time": 56.35411238670349,
      "citing_paper_id": "214423113",
      "cited_paper_id": 54457428
    },
    {
      "context_text": "We train a Word2Vec embedding (Mikolov et al. 2013a) with Wikipedia.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions training a Word2Vec embedding using Wikipedia, but does not specify a named dataset. 'Wikipedia' is a general reference and not a specific, verifiable dataset.",
      "processing_time": 57.71586036682129,
      "citing_paper_id": "214423113",
      "cited_paper_id": 5959482
    },
    {
      "context_text": "We train a Word2Vec embedding (Mikolov et al. 2013a) with Wikipedia.",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions training a Word2Vec embedding using Wikipedia, but does not specify a named dataset. 'Wikipedia' is a general reference and not a specific, verifiable dataset.",
      "processing_time": 57.71586036682129,
      "citing_paper_id": "214423113",
      "cited_paper_id": 16447573
    },
    {
      "context_text": "Besides, for styling relevance between generated sentences and user-speciﬁc sentences, we use the Word2Vec similarity (Mikolov et al. 2013a; 2013b) to measure the similarity between generated subject and source article.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of Word2Vec similarity for measuring the similarity between generated subjects and source articles.",
      "processing_time": 55.887900829315186,
      "citing_paper_id": "214423113",
      "cited_paper_id": 5959482
    },
    {
      "context_text": "Besides, for styling relevance between generated sentences and user-speciﬁc sentences, we use the Word2Vec similarity (Mikolov et al. 2013a; 2013b) to measure the similarity between generated subject and source article.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of Word2Vec similarity for measuring the similarity between generated subjects and source articles.",
      "processing_time": 55.887900829315186,
      "citing_paper_id": "214423113",
      "cited_paper_id": 16447573
    },
    {
      "context_text": "BLEU is a well-known metric for evaluating the quality of the generated text, which has been widely used for machine translation and image captioning.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a metric (BLEU) which is excluded according to the instructions.",
      "processing_time": 55.442164182662964,
      "citing_paper_id": "214423113",
      "cited_paper_id": 7139779
    },
    {
      "context_text": "We use smoothed BLEU (Lin and Och 2004) and report the results of BLEU from 1 to 4.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics. The context is focused on reporting BLEU scores, which are not datasets.",
      "processing_time": 56.184565782547,
      "citing_paper_id": "214423113",
      "cited_paper_id": 7139779
    },
    {
      "context_text": "Li and She (2017) use variational autoencoder to learn deep latent representation from item content, and jointly model the generation of latent content and user ratings.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (variational autoencoder) and a general application (item content and user ratings).",
      "processing_time": 56.390024185180664,
      "citing_paper_id": "214423113",
      "cited_paper_id": 13480063
    },
    {
      "context_text": "• S2S+Att is a sequence-to-sequence model with attention implemented by the OpenNMT (Klein et al. 2017).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a model and a toolkit, not a dataset. There are no specific, verifiable datasets mentioned in the context.",
      "processing_time": 55.763582944869995,
      "citing_paper_id": "214423113",
      "cited_paper_id": 16538528
    },
    {
      "context_text": "The idea of personalized review generation mostly aims to generate different aspects of reviews (Li, Li, and Zong 2019; Ni and McAuley 2018; Liu et al. 2018), which either exploits users’ past reviews as the additional input or utilizes users’ annotation/highlight words to capture different aspects…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions personalized review generation but does not specify any named datasets. It focuses on methods and approaches rather than specific datasets.",
      "processing_time": 55.43842697143555,
      "citing_paper_id": "214423113",
      "cited_paper_id": 52975881
    },
    {
      "context_text": "The idea of personalized review generation mostly aims to generate different aspects of reviews (Li, Li, and Zong 2019; Ni and McAuley 2018; Liu et al. 2018), which either exploits users’ past reviews as the additional input or utilizes users’ annotation/highlight words to capture different aspects…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions personalized review generation but does not specify any named datasets. It focuses on methods and approaches rather than specific datasets.",
      "processing_time": 55.43842697143555,
      "citing_paper_id": "214423113",
      "cited_paper_id": 69778590
    },
    {
      "context_text": "To address the third challenge, we propose a gated attentive autoencoder based on Ma et al. (2019).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (gated attentive autoencoder).",
      "processing_time": 54.900063276290894,
      "citing_paper_id": "214423113",
      "cited_paper_id": 54457428
    },
    {
      "context_text": "Extractive methods (Narayan, Cohen, and Lapata 2018; Jadhav and Rajan 2018) select sentences from articles and combine them into a paragraph, while abstractive methods (Cao et al. 2018b; Gao et al. 2019) rewrite the summaries, which may not be featured in the source text.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods for text summarization. No verifiable resources are identified.",
      "processing_time": 55.46481943130493,
      "citing_paper_id": "214423113",
      "cited_paper_id": 55461757
    },
    {
      "context_text": "One of the possible solutions is to use article summarization (Cao et al. 2018b; Gao et al. 2019), which aims to summarize the content with a few sentences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general approach to article summarization. No verifiable resources are identified.",
      "processing_time": 55.49197959899902,
      "citing_paper_id": "214423113",
      "cited_paper_id": 55461757
    },
    {
      "context_text": "Alternatively, personalized review generation (Ni and McAuley 2018; Li, Li, and Zong 2019) is another method that seeks to help users in their choices or the understanding of the recommendation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for personalized review generation.",
      "processing_time": 54.260359048843384,
      "citing_paper_id": "214423113",
      "cited_paper_id": 69778590
    },
    {
      "context_text": "Moreover, Truong and Lauw (2019) input both reviews and ratings to generate a more holistic representation of a review guided by the recommender, which generates a document according to rat-7539 ings.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context mentions 'ratings' as part of the input for generating a more holistic representation of a review, but does not specify a dataset name. The term 'ratings' is too generic and lacks a specific identifier.",
      "processing_time": 58.39716124534607,
      "citing_paper_id": "214423113",
      "cited_paper_id": 86471548
    },
    {
      "context_text": "SAM processes the detected boxes using a ViT-H/16 (Dosovitskiy et al. (2021)) image encoder ( Z ∈ R 256 × H/ 16 × W/ 16 ) and encodes box coordinates into sparse embeddings ( E b ∈ R N × 256 ).",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (ViT-H/16) and its application. No verifiable datasets are referenced.",
      "processing_time": 56.28755283355713,
      "citing_paper_id": "278714931",
      "cited_paper_id": 225039882
    },
    {
      "context_text": "Token selection: We look for combination of letters in the CLIP (Radford et al. (2021)) tokenizer that carry little to no prior association with any word.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (CLIP) which is excluded according to the rules.",
      "processing_time": 55.71572136878967,
      "citing_paper_id": "278714931",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "We begin by scanning the CLIP tokenizer vocabulary for apparently gibberish tokens, typically short words (4–5 letters) that are unlikely to appear in Figure 2: Overall Pipeline of Image-Alchemy conventional usage 2 .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method for identifying gibberish tokens in the CLIP tokenizer vocabulary.",
      "processing_time": 56.13318467140198,
      "citing_paper_id": "278714931",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "DINO generally performs well in capturing visual features and is less reliant on text-based understanding compared to CLIP.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (DINO and CLIP). The citation is discussing model performance rather than dataset usage.",
      "processing_time": 56.27863550186157,
      "citing_paper_id": "278714931",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "DINO generally performs well in capturing visual features and is less reliant on text-based understanding compared to CLIP.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models (DINO and CLIP). The citation is discussing model performance rather than dataset usage.",
      "processing_time": 56.27863550186157,
      "citing_paper_id": "278714931",
      "cited_paper_id": 233444273
    },
    {
      "context_text": "We found that the tokens used by DreamBooth for image personalization show strong biases in the CLIP text encoder of the Stable Diffusion XL (SDXL) model.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses biases in the CLIP text encoder of the SDXL model, which is a model, not a dataset.",
      "processing_time": 57.539966106414795,
      "citing_paper_id": "278714931",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "We found that the tokens used by DreamBooth for image personalization show strong biases in the CLIP text encoder of the Stable Diffusion XL (SDXL) model.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses biases in the CLIP text encoder of the SDXL model, which is a model, not a dataset.",
      "processing_time": 57.539966106414795,
      "citing_paper_id": "278714931",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "We found that the tokens used by DreamBooth for image personalization show strong biases in the CLIP text encoder of the Stable Diffusion XL (SDXL) model.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It discusses biases in the CLIP text encoder of the SDXL model, which is a model, not a dataset.",
      "processing_time": 57.539966106414795,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "In text-to-image diffusion models like SDXL, each prompt token is first mapped to a token embedding via CLIP’s text encoder.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is about the process of mapping prompt tokens to embeddings using CLIP’s text encoder, which is a method.",
      "processing_time": 57.72164559364319,
      "citing_paper_id": "278714931",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "In text-to-image diffusion models like SDXL, each prompt token is first mapped to a token embedding via CLIP’s text encoder.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is about the process of mapping prompt tokens to embeddings using CLIP’s text encoder, which is a method.",
      "processing_time": 57.72164559364319,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "CLIP-T measures cosine similarity between textual descriptions of the generated and reference images.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method for measuring similarity between textual descriptions and images.",
      "processing_time": 55.010247468948364,
      "citing_paper_id": "278714931",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "CLIP-I measures cosine similarity between the embeddings of reference and generated images, but it is not considered a reliable metric for evaluating frameworks like ours because it fails to recognize rare or unique tokens (e.g., ”mccre wearing a leather jacket and jeans”) that hold no meaning in its text encoder, leading to arbitrary similarity scores.",
      "catation_intent": "findings",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a metric (CLIP-I) which is not a dataset. The citation is about the limitations of a metric, not the use of a dataset.",
      "processing_time": 58.0222430229187,
      "citing_paper_id": "278714931",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "We compute embeddings for both reference images and generated outputs using CLIP (CLIP-I) (Radford et al. (2021)) and DINO (Caron et al. (2021)), by measuring cosine similarity in the subject region.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions CLIP and DINO, which are models, not datasets. No specific datasets are mentioned or used in the described methodology.",
      "processing_time": 56.51329016685486,
      "citing_paper_id": "278714931",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "We compute embeddings for both reference images and generated outputs using CLIP (CLIP-I) (Radford et al. (2021)) and DINO (Caron et al. (2021)), by measuring cosine similarity in the subject region.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions CLIP and DINO, which are models, not datasets. No specific datasets are mentioned or used in the described methodology.",
      "processing_time": 56.51329016685486,
      "citing_paper_id": "278714931",
      "cited_paper_id": 233444273
    },
    {
      "context_text": "Consequently, we seek a “rare” token—one that the model does not strongly associate with any specific concept, and for which the CLIP tokenizer is not well trained on—so that the newly introduced subject can be learned without disrupting the model’s learned representation by a substantial margin.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a general requirement for a 'rare' token. No verifiable resources are identified.",
      "processing_time": 56.22161602973938,
      "citing_paper_id": "278714931",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "Generative models have significantly evolved, with diffusion models (Ho et al. (2020), Nichol & Dhariwal (2021)",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only generative models and diffusion models. No verifiable resources are identified.",
      "processing_time": 55.73283267021179,
      "citing_paper_id": "278714931",
      "cited_paper_id": 231979499
    },
    {
      "context_text": "The state-of-the-art latent diffusion based image generation models, including Stable Diffusion(Rombach et al. (2022)), Dall-e (Ramesh et al. (2021)), have been able to produce convincing images of generic objects and scenes, but they struggle with representing a new, specific subject.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their capabilities. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 56.442832708358765,
      "citing_paper_id": "278714931",
      "cited_paper_id": 232035663
    },
    {
      "context_text": "The state-of-the-art latent diffusion based image generation models, including Stable Diffusion(Rombach et al. (2022)), Dall-e (Ramesh et al. (2021)), have been able to produce convincing images of generic objects and scenes, but they struggle with representing a new, specific subject.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their capabilities. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 56.442832708358765,
      "citing_paper_id": "278714931",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "Grounding DINO uses a Swin Transformer (Liu et al. (2021)) image encoder and a BERT-based (Devlin et al. (2019)) text encoder to project visual and textual features into a shared d-dimensional space ( d = 256 ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on describing the components of Grounding DINO, which uses a Swin Transformer and BERT-based encoders.",
      "processing_time": 57.74494004249573,
      "citing_paper_id": "278714931",
      "cited_paper_id": 232352874
    },
    {
      "context_text": "Grounding DINO uses a Swin Transformer (Liu et al. (2021)) image encoder and a BERT-based (Devlin et al. (2019)) text encoder to project visual and textual features into a shared d-dimensional space ( d = 256 ).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on describing the components of Grounding DINO, which uses a Swin Transformer and BERT-based encoders.",
      "processing_time": 57.74494004249573,
      "citing_paper_id": "278714931",
      "cited_paper_id": 233444273
    },
    {
      "context_text": "The segmentation pipeline integrates Grounding DINO’s zero-shot detection capabilities with SAM’s prompt-driven segmentation in a two-step framework, resulting in mask generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the integration of Grounding DINO and SAM for mask generation.",
      "processing_time": 56.85024571418762,
      "citing_paper_id": "278714931",
      "cited_paper_id": 233444273
    },
    {
      "context_text": "Grounded SAM (Ren et al. (2024)), which combines the capabilities of Grounding DINO (Liu et al. (2024)) and the Segment Anything Model (SAM) (Kirillov et al. (2023)), allows for open-set object detection and segmentation guided by textual prompts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the combination of capabilities from different models.",
      "processing_time": 56.29637265205383,
      "citing_paper_id": "278714931",
      "cited_paper_id": 233444273
    },
    {
      "context_text": "DINO evaluates subject preservation by computing cosine similarity.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating subject preservation.",
      "processing_time": 54.51538896560669,
      "citing_paper_id": "278714931",
      "cited_paper_id": 233444273
    },
    {
      "context_text": "In this work, we propose a two-stage pipeline that aims to preserve the original generative strengths of the latent diffusion-based (Rombach et al. (2022)) image generation model Stable Diffusion XL (Podell et al. (2023)) while introducing new subjects learned in a fast, lightweight manner.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 56.29676342010498,
      "citing_paper_id": "278714931",
      "cited_paper_id": 245335280
    },
    {
      "context_text": "In this work, we propose a two-stage pipeline that aims to preserve the original generative strengths of the latent diffusion-based (Rombach et al. (2022)) image generation model Stable Diffusion XL (Podell et al. (2023)) while introducing new subjects learned in a fast, lightweight manner.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 56.29676342010498,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "DreamBooth (Ruiz et al. (2023)) refines personalization by fine-tuning text-to-image models on a few user-provided images, allowing for the synthesis of subject-specific visuals while maintaining identity consistency.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method (DreamBooth) for personalizing text-to-image models, which is not a dataset.",
      "processing_time": 56.89630579948425,
      "citing_paper_id": "278714931",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Few shot fine-tuning techniques including Dreambooth (Ruiz et al. (2023)), Hyperdreambooth (Ruiz et al. (2024)) and Textual inversion (Gal et al. (2022)) either have a high computational burden, or low image fidelity, limiting their adaptability.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the limitations of few-shot fine-tuning techniques.",
      "processing_time": 56.24724769592285,
      "citing_paper_id": "278714931",
      "cited_paper_id": 251800180
    },
    {
      "context_text": "Few shot fine-tuning techniques including Dreambooth (Ruiz et al. (2023)), Hyperdreambooth (Ruiz et al. (2024)) and Textual inversion (Gal et al. (2022)) either have a high computational burden, or low image fidelity, limiting their adaptability.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and methods. The citation is focused on the limitations of few-shot fine-tuning techniques.",
      "processing_time": 56.24724769592285,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "InstructPix2Pi (Brooks et al. (2023)) extends this capability by integrating natural language instructions into the editing process, allowing users to specify precise changes using textual descriptions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for integrating natural language instructions into image editing.",
      "processing_time": 54.919782638549805,
      "citing_paper_id": "278714931",
      "cited_paper_id": 253581213
    },
    {
      "context_text": "Cones (Liu et al. (2023)) introduces concept neurons, focusing on interpretability over fine-tuning effectiveness, limiting its use for general customization.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called 'concept neurons' which is part of the Cones framework. The context focuses on the limitations of the method for general customization.",
      "processing_time": 57.00685167312622,
      "citing_paper_id": "278714931",
      "cited_paper_id": 257427549
    },
    {
      "context_text": "Diffusion models have also been widely adopted for image editing, where methods like MyStyle (Nitzan et al. (2022)) performed well in maintaining identity during image editing but needed extensive fine-tuning and computational power, restricting scalability.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (MyStyle) and its limitations. The context focuses on the challenges of using diffusion models for image editing.",
      "processing_time": 56.567041873931885,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "We demonstrate that this approach efficiently combines the model’s compositional power with high-fidelity subject insertion, with the entire pipeline taking only about 7–8 minutes to complete on the SDXL model.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (SDXL). No verifiable resources are identified.",
      "processing_time": 55.01573467254639,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "To address this problem, we propose a new set of tokens for subject personalization in SDXL.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a new set of tokens for subject personalization, which is a method or approach rather than a dataset.",
      "processing_time": 56.485899209976196,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "We fine-tune SDXL on 4–5 reference images of a specific subject (e.g., “Rahul”) using a standard approach similar to DreamBooth, without prior preservation loss.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method for fine-tuning a model using reference images, but does not name a dataset.",
      "processing_time": 56.0789155960083,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "The difference between SDXL’s baseline generation and our personalized outputs remains small, suggesting minimal degradation in overall fidelity.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between a baseline and personalized outputs.",
      "processing_time": 54.05092644691467,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "For each candidate token, we perform multiple text-to-image generations using the unmodified SDXL under different random seeds.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a method (text-to-image generations) and a model (unmodified SDXL).",
      "processing_time": 55.9262900352478,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "(a) Stage 1: Generate a generic image using the base (unmodified) SDXL by substituting the subject with its class label (e.g., “person”) in the prompt.",
      "catation_intent": "none",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes a method for generating images using a modified prompt with a class label.",
      "processing_time": 55.307044506073,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "By leveraging LoRA-based fine-tuning on SDXL’s attention layers and employing a segmentation-driven Img2Img process, the method effectively isolates subject personalization from scene composition.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and processes. There are no verifiable resources or datasets named in the text.",
      "processing_time": 55.30375266075134,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "LoRA-based fine-tuning: We fine-tune only the attention layers of the Unet (Ronneberger et al. (2015)) of SDXL (Podell et al. (2023)) with LoRA (Hu et al. (2021)) on 4–5 subject images, such that the model overfits on the new object, and store the LoRA safetensors separately.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the fine-tuning process using LoRA, which is a method, not a dataset.",
      "processing_time": 55.95424199104309,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "Rather than relying on the fine-tuned model to generate the entire scene, we exploit SDXL’s original, unaltered capabilities for layout and background details.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a model (SDXL) and its capabilities, which are excluded according to the instructions.",
      "processing_time": 55.480931758880615,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "Once the base image is generated (3.3) and the subject region is blurred, we load the LoRA-adapted SDXL model from Section 3.2 and construct a prompt containing the placeholder token.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model and a process. There are no verifiable resources that meet the criteria.",
      "processing_time": 54.852171421051025,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "HyperDreamBooth (Ruiz et al. (2024)) improves these methods by incorporating hypernetworks, which improve adaptability and efficiency when fine-tuning diffusion models.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called HyperDreamBooth. The context focuses on the improvements brought by hypernetworks in fine-tuning diffusion models.",
      "processing_time": 55.6791033744812,
      "citing_paper_id": "278714931",
      "cited_paper_id": null
    },
    {
      "context_text": "A common approach involves using an RLHF (Reinforcement Learning with Human Feedback) framework (Christiano et al., 2017; Bai et al., 2022) where a reward model is trained based on human feedback, and Proximal Policy Optimization (PPO) (Schulman et al., 2017) is employed to derive the aligned…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and frameworks. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 54.883965492248535,
      "citing_paper_id": "273185508",
      "cited_paper_id": 4787508
    },
    {
      "context_text": "A common approach involves using an RLHF (Reinforcement Learning with Human Feedback) framework (Christiano et al., 2017; Bai et al., 2022) where a reward model is trained based on human feedback, and Proximal Policy Optimization (PPO) (Schulman et al., 2017) is employed to derive the aligned…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and frameworks. The cited papers do not provide additional context to identify datasets.",
      "processing_time": 54.883965492248535,
      "citing_paper_id": "273185508",
      "cited_paper_id": 248118878
    },
    {
      "context_text": "Inspired by the concept of successor features (Dayan, 1993; Barreto et al., 2017), we first define the personalized reward function, which is composed of the features of the current state and personalized preferences.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only concepts and methods. There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 54.828465700149536,
      "citing_paper_id": "273185508",
      "cited_paper_id": 12559116
    },
    {
      "context_text": "Notably, DPO (Rafailov et al., 2024b) leverages the Bradley-Terry assumption (Bradley & Terry, 1952) for direct optimization of the preference-based objective.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (DPO) and a statistical assumption (Bradley-Terry).",
      "processing_time": 54.62137842178345,
      "citing_paper_id": "273185508",
      "cited_paper_id": 121987403
    },
    {
      "context_text": "The reward function is modeled under a contextual bandit setting using the Bradley-Terry preference model (Bradley & Terry, 1952): where y w and y l denote the preferred and not-preferred completions for the prompt x . p ∗ ( y w ⪰ y l ) denotes the probability that y w is preferred to y l .",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for modeling preferences in a contextual bandit setting.",
      "processing_time": 53.929075956344604,
      "citing_paper_id": "273185508",
      "cited_paper_id": 121987403
    },
    {
      "context_text": "Training-free General Policy Single Reward Generalizability MORLHF (Li et al., 2020) × ✓ × × MODPO (Zhou et al., 2023) × ✓ - × Personalized soups (Jang et al., 2023) × × × × Preference Prompting (Jang et al., 2023) ✓ ✓ - ✓ Rewarded soups (Rame et al., 2024) × × × × RiC (Yang et al., 2024b) × ✓ × × DPA (Wang et al., 2024a) × ✓ ✓ × Args (Khanov et al., 2024) ✓ ✓ × × MOD (Shi et al., 2024) ✓ × × × MetaAligner (Yang et al., 2024a) Policy), eliminating the need for training additional policy models (Training-free).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 53.92607355117798,
      "citing_paper_id": "273185508",
      "cited_paper_id": 174802898
    },
    {
      "context_text": "Training-free General Policy Single Reward Generalizability MORLHF (Li et al., 2020) × ✓ × × MODPO (Zhou et al., 2023) × ✓ - × Personalized soups (Jang et al., 2023) × × × × Preference Prompting (Jang et al., 2023) ✓ ✓ - ✓ Rewarded soups (Rame et al., 2024) × × × × RiC (Yang et al., 2024b) × ✓ × × DPA (Wang et al., 2024a) × ✓ ✓ × Args (Khanov et al., 2024) ✓ ✓ × × MOD (Shi et al., 2024) ✓ × × × MetaAligner (Yang et al., 2024a) Policy), eliminating the need for training additional policy models (Training-free).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 53.92607355117798,
      "citing_paper_id": "273185508",
      "cited_paper_id": 260333927
    },
    {
      "context_text": "Training-free General Policy Single Reward Generalizability MORLHF (Li et al., 2020) × ✓ × × MODPO (Zhou et al., 2023) × ✓ - × Personalized soups (Jang et al., 2023) × × × × Preference Prompting (Jang et al., 2023) ✓ ✓ - ✓ Rewarded soups (Rame et al., 2024) × × × × RiC (Yang et al., 2024b) × ✓ × × DPA (Wang et al., 2024a) × ✓ ✓ × Args (Khanov et al., 2024) ✓ ✓ × × MOD (Shi et al., 2024) ✓ × × × MetaAligner (Yang et al., 2024a) Policy), eliminating the need for training additional policy models (Training-free).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 53.92607355117798,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267411977
    },
    {
      "context_text": "Training-free General Policy Single Reward Generalizability MORLHF (Li et al., 2020) × ✓ × × MODPO (Zhou et al., 2023) × ✓ - × Personalized soups (Jang et al., 2023) × × × × Preference Prompting (Jang et al., 2023) ✓ ✓ - ✓ Rewarded soups (Rame et al., 2024) × × × × RiC (Yang et al., 2024b) × ✓ × × DPA (Wang et al., 2024a) × ✓ ✓ × Args (Khanov et al., 2024) ✓ ✓ × × MOD (Shi et al., 2024) ✓ × × × MetaAligner (Yang et al., 2024a) Policy), eliminating the need for training additional policy models (Training-free).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 53.92607355117798,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267682397
    },
    {
      "context_text": "Training-free General Policy Single Reward Generalizability MORLHF (Li et al., 2020) × ✓ × × MODPO (Zhou et al., 2023) × ✓ - × Personalized soups (Jang et al., 2023) × × × × Preference Prompting (Jang et al., 2023) ✓ ✓ - ✓ Rewarded soups (Rame et al., 2024) × × × × RiC (Yang et al., 2024b) × ✓ × × DPA (Wang et al., 2024a) × ✓ ✓ × Args (Khanov et al., 2024) ✓ ✓ × × MOD (Shi et al., 2024) ✓ × × × MetaAligner (Yang et al., 2024a) Policy), eliminating the need for training additional policy models (Training-free).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. No verifiable resources are identified.",
      "processing_time": 53.92607355117798,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270764846
    },
    {
      "context_text": "Training-free General Policy Single Reward Generalizability MORLHF (Li et al., 2020) × ✓ × × MODPO (Zhou et al., 2023) × ✓ - × Personalized soups (Jang et al., 2023) × × × × Preference Prompting (Jang et al., 2023) ✓ ✓ - ✓ Rewarded soups (Rame et al., 2024) × × × × RiC (Yang et al., 2024b) × ✓ × ×…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and papers. There are no clear identifiers for datasets within the text.",
      "processing_time": 54.45737910270691,
      "citing_paper_id": "273185508",
      "cited_paper_id": 174802898
    },
    {
      "context_text": "MORLHF (Li et al., 2020) optimizes for the weighted multi-objective reward function using PPO.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (MORLHF) and an algorithm (PPO).",
      "processing_time": 54.40304708480835,
      "citing_paper_id": "273185508",
      "cited_paper_id": 174802898
    },
    {
      "context_text": "Based on this, existing work (Li et al., 2020; Rame et al., 2024) employs a linear scalarization strategy, denoting human preferences as w such that R = w T ˆ R .",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a methodological approach. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 54.576637983322144,
      "citing_paper_id": "273185508",
      "cited_paper_id": 174802898
    },
    {
      "context_text": "We derive the value function (Watkins & Dayan, 1992) of personalized reward function, inspired by that the optimal policy π ∗ obtained by Equation 3 can be formulated as (Ziebart, 2010; Rafailov et al., 2024a): where Q , the action-value function (i.e., Q function) based on the token-level reward R…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only theoretical concepts and equations. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 54.52369737625122,
      "citing_paper_id": "273185508",
      "cited_paper_id": 208910339
    },
    {
      "context_text": "AI alignment ensures systems follow human intentions and values (Stiennon et al., 2020; Bai et al., 2022; Ouyang et al., 2022; Achiam et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works on AI alignment and human feedback. No verifiable resources are identified.",
      "processing_time": 54.69177269935608,
      "citing_paper_id": "273185508",
      "cited_paper_id": 246426909
    },
    {
      "context_text": "AI alignment ensures systems follow human intentions and values (Stiennon et al., 2020; Bai et al., 2022; Ouyang et al., 2022; Achiam et al., 2023).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to research works on AI alignment and human feedback. No verifiable resources are identified.",
      "processing_time": 54.69177269935608,
      "citing_paper_id": "273185508",
      "cited_paper_id": 248118878
    },
    {
      "context_text": "During decoding, the PRM scores the base model’s top-K predictions at each token generation step based on the current generation and personalized preferences.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for scoring predictions during decoding. No verifiable resources are identified.",
      "processing_time": 54.24750304222107,
      "citing_paper_id": "273185508",
      "cited_paper_id": 246634179
    },
    {
      "context_text": "…area of research in computer vision and natural language processing, with significant implications for the fields of embodied agents (Zhao et al., 2023; 2024b;c; Deng et al., 2023; 2024; Zhao et al., 2024a), video understanding (Chai et al., 2023; Song et al., 2024a;b), etc. (Chen et al., 2024a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research and papers. No verifiable resources are identified.",
      "processing_time": 54.25183820724487,
      "citing_paper_id": "273185508",
      "cited_paper_id": 260333927
    },
    {
      "context_text": "…area of research in computer vision and natural language processing, with significant implications for the fields of embodied agents (Zhao et al., 2023; 2024b;c; Deng et al., 2023; 2024; Zhao et al., 2024a), video understanding (Chai et al., 2023; Song et al., 2024a;b), etc. (Chen et al., 2024a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research and papers. No verifiable resources are identified.",
      "processing_time": 54.25183820724487,
      "citing_paper_id": "273185508",
      "cited_paper_id": 261031087
    },
    {
      "context_text": "…area of research in computer vision and natural language processing, with significant implications for the fields of embodied agents (Zhao et al., 2023; 2024b;c; Deng et al., 2023; 2024; Zhao et al., 2024a), video understanding (Chai et al., 2023; Song et al., 2024a;b), etc. (Chen et al., 2024a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research and papers. No verifiable resources are identified.",
      "processing_time": 54.25183820724487,
      "citing_paper_id": "273185508",
      "cited_paper_id": 265608726
    },
    {
      "context_text": "…area of research in computer vision and natural language processing, with significant implications for the fields of embodied agents (Zhao et al., 2023; 2024b;c; Deng et al., 2023; 2024; Zhao et al., 2024a), video understanding (Chai et al., 2023; Song et al., 2024a;b), etc. (Chen et al., 2024a).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general areas of research and papers. No verifiable resources are identified.",
      "processing_time": 54.25183820724487,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270559827
    },
    {
      "context_text": "…achieves joint optimization for different personalized preferences by defining a reward function with multiple dimensions and performing policy optimization (Zhou et al., 2023; Wang et al., 2024a;b; Guo et al., 2024; Yang et al., 2024b; Chakraborty et al., 2024; Sun et al., 2024; Li et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches for personalized text generation.",
      "processing_time": 53.98252463340759,
      "citing_paper_id": "273185508",
      "cited_paper_id": 260333927
    },
    {
      "context_text": "…achieves joint optimization for different personalized preferences by defining a reward function with multiple dimensions and performing policy optimization (Zhou et al., 2023; Wang et al., 2024a;b; Guo et al., 2024; Yang et al., 2024b; Chakraborty et al., 2024; Sun et al., 2024; Li et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches for personalized text generation.",
      "processing_time": 53.98252463340759,
      "citing_paper_id": "273185508",
      "cited_paper_id": 263831633
    },
    {
      "context_text": "…achieves joint optimization for different personalized preferences by defining a reward function with multiple dimensions and performing policy optimization (Zhou et al., 2023; Wang et al., 2024a;b; Guo et al., 2024; Yang et al., 2024b; Chakraborty et al., 2024; Sun et al., 2024; Li et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches for personalized text generation.",
      "processing_time": 53.98252463340759,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267411977
    },
    {
      "context_text": "…achieves joint optimization for different personalized preferences by defining a reward function with multiple dimensions and performing policy optimization (Zhou et al., 2023; Wang et al., 2024a;b; Guo et al., 2024; Yang et al., 2024b; Chakraborty et al., 2024; Sun et al., 2024; Li et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches for personalized text generation.",
      "processing_time": 53.98252463340759,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267682397
    },
    {
      "context_text": "…achieves joint optimization for different personalized preferences by defining a reward function with multiple dimensions and performing policy optimization (Zhou et al., 2023; Wang et al., 2024a;b; Guo et al., 2024; Yang et al., 2024b; Chakraborty et al., 2024; Sun et al., 2024; Li et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches for personalized text generation.",
      "processing_time": 53.98252463340759,
      "citing_paper_id": "273185508",
      "cited_paper_id": 275118993
    },
    {
      "context_text": "…al., 2023) × × × × Preference Prompting (Jang et al., 2023) ✓ ✓ - ✓ Rewarded soups (Rame et al., 2024) × × × × RiC (Yang et al., 2024b) × ✓ × × DPA (Wang et al., 2024a) × ✓ ✓ × Args (Khanov et al., 2024) ✓ ✓ × × MOD (Shi et al., 2024) ✓ × × × MetaAligner (Yang et al., 2024a) Policy), eliminating…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and models. There are no clear identifiers for datasets within the text.",
      "processing_time": 54.364686489105225,
      "citing_paper_id": "273185508",
      "cited_paper_id": 260333927
    },
    {
      "context_text": "DeAL (Huang et al., 2024) focusing on heuristic-guided searches to better meet diverse alignment objectives.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DeAL) and its application. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 54.79443860054016,
      "citing_paper_id": "273185508",
      "cited_paper_id": 261076203
    },
    {
      "context_text": "DeAL (Huang et al., 2024) focusing on heuristic-guided searches to better meet diverse alignment objectives.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DeAL) and its application. The cited paper titles do not provide additional information about datasets.",
      "processing_time": 54.79443860054016,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270357470
    },
    {
      "context_text": "In short, we need AI systems that are pluralistic and fair, being capable of reflecting diverse human values (Sorensen et al.; Hwang et al., 2023a; Kirk et al., 2024; Sorensen et al., 2024a; Chen et al., 2024d;c;b; Fan et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing AI fairness and debiasing. No verifiable resources are identified.",
      "processing_time": 54.535135984420776,
      "citing_paper_id": "273185508",
      "cited_paper_id": 261531157
    },
    {
      "context_text": "In short, we need AI systems that are pluralistic and fair, being capable of reflecting diverse human values (Sorensen et al.; Hwang et al., 2023a; Kirk et al., 2024; Sorensen et al., 2024a; Chen et al., 2024d;c;b; Fan et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing AI fairness and debiasing. No verifiable resources are identified.",
      "processing_time": 54.535135984420776,
      "citing_paper_id": "273185508",
      "cited_paper_id": 264306285
    },
    {
      "context_text": "In short, we need AI systems that are pluralistic and fair, being capable of reflecting diverse human values (Sorensen et al.; Hwang et al., 2023a; Kirk et al., 2024; Sorensen et al., 2024a; Chen et al., 2024d;c;b; Fan et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to papers discussing AI fairness and debiasing. No verifiable resources are identified.",
      "processing_time": 54.535135984420776,
      "citing_paper_id": "273185508",
      "cited_paper_id": 271213154
    },
    {
      "context_text": "As humans exhibit diverse preferences and values for a single task, it is essential to align large language models (LLMs) to users’ personalized preferences (Kirk et al., 2023; Sorensen et al., 2023; 2024c; Yao et al., 2023; Kirk et al., 2024; Zhong et al., 2024; Han et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. There are no clear identifiers for datasets, and the context focuses on the importance of aligning LLMs with personalized preferences.",
      "processing_time": 55.375767946243286,
      "citing_paper_id": "273185508",
      "cited_paper_id": 263834741
    },
    {
      "context_text": "As humans exhibit diverse preferences and values for a single task, it is essential to align large language models (LLMs) to users’ personalized preferences (Kirk et al., 2023; Sorensen et al., 2023; 2024c; Yao et al., 2023; Kirk et al., 2024; Zhong et al., 2024; Han et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to research works. There are no clear identifiers for datasets, and the context focuses on the importance of aligning LLMs with personalized preferences.",
      "processing_time": 55.375767946243286,
      "citing_paper_id": "273185508",
      "cited_paper_id": null
    },
    {
      "context_text": "Controlled Decoding (CD) (Mudgal et al., 2023) utilizes a prefix scorer module trained to assess value functions for rewards, allowing controlled generation from a frozen base model.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called Controlled Decoding. The context focuses on the methodology and its application, not on any particular dataset.",
      "processing_time": 54.64330768585205,
      "citing_paper_id": "273185508",
      "cited_paper_id": 264491118
    },
    {
      "context_text": "Diversity Score (Khanov et al., 2024): This metric compiles the rates of n-gram repetition.",
      "catation_intent": "none",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a metric called 'Diversity Score'. The metric is not a dataset and does not qualify as a reusable resource.",
      "processing_time": 54.49877095222473,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267411977
    },
    {
      "context_text": "As Args is originally designed for general preference, we use ArmoRM (Wang et al., 2024b) to provide rewards.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'ArmoRM' which is likely a method or model rather than a dataset. No other specific datasets are mentioned.",
      "processing_time": 54.03437376022339,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267411977
    },
    {
      "context_text": "As Args is originally designed for general preference, we use ArmoRM (Wang et al., 2024b) to provide rewards.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'ArmoRM' which is likely a method or model rather than a dataset. No other specific datasets are mentioned.",
      "processing_time": 54.03437376022339,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270562658
    },
    {
      "context_text": "Furthermore, our evaluation leverages GPT-4, a widely recognized tool in previous studies (Khanov et al., 2024; Yang et al., 2024a), to conduct the judgments towards certain personalized preference and report the win rate.",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of GPT-4 as a tool for evaluation. No verifiable datasets are referenced.",
      "processing_time": 54.37086510658264,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267411977
    },
    {
      "context_text": "Implementation details for different baselines are as follows: • • Args: We reproduce Args according to https://github.com/deeplearning-wisc/ args/tree/main by replacing the reward model with ArmoRM (Wang et al., 2024b).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Args) and a reward model (ArmoRM). No verifiable resources are identified.",
      "processing_time": 54.45206904411316,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267411977
    },
    {
      "context_text": "Implementation details for different baselines are as follows: • • Args: We reproduce Args according to https://github.com/deeplearning-wisc/ args/tree/main by replacing the reward model with ArmoRM (Wang et al., 2024b).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Args) and a reward model (ArmoRM). No verifiable resources are identified.",
      "processing_time": 54.45206904411316,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270562658
    },
    {
      "context_text": "Args (Khanov et al., 2024) is a reward-guided decoding-time alignment framework.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method called 'ARGS'. The cited paper title confirms that ARGS is a method, not a dataset.",
      "processing_time": 54.223905086517334,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267411977
    },
    {
      "context_text": "ARGS (Khanov et al., 2024) proposed using a reward signal to adjust probabilistic predictions, thereby generating semantically aligned texts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for generating semantically aligned texts.",
      "processing_time": 53.17022132873535,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267411977
    },
    {
      "context_text": "…(Jang et al., 2023) ✓ ✓ - ✓ Rewarded soups (Rame et al., 2024) × × × × RiC (Yang et al., 2024b) × ✓ × × DPA (Wang et al., 2024a) × ✓ ✓ × Args (Khanov et al., 2024) ✓ ✓ × × MOD (Shi et al., 2024) ✓ × × × MetaAligner (Yang et al., 2024a) Policy), eliminating the need for training additional…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only methods and tools. The title 'ARGS: Alignment as Reward-Guided Search' confirms that ARGS is a method, not a dataset.",
      "processing_time": 54.86834669113159,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267411977
    },
    {
      "context_text": "GPT-4 Evaluation Details We follow (Khanov et al., 2024) for the usage of GPT-4 in our evaluation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the usage of GPT-4. There are no verifiable resources or datasets mentioned in the context.",
      "processing_time": 54.15498375892639,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267411977
    },
    {
      "context_text": "Decoding-time alignment offers an alignment paradigm that does not require expensive RL training (Han et al., 2024; Liu et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to papers discussing alignment paradigms.",
      "processing_time": 53.1971549987793,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267547503
    },
    {
      "context_text": "…- × Personalized soups (Jang et al., 2023) × × × × Preference Prompting (Jang et al., 2023) ✓ ✓ - ✓ Rewarded soups (Rame et al., 2024) × × × × RiC (Yang et al., 2024b) × ✓ × × DPA (Wang et al., 2024a) × ✓ ✓ × Args (Khanov et al., 2024) ✓ ✓ × × MOD (Shi et al., 2024) ✓ × × × MetaAligner (Yang et…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various methods and models. No verifiable resources are identified.",
      "processing_time": 53.464956521987915,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267682397
    },
    {
      "context_text": "In our evaluation setup, we initially focus on alignment the three pre-defined dimensions: “harmless”, “helpful”, and “humor”, following previous works (Yang et al., 2024b;a; Shi et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only pre-defined dimensions for evaluation. The context focuses on methodological aspects rather than data sources.",
      "processing_time": 53.9186372756958,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267682397
    },
    {
      "context_text": "In our evaluation setup, we initially focus on alignment the three pre-defined dimensions: “harmless”, “helpful”, and “humor”, following previous works (Yang et al., 2024b;a; Shi et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only pre-defined dimensions for evaluation. The context focuses on methodological aspects rather than data sources.",
      "processing_time": 53.9186372756958,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270764846
    },
    {
      "context_text": "• Personalized Soups: We reproduce Personalized Soups according to https://github. com/joeljang/RLPHF by replacing the prompt with “harmless”,“helpful”, and “humor” dimensions, and change the reward model as in RiC.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a GitHub repository and a method (RiC). The 'Personalized Soups' is a method or model, not a dataset.",
      "processing_time": 54.80061388015747,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267682397
    },
    {
      "context_text": "During the development of our personalized reward model, we utilized datasets from multiple sources including Ultrafeedback (Cui et al., 2023), HelpSteer2 (Wang et al., 2024c), Rewards-in-Context (Yang et al., 2024b), and SafeRLHF (Dai et al., 2023).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Ultrafeedback",
        "HelpSteer2",
        "Rewards-in-Context",
        "SafeRLHF"
      ],
      "dataset_descriptions": {
        "Ultrafeedback": "Used to develop a personalized reward model, focusing on user feedback for dynamic preference adjustment.",
        "HelpSteer": "Used to evaluate the effectiveness of personalized text generation methods in steering user behavior towards desired outcomes.",
        "Rewards-in-Context": "Utilized to align foundation models with dynamic preferences, enhancing multi-objective alignment in personalized reward systems.",
        "SafeRLHF": "Employed to ensure safety and reliability in reinforcement learning for human feedback, supporting the development of robust personalized reward models."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions specific datasets used for developing a personalized reward model, which are clearly named and relevant to the research topic.",
      "processing_time": 59.823822259902954,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267682397
    },
    {
      "context_text": "Rewards-in-Context (RiC) (Yang et al., 2024b) conditions foundation model responses on multiple rewards in its prompt and uses supervised fine-tuning for alignment.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method called 'Rewards-in-Context (RiC)'. The method is described as conditioning foundation model responses on multiple rewards and using supervised fine-tuning for alignment.",
      "processing_time": 55.337461709976196,
      "citing_paper_id": "273185508",
      "cited_paper_id": 267682397
    },
    {
      "context_text": "Rewards-in-Context (RiC) (Yang et al., 2024b) conditions foundation model responses on multiple rewards in its prompt and uses supervised fine-tuning for alignment.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method called 'Rewards-in-Context (RiC)'. The method is described as conditioning foundation model responses on multiple rewards and using supervised fine-tuning for alignment.",
      "processing_time": 55.337461709976196,
      "citing_paper_id": "273185508",
      "cited_paper_id": null
    },
    {
      "context_text": "Additionally, we employ the ArmoRM (Wang et al., 2024b), a multi-dimension reward model known for its state-of-the-art performance on the Reward-Bench benchmark (Lambert et al., 2024).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Reward-Bench' as a benchmark, which is excluded as per instructions. No other specific datasets are mentioned.",
      "processing_time": 53.85228109359741,
      "citing_paper_id": "273185508",
      "cited_paper_id": 268537409
    },
    {
      "context_text": "Additionally, we employ the ArmoRM (Wang et al., 2024b), a multi-dimension reward model known for its state-of-the-art performance on the Reward-Bench benchmark (Lambert et al., 2024).",
      "catation_intent": "reusable resource",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Reward-Bench' as a benchmark, which is excluded as per instructions. No other specific datasets are mentioned.",
      "processing_time": 53.85228109359741,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270562658
    },
    {
      "context_text": "The derivation is inspired by Rafailov et al. (2024a) and Zhou et al. (2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There are no clear identifiers for datasets, and the context is focused on methods and approaches rather than data sources.",
      "processing_time": 54.73068284988403,
      "citing_paper_id": "273185508",
      "cited_paper_id": 269214194
    },
    {
      "context_text": "The derivation is inspired by Rafailov et al. (2024a) and Zhou et al. (2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to other works. There are no clear identifiers for datasets, and the context is focused on methods and approaches rather than data sources.",
      "processing_time": 54.73068284988403,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270095324
    },
    {
      "context_text": "For personalized alignment, we primarily utilize LLama-3-8B-SFT (AI@Meta, 2024; Meng et al., 2024) as the base language model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a language model (LLama-3-8B-SFT) but does not reference any specific datasets. The context is focused on the use of the model for personalized alignment.",
      "processing_time": 54.66710567474365,
      "citing_paper_id": "273185508",
      "cited_paper_id": 269983560
    },
    {
      "context_text": "As for ArmoRM, utilize dimension “0” and “10” for “helpful” and “harmless”.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only dimensions within a model. There are no verifiable resources or datasets mentioned.",
      "processing_time": 53.332173585891724,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270562658
    },
    {
      "context_text": "MOD (Shi et al., 2024) first trains multiple specializing networks and performs linear combination of their predictions.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method involving training multiple specializing networks.",
      "processing_time": 52.89339828491211,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270764846
    },
    {
      "context_text": "However, MOD still requires training base models for different preferences, making it difficult to scale to a large number of personalized preferences.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general challenge in scaling personalized preferences.",
      "processing_time": 52.44338583946228,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270764846
    },
    {
      "context_text": "…✓ - ✓ Rewarded soups (Rame et al., 2024) × × × × RiC (Yang et al., 2024b) × ✓ × × DPA (Wang et al., 2024a) × ✓ ✓ × Args (Khanov et al., 2024) ✓ ✓ × × MOD (Shi et al., 2024) ✓ × × × MetaAligner (Yang et al., 2024a) Policy), eliminating the need for training additional policy models (Training-free).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 53.57491421699524,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270764846
    },
    {
      "context_text": "Additionally, some approaches involve merging model parameters or predictions trained for each dimension to accommodate the diverse combinations expressed by those dimensions (Jang et al., 2023; Rame et al., 2024; Park et al., 2024; Shi et al., 2024).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to methods and approaches. There are no clear identifiers for datasets or other verifiable resources.",
      "processing_time": 53.73155331611633,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270764846
    },
    {
      "context_text": "MODPO (Zhou et al., 2023) integrates language modeling with reward modeling, training models to combine all objectives with specific weights.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (MODPO) that integrates language modeling with reward modeling. No verifiable datasets are referenced.",
      "processing_time": 53.88778018951416,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270764846
    },
    {
      "context_text": "The work most similar to ours is MOD (Shi et al., 2024), which achieves flexible trade-offs and optimization across multiple objectives by linearly combining predictions from different policy models at decoding time to output the next token.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (MOD) and its application in language model alignment. No verifiable resources are identified.",
      "processing_time": 53.72598886489868,
      "citing_paper_id": "273185508",
      "cited_paper_id": 270764846
    },
    {
      "context_text": "Additional experiments are conducted on Gemma (Team, 2024), Mistral-7B-SFT (Jiang et al., 2023; Tunstall et al., 2023), and Llama-2 (Touvron et al., 2023) to test scalability.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models and methods rather than datasets. No specific datasets are identified or used according to the context.",
      "processing_time": 53.06100535392761,
      "citing_paper_id": "273185508",
      "cited_paper_id": null
    },
    {
      "context_text": "Additional experiments are conducted on Gemma (Team, 2024), Mistral-7B-SFT (Jiang et al., 2023; Tunstall et al., 2023), and Llama-2 (Touvron et al., 2023) to test scalability.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions models and methods rather than datasets. No specific datasets are identified or used according to the context.",
      "processing_time": 53.06100535392761,
      "citing_paper_id": "273185508",
      "cited_paper_id": null
    },
    {
      "context_text": "We employ the Llama-3-8B model (AI@Meta, 2024) as our backbone, and append a linear layer directly following the embeddings, featuring an output dimension of 4096.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions a model (Llama-3-8B) but does not reference any specific datasets. The focus is on the model architecture and modifications.",
      "processing_time": 53.790547609329224,
      "citing_paper_id": "273185508",
      "cited_paper_id": null
    },
    {
      "context_text": "Since patients are increasingly encouraged to have an active role in treatment decision making (Pieterse et al., 2008), patients need to be accurately informed about their treatment options.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general statement about patient involvement in treatment decisions.",
      "processing_time": 52.79459238052368,
      "citing_paper_id": "209335890",
      "cited_paper_id": 511247
    },
    {
      "context_text": "As Mahamood and Reiter (2012) point out, involving clinicians in an early stage of the development of NLG systems can “signiﬁcantly enhance the quality of many NLG systems” (p.100).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general statement about involving clinicians in NLG system development.",
      "processing_time": 52.9644410610199,
      "citing_paper_id": "209335890",
      "cited_paper_id": 947719
    },
    {
      "context_text": "Earlier evaluation studies of NLG-systems, such as Mahamood and Reiter (2011), showed that all patients – regardless of their stress level – prefer affective texts over neutral ones.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a preference for affective texts over neutral ones in NLG systems.",
      "processing_time": 53.13140559196472,
      "citing_paper_id": "209335890",
      "cited_paper_id": 947719
    },
    {
      "context_text": "The module selection framework is based on van der Lee et al. (2017) who developed a system called ‘PASS’.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions 'PASS' but does not refer to it as a dataset. It is described as a system, which is likely a method or tool rather than a dataset.",
      "processing_time": 54.092262983322144,
      "citing_paper_id": "209335890",
      "cited_paper_id": 2364329
    },
    {
      "context_text": "For the development of this tool, we build on the PASS data-to-text system (van der Lee et al., 2017), which was originally developed for the tailored generation of soccer reports.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions the PASS data-to-text system, but it is described as a method or tool rather than a dataset. No specific dataset is mentioned.",
      "processing_time": 53.50828981399536,
      "citing_paper_id": "209335890",
      "cited_paper_id": 2364329
    },
    {
      "context_text": "As van der Lee et al. (2017) argue, a major advantage of such a modular approach is the ﬂexibil-ity of such a system.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a modular approach in a data-to-text system.",
      "processing_time": 52.68261766433716,
      "citing_paper_id": "209335890",
      "cited_paper_id": 2364329
    },
    {
      "context_text": "Partly because of this, patients want to be involved in treatment decision making (Shay and Elston Lafata, 2015).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to a review of shared decision making and patient outcomes, which is not a dataset.",
      "processing_time": 53.745203256607056,
      "citing_paper_id": "209335890",
      "cited_paper_id": 4581300
    },
    {
      "context_text": "Next to information on incidence and survival, patients also want to consider how a treatment is going to affect their quality of life (QoL) (Zafar et al., 2009).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general statement about patient considerations regarding quality of life in cancer treatment.",
      "processing_time": 52.940425634384155,
      "citing_paper_id": "209335890",
      "cited_paper_id": 9257319
    },
    {
      "context_text": "A recent systematic review concluded that “[...] people exposed to decision aids feel more knowledgeable, better informed, and clearer about their values, and they probably have a more active role in decision making and more accurate risk per-ceptions” (Stacey et al., 2017).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only findings from a systematic review. The context is about the impact of decision aids on patient decision-making, which does not involve the use of a specific dataset.",
      "processing_time": 54.21093416213989,
      "citing_paper_id": "209335890",
      "cited_paper_id": 10838471
    },
    {
      "context_text": "The ﬁrst is a registry data set called “PRO-FILES” (Patient Reported Outcomes Following Initial treatment and Long term Evaluation of Sur-vivorship (van de Poll-Franse et al., 2011).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PRO-FILES"
      ],
      "dataset_descriptions": {
        "PRO-FILES": "Used to collect patient-reported outcomes following initial treatment and long-term evaluation of survivorship, focusing on the scope, rationale, and design of the dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific registry dataset called 'PRO-FILES', which is clearly identified and referenced in the cited paper titles.",
      "processing_time": 55.75236392021179,
      "citing_paper_id": "209335890",
      "cited_paper_id": 12016582
    },
    {
      "context_text": "The ﬁrst is a registry data set called “PRO-FILES” (Patient Reported Outcomes Following Initial treatment and Long term Evaluation of Sur-vivorship (van de Poll-Franse et al., 2011).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PRO-FILES"
      ],
      "dataset_descriptions": {
        "PRO-FILES": "Used to collect patient-reported outcomes following initial treatment and long-term evaluation of survivorship, focusing on the scope, rationale, and design of the dataset."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions a specific registry dataset called 'PRO-FILES', which is clearly identified and referenced in the cited paper titles.",
      "processing_time": 55.75236392021179,
      "citing_paper_id": "209335890",
      "cited_paper_id": 24512760
    },
    {
      "context_text": "The information on QoL outcomes of patients is based on a representative sample of colorectal cancer survivors in the Netherlands (van de Poll-Franse et al., 2011) and all clinical information is registry based data from the NCR.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'registry based data from the NCR', which is a specific data source. However, the name 'NCR' is not sufficiently specific or well-known to be considered a verifiable dataset without further context.",
      "processing_time": 54.49737787246704,
      "citing_paper_id": "209335890",
      "cited_paper_id": 12016582
    },
    {
      "context_text": "The information on QoL outcomes of patients is based on a representative sample of colorectal cancer survivors in the Netherlands (van de Poll-Franse et al., 2011) and all clinical information is registry based data from the NCR.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'registry based data from the NCR', which is a specific data source. However, the name 'NCR' is not sufficiently specific or well-known to be considered a verifiable dataset without further context.",
      "processing_time": 54.49737787246704,
      "citing_paper_id": "209335890",
      "cited_paper_id": 24512760
    },
    {
      "context_text": "…have a strong preference for the presentation of statistical information (e.g. Brundage et al. (2005)), but studies also show that patients vary in their preferences (e.g. Hagerty et al. (2004)), the current system could help investigate which patterns underlie these statistical preferences.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general studies. There are no clear identifiers for datasets, corpora, or other verifiable resources.",
      "processing_time": 53.44997215270996,
      "citing_paper_id": "209335890",
      "cited_paper_id": 22553740
    },
    {
      "context_text": "However, this information is often not communicated to the patient, or is generic and difﬁcult to understand (Brundage et al., 2005).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to a study about communication of quality of life information to cancer patients.",
      "processing_time": 53.28344941139221,
      "citing_paper_id": "209335890",
      "cited_paper_id": 32041197
    },
    {
      "context_text": "Since research has shown that patients have a strong preference for the presentation of statistical information (e.g. Brundage et al. (2005)), but studies also show that patients vary in their preferences (e.g. Hagerty et al. (2004)), the current system could help investigate which patterns…",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general studies and patient preferences. No clear, verifiable resources are identified.",
      "processing_time": 52.8779559135437,
      "citing_paper_id": "209335890",
      "cited_paper_id": 32041197
    },
    {
      "context_text": "Some research indicates that “the framing effect” occurs when delivering messages (Akl et al., 2011).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general concept of 'framing effect'. No verifiable resources are identified.",
      "processing_time": 52.954888343811035,
      "citing_paper_id": "209335890",
      "cited_paper_id": 37693837
    },
    {
      "context_text": "Natural language generation (NLG) techniques can tackle these problems, and are therefore increasingly used in the health domain (Di Eugenio and Green, 2010; Pauws et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of NLG in the health domain. No verifiable resources are identified.",
      "processing_time": 53.11291551589966,
      "citing_paper_id": "209335890",
      "cited_paper_id": 46571650
    },
    {
      "context_text": "Natural language generation (NLG) techniques can tackle these problems, and are therefore increasingly used in the health domain (Di Eugenio and Green, 2010; Pauws et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of NLG in the health domain. No verifiable resources are identified.",
      "processing_time": 53.11291551589966,
      "citing_paper_id": "209335890",
      "cited_paper_id": 51966859
    },
    {
      "context_text": "Data-to-text generation systems are increasingly used in the health domain (Pauws et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general application of data-to-text generation in healthcare.",
      "processing_time": 52.6245756149292,
      "citing_paper_id": "209335890",
      "cited_paper_id": 51966859
    },
    {
      "context_text": "They can, for example, be used for automation of health reports, clinical decision support, encourage behavioural change, ensure patient engagement or assist patients with making health decisions (Pauws et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of data-to-text technology in healthcare.",
      "processing_time": 52.43816089630127,
      "citing_paper_id": "209335890",
      "cited_paper_id": 51966859
    },
    {
      "context_text": "Personalizing health information manually is time consuming, costly and the outputs are often inconsistent (Pauws et al., 2019).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general statement about personalizing health information.",
      "processing_time": 52.35134673118591,
      "citing_paper_id": "209335890",
      "cited_paper_id": 51966859
    },
    {
      "context_text": "Although it may seem evident that patients need information based on their own personal information, most patient education materials or decision aids are not tailored towards speciﬁc patient outcomes (Vromans et al., 2019a,b).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general statements about patient education materials and decision aids.",
      "processing_time": 52.27247452735901,
      "citing_paper_id": "209335890",
      "cited_paper_id": 145023057
    },
    {
      "context_text": "Building on an analysis of existing decision aids (Vromans et al., 2019a,b), templates were deﬁned with different framing policies relating to different outcome scenarios.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a review of decision aids. No verifiable resources are identified.",
      "processing_time": 52.592844009399414,
      "citing_paper_id": "209335890",
      "cited_paper_id": 145023057
    },
    {
      "context_text": "Furthermore, decision support tools in current practice are very static because they almost never take into account personalized information from the patient (Vromans et al., 2019a,b).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to personalized information from patients.",
      "processing_time": 52.261672258377075,
      "citing_paper_id": "209335890",
      "cited_paper_id": 145023057
    },
    {
      "context_text": "Vromans et al. (2019a,b) looked at the content and communication styles of such decision aids in more detail.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a review of decision aids. No clear, verifiable resource is identified.",
      "processing_time": 52.74528193473816,
      "citing_paper_id": "209335890",
      "cited_paper_id": 145023057
    },
    {
      "context_text": "At the same time, survival rates are improving (Mols et al., 2013).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to survival rates. The cited paper title mentions the PROFILES registry, but it is not explicitly used in the citation context.",
      "processing_time": 53.44242596626282,
      "citing_paper_id": "209335890",
      "cited_paper_id": 207034961
    },
    {
      "context_text": "The questionnaire-based data are acquired via the European Organisation for Research and Treatment of Cancer (EORTC) Quality of Life Questionnaire (QLQ) C30 (version 3.0) which assesses health-related quality of life (HRQOL) (Mols et al., 2013).",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 11 column 1 (char 642), response: ```json\n{\n    \"reasoning\": \"The context mentions the EORTC QLQ C30 (version 3.0) as a specific quest",
      "processing_time": 63.83172631263733,
      "citing_paper_id": "209335890",
      "cited_paper_id": 207034961
    },
    {
      "context_text": "Since survival rates for colorectal cancer patients are increasing (Mols et al., 2013), the relevance of QoL becomes more prominent and patients are more likely to consider, for example, how treatments will impact their social life, ability to go to work, or emotional well-being.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "PROFILES registry"
      ],
      "dataset_descriptions": {
        "PROFILES registry": "Mentioned as a source of data on chemotherapy-induced neuropathy and quality of life in colorectal cancer survivors, but specific usage details are not provided."
      },
      "confidence_score": 0.6,
      "reasoning": "The citation mentions the PROFILES registry, which is a specific, verifiable dataset. However, the context does not describe how the dataset is used in the research.",
      "processing_time": 55.53441643714905,
      "citing_paper_id": "209335890",
      "cited_paper_id": 207034961
    },
    {
      "context_text": "Additionally, Gkatzia et al. (2014) use NLG techniques to generate textual summaries of medical sensory data and personalize the presentation format of these summaries.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions the use of NLG techniques for generating personalized textual summaries of medical sensory data, but does not specify a dataset name. The title suggests a corpus study, but no specific dataset name is provided in the context.",
      "processing_time": 54.16380834579468,
      "citing_paper_id": "209335890",
      "cited_paper_id": 207821484
    },
    {
      "context_text": "Gigerenzer et al. (2007) even state that there is a “collective statistical illiter-acy” (p.53).",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to a general statement about statistical literacy.",
      "processing_time": 52.81187129020691,
      "citing_paper_id": "209335890",
      "cited_paper_id": 261601645
    },
    {
      "context_text": "Figure 1: The support tool within the three-talk shared decision model (Elwyn et al., 2017). lands alone (KWF Kankerbestrijding, 2019).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It refers to a figure from a paper and a reference to a cancer organization, neither of which are datasets.",
      "processing_time": 53.63771414756775,
      "citing_paper_id": "209335890",
      "cited_paper_id": null
    },
    {
      "context_text": "We consider a real world dataset from Amazon Electronics (McAuley et al., 2015) to evaluate our model.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Amazon Electronics"
      ],
      "dataset_descriptions": {
        "Amazon Electronics": "Used to evaluate the model on real-world data, focusing on personalized recommendations for electronic products, using the dataset to study personalized text generation."
      },
      "confidence_score": 0.9,
      "reasoning": "The context mentions a specific dataset from Amazon Electronics, which is used to evaluate the model. The dataset is clearly identified and relevant to the research topic of personalized text generation.",
      "processing_time": 55.5249400138855,
      "citing_paper_id": "29161455",
      "cited_paper_id": 1012652
    },
    {
      "context_text": "For the sequence encoder, the attention vector is defined as in many other applications (Bahdanau et al., 2014; Luong et al., 2015):",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods for attention mechanisms in neural machine translation.",
      "processing_time": 52.03302502632141,
      "citing_paper_id": "29161455",
      "cited_paper_id": 1998416
    },
    {
      "context_text": "For the sequence encoder, the attention vector is deﬁned as in many other applications (Bahdanau et al., 2014; Luong et al., 2015): α 1 tj e j (7) where a 1 t ∈ R n is the attention vector on the sequence encoder at time-step t , α 1 tj is the attention score over the encoder hidden state e j and…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers are about attention mechanisms in neural machine translation, which do not introduce specific datasets.",
      "processing_time": 53.13883137702942,
      "citing_paper_id": "29161455",
      "cited_paper_id": 1998416
    },
    {
      "context_text": "Inspired by the copy mechanism (Gu et al., 2016; See et al., 2017), we design an attention vector that estimates the probability that each aspect will be discussed in the next time-step: where s ui ∈ R k is the aspect importance considering the interaction between u and i , e t is the de-coder…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (copy mechanism) used in sequence-to-sequence learning.",
      "processing_time": 52.512760400772095,
      "citing_paper_id": "29161455",
      "cited_paper_id": 8174613
    },
    {
      "context_text": "Inspired by the copy mechanism (Gu et al., 2016; See et al., 2017), we design an attention vector that estimates the probability that each aspect will be discussed in the next time-step:",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers are about copying mechanisms and summarization techniques, which do not introduce specific datasets.",
      "processing_time": 53.20708107948303,
      "citing_paper_id": "29161455",
      "cited_paper_id": 8174613
    },
    {
      "context_text": "Inspired by the copy mechanism (Gu et al., 2016; See et al., 2017), we design an attention vector that estimates the probability that each aspect will be discussed in the next time-step:",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers are about copying mechanisms and summarization techniques, which do not introduce specific datasets.",
      "processing_time": 53.20708107948303,
      "citing_paper_id": "29161455",
      "cited_paper_id": 8314118
    },
    {
      "context_text": "…encoder, and α2tj is the attention score between the attribute latent factor γj and decoder hidden state ht.\nInspired by the copy mechanism (Gu et al., 2016; See et al., 2017), we design an attention vector that estimates the probability that each aspect will be discussed in the next…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and mechanisms. The context focuses on the attention mechanism and copy mechanism in neural networks.",
      "processing_time": 52.98170757293701,
      "citing_paper_id": "29161455",
      "cited_paper_id": 8314118
    },
    {
      "context_text": "…to a large body of work on data-to-text natural language generation (Gatt and Krahmer, 2017), which has applications including summarization (See et al., 2017), image captioning (Vinyals et al., 2015), and dialogue response generation (Xing et al., 2017; Li et al., 2016; Ghosh et al.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of data-to-text natural language generation. No specific, verifiable datasets are named.",
      "processing_time": 53.05069136619568,
      "citing_paper_id": "29161455",
      "cited_paper_id": 8314118
    },
    {
      "context_text": "Review generation belongs to a large body of work on data-to-text natural language generation (Gatt and Krahmer, 2017), which has applications including summarization (See et al., 2017), image captioning (Vinyals et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only general applications of data-to-text natural language generation.",
      "processing_time": 52.259939432144165,
      "citing_paper_id": "29161455",
      "cited_paper_id": 8314118
    },
    {
      "context_text": "Contextual, or ‘data-to-text’ natural language generation is one of the core tasks in natural language processing and has a considerable impact on various fields (Gatt and Krahmer, 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to the field of natural language generation.",
      "processing_time": 52.23200011253357,
      "citing_paper_id": "29161455",
      "cited_paper_id": 16946362
    },
    {
      "context_text": "Review generation belongs to a large body of work on data-to-text natural language generation (Gatt and Krahmer, 2017), which has applications including summarization (See et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to data-to-text natural language generation. No verifiable resources are identified.",
      "processing_time": 52.779558420181274,
      "citing_paper_id": "29161455",
      "cited_paper_id": 16946362
    },
    {
      "context_text": "Review generation belongs to a large body of work on data-to-text natural language generation (Gatt and Krahmer, 2017), which has applications including summarization (See et al., 2017), image captioning (Vinyals et al., 2015), and dialogue response generation (Xing et al., 2017; Li et al., 2016;…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of data-to-text natural language generation. No verifiable resources are identified.",
      "processing_time": 52.8508198261261,
      "citing_paper_id": "29161455",
      "cited_paper_id": 16946362
    },
    {
      "context_text": "Contextual, or ‘data-to-text’ natural language generation is one of the core tasks in natural language processing and has a considerable impact on various ﬁelds (Gatt and Krahmer, 2017).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to the field of natural language generation.",
      "processing_time": 52.30009913444519,
      "citing_paper_id": "29161455",
      "cited_paper_id": 16946362
    },
    {
      "context_text": "Research on automatic text summarization began more than five decades ago with the earlier works of Edmundson [1].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a historical reference to early work in automatic text summarization.",
      "processing_time": 52.376721143722534,
      "citing_paper_id": "247060002",
      "cited_paper_id": 1177942
    },
    {
      "context_text": "Research on automatic summarization began with the work of Luhn [11] and Edmundson [1].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to early works in automatic summarization. No verifiable resources are identified.",
      "processing_time": 52.84321737289429,
      "citing_paper_id": "247060002",
      "cited_paper_id": 1177942
    },
    {
      "context_text": "Research on automatic summarization began with the work of Luhn [11] and Edmundson [1].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to early works in automatic summarization. No verifiable resources are identified.",
      "processing_time": 52.84321737289429,
      "citing_paper_id": "247060002",
      "cited_paper_id": 15879823
    },
    {
      "context_text": "…several approaches for automatic text summarization can be found in literature; for example, statistical learning [13], machine learning [14, 15], text connectivity [16, 17], conceptual graphs [7, 18], algebraic reduction [19], clustering and probabilistic models [20] and reader-adaptive…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods for text summarization. There are no clear identifiers for datasets.",
      "processing_time": 52.913140296936035,
      "citing_paper_id": "247060002",
      "cited_paper_id": 7992772
    },
    {
      "context_text": "…approaches for automatic text summarization can be found in literature; for example, statistical learning [13], machine learning [14, 15], text connectivity [16, 17], conceptual graphs [7, 18], algebraic reduction [19], clustering and probabilistic models [20] and reader-adaptive methods [21].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods for automatic text summarization.",
      "processing_time": 52.36989760398865,
      "citing_paper_id": "247060002",
      "cited_paper_id": 9938081
    },
    {
      "context_text": "…approaches for automatic text summarization can be found in literature; for example, statistical learning [13], machine learning [14, 15], text connectivity [16, 17], conceptual graphs [7, 18], algebraic reduction [19], clustering and probabilistic models [20] and reader-adaptive methods [21].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various approaches and methods for automatic text summarization.",
      "processing_time": 52.36989760398865,
      "citing_paper_id": "247060002",
      "cited_paper_id": 13083632
    },
    {
      "context_text": "To evaluate our proposal, the automatic generation of extractive summaries, we conducted a study based on the Turing Test [35] as proposed by Molina and Torres [36].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Turing Test) for evaluating the system.",
      "processing_time": 52.24683952331543,
      "citing_paper_id": "247060002",
      "cited_paper_id": 14636783
    },
    {
      "context_text": "This experiment consisted of evaluating the quality of the summaries based on the Turing test [35] and consists of having a group of human judges, which must identify the origin, human or automatic, of a series of summaries.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for evaluating summaries using a Turing test.",
      "processing_time": 52.008888483047485,
      "citing_paper_id": "247060002",
      "cited_paper_id": 14636783
    },
    {
      "context_text": "These heuristics are based on the work of Acero and colleagues [22].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a reference to the work of Acero and colleagues. The title 'Generación automática de resümenes personalizados' suggests the work is about personalized summary generation, but no datasets are explicitly mentioned.",
      "processing_time": 54.09065365791321,
      "citing_paper_id": "247060002",
      "cited_paper_id": 41140640
    },
    {
      "context_text": "Several learning styles models have been proposed, such as the Felder-Silverman Learning Styles Model [31], Kolb Model [32] and the VAK Model [9] among others.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several learning styles models but does not refer to any specific datasets. The context is about describing different models rather than using datasets.",
      "processing_time": 52.623796701431274,
      "citing_paper_id": "247060002",
      "cited_paper_id": 146755699
    },
    {
      "context_text": "Several learning styles models have been proposed, such as the Felder-Silverman Learning Styles Model [31], Kolb Model [32] and the VAK Model [9] among others.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions several learning styles models but does not refer to any specific datasets. The context is about describing different models rather than using datasets.",
      "processing_time": 52.623796701431274,
      "citing_paper_id": "247060002",
      "cited_paper_id": null
    },
    {
      "context_text": "The Kolb Model works on two levels: a four-stage cycle of learning and four separate learning styles: diverging, assimilating, converging, and accommodating.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific, verifiable datasets. It describes the Kolb Model, which is a method or theory, not a dataset.",
      "processing_time": 52.69264602661133,
      "citing_paper_id": "247060002",
      "cited_paper_id": 146755699
    },
    {
      "context_text": "In this way, sentences are obtained that, in principle, were not in the source text [5, 6, 7, 8].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only refers to a general process of obtaining sentences not present in the source text.",
      "processing_time": 52.74654030799866,
      "citing_paper_id": "247060002",
      "cited_paper_id": null
    },
    {
      "context_text": "The participants filled in the Neurolinguistics Programming Test [34], thus we can know their VAK learning style.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a test but does not refer to a specific, verifiable dataset. The Neurolinguistics Programming Test is likely a method or tool rather than a dataset.",
      "processing_time": 52.74267363548279,
      "citing_paper_id": "247060002",
      "cited_paper_id": null
    },
    {
      "context_text": "The student model contains a representation of the state of the users including their VAK learning style obtained from the Neurolinguistics Programming Test [34].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions a test but does not specify a dataset. The Neurolinguistics Programming Test is likely a method or tool rather than a dataset.",
      "processing_time": 52.68272948265076,
      "citing_paper_id": "247060002",
      "cited_paper_id": null
    },
    {
      "context_text": "In this research work, Neurolinguistics Programming Model of Bandler and Grinder [9] was used; this model is also called VAK model for the learning styles it includes: Visual, Auditory and Kinesthetic.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a model (Neurolinguistics Programming Model/VAK model).",
      "processing_time": 52.38201880455017,
      "citing_paper_id": "247060002",
      "cited_paper_id": null
    },
    {
      "context_text": "The collection of VAK words is composed of words related with each one of the VAK learning styles as proposed by Bandler and Grinder [9].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable dataset. It only refers to a collection of VAK words, which is not a named, specific dataset.",
      "processing_time": 52.79292058944702,
      "citing_paper_id": "247060002",
      "cited_paper_id": null
    },
    {
      "context_text": "Recently, transfer learning based on Transformer models [1], such as BERT [2] and GPT-2 [3], has resulted in significant state-of-the-art performances.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 52.60189437866211,
      "citing_paper_id": "208909842",
      "cited_paper_id": 13756489
    },
    {
      "context_text": "Recently, transfer learning based on Transformer models [1], such as BERT [2] and GPT-2 [3], has resulted in significant state-of-the-art performances.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only models and their performance. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 52.60189437866211,
      "citing_paper_id": "208909842",
      "cited_paper_id": 160025533
    },
    {
      "context_text": "…BERT and GPT-2, a variety of Trans-former-based models emerged in a relatively short period of time, notably Grover by the University of Washington [18], Transformer-XL [19] and XLNet [20] by CMU and Google, ERNIE 2.0 by Baidu [21], MASS by Microsoft, [22], Evolved Trans-former by Google [23],…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 52.44203209877014,
      "citing_paper_id": "208909842",
      "cited_paper_id": 168169824
    },
    {
      "context_text": "…models emerged in a relatively short period of time, notably Grover by the University of Washington [18], Transformer-XL [19] and XLNet [20] by CMU and Google, ERNIE 2.0 by Baidu [21], MASS by Microsoft, [22], Evolved Trans-former by Google [23], SciBERT by the Allen Institute for…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 52.43897461891174,
      "citing_paper_id": "208909842",
      "cited_paper_id": 195069387
    },
    {
      "context_text": "My previous experiments in [4] [5] [6] showed effective results of the span-based approach.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to previous experiments. There are no verifiable resources or datasets mentioned.",
      "processing_time": 52.285319328308105,
      "citing_paper_id": "208909842",
      "cited_paper_id": 195791872
    },
    {
      "context_text": "A few days after my ai.patent.bot in [5] was online, I observed an interesting text generation which looks partly like a patent and partly like a letter.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only an observation about text generation. The cited paper title suggests the use of GPT-2, which is a model, not a dataset.",
      "processing_time": 52.614954710006714,
      "citing_paper_id": "208909842",
      "cited_paper_id": 195791872
    },
    {
      "context_text": "To my knowledge, my previous work in [5] is the first to propose patent claim generation and this paper is to push the idea further to personalization.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a previous work on patent claim generation. There are no clear identifiers for datasets in the given context.",
      "processing_time": 52.43420910835266,
      "citing_paper_id": "208909842",
      "cited_paper_id": 195791872
    },
    {
      "context_text": "How to split a claim into spans is skipped here for brevity, and interested readers can refer to [5] [6] for details.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to other papers for details on claim splitting.",
      "processing_time": 51.64168953895569,
      "citing_paper_id": "208909842",
      "cited_paper_id": 195791872
    },
    {
      "context_text": "In my previous work [5] [6], it is convenient to leverage the pre-trained GPT-2 model released by OpenAI.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions leveraging the pre-trained GPT-2 model but does not refer to any specific dataset. GPT-2 is a model, not a dataset.",
      "processing_time": 52.664642095565796,
      "citing_paper_id": "208909842",
      "cited_paper_id": 195791872
    },
    {
      "context_text": "In previous works, I had experimented on a classifier based on BERT [4], a prototype of patent claim generation based on GPT-2 [5], and a framework to measure the text generation of GPT-2 by using BERT [6].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BERT and GPT-2 but does not refer to them as datasets. They are models or methods, not datasets. No specific datasets are mentioned.",
      "processing_time": 52.717313289642334,
      "citing_paper_id": "208909842",
      "cited_paper_id": 195791872
    },
    {
      "context_text": "…short period of time, notably Grover by the University of Washington [18], Transformer-XL [19] and XLNet [20] by CMU and Google, ERNIE 2.0 by Baidu [21], MASS by Microsoft, [22], Evolved Trans-former by Google [23], SciBERT by the Allen Institute for Artificial Intelligence [24], VideoBERT by…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets within the text.",
      "processing_time": 52.090007066726685,
      "citing_paper_id": "208909842",
      "cited_paper_id": 198968327
    },
    {
      "context_text": "…Washington [18], Transformer-XL [19] and XLNet [20] by CMU and Google, ERNIE 2.0 by Baidu [21], MASS by Microsoft, [22], Evolved Trans-former by Google [23], SciBERT by the Allen Institute for Artificial Intelligence [24], VideoBERT by Google [25], DocBERT by the University of Waterloo [26], etc.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only various models and their creators. No verifiable resources are identified.",
      "processing_time": 52.011759996414185,
      "citing_paper_id": "208909842",
      "cited_paper_id": 202558505
    },
    {
      "context_text": "Recently, Keskar et al. [11] propose a conditional Transformer language model for controllable generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (conditional Transformer language model).",
      "processing_time": 51.621694803237915,
      "citing_paper_id": "208909842",
      "cited_paper_id": 202573071
    },
    {
      "context_text": "We can use link prediction to predict new protein-protein interactions [2], which has great significance to human life health and disease treatment.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general application of link prediction in healthcare and systems biology.",
      "processing_time": 51.85708498954773,
      "citing_paper_id": "129949198",
      "cited_paper_id": 2307261
    },
    {
      "context_text": "Method Content Network Publication wordRNN ✓ ⊘ [26] random-walk-based ⊘ ✓ [21, 10] Net2Text ✓ ✓ This paper",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets in the provided context.",
      "processing_time": 52.19150638580322,
      "citing_paper_id": "129949198",
      "cited_paper_id": 3051291
    },
    {
      "context_text": "Influence of vertex embedding dimensions In accordance with [21], network embedding dimensional representations are distributed, meaning each user or item is expressed by a subset of the dimensions and each dimension contributes to a subset of social concepts expressed by the space.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses the method of network embedding and its dimensions.",
      "processing_time": 51.575385093688965,
      "citing_paper_id": "129949198",
      "cited_paper_id": 3051291
    },
    {
      "context_text": "• Random-walk-based algorithm [21, 10]: We compare to a baseline with the idea of edge similarity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison to a baseline method using edge similarity.",
      "processing_time": 51.57773184776306,
      "citing_paper_id": "129949198",
      "cited_paper_id": 3051291
    },
    {
      "context_text": "Influence of embedding method Our model use random-walk-based algorithms as our vertex embedding method, therefore, we compare experiments performance between Deepwalk [21] and node2vec [10].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions methods (Deepwalk and node2vec) but does not refer to any specific datasets. The citation is focused on comparing the performance of these methods.",
      "processing_time": 52.44582152366638,
      "citing_paper_id": "129949198",
      "cited_paper_id": 3051291
    },
    {
      "context_text": "To learn latent representations of vertices in a network, we use local information obtained from truncated random walks by treating walks as the equivalent of sentences [21].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a method for learning latent representations using random walks, which is not a dataset.",
      "processing_time": 52.215718269348145,
      "citing_paper_id": "129949198",
      "cited_paper_id": 3051291
    },
    {
      "context_text": "propose a combined bottom-up and top-down attention mechanism that can enable deeper image understanding for image caption and visual question anwsering [3].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method for image captioning and visual question answering.",
      "processing_time": 51.40334105491638,
      "citing_paper_id": "129949198",
      "cited_paper_id": 3753452
    },
    {
      "context_text": "Simple RNN unit in vanilla version could not capture long dependency due to the gradient explosion/vanishing problem, therefore, we replace it with Gated Recurrent Unit [8].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Gated Recurrent Unit) used to address a technical issue in RNNs.",
      "processing_time": 52.27195906639099,
      "citing_paper_id": "129949198",
      "cited_paper_id": 5201925
    },
    {
      "context_text": "Simple RNN unit in vanilla version could not capture long dependency due to the gradient explosion/vanishing problem, therefore, we replace it with Gated Recurrent Unit [8].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Gated Recurrent Unit) used to address a technical issue in RNNs.",
      "processing_time": 52.27195906639099,
      "citing_paper_id": "129949198",
      "cited_paper_id": 17048224
    },
    {
      "context_text": "proposed an image caption model and it builds a multimodel RNN that considers image features [13].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a model and its components.",
      "processing_time": 51.320525884628296,
      "citing_paper_id": "129949198",
      "cited_paper_id": 8517067
    },
    {
      "context_text": "proposed an image caption model (Figure 2b) and it is a kind of language model that considers image features [13].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a model. The context focuses on the model's ability to generate image descriptions using visual-semantic alignments.",
      "processing_time": 52.37666201591492,
      "citing_paper_id": "129949198",
      "cited_paper_id": 8517067
    },
    {
      "context_text": "BLEU (Bilingual Evaluation Understudy) score [19] is a commonly used metric in the area of language generation.",
      "catation_intent": "none",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions BLEU as a metric, which is excluded according to the instructions. No datasets are mentioned.",
      "processing_time": 51.62826347351074,
      "citing_paper_id": "129949198",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "It is commonly used in speech recognition [9], machine translation [4], handwriting recognition [30] and other applications.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only lists general applications of neural networks.",
      "processing_time": 51.548630714416504,
      "citing_paper_id": "129949198",
      "cited_paper_id": 11212020
    },
    {
      "context_text": "It is commonly used in speech recognition [9], machine translation [4], handwriting recognition [30] and other applications.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only lists general applications of neural networks.",
      "processing_time": 51.548630714416504,
      "citing_paper_id": "129949198",
      "cited_paper_id": 44268933
    },
    {
      "context_text": "This model greatly improves the performance of speech recognition [23].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset, only a general improvement in speech recognition performance.",
      "processing_time": 51.29177689552307,
      "citing_paper_id": "129949198",
      "cited_paper_id": 12469208
    },
    {
      "context_text": "proposed a Recurrent Neural Network (RNN) which allows context information passing all through [16, 17].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to RNN-based language models. No verifiable resources are identified.",
      "processing_time": 51.76226568222046,
      "citing_paper_id": "129949198",
      "cited_paper_id": 14850173
    },
    {
      "context_text": "proposed a Recurrent Neural Network (RNN) which allows context information passing all through [16, 17].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only references to RNN-based language models. No verifiable resources are identified.",
      "processing_time": 51.76226568222046,
      "citing_paper_id": "129949198",
      "cited_paper_id": 17048224
    },
    {
      "context_text": "future newly added links and evolution process [31] as well.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general reference to links and evolution processes. No verifiable resources are identified.",
      "processing_time": 51.815250873565674,
      "citing_paper_id": "129949198",
      "cited_paper_id": 16313264
    },
    {
      "context_text": "In addition to various versions of Net2Text, we evaluated the performance against the following baseline algorithms (Summarized in Table 3): • wordRNN [26]: This method does not consider the local network structure between user and item but only concentrates on review content.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (wordRNN) which is used as a baseline for comparison.",
      "processing_time": 51.87135028839111,
      "citing_paper_id": "129949198",
      "cited_paper_id": 17048224
    },
    {
      "context_text": "To address the issue of gradient vanishing, a variant of RNN called LongShort Term Memory (LSTM) [25] is presented later.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (LSTM).",
      "processing_time": 51.27825164794922,
      "citing_paper_id": "129949198",
      "cited_paper_id": 17048224
    },
    {
      "context_text": "To address the issue of gradient vanishing, a variant of RNN called LongShort Term Memory (LSTM) [25] is presented later.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (LSTM).",
      "processing_time": 51.27825164794922,
      "citing_paper_id": "129949198",
      "cited_paper_id": 18939716
    },
    {
      "context_text": "Recurrent Neural Network (RNN) [16] is one of frequently used deep neural language model.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RNN).",
      "processing_time": 51.191543102264404,
      "citing_paper_id": "129949198",
      "cited_paper_id": 17048224
    },
    {
      "context_text": "Instead, wordRNN tries to generate reviews based on first few words from real reviews, and it helps establish a similar context (quality, service) and predicts in the right direction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only describes a method (wordRNN) and its application in generating reviews.",
      "processing_time": 52.040029764175415,
      "citing_paper_id": "129949198",
      "cited_paper_id": 17048224
    },
    {
      "context_text": "Karpathy et al. proposed an image caption model and it builds a multimodel RNN that considers image features [13].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a model and its functionality.",
      "processing_time": 51.06925868988037,
      "citing_paper_id": "129949198",
      "cited_paper_id": 17048224
    },
    {
      "context_text": "Mikolov et al. proposed a Recurrent Neural Network (RNN) which allows context information passing all through [16, 17].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (RNN).",
      "processing_time": 51.141008377075195,
      "citing_paper_id": "129949198",
      "cited_paper_id": 17048224
    },
    {
      "context_text": "Therefore, wordRNN performs better than random-walk-based algorithm under BLEU score.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a comparison between wordRNN and a random-walk-based algorithm using BLEU score.",
      "processing_time": 51.77103400230408,
      "citing_paper_id": "129949198",
      "cited_paper_id": 17048224
    },
    {
      "context_text": "Common language generation models, including n-gram models [7] and deep learning models (e.g., LSTM [25]), always generate text without considering additional features of network structures.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 51.824528217315674,
      "citing_paper_id": "129949198",
      "cited_paper_id": 18939716
    },
    {
      "context_text": ", LSTM [25]), always generate text without considering additional features of network structures.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (LSTM).",
      "processing_time": 51.13044571876526,
      "citing_paper_id": "129949198",
      "cited_paper_id": 18939716
    },
    {
      "context_text": "[5] first applied neural networks to language model domain in 2003.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the application of neural networks to language modeling.",
      "processing_time": 51.34960651397705,
      "citing_paper_id": "129949198",
      "cited_paper_id": 221275765
    },
    {
      "context_text": "While Generative adversarial networks (GANs) [20, 27, 38, 53] and autoregressive (AR) transformers [8, 10, 36, 52] have delivered impressive results, diffusion models [7, 16] have taken the lead in T2I generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on comparing different types of models for text-to-image generation.",
      "processing_time": 51.83832621574402,
      "citing_paper_id": "268723822",
      "cited_paper_id": 1563370
    },
    {
      "context_text": "While Generative adversarial networks (GANs) [20, 27, 38, 53] and autoregressive (AR) transformers [8, 10, 36, 52] have delivered impressive results, diffusion models [7, 16] have taken the lead in T2I generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on comparing different types of models for text-to-image generation.",
      "processing_time": 51.83832621574402,
      "citing_paper_id": "268723822",
      "cited_paper_id": 219955663
    },
    {
      "context_text": "While Generative adversarial networks (GANs) [20, 27, 38, 53] and autoregressive (AR) transformers [8, 10, 36, 52] have delivered impressive results, diffusion models [7, 16] have taken the lead in T2I generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on comparing different types of models for text-to-image generation.",
      "processing_time": 51.83832621574402,
      "citing_paper_id": "268723822",
      "cited_paper_id": 231592822
    },
    {
      "context_text": "While Generative adversarial networks (GANs) [20, 27, 38, 53] and autoregressive (AR) transformers [8, 10, 36, 52] have delivered impressive results, diffusion models [7, 16] have taken the lead in T2I generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on comparing different types of models for text-to-image generation.",
      "processing_time": 51.83832621574402,
      "citing_paper_id": "268723822",
      "cited_paper_id": 234357997
    },
    {
      "context_text": "While Generative adversarial networks (GANs) [20, 27, 38, 53] and autoregressive (AR) transformers [8, 10, 36, 52] have delivered impressive results, diffusion models [7, 16] have taken the lead in T2I generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on comparing different types of models for text-to-image generation.",
      "processing_time": 51.83832621574402,
      "citing_paper_id": "268723822",
      "cited_paper_id": 247778704
    },
    {
      "context_text": "While Generative adversarial networks (GANs) [20, 27, 38, 53] and autoregressive (AR) transformers [8, 10, 36, 52] have delivered impressive results, diffusion models [7, 16] have taken the lead in T2I generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on comparing different types of models for text-to-image generation.",
      "processing_time": 51.83832621574402,
      "citing_paper_id": "268723822",
      "cited_paper_id": 248476190
    },
    {
      "context_text": "While Generative adversarial networks (GANs) [20, 27, 38, 53] and autoregressive (AR) transformers [8, 10, 36, 52] have delivered impressive results, diffusion models [7, 16] have taken the lead in T2I generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only models and methods. The focus is on comparing different types of models for text-to-image generation.",
      "processing_time": 51.83832621574402,
      "citing_paper_id": "268723822",
      "cited_paper_id": 249926846
    },
    {
      "context_text": "The objective of text-to-image (T2I) tasks [29, 56] is to generate an image corresponding to a given textual description.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the general task of text-to-image generation.",
      "processing_time": 51.20061755180359,
      "citing_paper_id": "268723822",
      "cited_paper_id": 9996719
    },
    {
      "context_text": "The L bind loss is formulated to reduce the intersection over union (IoU) [51] between these two attention maps, encouraging a close alignment between the activations of the modifiers and the class tokens.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (IoU) used in the formulation of a loss function.",
      "processing_time": 51.490599155426025,
      "citing_paper_id": "268723822",
      "cited_paper_id": 15883006
    },
    {
      "context_text": "Thanks to large-scale datasets [3, 42] and advancements in language models [21, 34, 35], T2I models have witnessed remarkable progress.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'large-scale datasets' but does not specify any particular dataset names. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 51.88037109375,
      "citing_paper_id": "268723822",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "Thanks to large-scale datasets [3, 42] and advancements in language models [21, 34, 35], T2I models have witnessed remarkable progress.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "The context mentions 'large-scale datasets' but does not specify any particular dataset names. The cited papers do not provide additional context to identify specific datasets.",
      "processing_time": 51.88037109375,
      "citing_paper_id": "268723822",
      "cited_paper_id": 252917726
    },
    {
      "context_text": "Given only a single training image, the T2I model will likely lack the diversity of generation, known as the language drift [24, 28] problem.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a general issue with text-to-image models. No verifiable resources are identified.",
      "processing_time": 51.43043398857117,
      "citing_paper_id": "268723822",
      "cited_paper_id": 202542455
    },
    {
      "context_text": "(2) The text-alignment metric assesses the editing effectiveness of the fine-tuned model by calculating the text-image similarity between the generated images and the provided prompts using CLIP [15].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific dataset, only a metric (CLIP) which is not a dataset. The citation is about evaluating image captioning, not using a dataset.",
      "processing_time": 51.978633403778076,
      "citing_paper_id": "268723822",
      "cited_paper_id": 233296711
    },
    {
      "context_text": "Compatible with LoRA [18].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method called LoRA. The context is too limited to infer any dataset usage.",
      "processing_time": 51.47793006896973,
      "citing_paper_id": "268723822",
      "cited_paper_id": 235458009
    },
    {
      "context_text": "These models employ denoising processes in image space [1, 17, 31, 41, 49] or latent space [13, 37, 39], resulting in unprecedented image generation quality.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 51.646918535232544,
      "citing_paper_id": "268723822",
      "cited_paper_id": 235619773
    },
    {
      "context_text": "These models employ denoising processes in image space [1, 17, 31, 41, 49] or latent space [13, 37, 39], resulting in unprecedented image generation quality.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 51.646918535232544,
      "citing_paper_id": "268723822",
      "cited_paper_id": 244714856
    },
    {
      "context_text": "These models employ denoising processes in image space [1, 17, 31, 41, 49] or latent space [13, 37, 39], resulting in unprecedented image generation quality.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 51.646918535232544,
      "citing_paper_id": "268723822",
      "cited_paper_id": 246605112
    },
    {
      "context_text": "These models employ denoising processes in image space [1, 17, 31, 41, 49] or latent space [13, 37, 39], resulting in unprecedented image generation quality.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 51.646918535232544,
      "citing_paper_id": "268723822",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "These models employ denoising processes in image space [1, 17, 31, 41, 49] or latent space [13, 37, 39], resulting in unprecedented image generation quality.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. The cited papers' titles do not provide additional context to identify datasets.",
      "processing_time": 51.646918535232544,
      "citing_paper_id": "268723822",
      "cited_paper_id": 253254800
    },
    {
      "context_text": "Recently developed large-scale text-to-image models [1, 37, 39, 41] have shown unprecedented capabilities in synthesizing high-quality and diverse images based on a target text prompt.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and their capabilities. No verifiable resources are identified.",
      "processing_time": 51.360538482666016,
      "citing_paper_id": "268723822",
      "cited_paper_id": 248097655
    },
    {
      "context_text": "Recently developed large-scale text-to-image models [1, 37, 39, 41] have shown unprecedented capabilities in synthesizing high-quality and diverse images based on a target text prompt.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and their capabilities. No verifiable resources are identified.",
      "processing_time": 51.360538482666016,
      "citing_paper_id": "268723822",
      "cited_paper_id": 253254800
    },
    {
      "context_text": "Built on these models, personalized techniques [11, 40] are further introduced to customize the models for This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only references to personalized techniques. No verifiable resources are identified.",
      "processing_time": 51.168169260025024,
      "citing_paper_id": "268723822",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "We employ two key metrics: (1) The image-alignment metric evaluates the reconstruction of concepts, which measures the pairwise CLIP-space cosine similarity [11] be-tween the generated images and the corresponding real images.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only metrics and methods. The context focuses on evaluating the reconstruction of concepts using a metric, not on a particular dataset.",
      "processing_time": 51.774290561676025,
      "citing_paper_id": "268723822",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "Textual Inversion [11] uses pseudo-words to represent new concepts through a visual reconstruction objective.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a method called Textual Inversion, which is not a dataset.",
      "processing_time": 51.54980182647705,
      "citing_paper_id": "268723822",
      "cited_paper_id": 251253049
    },
    {
      "context_text": "Similar to [23], we employ clip-retrieval [2] to select 200 samples from LAION-5B [42] dataset as regularization images.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "LAION-5B"
      ],
      "dataset_descriptions": {
        "LIAON": "The dataset is used to train models for image-text alignment, specifically selecting 200 samples as regularization images to enhance model performance."
      },
      "confidence_score": 1.0,
      "reasoning": "The context mentions the LAION-5B dataset, which is a specific, verifiable resource. It is used to select samples for regularization images in the research.",
      "processing_time": 53.55958414077759,
      "citing_paper_id": "268723822",
      "cited_paper_id": 252917726
    },
    {
      "context_text": "Other methods like prompt-to-prompt [14], null-text inversion [30], and [33] impose constraints on latent noise during inference time without model training.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and techniques. The context is about imposing constraints on latent noise during inference without model training.",
      "processing_time": 51.548155069351196,
      "citing_paper_id": "268723822",
      "cited_paper_id": 253581838
    },
    {
      "context_text": "Notable examples include SINE [55] and UniTune [46], which achieve image editing by fine-tuning the diffusion model.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions SINE and UniTune but does not refer to them as datasets. They are described as methods or models for image editing.",
      "processing_time": 51.544633626937866,
      "citing_paper_id": "268723822",
      "cited_paper_id": 254408758
    },
    {
      "context_text": "Approaches such as [4, 9, 47] re-fine the cross-attention units to encompass all subject to-kens, motivating the model to fully convey the semantics in the input prompt.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only approaches and methods. There are no clear identifiers for datasets in the given context.",
      "processing_time": 51.37310838699341,
      "citing_paper_id": "268723822",
      "cited_paper_id": 254535649
    },
    {
      "context_text": "Techniques like [5, 26, 32] implement region control in T2I generation by using bounding boxes and paired object labels as inputs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only techniques and methods. The context focuses on region control in T2I generation using bounding boxes and paired object labels, which are not datasets.",
      "processing_time": 51.84275698661804,
      "citing_paper_id": "268723822",
      "cited_paper_id": 255942528
    },
    {
      "context_text": "Notably, these two indicators often conflict with each other [45].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, models, or methods. It only refers to indicators, which are not specific resources.",
      "processing_time": 51.14187431335449,
      "citing_paper_id": "268723822",
      "cited_paper_id": 258436985
    },
    {
      "context_text": "Given as input just a few images of the personal concepts (e.g., family, friends, pets, or individual objects), personalized text-to-image models aim to learn a new word embedding to represent a specific concept [45, 50].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a general approach to personalized text-to-image models using a few images of personal concepts.",
      "processing_time": 51.52333402633667,
      "citing_paper_id": "268723822",
      "cited_paper_id": 258436985
    },
    {
      "context_text": "To preserve the good generalization ability in pre-trained large-scale models, we follow [23, 45] to only update the light-weight modules ( W K and W V matrices) within the cross-attention units along with new token embeddings to extend concepts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on updating lightweight modules and token embeddings.",
      "processing_time": 51.026400566101074,
      "citing_paper_id": "268723822",
      "cited_paper_id": 258436985
    },
    {
      "context_text": "Custom-Diffusion [23] and Perfusion [45] compose multiple new concepts by updating only the cross-attention Keys and Values along with new token embeddings.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models or methods. The context focuses on the composition of new concepts using certain techniques.",
      "processing_time": 51.13399887084961,
      "citing_paper_id": "268723822",
      "cited_paper_id": 258436985
    },
    {
      "context_text": "This combination is akin to domain-specific pre-training on a large dataset before personalization [12, 25], with the added benefit of having access to a wealth of readily available LoRA parameters in the community.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to a general concept of 'a large dataset' without naming any particular resource.",
      "processing_time": 51.23911643028259,
      "citing_paper_id": "268723822",
      "cited_paper_id": 258865473
    },
    {
      "context_text": "When working with a dataset containing just a single image, current methods [12, 19, 25, 50] typically begin with additional domain-specific pre-training on a large dataset before adapting to the new concept.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It only refers to a generic 'large dataset' without providing a name or identifier.",
      "processing_time": 51.18040084838867,
      "citing_paper_id": "268723822",
      "cited_paper_id": 258865473
    },
    {
      "context_text": "However, existing methods still lack the flexibility to render all existing concepts in a given image, or only focus on a specific concept [12, 25].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods or models. The context focuses on the limitations of existing methods in text-to-image generation.",
      "processing_time": 51.06687641143799,
      "citing_paper_id": "268723822",
      "cited_paper_id": 258865473
    },
    {
      "context_text": "Therefore, our primary focus is to optimize the model to produce accurate cross-attention maps, elaborated in the following part.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It focuses on the optimization of cross-attention maps in a model.",
      "processing_time": 51.11482501029968,
      "citing_paper_id": "268723822",
      "cited_paper_id": 258888228
    },
    {
      "context_text": "4.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The provided context does not contain any specific, verifiable datasets or resources. It is too short and lacks the necessary information to identify a dataset.",
      "processing_time": 50.8424391746521,
      "citing_paper_id": "268723822",
      "cited_paper_id": null
    },
    {
      "context_text": "Then, the classes are separated and strengthened following the acti-*",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.0,
      "reasoning": "The provided context does not contain any specific, verifiable dataset names or clear usage descriptions.",
      "processing_time": 50.360968828201294,
      "citing_paper_id": "268723822",
      "cited_paper_id": null
    },
    {
      "context_text": "To leverage semantic priors from pre-trained models, DreamBooth [40] utilizes a unique identifier and class name within the input text to represent new concepts.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (DreamBooth) and its approach to leveraging semantic priors. No verifiable datasets are referenced.",
      "processing_time": 51.183443784713745,
      "citing_paper_id": "268723822",
      "cited_paper_id": null
    },
    {
      "context_text": "Several studies have employed Recurrent Neural Network (RNN) networks [20], coupled with Long Short-Term Memory (LSTM) [21], for generating explanatory texts, while others have utilized co-attention and Gated Recurrent Unit (GRU) [22] in conjunction with Convolutional At-tentional Memory Networks…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. No verifiable resources are identified.",
      "processing_time": 50.63609075546265,
      "citing_paper_id": "259224364",
      "cited_paper_id": 304614
    },
    {
      "context_text": "PETER [7] and NRT [20] are deep learning models that use review text for prediction and explanation at the same time.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 9 column 1 (char 339), response: ```json\n{\n    \"reasoning\": \"The citation mentions models (PETER and NRT) but does not refer to any s",
      "processing_time": 51.366461753845215,
      "citing_paper_id": "259224364",
      "cited_paper_id": 304614
    },
    {
      "context_text": "• Factorization methods: PMF [34] is a matrix factorization method that uses latent factors to represent users and SVD++ [35] leverages a user’s interacted items to enhance the latent factors.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span mentions methods (PMF and SVD++) but does not refer to any specific datasets. The context is about describing the methods used in the research.",
      "processing_time": 51.01717829704285,
      "citing_paper_id": "259224364",
      "cited_paper_id": 467086
    },
    {
      "context_text": "Therefore, aspects (Zhang et al., 2014), extracted from corresponding reviews, can be utilized to assist in the modeling of user representation.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific dataset names, only a general reference to 'aspects' extracted from reviews. No clear, verifiable dataset is identified.",
      "processing_time": 51.00883507728577,
      "citing_paper_id": "259224364",
      "cited_paper_id": 3331952
    },
    {
      "context_text": "We use an aspects extraction tool (Zhang et al., 2014) to extract the aspects in each review and correspond it to the respective review.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions an 'aspects extraction tool' but does not specify a dataset. The tool is used to extract aspects from reviews, which is relevant to personalized text generation but no specific dataset is named.",
      "processing_time": 51.3753764629364,
      "citing_paper_id": "259224364",
      "cited_paper_id": 3331952
    },
    {
      "context_text": "Recurrent Unit (GRU) (Cho et al., 2014) in conjunction with Convolutional Attentional Memory Networks (CAML) (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 50.74059224128723,
      "citing_paper_id": "259224364",
      "cited_paper_id": 5590763
    },
    {
      "context_text": "Several studies have employed Recurrent Neural Network (RNN) networks [20], coupled with Long Short-Term Memory (LSTM) [21], for generating explanatory texts, while others have utilized co-attention and Gated Recurrent Unit (GRU) [22] in conjunction with Convolutional At-tentional Memory Networks (CAML) [5] for text generation.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only models and methods. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 50.4623761177063,
      "citing_paper_id": "259224364",
      "cited_paper_id": 5590763
    },
    {
      "context_text": "BLEU-N (N=1,4) mainly counts on the N-grams.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a metric (BLEU) which is excluded according to the instructions.",
      "processing_time": 50.18932008743286,
      "citing_paper_id": "259224364",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "Specifically, (a) a CNN-based method, by which the review selected is too general, (b) a user-id attention-based query method (Papineni et al., 2002), by which the review selected is not specific, (c) a Co-attention based method (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on different approaches to selecting reviews, none of which involve a specific dataset.",
      "processing_time": 50.8613805770874,
      "citing_paper_id": "259224364",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "Explainability results: Table 3 shows that our proposed ERRA method consistently outperforms the baselines in terms of BLEU and ROUGE on different datasets.",
      "catation_intent": "findings",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that the ERRA method outperforms baselines on different datasets. No clear, verifiable dataset names are provided.",
      "processing_time": 50.804295778274536,
      "citing_paper_id": "259224364",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "In contrast, the increase in BLEU on the Yelp dataset is relatively small.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 11 column 1 (char 609), response: ```json\n{\n    \"reasoning\": \"The context mentions the Yelp dataset, which is a specific, verifiable d",
      "processing_time": 59.38015818595886,
      "citing_paper_id": "259224364",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "BLEU (Papineni et al., 2002), ROUGE (Lin, 2004) and BERTscore (Reimers and Gurevych, 2019) are commonly used metrics in natural language generation tasks.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions metrics (BLEU, ROUGE, BERTscore) but does not refer to any specific datasets. These metrics are excluded as per the instructions.",
      "processing_time": 50.557093143463135,
      "citing_paper_id": "259224364",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "Moreover, users rarely share a common preference (Papineni et al., 2002).",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 9 column 1 (char 359), response: ```json\n{\n    \"reasoning\": \"The citation does not mention any specific datasets, only a general obse",
      "processing_time": 50.70280909538269,
      "citing_paper_id": "259224364",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "BLEU [11], ROUGE [32] and BERTscore [33] are commonly used metrics in natural language generation tasks.",
      "catation_intent": "none",
      "resource_type": "metric",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions metrics commonly used in natural language generation tasks but does not refer to any specific datasets.",
      "processing_time": 49.96608066558838,
      "citing_paper_id": "259224364",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "For instance, take BLEU as an example, our method demonstrates the largest improvement on the TripAdvisor dataset.",
      "catation_intent": [],
      "resource_type": [],
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.3,
      "reasoning": "JSON decode error: Extra data: line 11 column 1 (char 549), response: ```json\n{\n    \"reasoning\": \"The context mentions the 'TripAdvisor dataset' which is a specific, veri",
      "processing_time": 57.28113555908203,
      "citing_paper_id": "259224364",
      "cited_paper_id": 11080756
    },
    {
      "context_text": "The former [14, 15] investigates how humans perceive different styles of explanations, whereas the latter generates explanations through the application of explainable recommendation algorithms, which is more relevant to our research.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only research on human perception of explanations and explainable recommendation algorithms.",
      "processing_time": 49.948498487472534,
      "citing_paper_id": "259224364",
      "cited_paper_id": 17471203
    },
    {
      "context_text": "The former (Gedikli et al., 2014; Chen and Wang, 2017) investigates how humans perceive different styles of explanations, whereas the latter generates explanations through the application of explainable recommendation algorithms, which is more relevant to our research.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only research works and their focus areas. The context is about comparing human perception of explanations and algorithmic generation of explanations.",
      "processing_time": 50.50869703292847,
      "citing_paper_id": "259224364",
      "cited_paper_id": 18712907
    },
    {
      "context_text": "These models, such as [23, 24] are trained on large-scale open-domain datasets utilizing self-supervised learning tasks, which enables them to encode common language knowledge.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.5,
      "reasoning": "The context mentions 'large-scale open-domain datasets' but does not specify any particular dataset names. The cited papers do not provide additional specific dataset names either.",
      "processing_time": 50.458035469055176,
      "citing_paper_id": "259224364",
      "cited_paper_id": 52967399
    },
    {
      "context_text": "These models, such as [23, 24] are trained on large-scale open-domain datasets utilizing self-supervised learning tasks, which enables them to encode common language knowledge.",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.5,
      "reasoning": "The context mentions 'large-scale open-domain datasets' but does not specify any particular dataset names. The cited papers do not provide additional specific dataset names either.",
      "processing_time": 50.458035469055176,
      "citing_paper_id": "259224364",
      "cited_paper_id": 201646309
    },
    {
      "context_text": ", 2019a), knowledge graphs (Xian et al., 2019), and rule justifications (Shi et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only types of resources like knowledge graphs. There are no clear identifiers for datasets.",
      "processing_time": 50.04526615142822,
      "citing_paper_id": "259224364",
      "cited_paper_id": 186206810
    },
    {
      "context_text": "Sentence-BERT [24] is utilized to encode each sentence in the corpus, which introduces no additional model parameters.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'corpus' but does not specify a named dataset. The cited paper is about a method (Sentence-BERT) and not a dataset.",
      "processing_time": 50.29157900810242,
      "citing_paper_id": "259224364",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "For example, a pre-trained model is Sentence-BERT [24], which utilizes a multi-layer bidirectional trans-former encoder and incorporates the Masked Language Model and Next Sentence Prediction to capture word and sentence-level representations.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a model (Sentence-BERT). The citation is used to describe the model's architecture and training method.",
      "processing_time": 50.421377420425415,
      "citing_paper_id": "259224364",
      "cited_paper_id": 201646309
    },
    {
      "context_text": "Retrieval-enhanced text generation has recently received increased attention due to its capacity to enhance model performance in a variety of natural language processing (NLP) tasks (Ren et al., 2021; Qiu et al., 2020).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general NLP tasks and models. There are no clear identifiers for datasets.",
      "processing_time": 50.08994722366333,
      "citing_paper_id": "259224364",
      "cited_paper_id": 212747830
    },
    {
      "context_text": "Furthermore, research has demonstrated that pre-trained models possess the capability to capture hierarchysensitive and syntactic dependencies (Qiu et al., 2020), which is highly beneficial for downstream NLP tasks.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only pre-trained models and their capabilities. There are no verifiable resources or datasets mentioned.",
      "processing_time": 49.98859739303589,
      "citing_paper_id": "259224364",
      "cited_paper_id": 212747830
    },
    {
      "context_text": "The ability to fine-tune these models with a small amount of labeled data has further increased their utility for NLP tasks (Qiu et al., 2020; Ren et al., 2021).",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only the utility of fine-tuning models with a small amount of labeled data.",
      "processing_time": 49.82521629333496,
      "citing_paper_id": "259224364",
      "cited_paper_id": 212747830
    },
    {
      "context_text": "Generally, Wikipedia is utilized as a retrieval corpus for the purpose of aiding statement verification [9, 10].",
      "catation_intent": "reusable resource",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "Wikipedia is mentioned as a retrieval corpus, but it does not meet the criteria for a specific, verifiable dataset. It is a general knowledge source.",
      "processing_time": 50.064589500427246,
      "citing_paper_id": "259224364",
      "cited_paper_id": 215737187
    },
    {
      "context_text": "Retrieval is typically implemented using established techniques, such as TF-IDF (Term Frequency-Inverse Document Frequency) or BM25 (Best Match 25) (Lewis et al., 2020), which efficiently match keywords with an",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only retrieval techniques. There are no verifiable resources that meet the criteria.",
      "processing_time": 49.67238688468933,
      "citing_paper_id": "259224364",
      "cited_paper_id": 218869575
    },
    {
      "context_text": "For instance, in open-domain question answering, retrieval-enhanced text generation models can generate the most up-to-date answers by incorporating the latest information during the generation process (Li and Gaussier, 2021; Li et al., 2020a).",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the capability of retrieval-enhanced text generation models in open-domain question answering.",
      "processing_time": 50.23489165306091,
      "citing_paper_id": "259224364",
      "cited_paper_id": 221186870
    },
    {
      "context_text": "We performed experiments on three datasets, namely Amazon (cell phones), Yelp (restaurants), and TripAdvisor (hotels) (Li et al., 2020b).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "Amazon (cell phones)",
        "Yelp (restaurants)",
        "TripAdvisor (hotels)"
      ],
      "dataset_descriptions": {
        "Amazon (cell phones)": "Used to generate personalized text for cell phone recommendations, focusing on user reviews and product attributes.",
        "Yelp (restaurants)": "Utilized to create personalized restaurant recommendations, analyzing user reviews and ratings for dining experiences.",
        "TripAdvisor (hotels)": "Applied to generate personalized hotel recommendations, examining user reviews and ratings for accommodation services."
      },
      "confidence_score": 0.9,
      "reasoning": "The citation mentions three specific datasets used for experiments, which are relevant to personalized text generation.",
      "processing_time": 53.18692064285278,
      "citing_paper_id": "259224364",
      "cited_paper_id": 224270828
    },
    {
      "context_text": "Numerous approaches exist for explaining recommendations, including the use of definition templates (Li et al., 2021a), image visualization (Chen et al.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only approaches for explaining recommendations. No dataset names are present.",
      "processing_time": 49.7675039768219,
      "citing_paper_id": "259224364",
      "cited_paper_id": 229386054
    },
    {
      "context_text": "Generally, Wikipedia is utilized as a retrieval corpus for the purpose of aiding statement verification (Karpukhin et al., 2020; Yamada et al., 2021).",
      "catation_intent": "reusable resource",
      "resource_type": "dataset",
      "extracted_datasets": [
        "wage data from English professional football"
      ],
      "dataset_descriptions": {
        "wage data from English professional football": "Used to study wage disparities and discrimination in English professional football, focusing on statistical analysis of salary distributions and demographic factors."
      },
      "confidence_score": 0.3,
      "reasoning": "Wikipedia is mentioned as a retrieval corpus for statement verification, which aligns with the topic of personalized text generation, especially in contexts where information retrieval is a component.",
      "processing_time": 53.82207727432251,
      "citing_paper_id": "259224364",
      "cited_paper_id": 235293983
    },
    {
      "context_text": "To evaluate the performance of explainability, we compare against three explanation methods, namely CAML [5] and ReXPlug [36] and NRT and PETER.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only explanation methods. The context focuses on comparing different explanation methods rather than using a particular dataset.",
      "processing_time": 49.777655363082886,
      "citing_paper_id": "259224364",
      "cited_paper_id": 235792544
    },
    {
      "context_text": "• ReXPlug uses GPT-2 to generate texts and is capable of rating prediction.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only the use of GPT-2 for text generation and rating prediction. GPT-2 is a model, not a dataset.",
      "processing_time": 50.1483998298645,
      "citing_paper_id": "259224364",
      "cited_paper_id": 235792544
    },
    {
      "context_text": ", 2019b) and ReXPlug (Hada et al., 2021) and NRT and PETER.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not provide specific, verifiable datasets. It mentions models/methods/tools which are excluded according to the instructions.",
      "processing_time": 49.484124183654785,
      "citing_paper_id": "259224364",
      "cited_paper_id": 235792544
    },
    {
      "context_text": "Recent years have witnessed a growing interest in the development of explainable recommendation models [1, 2].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a general trend in research. There are no verifiable resources or specific datasets mentioned.",
      "processing_time": 49.659770488739014,
      "citing_paper_id": "259224364",
      "cited_paper_id": null
    },
    {
      "context_text": "∗Corresponding author In addition to the two frameworks mentioned above, there has been a utilization of multi-task learning frameworks in explainable recommendation systems, where the latent representation shared between user and item embeddings is employed [1, 5].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methodologies and frameworks. There are no clear identifiers for datasets in the text.",
      "processing_time": 49.36312437057495,
      "citing_paper_id": "259224364",
      "cited_paper_id": null
    },
    {
      "context_text": "Natural language generation (NLG) has been intensively studied owing to its important applications such as automatic dialogue generation [1], machine translation [2], text summarization [3], image captions [4] and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of NLG. No dataset names are present in the text.",
      "processing_time": 49.29209351539612,
      "citing_paper_id": "51877952",
      "cited_paper_id": 739696
    },
    {
      "context_text": "Natural language generation (NLG) has been intensively studied owing to its important applications such as automatic dialogue generation [1], machine translation [2], text summarization [3], image captions [4] and so on.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only general applications of NLG. No dataset names are present in the text.",
      "processing_time": 49.29209351539612,
      "citing_paper_id": "51877952",
      "cited_paper_id": 1169492
    },
    {
      "context_text": "As demonstrated by previous reports [10] [11] [12], people’s BFP traits can be inferred by texts they shared on social media.",
      "catation_intent": "findings",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only that BFP traits can be inferred from social media texts. No clear, verifiable dataset names are provided.",
      "processing_time": 49.463489294052124,
      "citing_paper_id": "51877952",
      "cited_paper_id": 2568227
    },
    {
      "context_text": "Every input Chinese word is embedded into k dimensional representation vector by word2vec [14].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions word2vec but does not refer to a specific dataset. It is used to describe a method for embedding words into vectors.",
      "processing_time": 49.24651837348938,
      "citing_paper_id": "51877952",
      "cited_paper_id": 12890187
    },
    {
      "context_text": "As demonstrated by previous reports [10] The text classifier is designed as shown in Fig.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, models, or methods. It only refers to a figure showing the design of a text classifier.",
      "processing_time": 49.28571128845215,
      "citing_paper_id": "51877952",
      "cited_paper_id": 16482857
    },
    {
      "context_text": "For instance, Karpathy (2015) put forward a character-level recurrent neural network (Char-RNN) for generation tasks [5].",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (Char-RNN).",
      "processing_time": 48.879478216171265,
      "citing_paper_id": "51877952",
      "cited_paper_id": null
    },
    {
      "context_text": "…losses between { ˆn i } 𝑁𝑖 = 1 and their corresponding rendered normal maps { n i } 𝑁𝑖 = 1 , which consist of a MSE loss 𝐿 𝑚𝑠𝑒𝑔 and a perceptual loss [32] 𝐿 𝑝𝑒𝑟𝑔 , and can be formulated as follows: where 𝛾 𝑗 denotas the 𝑗 -th feature map in a pre-trained VGG [56]…",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only losses and a pre-trained model (VGG).",
      "processing_time": 48.69132733345032,
      "citing_paper_id": "271334613",
      "cited_paper_id": 980236
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 1033682
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 13637778
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 211989178
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 236976082
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 247939336
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 252596091
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 254408780
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257631648
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257757040
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257834153
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257912580
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "However, DreamVTON addresses the 3D personalized challenge, enabling the generation of diverse clothes while preserving identity.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only a method (DreamVTON) and its capabilities. No verifiable resources are identified.",
      "processing_time": 49.01684808731079,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "…and try-on generation separately, in which the former uses the Thin Plate Splines [5] (TPS) or flow-based [74] network to model geometry deformation, while the latter employs generative models like Generative Adversarial Network [15] or Diffusion Model [51] to synthesize the try-on results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers do not introduce datasets either.",
      "processing_time": 48.54702281951904,
      "citing_paper_id": "271334613",
      "cited_paper_id": 1033682
    },
    {
      "context_text": "…and try-on generation separately, in which the former uses the Thin Plate Splines [5] (TPS) or flow-based [74] network to model geometry deformation, while the latter employs generative models like Generative Adversarial Network [15] or Diffusion Model [51] to synthesize the try-on results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers do not introduce datasets either.",
      "processing_time": 48.54702281951904,
      "citing_paper_id": "271334613",
      "cited_paper_id": 232147187
    },
    {
      "context_text": "…and try-on generation separately, in which the former uses the Thin Plate Splines [5] (TPS) or flow-based [74] network to model geometry deformation, while the latter employs generative models like Generative Adversarial Network [15] or Diffusion Model [51] to synthesize the try-on results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers do not introduce datasets either.",
      "processing_time": 48.54702281951904,
      "citing_paper_id": "271334613",
      "cited_paper_id": 247939336
    },
    {
      "context_text": "…and try-on generation separately, in which the former uses the Thin Plate Splines [5] (TPS) or flow-based [74] network to model geometry deformation, while the latter employs generative models like Generative Adversarial Network [15] or Diffusion Model [51] to synthesize the try-on results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers do not introduce datasets either.",
      "processing_time": 48.54702281951904,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257757040
    },
    {
      "context_text": "…and try-on generation separately, in which the former uses the Thin Plate Splines [5] (TPS) or flow-based [74] network to model geometry deformation, while the latter employs generative models like Generative Adversarial Network [15] or Diffusion Model [51] to synthesize the try-on results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers do not introduce datasets either.",
      "processing_time": 48.54702281951904,
      "citing_paper_id": "271334613",
      "cited_paper_id": 265714588
    },
    {
      "context_text": "…and try-on generation separately, in which the former uses the Thin Plate Splines [5] (TPS) or flow-based [74] network to model geometry deformation, while the latter employs generative models like Generative Adversarial Network [15] or Diffusion Model [51] to synthesize the try-on results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers do not introduce datasets either.",
      "processing_time": 48.54702281951904,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "…and try-on generation separately, in which the former uses the Thin Plate Splines [5] (TPS) or flow-based [74] network to model geometry deformation, while the latter employs generative models like Generative Adversarial Network [15] or Diffusion Model [51] to synthesize the try-on results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only methods and models. The cited papers do not introduce datasets either.",
      "processing_time": 48.54702281951904,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "Traditional 3D VTON methods [6, 17, 19, 35, 45] relies on the 3D scan equipment or cloth simulation to generate geometric representations of high precision.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and tools. The context is about 3D VTON methods and their reliance on 3D scan equipment or cloth simulation.",
      "processing_time": 49.138349294662476,
      "citing_paper_id": "271334613",
      "cited_paper_id": 5632716
    },
    {
      "context_text": "…losses between { ˆn i } 𝑁𝑖 = 1 and their corresponding rendered normal maps { n i } 𝑁𝑖 = 1 , which consist of a MSE loss 𝐿 𝑚𝑠𝑒𝑔 and a perceptual loss [32] 𝐿 𝑝𝑒𝑟𝑔 , and can be formulated as follows: where 𝛾 𝑗 denotas the 𝑗 -th feature map in a pre-trained VGG [56] network.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only losses and a pre-trained VGG network. The VGG network is a method, not a dataset.",
      "processing_time": 48.87478995323181,
      "citing_paper_id": "271334613",
      "cited_paper_id": 14124313
    },
    {
      "context_text": "During training, the batch size on each GPU is set to 1 and both networks are trained by using AdamW [41] = 1 is composed of the front and back view normal maps.",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (AdamW). The context is about training parameters and does not indicate the use of any verifiable dataset.",
      "processing_time": 49.00110864639282,
      "citing_paper_id": "271334613",
      "cited_paper_id": 53592270
    },
    {
      "context_text": "…onto DMTet mesh to obtain a normal map n , which will then be passed to the pre-trained SD to calculate the normal map SDS loss as follows: where z nt is the latent code of n with t -step noising, c n is the embedding of normal map prompt extracted by CLIP [47], and 𝜓 𝑔 is the parameters of Ψ g .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context is about the technical details of a method involving a pre-trained model and CLIP embeddings.",
      "processing_time": 48.83473515510559,
      "citing_paper_id": "271334613",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "Inspired by HumanNorm [27], we choose CLIP-Similarity [47] and FID [23] to evaluate the generated quality of the 3D try-on re-sults, in which FID measures the realism of rendered results, while CLIP-Similarity measures the similarity between the rendered re-sults from arbitrary viewpoint and the…",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only evaluation metrics (CLIP-Similarity and FID). These are excluded as they are metrics, not datasets.",
      "processing_time": 48.745994091033936,
      "citing_paper_id": "271334613",
      "cited_paper_id": 231591445
    },
    {
      "context_text": "0 dataset [68], while the text prompts are extracted by BLIP [37].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not provide specific dataset names, only a reference to 'dataset' without a clear identifier. The citation is likely referring to a method or tool rather than a specific dataset.",
      "processing_time": 48.74254012107849,
      "citing_paper_id": "271334613",
      "cited_paper_id": 233305207
    },
    {
      "context_text": "0 dataset [68], while the text prompts are extracted by BLIP [37].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.2,
      "reasoning": "The context does not provide specific dataset names, only a reference to 'dataset' without a clear identifier. The citation is likely referring to a method or tool rather than a specific dataset.",
      "processing_time": 48.74254012107849,
      "citing_paper_id": "271334613",
      "cited_paper_id": 246411402
    },
    {
      "context_text": "As for text prompts, DreamVTON employs the visual-language model BLIP [37] pose across various viewpoints.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions BLIP, which is a model, not a dataset. There are no specific datasets mentioned in the context.",
      "processing_time": 48.32390069961548,
      "citing_paper_id": "271334613",
      "cited_paper_id": 246411402
    },
    {
      "context_text": "They apply SDS-based optimization[46] to progressively generate 3D humans from initial shape often parameterized by SMPL[40].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets in the given context.",
      "processing_time": 48.32566475868225,
      "citing_paper_id": "271334613",
      "cited_paper_id": 248986576
    },
    {
      "context_text": "They apply SDS-based optimization[46] to progressively generate 3D humans from initial shape often parameterized by SMPL[40].",
      "catation_intent": "method",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. There are no clear identifiers for datasets in the given context.",
      "processing_time": 48.32566475868225,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "…human, our DreamVTON inherits the advanced two-stage 3D human generation framework [8, 27, 29], in which the 3D geometry and texture are optimized separately by using Score Distillation Sampling (SDS) [46] to distill the generative priors from the pre-trained Stable Diffusion (SD) [51] 𝜖 𝜙 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the technical aspects of the 3D human generation framework and the use of Score Distillation Sampling and Stable Diffusion.",
      "processing_time": 48.80712938308716,
      "citing_paper_id": "271334613",
      "cited_paper_id": 252596091
    },
    {
      "context_text": "…human, our DreamVTON inherits the advanced two-stage 3D human generation framework [8, 27, 29], in which the 3D geometry and texture are optimized separately by using Score Distillation Sampling (SDS) [46] to distill the generative priors from the pre-trained Stable Diffusion (SD) [51] 𝜖 𝜙 .",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and models. The context focuses on the technical aspects of the 3D human generation framework and the use of Score Distillation Sampling and Stable Diffusion.",
      "processing_time": 48.80712938308716,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "AvatarBooth[69] employs DreamBooth[52] to inject specific identity information into SD, enhancing identity consistency in the personalized 3D hu-manbody generationprocess.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to methods and models (DreamBooth, SD) but does not cite any datasets.",
      "processing_time": 48.4633252620697,
      "citing_paper_id": "271334613",
      "cited_paper_id": 252596091
    },
    {
      "context_text": "AvatarBooth[69] employs DreamBooth[52] to inject specific identity information into SD, enhancing identity consistency in the personalized 3D hu-manbody generationprocess.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It refers to methods and models (DreamBooth, SD) but does not cite any datasets.",
      "processing_time": 48.4633252620697,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "TADA[38] and TeCH[29] deploys SMPL-X[44] expressing 3D human with more detail.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions TADA and TeCH, which are systems or methods, not datasets. SMPL-X is a model, not a dataset. No specific datasets are mentioned.",
      "processing_time": 48.47487211227417,
      "citing_paper_id": "271334613",
      "cited_paper_id": 252596091
    },
    {
      "context_text": "TADA[38] and TeCH[29] deploys SMPL-X[44] expressing 3D human with more detail.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions TADA and TeCH, which are systems or methods, not datasets. SMPL-X is a model, not a dataset. No specific datasets are mentioned.",
      "processing_time": 48.47487211227417,
      "citing_paper_id": "271334613",
      "cited_paper_id": 253708074
    },
    {
      "context_text": "TADA[38] and TeCH[29] deploys SMPL-X[44] expressing 3D human with more detail.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions TADA and TeCH, which are systems or methods, not datasets. SMPL-X is a model, not a dataset. No specific datasets are mentioned.",
      "processing_time": 48.47487211227417,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260926600
    },
    {
      "context_text": "TADA[38] and TeCH[29] deploys SMPL-X[44] expressing 3D human with more detail.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions TADA and TeCH, which are systems or methods, not datasets. SMPL-X is a model, not a dataset. No specific datasets are mentioned.",
      "processing_time": 48.47487211227417,
      "citing_paper_id": "271334613",
      "cited_paper_id": 261064940
    },
    {
      "context_text": "Specifically, our DreamVTON inherits the advanced two-stage 3D generation framework [8, 27, 29], the first stage optimizes the DMTet-based [12, 54] 3D geometry, while second stage optimizes the texture.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and frameworks. The context focuses on the technical aspects of the 3D generation framework and its stages.",
      "processing_time": 48.35485649108887,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257757213
    },
    {
      "context_text": "Specifically, our DreamVTON inherits the advanced two-stage 3D generation framework [8, 27, 29], the first stage optimizes the DMTet-based [12, 54] 3D geometry, while second stage optimizes the texture.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and frameworks. The context focuses on the technical aspects of the 3D generation framework and its stages.",
      "processing_time": 48.35485649108887,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260926600
    },
    {
      "context_text": "…success of diffusion models [49, 51, 53] for text-to-image (T2I) has largely prompted the development of high-quality 3D content generation [8, 39, 46, 48, 55, 59], whose optimization of the 3D representation is guided by 2D generative priors from the pre-trained T2I diffusion model (e.g.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. The context focuses on the success of diffusion models and their application in 3D content generation.",
      "processing_time": 48.29367399215698,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257757213
    },
    {
      "context_text": "To efficiently model high-quality 3D try-on digital human, our DreamVTON inherits the advanced two-stage 3D human generation framework [8, 27, 29], in which the 3D geometry and texture are optimized separately by using Score Distillation Sampling (SDS) [46] to distill the generative priors from the…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and frameworks. The context focuses on the technical aspects of 3D human generation and does not reference any data sources.",
      "processing_time": 48.65195417404175,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257757213
    },
    {
      "context_text": "To efficiently model high-quality 3D try-on digital human, our DreamVTON inherits the advanced two-stage 3D human generation framework [8, 27, 29], in which the 3D geometry and texture are optimized separately by using Score Distillation Sampling (SDS) [46] to distill the generative priors from the…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and frameworks. The context focuses on the technical aspects of 3D human generation and does not reference any data sources.",
      "processing_time": 48.65195417404175,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260926600
    },
    {
      "context_text": "For texture modeling, DreamVTON utilizes another MLP network Ψ t to parameterize the material model and uses the Physically-Based Rendering derived from Fantasia3D [8] to obtain the rendered RGB image x .",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only a method (Physically-Based Rendering) derived from a tool (Fantasia3D).",
      "processing_time": 48.02417826652527,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257757213
    },
    {
      "context_text": "DreamWaltz[28]andAvatarVerse[70] leverage Pose ControlNet[71] to obtain detailed human body models.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Pose ControlNet' but does not refer to it as a dataset. It is likely a method or tool used to generate detailed human body models. No specific datasets are mentioned.",
      "processing_time": 48.35934805870056,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257834153
    },
    {
      "context_text": "DreamWaltz[28]andAvatarVerse[70] leverage Pose ControlNet[71] to obtain detailed human body models.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Pose ControlNet' but does not refer to it as a dataset. It is likely a method or tool used to generate detailed human body models. No specific datasets are mentioned.",
      "processing_time": 48.35934805870056,
      "citing_paper_id": "271334613",
      "cited_paper_id": 257912580
    },
    {
      "context_text": "DreamWaltz[28]andAvatarVerse[70] leverage Pose ControlNet[71] to obtain detailed human body models.",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context mentions 'Pose ControlNet' but does not refer to it as a dataset. It is likely a method or tool used to generate detailed human body models. No specific datasets are mentioned.",
      "processing_time": 48.35934805870056,
      "citing_paper_id": "271334613",
      "cited_paper_id": 258833547
    },
    {
      "context_text": "We provide additional visual comparisons among our proposed DreamVTON and the existing 3D human generation methods (i.e., DreamWaltz [28], TEXTure [50], and TeCH [29]) in Figure 12 Training Data Slim Shape Mean Shape Fat Shape “a woman wears a beige t-shirt and black pants ” “a man wears a blue…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only comparisons between different 3D human generation methods. No verifiable datasets are referenced.",
      "processing_time": 47.73677921295166,
      "citing_paper_id": "271334613",
      "cited_paper_id": 258833547
    },
    {
      "context_text": "We provide additional visual comparisons among our proposed DreamVTON and the existing 3D human generation methods (i.e., DreamWaltz [28], TEXTure [50], and TeCH [29]) in Figure 12 Training Data Slim Shape Mean Shape Fat Shape “a woman wears a beige t-shirt and black pants ” “a man wears a blue…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific datasets, only comparisons between different 3D human generation methods. No verifiable datasets are referenced.",
      "processing_time": 47.73677921295166,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "…each assignment in the questionnaire, given the person and clothes images, volunteers are asked to select the best 3D try-on result (presented in video format) out of four options, which are generated by our DreamVTON and the other baseline methods (i.e., DreamWaltz [28], TEXTure [50], TeCH [29]).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a user study where volunteers compare 3D try-on results generated by different methods, but no dataset name is explicitly mentioned.",
      "processing_time": 48.43404817581177,
      "citing_paper_id": "271334613",
      "cited_paper_id": 258833547
    },
    {
      "context_text": "…each assignment in the questionnaire, given the person and clothes images, volunteers are asked to select the best 3D try-on result (presented in video format) out of four options, which are generated by our DreamVTON and the other baseline methods (i.e., DreamWaltz [28], TEXTure [50], TeCH [29]).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a user study where volunteers compare 3D try-on results generated by different methods, but no dataset name is explicitly mentioned.",
      "processing_time": 48.43404817581177,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260926600
    },
    {
      "context_text": "…each assignment in the questionnaire, given the person and clothes images, volunteers are asked to select the best 3D try-on result (presented in video format) out of four options, which are generated by our DreamVTON and the other baseline methods (i.e., DreamWaltz [28], TEXTure [50], TeCH [29]).",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The context does not mention any specific, verifiable datasets. It describes a user study where volunteers compare 3D try-on results generated by different methods, but no dataset name is explicitly mentioned.",
      "processing_time": 48.43404817581177,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "We compare our DreamVTON with three existing 3D human generation methods, namely DreamWaltz [28], TEXTure [50], and TeCH [29].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions methods/models (DreamWaltz, TEXTure, TeCH) but does not refer to any specific datasets. The context is about comparing methods, not using datasets.",
      "processing_time": 47.90944862365723,
      "citing_paper_id": "271334613",
      "cited_paper_id": 258833547
    },
    {
      "context_text": "We compare our DreamVTON with three existing 3D human generation methods, namely DreamWaltz [28], TEXTure [50], and TeCH [29].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions methods/models (DreamWaltz, TEXTure, TeCH) but does not refer to any specific datasets. The context is about comparing methods, not using datasets.",
      "processing_time": 47.90944862365723,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260926600
    },
    {
      "context_text": "We compare our DreamVTON with three existing 3D human generation methods, namely DreamWaltz [28], TEXTure [50], and TeCH [29].",
      "catation_intent": "none",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation mentions methods/models (DreamWaltz, TEXTure, TeCH) but does not refer to any specific datasets. The context is about comparing methods, not using datasets.",
      "processing_time": 47.90944862365723,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "Previous 3D human generation works explore this diffusion-based 3D generation framework to sculpt a 3D human according to textual descriptions [7, 27, 28, 31, 33, 38, 70] or reference human images [29, 69].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to previous works exploring 3D human generation using textual descriptions or reference human images.",
      "processing_time": 47.64469337463379,
      "citing_paper_id": "271334613",
      "cited_paper_id": 258833547
    },
    {
      "context_text": "Previous 3D human generation works explore this diffusion-based 3D generation framework to sculpt a 3D human according to textual descriptions [7, 27, 28, 31, 33, 38, 70] or reference human images [29, 69].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to previous works exploring 3D human generation using textual descriptions or reference human images.",
      "processing_time": 47.64469337463379,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260926600
    },
    {
      "context_text": "Previous 3D human generation works explore this diffusion-based 3D generation framework to sculpt a 3D human according to textual descriptions [7, 27, 28, 31, 33, 38, 70] or reference human images [29, 69].",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation context does not mention any specific datasets, only references to previous works exploring 3D human generation using textual descriptions or reference human images.",
      "processing_time": 47.64469337463379,
      "citing_paper_id": "271334613",
      "cited_paper_id": 261064940
    },
    {
      "context_text": "Although the advanced 2D solutions [10, 13, 16, 22, 30, 60–63, 65, 66, 73] can synthesize compelling results within particular viewpoint (e.g., front view), they fail to display try-on results for arbitrary observed viewpoint, which is commonly required in the real-world scenarios.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only discusses limitations of 2D solutions in synthesizing results for arbitrary viewpoints.",
      "processing_time": 47.3078031539917,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260866168
    },
    {
      "context_text": "Most 2D VTON methods [2, 16, 21, 22, 36, 58, 60, 67] employ a two-stage framework to process garment deformation and try-on generation separately, in which the former uses the Thin Plate Splines [5] (TPS) or flow-based [74] network to model geometry deformation, while the latter employs generative…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and frameworks. The context focuses on the methodology of 2D VTON methods and their components.",
      "processing_time": 47.57853412628174,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260866168
    },
    {
      "context_text": "TeCH [29] takes both text and images as inputs, thus is capable of preserving the clothes details in front view.",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only a method (TeCH) that processes text and images. No verifiable dataset names are provided.",
      "processing_time": 47.56845545768738,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260926600
    },
    {
      "context_text": "Although existing methods [27, 29] based on the above two-stage framework can obtain high-quality 3D digital human, they can not be adapted to image-based 3D VTON, because they are incapable of handling clothes inputs.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only methods and limitations of existing approaches.",
      "processing_time": 47.027092933654785,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260926600
    },
    {
      "context_text": "…visual comparisons among our proposed DreamVTON and the existing 3D human generation methods (i.e., DreamWaltz [28], TEXTure [50], and TeCH [29]) in Figure 12 Training Data Slim Shape Mean Shape Fat Shape “a woman wears a beige t-shirt and black pants ” “a man wears a blue t-shirt and grey…",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only comparisons between methods. No verifiable resources are identified.",
      "processing_time": 47.104564905166626,
      "citing_paper_id": "271334613",
      "cited_paper_id": 260926600
    },
    {
      "context_text": "…of diffusion models [49, 51, 53] for text-to-image (T2I) has largely prompted the development of high-quality 3D content generation [8, 39, 46, 48, 55, 59], whose optimization of the 3D representation is guided by 2D generative priors from the pre-trained T2I diffusion model (e.g.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets in the given context.",
      "processing_time": 47.182973861694336,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "…of diffusion models [49, 51, 53] for text-to-image (T2I) has largely prompted the development of high-quality 3D content generation [8, 39, 46, 48, 55, 59], whose optimization of the 3D representation is guided by 2D generative priors from the pre-trained T2I diffusion model (e.g.,…",
      "catation_intent": "research work",
      "resource_type": "none",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation does not mention any specific datasets, only models and methods. There are no clear identifiers for datasets in the given context.",
      "processing_time": 47.182973861694336,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    },
    {
      "context_text": "Most 2D VTON methods [2, 16, 21, 22, 36, 58, 60, 67] employ a two-stage framework to process garment deformation and try-on generation separately, in which the former uses the Thin Plate Splines [5] (TPS) or flow-based [74] network to model geometry deformation, while the latter employs generative models like Generative Adversarial Network [15] or Diffusion Model [51] to synthesize the try-on results.",
      "catation_intent": "research work",
      "resource_type": "method",
      "extracted_datasets": [],
      "dataset_descriptions": {},
      "confidence_score": 0.6,
      "reasoning": "The citation span does not mention any specific datasets, only methods and models. There are no verifiable resources that meet the criteria for inclusion.",
      "processing_time": 47.256972789764404,
      "citing_paper_id": "271334613",
      "cited_paper_id": null
    }
  ],
  "filtering_stats": {
    "original_papers_count": 95,
    "filtered_papers_count": 89,
    "filtered_percentage": "93.7%"
  },
  "extraction_stats": {
    "unique_contexts_processed": 2218,
    "total_citation_instances": 2943,
    "successful_extractions": 155,
    "failed_extractions": 2788,
    "total_processing_time": 132.86774897575378
  }
}