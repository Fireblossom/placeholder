Name (extracted)	Citing Article	Citied Article	Features
Yelp	https://doi.org/10.48550/arXiv.2304.11406 (2023), https://doi.org/10.1145/3580305.3599535 (2022), https://doi.org/10.1145/3626772.3657821 (2024) (+3)	https://doi.org/10.18653/v1/2021.acl-long.383 (2021)	The Yelp dataset is primarily used for sentiment style transfer and personalized sentiment prediction in user reviews. Researchers employ Transformer-based models to change the sentiment of reviews while preserving content, and to predict user-specific sentiment patterns. The dataset also supports the evaluation of fairness, utility, and aspect coverage in generated text, as well as the modeling of user behavior evolution in personalized text generation.
Wikibio	https://www.semanticscholar.org/paper/09f90a7fe63eaff68292ad463838c4ba13ea104c (2025), https://doi.org/10.1109/ICASSP49357.2023.10096932 (2023)	https://doi.org/10.18653/v1/D16-1128 (2016)	The Wikibio dataset is primarily used as a benchmark for table-to-text generation, specifically for generating biographical texts from structured data. It is employed to convert tabular information from Wikipedia into coherent and informative narratives, enhancing the personalization and accuracy of biographical information. This dataset facilitates research in natural language generation, focusing on the biography domain.
Yelp19	https://doi.org/10.48550/arXiv.2408.09865 (2024)	https://doi.org/10.1145/3340531.3411992 (2020)	The Yelp19 dataset is primarily used for generating neural template explanations in recommendation systems, particularly in the restaurant domain. It is employed to train and evaluate models like MAPLE, focusing on improving the interpretability and effectiveness of recommendations. The dataset also supports sentiment analysis to understand user opinions and preferences, and is used in case studies to enhance personalized text generation and user recommendations.
PERSONA-CHAT	https://doi.org/10.48550/arXiv.2310.18342 (2023), https://doi.org/10.18653/V1/2021.NAACL-MAIN.157 (2021), https://doi.org/10.1109/ICAC3N56670.2022.10074067 (2022) (+1)	https://doi.org/10.48550/arXiv.2305.11482 (2023)	The PERSONA-CHAT dataset is used to train and fine-tune dialogue systems for generating personalized responses in conversations. It enhances personalized dialogue generation by incorporating persona information, improving conversational coherence and engagement. Researchers use it to construct multi-turn chitchat interactions and to generate conversation topics by randomly selecting personas, which are then fed as input to models during training. This dataset specifically supports the development of more natural and contextually relevant dialogues.
PersonalDialog	https://doi.org/10.18653/V1/2021.NAACL-MAIN.157 (2021)	https://www.semanticscholar.org/paper/a3ce3004a0eade48a3ae652dbf5c04a60c2416aa (2019)	The PersonalDialog dataset is used to develop and enhance personalized dialogue systems, focusing on maintaining coherent and engaging conversations over multiple turns. It is employed to generate personalized dialogues with diversified traits, particularly by incorporating varied conversational elements from Chinese social media Weibo. This dataset supports research aimed at improving conversational diversity and personalization in chatbot interactions.
WEATHERGOV	https://www.semanticscholar.org/paper/09f90a7fe63eaff68292ad463838c4ba13ea104c (2025)	https://doi.org/10.3115/1687878.1687893 (2009)	The WEATHERGOV dataset is used for generating weather forecasts, with a focus on establishing semantic correspondences using minimal supervision. This approach leverages the dataset's weather-related content to enhance forecast accuracy and coherence, addressing the challenge of producing reliable and contextually appropriate weather predictions with reduced training data.
ROBOCUP	https://www.semanticscholar.org/paper/09f90a7fe63eaff68292ad463838c4ba13ea104c (2025)	https://doi.org/10.3115/1687878.1687893 (2009)	The ROBOCUP dataset is used to generate sports commentaries, focusing on grounded language acquisition in a sports domain. Researchers apply the dataset to test and develop models that can produce contextually relevant and accurate commentaries, enhancing the understanding of how language is learned and used in specific environments.
Rotowire	https://www.semanticscholar.org/paper/09f90a7fe63eaff68292ad463838c4ba13ea104c (2025)	https://doi.org/10.3115/1687878.1687893 (2009)	The Rotowire dataset is utilized in research for generating sports news articles, focusing on the challenge of data-to-document generation. It enables researchers to develop and test algorithms that convert structured sports data into coherent and contextually accurate news articles. This dataset is particularly relevant for evaluating the performance of natural language generation models in creating content that mimics human-written sports journalism.
E2E	https://www.semanticscholar.org/paper/09f90a7fe63eaff68292ad463838c4ba13ea104c (2025)	https://doi.org/10.3115/1687878.1687893 (2009)	The E2E dataset is used for generating restaurant reviews, addressing the challenges in data-to-document generation within the restaurant domain. Researchers employ this dataset to develop and evaluate models that can transform structured data into coherent and contextually appropriate text. This enables the exploration of natural language generation techniques, focusing on the accuracy and fluency of generated reviews.
IMDB	https://doi.org/10.48550/arXiv.2304.11406 (2023)	https://doi.org/10.18653/v1/2021.findings-acl.129 (2021)	The IMDB dataset is primarily used for personalized sentiment prediction, focusing on user-specific sentiment patterns in movie reviews. Researchers employ this dataset to explore and predict personalized product ratings and sentiments, utilizing publicly available movie review data. The dataset's rich textual content and user-specific annotations enable detailed analysis and modeling of individual sentiment variations.
TCFC dataset	https://doi.org/10.48550/arXiv.2310.18342 (2023)	https://doi.org/10.1162/tacl_a_00027 (2018)	The TCFC dataset is primarily used to analyze and study formal language style, focusing on stylistic elements in formal communication. Researchers employ this dataset to address limitations in data quality and resource availability, particularly in text style transfer applications. The dataset helps in examining noise and low-resource stylization issues, enabling more nuanced research into formal language styles.
PERSONA CHAT	https://doi.org/10.1145/3439816 (2021), https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920 (2019)	https://doi.org/10.18653/v1/P18-1205 (2018)	The PERSONA CHAT dataset is used to train and evaluate personalized dialogue agents, focusing on incorporating user profile information into conversations to enhance personalization and engagement. This dataset enables researchers to develop models that can effectively integrate personal details into conversational responses, improving the naturalness and relevance of interactions.
Reddit dataset	https://doi.org/10.18653/V1/2021.NAACL-MAIN.157 (2021), https://doi.org/10.48550/arXiv.2308.07968 (2023)	https://doi.org/10.18653/v1/D16-1127 (2016)	The Reddit dataset is utilized to study casual and diverse conversation patterns, enhancing models' ability to engage in natural and varied dialogues. It is also used to train and evaluate personalized dialogue agents, focusing on user attributes and utterances to generate contextually relevant responses. This dataset enables researchers to improve the conversational skills of AI systems by providing a rich source of real-world, user-generated content.
LongLaMP	https://www.semanticscholar.org/paper/831b89a50ce08af10b1708cbcd841fb7fee48d7b (2025), https://doi.org/10.48550/arXiv.2501.04167 (2025), https://doi.org/10.48550/arXiv.2502.06560 (2025)	https://doi.org/10.48550/arXiv.2407.11016 (2024)	The LongLaMP dataset is used to evaluate personalized long-form text generation models, focusing on the validation set to assess performance, coherence, and consistency in generated texts over extended lengths. It extends the LAMP dataset, enhancing the scope of tasks and providing deeper insights into model capabilities. This dataset enables researchers to rigorously test and improve the quality of personalized text generation.
Amazon Reviews Dataset	https://doi.org/10.48550/arXiv.2407.11016 (2024), https://doi.org/10.48550/arXiv.2501.02157 (2025)	https://doi.org/10.18653/v1/D19-1018 (2019)	The Amazon Reviews Dataset is primarily used for generating data samples for personalized text generation, leveraging 150 million user reviews to train models on user preferences and review content. It is also utilized to bridge language and items for retrieval and recommendation, enhancing recommendation accuracy by focusing on user-item interactions and textual reviews. This dataset's extensive size and rich textual data enable researchers to develop more contextually rich and diverse text outputs and improve recommendation systems.
NBDESCRIB	https://www.semanticscholar.org/paper/09f90a7fe63eaff68292ad463838c4ba13ea104c (2025)	https://doi.org/10.3115/v1/P15-1142 (2015)	The NBDESCRIB dataset is used to train and evaluate models for generating personalized text descriptions from tabular data. It focuses on compositional semantic parsing and controlled table-to-text generation, enhancing the accuracy and relevance of generated text through scientific reasoning and decomposition of evidence and questions. This dataset enables research in high-fidelity personalized text generation, specifically tailored for table-based reasoning tasks.
Helpsteer	https://www.semanticscholar.org/paper/831b89a50ce08af10b1708cbcd841fb7fee48d7b (2025)	https://doi.org/10.18653/v1/2022.acl-long.229 (2021)	The Helpstead dataset is used to evaluate multi-attribute helpfulness in language models, specifically focusing on steering these models to generate more useful and relevant responses. This involves assessing the effectiveness of language models in producing content that is perceived as helpful across various attributes. The dataset enables researchers to test and improve the utility and relevance of model-generated text, enhancing its practical applicability.
Ultra-Chat	https://www.semanticscholar.org/paper/831b89a50ce08af10b1708cbcd841fb7fee48d7b (2025)	https://doi.org/10.18653/v1/2022.acl-long.229 (2021)	The Ultra-Chat dataset is used to enhance chat language models by scaling high-quality dialogues, specifically focusing on personalized text generation and improving conversational quality. This dataset enables researchers to develop more natural and contextually relevant responses in chat systems, leveraging its large volume of high-quality dialogue data.
Personal Preference Eval	https://www.semanticscholar.org/paper/831b89a50ce08af10b1708cbcd841fb7fee48d7b (2025)	https://doi.org/10.18653/v1/2022.acl-long.229 (2021)	The 'Personal Preference Eval' dataset is used to evaluate how well language models can align with individual human preferences. It assesses the models' ability to reflect specific user preferences, focusing on the alignment between generated text and personal preferences. This dataset enables researchers to measure and improve the personalization capabilities of language models through systematic evaluation.
PPDB Set	https://doi.org/10.18653/v1/W19-8634 (2019)	https://doi.org/10.18653/v1/P16-2024 (2016)	The PPDB Set is used in natural language processing research for deriving personalized rankings of substitution candidates and evaluating paraphrase quality. It focuses on simplification and semantic equivalence, enhancing contextually appropriate paraphrasing by filtering out complex and irrelevant substitutions. This dataset enables researchers to improve the accuracy and relevance of paraphrases in text generation tasks.
CelebAMask-HQ	https://doi.org/10.48550/arXiv.2312.06116 (2023)	https://doi.org/10.1109/cvpr42600.2020.00559 (2019)	The CelebAMask-HQ dataset is used to enhance personalized text-to-image generation by providing high-quality, well-curated facial image data. It is utilized to train and fine-tune models, particularly the DTI module, by supplying foreground-masked identity images and rich meta-annotations. This enables the generation of textual embeddings for facial image manipulation and improves the evaluation of personalized text-to-image systems.
Stanford Politeness Corpus (SPC)	https://doi.org/10.48550/arXiv.2310.18342 (2023)	https://doi.org/10.1162/tacl_a_00027 (2018)	The Stanford Politeness Corpus (SPC) is used to study politeness in dialogue, focusing on linguistic markers of politeness across various contexts. Researchers highlight issues with noise and low-resource stylization within the dataset, which informs methodological approaches to analyzing politeness. This dataset enables research into how politeness is expressed and perceived in different dialogic situations, contributing to a deeper understanding of linguistic behavior.
synthetic polite conversational data	https://doi.org/10.48550/arXiv.2310.18342 (2023)	https://doi.org/10.1162/tacl_a_00027 (2018)	The synthetic polite conversational data dataset is used to generate and evaluate polite conversational responses, specifically to improve the politeness in automated systems. Researchers focus on the effectiveness of synthetic data, noting its utility despite lower quality compared to ChatGPT-generated data. This dataset enables the assessment of politeness in generated conversations, contributing to the development of more courteous AI interactions.
Wizard of Wikipedia	https://doi.org/10.1145/3439816 (2021)	https://www.semanticscholar.org/paper/227458886343b86bd15adf58c769be326b4b058a (2018)	The Wizard of Wikipedia dataset is used to train conversational agents that integrate Wikipedia knowledge, enhancing dialogue with factual information to improve engagement and coherence. Research focuses on grounding conversations with retrieved knowledge, using the dataset to develop knowledge-powered conversational systems. This approach aims to make dialogues more informative and engaging by leveraging structured Wikipedia data.
Per-MPST	https://doi.org/10.18653/v1/2024.emnlp-main.737 (2023)	https://doi.org/10.18653/v1/2023.acl-long.190 (2023)	The Per-MPST dataset is used for evaluating and training models in personalized text generation. It supports pointwise evaluation in individual settings, focusing on specific metrics to assess performance. Additionally, it is utilized for reproducing and studying personalized multi-perspective storytelling, aiming to generate coherent narratives from multiple viewpoints. The dataset also enhances the training of personalized instruction data, improving model coherence and contextual relevance in responses.
Per-DOC	https://doi.org/10.18653/v1/2024.emnlp-main.737 (2023)	https://doi.org/10.18653/v1/2023.acl-long.190 (2023)	The Per-DOC dataset is used in research to enhance the coherence and quality of generated long stories through detailed outline control. It is employed in pairwise comparisons in personalized settings to evaluate narrative consistency and structure, addressing the challenge of maintaining coherence in long-form narratives. This dataset facilitates the development and assessment of methods for generating structured and coherent stories.
RateBeer	https://doi.org/10.1145/3580305.3599535 (2022), https://doi.org/10.1145/3696410.3714583 (2024)	https://doi.org/10.1145/2488388.2488466 (2013)	The RateBeer dataset is used for personalized text generation research, specifically focusing on user reviews of beers and breweries. It is employed to evaluate model performance in generating nuanced and specific content, as well as assessing aspect coverage, phrase diversity, and distinct-2 metrics in personalized beer recommendations. This dataset enables researchers to test and refine models for generating high-quality, user-specific textual content.
Yelp23	https://doi.org/10.48550/arXiv.2408.09865 (2024)	https://doi.org/10.1145/3340531.3411992 (2020)	The Yelp23 dataset is primarily used for benchmarking and training models in personalized text generation, particularly in the restaurant domain. It focuses on generating neural template explanations for recommendation systems, evaluating model efficiency and effectiveness. Additionally, the dataset is utilized for sentiment analysis to understand user opinions and preferences from customer reviews.
empathetic dataset	https://www.semanticscholar.org/paper/3708ed2aa909ebde32647257f5ffb3c6548b0e8d (2021)	https://doi.org/10.18653/v1/W17-0906 (2017)	The empathetic dataset is used to evaluate models' performance in generating empathetic responses, with a focus on emotional understanding and personalized interaction in dialogue systems. Researchers employ this dataset to assess how well models can produce contextually appropriate and emotionally sensitive replies, enhancing the quality of human-computer interactions.
MS COCO	https://doi.org/10.1109/TPAMI.2018.2824816 (2019)	https://doi.org/10.1007/978-3-319-10602-1_48 (2014)	The MS COCO dataset is primarily used for training and evaluating image captioning models. It provides a large set of images, each with multiple ground truth captions, which helps improve the quality and diversity of generated text. Researchers use it to highlight limitations, such as the limited number of objects in images, and to enhance model performance through diverse annotations.
Ubuntu Dialogue Corpus	https://doi.org/10.1145/3439816 (2021)	https://doi.org/10.18653/v1/w15-4640 (2015)	The Ubuntu Dialogue Corpus is used to research and develop unstructured multi-turn dialogue systems, particularly focusing on context-based interactions. It leverages almost one million multi-turn conversations extracted from Ubuntu chat logs to train context-sensitive technical dialogue systems. This dataset enables researchers to enhance the contextual understanding and responsiveness of dialogue models in technical support scenarios.
CMU DoG	https://doi.org/10.1145/3439816 (2021)	https://doi.org/10.18653/v1/D18-1076 (2018)	The CMU DoG dataset is used to train and evaluate document-grounded conversation models, focusing on generating contextually accurate responses based on specified documents, particularly Wikipedia articles about popular movies. This dataset enables researchers to enhance conversational context and accuracy by providing a rich source of grounded information, facilitating the development of more informed and relevant conversational agents.
CMU DoG 23	https://doi.org/10.1145/3439816 (2021)	https://doi.org/10.18653/v1/D18-1076 (2018)	The CMU DoG 23 dataset is used to train conversational agents that integrate factual information from documents about popular movies into dialogues. This involves methodologies focused on grounding conversations in specific, factual content to enhance the agents' ability to engage in informed discussions. The dataset's relevance lies in its structured movie-related data, enabling researchers to develop and evaluate conversational systems that can effectively incorporate and discuss factual information.
SQuAD	https://doi.org/10.48550/arXiv.2206.04187 (2022)	https://doi.org/10.18653/v1/P17-1123 (2017)	The SQuAD dataset is primarily used to train and evaluate neural Seq2Seq models for question generation, specifically focusing on reading comprehension tasks. It enables researchers to assess the model's ability to generate questions from given passages, emphasizing the accuracy and relevance of the generated questions. This dataset facilitates the development and testing of models that can understand and process textual information effectively.
Twitter dataset	https://doi.org/10.18653/V1/2021.NAACL-MAIN.157 (2021)	https://doi.org/10.18653/v1/D16-1127 (2016)	The Twitter dataset is used to analyze short-form, informal communication, enhancing the generation of concise and contextually appropriate responses. Researchers employ this dataset to improve natural language processing techniques, focusing on the unique characteristics of tweets such as brevity and colloquial language. This enables more effective and realistic text generation in conversational AI systems.
Dialog NLI dataset	https://doi.org/10.18653/V1/2021.NAACL-MAIN.157 (2021)	https://doi.org/10.18653/v1/P19-1363 (2018)	The Dialog NLI dataset is used to train sequence classification and NLI models for evaluating persona consistency and natural language inference in dialogue contexts. Specifically, it helps assess the consistency between user comments and generated sentences, ensuring that generated responses align with the user's persona. This dataset enables researchers to improve the coherence and relevance of generated dialogues by providing annotated data that captures the nuances of natural language interactions.
Persona dataset	https://doi.org/10.18653/V1/2021.NAACL-MAIN.157 (2021)	https://doi.org/10.18653/v1/P19-1363 (2018)	The Persona dataset is primarily used to create NLI annotations for training models to assess persona consistency in dialog systems. It serves as the foundation for the Dialog NLI dataset, which includes annotations between persona descriptions and dialogue utterances. This enhances the development of models for personalized text generation by ensuring that dialog responses are consistent with the persona.
L A MP-C AP	https://doi.org/10.48550/arXiv.2506.06561 (2025)		The L A MP-C AP dataset is used to evaluate the performance of large language models (LLMs) in generating personalized captions. Specifically, it focuses on assessing the models' ability to tailor captions to individual users. This dataset enables researchers to compare and analyze the effectiveness of different LLMs in personalized text generation tasks, providing insights into user-specific content creation.
LibriTTS	https://www.semanticscholar.org/paper/155a3210bbc715b04a455b2d396f9fbb585540aa (2021)	https://www.semanticscholar.org/paper/3321263fd0b2be6011f20d7b74b8ae801741eb21 (2018)	The LibriTTS dataset is primarily used to train multi-speaker English speech synthesis models, such as StyleSpeech and Meta-StyleSpeech. It provides a rich corpus that enables researchers to develop controllable speech synthesis systems, focusing on enhancing the naturalness and variability of synthesized speech. The dataset's extensive speaker diversity and high-quality audio recordings are crucial for these applications.
Avocado Research Email Collection	https://doi.org/10.1145/3589334.3645408 (2023), https://doi.org/10.48550/arXiv.2308.07968 (2023)		The Avocado Research Email Collection is used for generating personalized emails and studying email communication patterns in an IT company. It focuses on creating contextually appropriate and user-specific email content through content and attachment analysis, enabling research in personalized text generation and communication behavior.
Citation Network Dataset (V14)	https://doi.org/10.48550/arXiv.2407.11016 (2024)	https://doi.org/10.1145/1401890.1402008 (2008)	The Citation Network Dataset (V14) is primarily used to generate data samples for personalized text generation, leveraging its extensive collection of 5,259,858 papers and 29 features per paper. Researchers focus on the structure and content of academic citations to enhance the comprehensiveness and relevance of generated text. This dataset enables the creation of more accurate and contextually appropriate personalized text by providing rich, structured data on academic citations.
Taobao Advertising	https://doi.org/10.1109/ICASSP49357.2023.10096932 (2023)	https://doi.org/10.18653/v1/D16-1128 (2016)	The Taobao Advertising dataset is used for generating text from structured data in Chinese, specifically focusing on advertising content. It employs methodologies that convert tabular information into natural language descriptions to enhance user engagement and personalize advertising messages. This dataset enables researchers to explore how structured advertising data can be effectively transformed into compelling and relevant text, addressing research questions related to user engagement and content personalization.
CelebA-HQ	https://doi.org/10.48550/arXiv.2309.05793 (2023)	https://www.semanticscholar.org/paper/744fe47157477235032f7bb3777800f9f2f45e52 (2017)	The CelebA-HQ dataset is used to fine-tune models on high-quality celebrity images, enhancing the visual fidelity and realism in personalized text generation. This dataset's high-resolution images enable researchers to improve the quality of generated content, focusing on the integration of realistic visual elements into text.
Fairface	https://doi.org/10.48550/arXiv.2309.05793 (2023)	https://www.semanticscholar.org/paper/744fe47157477235032f7bb3777800f9f2f45e52 (2017)	The Fairface dataset is used to fine-tune models for balanced representation of race, gender, and age attributes, enhancing fairness in machine learning applications. It is specifically employed to improve the fairness of personalized text generation models by ensuring balanced and representative data, addressing issues of bias and underrepresentation in these models.
Common Crawl	https://doi.org/10.54254/2755-2721/97/20241406 (2024), https://doi.org/10.48550/arXiv.2308.07968 (2023)	https://doi.org/10.1109/ICCV.2015.11 (2015)	The Common Crawl dataset is used to provide a diverse and complex array of web-based textual data, enhancing the richness of training data. It is also employed to train GloVe word embeddings, leveraging co-occurrence statistics to capture semantic and syntactic word relationships. This dataset enables researchers to improve the quality and breadth of natural language processing models by incorporating a wide range of textual content.
Beauty dataset	https://www.semanticscholar.org/paper/fb394896bf1b31183839c766afc62dd251a7b9b7 (2021), https://doi.org/10.1145/3626772.3657821 (2024)	https://doi.org/10.3115/1073083.1073135 (2002)	The Beauty dataset is used to evaluate the performance of text generation models on beauty-related content. Research focuses on measuring the effectiveness of generated sentences using metrics like ROUGE and BLEU scores. Additionally, the dataset is employed to assess personalized text generation models, considering user preferences in beauty-related contexts. This enables researchers to refine models for more tailored and contextually appropriate text outputs.
ROCStories	https://www.semanticscholar.org/paper/3708ed2aa909ebde32647257f5ffb3c6548b0e8d (2021)	https://doi.org/10.1007/978-3-319-10602-1_48 (2014)	The ROCStories dataset is utilized to evaluate narrative coherence and logical flow in short story generation. Researchers employ this dataset to assess models' abilities to produce compelling and consistent narratives, focusing on the logical progression and coherence of generated stories. This dataset enables the testing of models' narrative skills, ensuring they can create stories that are both engaging and logically structured.
Personality Captioning dataset	https://doi.org/10.18653/v1/2020.acl-main.673 (2020)	https://doi.org/10.1109/CVPR.2019.01280 (2018)	The Personality Captioning dataset is used to collect image captions that reflect 215 different personality traits, aiming to enhance engagement by generating personalized and engaging captions. This dataset supports research in creating more interactive and tailored image captioning systems, focusing on the impact of personality traits on user engagement and content relevance.
IAM On-Line Handwriting Database	https://doi.org/10.1109/SMC53654.2022.9945138 (2022)	https://doi.org/10.1109/ICDAR.2005.132 (2005)	The IAM On-Line Handwriting Database is used to train a conditional recurrent variational autoencoder (C-RVAE) for generating personalized digital ink. This focuses on handwriting recognition and synthesis, enabling researchers to develop models that can accurately recognize and synthesize individual handwriting styles. The dataset's detailed stroke information and large sample size facilitate robust training and testing of these models.
IAMOnDB	https://doi.org/10.1109/SMC53654.2022.9945138 (2022)	https://doi.org/10.1109/ICDAR.2005.132 (2005)	The IAMOnDB dataset is used to train a conditional recurrent variational autoencoder (C-RVAE) for generating personalized digital ink, specifically focusing on handwriting recognition and synthesis. This methodology enables researchers to explore the nuances of individual writing styles, enhancing the accuracy and realism of synthesized handwriting. The dataset's detailed digital ink recordings are crucial for capturing the dynamic and stylistic elements of handwriting, facilitating advancements in personalized text generation and recognition systems.
standard Wikipedia	https://doi.org/10.18653/v1/W19-8634 (2019)	https://doi.org/10.18653/v1/P16-2024 (2016)	The standard Wikipedia dataset is used to train models for ranking substitution candidates by simplicity, leveraging its rich, diverse corpus. This enables researchers to compare original and simplified versions, focusing on enhancing text simplification techniques. The dataset's extensive content and variability support the development and evaluation of algorithms aimed at improving text accessibility.
Simple Wikipedia	https://doi.org/10.18653/v1/W19-8634 (2019)	https://doi.org/10.18653/v1/P16-2024 (2016)	The Simple Wikipedia dataset is used alongside the standard Wikipedia to train models that rank substitution candidates by simplicity. This involves focusing on simpler language and concepts, enabling research into methods for improving text simplification and accessibility. The dataset's characteristic use of straightforward language supports the development of algorithms that can effectively identify and rank simpler alternatives to complex terms and phrases.
PENS	https://doi.org/10.48550/arXiv.2304.11406 (2023)	https://doi.org/10.18653/v1/2021.acl-long.7 (2021)	The PENS dataset is used to construct personalized headline generation systems, leveraging realistic user interaction data from Microsoft News. It focuses on enhancing personalization and improving user engagement through tailored news headlines. The dataset enables researchers to develop and evaluate methods that generate more relevant and engaging headlines for individual users.
News Categorization dataset	https://doi.org/10.48550/arXiv.2304.11406 (2023)	https://doi.org/10.48550/arXiv.2209.11429 (2022)	The News Categorization dataset, derived from HuffPost articles, is primarily used to construct and evaluate personalized text generation models. It leverages news articles categorized by topic, enabling researchers to train models that can generate text tailored to specific categories or user preferences. This dataset facilitates the development and assessment of algorithms designed to produce contextually relevant and personalized content.
Amazon review dataset	https://doi.org/10.1145/3626772.3657821 (2024)	https://doi.org/10.1145/2766462.2767755 (2015)	The Amazon review dataset is used to gather reviews from categories such as Sports, Beauty, and Toys, focusing on user preferences and product ratings. Researchers employ this dataset to analyze consumer behavior and sentiment, using methodologies that involve categorizing and evaluating textual data. This enables studies on user preferences and product satisfaction, providing insights into consumer decision-making processes.
Weibo	https://doi.org/10.48550/arXiv.2308.07968 (2023)	https://doi.org/10.18653/v1/D18-1298 (2018)	The Weibo dataset is used to train and evaluate personalized dialogue agents, focusing on integrating user attributes and utterances to generate contextually relevant responses. This involves methodologies that emphasize the contextual understanding and personalization of dialogues, enabling research into more natural and user-specific conversational interactions.
PersonaExt	https://doi.org/10.18653/v1/2023.acl-long.544 (2023)	https://doi.org/10.18653/v1/D18-1514 (2018)	The PersonaExt dataset is used to evaluate the performance of frameworks in personalized text generation tasks. It is specifically employed to measure improvements and compare against strong baselines, enabling researchers to assess the effectiveness of their models in generating personalized text.
person-chat dataset	https://doi.org/10.1109/AINIT59027.2023.10212566 (2023)	https://doi.org/10.18653/v1/P19-1363 (2018)	The 'person-chat dataset' is used to label Natural Language Inference (NLI) tags within dialogue contexts, enhancing personalized text generation. This involves employing NLI techniques to improve the coherence and relevance of generated text in conversational settings. The dataset's focus on dialogue provides rich contextual data, enabling researchers to develop more nuanced and context-aware text generation models.
myPersonality dataset	https://doi.org/10.1109/ICCCNT61001.2024.10724424 (2024)	https://www.semanticscholar.org/paper/0e00a7e0eed484f0099eb46a0cdcb99df1a42336 (2020)	The myPersonality dataset is used to detect particularity values from utterances, aiding in the construction of a personality identifier. It focuses on the relationship between language use and personality traits, employing methodologies that analyze linguistic patterns to infer individual personality characteristics. This dataset enables researchers to explore how specific language features correlate with different personality types, enhancing understanding of human behavior and communication.
b5 corpus	https://doi.org/10.1109/ICCCNT61001.2024.10724424 (2024)	https://www.semanticscholar.org/paper/547a6c2a15f8b40c015c7515abf3680a5df74d85 (2018)	The b5 corpus is used to study personality-dependent natural language understanding and generation. It includes controlled and free textbooks with diverse communicative tasks and author personality data. Researchers employ this dataset to explore how personality traits influence language use and to develop models that can generate text reflecting specific personality characteristics.
Stellar	https://doi.org/10.48550/arXiv.2312.06116 (2023)	https://doi.org/10.1109/cvpr42600.2020.00559 (2019)	The Stellar dataset is used in research for generating personalized text based on multimodal prompts featuring imaginary human-centric depictions. It employs publicly available images of celebrities for training and evaluation, enabling researchers to explore the integration of visual and textual data in creating more contextually rich and personalized text outputs.
personalized dialogue data	https://doi.org/10.1145/3439816 (2021)	https://www.semanticscholar.org/paper/bfe6d67ed1c9119f91774e62fe0f4f328830526e (2017)	The 'personalized dialogue data' dataset is used to train response-generation models, specifically focusing on speaker-role adaptation in neural conversation models. This involves employing multi-task learning to enhance the model's ability to generate contextually appropriate responses that reflect different speaker roles. The dataset enables researchers to develop more nuanced and role-specific conversational agents by providing diverse dialogue examples.
Knowledge-based dataset	https://doi.org/10.1145/3439816 (2021)	https://doi.org/10.24963/ijcai.2018/643 (2018)	The Knowledge-based dataset is used to train models for generating commonsense-aware conversations, specifically focusing on one-turn post-response pairs. It incorporates associated knowledge graphs to enhance the contextual relevance and coherence of the generated responses. This dataset enables researchers to develop more sophisticated conversational agents by providing structured knowledge that informs the model's understanding and generation processes.
commonsense conversation dataset	https://doi.org/10.1145/3439816 (2021)	https://doi.org/10.24963/ijcai.2018/643 (2018)	The commonsense conversation dataset is used to generate commonsense-aware conversations, specifically focusing on one-turn post-response pairs. Researchers employ this dataset to incorporate associated knowledge graphs, enhancing the contextual relevance and coherence of conversational responses. This approach addresses the challenge of integrating commonsense knowledge into conversational systems, enabling more natural and contextually appropriate interactions.
Wikidata	https://doi.org/10.1145/3439816 (2021)	https://doi.org/10.18653/v1/D19-1299 (2019)	Wikidata is used as an external knowledge base to link extracted entities from data fields, enhancing neural data-to-text generation models with background information. This linkage provides context and enriches the generated text, improving the accuracy and relevance of the output. The dataset's extensive and structured information supports the integration of real-world knowledge into text generation processes.
TaoDescribe	https://doi.org/10.1145/3439816 (2021)	https://doi.org/10.1145/3292500.3330725 (2019)	The TaoDescribe dataset is used for generating personalized and knowledge-based product descriptions in e-commerce. It integrates user preferences and product knowledge to enhance the relevance and appeal of product descriptions. This dataset enables researchers to develop and test algorithms that incorporate user-specific data and detailed product information, improving the user experience in online shopping environments.
Personalized product description dataset	https://doi.org/10.1145/3439816 (2021)	https://doi.org/10.1145/3292500.3330725 (2019)	The 'Personalized product description dataset' is used to generate personalized product descriptions in e-commerce settings. Researchers incorporate knowledge and user category attributes to enhance user experience. The dataset enables the development of models that tailor product descriptions to individual users, improving relevance and engagement. This approach focuses on enhancing the personalization of e-commerce interactions through data-driven text generation.
LAION-5B	https://doi.org/10.48550/arXiv.2504.20998 (2025)	https://doi.org/10.48550/arXiv.2210.08402 (2022)	The LAION-5B dataset is used to sample easy-negative examples, enhancing model robustness against irrelevant data. This methodology ensures consistency across various concepts, improving the reliability and performance of models in diverse applications. The dataset's large scale and diverse content enable researchers to address challenges related to data irrelevance and model consistency.
Pushshift Reddit Dataset	https://doi.org/10.18653/V1/2021.NAACL-MAIN.157 (2021)	https://doi.org/10.5281/ZENODO.3608135 (2020)	The Pushshift Reddit Dataset is used to provide raw data for preprocessing user attributes, with a focus on ensuring the reproducibility of models and scripts. This dataset enables researchers to develop and validate methods for handling and analyzing large-scale social media data, enhancing the transparency and replicability of their research.
Instruct-QA	https://doi.org/10.48550/arXiv.2504.02867 (2025)	https://doi.org/10.18653/v1/P19-1612 (2019)	The Instruct-QA dataset is used to evaluate and train models on three different information-seeking QA tasks, including open-domain QA. It encompasses diverse question types, enabling researchers to assess model performance across various query complexities. This dataset facilitates the development of more robust and versatile QA systems by providing a rich set of questions for training and evaluation.
Gender	https://doi.org/10.1109/ICKECS56523.2022.10059789 (2022)	https://doi.org/10.18653/v1/P18-1080 (2018)	The 'Gender' dataset is used for personal style transfer experiments, specifically to alter gender-related language in text. This involves methodologies that manipulate textual attributes to reflect different gender identities, enabling research into the nuances of gender expression in language. The dataset facilitates these experiments by providing a basis for testing and validating style transfer techniques.
ConvAI2	https://doi.org/10.1109/ICKECS56523.2022.10059789 (2022)	https://doi.org/10.1007/978-3-030-29135-8_7 (2019)	The ConvAI2 dataset is used to train Seq2Seq models for generating textual responses, specifically aiming to enhance conversational intelligence and personalization in AI-generated dialogues. This dataset enables researchers to focus on improving the quality and naturalness of machine-generated conversations by providing a rich set of human-human interactions.
Political slant	https://doi.org/10.1109/ICKECS56523.2022.10059789 (2022)	https://doi.org/10.18653/v1/P18-1080 (2018)	The 'Political slant' dataset is used for political style transfer experiments, specifically to modify the political bias in text. Researchers employ this dataset to develop and test algorithms that can alter the ideological tone of written content, enabling studies on the impact of political framing and bias in communication.
massive generic dialogue data	https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920 (2019)	https://doi.org/10.1137/1.9781611975321.71 (2018)	The 'massive generic dialogue data' dataset is primarily used to pre-train dialogue models, enabling them to generate general conversational responses. This pre-training step focuses on building a robust foundation of conversational skills before any personalization is applied. The dataset's large scale and generic nature make it suitable for enhancing the model's ability to handle a wide range of conversational contexts, thereby improving its overall performance in subsequent personalized text generation tasks.
small-scale personalized dialogue data	https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920 (2019)	https://doi.org/10.1137/1.9781611975321.71 (2018)	The 'small-scale personalized dialogue data' dataset is used to fine-tune pre-trained models, specifically to incorporate user-specific information. This enables the generation of more personalized responses in dialogue systems. The dataset's focus on user-specific details enhances the model's ability to produce contextually relevant and individualized interactions.
EmotionLines	https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920 (2019)	https://www.semanticscholar.org/paper/ba4c923b43360325cba984549aa3c3224863d1f6 (2018)	The EmotionLines dataset is used to collect and analyze emotional dialogues from telescripts and Facebook, with a focus on multi-party conversations. It enhances personalized text generation by providing a rich source of emotional interactions, enabling researchers to develop more nuanced and contextually appropriate dialogue systems.
REDDIT TaoDescribe	https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920 (2019)	https://doi.org/10.18653/v1/D18-1298 (2018)	The REDDIT TaoDescribe dataset is used to extract personalized characteristics from users' posts, which enhances the ability to generate personalized dialogues and product descriptions. This involves analyzing user-generated content to capture individual traits and preferences, enabling more tailored and contextually relevant text generation.
REDDIT19	https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920 (2019)	https://doi.org/10.18653/v1/D18-1298 (2018)	The REDDIT19 dataset is used to construct a profile-based dialogue dataset by extracting personalized characteristics from users' social posts. This dataset trains personalized dialogue agents, focusing on building more authentic and contextually relevant conversational models. The methodology involves analyzing user-generated content to capture individual traits, enhancing the agents' ability to simulate natural and personalized interactions.
target story generation dataset	https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920 (2019)	https://doi.org/10.18653/v1/D19-1615 (2019)	The 'target story generation dataset' is used for final fine-tuning with multi-task learning to enhance model performance on specific story generation tasks. It focuses on targeted common sense grounding, improving the model's ability to generate stories that are contextually coherent and grounded in realistic scenarios. This dataset enables researchers to address challenges in generating narratives that require nuanced understanding and application of common sense knowledge.
story data	https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920 (2019)	https://doi.org/10.18653/v1/D19-1615 (2019)	The 'story data' dataset is used for intermediate fine-tuning of pre-trained GPT-2 models to adapt them to the domain of stories. This process enhances the model's ability to generate coherent narratives. The dataset enables researchers to improve the contextual understanding and narrative coherence of generated texts, focusing on the specific characteristics of storytelling.
task-oriented dialogue system dataset	https://doi.org/10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00176 (2019)	https://www.semanticscholar.org/paper/a51158f795e260e07c8dc540c07a2749add411cd (2017)	The task-oriented dialogue system dataset is primarily used to support research on personalized text generation. It contains conversations that include users' personalized information, enabling researchers to develop and evaluate models that can generate more contextually relevant and user-specific responses. This dataset facilitates the exploration of how incorporating user-specific data can enhance the effectiveness and naturalness of dialogue systems.
IMDb62	https://doi.org/10.48550/arXiv.2402.04914 (2024)	https://doi.org/10.1162/COLI_a_00173 (2014)	The IMDb62 dataset is used for authorship attribution studies, focusing on 62,000 movie reviews from 62 prolific IMDb users, each contributing 1,000 reviews. Researchers employ this dataset to analyze writing styles and patterns, enabling the development and testing of algorithms that can accurately attribute authorship based on textual features. This dataset facilitates the exploration of linguistic characteristics and the robustness of attribution models in large-scale, diverse review data.
persona-based empathetic conversations	https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920 (2019)	https://doi.org/10.18653/v1/2020.emnlp-main.531 (2020)	The 'persona-based empathetic conversations' dataset is used to train and evaluate a BERT-based response selection model, CoBERT. This model focuses on learning higher-level interactive matching through multi-hop co-attention, specifically in the context of empathetic conversations. The dataset enables researchers to assess the effectiveness of CoBERT in generating contextually appropriate and empathetic responses, enhancing the quality of conversational interactions.
The Pile	https://doi.org/10.48550/arXiv.2402.04914 (2024)	https://www.semanticscholar.org/paper/db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e (2020)	The Pile is used for pretraining language models, leveraging its 825GB of English text from 22 diverse sources, including academic writing, internet, prose, dialogue, and miscellaneous content. This dataset enables researchers to develop robust language models by providing a wide range of textual data, enhancing model performance across various linguistic contexts and applications.
Amazon review data	https://doi.org/10.1145/3589334.3645408 (2023)		The Amazon review data is used to generate personalized book reviews, focusing on the largest category of books to create user-specific review texts. This involves employing natural language processing techniques to tailor reviews to individual users, enhancing the relevance and personalization of the content. The dataset's extensive collection of reviews enables researchers to train models that can produce detailed and contextually appropriate reviews, specifically addressing the needs and preferences of individual users.
product descriptions and user history	https://doi.org/10.48550/arXiv.2310.11593 (2023)	https://doi.org/10.18653/v1/D19-1319 (2019)	The 'product descriptions and user history' dataset is used to generate personalized reviews by integrating domain-specific features into the text generation process. This approach enhances personalization, leveraging user history and product details to create more relevant and tailored review content. The dataset's focus on domain-specific features is crucial for improving the authenticity and utility of the generated reviews.
Long-form Language Model Personalization (LongLaMP) benchmark	https://doi.org/10.48550/arXiv.2501.04167 (2025)	https://doi.org/10.48550/arXiv.2407.11016 (2024)	The Long-form Language Model Personalization (LongLaMP) benchmark is used to evaluate personalized long-form text generation models across four diverse tasks. It focuses on assessing the effectiveness of personalization in generating coherent and contextually relevant text. This dataset enables researchers to measure how well models can adapt to individual user characteristics and maintain consistency over longer text sequences.
data from user profiles	https://doi.org/10.54254/2755-2721/107/20241355 (2024)	https://doi.org/10.48550/arXiv.2402.05133 (2024)	The dataset from user profiles is used to enhance personalized model performance by integrating user-specific representations, focusing on improving model accuracy. This involves methodologies that incorporate user data to refine and tailor model outputs, specifically addressing the need for more accurate and personalized results. The dataset's user-specific data is crucial for these enhancements.
Amazon Movies	https://doi.org/10.48550/arXiv.2210.15500 (2022)	https://www.semanticscholar.org/paper/113424928b19a1d7645ef04a2b53532dd426c283 (2015)	The Amazon Movies dataset is used to evaluate the fairness and utility of the DDP method by plotting results on movie reviews. This involves analyzing review data to assess how well the DDP method maintains fairness while preserving utility in the context of movie ratings and reviews. The dataset's review content and ratings are key features enabling this evaluation.
Amazon Movies 1	https://doi.org/10.48550/arXiv.2210.15500 (2022)	https://doi.org/10.18653/v1/2021.acl-long.383 (2021)	The Amazon Movies 1 dataset is used to investigate explanation generation for movie recommendations using the personalized transformer model PETER. It focuses on generating explanations that help users understand why certain movies are recommended to them. This research employs the dataset to enhance the transparency and interpretability of recommendation systems, leveraging the dataset's rich user-movie interaction data.
LAMP	https://doi.org/10.48550/arXiv.2502.06560 (2025)	https://doi.org/10.48550/arXiv.2407.11016 (2024)	The LAMP dataset is used to benchmark personalized text generation tasks, such as tweet generation, movie reviewing, email writing, and social media post writing. It provides actionable performance metrics, enabling researchers to evaluate and compare the effectiveness of different models in generating contextually appropriate and personalized text.
Pinterest image dataset	https://doi.org/10.1109/TMM.2024.3399075 (2024)		The Pinterest image dataset is used to construct subsets for personalized text generation, specifically focusing on image-based content. Researchers employ this dataset to enhance user engagement and personalization by leveraging the visual elements. The dataset's image-centric nature is crucial for developing algorithms that generate personalized text descriptions, improving the relevance and appeal of content for users.
Personalized VideoIC dataset	https://doi.org/10.1145/3589334.3645711 (2024)		The Personalized VideoIC dataset is used to develop methods for generating personalized video content automatically, without the need for manually labeled personality traits. It focuses on video-to-text generation, enabling researchers to explore automatic personalization techniques in multimedia content creation. This dataset supports the development and evaluation of algorithms that can infer and apply personalization directly from video data, enhancing the relevance and engagement of generated content.
Ultrafeedback	https://www.semanticscholar.org/paper/95124cb03a6e5de7a623db32b987531d7830629e (2024)	https://doi.org/10.48550/arXiv.2402.10207 (2024)	The Ultrafeedback dataset is used to develop a personalized reward model, specifically focusing on incorporating user feedback to dynamically adjust preferences. This approach enables researchers to refine and personalize text generation models by continuously aligning them with user preferences, enhancing the relevance and satisfaction of generated content.
MPST	https://doi.org/10.18653/v1/2024.emnlp-main.737 (2023)	https://doi.org/10.18653/v1/2023.acl-long.190 (2023)	The MPST dataset is primarily used for multi-perspective storytelling, enabling researchers to generate narratives from various viewpoints. It provides a structured basis for exploring narrative diversity and perspective-taking in computational models. The dataset's key feature is its multi-perspective content, which supports the development and evaluation of algorithms designed to create coherent and varied stories. This facilitates research into narrative generation and the cognitive processes involved in storytelling.
DOC	https://doi.org/10.18653/v1/2024.emnlp-main.737 (2023)	https://doi.org/10.18653/v1/2023.acl-long.190 (2023)	The DOC dataset is used to enhance the coherence and narrative structure of long stories by providing detailed outlines. Researchers employ this dataset to control and improve the flow of narratives, focusing on how detailed outlines can guide the generation of more coherent and structured stories. This approach addresses the challenge of maintaining narrative consistency over longer texts.
HelpSteer2	https://www.semanticscholar.org/paper/95124cb03a6e5de7a623db32b987531d7830629e (2024)	https://doi.org/10.48550/arXiv.2402.10207 (2024)	The HelpSteer2 dataset is utilized in the development of a personalized reward model, focusing on enhancing user guidance and interaction. This involves employing methodologies that emphasize user feedback and engagement to refine the reward system. The dataset enables researchers to address specific research questions related to improving user experience and interaction in personalized systems.
Rewards-in-Context	https://www.semanticscholar.org/paper/95124cb03a6e5de7a623db32b987531d7830629e (2024)	https://doi.org/10.48550/arXiv.2402.10207 (2024)	The 'Rewards-in-Context' dataset is used to align foundation models with dynamic user preferences, focusing on enhancing multi-objective alignment in personalized reward systems. This involves methodologies that integrate dynamic preference data to improve model adaptability and responsiveness. The dataset enables researchers to address the challenge of maintaining alignment as user preferences evolve, making it particularly useful for developing more adaptive and responsive personalized systems.
SafeRLHF	https://www.semanticscholar.org/paper/95124cb03a6e5de7a623db32b987531d7830629e (2024)	https://doi.org/10.48550/arXiv.2402.10207 (2024)	The SafeRLHF dataset is used to ensure safety in reinforcement learning models through human feedback, focusing on the development of a robust personalized reward model. It supports methodologies that integrate human preferences to enhance the safety and reliability of RL systems, addressing research questions related to aligning AI behavior with human values and ensuring ethical outcomes.
LaMP-5U	https://doi.org/10.1007/978-3-031-88714-7_40 (2025)	https://doi.org/10.48550/arXiv.2304.11406 (2023)	The LaMP-5U dataset is used to analyze and compare document lengths across various datasets, specifically examining how document length impacts personalization in large language models. This involves quantitative comparisons and statistical analyses to understand the relationship between document length and the effectiveness of personalization techniques. The dataset's focus on document length provides insights into optimizing personalization in language models.
LaMP-4	https://doi.org/10.1007/978-3-031-88714-7_40 (2025)	https://doi.org/10.48550/arXiv.2304.11406 (2023)	The LaMP-4 dataset is used to evaluate personalized text generation, specifically focusing on the integration of user preferences and context within large language models. This dataset enables researchers to assess how well these models can incorporate individual user inputs and contextual information, enhancing the personalization and relevance of generated text.
LaMP-5	https://doi.org/10.1007/978-3-031-88714-7_40 (2025)	https://doi.org/10.48550/arXiv.2304.11406 (2023)	The LaMP-5 dataset is used to evaluate personalized text generation, specifically focusing on the integration of user preferences and context within large language models. This dataset enables researchers to assess how well these models can incorporate individual user inputs and contextual information, enhancing the personalization and relevance of generated text.
LaMP-7	https://doi.org/10.1007/978-3-031-88714-7_40 (2025)	https://doi.org/10.48550/arXiv.2304.11406 (2023)	The LaMP-7 dataset is used to evaluate personalized text generation, specifically focusing on the integration of user preferences and context. Researchers employ this dataset to assess how well models can incorporate these elements, enhancing the relevance and personalization of generated text. This evaluation helps in refining algorithms to better align with user-specific needs and contexts.
BookCorpus	https://doi.org/10.54254/2755-2721/97/20241406 (2024)	https://doi.org/10.1109/ICCV.2015.11 (2015)	The BookCorpus dataset is used to train models in understanding narrative structures and generating story-like text. It provides extensive textual content that enables researchers to develop and evaluate algorithms capable of producing coherent and contextually appropriate narratives. This dataset supports research focused on enhancing the narrative coherence and creativity of generated text, making it valuable for studies in natural language processing and computational creativity.
English Wikipedia	https://doi.org/10.54254/2755-2721/97/20241406 (2024)	https://doi.org/10.1109/ICCV.2015.11 (2015)	The English Wikipedia dataset is utilized as a vast repository of factual information and diverse writing styles to enhance the breadth and depth of generated text. It provides a rich source of content that improves the quality and variety of text generation, supporting research in natural language processing and machine learning models.
Amazon	https://doi.org/10.1145/3696410.3714583 (2024)		The Amazon dataset is used to construct a dataset for personalized text generation, specifically focusing on user reviews across various product categories. This involves leveraging the textual content and user-specific information to develop models that can generate personalized text. The dataset's diverse range of product categories and rich user review data enable researchers to explore and enhance personalized text generation techniques.
Facescape	https://doi.org/10.1145/3664647.3680861 (2024)		The Facescape dataset is used to provide high-resolution 3D facial UV-texture data, which is specifically employed to enhance personalized text generation. This dataset enables researchers to focus on detailed facial textures, improving the realism and personalization of generated text. The high-resolution characteristic of the dataset is crucial for achieving fine-grained detail in facial representations, thereby enhancing the quality of personalized text outputs.
FFHQ-UV	https://doi.org/10.1145/3664647.3680861 (2024)		The FFHQ-UV dataset is used to provide high-resolution 3D facial UV-texture data, specifically for enhancing personalized text generation. It focuses on detailed facial textures, which are crucial for improving the realism and personalization of generated text. This dataset enables researchers to develop more sophisticated models that can incorporate fine-grained facial details, thereby enhancing the overall quality and personalization of text outputs.
Grammar and Online Product dataset	https://doi.org/10.48550/arXiv.2501.02157 (2025)		The Grammar and Online Product dataset is used to study stylistic variation across multiple platforms and domains. Researchers employ this dataset to analyze how platform and domain influence text style, using it to explore the impact of these factors on linguistic and stylistic choices in online content. This dataset enables a comparative analysis of text styles, providing insights into how different contexts shape language use.
Datafiniti Product Database on Grammar and Online Product Reviews	https://doi.org/10.48550/arXiv.2501.02157 (2025)		The Datafiniti Product Database on Grammar and Online Product Reviews is used to analyze grammar and sentiment in online product reviews. Researchers focus on personalized text generation techniques and user-specific language patterns, employing methodologies that examine how language varies across different users. This dataset enables detailed analysis of linguistic features and their application in generating personalized text.
Datafiniti Products dataset	https://doi.org/10.48550/arXiv.2501.02157 (2025)		The Datafiniti Products dataset is primarily used as a source for constructing new datasets, specifically focusing on product information and attributes. This dataset enables researchers to compile detailed product data, which is then utilized for developing and training models in personalized text generation. The dataset's rich attribute information facilitates the creation of more contextually relevant and personalized text outputs.
train-clean-100 subset of LibriTTS	https://doi.org/10.48550/arXiv.2410.13342 (2024)	https://doi.org/10.21437/interspeech.2019-2441 (2019)	The train-clean-100 subset of LibriTTS is primarily used for training text-to-speech (TTS) models, leveraging its clean audio data. This dataset enables researchers to develop TTS systems that produce high-quality, natural-sounding speech. The focus on clean audio enhances model performance, making it suitable for applications requiring clear and intelligible speech synthesis.
L2-ARCTIC dataset	https://doi.org/10.48550/arXiv.2410.13342 (2024)	https://doi.org/10.21437/interspeech.2019-2441 (2019)	The L2-ARCTIC dataset is used for training text-to-speech (TTS) models, particularly focusing on non-native speakers to enhance cross-lingual synthesis. This dataset enables researchers to develop TTS systems that better accommodate and improve the speech quality for individuals speaking a second language, addressing the specific challenges and nuances of non-native pronunciation and intonation.
Amazon 5-core	https://www.semanticscholar.org/paper/fb394896bf1b31183839c766afc62dd251a7b9b7 (2021)	https://doi.org/10.1145/2766462.2767755 (2015)	The Amazon 5-core dataset is used to build datasets for personalized text generation, specifically focusing on user-generated reviews and metadata from May 1996 to July 2014, ensuring no duplicates. This dataset enables researchers to analyze and generate personalized text content based on historical review data, enhancing the understanding of user preferences and behaviors over time.
CMCC	https://doi.org/10.48550/arXiv.2502.08972 (2025)	https://www.semanticscholar.org/paper/2abe6b9ea1b13653b7384e9c8ef14b0d87e20cfc (2004)	The CMCC dataset is used for analyzing emails and essays on controversial topics written by students, focusing on authorship and content analysis. Researchers employ methodologies that involve examining the textual content and stylistic features to understand authorship attributes and thematic elements. This dataset enables detailed studies into how students express opinions and arguments on contentious issues, providing insights into educational and psychological aspects of writing.
Electronics dataset	https://www.semanticscholar.org/paper/fb394896bf1b31183839c766afc62dd251a7b9b7 (2021)	https://doi.org/10.3115/1073083.1073135 (2002)	The Electronics dataset is used to evaluate the performance of text generation models on electronics-related content. Researchers focus on measuring the quality of generated sentences using ROUGE scores, which assess the overlap between machine-generated and reference texts. This dataset enables the assessment of model accuracy and coherence in generating electronics-specific text.
BeerAdvocate	https://doi.org/10.1145/3404835.3462939 (2021)	https://doi.org/10.1109/ICDM.2012.110 (2012)	The BeerAdvocate dataset is used to generate personalized beer reviews by leveraging user-specific attributes and attitudes extracted from multi-aspect reviews. This involves analyzing detailed review data to capture individual preferences and sentiments, enabling the creation of tailored content that reflects users' unique perspectives and experiences with different beers.
Yelp6	https://doi.org/10.1145/3580305.3599535 (2022)	https://doi.org/10.1145/2488388.2488466 (2013)	The Yelp6 dataset is used for evaluating models in personalized text generation, specifically focusing on restaurant reviews. Researchers employ this dataset to assess the model's ability to generate contextually relevant and personalized content, emphasizing the accuracy and relevance of the generated text in a restaurant review context.
Wikipedia	https://doi.org/10.1145/3580305.3599535 (2022)	https://doi.org/10.1145/2488388.2488466 (2013)	The Wikipedia dataset is used as a pre-training corpus to ensure fair comparisons with baseline models, focusing on general language understanding and generation tasks. It provides a large, diverse text corpus that supports initial model training, enabling researchers to establish robust foundational models before fine-tuning on more specific datasets. This approach facilitates consistent performance evaluations across different studies.
one-billion-words dataset	https://doi.org/10.1145/3580305.3599535 (2022)	https://doi.org/10.18653/v1/N19-1423 (2019)	The one-billion-words dataset is primarily used to fine-tune the BERT-large model for downstream tasks, which enhances the model's performance in personalized text generation. This dataset provides a large corpus of text that is essential for improving the contextual understanding and generative capabilities of the model.
review-generation datasets in the restaurant domain	https://doi.org/10.48550/arXiv.2408.09865 (2024)	https://doi.org/10.1145/3340531.3411992 (2020)	The review-generation datasets in the restaurant domain are used to enhance the quality of aspect terms and label associated aspect categories, which improves the generation of neural template explanations for recommendation systems. This methodology focuses on refining the textual content to provide more accurate and contextually relevant recommendations. The dataset's inclusion of high-quality aspect terms and labeled categories enables researchers to develop more sophisticated and nuanced recommendation algorithms.
Twitter data	https://doi.org/10.58729/1941-6679.1460 (2021)	https://doi.org/10.2307/2087772 (1982)	The Twitter data dataset is used to gather personal information for personalized text generation, specifically focusing on user attitudes and behaviors expressed in tweets. This involves analyzing tweet content to understand individual user perspectives and actions, which is then utilized to tailor text generation models to reflect these personal attributes.
SQUAD 2	https://doi.org/10.1109/ICAC3N56670.2022.10074067 (2022)	https://www.semanticscholar.org/paper/7a064df1aeada7e69e5173f7d4c8606f4470365b (2019)	The SQUAD 2 dataset is primarily used to fine-tune models for question answering tasks, enhancing their contextual understanding. It is employed in research focused on improving the performance of models in generating accurate and contextually relevant answers. This dataset enables researchers to address specific challenges in natural language processing, particularly in the domain of question answering, by providing a large set of context-question-answer triples.
OP-I-MISTRAL	https://doi.org/10.48550/arXiv.2503.00449 (2025)	https://doi.org/10.48550/arXiv.2402.11683 (2024)	The OP-I-MISTRAL dataset is used to evaluate opinion summaries generated by large language models (LLMs), specifically focusing on aspect coverage and sentiment consistency. Researchers employ this dataset to assess the quality and reliability of LLM-generated summaries, ensuring they accurately reflect the opinions and sentiments present in the source data. This evaluation helps in refining and improving the performance of LLMs in generating coherent and comprehensive opinion summaries.
DailyDialog	https://www.semanticscholar.org/paper/3708ed2aa909ebde32647257f5ffb3c6548b0e8d (2021)	https://www.semanticscholar.org/paper/3108f96f80d129036f53684344f4058257b37c4b (2017)	The DailyDialog dataset is used to train and evaluate personalized text generation models, particularly for multi-turn empathetic conversations. It enables researchers to develop and assess models that can generate contextually appropriate and emotionally responsive dialogues, enhancing the naturalness and effectiveness of conversational agents.
Melon Playlist Dataset	https://doi.org/10.48550/arXiv.2301.08145 (2023)	https://www.semanticscholar.org/paper/c6c734e16f66fbfcefac7625cc64599e83292c1e (2020)	The Melon Playlist Dataset is used to evaluate the KLEU RoberTa small model for generating playlist titles. Research focuses on the effectiveness of the model's embeddings in producing diverse and relevant titles, highlighting the dataset's utility in assessing natural language generation techniques for music playlists.
Million Playlist Dataset	https://doi.org/10.48550/arXiv.2301.08145 (2023)	https://www.semanticscholar.org/paper/c6c734e16f66fbfcefac7625cc64599e83292c1e (2020)	The Million Playlist Dataset is used to evaluate models, such as all-MiniLM-L6-v2, for generating playlist titles. Research focuses on assessing the model's ability to produce diverse and contextually appropriate titles. The dataset's large scale and rich metadata enable comprehensive performance evaluations, ensuring that generated titles are both relevant and varied.
Dress Code	https://doi.org/10.48550/arXiv.2504.14011 (2025)	https://doi.org/10.1109/CVPRW56347.2022.00243 (2022)	The 'Dress Code' dataset is used to conduct experiments on virtual try-on, specifically focusing on high-resolution multi-category image pairs. This dataset enhances personalized text generation by providing detailed visual data, enabling researchers to explore and improve the integration of visual and textual information in virtual fashion applications.
MSR-VTT	https://doi.org/10.48550/arXiv.2502.02885 (2025)	https://doi.org/10.1109/CVPR.2016.571 (2016)	The MSR-VTT dataset is used to train and evaluate models that generate personalized text descriptions of video content. It focuses on the relationship between visual and textual information, enabling researchers to develop and test methods that accurately capture and describe the content of videos in a personalized manner.
amazon.com user reviews	https://www.semanticscholar.org/paper/28a70871ef06acda945b95ac6e4a7a5fbe58528d (2014)	https://doi.org/10.1145/1341531.1341560 (2008)	The 'amazon.com user reviews' dataset is used to study user review patterns and sentiment, particularly focusing on product feedback. It is employed in research aimed at understanding and generating personalized text. The dataset's rich textual content and diverse product categories enable detailed analysis of user sentiments and feedback, facilitating the development of more nuanced and contextually appropriate text generation models.
ratebeer.com user reviews	https://www.semanticscholar.org/paper/28a70871ef06acda945b95ac6e4a7a5fbe58528d (2014)	https://doi.org/10.1145/1341531.1341560 (2008)	The 'ratebeer.com user reviews' dataset is used to analyze beer reviews, focusing on taste and experience descriptions. This analysis employs natural language processing techniques to generate personalized recommendations. The dataset's rich textual content, detailing user experiences and preferences, enables researchers to develop models that can suggest beers tailored to individual tastes.
Home	https://doi.org/10.1145/3404835.3462854 (2021)	https://doi.org/10.1609/AAAI.V33I01.33016690 (2019)	The 'Home' dataset is used to evaluate the limitations of the USN model in personalized review summarization. Researchers employ this dataset to identify and analyze areas where the model's performance is suboptimal, focusing on specific challenges in generating accurate and contextually relevant summaries. This dataset enables a detailed assessment of model weaknesses, facilitating targeted improvements in personalized text generation.
Movie	https://doi.org/10.1145/3404835.3462854 (2021)	https://doi.org/10.1609/AAAI.V33I01.33016690 (2019)	The Movie dataset is used to evaluate the performance of the USN model in personalized review summarization, specifically focusing on user-aware sequence networks. This involves analyzing user-specific patterns in reviews to generate more accurate and personalized summaries. The dataset's user-centric nature enables researchers to test and improve models that can capture individual preferences and writing styles, enhancing the effectiveness of personalized text generation in review contexts.
PPDB	https://doi.org/10.18653/v1/W19-8634 (2019)	https://doi.org/10.18653/v1/P16-2024 (2016)	The PPDB dataset is used in research to evaluate substitution candidates, enabling a clear comparison between different methods, particularly focusing on simplicity-based approaches. Its extensive substitution options facilitate this evaluation, making it a valuable resource for refining and assessing text simplification techniques.
personalized CWI dataset	https://doi.org/10.18653/v1/W19-8634 (2019)	https://doi.org/10.18653/v1/P16-2024 (2016)	The personalized CWI dataset is used to refine substitution candidate rankings in personalized text generation by excluding non-complex target words and removing complex substitution candidates tailored to individual users. This approach enhances the relevance and appropriateness of text substitutions, addressing the specific needs and preferences of each user. The dataset's focus on personalization and complexity filtering enables more effective and user-specific text generation research.
Google Web Trillion Word Corpus	https://doi.org/10.18653/v1/W19-8634 (2019)		The Google Web Trillion Word Corpus is used to sort words by frequency, which supports the methodology of grouping words for personalized text generation. This dataset enables researchers to systematically organize and analyze word frequencies, facilitating more nuanced and contextually appropriate text generation models.
Simple PPDB	https://doi.org/10.18653/v1/W19-8634 (2019)	https://doi.org/10.18653/v1/P16-2024 (2016)	The Simple PPDB dataset is used as a reference for paraphrase simplification in research, not for simplicity ranking due to its non-overlapping word pairs. It provides a benchmark for evaluating simplification techniques, enabling researchers to compare and refine methods for generating simpler paraphrases.
Huffington Post articles	https://doi.org/10.48550/arXiv.2304.11406 (2023)	https://doi.org/10.48550/arXiv.2209.11429 (2022)	The Huffington Post articles dataset is used to create a categorized dataset for personalized text generation, specifically focusing on classifying news articles into various topics. This involves employing methodologies that categorize and label articles, enabling research into how different topics can be identified and utilized in personalized text generation systems.
Sports	https://doi.org/10.1145/3626772.3657821 (2024)		The 'Sports' dataset is used to evaluate personalized text generation models, specifically focusing on sports-related content and user preferences. This involves assessing how well these models can generate text that aligns with individual user interests and contexts within the sports domain. The dataset enables researchers to test and refine algorithms that enhance personalization in text generation, ensuring the content is relevant and engaging for users.
Toys	https://doi.org/10.1145/3626772.3657821 (2024)		The 'Toys' dataset is used to evaluate personalized text generation models, specifically focusing on toy-related content and user preferences. Researchers employ this dataset to assess how well these models can generate text that aligns with individual user interests and preferences in the context of toys. This evaluation helps in refining algorithms to better personalize text outputs for users.
ForumSum	https://doi.org/10.48550/arXiv.2308.07968 (2023)	https://doi.org/10.18653/v1/N19-1260 (2018)	The ForumSum dataset is utilized in research to generate summaries from forum discussions, focusing on capturing key points in user-generated content. This involves employing natural language processing techniques to distill essential information, enabling researchers to address the challenge of summarizing diverse and unstructured online conversations effectively.
Reddit TIFU-long	https://doi.org/10.48550/arXiv.2308.07968 (2023)	https://doi.org/10.18653/v1/N19-1260 (2018)	The Reddit TIFU-long dataset is used for narrative summarization of long-form Reddit posts from the 'TIFU' subreddit. Researchers apply this dataset to develop and evaluate summarization models, focusing on capturing the essence of personal stories and incidents. The dataset's long-form nature and narrative structure enable the testing of summarization techniques on complex, real-world text.
persona attribute triplet extraction dataset	https://doi.org/10.18653/v1/2023.acl-long.544 (2023)	https://doi.org/10.18653/v1/P19-1363 (2018)	The persona attribute triplet extraction dataset is used to enhance personalized text generation by extracting persona attributes from dialogues. Researchers employ triplet annotations to identify and structure these attributes, which are then utilized to improve the personalization and coherence of generated text. This dataset specifically supports methodologies focused on annotating and utilizing persona information to enrich dialogue systems.
Dialogue NLI	https://doi.org/10.18653/v1/2023.acl-long.544 (2023)	https://doi.org/10.18653/v1/P19-1363 (2018)	The Dialogue NLI dataset is used to construct the PersonaExt dataset, which provides natural language inference examples in dialogue contexts. This supports research in personalized text generation by offering structured data that enhances the understanding and generation of contextually appropriate and personalized responses.
Dialogue Natural Language Inference (NLI) dataset	https://doi.org/10.18653/v1/2023.acl-long.544 (2023)	https://doi.org/10.18653/v1/P19-1363 (2018)	The Dialogue Natural Language Inference (NLI) dataset is primarily used for training models to understand and generate dialogue, focusing on natural language inference tasks. It serves as a foundational resource, enabling researchers to develop models that can accurately infer relationships between utterances in dialogues. This dataset supports the enhancement of dialogue understanding and generation capabilities, crucial for advancing conversational AI systems.
