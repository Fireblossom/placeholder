Name (extracted)	Citing Article	Citied Article	Features
Urban100	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/ICCVW54120.2021.00210 (2021), https://doi.org/10.1109/CVPR52688.2022.00564 (2021) (+36)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The Urban100 dataset is primarily used to evaluate image restoration methods, particularly in urban scenes. It focuses on assessing the performance of GAN-based super-resolution and denoising algorithms using metrics like PSNR and LPIPS. The dataset emphasizes architectural details, textures, and fine details, making it suitable for testing under various noise levels and conditions such as rain, blur, and low light.
GoPro	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1007/978-3-031-20071-7_4 (2021), https://doi.org/10.1109/CVPRW53098.2021.00027 (2021) (+32)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The GoPro dataset is primarily used for training and testing image deblurring models, particularly focusing on motion blur. It consists of paired blurred and sharp images, enabling researchers to develop and evaluate algorithms that restore image clarity. The dataset is widely used in the context of dynamic scene deblurring, providing a benchmark for assessing restoration quality under various motion blur conditions. It supports the development of deep learning models, such as multi-scale convolutional neural networks, and is crucial for improving image clarity in both static and video sequences.
Rain100L	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.48550/arXiv.2405.02843 (2024), https://doi.org/10.1109/CVPR52688.2022.01693 (2022) (+26)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The Rain100L dataset is primarily used for testing and evaluating rain removal algorithms, with a focus on both light and heavy rain conditions. It is employed in training and assessing deraining techniques, particularly for low-resolution images with synthetic rain. The dataset includes 100 pairs of original and rainy images, enabling researchers to measure restoration quality using metrics like PSNR and SSIM. It serves as a benchmark for single-task deraining, evaluating the effectiveness and performance of various methods.
DIV2K	https://doi.org/10.48550/arXiv.2306.05390 (2023), https://doi.org/10.48550/arXiv.2210.01427 (2022), https://doi.org/10.48550/arXiv.2405.02843 (2024) (+28)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The DIV2K dataset is primarily used for training and evaluating models in single image super-resolution, image denoising, and compression artifact reduction. It provides high-quality images that enhance restoration performance, focusing on improving image resolution, quality, and reducing artifacts. Models like COLA-Net and SwinIR are trained using this dataset to achieve better results in these tasks, particularly at various scale factors.
BSD68	https://doi.org/10.1109/CVPR52688.2022.01693 (2022), https://doi.org/10.1007/s11263-023-01843-5 (2023), https://doi.org/10.1109/TPAMI.2021.3088914 (2020) (+26)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The BSD68 dataset is primarily used for evaluating image denoising and restoration algorithms. It focuses on performance metrics under controlled conditions, particularly at noise levels σ=15, σ=25, and σ=50. The dataset includes a diverse set of natural images, some with human-segmented annotations, which allows researchers to test the robustness and generalization capabilities of their methods. It is used to assess both grayscale and color image denoising, emphasizing the performance of algorithms across varying complexities and noise intensities.
WED	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/CVPR52688.2022.01693 (2022), https://doi.org/10.48550/arXiv.2410.08688 (2024) (+24)	https://doi.org/10.1109/TIP.2016.2631888 (2017)	The WED dataset is primarily used for training and evaluating image restoration models, focusing on various degradations such as rain, noise, blur, and low-light conditions. It provides 4,744 high-quality images, enabling researchers to assess and enhance model performance in removing watermarks, denoising, and restoring images under multiple degradation scenarios. The dataset serves as a benchmark for testing the robustness and effectiveness of image restoration techniques, particularly in challenging conditions.
Set5	https://doi.org/10.1109/ICCVW54120.2021.00210 (2021), https://doi.org/10.1109/CVPRW.2018.00121 (2018), https://doi.org/10.48550/arXiv.2210.01427 (2022) (+15)	https://doi.org/10.1007/978-3-642-27413-8_47 (2010)	The Set5 dataset is primarily used to evaluate super-resolution methods, focusing on performance metrics such as PSNR, SSIM, and LPIPS. It is employed to assess the quality and effectiveness of GAN-based and low-complexity single-image super-resolution techniques, particularly in enhancing image resolution at various scaling factors. The dataset also tests the generalization ability of networks on images with blended distortions and different resolutions, contributing to the broader field of image restoration.
Set14	https://doi.org/10.1109/CVPRW.2018.00121 (2018), https://doi.org/10.1109/ICCVW54120.2021.00210 (2021), https://www.semanticscholar.org/paper/cbd65255f6266f798326acc8e0654e40ea0918cf (2018) (+15)	https://doi.org/10.1007/978-3-642-27413-8_47 (2010)	Set14 is primarily used to evaluate image super-resolution and restoration methods, focusing on performance metrics such as PSNR, SSIM, and LPIPS. It is employed to assess the quality and perceptual similarity of restored images, particularly in GAN-based and sparse-representation techniques. The dataset enables researchers to compare and validate the effectiveness of different super-resolution approaches, emphasizing high-quality image restoration and low-complexity methods.
BSD400	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/CVPR52688.2022.01693 (2022), https://doi.org/10.48550/arXiv.2312.05038 (2023) (+19)	https://doi.org/10.1109/TIP.2016.2631888 (2017)	The BSD400 dataset is primarily used for training and evaluating image restoration models, with a focus on denoising, deblurring, and addressing various degradations such as rain, haze, noise, blur, and low-light conditions. It provides 400 high-quality, diverse images that enhance model performance and robustness, serving as a benchmark for assessing restoration quality.
HIDE	https://www.semanticscholar.org/paper/6af728164e4424218967fd356b3448f5037acd88 (2023), https://doi.org/10.1007/978-3-031-20071-7_4 (2021), https://doi.org/10.1109/TPAMI.2023.3330416 (2023) (+14)	https://doi.org/10.1109/ICCV.2019.00567 (2019)	The HIDE dataset is primarily used for evaluating and comparing image restoration models, particularly in the areas of deblurring and denoising. It features a large collection of high-resolution images with varying degrees of blur and noise, enabling researchers to assess model performance on diverse and challenging real-world scenarios. The dataset supports the evaluation of techniques such as DiffIR, human-aware motion deblurring, and the Test-time Local Converter, focusing on robustness, generalization, and reducing train-test inconsistencies. It also facilitates numerical comparisons and performance metrics in dynamic scene deblurring and synthetic image deblurring, providing realistic blur synthesis for both training and testing.
Rain100H	https://doi.org/10.1109/TMM.2024.3407656 (2024), https://www.semanticscholar.org/paper/6af728164e4424218967fd356b3448f5037acd88 (2023), https://doi.org/10.48550/arXiv.2503.10120 (2025) (+12)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The Rain100H dataset is primarily used for training and evaluating rain removal algorithms, particularly focusing on high-resolution images with heavy and synthetic rain. It assesses the performance of deraining methods using metrics like PSNR and SSIM, emphasizing the effectiveness in removing rain streaks and preserving image details. This dataset enables researchers to test and improve deraining techniques in challenging rain conditions.
LOL	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.48550/arXiv.2503.10120 (2025), https://doi.org/10.48550/arXiv.2310.10123 (2023) (+11)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The LOL dataset is primarily used for evaluating low-light image enhancement methods, focusing on improving visibility, color fidelity, and overall image quality in dark conditions. It serves as a benchmark for assessing restoration techniques and contains low-light and normal-light image pairs, enabling researchers to test and compare the performance of various enhancement algorithms.
ImageNet	https://doi.org/10.48550/arXiv.2412.00878 (2024), https://doi.org/10.1109/CVPR52729.2023.00958 (2023), https://doi.org/10.48550/arXiv.2306.02342 (2023) (+14)	https://doi.org/10.1109/CVPR.2009.5206848 (2009)	ImageNet is used in research to evaluate and improve image restoration techniques, including super-resolution and deblurring. It serves as a pre-training dataset for models like diffusion models and vision transformers, enhancing their performance in image restoration tasks. The dataset's large-scale, diverse, and high-quality images provide a robust foundation for training and validating these models, enabling researchers to achieve better restoration outcomes and richer semantic representations.
SIDD	https://doi.org/10.1109/CVPRW53098.2021.00027 (2021), https://doi.org/10.48550/arXiv.2203.06074 (2022), https://doi.org/10.1109/CVPR52688.2022.00564 (2021) (+8)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The SIDD dataset is primarily used for denoising experiments, particularly focusing on real-world noise reduction in smartphone camera images. It is employed to train and evaluate denoising algorithms, providing a benchmark for assessing restoration quality and performance metrics such as PSNR. The dataset's high-quality, real-world noisy images enable researchers to test and improve denoising techniques, enhancing image fidelity and addressing specific noise patterns found in smartphone cameras.
Manga109	https://doi.org/10.1109/ICCVW54120.2021.00210 (2021), https://doi.org/10.48550/arXiv.2210.01427 (2022), https://doi.org/10.1007/978-3-030-58523-5_36 (2020) (+11)	https://doi.org/10.1007/978-3-642-27413-8_47 (2010)	The Manga109 dataset is primarily used for evaluating image restoration and super-resolution methods, particularly in manga images. Researchers employ this dataset to assess the performance of various techniques using metrics such as PSNR, SSIM, and LPIPS, focusing on image quality, perceptual similarity, and character detail preservation. The dataset enables the evaluation of models' generalization abilities on images with blended distortions and different resolutions, as well as the effectiveness of low-complexity super-resolution methods.
Snow100K	https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.48550/arXiv.2409.00263 (2024) (+14)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Snow100K dataset is primarily used for training and evaluating snow removal algorithms, focusing on synthetic snow images. It is utilized to assess the performance of various models, including hierarchical dual-tree complex wavelet representation, context-aware deep networks, and OneRestore, on tasks such as single image desnowing and restoring underlying scene details. The dataset's large size, particularly its 50,000 paired images in the test split, enables robust training and evaluation of these image restoration techniques.
SOTS	https://doi.org/10.24963/ijcai.2024/80 (2024), https://doi.org/10.48550/arXiv.2312.05038 (2023), https://doi.org/10.48550/arXiv.2410.08688 (2024) (+11)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The SOTS dataset is primarily used for evaluating and benchmarking single-image dehazing algorithms. It consists of 500 outdoor images and is utilized to test the performance and effectiveness of dehazing techniques, both in synthetic and real-world conditions. Researchers use it to compare their proposed methods against state-of-the-art algorithms, focusing on metrics like PSNR and visual quality improvements. The dataset's controlled conditions and ground truth data enable rigorous quantitative analysis and validation of dehazing models.
RESIDE	https://doi.org/10.48550/arXiv.2308.09388 (2023), https://doi.org/10.48550/arXiv.2409.19403 (2024), https://doi.org/10.1109/CVPR52688.2022.01693 (2022) (+18)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The RESIDE dataset is primarily used for training and evaluating single-image dehazing models. It includes diverse indoor and outdoor scenes, synthetic daytime scenes, and paired images, which are crucial for benchmarking performance across various weather conditions. The dataset enables researchers to focus on improving image clarity, color fidelity, and overall quality in hazy conditions, making it a valuable resource for dehazing research.
Kodak24	https://doi.org/10.1007/s11263-023-01843-5 (2023), https://doi.org/10.48550/arXiv.2405.02843 (2024), https://doi.org/10.1109/CVPR52688.2022.00564 (2021) (+10)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The Kodak24 dataset is primarily used for evaluating image denoising and restoration algorithms. It provides a standard set of high-quality images for both visual and quantitative assessments, focusing on color fidelity and detail preservation. Researchers use it to test and compare the effectiveness of their methods, often under controlled conditions, and to measure performance using established image quality metrics.
CSD	https://doi.org/10.24963/ijcai.2024/80 (2024), https://doi.org/10.1109/TPAMI.2023.3330416 (2023), https://doi.org/10.1109/TCSVT.2024.3429557 (2024) (+10)	https://doi.org/10.1109/ICCV48922.2021.00416 (2021)	The CSD dataset is primarily used for training and evaluating image restoration algorithms, particularly focusing on desnowing and deraining tasks. It provides a diverse set of images with various weather degradations, enabling researchers to assess the effectiveness of models in removing rain, snow, and other weather-related distortions. The dataset supports the development and comparison of algorithms by offering realistic scenarios and facilitating the evaluation of performance metrics such as PSNR and model complexity.
Flickr2K	https://doi.org/10.48550/arXiv.2306.05390 (2023), https://doi.org/10.48550/arXiv.2210.01427 (2022), https://doi.org/10.48550/arXiv.2402.15648 (2024) (+10)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The Flickr2K dataset is primarily used for training and enhancing image restoration models, particularly in single image super-resolution and image denoising. It provides a large, diverse set of high-quality images that improve model robustness and generalization. The dataset supports various methodologies, including training models for specific tasks like Gaussian denoising and enhancing image quality at different scales (x4 and x8). Its extensive and varied image content enables researchers to develop more effective and versatile image restoration techniques.
LIVE1	https://doi.org/10.1109/CVPRW63382.2024.00645 (2024), https://doi.org/10.1109/CVPR.2019.01131 (2019), https://doi.org/10.48550/arXiv.2210.00405 (2022) (+8)	https://doi.org/10.1109/TIP.2006.881959 (2006)	The LIVE1 dataset is primarily used for evaluating the performance of image restoration methods, including artifact removal, denoising, and deblocking of both grayscale and color images. It is employed to assess perceptual quality and distortion types, particularly under JPEG compression at various quality factors. The dataset, consisting of real-world images with diverse content, enables researchers to test and compare restoration algorithms using metrics like PSNR, focusing on high-quality restoration and super resolution. It also serves as a benchmark for full-reference image quality assessment algorithms.
BSD100	https://doi.org/10.1109/ICCVW54120.2021.00210 (2021), https://www.semanticscholar.org/paper/cbd65255f6266f798326acc8e0654e40ea0918cf (2018), https://doi.org/10.1109/CVPRW.2018.00121 (2018) (+6)	https://doi.org/10.1007/978-3-642-27413-8_47 (2010)	The BSD100 dataset is primarily used for evaluating image super-resolution methods, focusing on performance metrics such as PSNR and SSIM at various upscaling factors (×2, ×3, and ×4). It is employed to assess the quality and effectiveness of single-image super-resolution techniques, enabling researchers to compare and validate their methods against established benchmarks.
Rain800	https://doi.org/10.48550/arXiv.2404.12091 (2024), https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.48550/arXiv.2306.05390 (2023) (+3)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The Rain800 dataset is primarily used for training and evaluating rain removal algorithms, particularly focusing on both synthetic and real-world rainy images with varying densities. It is employed to assess the deraining capabilities of models like AIRFormer, DGUNet, and CoIC, emphasizing their performance in handling diverse rain conditions and improving the quality of restored images. The dataset's high-quality images and ground truth data enable researchers to rigorously test and refine deraining techniques.
Test100	https://www.semanticscholar.org/paper/6af728164e4424218967fd356b3448f5037acd88 (2023), https://doi.org/10.1109/TMM.2024.3407656 (2024), https://doi.org/10.1109/TPAMI.2024.3419007 (2024) (+7)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The Test100 dataset is primarily used for evaluating image de-raining methods, focusing on performance metrics such as PSNR and visual quality. It is employed to test the generalization and robustness of deraining algorithms, including conditional generative adversarial networks, on a smaller set of diverse rainy images. This dataset enables researchers to compare and assess the effectiveness of different deraining techniques, providing insights into model accuracy and reliability.
Test2800	https://doi.org/10.1109/TMM.2024.3407656 (2024), https://www.semanticscholar.org/paper/6af728164e4424218967fd356b3448f5037acd88 (2023), https://doi.org/10.1109/CVPRW53098.2021.00027 (2021) (+6)	https://doi.org/10.1109/CVPR.2017.186 (2017)	The Test2800 dataset is primarily used for evaluating and training deraining methods, containing a large set of synthetic rainy images. It is employed to assess the performance of restoration algorithms using metrics like PSNR and SSIM, focusing on the effectiveness of techniques such as conditional generative adversarial networks. The dataset supports comprehensive benchmarking, scalability testing, and validation of model robustness and generalization across diverse image conditions.
Rain200L	https://doi.org/10.48550/arXiv.2404.12091 (2024), https://doi.org/10.48550/arXiv.2203.06074 (2022), https://doi.org/10.1109/CVPR52733.2024.00277 (2023) (+3)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The Rain200L dataset is primarily used for training and evaluating rain removal methods, particularly focusing on low-resolution images with synthetic rain and light rain conditions. It is employed to assess the performance of deraining algorithms, emphasizing the removal of rain streaks to improve image clarity and visual quality. The dataset facilitates the evaluation of PSNR improvements and algorithm robustness in handling low-complexity rain patterns.
CBSD68	https://doi.org/10.48550/arXiv.2407.20928 (2024), https://doi.org/10.1109/TPAMI.2021.3088914 (2020), https://doi.org/10.48550/arXiv.2310.10123 (2023) (+12)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The CBSD68 dataset is primarily used for evaluating image denoising performance, particularly in natural images with complex textures and structures. It is employed to test and benchmark various denoising algorithms, including those focused on synthetic noisy images with varying noise levels. The dataset supports research by providing human-segmented images, enabling detailed comparisons of PSNR values and restoration quality across different methods and noise conditions.
Test1200	https://doi.org/10.1109/TMM.2024.3407656 (2024), https://www.semanticscholar.org/paper/6af728164e4424218967fd356b3448f5037acd88 (2023), https://doi.org/10.1109/CVPRW53098.2021.00027 (2021) (+5)	https://doi.org/10.1109/CVPR.2017.186 (2017)	The Test1200 dataset is primarily used for evaluating and validating deraining methods in image restoration. It contains a moderate to large set of images with synthetic rain, enabling researchers to assess the performance, robustness, and scalability of restoration algorithms using metrics like PSNR and SSIM. The dataset supports comprehensive evaluations of model generalization and consistency across diverse rainy conditions, making it suitable for comparing different deraining techniques and ensuring reliable performance in varied scenarios.
McMaster	https://doi.org/10.1109/CVPR52688.2022.00564 (2021), https://doi.org/10.48550/arXiv.2407.20928 (2024), https://doi.org/10.1109/TPAMI.2021.3088914 (2020) (+7)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The McMaster dataset is primarily used for evaluating image denoising and enhancement algorithms. It contains a diverse set of images, which are used to test and compare the performance of denoising methods under controlled conditions, particularly with additive white Gaussian noise. The dataset is also applied to assess texture and edge preservation in natural scenes, and it supports the evaluation of color image denoising at specific noise levels (15, 25, and 50). This diversity enables comprehensive testing and benchmarking of image restoration techniques.
RainDrop	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/TIP.2024.3368961 (2023), https://doi.org/10.1109/TCSVT.2023.3299324 (2024) (+6)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The RainDrop dataset is primarily used for training and evaluating raindrop removal algorithms, focusing on enhancing image clarity by removing raindrops from images. It includes both real and synthetic raindrop images, which are used to train models such as AttentiveGAN and other generative models. The dataset enables researchers to address the challenge of realistic raindrop effects, improving visibility and image quality in rainy conditions.
Rain200H	https://doi.org/10.48550/arXiv.2404.12091 (2024), https://doi.org/10.48550/arXiv.2203.06074 (2022), https://doi.org/10.1109/CVPR52733.2024.00277 (2023)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The Rain200H dataset is primarily used for training and evaluating rain removal methods, particularly focusing on high-resolution images with synthetic rain. It challenges de-raining techniques by including heavy rain conditions and high-complexity rain patterns. Researchers use it to assess and improve the performance of models in removing severe rain streaks, enhancing image clarity, and achieving specific metrics like PSNR improvements. The dataset is also utilized to train models like DGUNet, emphasizing the impact of rain-/detail-aware negative exemplars and plotting layer-wise log T lcc ′ for performance evaluation.
Rain13K	https://doi.org/10.48550/arXiv.2306.05390 (2023), https://doi.org/10.1109/CVPRW53098.2021.00027 (2021), https://doi.org/10.48550/arXiv.2409.19403 (2024) (+3)	https://doi.org/10.1109/CVPR46437.2021.01458 (2021)	The Rain13K dataset is primarily used for deraining tasks, providing a large-scale collection of paired rainy and clean images. It is employed to train and evaluate deraining algorithms, focusing on diverse rain models and progressive image restoration techniques to improve the quality of rain removal. The dataset's extensive size and inclusion of both synthetic and real-world images enhance its utility in assessing the effectiveness of restoration methods.
RESIDE-OTS	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.48550/arXiv.2407.04621 (2024), https://doi.org/10.1109/TIV.2023.3347952 (2024)	https://doi.org/10.1007/978-3-031-72764-1_1 (2024)	The RESIDE-OTS dataset is primarily used to evaluate and assess dehazing and image restoration techniques, particularly for outdoor synthetic scenes. It focuses on evaluating the performance of dehazing algorithms, deraining methods, and all-in-one image restoration models under various degradations such as haze, rain, noise, blur, and low-light conditions. The dataset serves as a benchmark for quantitatively and qualitatively measuring the effectiveness of these techniques in improving image quality and clarity.
Classic5	https://doi.org/10.1007/s11263-023-01843-5 (2023), https://doi.org/10.48550/arXiv.2210.00405 (2022), https://doi.org/10.1109/ICCVW54120.2021.00210 (2021) (+4)	https://doi.org/10.1109/TIP.2007.891788 (2007)	The Classic5 dataset is primarily used to evaluate the performance of image restoration techniques, including denoising, deblocking, and super-resolution. It consists of five classic images and is employed to test methods under various conditions such as different noise levels, JPEG quality factors, and compression artifacts. Researchers use it to compare models like BNNs and deep CNNs, focusing on metrics like image quality and artifact reduction. The dataset's ground truth images enable precise performance assessment in these specific applications.
DPDD	https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.24963/ijcai.2024/80 (2024), https://doi.org/10.1109/TPAMI.2023.3330416 (2023) (+4)	https://doi.org/10.1007/978-3-030-58607-2_7 (2020)	The DPDD dataset is primarily used to evaluate and compare single-image defocus deblurring methods, focusing on performance metrics such as PSNR, MAE, and LPIPS. It is employed to assess the trade-offs between model complexity (number of parameters) and image quality, as well as to verify the effectiveness of proposed algorithms against established methods. The dataset supports both training and evaluation, particularly for high-resolution image restoration tasks.
GoPro dataset	https://doi.org/10.1007/978-3-031-20071-7_4 (2021), https://doi.org/10.48550/arXiv.2310.10123 (2023), https://doi.org/10.48550/arXiv.2301.11699 (2023) (+11)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The GoPro dataset is primarily used for evaluating and training deblurring algorithms, particularly in dynamic scenes with camera shake and motion blur. It features 2103 blurry/sharp image pairs for training and 1111 pairs for evaluation. Researchers use it to assess the performance of various models, including multi-scale convolutional neural networks, in tasks such as single-image and video deblurring, focusing on quantitative metrics like PSNR and visual quality improvements.
SOTS-Indoor	https://doi.org/10.1109/TPAMI.2024.3419007 (2024), https://doi.org/10.48550/arXiv.2305.17863 (2023), https://doi.org/10.1109/TPAMI.2023.3330416 (2023) (+6)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The SOTS-Indoor dataset is primarily used for evaluating and benchmarking single-image dehazing algorithms. It focuses on assessing the trade-offs between Peak Signal-to-Noise Ratio (PSNR) and computational efficiency (FLOPs). Researchers use this dataset to compare the performance of various models, such as FSNet-S, ConvIR-B, MB-TaylorFormer-L, DeHamer, OKNet, and DehazeFormer, in terms of dehazing effectiveness and computational complexity. The dataset is particularly useful for visual comparisons and performance evaluations in indoor synthetic daytime scenes, enabling detailed analysis of dehazing techniques.
Haze4K	https://doi.org/10.48550/arXiv.2305.17863 (2023), https://doi.org/10.1109/TPAMI.2024.3419007 (2024), https://doi.org/10.48550/arXiv.2308.09388 (2023) (+1)	https://doi.org/10.1145/3474085.3475331 (2021)	The Haze4K dataset is primarily used for evaluating and comparing dehazing algorithms, particularly in high-resolution synthetic and real-world images. It contains 4,000 hazy images, enabling researchers to assess the effectiveness, performance, and robustness of dehazing techniques in both daytime and nighttime conditions. The dataset supports visual comparisons and benchmarking, focusing on ultra-high-definition images and realistic synthetic haze conditions.
Dense-Haze	https://doi.org/10.48550/arXiv.2308.09388 (2023), https://doi.org/10.24963/ijcai.2024/80 (2024), https://doi.org/10.1109/TCSVT.2024.3429557 (2024) (+6)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The Dense-Haze dataset is primarily used for evaluating and benchmarking dehazing algorithms under real-world dense haze conditions. It consists of 33 pairs of outdoor hazy and haze-free images, which are utilized to assess the performance, robustness, and accuracy of dehazing methods. Researchers employ this dataset to compare algorithmic improvements, focusing on metrics like PSNR to measure image quality enhancement in challenging atmospheric scenarios.
Set12	https://doi.org/10.1109/CVPR52688.2022.00564 (2021), https://doi.org/10.48550/arXiv.2210.00405 (2022), https://doi.org/10.1109/TPAMI.2021.3088914 (2020) (+5)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	Set12 is primarily used for evaluating image denoising and restoration algorithms under controlled conditions. It focuses on a small set of high-quality, grayscale images to assess performance metrics such as PSNR and visual quality at specific noise levels (σ=15, σ=25, and σ=50). The dataset enables researchers to benchmark and compare denoising methods, emphasizing the accuracy and effectiveness of restoration techniques on synthetic benchmarks.
DND	https://doi.org/10.1109/CVPR52688.2022.00564 (2021), https://doi.org/10.48550/arXiv.2210.01427 (2022), https://doi.org/10.48550/arXiv.2211.13654 (2022) (+4)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The DND dataset is primarily used for real-world image denoising experiments, focusing on evaluating the effectiveness of denoising algorithms on diverse sets of real-world noisy images, particularly from digital photographs and smartphone cameras. It serves as a benchmark for testing and comparing various denoising models, including the IPT-V2 and ART models, under different conditions and parameter capacities. The dataset's real-world nature allows researchers to assess high-quality denoising performance and validate the superiority of new methods over existing state-of-the-art techniques.
BSD500	https://doi.org/10.1145/3528233.3530757 (2021), https://doi.org/10.48550/arXiv.2407.20928 (2024), https://doi.org/10.1109/TNNLS.2021.3131739 (2020) (+4)	https://doi.org/10.1109/TPAMI.2010.161 (2011)	The BSD500 dataset is primarily used for training and evaluating models in image restoration tasks, particularly focusing on image denoising and reducing JPEG compression artifacts. It provides a diverse set of natural images, which enhances the generalization and performance of restoration models. The dataset is also utilized to generate synthetic noisy images, contributing to comprehensive training sets and enabling robust model evaluation.
NHR	https://doi.org/10.24963/ijcai.2024/80 (2024), https://doi.org/10.1109/TPAMI.2023.3330416 (2023), https://doi.org/10.1109/TPAMI.2024.3419007 (2024) (+2)	https://doi.org/10.1145/3394171.3413763 (2020)	The NHR dataset is primarily used for evaluating and comparing nighttime image dehazing algorithms. It contains 16,146 training and 1,794 testing image pairs, providing both synthetic and real-world hazy images. Researchers use it to assess dehazing performance, focusing on techniques like high-low frequency decomposition, grayscale-color networks, and state-of-the-art models such as CSNet. The dataset enables detailed comparisons of various dehazing methods, particularly under low-light conditions, and supports the development of more effective nighttime image restoration techniques.
Outdoor-Rain	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/TPAMI.2023.3238179 (2022), https://doi.org/10.48550/arXiv.2305.17863 (2023) (+5)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The Outdoor-Rain dataset is primarily used for training and evaluating image restoration models focused on rain removal from outdoor scenes. It contains real-world outdoor rain images, which are utilized to test model robustness and performance in deraining tasks. The dataset supports methodologies such as physics models, conditional adversarial learning, and generative modeling with GANs, enabling researchers to enhance image quality and compare the effectiveness of different restoration techniques.
REDS	https://doi.org/10.48550/arXiv.2308.09388 (2023), https://doi.org/10.1109/CVPRW53098.2021.00027 (2021), https://doi.org/10.1109/TMM.2024.3407656 (2024) (+2)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The REDS dataset is primarily used for training and evaluating video deblurring methods, with a focus on handling realistic motion blur in video sequences. It is utilized to improve the representation capability of image restoration networks, particularly in addressing complex degradations such as motion blur and JPEG compression artifacts. The dataset enables researchers to assess performance metrics and validate the effectiveness of their models, including the 3× speedup in dynamic scene deblurring and the use of HIN in video deblurring.
SRRS	https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.1109/TPAMI.2023.3330416 (2023), https://www.semanticscholar.org/paper/6af728164e4424218967fd356b3448f5037acd88 (2023) (+3)	https://doi.org/10.1007/978-3-030-58589-1_45 (2020)	The SRRS dataset is primarily used for evaluating and training image desnowing models, focusing on the removal of snow from images. It employs methodologies such as hierarchical dual-tree complex wavelet representation, context-aware deep networks, and size and transparency-aware algorithms. The dataset is also used to assess the effectiveness of desnowing techniques in diverse and realistic image conditions, enhancing visual quality and performance.
RESIDE-SOTS	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/CVPR.2019.00717 (2019)	https://doi.org/10.1007/978-3-031-72764-1_1 (2024)	The RESIDE-SOTS dataset is primarily used to evaluate and benchmark image restoration techniques, particularly focusing on dehazing and deraining. It is utilized to assess the performance of algorithms in both real-world and synthetic outdoor scenes, emphasizing realistic haze removal and image quality. The dataset supports research by providing a standardized set of images with controlled degradations, enabling consistent evaluation of restoration models.
SMD	https://doi.org/10.1109/TIV.2023.3347952 (2024)	https://doi.org/10.1109/TMM.2018.2865686 (2018)	The SMD dataset is primarily used for evaluating and comparing various image restoration techniques, including dehazing, deraining, desnowing, and low-light enhancement. It serves as a benchmark for assessing performance through metrics like PSNR, SSIM, FSIM, and NIQE, and for visual comparisons. The dataset includes real-world and synthetic images, particularly emphasizing diverse and challenging scenarios, such as those found in maritime environments.
SOTS-Outdoor	https://doi.org/10.1109/TPAMI.2024.3419007 (2024), https://doi.org/10.1109/TPAMI.2023.3330416 (2023), https://doi.org/10.48550/arXiv.2409.19403 (2024) (+4)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The SOTS-Outdoor dataset is primarily used to evaluate and benchmark dehazing methods, focusing on outdoor scenes. It is employed to assess the performance of dehazing algorithms in removing atmospheric haze, with metrics such as PSNR and visual comparisons. The dataset emphasizes real-world hazy conditions and is used to compare proposed models against state-of-the-art methods, highlighting parameter efficiency and performance in realistic outdoor scenarios.
RealBlur-R	https://doi.org/10.1109/CVPR52729.2023.01753 (2023), https://doi.org/10.48550/arXiv.2306.13653 (2023), https://doi.org/10.1109/CVPR52733.2024.00277 (2023) (+4)	https://doi.org/10.1109/ICCV.2019.00567 (2019)	The RealBlur-R dataset is primarily used to evaluate deblurring performance on real-world images, focusing on robustness, generalization, and practical applicability. It contains real-world blurred images captured under various conditions, including out-of-focus and motion blur, which are used to assess the effectiveness and adaptability of deblurring algorithms. The dataset enables researchers to test and improve the accuracy and zero-shot generalization capabilities of their methods, often using performance metrics such as PSNR and SSIM.
RSBlur	https://doi.org/10.1109/TPAMI.2023.3330416 (2023), https://www.semanticscholar.org/paper/3fb08a1c07eba3461d6ed784b25d952979e90e0d (2023), https://doi.org/10.1109/TPAMI.2024.3419007 (2024)	https://doi.org/10.1007/978-3-031-20071-7_29 (2022)	The RSBlur dataset is primarily used to evaluate and train image deblurring models, focusing on real-world scenarios and realistic blur synthesis. It assesses performance on naturally and motion-blurred images, emphasizing the trade-off between PSNR and model complexity. The dataset helps researchers test the robustness, generalization, and effectiveness of deblurring algorithms in practical conditions.
Seaships	https://doi.org/10.1109/TIV.2023.3347952 (2024)	https://doi.org/10.1109/TMM.2018.2865686 (2018)	The Seaships dataset is primarily used for evaluating and comparing image restoration techniques, specifically dehazing, deraining, and low-light enhancement, in maritime contexts. It focuses on ship detection and visual quality assessments, employing metrics like PSNR, SSIM, and FSIM. The dataset's precise annotations and large-scale, synthetic images enable robust training and evaluation of ship detection models under various environmental conditions.
B100	https://doi.org/10.48550/arXiv.2210.01427 (2022), https://www.semanticscholar.org/paper/34439db81b482cd562e1cdba974c70a2b89cd6d4 (2019), https://doi.org/10.48550/arXiv.2210.00405 (2022) (+2)	https://doi.org/10.5244/C.26.135 (2012)	Dataset B100 is primarily used for evaluating image super-resolution methods, focusing on low-complexity algorithms and sparse-representation techniques. It consists of 100 high-resolution natural images and is employed to assess the performance of image restoration algorithms, particularly in scaling up images. Research questions often center on the effectiveness of these methods, measured using PSNR and SSIM metrics.
LOL dataset	https://doi.org/10.1109/CVPR46437.2021.01594 (2021), https://doi.org/10.1109/TMM.2024.3407656 (2024), https://doi.org/10.1145/3664647.3681621 (2024) (+4)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The LOL dataset is primarily used for low-light image enhancement research, focusing on improving image quality and detail preservation in low-light conditions. It contains real scene images captured at different exposure times and ISO settings, enabling the training and evaluation of supervised, unsupervised, and zero-shot methods. The dataset supports quantitative comparisons of various enhancement techniques, including deep retinex decomposition and MIRNet, and provides ground-truth images for benchmarking performance metrics.
NH-HAZE	https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.1109/TPAMI.2023.3330416 (2023), https://doi.org/10.1109/TPAMI.2024.3419007 (2024) (+5)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The NH-HAZE dataset is primarily used for evaluating and testing dehazing algorithms on real-world hazy images, particularly in outdoor and natural environments. It serves as a benchmark for assessing the robustness, effectiveness, and performance of dehazing techniques, often focusing on metrics like PSNR to measure image quality improvement. The dataset includes both hazy and haze-free images, enabling researchers to compare and validate dehazing methods under diverse conditions.
O-HAZE	https://doi.org/10.1109/TPAMI.2024.3419007 (2024), https://doi.org/10.24963/ijcai.2024/80 (2024), https://doi.org/10.1109/TCSVT.2024.3429557 (2024) (+1)	https://doi.org/10.1007/978-3-030-01449-0_52 (2018)	The O-HAZE dataset is used to assess and validate the performance of dehazing algorithms on real-world outdoor hazy images. It provides realistic conditions and challenging scenarios, enabling researchers to evaluate the effectiveness of their methods in removing haze. The dataset includes both hazy and haze-free images, facilitating direct comparisons and performance metrics such as PSNR improvements.
Rain14000	https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.1109/TMM.2024.3407656 (2024), https://doi.org/10.48550/arXiv.2306.05390 (2023) (+2)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The Rain14000 dataset is primarily used for training and evaluating rain removal algorithms, focusing on diverse rain patterns and intensities. It provides a large set of 11,200 clean-rain image pairs, enhancing model robustness and generalization. This dataset is crucial for improving deraining models through deep learning techniques, ensuring they perform well across various rain conditions.
DID-Data	https://doi.org/10.48550/arXiv.2404.12091 (2024), https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.1109/CVPR52733.2024.00277 (2023)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The DID-Data dataset is primarily used for training and evaluating image restoration models, particularly in de-raining and denoising tasks. It contains paired rainy and clean images, as well as diverse synthetic rain and noise conditions, enabling researchers to test the robustness and effectiveness of their methods in various degradation scenarios. The dataset supports the integration of physics models and conditional adversarial learning, enhancing the performance and detail preservation in image restoration.
DDN-Data	https://doi.org/10.48550/arXiv.2404.12091 (2024), https://doi.org/10.1109/CVPR52733.2024.00277 (2023), https://doi.org/10.48550/arXiv.2308.09388 (2023)	https://doi.org/10.1109/CVPR.2017.186 (2017)	The DDN-Data dataset is primarily used for training and evaluating image de-raining models, focusing on synthetic rain effects. It features synthetic rain images generated by a deep detail network, which are used to test and enhance the robustness of rain removal algorithms. The dataset emphasizes realistic rain patterns and preserves image details, enabling researchers to assess the effectiveness of various rain augmentations, particularly light and heavy rain effects.
MIT-Adobe FiveK	https://doi.org/10.48550/arXiv.2310.10513 (2023), https://doi.org/10.1109/CVPR52729.2023.01350 (2022), https://doi.org/10.1109/TNNLS.2021.3131739 (2020) (+1)	https://www.semanticscholar.org/paper/5ee57b18a7be2b671ffc6f5ce5dbbe92112ee0fb (2007)	The MIT-Adobe FiveK dataset is primarily used to evaluate and compare image restoration and retouching techniques. It involves applying operators on images retouched by expert C to assess the performance and effectiveness of these techniques using metrics like PSNR and SSIM. The dataset also contributes to generating synthetic noisy images and exposure correction datasets, enhancing the training, validation, and testing of models like ShadowDiffusion and MIRNet for image enhancement and restoration.
RealSRSet	https://doi.org/10.48550/arXiv.2308.15070 (2023), https://doi.org/10.1109/ICCVW54120.2021.00210 (2021)	https://doi.org/10.1109/CVPRW50498.2020.00241 (2020)	The RealSRSet dataset is primarily used for evaluating and comparing real-world super-resolution methods, focusing on visual quality, performance, and metric scores. It provides a diverse set of real-world images, enabling comprehensive testing of algorithms like SwinIR and DiffBIR, particularly at ×4 scale. The dataset supports research on low-quality image synthesis, degradation models, and techniques such as kernel estimation and noise injection.
Raindrop datasets	https://doi.org/10.48550/arXiv.2310.10123 (2023), https://doi.org/10.1109/ACCESS.2025.3526168 (2023), https://doi.org/10.1109/ICCV48922.2021.00231 (2021) (+2)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The Raindrop datasets are primarily used for raindrop and rain streak removal from images, focusing on realistic raindrop effects and enhancing image clarity. These datasets are employed to train and evaluate models, such as SPAIR, in deraining tasks, specifically assessing their performance in removing raindrop artifacts and improving visual quality.
RealBlur-J	https://doi.org/10.48550/arXiv.2306.13653 (2023), https://doi.org/10.1109/CVPR52733.2024.00277 (2023), https://doi.org/10.48550/arXiv.2310.11881 (2023) (+3)	https://doi.org/10.1109/ICCV.2019.00567 (2019)	The RealBlur-J dataset is primarily used to evaluate deblurring performance on real-world images, focusing on robustness and generalization to various challenging conditions such as low light, JPEG compression, and different types of blur. It is employed to compare proposed methods against state-of-the-art techniques, enhancing deblurring robustness and assessing zero-shot generalization capabilities. The dataset's real-world blurred images with varying degrees of blur and noise make it suitable for benchmarking and testing the effectiveness of deblurring algorithms in practical scenarios.
Rain1200	https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.48550/arXiv.2407.04621 (2024), https://doi.org/10.48550/arXiv.2306.05390 (2023)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Rain1200 dataset is primarily used for training and evaluating rain removal algorithms, focusing on synthetic rain images. It is employed to test the capability of models like OneRestore in removing rain streaks and restoring clean images. The dataset's large set of synthetic rainy images enables researchers to assess the performance and effectiveness of deraining models.
BSD	https://www.semanticscholar.org/paper/cbd65255f6266f798326acc8e0654e40ea0918cf (2018), https://doi.org/10.48550/arXiv.2407.00676 (2024), https://doi.org/10.48550/arXiv.2404.12091 (2024) (+2)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The BSD dataset is primarily used for training and testing image restoration models, focusing on denoising and deblurring tasks. It provides a diverse set of natural images with ground truth annotations, enabling researchers to enhance model performance through patch cropping and concatenation with other datasets like WED. The dataset's 200 training, 100 validation, and 200 test images are used to evaluate model effectiveness at various noise levels (σ = 30, 50, 70). Additionally, BSD is utilized to explore overlaps in ground truths with UCID, impacting the separation of dataset-level or density-level properties in instance-level representations.
Rain12	https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.48550/arXiv.2306.05390 (2023), https://doi.org/10.1109/CVPR52688.2022.01688 (2022) (+1)	https://doi.org/10.1109/CVPR.2016.299 (2016)	The Rain12 dataset is used for training and evaluating rain removal algorithms, particularly focusing on a small set of challenging and high-quality rainy images. It serves as a specialized subset within larger datasets like Rain13K, enabling detailed performance analysis and the development of models for rain streak removal in both synthetic and real-world images. The dataset's size and quality make it suitable for refining and testing layer priors in deraining techniques.
RealBlur	https://doi.org/10.48550/arXiv.2208.05244 (2022), https://doi.org/10.1109/TPAMI.2023.3330416 (2023), https://doi.org/10.48550/arXiv.2211.07317 (2022) (+2)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The RealBlur dataset is primarily used for training and evaluating deblurring methods, particularly in real-world scenarios. It provides a realistic testbed with authentic, motion-blurred images, enabling researchers to assess the robustness, generalization, and effectiveness of deblurring algorithms. The dataset features varying degrees of blur, enhancing the reliability of benchmarking and experimental results in image motion deblurring.
RealSR	https://doi.org/10.48550/arXiv.2308.15070 (2023), https://doi.org/10.48550/arXiv.2308.09388 (2023), https://doi.org/10.1007/978-3-030-58595-2_30 (2020)	https://doi.org/10.1109/ICCV.2019.00318 (2019)	The RealSR dataset is primarily used for evaluating and comparing image super-resolution methods, particularly focusing on real-world data. It supports the assessment of natural image enhancement, detail preservation, and out-of-distribution generalization. Researchers use it to quantitatively evaluate the performance of various models, including CNN-based, transformer-based, and diffusion models, on single image super-resolution tasks. The dataset provides training and test image pairs at scale factors 2, 3, and 4, enabling comprehensive evaluation of restoration quality and model generalization to unseen data.
HSTS	https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://www.semanticscholar.org/paper/0c291c421fb11b5b27e2d3526efb2353d88c27a8 (2023)	https://doi.org/10.1016/j.patrec.2018.01.010 (2018)	The HSTS dataset is used for training and evaluating image restoration algorithms, particularly for deraining and dehazing. It includes high-quality synthetic rain images and a mix of synthetic and real-world hazy images, enabling researchers to benchmark and compare the performance of different methods in both controlled and real-world scenarios.
Snow100K-L	https://doi.org/10.1109/TIP.2024.3368961 (2023), https://doi.org/10.1109/ACCESS.2025.3526168 (2023), https://doi.org/10.48550/arXiv.2207.04754 (2022) (+1)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Snow100K-L dataset is used to evaluate and train image restoration methods, particularly for removing snow from images. It contains 16,801 images and is utilized to assess desnowing performance, focusing on larger-scale images with moderate PSNR/SSIM metrics. The dataset enables researchers to test and enhance algorithms for improving image quality in snowy environments, addressing the most challenging subsets of images.
Test1	https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.1109/TIP.2024.3368961 (2023), https://doi.org/10.1109/TPAMI.2023.3238179 (2022)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The Test1 dataset is used to evaluate the performance of image restoration models, particularly in deraining tasks. It includes 750 images and is employed for both qualitative and quantitative assessments, focusing on the effectiveness of models in removing rain streaks and restoring image quality under heavy rain conditions. This dataset enables researchers to comprehensively test and compare the general restoration capabilities of their methods.
ImageNet 1K	https://doi.org/10.48550/arXiv.2308.09388 (2023), https://www.semanticscholar.org/paper/3d3c5fcbc40aadccceda58d3d9c5cd00588ea0b7 (2022), https://doi.org/10.1109/CVPRW59228.2023.00178 (2023)	https://doi.org/10.1109/ICCV.2015.425 (2014)	The ImageNet 1K dataset is primarily used for evaluating and comparing image restoration techniques, particularly in super-resolution and deblurring tasks. It provides a large-scale, diverse set of images that enable researchers to assess model performance across various categories. Studies use it to test 4x super-resolution models, evaluate zero-shot methods, and compare different approaches like DGP, RED, and SNIPS, focusing on image quality and restoration performance without noise.
LOL-v1	https://doi.org/10.48550/arXiv.2501.12981 (2025), https://doi.org/10.1109/TMM.2024.3407656 (2024), https://doi.org/10.48550/arXiv.2408.08091 (2024) (+4)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The LOL-v1 dataset is primarily used for low-light image enhancement research, where it serves as a benchmark to validate and compare the performance of various enhancement methods. It provides a collection of low-light and normal-light image pairs, enabling researchers to assess restoration quality using metrics like PSNR and SSIM. The dataset supports the development and evaluation of algorithms aimed at improving image visibility and quality in low-light conditions, often employing techniques such as deep retinex decomposition.
BSDS100	https://doi.org/10.1007/978-3-030-58523-5_36 (2020), https://doi.org/10.48550/arXiv.2310.10513 (2023)	https://doi.org/10.1007/978-3-642-27413-8_47 (2010)	The BSDS100 dataset is primarily used to evaluate and test image restoration methods, focusing on edge preservation, texture recovery, and segmentation accuracy under various distortions and resolutions. It assesses the generalization ability of restoration models on images with blended distortions, enabling researchers to compare performance metrics and refine techniques for better edge detection and overall image quality.
SPA	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/CVPR52729.2023.02083 (2023), https://doi.org/10.48550/arXiv.2309.06023 (2023)	https://doi.org/10.1109/CVPR.2019.01255 (2019)	The SPA dataset is primarily used for rain removal tasks in image restoration research, focusing on both synthetic and real rain images. It serves as a foundational resource for constructing enhanced datasets like SPA+ and is utilized to improve and evaluate the performance of deraining algorithms, particularly in single-image deraining scenarios. The dataset's high-quality real rain data is crucial for assessing and enhancing rain removal accuracy and demonstrating significant PSNR improvements in retrained models.
DF2K	https://doi.org/10.48550/arXiv.2412.20066 (2024), https://doi.org/10.48550/arXiv.2306.05390 (2023), https://doi.org/10.1109/CVPRW59228.2023.00178 (2023) (+2)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The DF2K dataset is used primarily for single image super-resolution and image restoration research. It combines images from DIV2K and Flickr2K to create a larger, more diverse training set, enhancing model performance and evaluation. Researchers use it to train and compare classic and advanced models, such as those employing the Swin Transformer architecture, to improve the quality of degraded images.
I-Haze	https://doi.org/10.1109/TPAMI.2024.3419007 (2024), https://doi.org/10.1109/TCSVT.2024.3429557 (2024)	https://doi.org/10.1007/978-3-030-01449-0_52 (2018)	The I-Haze dataset is used to test and benchmark dehazing algorithms on real indoor hazy and haze-free images. It serves as a critical resource for evaluating dehazing performance in indoor scenarios, providing researchers with a standardized set of real-world images to assess algorithm effectiveness. This dataset enables the comparison of different dehazing models, facilitating advancements in image restoration techniques for indoor environments.
GTA5	https://doi.org/10.1109/TPAMI.2024.3419007 (2024), https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.24963/ijcai.2024/80 (2024)	https://doi.org/10.1007/978-3-030-58610-2_28 (2020)	The GTA5 dataset is primarily used in research for evaluating nighttime dehazing algorithms. It provides synthetic nighttime hazy images, which are utilized to test and assess the performance of image restoration methods, particularly in simulated urban environments. Researchers employ this dataset to demonstrate improvements in dehazing results and overall image quality, focusing on synthetic benchmark performance.
HQ-50K	https://doi.org/10.48550/arXiv.2306.05390 (2023)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The HQ-50K dataset is primarily used for high-quality image restoration tasks. It is utilized to compare the dataset's size and resolution with other datasets, emphasizing its suitability for image restoration. Researchers use it to train and evaluate models, focusing on performance metrics and comparing results with benchmarks like DIV2K. The dataset's large scale and high resolution are key characteristics that enable these comparisons and evaluations.
ICB	https://doi.org/10.1109/CVPRW63382.2024.00645 (2024)	https://doi.org/10.1109/CVPRW.2017.151 (2017)	The ICB dataset is used to evaluate and benchmark image restoration and compression techniques. It focuses on assessing the performance of methods like PromptCIR on image restoration quality at various factors (10, 20, 30, 40) and examines the impact of compression on image restoration and artifact reduction. This dataset enables researchers to compare and refine algorithms for enhancing image quality and reducing artifacts in restored images.
RESIDE-6k	https://doi.org/10.48550/arXiv.2503.10120 (2025), https://doi.org/10.48550/arXiv.2306.13653 (2023)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The RESIDE-6k dataset is primarily used for image dehazing research, enhancing image clarity by removing haze effects. It provides a large set of diverse real-world hazy images, enabling the training and evaluation of dehazing algorithms. The dataset supports comprehensive testing and assessment of these algorithms under various atmospheric conditions, facilitating advancements in image restoration techniques.
All-Weather dataset	https://doi.org/10.1109/ACCESS.2025.3526168 (2023), https://doi.org/10.1109/CVPR52733.2024.02352 (2023)	https://doi.org/10.1109/cvpr42600.2020.00324 (2020)	The All-Weather dataset is used to train and evaluate image restoration techniques under various weather conditions, such as rain, fog, and snow. It supports the analysis of L2 norm distribution across image channels and partitions images into subsets based on degradation severity (slight, moderate, heavy). This enables researchers to assess and compare the performance of their methods against state-of-the-art techniques in restoring weather-degraded images.
LSUN	https://doi.org/10.1109/CVPR52729.2023.00958 (2023), https://www.semanticscholar.org/paper/3d3c5fcbc40aadccceda58d3d9c5cd00588ea0b7 (2022)	https://www.semanticscholar.org/paper/744fe47157477235032f7bb3777800f9f2f45e52 (2017)	The LSUN dataset is used to evaluate image restoration models across various categories, leveraging internet-sourced images to test generalization capabilities. It assesses model performance on large-scale, 256x256 images, focusing on consistency and FID scores. The dataset enables researchers to compare supervised and unsupervised methods, emphasizing the model's ability to handle diverse and complex scenes.
91 images	https://www.semanticscholar.org/paper/cbd65255f6266f798326acc8e0654e40ea0918cf (2018), https://doi.org/10.1109/CVPRW59228.2023.00178 (2023)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The '91 images' dataset is used primarily for training and evaluating image restoration methods, particularly in the domain of image super-resolution. It provides a small, manageable set of 91 high-quality images, enabling researchers to assess the performance of their models efficiently. This dataset facilitates the development and benchmarking of early image restoration techniques by offering a consistent and well-defined subset for both training and evaluation.
Berkeley Segmentation Dataset (BSD)	https://www.semanticscholar.org/paper/cbd65255f6266f798326acc8e0654e40ea0918cf (2018), https://doi.org/10.1109/CVPRW.2018.00121 (2018), https://doi.org/10.1109/ICCV.2017.486 (2017) (+1)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The Berkeley Segmentation Dataset (BSD) is primarily used for training and evaluating image restoration and denoising models. It provides a diverse set of natural images, often combined from train, validation, and test sets, to generate image patches and construct comprehensive datasets. Researchers use the dataset to focus on natural image boundaries and structures, enhancing the performance of segmentation and restoration algorithms. The dataset's versatility in providing high-quality, varied images makes it a valuable resource for improving the robustness and accuracy of image processing techniques.
DRealSR	https://doi.org/10.48550/arXiv.2308.15070 (2023), https://doi.org/10.48550/arXiv.2308.09388 (2023)	https://doi.org/10.1109/ICCV.2019.00318 (2019)	DRealSR is used for evaluating image super-resolution performance, particularly in real-world and synthetic contexts. It focuses on enhancing image details and assessing restoration quality. The dataset includes real-world images captured with DSLR cameras and various lenses, enabling researchers to quantitatively evaluate and compare single image super-resolution models.
Raindrop800	https://doi.org/10.48550/arXiv.2203.06074 (2022)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The Raindrop800 dataset is primarily used for evaluating and training de-raining algorithms, with a specific focus on raindrop effects. It is employed to enhance image clarity and visibility in rainy scenes by removing raindrops, improving PSNR by 0.84dB. The dataset features realistic raindrop patterns, enabling researchers to assess and improve the performance of rain removal models in real-world scenarios.
TIP2018	https://doi.org/10.48550/arXiv.2203.06074 (2022)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The TIP2018 dataset is used to evaluate and compare the performance of various image restoration techniques, focusing on a diverse set of image degradations such as noise, rain, and moiré patterns. It provides a comprehensive set of challenges, enabling researchers to assess methods using metrics like PSNR and to address specific issues like denoising, de-raining, and demoireing. The dataset's diverse and varied image conditions facilitate robust evaluation across multiple restoration tasks.
SateHaze1k	https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.1109/TPAMI.2024.3419007 (2024)	https://doi.org/10.1109/WACV45572.2020.9093471 (2020)	The SateHaze1k dataset is primarily used for evaluating and enhancing image restoration techniques in remote sensing, with a focus on haze removal and improving image clarity. It is utilized in dehazing experiments to assess the performance of various dehazing algorithms, particularly in satellite imagery. The dataset supports the application of models like Asimage and leverages SAR image priors in conditional GANs to enhance optical imagery quality.
CelebA	https://doi.org/10.1109/CVPR52729.2023.00958 (2023)	https://www.semanticscholar.org/paper/744fe47157477235032f7bb3777800f9f2f45e52 (2017)	The CelebA dataset is used in research to evaluate image restoration techniques, specifically focusing on inpainting and super-resolution tasks. It is employed to demonstrate the visual quality and effectiveness of models in restoring 256x256 celebrity face images, with an emphasis on facial detail recovery. Additionally, it is used to test generative models' capabilities in producing high-fidelity facial images, assessing consistency and FID scores.
All-weather	https://doi.org/10.48550/arXiv.2312.16610 (2023), https://doi.org/10.1109/CVPR52688.2022.00239 (2021), https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1109/CVPR.2019.00821 (2019)	The All-weather dataset is primarily used for training and evaluating image restoration models across various weather conditions, such as raindrop removal and deweathering. It employs generative adversarial networks and assesses model performance using metrics like PSNR and SSIM. The dataset supports research on improving image clarity in degraded scenes and enhancing downstream tasks like segmentation. It also facilitates the comparison of different models, including MoFME, highlighting efficiency and effectiveness in image restoration.
USC-SIPI	https://www.semanticscholar.org/paper/3d3c5fcbc40aadccceda58d3d9c5cd00588ea0b7 (2022), https://doi.org/10.1109/CVPR52729.2023.00958 (2023)	https://www.semanticscholar.org/paper/744fe47157477235032f7bb3777800f9f2f45e52 (2017)	The USC-SIPI dataset is used to evaluate image restoration models, specifically focusing on 256 × 256 images. It assesses the restoration quality of models like DDRM and GDP, emphasizing their effectiveness on diverse image content beyond ImageNet classes. The dataset enables researchers to test and validate the performance of these models on a wide range of image types, ensuring robustness and generalizability in image restoration tasks.
SPA+	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1145/3664647.3680762 (2024), https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	The SPA+ dataset is primarily used for image deraining, enhancing and expanding the original SPA dataset to improve rain removal performance. It is employed in training and evaluating image restoration models, focusing on removing rain, haze, and snow to restore clear images. The dataset supports research on spatial attention mechanisms and assesses model effectiveness in various adverse weather conditions.
RealSnow	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1145/3664647.3680762 (2024), https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	https://doi.org/10.1109/CVPR46437.2021.00912 (2021)	The RealSnow dataset is primarily used for image desnowing, focusing on the evaluation and training of image restoration models to remove snow artifacts from real-world images. It enables researchers to assess the performance and effectiveness of snow removal algorithms, enhancing image clarity and restoration quality in snowy scenes.
REVIDE	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1145/3664647.3680762 (2024), https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	https://doi.org/10.1109/CVPR46437.2021.00912 (2021)	The REVIDE dataset is used for training and evaluating image restoration models, primarily focusing on rain and haze removal. It is utilized to test methods for dehazing and improving visibility in hazy images, as well as removing rain artifacts from real-world videos. The dataset supports the synthesis of realistic rain and haze conditions, enabling researchers to assess the effectiveness of restoration techniques in these challenging scenarios.
BSD train set	https://www.semanticscholar.org/paper/cbd65255f6266f798326acc8e0654e40ea0918cf (2018), https://doi.org/10.1109/ICCV.2017.486 (2017)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The BSD train set is used for training models in image super-resolution, specifically contributing 200 images from the Berkeley Segmentation Dataset. These images are utilized to enhance model performance and are integral to the training process in single image super-resolution tasks. The dataset's images help improve the resolution and quality of output images in these models.
LOL-v2	https://doi.org/10.48550/arXiv.2409.19403 (2024), https://doi.org/10.1109/TMM.2024.3407656 (2024)	https://doi.org/10.1109/TIP.2021.3050850 (2021)	The LOL-v2 dataset is used to evaluate and train low-light image enhancement (LLIE) methods. It provides paired low-light and normal-light images, enabling researchers to assess restoration quality using metrics like PSNR and SSIM. This dataset supports the development and testing of LLIE techniques by offering realistic low-light scenarios and corresponding ground truth images.
LFW-Test	https://doi.org/10.48550/arXiv.2308.15070 (2023)	https://doi.org/10.1109/ICCV.2015.425 (2014)	The LFW-Test dataset is primarily used to evaluate the BFR (Blur, Face Recognition) method on real-world face images. It assesses performance in diverse lighting and pose conditions, focusing on face recognition and restoration tasks. The dataset's real-world images enable researchers to test and improve the robustness of face recognition systems under varied and challenging conditions.
WIDER-Test	https://doi.org/10.48550/arXiv.2308.15070 (2023)	https://doi.org/10.1109/ICCV.2015.425 (2014)	The WIDER-Test dataset is used to evaluate the BFR method on real-world face images, focusing on face detection and restoration capabilities. It assesses performance in complex scenarios with varying scales and occlusions, enabling researchers to test and improve face detection and restoration algorithms in practical conditions.
real47	https://doi.org/10.48550/arXiv.2308.15070 (2023)	https://doi.org/10.1109/ICCV.2019.00318 (2019)	The real47 dataset is used to evaluate the performance of models on real-world single image super-resolution tasks, specifically focusing on metric scores. It is employed in the evaluation of the DiffBIR and BSR models, with an emphasis on assessing their effectiveness in enhancing real-world images. The dataset's real-world characteristics make it suitable for benchmarking super-resolution techniques.
DIV2K validation set	https://doi.org/10.48550/arXiv.2310.10123 (2023), https://www.semanticscholar.org/paper/dbfdb4235ac0d766b2f1a2dde89de6ed60e86605 (2021), https://doi.org/10.1109/TPAMI.2021.3088914 (2020)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The DIV2K validation set is primarily used for super-resolution tasks, providing a high-quality set of 100 images to validate image restoration models. It supports the development and testing of algorithms by offering a benchmark for upscaling and enhancing image quality. The dataset's high-resolution images enable researchers to evaluate the performance and effectiveness of their models in producing detailed, high-quality outputs.
Rain1800	https://doi.org/10.48550/arXiv.2306.05390 (2023), https://doi.org/10.1109/CVPR52688.2022.01688 (2022), https://doi.org/10.1109/TCSVT.2024.3398810 (2023)	https://doi.org/10.1109/CVPR.2016.299 (2016)	The Rain1800 dataset is used primarily for training and evaluating rain removal models in the field of image restoration. It provides 1,800 clean-rain image pairs, which are utilized to enhance the performance of deep learning algorithms in removing rain streaks from images. This moderate-sized dataset, part of the larger Rain13K collection, offers varied rainy conditions, making it suitable for improving and assessing deraining techniques.
LoLi-Phone	https://doi.org/10.1109/CVPR52729.2023.00958 (2023)	https://doi.org/10.1109/TPAMI.2021.3126387 (2021)	The LoLi-Phone dataset is primarily used for low-light image and video enhancement, specifically tailored for mobile phone cameras. It is employed to train and evaluate deep learning models, addressing real-world performance and user experience challenges. The dataset helps researchers enhance visual quality and detail in low-light conditions, pushing the boundaries of current enhancement techniques.
UIRD-12	https://doi.org/10.48550/arXiv.2410.08688 (2024)	https://doi.org/10.48550/arXiv.2407.04621 (2024)	The UIRD-12 dataset is used to evaluate image restoration methods, specifically One-to-Many and One-to-Composite techniques, as well as the CoR method. It focuses on assessing performance across various degradation types, enabling researchers to compare and analyze the effectiveness of different restoration approaches.
LAION-5B	https://doi.org/10.1109/CVPR52733.2024.02425 (2024), https://doi.org/10.48550/arXiv.2306.05390 (2023)	https://doi.org/10.48550/arXiv.2210.08402 (2022)	The LAION-5B dataset is used to evaluate and compare image quality against other large datasets, emphasizing the importance of high-quality images for restoration tasks. It highlights the limitations of large-scale, high-resolution datasets in providing sufficient texture information for training restoration models. Additionally, it serves as a foundation for multimodal pretraining, aiding in the creation of specialized restoration datasets.
General100	https://doi.org/10.1109/ICCV51070.2023.01204 (2023), https://doi.org/10.48550/arXiv.2310.10513 (2023)	https://doi.org/10.1007/978-3-642-27413-8_47 (2010)	The General100 dataset is used to evaluate GAN-based and other image restoration methods, focusing on performance metrics such as PSNR and LPIPS to assess image quality and perceptual similarity. It covers a wide range of image types and degradation scenarios, enabling researchers to test and compare high-quality image restoration techniques.
rain-haze-noise-blur-dark	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The 'rain-haze-noise-blur-dark' dataset is used for comprehensive image restoration research, focusing on handling multiple degradations such as rain, haze, noise, blur, and low light. It is employed to test and evaluate image restoration algorithms and models designed to address these combined degradations, enabling researchers to assess the effectiveness of all-in-one restoration techniques.
ITS	https://doi.org/10.1109/TCSVT.2023.3299324 (2024)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The ITS dataset is primarily used for training and evaluating image deraining algorithms, specifically focusing on indoor scenes with synthetic rain. It enables researchers to assess the performance of deraining techniques in controlled, synthetic environments, ensuring that the algorithms can effectively remove rain artifacts from images. This dataset supports the development and refinement of image restoration methods tailored to indoor settings.
OTS	https://doi.org/10.1109/TCSVT.2023.3299324 (2024)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The OTS dataset is primarily used for training and evaluating image deraining algorithms, specifically focusing on outdoor scenes with synthetic rain. This dataset enables researchers to assess the performance of deraining techniques in realistic outdoor environments, contributing to advancements in image restoration and enhancement methodologies.
FFHQ	https://doi.org/10.1109/CVPRW59228.2023.00178 (2023), https://doi.org/10.1109/ICCV51070.2023.00495 (2023), https://www.semanticscholar.org/paper/3d3c5fcbc40aadccceda58d3d9c5cd00588ea0b7 (2022)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The FFHQ dataset is used in research for training, testing, and evaluating image restoration models, specifically focusing on high-quality face images. It enables researchers to enhance facial details, assess the quality and realism of restored faces, and evaluate texture recovery in high-resolution images. The dataset's high-quality and high-resolution characteristics are crucial for these applications.
RENOIR	https://doi.org/10.1109/TNNLS.2021.3131739 (2020), https://doi.org/10.1109/TMM.2021.3063916 (2021)	https://doi.org/10.1109/CVPR.2019.01129 (2018)	The RENOIR dataset is used to evaluate image restoration methods, particularly for denoising images corrupted by realistic noise. It provides real noisy images, typically cropped into 512 × 512 pixel patches, which are used to enhance the quality of visual data. This dataset enables researchers to test and compare the effectiveness of various image restoration techniques under realistic conditions.
LSDIR-val	https://doi.org/10.48550/arXiv.2409.19403 (2024)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The LSDIR-val dataset is used for evaluating and validating image restoration models, specifically in kernel deblurring and JPEG artifact removal. It assesses model performance in handling specific image degradation issues and focuses on the accuracy of estimated degradation kernels. This dataset enables researchers to test and refine methods for improving image quality under various degradation conditions.
DIV2K-Val	https://doi.org/10.48550/arXiv.2308.15070 (2023)	https://doi.org/10.1109/TIP.2018.2839891 (2017)	The DIV2K-Val dataset is used for validating and evaluating image restoration models, particularly focusing on high-resolution image quality and restoration accuracy. It is also employed to assess synthetic image super-resolution performance in the BSR task. The dataset's high-resolution images enable researchers to rigorously test and refine their models, ensuring they meet stringent quality standards.
RNI15	https://doi.org/10.48550/arXiv.2308.15070 (2023), https://doi.org/10.1109/TNNLS.2021.3131739 (2020)	https://doi.org/10.1109/TIP.2018.2839891 (2017)	The RNI15 dataset is primarily used for evaluating the BID task, particularly in the context of image denoising. It provides a variety of real-world images, including real noisy face images, which are used to assess the performance of denoising algorithms under realistic conditions. This dataset enables researchers to test and compare the effectiveness of different image restoration techniques in practical scenarios.
Rain13k-Test	https://doi.org/10.48550/arXiv.2409.19403 (2024)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The Rain13k-Test dataset is used for evaluating deraining algorithms by combining multiple test sets. It assesses the performance of these algorithms in removing rain streaks from images under diverse conditions. This dataset enables researchers to compare the effectiveness of different deraining methods, ensuring robustness across various scenarios.
SIDD validation set	https://doi.org/10.48550/arXiv.2310.10123 (2023), https://doi.org/10.48550/arXiv.2211.13654 (2022)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The SIDD validation set is used in research to validate deblurring and denoising algorithms, focusing on real-world image degradation and photographic noise reduction. It enables researchers to evaluate the performance of these algorithms by providing realistic scenarios, ensuring that the methods can effectively handle practical issues in image restoration.
Rain100	https://doi.org/10.48550/arXiv.2310.10123 (2023), https://doi.org/10.48550/arXiv.2312.01677 (2023)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The Rain100 dataset is used for evaluating rain removal techniques in image restoration. It contains both synthetic and real rain streaks, enabling researchers to test the deraining capabilities of models like DINO-IR on unseen data with rain degradation. This dataset facilitates the assessment of model performance in removing rain artifacts, enhancing image clarity and quality.
WaterlooED	https://doi.org/10.48550/arXiv.2407.20928 (2024)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The WaterlooED dataset is used for training in image restoration, providing a diverse set of images to enhance model robustness. It is specifically employed to improve the performance of restoration models by exposing them to a wide range of image conditions, thereby addressing research questions related to the effectiveness and generalizability of these models.
DID-MDN	https://doi.org/10.1007/978-3-030-58526-6_19 (2020), https://doi.org/10.48550/arXiv.2308.09388 (2023)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The DID-MDN dataset is primarily used for evaluating and enhancing single image de-raining methods, with a focus on density-aware performance. It is employed in constructing more complex hybrid distortion datasets (DID-HY) to test image restoration approaches under increased difficulty. The dataset facilitates the development of multi-stream dense networks to improve network representation capabilities for handling complex degradations.
LSDIR	https://doi.org/10.48550/arXiv.2404.02154 (2024), https://doi.org/10.1109/CVPRW63382.2024.00645 (2024)	https://doi.org/10.1109/CVPRW53098.2021.00074 (2021)	The LSDIR dataset is used for training and evaluating image restoration models, providing a large-scale collection of 84,991 high-quality, high-resolution natural images. It addresses complex image degradation by enhancing model robustness and performance, particularly in tasks requiring extensive data diversity and quality.
ImageNet ctest10k	https://doi.org/10.1145/3528233.3530757 (2021)	https://doi.org/10.1007/978-3-319-46493-0_35 (2016)	The ImageNet ctest10k dataset is primarily used for benchmarking the performance of various image restoration and translation models. It is employed to evaluate colorization tasks, comparing the Palette model against other methods, and to assess image-to-image translation tasks, focusing on model performance across different scenarios. Additionally, it is used to benchmark image inpainting models like DeepFillv2 and HiFill, particularly on ultra high-resolution images. This dataset serves as a standardized test set, enabling researchers to compare and validate the effectiveness of their models in specific image processing tasks.
Places2	https://doi.org/10.1145/3528233.3530757 (2021)	https://doi.org/10.1109/ICCV.2019.01062 (2019)	The Places2 dataset is primarily used for evaluating and training image extension methods, particularly uncropping and outpainting techniques. It supports research by providing a diverse set of images, enabling comparisons of performance across different categories and methodologies, such as generative adversarial networks. The dataset facilitates the assessment of image quality metrics and the effectiveness of various image extension approaches.
BSDS400	https://doi.org/10.48550/arXiv.2306.05390 (2023)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The BSDS400 dataset is used for image restoration, featuring 400 clean images. It serves as a benchmark to compare with larger datasets like HQ-50K, highlighting differences in scale. This dataset enables researchers to evaluate and contrast the performance of image restoration techniques, providing a standardized set of high-quality images for method validation and comparison.
SPANet	https://doi.org/10.48550/arXiv.2405.02843 (2024)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The SPANet dataset is used to evaluate the performance of deraining models on real-world rainy images. Researchers employ this dataset to test and assess the effectiveness of trained models, particularly those using GAN-based methods, in practical deraining scenarios. This evaluation helps in understanding the practical applicability and robustness of these models in real-world conditions.
Solid dataset	https://doi.org/10.1109/TCSVT.2023.3286405 (2024)	https://doi.org/10.1109/ICCV.2017.423 (2017)	The Solid dataset is used to evaluate image restoration techniques, particularly on indoor solid object scenes. It contains 200 image triplets and is employed to assess the robustness, accuracy, and quality of restored images in controlled environments. The dataset supports research in reflection removal and general image restoration, enabling detailed performance comparisons of different algorithms.
AdaIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The AdaIR dataset is used for adaptive image restoration, specifically to test and develop techniques that dynamically adjust restoration parameters. Research focuses on methods like frequency mining and modulation to enhance image restoration adaptively. This dataset enables researchers to evaluate and refine algorithms that can dynamically respond to varying image conditions, improving restoration outcomes.
InstructIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The InstructIR dataset is used for instruction-based image restoration, enhancing images according to specific human instructions. It evaluates high-quality image restoration methods, focusing on diverse restoration tasks and techniques. This dataset enables researchers to assess and improve image restoration models guided by detailed instructions, ensuring more precise and contextually appropriate image enhancements.
NDR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The NDR dataset is primarily used for evaluating noise reduction and deblurring techniques in image restoration. It focuses on denoising images under various noise levels and testing non-uniform deblurring methods, particularly for motion blur. Researchers use this dataset to assess the performance of noise reduction algorithms on natural image datasets, enabling the development and refinement of image restoration methodologies.
DaAIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The DaAIR dataset is used for data-augmented image restoration, specifically to enhance the robustness and generalization of image restoration algorithms. It is employed to evaluate and test these algorithms under diverse and challenging degradations, focusing on improving their performance through data augmentation techniques.
DyNet	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The DyNet dataset is used for dynamic network training and testing, specifically focusing on adaptive and real-time image restoration techniques. It enables researchers to optimize restoration models for various conditions, assessing the performance of dynamic image restoration methods in practical applications. The dataset supports the development of more flexible and responsive image restoration algorithms.
AnyIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The AnyIR dataset is used for evaluating and testing all-in-one image restoration techniques, specifically focusing on handling multiple degradation types simultaneously. It enables researchers to assess the versatility of restoration methods across various degradations, ensuring robust performance in a single framework. This dataset supports the development and evaluation of comprehensive image restoration solutions.
HAIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The HAIR dataset is used for high-quality image restoration, with a focus on preserving fine details and textures in high-resolution images. It is employed to test both single and hybrid restoration techniques, enabling researchers to evaluate and combine multiple methods to achieve superior image restoration outcomes.
MEASNet	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The MEASNet dataset is used for evaluating and enhancing multi-exposure image fusion techniques. It focuses on combining multiple images taken under varying lighting conditions into a single high-quality image, assessing methods for detail enhancement and overall image restoration. This dataset enables researchers to test and compare different fusion algorithms, specifically addressing the challenges of multi-exposure adaptive synthesis and image quality improvement.
Perceive-IR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The Perceive-IR dataset is used for perceptual image restoration, specifically to enhance visual quality and realism. It is employed to evaluate image restoration methods, focusing on how well these methods improve the perceptual quality and realism of images for human observers. This dataset enables researchers to assess and compare different restoration techniques based on their ability to produce visually pleasing results.
DIV2K100	https://doi.org/10.1109/ICCV51070.2023.01204 (2023)	https://doi.org/10.1007/978-3-642-27413-8_47 (2010)	The DIV2K100 dataset is primarily used to evaluate GAN-based super-resolution methods and image restoration techniques. Research focuses on performance metrics such as PSNR and LPIPS to assess image quality and perceptual similarity in high-resolution images. This dataset enables researchers to benchmark and compare the effectiveness of different super-resolution and restoration approaches, emphasizing high-quality image output.
PromptIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1007/978-3-031-72764-1_1 (2024)	The PromptIR dataset is used to evaluate and enhance image restoration methods, particularly focusing on instruction-based and prompt-driven approaches. It supports research in human-guided and adaptive restoration techniques, aiming to generate high-quality restored images. This dataset facilitates the assessment of these methodologies by providing a platform for testing and comparing different restoration algorithms.
AirNet	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1007/978-3-031-72764-1_1 (2024)	The AirNet dataset is primarily used for testing and assessing air-light estimation in hazy images, enhancing visibility in outdoor and aerial scenes. It serves as a benchmark for evaluating image restoration techniques, particularly in handling various degradations. The dataset's focus on atmospheric light recovery makes it valuable for dehazing research, enabling researchers to improve the clarity and quality of images affected by haze.
PIP	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1007/978-3-031-72764-1_1 (2024)	The PIP dataset is used in research to test and evaluate image restoration algorithms, focusing on tasks such as image inpainting and handling complex degradations. It is employed to assess the performance of methods in filling in missing regions and addressing various types of image degradation, enabling researchers to compare and improve restoration techniques.
TextpromptIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1007/978-3-031-72764-1_1 (2024)	The TextpromptIR dataset is used to evaluate text-guided image restoration techniques, focusing on enhancing image quality through textual prompts. It supports research in image restoration by providing a framework to assess methods that use text-based guidance, enabling the development and comparison of algorithms designed to restore images based on specific textual inputs.
Naturalness Preserved Enhancement dataset (NPE)	https://doi.org/10.48550/arXiv.2407.04621 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Naturalness Preserved Enhancement (NPE) dataset is primarily used for low-light image enhancement research, where the focus is on enhancing image visibility while maintaining natural appearance. This dataset enables researchers to develop and evaluate algorithms that improve image quality under low-light conditions, ensuring that enhanced images look realistic and preserve natural details.
RESIDE Real-world Task-driven Testing Set (RTTS)	https://doi.org/10.48550/arXiv.2407.04621 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The RESIDE Real-world Task-driven Testing Set (RTTS) is primarily used for evaluating image dehazing algorithms. It provides real-world images with varying levels of haze, enabling researchers to assess the performance of dehazing techniques in practical scenarios. This dataset supports the development and refinement of algorithms by offering diverse and realistic test cases, ensuring that the methods can handle a wide range of hazy conditions.
Yang’s dataset (RS)	https://doi.org/10.48550/arXiv.2407.04621 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	Yang’s dataset (RS) is primarily used for image deraining research, featuring both synthetic and real rain-streak images. It is employed to test and evaluate the performance of deraining algorithms, focusing on the effectiveness of removing rain streaks from images. The dataset's inclusion of diverse rain conditions enables researchers to assess algorithm robustness and accuracy in various scenarios.
real Snow100k dataset (Snow100k-R)	https://doi.org/10.48550/arXiv.2407.04621 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The real Snow100k dataset (Snow100k-R) is used for image desnowing research, specifically to assess the effectiveness of desnowing algorithms on real snow-covered scenes. This dataset enables researchers to evaluate and improve desnowing techniques by providing a realistic benchmark for testing and validation.
DIV8K	https://doi.org/10.1109/CVPRW59228.2023.00178 (2023), https://doi.org/10.1109/ICCV51070.2023.00495 (2023)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The DIV8K dataset is used for evaluating and training image restoration models, particularly focusing on high-resolution image inpainting and quality assessment. It provides high-resolution images to test the scalability and quality of restoration techniques, enabling researchers to assess the performance of their models in handling detailed and large-scale images.
OST	https://doi.org/10.1109/CVPRW59228.2023.00178 (2023), https://doi.org/10.1109/ICCV51070.2023.00495 (2023)	https://doi.org/10.1109/CVPR.2018.00070 (2018)	The OST dataset is used to evaluate and assess image restoration algorithms, particularly focusing on the reconstruction task in image super-resolution and the restoration of textures and details in outdoor scenes. It contains 300 images with rich textures, enabling researchers to test and improve the performance of deep spatial feature transform methods in realistic texture recovery.
RainDrop test dataset	https://doi.org/10.1109/CVPR52688.2022.00239 (2021)	https://doi.org/10.1109/CVPR.2018.00263 (2017)	The RainDrop test dataset is used for evaluating the performance of trained models, particularly attentive generative adversarial networks, in removing raindrops from images. It assesses the effectiveness of these methods in enhancing visual clarity and preserving image details. This dataset enables researchers to rigorously test and compare different raindrop removal techniques.
WeatherStream	https://doi.org/10.1109/TIP.2024.3501855 (2024), https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1109/CVPR52729.2023.01297 (2023)	The WeatherStream dataset is used to train and evaluate image restoration models, specifically focusing on realistic weather degradation scenarios such as rain, fog, and snow. It enhances the robustness of models like MWFormer-real and TransWeather-real by providing real-world frames, enabling researchers to assess and improve the performance of single image deweathering techniques.
real-world dehazing dataset	https://doi.org/10.1109/CVPR52729.2023.02083 (2023), https://doi.org/10.48550/arXiv.2412.00878 (2024)	https://doi.org/10.1109/CVPR46437.2021.00912 (2021)	The real-world dehazing dataset is used to evaluate and train de-hazing algorithms, focusing on real-world images to assess performance in practical scenarios. It provides visual samples for dehazing tasks, enabling comparisons with other datasets like RealSnow. The dataset enhances image clarity and visual quality, specifically supporting research in dehazing and image restoration.
LIME low-light enhancement dataset	https://doi.org/10.48550/arXiv.2407.04621 (2024)	https://doi.org/10.1109/TIP.2016.2639450 (2017)	The LIME low-light enhancement dataset is used for improving illumination in underexposed images through illumination map estimation. Researchers employ this dataset to enhance low-light images, focusing on methodologies that estimate and adjust illumination maps to achieve better visual quality. This dataset enables specific research into low-light image enhancement techniques, addressing challenges such as poor visibility and color fidelity in dimly lit conditions.
RESIDE Real-world Task-driven Testing Set (RESIDE-RTTS)	https://doi.org/10.48550/arXiv.2407.04621 (2024)	https://doi.org/10.1109/TIP.2016.2639450 (2017)	The RESIDE Real-world Task-driven Testing Set (RESIDE-RTTS) is primarily used for dehazing tasks, providing real-world images with varying degrees of haze. Researchers employ this dataset to test and benchmark dehazing algorithms, focusing on the effectiveness and performance of these algorithms in realistic conditions. The dataset's real-world images enable robust evaluation and comparison, facilitating advancements in image restoration techniques specifically for dehazing.
Yang’s rainy dataset	https://doi.org/10.48550/arXiv.2407.04621 (2024)	https://doi.org/10.1109/TIP.2016.2639450 (2017)	Yang’s rainy dataset is used for evaluating rain removal techniques, featuring both synthetic and real rainy images. Researchers employ this dataset to assess the performance of rain detection and removal methods, focusing on improving image clarity and quality in rainy conditions. The dataset's inclusion of diverse rainy scenarios enhances its utility for benchmarking and validating these methods.
Snow100k dataset	https://doi.org/10.48550/arXiv.2407.04621 (2024)	https://doi.org/10.1109/TIP.2016.2639450 (2017)	The Snow100k dataset is used for evaluating snow removal techniques in image restoration. It features realistic snowy images that help researchers assess the effectiveness of these techniques under various conditions. The dataset enables the development and testing of algorithms designed to remove snow from images, enhancing their clarity and usability.
Challenge-60	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/TCSVT.2019.2963772 (2019)	The Challenge-60 dataset is used for evaluating and comparing the performance of image restoration methods, particularly in enhancing structural details and color correction under natural light conditions. It is specifically applied to assess underwater image restoration techniques, focusing on visual quality and the effectiveness of methods like NU2Net in improving images captured in diverse natural lighting environments.
UCCS	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/TCSVT.2019.2963772 (2019)	The UCCS dataset is used for evaluating and comparing the performance of underwater image enhancement algorithms. It focuses on enhancing structural details and correcting color casts under natural light conditions. Researchers use it to test the effectiveness of methods like NU2Net in improving overall image quality, making it valuable for visual assessments and algorithmic comparisons in underwater imaging.
EUVP-330	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/TCSVT.2019.2963772 (2019)	The EUVP-330 dataset is used for evaluating and comparing underwater image restoration techniques, particularly focusing on enhancing structural details and reducing color casts under natural light conditions. It is employed to test the robustness of restoration methods, such as NU2Net, by assessing their performance in improving visual clarity in natural light environments. This dataset enables researchers to visually compare restoration results and validate the effectiveness of different algorithms in realistic underwater settings.
SPA-Data	https://doi.org/10.1007/978-3-031-20071-7_4 (2021)	https://doi.org/10.1109/CVPR.2019.01255 (2019)	The SPA-Data dataset is primarily used to evaluate and benchmark deraining algorithms, particularly focusing on single-image deraining performance. It is utilized to assess the effectiveness of SPDNet and SPDNet-local in removing rain from images, comparing different inference methods. The dataset's high-quality real rain data enables researchers to rigorously test and improve deraining techniques.
real3	https://doi.org/10.48550/arXiv.2308.15070 (2023)	https://doi.org/10.1109/TIP.2018.2839891 (2017)	The real3 dataset is used for the BID task, contributing to a mixed real-world dataset for comprehensive image restoration evaluation, particularly focusing on image denoising. It enables researchers to assess the effectiveness of image restoration techniques in real-world scenarios, providing a robust benchmark for evaluating denoising performance.
real9	https://doi.org/10.48550/arXiv.2308.15070 (2023)	https://doi.org/10.1109/TIP.2018.2839891 (2017)	The real9 dataset is used for the BID task, primarily to provide additional real-world images for mixed dataset evaluation and to focus on image denoising in real-world scenarios. It enhances the robustness of models by incorporating diverse and realistic image conditions, enabling more accurate performance assessments in practical applications.
Adobe-MIT Fivek dataset	https://doi.org/10.1145/3664647.3681621 (2024), https://doi.org/10.48550/arXiv.2310.10513 (2023)	https://www.semanticscholar.org/paper/5ee57b18a7be2b671ffc6f5ce5dbbe92112ee0fb (2007)	The Adobe-MIT Fivek dataset is used for training and evaluating image restoration models, particularly focusing on expert-retouched images. It supports research in retouching, Low-Light Filtering (LLF), and Multi-Task Modeling (MTM), enabling the development of algorithms that perform expert-level image adjustments and multi-task learning. The dataset's emphasis on high-quality, professionally adjusted images facilitates the creation of more sophisticated and realistic image processing techniques.
Poly	https://doi.org/10.1109/TNNLS.2021.3131739 (2020)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The Poly dataset is used in image restoration research, specifically to provide real noisy images. It consists of cropped patches of 512 × 512 pixels, which are utilized to enhance the quality of degraded images. This dataset enables researchers to test and develop algorithms for noise reduction and image enhancement, focusing on improving the fidelity of restored images.
Flick2K	https://doi.org/10.48550/arXiv.2306.05390 (2023), https://doi.org/10.48550/arXiv.2308.09388 (2023)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The Flick2K dataset is primarily used for single image super-resolution, particularly focusing on enhancing the quality and detail of outdoor natural images. It is employed in training models using traditional image super-resolution techniques, with a specific emphasis on bicubic downsampling. This dataset enables researchers to develop and evaluate algorithms that improve image resolution and clarity.
Waterloo Exploration Database (WED)	https://doi.org/10.1109/CVPRW.2018.00121 (2018), https://doi.org/10.48550/arXiv.2306.05390 (2023)	https://doi.org/10.1109/TIP.2016.2631888 (2017)	The Waterloo Exploration Database (WED) is used in image restoration research, specifically for denoising and dejpeg tasks. It contains 4,744 images and is utilized to train models like MWCNN, introducing challenges for image quality assessment and restoration. The dataset's diverse image content and degradation types enable robust evaluation and development of restoration algorithms.
Flicke2K	https://doi.org/10.48550/arXiv.2210.01427 (2022)	https://doi.org/10.1109/ICCV.2013.241 (2013)	The Flicke2K dataset is primarily used for training models focused on image super-resolution, specifically enhancing image quality at a 2x scale. It is employed to generate high-resolution images from low-resolution inputs, enabling research in improving visual clarity and detail in digital images. The dataset's focus on 2x scaling is a key characteristic, supporting methodologies aimed at efficient and effective image enhancement.
Set6	https://doi.org/10.1109/TPAMI.2021.3088914 (2020)	https://doi.org/10.1109/ICCV.2011.6126278 (2011)	Set6 is used in research to evaluate the effectiveness of image restoration methods, particularly focusing on performance metrics such as PSNR. It is employed to compare the proposed DPIR method against other established techniques like EPLL, FDN, DMPHN, IRCNN, and IR-CNN+. The dataset enables researchers to quantitatively assess and benchmark the performance of these methods in image restoration tasks.
CelebA-HQ	https://doi.org/10.48550/arXiv.2308.09388 (2023), https://doi.org/10.1109/TPAMI.2024.3461721 (2024)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The CelebA-HQ dataset is used for evaluating face super-resolution models, focusing on high-quality facial images to test accuracy and detail preservation. It is also utilized to construct a test dataset of 2,000 facial images, specifically for assessing the quality of facial image restoration. The dataset's high-resolution and detailed facial images enable researchers to rigorously evaluate and compare different restoration techniques.
Real-World Noisy Image Dataset	https://doi.org/10.1109/CVPR.2019.00717 (2019)	https://www.semanticscholar.org/paper/fb52f9294fa1cd83660eccac486367eac01ea32d (2018)	The Real-World Noisy Image Dataset is used to evaluate and test denoising algorithms on real-world noisy images, particularly focusing on practical performance. It assesses models like DuRN-P on 40 pairs of noisy and mean images captured by a CMOS camera, emphasizing authentic noise patterns. This dataset enables researchers to validate the effectiveness of denoising techniques in realistic scenarios.
Kodak	https://doi.org/10.1109/CVPR52729.2023.01753 (2023), https://doi.org/10.1109/TMM.2024.3407656 (2024)	https://doi.org/10.1109/TIP.2016.2574984 (2016)	The Kodak dataset is used in research for evaluating image denoising and restoration techniques. It serves as test data to assess the effectiveness of denoising methods on high-quality images and to compare the performance of various restoration models, including GRL-S, with a focus on PSNR scores. This dataset enables researchers to benchmark and validate their algorithms against a standardized set of images.
RainCityscapes	https://doi.org/10.48550/arXiv.2312.16610 (2023)	https://doi.org/10.1109/CVPR.2019.00821 (2019)	The RainCityscapes dataset is used to evaluate and compare single-image rain removal techniques, focusing on performance metrics such as FLOPs, number of parameters, PSNR, and SSIM. It is particularly useful for assessing the effectiveness of the MoFME model, which has shown improved results over prior models in rain removal tasks. The dataset enables researchers to rigorously test and benchmark different rain removal algorithms.
RealPhoto60	https://doi.org/10.1007/978-3-031-73661-2_25 (2023)	https://doi.org/10.1109/ICCV48922.2021.00510 (2021)	The RealPhoto60 dataset is used as a real-world test set to evaluate the impact of semantic and restoration prompts on image quality. Researchers employ non-reference metrics to assess these influences, focusing on how different prompts affect the restoration outcomes. This dataset enables the evaluation of image restoration techniques in practical scenarios, providing insights into the effectiveness of various prompts.
RealSet80	https://doi.org/10.1109/TPAMI.2024.3461721 (2024)	https://doi.org/10.1109/ICCV.2017.355 (2017)	RealSet80 is used to evaluate and develop image restoration methods, particularly focusing on low-quality and real-world images. The dataset supports the testing of blind image restoration techniques and enhances the quality of images commonly referenced in recent literature. It enables researchers to assess the effectiveness of various restoration approaches in practical scenarios.
Wild dataset	https://doi.org/10.1109/TCSVT.2023.3286405 (2024)	https://doi.org/10.1109/ICCV.2017.423 (2017)	The Wild dataset is used to evaluate image restoration algorithms by testing their performance on 55 image triplets from diverse real-world scenes. It assesses the generalization and robustness of these algorithms across various conditions, emphasizing their effectiveness in wild settings. This dataset enables researchers to validate the reliability of image restoration techniques in practical, uncontrolled environments.
Postcard dataset	https://doi.org/10.1109/TCSVT.2023.3286405 (2024)	https://doi.org/10.1109/ICCV.2017.423 (2017)	The Postcard dataset is used to assess and test image restoration techniques, particularly focusing on the preservation of fine details and color accuracy in 199 triplet images from postcards. It evaluates algorithm performance, including single-image reflection removal, using metrics like PSNR to measure effectiveness. This dataset challenges researchers to improve restoration methods while maintaining high visual quality.
CDD-11	https://doi.org/10.48550/arXiv.2410.08688 (2024)	https://doi.org/10.1007/978-3-030-58595-2_30 (2020)	The CDD-11 dataset is used to evaluate and compare low-order methods integrated with CoR against end-to-end methods in image restoration. It focuses on One-to-One and One-to-Many restoration techniques, encompassing 11 degradation types such as l, h, r, s, and their combinations. This dataset enables researchers to assess the effectiveness of different restoration approaches under various degradation scenarios.
U-WADN	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The U-WADN dataset is used for training and evaluating wide-adaptive dynamic networks, specifically to enhance all-in-one image restoration capabilities. It is particularly effective in handling underwater images, allowing researchers to assess and improve image restoration methods in challenging aquatic environments. This dataset enables the development and testing of algorithms that can adapt to varying image conditions, thereby advancing the field of image restoration.
SA-1B	https://doi.org/10.1109/CVPR52733.2024.02425 (2024)	https://doi.org/10.48550/arXiv.2210.08402 (2022)	The SA-1B dataset is used to evaluate and compare image quality against other large datasets, highlighting its significance in image restoration tasks. Researchers employ this dataset to assess the effectiveness of different restoration methods, focusing on the importance of high-quality images in achieving better restoration outcomes. This dataset enables rigorous benchmarking and validation of image restoration techniques.
PieAPP	https://www.semanticscholar.org/paper/f942a4a56e6549c83844747ad6c4ae58000b2988 (2020)	https://doi.org/10.1109/CVPR.2018.00194 (2018)	The PieAPP dataset is used to assess perceptual errors in image restoration by conducting pairwise comparisons to evaluate human preference and perception of image quality. It focuses on measuring the differences between restored and original images, enabling researchers to refine restoration techniques based on human visual preferences.
Snow100K-S	https://doi.org/10.48550/arXiv.2207.04754 (2022), https://doi.org/10.1109/TPAMI.2023.3238179 (2022)	https://doi.org/10.1109/TCSVT.2020.3003025 (2021)	The Snow100K-S dataset is used to evaluate the performance of image desnowing techniques, particularly in smaller-scale images. It focuses on comparing methods like SMGARN and DS-GAN, emphasizing metrics such as PSNR and SSIM to assess improvements in de-snowing effectiveness. This dataset enables researchers to benchmark and refine algorithms for better image restoration in snowy conditions.
synthetic rain (Zamir et al. 2021) datasets (SRD)	https://doi.org/10.48550/arXiv.2409.00263 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The synthetic rain (Zamir et al. 2021) datasets (SRD) are used to train methods for rain removal, specifically evaluating the effectiveness of synthetic rain data in enhancing all-weather image restoration. This dataset enables researchers to test and improve algorithms by providing a controlled environment with synthetic rain conditions, facilitating the development of more robust image restoration techniques.
Test1 dataset	https://doi.org/10.1109/CVPR52688.2022.00239 (2021)	https://doi.org/10.1109/CVPR.2018.00263 (2017)	The Test1 dataset is used for evaluating the performance of image restoration methods, specifically focusing on general image quality metrics. Researchers employ this dataset to assess and compare the effectiveness of different restoration techniques, ensuring that the restored images meet high-quality standards. This dataset enables rigorous testing and validation of image restoration algorithms, contributing to advancements in the field.
Snow100k-L test set	https://doi.org/10.1109/CVPR52688.2022.00239 (2021)	https://doi.org/10.1109/CVPR.2018.00263 (2017)	The Snow100k-L test set is used to evaluate methods for removing snow from images, focusing on the reduction of noise and enhancement of visibility. This dataset enables researchers to assess the effectiveness of their techniques in improving image quality under snowy conditions, providing a benchmark for performance comparison.
U45	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/TCSVT.2019.2963772 (2019)	The U45 dataset is used for visual and real-world underwater image enhancement, specifically focusing on improving structural details under natural light conditions. It facilitates the testing and comparison of restoration techniques, enabling researchers to address the unique challenges of underwater imaging. This dataset supports the evaluation of methods designed to enhance image quality in natural lighting scenarios.
SQUID-16	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/TCSVT.2019.2963772 (2019)	The SQUID-16 dataset is used for evaluating and comparing image restoration techniques, particularly in enhancing structural details under natural light conditions. It is specifically applied to assess underwater image enhancement methods, addressing the unique challenges posed by natural lighting. This dataset facilitates visual comparisons and performance evaluations, enabling researchers to refine and validate their restoration algorithms in realistic scenarios.
RealIR	https://doi.org/10.48550/arXiv.2412.00878 (2024)	https://doi.org/10.1109/ICCV48922.2021.00510 (2021)	The RealIR dataset is used as a test set without ground truth for evaluating image restoration methods. It employs non-reference metrics aligned with human perception to assess the performance of these methods. This enables researchers to validate the effectiveness of image restoration techniques in scenarios where ground truth images are unavailable, focusing on perceptual quality rather than pixel-level accuracy.
UIEB	https://doi.org/10.48550/arXiv.2501.12981 (2025), https://doi.org/10.1145/3664647.3681621 (2024)	https://doi.org/10.1016/j.image.2020.115978 (2019)	The UIEB dataset is used for evaluating and comparing underwater image enhancement algorithms. It focuses on assessing the visual quality and restoration effectiveness of enhanced underwater images against reference images. This dataset enables researchers to improve visual clarity and quality in underwater environments, supporting the development and refinement of image enhancement techniques.
Indoor Training Set	https://doi.org/10.1145/3664647.3680762 (2024)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The Indoor Training Set, part of the RESIDE dataset, is used for dehazing indoor scenes to enhance visibility and clarity. This dataset supports research focused on image dehazing techniques, employing methodologies aimed at improving the visual quality of indoor images by removing haze effects. It enables researchers to develop and evaluate algorithms that restore clear images from hazy ones, addressing specific challenges in indoor environments.
Rain-Haze-Snow	https://doi.org/10.1109/CVPR52729.2023.00563 (2023), https://doi.org/10.48550/arXiv.2505.12630 (2025)	https://doi.org/10.1109/cvpr42600.2020.00324 (2020)	The 'Rain-Haze-Snow' dataset is used to train and evaluate machine learning models for all-in-one image restoration, specifically targeting rain, haze, and snow removal. It supports neural architecture search methods and single-encoder, multi-decoder frameworks, enabling researchers to develop and test algorithms that effectively handle multiple weather-based image degradations.
Microsoft COCO	https://doi.org/10.1109/CVPR52729.2023.01351 (2023)	https://doi.org/10.1007/s11263-015-0816-y (2014)	The Microsoft COCO dataset is used for training and evaluating image restoration models, particularly focusing on common objects in context. It helps researchers assess model performance on high-quality images and identify issues with low-quality inputs, ensuring robustness in real-world scenarios. The dataset's rich annotations and diverse image content enable comprehensive evaluation and improvement of image restoration techniques.
GoPro test dataset	https://doi.org/10.48550/arXiv.2208.05244 (2022)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The GoPro test dataset is used to evaluate and compare the performance of deblurring methods, particularly in dynamic scenes. It focuses on assessing quantitative metrics and visual quality, enabling researchers to measure image restoration accuracy and overall performance against state-of-the-art techniques. This dataset supports the development and validation of advanced deblurring algorithms by providing a standardized benchmark for image quality and restoration.
CoCo	https://doi.org/10.1109/CVPR52729.2023.01351 (2023)	https://doi.org/10.1007/s11263-015-0816-y (2014)	The CoCo dataset is used to provide a rich semantic representation space for image restoration, particularly focusing on common objects in context. This enables researchers to enhance the contextual understanding and accuracy of restored images, addressing specific challenges related to object-centric restoration.
CUB	https://doi.org/10.1109/CVPR52729.2023.01351 (2023)	https://www.semanticscholar.org/paper/c069629a51f6c1c301eb20ed77bc6b586c24ce32 (2011)	The CUB dataset is used for pre-training recognition models like VGG16 and ResNet50 on clean images, which aids in evaluating restored test images from degraded sets. It is also employed in image classification tasks to compare state-of-the-art image restoration methods for both single and multiple degradations. This dataset facilitates the assessment of restoration techniques by providing a benchmark for classification accuracy post-restoration.
BSD dataset	https://doi.org/10.1109/CVPRW59228.2023.00178 (2023)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The BSD dataset is used to train and evaluate early image restoration methods, specifically employing a larger set of 400 images. This dataset helps assess the generalization and robustness of these methods, enabling researchers to test and improve the performance of image restoration techniques across diverse image content.
SCUT-CTW1500	https://doi.org/10.1109/CVPRW59228.2023.00178 (2023)	https://doi.org/10.1109/CVPR.2018.00070 (2018)	The SCUT-CTW1500 dataset is primarily used for evaluating curve text detection in wild images. It focuses on the restoration and recognition of curved text in diverse environments, employing methodologies that test the accuracy and robustness of text detection algorithms. This dataset enables researchers to address specific challenges in recognizing and restoring curved text, enhancing the performance of text detection systems in real-world scenarios.
RO	https://doi.org/10.1109/TPAMI.2023.3330416 (2023)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The RO dataset is used to evaluate image restoration models, focusing on performance and inference speed comparisons, particularly against Restormer. It enables researchers to assess and benchmark the effectiveness of different restoration techniques, ensuring that new models meet high standards in both quality and efficiency.
RAIN 100L	https://doi.org/10.1109/TPAMI.2023.3330416 (2023)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The RAIN 100L dataset is used to evaluate the performance of rain removal algorithms, specifically focusing on synthetic rain images with varying intensities and complexities. This dataset enables researchers to test and compare different methodologies for rain removal, ensuring robustness across diverse rain conditions.
TEST 100	https://doi.org/10.1109/TPAMI.2023.3330416 (2023)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The TEST 100 dataset is used to evaluate the performance of rain removal algorithms on a controlled set of test images. Researchers employ this dataset to assess algorithm effectiveness, focusing on specific image restoration tasks such as rain removal. The dataset's smaller, controlled nature allows for precise and manageable testing environments, enabling detailed analysis of algorithmic performance in rain removal scenarios.
TEST 1200	https://doi.org/10.1109/TPAMI.2023.3330416 (2023)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The TEST 1200 dataset is used to evaluate the robustness of rain removal methods by applying these techniques to a large, diverse set of test images. This evaluation helps researchers assess the effectiveness and generalizability of rain removal algorithms across various image conditions. The dataset's diversity and size enable comprehensive testing, ensuring that the methods can handle a wide range of real-world scenarios.
TEST 2800	https://doi.org/10.1109/TPAMI.2023.3330416 (2023)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The TEST 2800 dataset is used to evaluate the scalability and generalization of rain removal techniques on a large set of test images. It provides a comprehensive benchmark for assessing the performance of these techniques under diverse conditions, enabling researchers to validate the robustness and effectiveness of their methods in removing rain from images.
AAHCS	https://doi.org/10.1109/TGRS.2024.3378828 (2024)	https://doi.org/10.1109/LGRS.2017.2771212 (2017)	The AAHCS dataset is used for hyperspectral image reconstruction, employing compressive sensing and tensor decomposition techniques. It enables researchers to address challenges in efficiently reconstructing high-dimensional hyperspectral images from compressed measurements, facilitating advancements in hyperspectral imaging technology.
SPACE	https://doi.org/10.1109/TGRS.2024.3378828 (2024)	https://doi.org/10.1109/LGRS.2017.2771212 (2017)	The SPACE dataset is primarily used for hyperspectral image reconstruction, employing methodologies such as compressive sensing and tensor decomposition. It addresses research questions related to efficient and accurate reconstruction of hyperspectral images from compressed data. The dataset's characteristics enable researchers to test and validate advanced reconstruction algorithms, enhancing the quality and resolution of hyperspectral imagery.
H-LSS	https://doi.org/10.1109/TGRS.2024.3378828 (2024)	https://doi.org/10.1109/LGRS.2017.2771212 (2017)	The H-LSS dataset is primarily used for hyperspectral image reconstruction, employing methodologies such as compressive sensing and tensor decomposition. This dataset enables researchers to address challenges in efficiently reconstructing high-dimensional hyperspectral images from compressed measurements, enhancing the quality and resolution of the reconstructed images. The dataset's characteristics support advanced signal processing techniques, making it valuable for improving the accuracy and efficiency of hyperspectral imaging applications.
Set68	https://www.semanticscholar.org/paper/cbd65255f6266f798326acc8e0654e40ea0918cf (2018)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	Set68 is used for testing image restoration and denoising models, focusing on performance evaluation at specific noise levels (σ = 15, 25, 50). The dataset enables researchers to assess model effectiveness under controlled conditions, providing a standardized benchmark for comparing different image restoration techniques.
Outdoor	https://doi.org/10.1109/TIP.2024.3368961 (2023)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The 'Outdoor' dataset is used to train models on heavy rain images containing rain streaks and haze, enhancing the model's performance in complex weather conditions. This dataset specifically supports research in image restoration under challenging environmental scenarios, focusing on improving visual clarity and detail recovery in adverse weather.
CelebA-Test	https://doi.org/10.48550/arXiv.2308.15070 (2023)	https://doi.org/10.1109/ICCV.2015.425 (2014)	The CelebA-Test dataset is used to evaluate the performance of image restoration methods, specifically DiffBIR and BFR. It focuses on achieving high FID scores and improving attribute restoration and recognition accuracy on synthetic face images. The dataset's facial attributes and synthetic nature enable researchers to rigorously test and compare different restoration techniques.
SateHaze1k-Thin	https://doi.org/10.1109/TPAMI.2024.3419007 (2024)	https://doi.org/10.1007/978-3-030-58610-2_28 (2020)	The SateHaze1k-Thin dataset is used to evaluate model performance in remote sensing image dehazing, specifically under thin haze conditions. Researchers apply this dataset to assess the effectiveness of dehazing algorithms, focusing on the clarity and quality of restored images. The dataset's emphasis on thin haze scenarios makes it particularly useful for refining and testing dehazing techniques in less severe atmospheric conditions.
SateHaze1k-Moderate	https://doi.org/10.1109/TPAMI.2024.3419007 (2024)	https://doi.org/10.1007/978-3-030-58610-2_28 (2020)	The SateHaze1k-Moderate dataset is used to evaluate the effectiveness of dehazing models in moderate haze conditions for remote sensing images. It specifically tests the model's ability to achieve high-quality dehazing, focusing on improving image clarity and detail in hazy satellite imagery. This dataset enables researchers to assess and enhance dehazing algorithms, ensuring they perform well under realistic atmospheric conditions.
SateHaze1k-Thick	https://doi.org/10.1109/TPAMI.2024.3419007 (2024)	https://doi.org/10.1007/978-3-030-58610-2_28 (2020)	The SateHaze1k-Thick dataset is used to evaluate the robustness of models in thick haze conditions for remote sensing images. It is employed to demonstrate state-of-the-art performance in this challenging environment, focusing on the ability of models to maintain accuracy and reliability under dense atmospheric haze. This dataset specifically enables researchers to test and improve image restoration techniques in real-world, hazy conditions.
ISTD	https://doi.org/10.48550/arXiv.2203.06074 (2022)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The ISTD dataset is primarily used for shadow removal in images, enhancing overall image quality by effectively reducing shadow effects. This dataset supports research focused on improving visual clarity and detail in images affected by shadows. The methodologies employed involve techniques to identify and mitigate shadow impacts, contributing to advancements in image restoration and enhancement.
our unpaired training set	https://doi.org/10.1109/TIP.2021.3051462 (2019)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The 'our unpaired training set' dataset is used to train a vanilla CycleGAN for low-light image enhancement. It is employed to compare the performance of this method against other techniques such as RetinexNet, SRIE, LIME, and NPE. This dataset enables researchers to evaluate and benchmark different low-light image enhancement approaches, focusing on the effectiveness and efficiency of CycleGAN in this context.
BBD-100k	https://doi.org/10.1109/TIP.2021.3051462 (2019)	https://doi.org/10.1109/cvpr42600.2020.00271 (2018)	The BBD-100k dataset is used to evaluate and demonstrate the effectiveness of image restoration techniques, particularly in diverse driving scenarios. It supports visual comparisons and showcases the ability of models like EnlightenGAN to improve image quality. The dataset's diverse scenarios enable researchers to test and validate multitask learning approaches in image restoration.
Snow realistic	https://doi.org/10.1109/ICCV51070.2023.01983 (2023)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The 'Snow realistic' dataset is used to test and validate snow removal algorithms by providing realistic synthetic snow images. It is employed in real-world experimental analysis to assess the effectiveness of desnowing methods, enabling researchers to evaluate how well these algorithms perform on realistic snow scenes.
NYUv2	https://doi.org/10.48550/arXiv.2409.15278 (2024)	https://doi.org/10.1007/978-3-642-33715-4_54 (2012)	The NYUv2 dataset is utilized for monocular depth estimation and surface normal estimation, primarily in indoor scenes. It provides RGB-D images, which are used to evaluate image restoration techniques. The dataset's detailed RGBD images and surface normals enable researchers to assess and improve algorithms for these specific tasks, enhancing the accuracy of depth and normal predictions in indoor environments.
Hypersim	https://doi.org/10.48550/arXiv.2409.15278 (2024)	https://www.semanticscholar.org/paper/c6e57b2d36a4231cef82d7e0e27413ae4bb4dee5 (2020)	The Hypersim dataset is used for holistic indoor scene understanding, leveraging photorealistic synthetic data to train and evaluate image restoration models. It provides a rich set of annotations and high-quality images, enabling researchers to address complex challenges in scene understanding and image restoration within indoor environments.
VKITTI 2	https://doi.org/10.48550/arXiv.2409.15278 (2024)	https://www.semanticscholar.org/paper/c6e57b2d36a4231cef82d7e0e27413ae4bb4dee5 (2020)	The VKITTI 2 dataset is utilized for evaluating image restoration techniques, providing synthetic data with controlled variations. Researchers use this dataset to assess the performance of models under different conditions, focusing on the accuracy and robustness of image restoration methods. The controlled nature of the synthetic data allows for a rigorous evaluation of these techniques, enabling researchers to identify strengths and weaknesses in their models.
MagicBrush Test	https://doi.org/10.48550/arXiv.2409.15278 (2024)	https://doi.org/10.48550/arXiv.2306.10012 (2023)	The MagicBrush Test dataset is used to evaluate the effectiveness of PixWizard in instruction-guided image editing. Research focuses on assessing the accuracy and quality of image edits based on manual annotations. This dataset enables researchers to measure how well the model follows specific instructions, providing insights into the performance and reliability of instruction-based image editing techniques.
Emu Edit Test	https://doi.org/10.48550/arXiv.2409.15278 (2024)	https://doi.org/10.48550/arXiv.2306.10012 (2023)	The 'Emu Edit Test' dataset is used to assess the performance of PixWizard in precise image editing tasks. It combines recognition and generation to evaluate the precision and coherence of editing outcomes. This dataset enables researchers to test and refine algorithms for image editing, focusing on the accuracy and contextual consistency of the edits.
Rain100 L	https://doi.org/10.1109/TIV.2023.3347952 (2024)	https://doi.org/10.18535/ijecs/v5i1.12 (2016)	The Rain100 L dataset is used to train and evaluate the AirNet model, specifically addressing overfitting issues in image de-raining. The dataset employs attention mechanisms and contrastive learning to enhance the model's performance. It is crucial for assessing the effectiveness of these techniques in removing rain from images, making it a valuable resource for improving image restoration algorithms.
NTIRE	https://doi.org/10.48550/arXiv.2404.02154 (2024), https://doi.org/10.1109/CVPR52729.2023.00958 (2023)	https://doi.org/10.1109/CVPRW53098.2021.00074 (2021)	The NTIRE dataset is used to provide high-quality, high-resolution natural images for training and evaluating image restoration models. It supports tasks such as low-light enhancement and HDR recovery, enabling researchers to demonstrate superior qualitative and quantitative performance compared to zero-shot baselines. The dataset's high-resolution images facilitate robust model training and rigorous performance evaluation in these specific restoration tasks.
Laion-HR	https://doi.org/10.48550/arXiv.2404.02154 (2024), https://doi.org/10.48550/arXiv.2306.05390 (2023)	https://doi.org/10.1109/CVPRW53098.2021.00074 (2021)	The Laion-HR dataset is used for training and evaluating image restoration models, particularly focusing on high-resolution image enhancement. It serves as a large-scale, high-quality visual content subset of Laion-5B, enabling researchers to develop and test advanced image restoration techniques. This dataset's massive size and high resolution are crucial for improving the performance and robustness of image restoration models.
polyU Real World Noisy Images Dataset	https://doi.org/10.48550/arXiv.2306.05390 (2023)	https://www.semanticscholar.org/paper/fb52f9294fa1cd83660eccac486367eac01ea32d (2018)	The polyU Real World Noisy Images Dataset is used to train color denoising models, specifically focusing on real-world noisy images. This dataset enhances the denoising performance in practical scenarios by providing realistic noise patterns, enabling researchers to develop more effective and robust image restoration techniques.
Smartphone Image Denoising Dataset (SIDD)	https://doi.org/10.48550/arXiv.2306.05390 (2023)	https://www.semanticscholar.org/paper/fb52f9294fa1cd83660eccac486367eac01ea32d (2018)	The Smartphone Image Denoising Dataset (SIDD) is primarily used to train and evaluate color denoising models, focusing on noise reduction in images captured by smartphone cameras. This dataset enables researchers to develop and test algorithms that enhance image quality by specifically addressing the unique noise characteristics of smartphone camera sensors.
Rain1400	https://doi.org/10.48550/arXiv.2306.05390 (2023)	https://doi.org/10.1109/CVPR.2016.299 (2016)	The Rain1400 dataset is used for training and evaluating deraining models, offering a diverse collection of synthetic and real-world rainy images. This dataset enables researchers to test the effectiveness of their models in removing rain artifacts from images, thereby improving image clarity and quality. The diversity of the dataset supports robust model evaluation across various rainy conditions.
DDN 12	https://doi.org/10.48550/arXiv.2404.12091 (2024)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The DDN 12 dataset is used to evaluate de-raining techniques on a large set of synthetic rainy images. Researchers employ this dataset to test the scalability and performance of feature extractors in de-raining tasks, focusing on how well these methods generalize to a broader range of synthetic data. This evaluation helps in assessing the robustness and efficiency of de-raining algorithms.
RealInt	https://doi.org/10.48550/arXiv.2404.12091 (2024)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The RealInt dataset is used to evaluate de-raining techniques on real-world rainy images. Researchers focus on the practical effectiveness of feature extractors by testing their performance on this dataset. This enables the assessment of how well these methods can remove rain artifacts and improve image quality in real-world conditions.
DDN 4	https://doi.org/10.48550/arXiv.2404.12091 (2024)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The DDN 4 dataset is used to evaluate de-raining performance on a limited set of synthetic rainy images. Researchers focus on the accuracy of the feature extractor, employing the dataset to assess how effectively it can isolate and correct rain artifacts. This specific application highlights the dataset's utility in refining image restoration techniques, particularly in controlled, synthetic environments.
Clean	https://doi.org/10.48550/arXiv.2404.12091 (2024)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The 'Clean' dataset is used as a baseline to evaluate the quality of de-rained images by comparing them against clean images. This ensures that the feature extractor maintains image fidelity. The dataset enables researchers to assess the effectiveness of image restoration techniques, specifically focusing on de-raining, by providing a standard reference for image quality.
CelebA 1K	https://doi.org/10.48550/arXiv.2308.09388 (2023)	https://doi.org/10.1109/ICCV.2015.425 (2014)	The CelebA 1K dataset is used to test and evaluate image restoration models, specifically focusing on 4x super-resolution and zero-shot deblurring tasks. It is employed to enhance facial details and textures in celebrity images, enabling researchers to assess the performance of these models in restoring and deblurring facial features.
UCID	https://doi.org/10.48550/arXiv.2404.12091 (2024)	https://doi.org/10.1117/12.525375 (2003)	The UCID dataset is used to illustrate the potential overlap in ground truths with the BSD dataset, impacting the separation of dataset-level or density-level properties in instance-level representations. This highlights issues in embedding space separation, aiding researchers in understanding and addressing these overlaps in their methodologies.
DVD	https://doi.org/10.1109/ICCV.2019.00897 (2019)	https://doi.org/10.1109/CVPR.2017.33 (2017)	The DVD dataset is used in image restoration research, specifically for evaluating and training deblurring models. It consists of 600 images, primarily focusing on motion blur correction. Researchers select every second frame to diversify the training data and prevent overfitting, enhancing the robustness of deblurring techniques. This dataset enables the development and assessment of advanced image restoration methods by providing a diverse set of blurred images.
RealDAE	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.1109/CVPR.2018.00494 (2018)	The RealDAE dataset is used in image restoration research, specifically for evaluating and training models on real-world degraded images. It contributes 450 real-world images to the training process, enhancing the model's performance on actual data. The dataset is crucial for assessing the effectiveness of image restoration methods on authentic, challenging test cases.
VE-LOL-L	https://doi.org/10.1109/CVPR52729.2023.00958 (2023)	https://doi.org/10.1109/TPAMI.2021.3126387 (2021)	The VE-LOL-L dataset is used for evaluating low-light video enhancement, specifically focusing on temporal consistency and visual quality in dark videos. It assesses the performance of methods like GDP in enhancing video content under low-light conditions, ensuring that the enhanced videos maintain both clarity and temporal coherence. This dataset enables researchers to rigorously test and compare different enhancement techniques in challenging lighting scenarios.
RDD	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.1109/ICIP46576.2022.9897217 (2022)	The RDD dataset is used to train models for image restoration tasks, specifically contributing 4,371 real images to the training set. It is also utilized to train BGSNet for document shadow removal, emphasizing real-world scenarios and high-resolution images. This dataset enables researchers to develop and refine algorithms that enhance image quality and remove shadows in documents, leveraging its large, realistic image collection.
BSD-grayscale	https://doi.org/10.1109/CVPR.2019.00717 (2019)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The BSD-grayscale dataset is used for training and testing image restoration models, particularly focusing on grayscale images. It evaluates the performance of techniques such as denoising and deblurring, specifically assessing the effectiveness of the DuRN-P model in removing additive Gaussian noise at levels 30, 50, and 70. This dataset enables researchers to benchmark and compare different restoration methods in controlled conditions.
BSDS500	https://doi.org/10.1109/CVPRW63382.2024.00645 (2024)		The BSDS500 dataset is primarily used to evaluate edge detection and segmentation performance, which is crucial for assessing the effectiveness of image restoration algorithms in preserving fine image details. Researchers employ this dataset to test and compare different methodologies, focusing on how well these techniques maintain structural integrity and clarity in restored images. The dataset's rich set of annotated images enables rigorous and standardized evaluation, facilitating advancements in image processing and computer vision.
exposure correction dataset	https://doi.org/10.1109/CVPR52729.2023.01350 (2022)	https://www.semanticscholar.org/paper/5ee57b18a7be2b671ffc6f5ce5dbbe92112ee0fb (2007)	The exposure correction dataset, derived from the MIT-Adobe FiveK dataset, is used to evaluate the ShadowDiffusion model for improving image quality through exposure correction. Researchers focus on assessing the model's performance in enhancing images, specifically addressing issues related to shadow and exposure. This publicly available dataset enables rigorous evaluation and comparison of image restoration techniques.
ctest10k	https://doi.org/10.1145/3528233.3530757 (2021)	https://doi.org/10.1007/978-3-319-46493-0_35 (2016)	The ctest10k dataset is used for evaluating image restoration models, particularly focusing on the 10,000 image subset from the ImageNet validation set. It is employed to assess the performance of these models, with specific emphasis on colorization tasks. This dataset enables researchers to benchmark and compare different image restoration techniques, ensuring robust evaluation through a standardized set of images.
MS-COCO	https://doi.org/10.1145/3528233.3530757 (2021), https://doi.org/10.1007/978-3-031-73661-2_25 (2023)	https://doi.org/10.1109/TMM.2019.2895280 (2019)	The MS-COCO dataset is used for training and evaluation in image restoration research. It features a large-scale collection of images with diverse annotations, enabling the selection of image-prompt pairs from the validation set to assess restoration methods, particularly focusing on common objects in context. This dataset's extensive and varied content supports robust model training and evaluation.
Rain-1 Drop	https://doi.org/10.48550/arXiv.2503.10120 (2025)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The Rain-1 Drop dataset is used to train and evaluate models for raindrop removal from images, focusing on realistic raindrop effects. This dataset enables researchers to develop and test algorithms that enhance image quality by removing raindrops, addressing the specific challenge of realistic raindrop simulation in image restoration tasks.
SNOW 100K	https://doi.org/10.1109/TCSVT.2024.3429557 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The SNOW 100K dataset is used to evaluate model performance in complex snow scenarios, focusing on the effectiveness of models in addressing intricate snow degradations. This dataset enables researchers to test and validate their models against challenging snow conditions, ensuring robustness and reliability in image restoration tasks.
MEF	https://doi.org/10.1109/CVPR52733.2024.02404 (2024)	https://doi.org/10.1109/TIP.2013.2261309 (2013)	The MEF dataset is used to evaluate multi-exposure image fusion techniques, specifically focusing on perceptual quality and the preservation of naturalness in real-world scenarios. Researchers employ this dataset to assess and compare different fusion methods, ensuring that the resulting images maintain high visual fidelity and realism. This evaluation helps in advancing image processing algorithms for practical applications.
NPE	https://doi.org/10.1109/CVPR52733.2024.02404 (2024)	https://doi.org/10.1109/TIP.2013.2261309 (2013)	The NPE dataset is used to evaluate non-uniform illumination image enhancement techniques, focusing on preserving naturalness and enhancing visual quality in images with challenging lighting conditions. Researchers employ this dataset to assess the effectiveness of their methods in improving image appearance while maintaining realistic and natural visual attributes.
DICM	https://doi.org/10.1109/CVPR52733.2024.02404 (2024)	https://doi.org/10.1109/TIP.2013.2261309 (2013)	The DICM dataset is used to test image restoration methods in real-world settings, particularly focusing on scenarios where ground truth data is unavailable. This dataset enables researchers to evaluate the practical applicability and robustness of their restoration techniques in more realistic conditions, enhancing the reliability of image restoration methods.
Nature dataset	https://doi.org/10.1109/TCSVT.2023.3286405 (2024)	https://doi.org/10.1109/ICCV.2017.423 (2017)	The Nature dataset is used to evaluate image restoration methods, particularly focusing on reflection removal performance. It consists of 20 indoor and outdoor scene pairs, constructed by IBCLN, to assess restoration quality in diverse natural settings. This dataset emphasizes the versatility of image restoration techniques in handling various environmental conditions.
PIPAL full set	https://doi.org/10.1007/978-3-030-58621-8_37 (2020)	https://www.semanticscholar.org/paper/8c92054c26fb4c6dd7435bc99fbb8af3323eae1b (2019)	The PIPAL full set dataset is used to evaluate the performance of anti-aliasing pooling layers in image quality assessment, specifically focusing on full-reference image distortions. This dataset enables researchers to assess and compare different anti-aliasing techniques by providing a comprehensive set of distorted images and their corresponding reference images, facilitating the development and validation of image quality metrics.
GAN-based distortion subset	https://doi.org/10.1007/978-3-030-58621-8_37 (2020)	https://www.semanticscholar.org/paper/8c92054c26fb4c6dd7435bc99fbb8af3323eae1b (2019)	The GAN-based distortion subset is used to evaluate the impact of anti-aliasing pooling layers on GAN-generated images, focusing on distortion effects and synthetic artifacts. This dataset enhances the assessment of robustness in GAN-generated images, specifically addressing how anti-aliasing techniques improve image quality and reduce distortions.
Outdoor-Rain-Test	https://doi.org/10.48550/arXiv.2305.17863 (2023)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The Outdoor-Rain-Test dataset is used for evaluating image restoration models, particularly in outdoor scenes affected by haze and rain. It focuses on assessing the quality of dehazing and restoration under real-world degradation conditions, especially heavy rain. This dataset enables researchers to test and compare the effectiveness of various image restoration methods in challenging environmental scenarios.
WorldView II	https://www.semanticscholar.org/paper/4b688c486f2b223212682fd2b3f72cc0caa94b1b (2023)	https://doi.org/10.1007/978-3-031-19800-7_10 (2022)	The WorldView II dataset is used for evaluating image restoration techniques, particularly in enhancing the clarity and detail of high-resolution satellite imagery. Researchers employ this dataset to assess the effectiveness of various restoration methods, focusing on improving image quality and detail. This dataset's high-resolution characteristics make it suitable for testing and validating advanced image restoration algorithms.
WorldView III	https://www.semanticscholar.org/paper/4b688c486f2b223212682fd2b3f72cc0caa94b1b (2023)	https://doi.org/10.1007/978-3-031-19800-7_10 (2022)	The WorldView III dataset is used for evaluating image restoration techniques, particularly focusing on high-resolution satellite imagery. Researchers employ this dataset to enhance the clarity and detail of satellite images, addressing specific challenges in image restoration. The high resolution and detailed nature of the dataset enable precise evaluation and improvement of restoration algorithms.
GaoFen2	https://www.semanticscholar.org/paper/4b688c486f2b223212682fd2b3f72cc0caa94b1b (2023)	https://doi.org/10.1007/978-3-031-19800-7_10 (2022)	The GaoFen2 dataset is used for evaluating image restoration techniques, particularly in enhancing the clarity and detail of high-resolution satellite imagery. Researchers employ this dataset to test and validate their methods, focusing on improving image quality in satellite applications. The dataset's high-resolution characteristics make it suitable for assessing the effectiveness of restoration algorithms in real-world scenarios.
DID 1	https://doi.org/10.48550/arXiv.2404.12091 (2024)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The DID 1 dataset is used to evaluate de-raining performance on a small, diverse set of synthetic rainy images. Researchers employ this dataset to assess the generalizability of feature extractors, focusing on how well these models can handle varied synthetic rain conditions. This evaluation helps in understanding the robustness and adaptability of image restoration techniques.
DID 3	https://doi.org/10.48550/arXiv.2404.12091 (2024)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The DID 3 dataset is used to test de-raining algorithms on a moderate set of diverse synthetic rainy images. Researchers focus on evaluating the consistency of the feature extractor, ensuring that the model can reliably remove rain artifacts while preserving image details. This dataset enables the assessment of de-raining techniques in controlled, synthetic environments.
FFHQ-raw	https://doi.org/10.1109/CVPR52733.2024.02425 (2024)	https://doi.org/10.1109/CVPR.2019.00453 (2018)	The FFHQ-raw dataset is used to enhance face restoration performance by providing 70,000 unaligned high-resolution facial images for training models. This dataset specifically supports research in improving the quality and accuracy of face restoration techniques, enabling models to better handle diverse and complex facial images.
BAPPS	https://www.semanticscholar.org/paper/f942a4a56e6549c83844747ad6c4ae58000b2988 (2020)	https://doi.org/10.1109/CVPR.2018.00194 (2018)	The BAPPS dataset is used as a benchmark for perceptual image quality assessment, specifically to evaluate the effectiveness of image restoration algorithms in preserving visual fidelity. It enables researchers to assess how well these algorithms maintain the perceptual quality of restored images, focusing on the visual fidelity aspect rather than just technical metrics. This dataset facilitates the comparison and validation of different image restoration techniques in terms of their ability to produce visually pleasing results.
DIV2K train set	https://doi.org/10.1109/ICCV51070.2023.00495 (2023)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The DIV2K train set is used for training image restoration models, specifically focusing on high-resolution image recovery and enhancement. This dataset enables researchers to develop and refine algorithms that improve image quality, addressing issues such as resolution, clarity, and detail. Its high-resolution images provide a robust foundation for training models to perform advanced image restoration tasks.
DIV8K train set	https://doi.org/10.1109/ICCV51070.2023.00495 (2023)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The DIV8K train set is used for training image restoration models, providing a larger dataset to enhance model performance. This dataset supports the development and improvement of image restoration techniques by offering a substantial amount of data, which is crucial for training robust and effective models.
Snow100K-M	https://doi.org/10.48550/arXiv.2207.04754 (2022)	https://doi.org/10.1109/TCSVT.2020.3003025 (2021)	The Snow100K-M dataset is used to evaluate the performance of SMGARN in de-snowing images, focusing on PSNR improvements compared to DS-GAN. This dataset enables researchers to quantitatively assess and compare the effectiveness of different de-snowing algorithms, specifically in enhancing image quality metrics.
new dataset	https://doi.org/10.1109/CVPR52688.2022.00239 (2021)	https://doi.org/10.1109/CVPR.2018.00263 (2017)	The 'new dataset' is specifically used for raindrop removal in image restoration research. It supports the training and evaluation of models aimed at restoring images degraded by raindrops. This dataset enables researchers to develop and test algorithms that enhance image quality by effectively removing raindrop artifacts, thereby improving the clarity and usability of images in various applications.
RESIDE’s Synthetic Objective Testing Set (SOTS) outdoor	https://doi.org/10.48550/arXiv.2409.00263 (2024)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The RESIDE’s Synthetic Objective Testing Set (SOTS) outdoor dataset is used for evaluating de-hazing algorithms. It consists of 500 paired images, enabling researchers to assess algorithm performance in outdoor conditions. This dataset facilitates the testing and comparison of de-hazing techniques by providing a standardized set of images, ensuring consistent evaluation across different studies.
RED	https://www.semanticscholar.org/paper/3d3c5fcbc40aadccceda58d3d9c5cd00588ea0b7 (2022)	https://doi.org/10.1137/16M1102884 (2016)	The RED dataset is used for image restoration experiments, focusing on denoising and regularization techniques to enhance image quality and reduce noise. Researchers employ this dataset to test and validate algorithms that improve visual clarity, leveraging its characteristics to address specific challenges in image processing.
LSUN bedrooms	https://www.semanticscholar.org/paper/3d3c5fcbc40aadccceda58d3d9c5cd00588ea0b7 (2022)	https://www.semanticscholar.org/paper/4dcdae25a5e33682953f0853ee4cf7ca93be58a9 (2015)	The LSUN bedrooms dataset is used to train and evaluate image restoration models, specifically focusing on bedroom images at 256x256 resolution. This dataset enables researchers to assess the performance of restoration techniques in enhancing or repairing degraded images within a consistent and well-defined context.
Snow100K-real	https://doi.org/10.1109/TIP.2024.3501855 (2024)	https://doi.org/10.1109/CVPR52688.2022.01693 (2022)	The Snow100K-real dataset is used to evaluate and compare the performance of MWFormer and other models on real weather-degraded images, specifically focusing on restoration under unknown corruptions. This dataset enables researchers to assess the effectiveness of image restoration techniques in realistic conditions, providing a benchmark for model accuracy and robustness.
LSUN cats	https://www.semanticscholar.org/paper/3d3c5fcbc40aadccceda58d3d9c5cd00588ea0b7 (2022)	https://www.semanticscholar.org/paper/4dcdae25a5e33682953f0853ee4cf7ca93be58a9 (2015)	The LSUN cats dataset is used to train and evaluate image restoration models, specifically focusing on cat images at 256x256 resolution. This dataset enables researchers to assess the performance of restoration techniques tailored to high-resolution cat images, providing a standardized benchmark for comparing different models.
real-world rainy images	https://doi.org/10.1109/TIP.2024.3501855 (2024)	https://doi.org/10.1007/978-3-031-20071-7_42 (2022)	The 'real-world rainy images' dataset is used to train a novel deraining network, specifically focusing on enhancing the robustness and generalization of the model in real-world scenarios. This dataset enables researchers to address the challenge of removing rain artifacts from images, improving image quality and usability in various applications.
real-world de-snowing dataset	https://doi.org/10.48550/arXiv.2412.00878 (2024)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The real-world de-snowing dataset is used to evaluate de-snowing algorithms by assessing their performance on practical, real-world images. This dataset enables researchers to focus on the effectiveness of these algorithms in realistic scenarios, ensuring that they can handle the complexities and variations present in actual snowy conditions. The dataset's emphasis on real-world images provides a robust testbed for algorithmic improvements and performance validation.
LOL-v2-real	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1016/j.cviu.2022.103403 (2022)	The LOL-v2-real dataset is used to validate the performance of UniUIR on real-world low-light image enhancement. It is employed to compare UniUIR against other methods, focusing on enhancing images captured in low-light conditions. This dataset enables researchers to assess the effectiveness and superiority of different image enhancement techniques in practical scenarios.
SID	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1016/j.cviu.2022.103403 (2022)	The SID dataset is used to validate the performance of UniUIR on low-light image enhancement, specifically focusing on images captured by Sony cameras. This dataset enables researchers to assess and improve the effectiveness of image restoration techniques under low-light conditions, ensuring that the enhancements are robust and reliable for Sony camera images.
BAID	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1016/j.cviu.2022.103403 (2022)	The BAID dataset is used to validate the performance of UniUIR on backlit image enhancement, specifically by comparing it against other methods. This dataset enables researchers to assess and benchmark the effectiveness of image restoration techniques in enhancing backlit images, focusing on the improvement of visual quality and detail recovery.
T90	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/ICCV51070.2023.00371 (2023)	The T90 dataset is used to assess the effectiveness of underwater image restoration techniques on segmentation performance. Researchers apply the Segment Anything Model (SAM) to restored images from various underwater image restoration (UIR) methods, evaluating how these enhancements improve segmentation accuracy. This dataset enables the comparison of different UIR approaches and their impact on downstream computer vision tasks.
Waterloo Exploration	https://doi.org/10.48550/arXiv.2301.11699 (2023)	https://doi.org/10.1109/TPAMI.2010.161 (2011)	The Waterloo Exploration dataset is used to train models for image denoising, providing a rich set of high-quality images that enhance the comprehensiveness of the training process. This dataset supports the development of robust image restoration techniques by offering diverse and high-fidelity images, enabling researchers to improve model performance in denoising tasks.
DPDD dataset	https://doi.org/10.1007/978-3-031-20071-7_4 (2021)	https://doi.org/10.1007/978-3-030-58607-2_7 (2020)	The DPDD dataset is used for qualitative evaluation of the TLC method in dual-pixel defocus deblurring, specifically focusing on image restoration quality and performance. It enables researchers to assess and compare the effectiveness of defocus deblurring techniques, providing a benchmark for evaluating restoration algorithms.
DPDD testset	https://doi.org/10.1007/978-3-031-20071-7_4 (2021)	https://doi.org/10.1007/978-3-030-58607-2_7 (2020)	The DPDD testset is used to evaluate defocus deblurring methods, focusing on performance comparisons across 37 indoor and 39 outdoor scenes. This dataset enables researchers to assess the effectiveness of various deblurring techniques in diverse environmental conditions, providing a standardized benchmark for methodological advancements in image restoration.
IPT Dataset	https://doi.org/10.1007/978-3-031-20071-7_4 (2021)	https://doi.org/10.1109/CVPR46437.2021.01212 (2020)	The IPT Dataset is used for training and evaluating image processing transformers, specifically focusing on restoration tasks. It enables researchers to assess performance metrics, ensuring that models can effectively restore images. This dataset supports the development and refinement of image restoration techniques through rigorous evaluation.
RealBlur dataset	https://doi.org/10.48550/arXiv.2208.05244 (2022)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The RealBlur dataset is used to train deblurring generators, specifically focusing on real-world blur scenarios. This enhances the performance of deblurring algorithms by providing realistic training data. The dataset's emphasis on authentic blur conditions enables researchers to develop more effective and robust deblurring techniques.
Caltech-UCSD Birds-200-2011	https://doi.org/10.1109/CVPR52729.2023.01351 (2023)	https://www.semanticscholar.org/paper/c069629a51f6c1c301eb20ed77bc6b586c24ce32 (2011)	The Caltech-UCSD Birds-200-2011 dataset is used to evaluate image restoration methods, particularly in the context of bird classification tasks. Researchers focus on assessing the performance of these methods under low contrast conditions, utilizing the dataset's detailed images of birds to test and improve the accuracy of classification algorithms in challenging visual environments.
Outdoor-Rain test samples	https://doi.org/10.1109/TPAMI.2023.3238179 (2022)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The 'Outdoor-Rain test samples' dataset is used to qualitatively evaluate and compare the performance of different models, such as the best model, HRGAN, and MPRNet, in heavy rain image restoration. Research focuses on visual quality and detail preservation, employing the dataset to assess and contrast the effectiveness of these models in restoring images degraded by heavy rain.
Outdoor-Rain test images	https://doi.org/10.1109/TPAMI.2023.3238179 (2022)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The 'Outdoor-Rain test images' dataset is used to evaluate the performance of rain image restoration models, particularly in comparing RainHazeDiff64 against HRGAN and MPRNet. Visual quality assessments are employed to assess model effectiveness. This dataset enables researchers to benchmark and refine algorithms designed to restore images degraded by rain, focusing on enhancing visual clarity and detail.
SnowTest100K	https://doi.org/10.1109/TPAMI.2023.3238179 (2022)	https://doi.org/10.1109/TIP.2021.3104166 (2021)	The SnowTest100K dataset is used to qualitatively evaluate and compare the performance of different models, specifically the best model, DesnowNet, and DDMSNet, in snow removal tasks. It leverages semantic and depth priors to enhance the accuracy and effectiveness of snow removal techniques. This dataset enables researchers to assess the visual quality and robustness of these models in handling snow-related image restoration challenges.
RainDS	https://doi.org/10.1109/TPAMI.2023.3238179 (2022)	https://doi.org/10.1109/CVPR46437.2021.00903 (2021)	The RainDS dataset is used to evaluate the effectiveness of raindrop removal methods in image restoration. It consists of 97 real-world test images, providing practical test cases to assess the performance of restoration techniques. This dataset enables researchers to validate their algorithms against real raindrop distortions, ensuring robustness and reliability in various conditions.
CelebChild-Test	https://doi.org/10.48550/arXiv.2308.15070 (2023)	https://doi.org/10.1109/ICCV.2015.425 (2014)	The CelebChild-Test dataset is used to evaluate the BFR method on real-world child face images, focusing on the robustness and generalization of the model. This dataset specifically supports research in facial image restoration, enabling researchers to test how well their models perform on diverse and challenging child face images.
SATE HAZE 1K	https://doi.org/10.1109/TPAMI.2024.3419007 (2024)	https://doi.org/10.1007/978-3-030-01449-0_52 (2018)	The SATE HAZE 1K dataset is used to evaluate dehazing algorithms specifically for remote sensing images, including satellite and aerial imagery. Researchers employ this dataset to assess the performance of dehazing techniques, focusing on improving image clarity and quality in these types of images. The dataset's relevance lies in its application to enhance the visibility and usability of remote sensing data in various environmental and monitoring studies.
CSBD68	https://doi.org/10.1109/CVPR.2019.01131 (2019)	https://doi.org/10.1109/TIP.2017.2662206 (2016)	The CSBD68 dataset is used to train and evaluate image denoising models, specifically focusing on residual learning with deep CNNs in RGB channels. This dataset enables researchers to assess the performance of their models in removing noise while preserving image details, contributing to advancements in image restoration techniques.
LOL ProRes	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	The LOL ProRes dataset is primarily used for low-light image enhancement, focusing on improving visibility and detail in dark images. Researchers employ this dataset to develop and evaluate algorithms that enhance image quality under low-light conditions. The dataset's characteristics, such as a wide range of low-light images, enable robust testing and validation of enhancement techniques. This application addresses the specific research question of how to effectively restore and enhance images captured in low-light environments.
ExDark	https://doi.org/10.1109/TIP.2021.3051462 (2019)	https://doi.org/10.1109/ICCV.2017.511 (2017)	The ExDark dataset is used to investigate the impact of light enhancement on extremely dark images, focusing on improving subsequent high-level vision tasks. Researchers employ this dataset to evaluate and develop methods for enhancing image quality under low-light conditions, which is crucial for applications such as surveillance and nighttime photography. The dataset's characteristic low-light images enable the assessment of light enhancement techniques and their effectiveness in supporting advanced vision tasks.
Enhancing Under-water Visual Perception (EUVP)	https://doi.org/10.48550/arXiv.2310.10123 (2023)	https://doi.org/10.1109/CVPR46437.2021.00906 (2020)	The EUVP dataset is used to evaluate techniques for reducing underexposure and blur artifacts in underwater images, enhancing visual perception. Researchers employ this dataset to test and compare methods that improve image clarity and quality, focusing on specific visual perception challenges in underwater environments. This dataset enables rigorous assessment of image restoration algorithms tailored for underwater conditions.
unseen under-display-camera dataset	https://doi.org/10.48550/arXiv.2310.10123 (2023)	https://doi.org/10.48550/arXiv.2309.06380 (2023)	The unseen under-display-camera dataset is used to test image restoration techniques, specifically focusing on artifact removal and enhancing image quality from under-display-camera images. This dataset enables researchers to evaluate and improve the performance of image restoration algorithms in addressing unique artifacts and quality issues associated with under-display-camera technology.
Enhancing Underwater Visual Perception (EUVP) dataset	https://doi.org/10.48550/arXiv.2310.10123 (2023)	https://doi.org/10.48550/arXiv.2309.06380 (2023)	The EUVP dataset is used to evaluate image restoration methods on underwater images, focusing on issues such as color correction and clarity improvement. Researchers employ this dataset to test and validate their algorithms, ensuring they effectively enhance visual perception in underwater environments. The dataset's relevance lies in its ability to provide realistic challenges for image restoration techniques, making it a valuable resource for advancing underwater visual perception.
JPEG Artifacts	https://doi.org/10.1109/CVPRW53098.2021.00027 (2021)	https://doi.org/10.1109/CVPRW53098.2021.00025 (2021)	The JPEG Artifacts dataset is used to evaluate image restoration methods, particularly in reducing JPEG compression artifacts. It features images with a PSNR of 29.70, which helps researchers assess the effectiveness of their restoration techniques. This dataset enables the comparison and validation of different methods aimed at improving image quality post-compression.
REDS-val-300	https://doi.org/10.1109/CVPRW53098.2021.00027 (2021)	https://doi.org/10.1109/CVPRW53098.2021.00025 (2021)	The REDS-val-300 dataset is used for evaluating image deblurring methods, specifically focusing on the performance of algorithms on a subset of 300 validation images. This dataset enables researchers to assess the effectiveness of deblurring techniques by providing a standardized set of images for benchmarking.
Real-world Task-driven Testing Set (RTTS)	https://doi.org/10.1109/ICCV51070.2023.01983 (2023)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Real-world Task-driven Testing Set (RTTS) is used for evaluating image restoration techniques on real-world degraded images. It focuses on task-driven performance metrics, enabling researchers to assess the effectiveness of restoration methods in practical scenarios. This dataset provides a benchmark for comparing different restoration algorithms under realistic conditions.
Rain In Driving (RID)	https://doi.org/10.1109/ICCV51070.2023.01983 (2023)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Rain In Driving (RID) dataset is utilized to evaluate rain removal techniques in driving scenarios. It focuses on analyzing the impact of these techniques on visibility and safety. The dataset enables researchers to assess how effectively different methods can enhance image clarity and, consequently, improve driving conditions during rainy weather.
RTTS	https://doi.org/10.1109/ICCV51070.2023.01983 (2023)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The RTTS dataset is used for real-world experimental analysis in snow removal, providing diverse scenarios to test the robustness of models. It enables researchers to evaluate and improve the performance of image restoration techniques under varied and challenging conditions, focusing on the practical application of these methods in real-world settings.
RID	https://doi.org/10.1109/ICCV51070.2023.01983 (2023)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The RID dataset is used for real-world experimental analysis in snow removal, incorporating both real and synthetic images to evaluate model performance. It provides a diverse set of images that enable researchers to assess the effectiveness of image restoration techniques specifically in snow removal scenarios.
ORD database	https://doi.org/10.1109/ICCV51070.2023.01983 (2023)	https://doi.org/10.1109/CVPR52688.2022.01713 (2022)	The ORD database is used to evaluate the performance of multi-weather image restoration methods, specifically focusing on object detection and depth estimation in both degraded and restored images. This dataset enables researchers to assess how well restoration techniques improve image quality under various weather conditions, enhancing the accuracy of subsequent computer vision tasks.
Comprehensive Snow Database (CSD)	https://doi.org/10.1109/ICCV51070.2023.01983 (2023)	https://doi.org/10.1109/ICCV48922.2021.00416 (2021)	The Comprehensive Snow Database (CSD) is used for training and testing image restoration algorithms, focusing on mitigating snow and fog degradation. It contains 8000 training and 2000 testing images, enabling researchers to develop and evaluate algorithms that enhance image quality under adverse weather conditions. This dataset supports the advancement of image restoration techniques by providing a diverse set of images that simulate real-world challenges.
Waterloo Exploration Dataset (WED)	https://doi.org/10.48550/arXiv.2412.20066 (2024)	https://doi.org/10.1109/TIP.2016.2631888 (2017)	The Waterloo Exploration Dataset (WED) is used for training models like MaIR on synthetic noise removal tasks. It introduces new challenges for image quality assessment, enhancing the robustness of restoration algorithms. The dataset's synthetic noise characteristics enable researchers to evaluate and improve the performance of image restoration techniques under controlled conditions.
ITS dataset	https://doi.org/10.1145/3664647.3681621 (2024)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The ITS dataset is primarily used for dehazing tasks in image restoration research. It provides images with varying levels of haze, enabling researchers to evaluate the performance of dehazing algorithms. The dataset's diverse haze conditions facilitate the testing and validation of restoration techniques, ensuring robustness across different scenarios.
DND-SRGB IMAGES	https://doi.org/10.1109/TNNLS.2021.3131739 (2020)	https://doi.org/10.1109/CVPR.2019.00181 (2018)	The DND-SRGB IMAGES dataset is used to evaluate image restoration algorithms, focusing on denoising performance. It contains real photographs and is employed to measure PSNR improvements over existing methods, serving as a benchmark for algorithmic advancements in image restoration.
Adobe-MIT Fivek	https://doi.org/10.1145/3664647.3681621 (2024)	https://www.semanticscholar.org/paper/0250f9026b540ae05e2b6528b3c9064e6db637dd (2011)	The Adobe-MIT Fivek dataset is used to generate image pairs for training and evaluating image restoration models, specifically focusing on global tonal adjustments and retouching techniques. This dataset enables researchers to assess the effectiveness of various retouching methods by providing a diverse set of before-and-after image pairs, facilitating the development and refinement of image processing algorithms.
GoPro testset	https://www.semanticscholar.org/paper/6af728164e4424218967fd356b3448f5037acd88 (2023)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The GoPro testset is used to evaluate the computational costs and performance metrics of motion deblurring methods in dynamic scenes. It focuses on assessing the efficiency of various deblurring techniques, enabling researchers to compare and optimize algorithms for real-world applications. The dataset's characteristics support rigorous testing of these methods under realistic conditions.
SUNRGB-D	https://doi.org/10.48550/arXiv.2409.15278 (2024)	https://doi.org/10.1007/978-3-642-33715-4_54 (2012)	The SUNRGB-D dataset is primarily used for monocular depth estimation, leveraging its large collection of RGB-D images with depth annotations. Researchers employ this dataset to train and evaluate models that predict depth from single RGB images. The dataset's rich annotations enable the development and testing of algorithms aimed at improving depth perception in computer vision tasks.
NYU-Depth v2	https://doi.org/10.48550/arXiv.2409.15278 (2024)	https://doi.org/10.1007/978-3-642-33715-4_54 (2012)	The NYU-Depth v2 dataset is primarily used for surface normal estimation, leveraging its high-resolution RGB-D images of indoor scenes. Researchers employ this dataset to develop and evaluate algorithms that accurately estimate surface normals from depth and color data, enhancing the understanding of 3D scene geometry in indoor environments. The dataset's rich visual and depth information enables robust training and testing of these algorithms, contributing to advancements in computer vision and robotics.
LAION Art dataset	https://doi.org/10.48550/arXiv.2409.15278 (2024)	https://doi.org/10.48550/arXiv.2210.08402 (2022)	The LAION Art dataset is used to gather high-quality natural images from the Internet for image restoration experiments. It enhances the diversity and quality of training data, which is crucial for improving the performance and robustness of image restoration models. This dataset supports research focused on enhancing image quality and addressing various degradation issues in images.
91 images from Yang et al.	https://doi.org/10.1109/ICCV.2017.486 (2017)	https://doi.org/10.1109/CVPR.2015.7299156 (2015)	The '91 images from Yang et al.' dataset is used for training in single image super-resolution, providing a subset of high-resolution images to enhance model performance. This dataset enables researchers to develop and refine algorithms that improve image resolution, focusing on the quality and detail of restored images.
Flikr2K	https://doi.org/10.48550/arXiv.2404.02154 (2024)	https://doi.org/10.1109/CVPRW53098.2021.00074 (2021)	The Flikr2K dataset is used for training and evaluating image restoration models, focusing on diverse content and real-world scenarios. It enables researchers to test the robustness and generalizability of their models by providing a wide range of images, enhancing the reliability of image restoration techniques.
BSDS	https://doi.org/10.48550/arXiv.2306.05390 (2023)	https://doi.org/10.7892/BORIS.113226 (2017)	The BSDS dataset is used for evaluating image restoration algorithms, specifically for denoising and dejpeg tasks. It contains 400 images, which researchers use to assess the performance of their algorithms. The dataset's diverse image content enables robust testing and validation of restoration techniques, ensuring they effectively handle various types of image degradation.
ImageNet-50K	https://doi.org/10.48550/arXiv.2306.05390 (2023)		The ImageNet-50K dataset is used to evaluate the performance of DAMoE, specifically focusing on image restoration quality and efficiency. It serves as a benchmark to compare different methods, ensuring that the restoration processes are both effective and computationally efficient. The dataset's large scale and diverse image content enable robust testing and validation of image restoration techniques.
Laion-50K	https://doi.org/10.48550/arXiv.2306.05390 (2023)		The Laion-50K dataset is used to evaluate the performance of DAMoE, specifically focusing on image restoration quality and efficiency. It serves as a benchmark to compare different models and methodologies in the field of image restoration, enabling researchers to assess and enhance the effectiveness of their techniques.
Laion-Figure HR	https://doi.org/10.48550/arXiv.2306.05390 (2023)		The Laion-Figure HR dataset, a high-resolution subset of Laion-5B, is used in research to demonstrate the limitations of texture information in training effective image restoration models. This dataset helps researchers identify and address the insufficiencies in current training methodologies, contributing to the development of more robust restoration techniques.
Waterloo Exploration Database	https://doi.org/10.1109/TPAMI.2021.3088914 (2020)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The Waterloo Exploration Database contributes 4,744 images to enhance the diversity and scale of image restoration training sets. This dataset is specifically used to improve the robustness and generalization of image restoration models by providing a wide range of image types and conditions. It supports research in developing more effective and versatile image restoration techniques.
Flick2K dataset	https://doi.org/10.1109/TPAMI.2021.3088914 (2020)	https://doi.org/10.1109/CVPRW.2017.150 (2017)	The Flick2K dataset is used to expand the variety and quantity of images for image restoration tasks. It supplies 2,750 images, enhancing the diversity of the dataset. This expansion supports research in image restoration by providing a larger, more varied set of images, which can improve the robustness and generalizability of restoration models.
WEB	https://doi.org/10.1109/TIP.2024.3456583 (2023)	https://doi.org/10.1109/TIP.2016.2631888 (2017)	The WEB dataset is used for training denoising models, providing web images that enhance the real-world applicability of these models. This dataset enables researchers to develop and refine algorithms that can effectively reduce noise in images sourced from the internet, improving their quality and usability in various applications.
Lai dataset	https://doi.org/10.1109/ICCV.2019.00897 (2019)	https://doi.org/10.1109/CVPR.2016.188 (2016)	The Lai dataset is used to evaluate single image blind deblurring methods, featuring real-world blurry images of varying qualities and resolutions across diverse scenes. It enables researchers to assess the effectiveness of deblurring algorithms in handling natural, uncontrolled conditions, providing a robust benchmark for performance evaluation.
DVD testing set	https://doi.org/10.1109/ICCV.2019.00897 (2019)	https://doi.org/10.1109/CVPR.2017.33 (2017)	The DVD testing set is used to evaluate the performance of DeblurGAN-v2 in deblurring tasks, specifically in a single-frame setting where each frame is treated as an individual image. This dataset enables researchers to assess the effectiveness of deblurring algorithms by providing a standardized set of images for benchmarking.
DVD dataset	https://doi.org/10.1109/ICCV.2019.00897 (2019)	https://doi.org/10.1109/CVPR.2017.33 (2017)	The DVD dataset is used in deep video deblurring research, focusing on real-world videos captured at 240 fps by various devices. It enables researchers to develop and test algorithms that enhance video clarity, addressing issues like motion blur. The dataset's high frame rate and diverse device sources provide a robust foundation for evaluating deblurring techniques in realistic scenarios.
NFS	https://doi.org/10.1109/ICCV.2019.00897 (2019)	https://doi.org/10.1109/CVPR.2017.33 (2017)	The NFS dataset is used to train deblurring models in image restoration research. Researchers select every tenth frame from the dataset to ensure a diverse training set, which helps prevent overfitting. This method leverages the dataset's temporal diversity to enhance model generalization and effectiveness in deblurring tasks.
Kohler dataset	https://doi.org/10.1109/ICCV.2019.00897 (2019)	https://doi.org/10.1007/978-3-642-33786-4_3 (2012)	The Kohler dataset is used to benchmark blind deconvolution algorithms, focusing on evaluating their performance on real-world images blurred with various kernels. This dataset enables researchers to assess algorithm effectiveness in restoring images degraded by different types of blurring, providing a robust testbed for image restoration methodologies.
DocUNet	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.1109/CVPR.2018.00494 (2018)	The DocUNet dataset is used for evaluating document image unwarping, specifically providing 130 images for assessment. It enables researchers to test and compare the performance of unwarping algorithms, focusing on the accuracy and effectiveness of restoring distorted document images. The dataset's curated images facilitate rigorous evaluation in this domain.
Jung’s dataset	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.1109/CVPR.2018.00252 (2018)	Jung’s dataset is used as a testing set for image restoration, contributing 87 images to evaluate the performance of proposed methods. It is specifically employed to assess the effectiveness of restoration techniques, ensuring robust evaluation through its diverse image content. This dataset enables researchers to validate their models against a standardized set of images, facilitating comparative analysis and benchmarking.
Text Deblur Dataset (TDD)	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.5244/C.29.6 (2015)	The Text Deblur Dataset (TDD) is used to train models specifically for text deblurring. Researchers select 40K samples from the 66K available training samples to develop and refine deblurring algorithms. This dataset enables the enhancement of text clarity in images, addressing the challenge of restoring legibility in blurred text regions.
VE-LOL	https://doi.org/10.1109/CVPR52729.2023.00958 (2023)	https://doi.org/10.1109/TPAMI.2021.3126387 (2021)	The VE-LOL dataset is used to assess video enhancement in low-light scenarios, focusing on temporal consistency and noise reduction. Researchers employ this dataset to evaluate and improve algorithms designed to enhance video quality under low-light conditions, ensuring that the enhanced videos maintain temporal coherence and reduced noise levels. This dataset enables the development and testing of advanced video processing techniques specifically tailored for challenging lighting environments.
LoLi-Phone Dataset	https://doi.org/10.1109/CVPR52729.2023.00958 (2023)	https://doi.org/10.1109/TPAMI.2021.3126387 (2021)	The LoLi-Phone Dataset is used to evaluate low-light image and video enhancement techniques, specifically focusing on improving visual quality in dark conditions. Researchers employ deep learning methods to enhance images and videos captured in low-light environments. This dataset enables the assessment of these techniques by providing a benchmark for visual quality improvements under challenging lighting conditions.
Kligler’s dataset	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.1109/CVPR.2018.00252 (2018)	Kligler’s dataset is used as part of the testing set for image restoration, providing 300 images to evaluate the performance of proposed methods. It contributes to assessing the effectiveness and robustness of image restoration techniques by offering a diverse set of images for validation.
OSR	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.1109/CVPR.2018.00252 (2018)	The OSR dataset is used as part of the testing set for image restoration, contributing 237 images to evaluate the performance of proposed methods. It enables researchers to assess the effectiveness of their restoration techniques by providing a standardized set of images for benchmarking.
TDD	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.1109/TPAMI.2020.3022406 (2020)	The TDD dataset is used to train models for deblurring photographed document images, specifically enhancing document quality. Researchers employ generative adversarial networks (GANs) to improve image clarity. This dataset enables the development and evaluation of deblurring techniques, addressing the challenge of restoring degraded document images.
Doc3DShade	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.5244/c.34.188 (2020)	The Doc3DShade dataset is used to train models for image restoration, specifically enhancing the model's ability to handle various shading conditions. It provides 90K synthetic images, which are crucial for improving the robustness and performance of image restoration algorithms under different lighting scenarios. This dataset enables researchers to develop more effective and versatile image restoration techniques.
Doc3D	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.48550/arXiv.2210.08161 (2022)	The Doc3D dataset is primarily used for training models in document image rectification, focusing on correcting geometric distortions in both synthetic and real document images. This dataset provides a large, diverse set of images, enabling researchers to develop and evaluate algorithms that improve the quality and readability of distorted document images.
DIR300	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.48550/arXiv.2210.08161 (2022)	The DIR300 dataset is used for evaluating the performance of trained models in document image restoration. It serves as a benchmark with 300 challenging document images, enabling researchers to test and compare the effectiveness of their restoration techniques. This dataset facilitates the assessment of model accuracy and robustness in handling complex document images.
HDR dataset from the NTIRE2021 Multi-Frame HDR Challenge	https://doi.org/10.1109/CVPR52729.2023.00958 (2023)	https://doi.org/10.1109/TPAMI.2021.3126387 (2021)	The HDR dataset from the NTIRE2021 Multi-Frame HDR Challenge is used to evaluate HDR recovery methods, particularly for comparing HDR-GDP-x0 with other state-of-the-art HDR techniques. It involves testing on 100 randomly selected scenes, enabling researchers to assess the performance and effectiveness of different HDR algorithms in recovering high dynamic range images from multiple low dynamic range frames.
FSDSRD	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.1109/ICIP46576.2022.9897217 (2022)	The FSDSRD dataset is used to train models for document shadow removal, specifically employing 14,200 synthetic images. This dataset enables researchers to develop and evaluate algorithms that effectively remove shadows from documents, enhancing image quality and readability. The large number of synthetic images supports robust training and testing of these models.
SD7K	https://doi.org/10.1109/CVPR52733.2024.01482 (2024)	https://doi.org/10.1109/ICCV51070.2023.01144 (2023)	The SD7K dataset is used to train DocShadow, a model focused on document shadow removal. It emphasizes a large-scale dataset with diverse shadow conditions, enabling researchers to develop and test algorithms that effectively handle various shadow scenarios in document images. This dataset's extensive and varied content supports the training and evaluation of robust shadow removal techniques.
HYDICE DC Mall data	https://doi.org/10.1109/ICCVW.2019.00477 (2019)	https://doi.org/10.1109/JSTARS.2014.2329322 (2014)	The HYDICE DC Mall data is used to evaluate the performance of denoising algorithms by adding synthetic Gaussian noise (σ = 100) and assessing the algorithm's effectiveness in removing it. This dataset enables researchers to test and validate denoising methodologies, focusing on the improvement of image quality in noisy conditions.
Dehaze-TestA	https://doi.org/10.1109/CVPR.2019.00717 (2019)	https://doi.org/10.1007/s11263-015-0816-y (2014)	The Dehaze-TestA dataset is used to evaluate the performance of the DuRN-US model on dehazing tasks, specifically focusing on the quality of image restoration. This dataset enables researchers to assess how effectively their models can remove haze from images, enhancing clarity and visual quality.
https://github.com/rwenqi/GFNdehazing	https://doi.org/10.1109/CVPR.2019.00717 (2019)	https://doi.org/10.1109/CVPR.2018.00343 (2018)	The dataset from 'https://github.com/rwenqi/GFNdehazing' is used to provide images for dehazing experiments. Specifically, these images are fed into a convolutional encoder-decoder network to estimate the ground truth image. This approach helps researchers evaluate and improve dehazing algorithms by providing a standardized set of images for testing and validation.
Dehaze Dataset	https://doi.org/10.1109/CVPR.2019.00717 (2019)	https://www.semanticscholar.org/paper/fb52f9294fa1cd83660eccac486367eac01ea32d (2018)	The Dehaze Dataset is primarily used for image dehazing research, focusing on the evaluation of techniques to remove atmospheric effects and enhance image clarity. This dataset enables researchers to assess the performance of dehazing algorithms by providing a benchmark for comparing different methods. It is specifically tailored to address the challenge of improving visual quality in hazy images, making it a valuable resource for advancing image restoration methodologies.
GoPro-test	https://doi.org/10.1109/CVPR.2019.00717 (2019)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The GoPro-test dataset is used to evaluate the performance of the DuRNU model for dynamic scene deblurring. It facilitates comparisons against state-of-the-art methods, focusing on the effectiveness of deblurring techniques in dynamic scenes. This dataset enables researchers to assess and validate the model's capabilities in enhancing image clarity in motion-blurred images.
DID-MDN Data	https://doi.org/10.1109/CVPR.2019.00717 (2019)	https://www.semanticscholar.org/paper/fb52f9294fa1cd83660eccac486367eac01ea32d (2018)	The DID-MDN Data dataset is used for joint dehazing and deraining in image restoration research. It tests the robustness of models in handling multiple degradations simultaneously. This dataset enables researchers to evaluate and improve the performance of models designed to address complex image degradation issues, ensuring they can effectively restore images under varied conditions.
URBAN10	https://doi.org/10.1007/978-3-030-58523-5_36 (2020)	https://doi.org/10.1007/978-3-642-27413-8_47 (2010)	The URBAN10 dataset is used for assessing image restoration in urban scenes, specifically focusing on the preservation of texture and structure in complex environments. Researchers employ this dataset to evaluate the effectiveness of image restoration techniques in maintaining fine details and structural integrity, which are crucial for applications in urban scene analysis and visualization.
Rain/HazeCityscapes	https://doi.org/10.48550/arXiv.2312.16610 (2023)	https://doi.org/10.1109/CVPR.2019.00821 (2019)	The Rain/HazeCityscapes dataset is used to evaluate the performance of image restoration techniques, specifically focusing on deweathering and segmentation accuracy under rain and haze conditions. Researchers employ this dataset to test and compare algorithms designed to enhance image quality and maintain segmentation accuracy in adverse weather scenarios. The dataset's inclusion of diverse weather conditions enables robust assessment of these methodologies.
FiveK	https://doi.org/10.48550/arXiv.2306.13653 (2023)	https://www.semanticscholar.org/paper/5ee57b18a7be2b671ffc6f5ce5dbbe92112ee0fb (2007)	The FiveK dataset is primarily used for low-light image enhancement research. It employs the ProRes framework to improve image quality under low-light conditions. This dataset enables researchers to develop and test algorithms that enhance visual clarity and detail in images captured in dim environments, focusing on practical applications such as photography and surveillance.
Low-Light enhancement dataset (LOL)	https://doi.org/10.48550/arXiv.2306.13653 (2023)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The Low-Light enhancement dataset (LOL) is used for improving visibility in dark images through low-light image enhancement. Specifically, it employs deep retinex decomposition techniques to enhance image quality. This dataset enables researchers to address the challenge of enhancing images captured in low-light conditions, focusing on methods that can effectively boost visibility and detail in such images.
RESIDE/SOTS	https://www.semanticscholar.org/paper/3fb08a1c07eba3461d6ed784b25d952979e90e0d (2023)	https://www.semanticscholar.org/paper/3c5ab1aba2091c690729b5a8f0762ecda3d06163 (2021)	The RESIDE/SOTS dataset is used to evaluate the performance of IRNeXt on synthetic dehazing tasks. Researchers focus on metrics such as PSNR to assess improvements in image quality. This dataset enables the systematic evaluation of dehazing algorithms, providing synthetic images that simulate various atmospheric conditions, thus facilitating the comparison of different restoration techniques.
EUVP	https://doi.org/10.48550/arXiv.2503.10120 (2025)	https://doi.org/10.1109/LRA.2020.2974710 (2019)	The EUVP dataset is used for qualitative comparisons in underwater image enhancement research. It provides visual results to demonstrate improvements in visual perception, enabling researchers to evaluate and compare the effectiveness of different enhancement techniques. This dataset supports the development and assessment of algorithms aimed at improving the clarity and quality of underwater images.
SOTS (outdoor)	https://doi.org/10.1007/978-3-031-72764-1_1 (2024)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The SOTS (outdoor) dataset is used to evaluate dehazing methods, specifically focusing on outdoor scenes. It enables researchers to assess the performance of these methods in realistic conditions, ensuring that the dehazing techniques are effective in practical scenarios. The dataset's emphasis on outdoor environments provides a robust testbed for dehazing algorithms.
SOTS outdoor dataset	https://doi.org/10.1007/978-3-031-72764-1_1 (2024)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The SOTS outdoor dataset is used for dehazing comparisons in all-in-one image restoration methods, specifically to enhance outdoor image quality and improve clarity. Researchers employ this dataset to evaluate and compare the effectiveness of different dehazing techniques, focusing on the visual quality and clarity of restored images.
RESIDE-β	https://doi.org/10.1109/TCSVT.2024.3429557 (2024)	https://doi.org/10.1007/978-3-030-01234-2_16 (2018)	The RESIDE-β dataset is primarily used for training deep learning models in image dehazing, aimed at enhancing the visibility and quality of hazy images. This dataset supports research focused on developing and refining algorithms to remove haze, leveraging its extensive collection of hazy and clear image pairs. The dataset's characteristics enable researchers to evaluate and improve the performance of dehazing models, contributing to advancements in image restoration techniques.
Set11	https://doi.org/10.1109/CVPR52688.2022.01688 (2022)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	Set11 is used for evaluating image restoration methods, offering a small but diverse set of images to assess performance. This dataset enables researchers to test and compare the effectiveness of various restoration techniques, focusing on how well these methods handle different types of image degradation. The diversity of images in Set11 provides a robust basis for performance assessment in image restoration research.
DIV2K-Valid	https://doi.org/10.48550/arXiv.2310.10513 (2023)	https://doi.org/10.1007/s11042-016-4020-z (2015)	The DIV2K-Valid dataset is used for validating and benchmarking image restoration models. It provides high-quality images essential for evaluating the performance of these models. Researchers employ this dataset to ensure their methods achieve accurate and reliable image restoration, focusing on benchmarking and validation rather than training. The dataset's high-quality images enable precise assessment of restoration techniques, facilitating robust comparisons across different models and approaches.
CVF dataset	https://doi.org/10.48550/arXiv.2310.10513 (2023)	https://doi.org/10.1109/CVPR.2009.5206848 (2009)	The CVF dataset is used for training and evaluating models in the context of enhancing performance on visual data. It comprises a diverse array of figures from computer vision papers, which helps in improving model robustness and generalization. This dataset is specifically utilized to address research questions related to image restoration and visual data processing, enabling researchers to test and refine their methodologies on a wide range of visual content.
ImageNet/CVF	https://doi.org/10.48550/arXiv.2310.10513 (2023)	https://doi.org/10.1109/CVPR.2009.5206848 (2009)	The ImageNet/CVF dataset is used to extract crude images for Masked Autoencoder (MAE) training and to stitch paired images for inference, specifically focusing on image restoration techniques. This dataset facilitates the development and evaluation of methods aimed at restoring degraded images, leveraging its extensive collection of visual data.
Laion-High-Resolution	https://www.semanticscholar.org/paper/7d7712fbd2f7cdda845c176b03b84f2df93a8b2f (2025)	https://doi.org/10.48550/arXiv.2210.08402 (2022)	The Laion-High-Resolution dataset is used to select high-quality, diverse images for image restoration experiments. Researchers focus on enhancing image clarity and detail by leveraging the dataset's rich, high-resolution content. This enables the development and evaluation of advanced image restoration techniques, ensuring robust performance across a wide range of image types and conditions.
sequentially-applied (or mixed) distortion dataset	https://doi.org/10.1109/CVPRW56347.2022.00069 (2022)	https://doi.org/10.1109/CVPR.2018.00259 (2018)	The sequentially-applied (or mixed) distortion dataset is used to evaluate image restoration methods by applying a sequence of distortions to images. This enhances the robustness of restoration algorithms, focusing on their ability to handle multiple, cumulative distortions. The dataset enables researchers to test and improve the performance of these algorithms under complex, real-world conditions.
SHDD	https://doi.org/10.1109/CVPRW56347.2022.00069 (2022)	https://doi.org/10.1109/CVPR.2018.00259 (2018)	The SHDD dataset is used to evaluate image restoration methods by comparing their performance against mixed distortions and original images. Researchers employ deep reinforcement learning to assess these methods, focusing on how effectively they can restore images degraded by various distortions. This dataset enables rigorous testing and benchmarking of restoration algorithms, ensuring they can handle real-world image degradation scenarios.
HMDD	https://doi.org/10.1109/CVPRW56347.2022.00069 (2022)	https://doi.org/10.1109/CVPR.2018.00259 (2018)	The HMDD dataset is utilized in image restoration research to integrate multiple distortion scenarios, providing a comprehensive resource that generalizes previous multi-degraded datasets. This integration allows researchers to address a broader range of image degradation issues, enhancing the robustness and versatility of image restoration models. The dataset's diverse and inclusive nature supports the development of more generalized and effective restoration algorithms.
BSD300	https://doi.org/10.1109/TCSVT.2024.3398810 (2023)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The BSD300 dataset is primarily used for denoising research, serving as a benchmark for evaluating denoising methods. It provides a well-known collection of clean and noisy images, enabling researchers to test and compare the effectiveness of various denoising algorithms. This dataset facilitates the development and validation of image restoration techniques by offering standardized data for consistent performance assessment.
ImageNet-Test	https://doi.org/10.1109/TPAMI.2024.3461721 (2024)	https://doi.org/10.1109/CVPR.2009.5206848 (2009)	The ImageNet-Test dataset, comprising 3000 randomly selected images from the validation set, is primarily used for synthetic testing in image restoration research. It serves as a benchmark to evaluate the performance of restoration algorithms under controlled conditions. This dataset enables researchers to assess the effectiveness of their methods by providing a standardized set of images for consistent testing and comparison.
Laion400M	https://doi.org/10.1109/TPAMI.2024.3461721 (2024)	https://www.semanticscholar.org/paper/b668ce936cff0b0ca8b635cd5f25a62eaf4eb3df (2021)	The Laion400M dataset is used to pre-train the CLIP model, leveraging its large-scale collection of image-text pairs to enhance the model's generalization ability in image restoration tasks. This pre-training approach helps improve the performance and robustness of image restoration models by providing diverse and extensive data.
RealSR-V3	https://doi.org/10.1109/TPAMI.2024.3461721 (2024)	https://doi.org/10.48550/arXiv.2207.12396 (2022)	The RealSR-V3 dataset is used for evaluating image restoration approaches, particularly focusing on real-world super-resolution performance and quality. Researchers employ this dataset to assess and compare the effectiveness of different super-resolution techniques, ensuring they perform well under realistic conditions. This dataset enables the validation of algorithms designed to enhance image clarity and detail in practical scenarios.
rain-streak datasets	https://doi.org/10.1109/ICCV48922.2021.00231 (2021)	https://doi.org/10.1109/CVPR.2017.186 (2017)	Rain-streak datasets are used to train deep detail networks for removing rain streaks from single images. The focus is on addressing degradation patterns and preserving image details. These datasets enable researchers to develop and refine algorithms that enhance image quality by effectively eliminating rain streaks, thereby improving the clarity and usability of images in various applications.
AGAN	https://doi.org/10.1109/ICCV48922.2021.00231 (2021)	https://doi.org/10.1109/CVPR.2017.186 (2017)	The AGAN dataset is used to evaluate the performance of the SPAIR model for image restoration, specifically focusing on adversarial generation and enhancing image quality. It employs a dataset generated by an adversarial network to assess the effectiveness of the SPAIR model in improving image restoration outcomes.
Set14 × 2	https://doi.org/10.1007/s11263-023-01843-5 (2023)	https://doi.org/10.1109/CVPR.2019.01132 (2019)	The Set14 × 2 dataset is primarily used for performance comparison in single image super-resolution tasks. Researchers employ this dataset to evaluate and benchmark the efficiency of different algorithms, focusing on metrics such as FLOPs, running time, and peak memory consumption. This enables a detailed analysis of computational efficiency and resource utilization, facilitating advancements in algorithm optimization.
Mixed RainStreak Dataset	https://doi.org/10.1109/ICCV48922.2021.00231 (2021)	https://doi.org/10.1109/CVPR42600.2020.00837 (2020)	The Mixed RainStreak Dataset is used for training and evaluating the SPAIR model in deraining tasks. It specifically supports the assessment of deraining performance, as evidenced by its use in generating results presented in Table 1 of the main paper. This dataset enables researchers to test and improve image restoration techniques focused on removing rain streaks from images.
standard test dataset of 68 natural images	https://doi.org/10.1109/TPAMI.2016.2596743 (2015)	https://doi.org/10.1007/s11263-008-0197-6 (2009)	The standard test dataset of 68 natural images is primarily used to evaluate the denoising performance of trained models, specifically focusing on Gaussian denoising. This dataset enables researchers to test and compare the effectiveness of their models in removing noise from natural images, providing a standardized benchmark for performance assessment.
SID Sony dataset	https://doi.org/10.1109/CVPR46437.2021.00349 (2021)	https://doi.org/10.1007/978-3-319-10602-1_48 (2014)	The SID Sony dataset is mentioned in the citation context but lacks detailed descriptions of its usage in specific research studies. Therefore, there is no evidence to describe its application, methodology, research questions, or enabling capabilities in any particular research area.
NYU V2	https://doi.org/10.1109/TCSVT.2023.3286405 (2024)	https://doi.org/10.1007/978-3-642-33715-4_54 (2012)	The NYU V2 dataset is primarily used to synthesize the RESIDE dataset, which provides indoor RGBD images. These images are utilized for segmentation tasks and support inference, enabling researchers to develop and evaluate algorithms that can accurately segment and interpret indoor environments. The dataset's rich RGBD data facilitates robust training and testing of computer vision models.
Middlebury Stereo	https://doi.org/10.1109/TCSVT.2023.3286405 (2024)	https://doi.org/10.1007/978-3-642-33715-4_54 (2012)	The Middlebury Stereo dataset is used to synthesize the RESIDE dataset, providing stereo images for both indoor and outdoor scenes. This contributes to the creation of diverse and realistic image pairs, which are essential for training and evaluating algorithms in stereo vision tasks. The dataset's rich variety of scenes enhances the robustness and generalization of models in stereo matching and depth estimation research.
Bokeh Effect Transformation dataset	https://doi.org/10.1109/CVPRW59228.2023.00169 (2023)	https://doi.org/10.1109/CVPR52688.2022.00564 (2021)	The Bokeh Effect Transformation dataset is used to evaluate the effectiveness of image restoration methods, particularly in high-resolution image restoration tasks. It is employed to compare the performance of the proposed method against state-of-the-art techniques like Restormer. This dataset enables researchers to assess and benchmark the quality and efficiency of their restoration algorithms.
stereo super-resolution validation dataset	https://doi.org/10.1109/CVPRW59228.2023.00169 (2023)	https://doi.org/10.48550/arXiv.2301.11699 (2023)	The stereo super-resolution validation dataset is used to assess the performance and restoration quality of stereo super-resolution methods. Researchers employ mean squared error as a primary metric to validate these methods, ensuring they effectively enhance image resolution while maintaining accuracy and detail. This dataset enables rigorous evaluation and comparison of different stereo super-resolution techniques.
NTIRE 2023 Stereo Image Super-Resolution Challenge	https://doi.org/10.1109/CVPRW59228.2023.00169 (2023)		The NTIRE 2023 Stereo Image Super-Resolution Challenge dataset is primarily used for evaluating and benchmarking stereo image super-resolution techniques. It provides researchers with a standardized set of low-resolution stereo image pairs to upscale, enabling the comparison of different super-resolution algorithms. The dataset's focus on stereo images allows for the assessment of depth and disparity accuracy in high-resolution outputs, facilitating advancements in 3D imaging and computer vision tasks.
Flickr1024	https://doi.org/10.1109/CVPRW59228.2023.00169 (2023)		The Flickr1024 dataset is primarily used for validating stereo images in the NTIRE 2023 challenge, focusing on evaluating model performance. It provides a standardized set of images to assess the effectiveness of image restoration techniques, ensuring consistent and comparable results across different models and approaches.
Real20	https://doi.org/10.1109/TCSVT.2023.3286405 (2024)	https://doi.org/10.1109/CVPR.2018.00503 (2018)	The Real20 dataset is used to evaluate image restoration methods by providing 20 real image pairs from diverse scenes. Researchers focus on assessing the performance of these methods across various visual contexts, ensuring robustness and effectiveness in real-world applications. This dataset enables detailed performance comparisons and validation of restoration techniques in complex, realistic scenarios.
Snow10k	https://doi.org/10.48550/arXiv.2305.17863 (2023)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The Snow10k dataset is mentioned in the citation context but lacks detailed descriptions of its usage in research. There is no explicit information on its application, methodology, research questions, or specific characteristics. Therefore, it cannot be accurately described as being used for All-in-One Image Restoration or any other specific research area based on the provided evidence.
RainDrop-Test	https://doi.org/10.48550/arXiv.2305.17863 (2023)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The RainDrop-Test dataset is used for evaluating raindrop removal models, particularly under heavy rain conditions. Researchers employ this dataset to test and assess the quality of image restoration techniques, focusing on the effectiveness of removing raindrops from images. This dataset enables the rigorous evaluation of restoration algorithms by providing challenging scenarios with dense raindrops.
Outdoor-Rain dataset	https://doi.org/10.48550/arXiv.2305.17863 (2023)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The Outdoor-Rain dataset is mentioned in the citation context but lacks detailed descriptions of its usage in research. Therefore, there is no specific evidence to indicate how it is used, the methodologies employed, or the research questions it addresses. Its role in All-in-One Image Restoration or any other research area is not substantiated by the provided information.
RESIDE SOTS-Indoor	https://www.semanticscholar.org/paper/caabf4abb96ee83f650aa7b707bd9a99007b3e74 (2023)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The RESIDE SOTS-Indoor dataset is primarily used for synthetic image dehazing experiments, focusing on indoor scenes. Researchers employ this dataset to evaluate the performance of dehazing algorithms, leveraging its synthetic nature to provide controlled conditions for testing and validation. This enables precise assessment of algorithmic effectiveness in enhancing image clarity in hazy indoor environments.
Indoor Training Set (ITS)	https://www.semanticscholar.org/paper/4b688c486f2b223212682fd2b3f72cc0caa94b1b (2023)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The Indoor Training Set (ITS) is used to train models for single-image dehazing, specifically containing 13,990 hazy indoor images generated from 1,399 clear images. This dataset enables researchers to develop and evaluate dehazing algorithms by providing a large and diverse set of synthetic hazy images, facilitating advancements in image restoration techniques.
