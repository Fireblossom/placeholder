Name (extracted)	Citing Article	Citied Article	Features
GoPro	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.48550/arXiv.2411.18412 (2024), https://doi.org/10.48550/arXiv.2506.16960 (2025) (+25)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The GoPro dataset is primarily used for motion deblurring research, focusing on both synthetic and real-world motion blur in images and video sequences. It is employed to train and evaluate deep learning models, particularly multi-scale convolutional neural networks, to improve image clarity and high-resolution quality in dynamic scenes. The dataset includes motion-blurred images and their corresponding sharp versions, enabling researchers to address camera and object motion blur effectively.
Rain100L	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/TPAMI.2025.3562211 (2024), https://doi.org/10.1109/CVPR52688.2022.01693 (2022) (+28)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The Rain100L dataset is primarily used for image deraining, focusing on the removal of rain streaks to enhance image clarity. It consists of 200 clean-rainy image pairs for training and 100 pairs for testing. Researchers employ deep multi-scale convolutional neural networks and other models to train, test, and evaluate deraining performance, often in single-task settings. The dataset is used for ablation experiments, visual comparisons with state-of-the-art methods, and assessing PSNR gains, specifically in the context of synthetic rainy images.
WED	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/CVPR52733.2024.00277 (2023), https://doi.org/10.48550/arXiv.2411.18466 (2024) (+25)	https://doi.org/10.1109/TIP.2016.2631888 (2017)	The WED dataset is primarily used for image denoising research, providing a diverse set of images to train and evaluate denoising algorithms. It is employed in both training and testing phases, often with synthetic Gaussian noise, to enhance and assess the performance of image restoration models. The dataset complements other benchmarks like BSD400, offering additional challenges and variations in image quality, which helps in evaluating the robustness and effectiveness of denoising techniques under various degradations.
Urban100	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.48550/arXiv.2406.18242 (2024), https://doi.org/10.1109/CVPR52688.2022.01693 (2022) (+18)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The Urban100 dataset is primarily used to evaluate image restoration techniques, particularly in urban scenes with complex structures and high-resolution details. It is employed to assess the performance of various restoration methods, including denoising, deblurring, and handling issues like rain, haze, and low-light conditions. The dataset's 100 diverse urban images enable researchers to measure PSNR improvements and the effectiveness of algorithms in preserving architectural details and textures.
BSD400	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/CVPR52688.2022.01693 (2022), https://doi.org/10.48550/arXiv.2411.18466 (2024) (+21)	https://doi.org/10.1109/TIP.2016.2631888 (2017)	The BSD400 dataset is primarily used for image denoising research, focusing on improving image quality by reducing noise while preserving important features. It is employed to train and evaluate denoising models using synthetic Gaussian noise at various levels (σ = 15, 25, 50). The dataset provides a diverse set of natural images, enhancing model robustness and serving as a benchmark for comparing denoising algorithms. Additionally, it is used to evaluate image restoration models under various degradations, including rain, haze, blur, and low-light conditions, making it a valuable resource for assessing performance across diverse image content.
BSD68	https://doi.org/10.1109/CVPR52688.2022.01693 (2022), https://doi.org/10.48550/arXiv.2404.02154 (2024), https://doi.org/10.48550/arXiv.2403.14614 (2024) (+20)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The BSD68 dataset is primarily used for evaluating image denoising and restoration algorithms. It serves as a testing set containing 68 ground truth images, often used after training on larger datasets like BSD400 and WED. Researchers employ it to assess performance at various noise levels, focusing on natural images with human-segmented annotations. The dataset is crucial for benchmarking denoising models, evaluating restoration quality, and enhancing visual performance metrics.
LOL	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.48550/arXiv.2411.18412 (2024), https://doi.org/10.48550/arXiv.2310.10123 (2023) (+12)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The LOL dataset is primarily used for low-light image enhancement research, focusing on improving image quality, visibility, and color fidelity in low-light conditions. It is employed to train and evaluate deep learning models, including those using deep retinex decomposition and ERFM techniques. The dataset enables researchers to assess and compare the performance of various image restoration algorithms, often demonstrating significant improvements in metrics like PSNR.
RESIDE	https://doi.org/10.48550/arXiv.2410.15385 (2024), https://doi.org/10.1109/WACV61041.2025.00069 (2025), https://doi.org/10.48550/arXiv.2506.16960 (2025) (+18)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The RESIDE dataset is primarily used for training and evaluating models focused on image dehazing. It provides a comprehensive benchmark for assessing dehazing techniques, including single-degradation scenarios, using metrics like PSNR, MS-SSIM, and BD-PSNR. The dataset contains hazy images that help optimize models such as TANet and Restormer+EVC to improve visibility and clarity in both synthetic and real-world hazy conditions.
Snow100K	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.3390/electronics13142817 (2024), https://doi.org/10.1109/TCSVT.2024.3429557 (2024) (+11)	https://doi.org/10.1109/ICCV48922.2021.00416 (2021)	The Snow100K dataset is primarily used for desnowing, which involves removing snowflakes and enhancing visual clarity in images. It is utilized for training and evaluating snow removal algorithms, particularly focusing on diverse snow patterns and intensities. The dataset supports qualitative comparisons and performance assessments of various desnowing methods, including the use of hierarchical dual-tree complex wavelet representation and contradict channel loss. Its large-scale synthetic nature makes it suitable for optimizing and testing image desnowing models.
CSD	https://doi.org/10.3390/electronics13142817 (2024), https://doi.org/10.1109/TIP.2025.3572788 (2025), https://doi.org/10.1109/TCSVT.2024.3429557 (2024) (+3)	https://doi.org/10.1109/ICCV48922.2021.00416 (2021)	The CSD dataset is primarily used for training and evaluating image restoration algorithms, particularly for haze and snow removal. It serves as a benchmark for assessing the performance of dehazing and desnowing models using metrics like PSNR, MS-SSIM, and BD-PSNR. The dataset includes synthetic hazy and snowy images, enabling researchers to focus on visual fidelity and artifact reduction in image restoration.
SOTS	https://doi.org/10.1109/TPAMI.2025.3562211 (2024), https://doi.org/10.1109/CVPR52733.2024.00277 (2023), https://doi.org/10.48550/arXiv.2404.02154 (2024) (+11)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The SOTS dataset is primarily used for image dehazing research, focusing on improving visibility by removing atmospheric haze effects from both synthetic and real-world images. It contains 72,135 training images and 500 testing images, enabling the training and evaluation of dehazing algorithms. Researchers use SOTS to benchmark single-image dehazing methods, conduct visual comparisons, and measure performance improvements, such as PSNR enhancements, demonstrating its utility in advancing dehazing techniques.
RainDrop	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/TCSVT.2023.3299324 (2024) (+6)	https://doi.org/10.1109/CVPR.2018.00263 (2017)	The RainDrop dataset is primarily used for raindrop removal from images, both in synthetic and real-world settings. It is employed to train and evaluate algorithms that aim to eliminate raindrops, focusing on the effectiveness of these methods in restoring image quality. The dataset includes realistic raindrop effects, enabling researchers to assess the performance of restoration techniques on images with varying raindrop conditions.
HIDE	https://doi.org/10.48550/arXiv.2410.15385 (2024), https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/CVPR52733.2024.00277 (2023) (+4)	https://doi.org/10.1109/ICCV.2019.00567 (2019)	The HIDE dataset is used for evaluating and testing image restoration methods, particularly in high-resolution image restoration tasks. It assesses performance across diverse image degradation scenarios, including real-world motion blur, haze, and noise. The dataset supports research on deblurring, haze removal, and generalization in image restoration, featuring synthetic and real distortions. It enables researchers to validate the effectiveness of their algorithms in handling complex and varied image degradations.
SIDD	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.48550/arXiv.2503.09403 (2025) (+2)	https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	The SIDD dataset is primarily used for real denoising in image restoration research, focusing on reducing noise in real-world images, particularly from smartphone cameras. It provides 20 paired noisy-clean images for training and testing denoising models. The dataset is crucial for evaluating the effectiveness of denoising algorithms, especially in handling realistic noise patterns while preserving important image details.
Rain100H	https://doi.org/10.48550/arXiv.2411.18412 (2024), https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/TCSVT.2023.3299324 (2024) (+3)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The Rain100H dataset is primarily used for training and evaluating rain removal algorithms, focusing on high-resolution images with synthetic and heavy rain streaks. It challenges and refines models by providing a large set of rain-streaked images, enabling researchers to assess the effectiveness of deraining techniques in both synthetic and real-world scenarios.
Rain200L	https://doi.org/10.3390/electronics13142817 (2024), https://doi.org/10.48550/arXiv.2411.18412 (2024), https://doi.org/10.1109/CVPR52733.2024.00277 (2023) (+4)	https://doi.org/10.1109/TIP.2016.2631888 (2017)	The Rain200L dataset is primarily used for deraining research, providing synthetic rain images to train and evaluate models focused on removing rain streaks from low-resolution images. It enhances the degradation space by offering low-quality synthetic rain images, which increases the diversity of training data. This dataset is crucial for improving the visual quality of images and comparing the effectiveness of various deraining methods, particularly in scenarios with light rain.
O-HAZE	https://doi.org/10.48550/arXiv.2505.21637 (2025), https://doi.org/10.1109/TPAMI.2025.3562211 (2024), https://doi.org/10.48550/arXiv.2411.17687 (2024) (+2)	https://doi.org/10.1109/CVPRW.2018.00119 (2018)	The O-HAZE dataset is primarily used for evaluating dehazing algorithms on real-world hazy and haze-free outdoor images. It provides a benchmark for assessing the performance and generalization of these algorithms under realistic conditions, often comparing them with state-of-the-art methods. The dataset's real-world images enable researchers to test and validate dehazing techniques, focusing on practical applications and performance metrics such as PSNR gains.
DPDD	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.1109/TIP.2025.3572788 (2025) (+2)	https://doi.org/10.1007/978-3-030-58607-2_7 (2020)	The DPDD dataset is primarily used for defocus deblurring research, focusing on restoring sharp images from out-of-focus regions. It is utilized for training and evaluating single-image and dual-pixel defocus deblurring methods, particularly in high-resolution image restoration. The dataset enables researchers to assess the performance of their models, compare PSNR gains, and optimize parameter efficiency. Dual-pixel data is a key feature, enhancing the effectiveness of defocus deblurring algorithms.
LOL-v1	https://www.semanticscholar.org/paper/4af9a92a556981375dab533ccc55860f01c8b5da (2025), https://doi.org/10.48550/arXiv.2411.17687 (2024), https://doi.org/10.48550/arXiv.2411.18412 (2024) (+9)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The LOL-v1 dataset is primarily used for low-light image enhancement, focusing on improving image quality and visibility in underexposed conditions. It is utilized to evaluate and validate models, particularly those employing deep retinex decomposition, for enhancing images captured in low-light environments. The dataset serves as a benchmark for comparing the performance of different enhancement techniques.
RESIDE-SOTS	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://www.semanticscholar.org/paper/4af9a92a556981375dab533ccc55860f01c8b5da (2025)	https://doi.org/10.1109/CVPR52729.2023.00564 (2023)	The RESIDE-SOTS dataset is primarily used for evaluating dehazing algorithms and image restoration models in outdoor scenes, both synthetic and real-world. It assesses the performance and robustness of these models under various conditions, including realistic haze effects and other degradations like rain and low-light. This dataset enables researchers to benchmark and compare different dehazing methods, focusing on the quality and effectiveness of haze removal in outdoor environments.
Rain800	https://doi.org/10.3390/electronics13142817 (2024), https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.48550/arXiv.2406.18242 (2024) (+1)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The Rain800 dataset is primarily used for training and evaluating rain removal algorithms, focusing on synthetic rain images with varying densities. It provides 1800 pairs of degraded and clean images for training and 200 pairs for testing, enabling detailed performance analysis and comparison of deraining methods. The dataset assesses the robustness and generalization of models, particularly in handling diverse rain intensities.
Rain200H	https://doi.org/10.3390/electronics13142817 (2024), https://doi.org/10.1109/TMM.2025.3535316 (2024), https://doi.org/10.1109/CVPR52733.2024.00277 (2023) (+1)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The Rain200H dataset is primarily used for training and evaluating deraining models, focusing on high-resolution images with synthetic rain. It provides 1800 pairs of degraded and clean images for training and 200 pairs for testing, enhancing the degradation space and increasing the robustness of rain removal techniques. The dataset is crucial for assessing the effectiveness of various models in restoring images with heavy rain and synthetic rainstreaks, making it a valuable resource for single-image rain detection and removal research.
LHP	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.48550/arXiv.2411.17687 (2024), https://doi.org/10.48550/arXiv.2505.18047 (2025) (+1)	https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	The LHP dataset is primarily used for evaluating and improving real-world de-raining techniques, focusing on the performance of image restoration methods under varying rain intensities and environmental conditions. It is also utilized to test the generalization capability of models on under-display camera images and to assess their effectiveness in handling low-light and high-dynamic-range images. The dataset provides a diverse set of images, enabling researchers to enhance and evaluate deraining and low-light image enhancement methods.
RESIDE-OTS	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.48550/arXiv.2402.03738 (2024)	https://doi.org/10.1109/CVPR52729.2023.00564 (2023)	The RESIDE-OTS dataset is primarily used to evaluate the performance of image restoration models, particularly in dehazing outdoor synthetic scenes. It provides a variety of synthetic outdoor images with different levels of haze, enabling researchers to test and compare the effectiveness of dehazing algorithms. The dataset supports the assessment of models' ability to restore clear images from hazy conditions, making it a valuable resource for advancing dehazing techniques in image restoration.
Rain1400	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.1109/WACV61041.2025.00069 (2025), https://doi.org/10.48550/arXiv.2410.08177 (2024)	https://doi.org/10.1109/CVPR.2017.186 (2017)	The Rain1400 dataset is primarily used for deraining tasks, focusing on the removal of rain streaks from images. It serves as a benchmark for evaluating the performance of various restoration algorithms, particularly in synthetic data. Researchers use metrics like PSNR, MS-SSIM, and BD-PSNR to assess the effectiveness of methods such as TANet and deep detail networks in enhancing image quality and clarity.
SOTS-Outdoor	https://doi.org/10.48550/arXiv.2310.10123 (2023), https://doi.org/10.48550/arXiv.2409.19403 (2024), https://doi.org/10.48550/arXiv.2411.18412 (2024) (+4)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The SOTS-Outdoor dataset is primarily used for evaluating dehazing algorithms in outdoor scenes, focusing on enhancing visibility and restoring clear images from hazy environments. It is also utilized for testing image deraining, assessing the model's ability to remove rain from outdoor images. The dataset consists of real-world outdoor scenes, enabling researchers to evaluate the performance of dehazing and deraining methods under varying atmospheric conditions.
Outdoor-Rain	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.48550/arXiv.2504.05135 (2025), https://doi.org/10.48550/arXiv.2506.16960 (2025) (+2)	https://doi.org/10.1109/CVPR.2018.00263 (2017)	The Outdoor-Rain dataset is primarily used for rain removal in outdoor scenes, focusing on realistic rain effects and their impact on image quality. It is employed to train and evaluate rain removal algorithms, using both synthetic and real rain images to enhance image clarity and model robustness in various rainy conditions, including heavy rain with streaks and haze. The dataset supports deraining tasks by providing real-world outdoor rain images, enabling researchers to test and improve the performance of rain removal techniques.
RealSnow	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.48550/arXiv.2412.20157 (2024), https://doi.org/10.48550/arXiv.2410.15067 (2024) (+1)	https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	The RealSnow dataset is primarily used for evaluating and testing desnowing methods in image restoration. It provides real-world snow images to assess the effectiveness of algorithms in removing snow artifacts, focusing on clarity and texture preservation. Researchers use this dataset to evaluate the performance of desnowing techniques, ensuring they can handle realistic snow conditions and improve image quality.
CBSD68	https://doi.org/10.48550/arXiv.2406.18242 (2024), https://doi.org/10.48550/arXiv.2310.10123 (2023), https://doi.org/10.48550/arXiv.2505.12630 (2025) (+3)	https://doi.org/10.1109/CVPR.2015.7299156 (2015)	The CBSD68 dataset is primarily used for evaluating and benchmarking image denoising and restoration algorithms. It consists of 68 color images with known ground truth, enabling researchers to test performance under various noise levels (σ = 15, 25, 50). The dataset facilitates visual comparisons and quantitative assessments, focusing on denoising accuracy, detail preservation, and overall image quality. It serves as a standard benchmark for comparing state-of-the-art methods in image restoration.
SRRS	https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.1109/TIP.2025.3572788 (2025), https://doi.org/10.48550/arXiv.2411.18412 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The SRRS dataset is primarily used to train and evaluate image desnowing models, focusing on the removal of snow from images. It is employed to assess the performance of algorithms in handling varying snow intensities, textures, and complex scenarios, emphasizing size and transparency-aware techniques. The dataset supports research by providing a benchmark for comparing the effectiveness of different models, such as PoolNet-S and FocalNet, using metrics like PSNR.
Dense-Haze	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.1109/TIP.2025.3572788 (2025)	https://doi.org/10.1109/ICIP.2019.8803046 (2019)	The Dense-Haze dataset is primarily used for dehazing images, particularly in dense haze conditions, to evaluate and improve the performance of dehazing algorithms. It is employed to test the robustness and effectiveness of methods in enhancing visibility and color fidelity in hazy images. The dataset serves as a benchmark, providing dense-haze and haze-free images for real-world scenario evaluations.
NH-HAZE	https://doi.org/10.48550/arXiv.2503.09403 (2025), https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.1109/TCSVT.2024.3429557 (2024) (+1)	https://doi.org/10.1109/CVPRW50498.2020.00230 (2020)	The NH-HAZE dataset is primarily used for non-homogeneous dehazing research, providing paired hazy and haze-free images to evaluate dehazing algorithms. It is utilized to assess the performance of models under varying conditions, focusing on the restoration of clear and sharp images from real-world hazy environments. This dataset enables researchers to test and compare dehazing methods effectively.
REVIDE	https://doi.org/10.48550/arXiv.2411.17687 (2024), https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.48550/arXiv.2505.18047 (2025) (+2)	https://doi.org/10.1109/CVPR46437.2021.00912 (2021)	The REVIDE dataset is primarily used for evaluating and comparing methods in image and video restoration, specifically focusing on rain and haze removal. It is utilized to test the effectiveness of dehazing and deraining techniques in both static images and video sequences, enabling researchers to assess performance in real-world scenarios. The dataset includes dynamic scene data, which is crucial for training and evaluating deblurring models.
Snow100K-L	https://doi.org/10.1109/TMM.2025.3535316 (2024), https://doi.org/10.1109/TCSVT.2024.3516074 (2024), https://doi.org/10.48550/arXiv.2410.08177 (2024) (+2)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The Snow100K-L dataset is primarily used for evaluating snow removal techniques in synthetic images. Researchers employ it to test and assess the effectiveness of desnowing algorithms, focusing on improving image visibility and restoration under snow degradation. The dataset's large scale and high-resolution synthetic snowy images enable robust testing of various restoration methods, including hierarchical dual-tree complex wavelet representation and contradict channel loss.
LOL-v2	https://doi.org/10.48550/arXiv.2409.19403 (2024), https://doi.org/10.1109/TCSVT.2024.3519352 (2025), https://doi.org/10.48550/arXiv.2412.20157 (2024) (+2)	https://doi.org/10.1109/CVPR52688.2022.01719 (2022)	The LOL-v2 dataset is primarily used for evaluating and testing low-light image enhancement techniques. It contains paired low-light and normal-light images, which researchers use to assess the effectiveness of image restoration methods in improving visibility and color accuracy in dark environments. This dataset enables the evaluation of models like AllRestorer, focusing on enhancing visibility and color fidelity in low-light conditions.
Test1	https://doi.org/10.1109/TMM.2025.3535316 (2024), https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.1109/CVPR52688.2022.00239 (2021) (+1)	https://doi.org/10.1109/CVPR.2019.00173 (2019)	The Test1 dataset is primarily used to evaluate the performance of image restoration methods, particularly in removing rain and haze from images. It contains 750 images and is employed to assess the effectiveness of models in enhancing image quality under various degradations, including rain streaks and complex weather conditions. This dataset enables researchers to test and compare different restoration techniques, focusing on both specific and general restoration capabilities.
EUVP	https://doi.org/10.3390/electronics13142817 (2024), https://doi.org/10.48550/arXiv.2506.16960 (2025)	https://doi.org/10.1109/LRA.2020.2974710 (2019)	The EUVP dataset is primarily used for evaluating and comparing underwater image enhancement techniques, focusing on visual perception improvements. It consists of 900 pairs of degraded and clean images for training and 100 pairs for testing, enabling researchers to assess the performance of various enhancement methods and restoration algorithms. The dataset supports experiments aimed at improving visual perception in underwater images, using specific restoration techniques and models.
LIVE1	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.48550/arXiv.2406.18242 (2024), https://doi.org/10.48550/arXiv.2410.15385 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The LIVE1 dataset is primarily used for JPEG artifact removal, focusing on reducing compression artifacts, particularly at low quality factors such as q = 10. It is employed to evaluate and demonstrate the effectiveness of image restoration algorithms in removing these artifacts, as well as to assess the loss of degradation information post-processing. This dataset enables researchers to test and compare different methods for improving image quality in the context of JPEG compression.
RealBlur	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.48550/arXiv.2410.15385 (2024), https://doi.org/10.1109/CVPR52733.2024.00277 (2023)	https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	The RealBlur dataset is primarily used for motion deblurring research, focusing on real-world motion blur in images. It consists of authentic out-of-focus and motion-blurred images captured under various conditions. Researchers use this dataset to test and assess the effectiveness of deblurring algorithms, emphasizing sharpness and detail recovery, and improving overall image clarity.
I-Haze	https://doi.org/10.48550/arXiv.2503.09403 (2025), https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.1109/TCSVT.2024.3519352 (2025)	https://doi.org/10.1109/CVPRW.2018.00119 (2018)	The I-Haze dataset is used for evaluating dehazing algorithms by providing 10 paired low-quality and high-quality images, as well as real-world hazy and haze-free indoor images. It is employed in dehazing experiments to test the robustness and performance of dehazing algorithms, particularly in the context of all-in-one image restoration models. The dataset's real-world images enable researchers to assess the effectiveness of their methods in practical scenarios.
SPANet	https://doi.org/10.48550/arXiv.2505.21637 (2025), https://doi.org/10.1109/TPAMI.2025.3562211 (2024)	https://doi.org/10.1109/CVPRW.2018.00119 (2018)	The SPANet dataset is primarily used for evaluating and training image restoration models, particularly in deraining tasks. It is employed to assess the performance of various algorithms, such as BaryIR and DA-RCOT, on real-world rain degradation, emphasizing robustness and generalization on unseen data. The dataset facilitates comparisons with state-of-the-art methods, focusing on improving image clarity and removing rain streaks, and is used to measure performance metrics like PSNR.
DIV2K	https://doi.org/10.1109/TIP.2025.3572788 (2025), https://doi.org/10.48550/arXiv.2310.10123 (2023), https://doi.org/10.48550/arXiv.2404.02154 (2024) (+1)	https://doi.org/10.1109/CVPRW.2017.151 (2017)	The DIV2K dataset is primarily used for training and evaluating image restoration models, focusing on high-resolution image quality and detail preservation. It is utilized for tasks such as image super-resolution, denoising, and compression, particularly in single-degradation scenarios. The dataset provides high-quality, high-resolution natural images, enabling researchers to develop and assess algorithms that enhance image clarity and reduce noise.
TOLED	https://doi.org/10.48550/arXiv.2503.09403 (2025), https://doi.org/10.48550/arXiv.2505.18047 (2025), https://doi.org/10.48550/arXiv.2412.20157 (2024) (+1)	https://doi.org/10.1109/CVPR46437.2021.00906 (2020)	The TOLED dataset is used for evaluating and enhancing the quality of images captured by under-display cameras, particularly in OLED displays. It provides 10 paired images to assess restoration techniques, focusing on improving image clarity and reducing noise. The dataset supports research on generalizing image restoration models to unseen tasks, ensuring robust performance on real-world under-display camera images.
RainDS	https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.48550/arXiv.2411.17687 (2024)	https://doi.org/10.1109/CVPR.2017.35 (2016)	RainDS is primarily used for raindrop and rain removal research, providing a diverse set of synthetic and real rainy images. It is employed to train and evaluate algorithms, assessing their performance in removing raindrops and rain from images. The dataset's variety of rainy conditions enables researchers to rigorously test and improve image restoration techniques.
BSD	https://doi.org/10.48550/arXiv.2410.15385 (2024), https://doi.org/10.1109/CVPR52733.2024.00277 (2023), https://doi.org/10.48550/arXiv.2407.00676 (2024) (+1)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The BSD dataset is primarily used for training and evaluating models in image restoration, specifically for denoising and deblurring tasks. It provides a benchmark with 400 natural images, often concatenated with other datasets like WED, to form robust training sets. This dataset enables researchers to assess the performance of denoising algorithms and improve image restoration techniques through diverse, ground-truth annotated images.
Kodak24	https://doi.org/10.1109/TCSI.2024.3519532 (2025), https://doi.org/10.1109/CVPR52729.2023.00564 (2023), https://doi.org/10.48550/arXiv.2403.14614 (2024) (+2)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The Kodak24 dataset is primarily used for image denoising and restoration research, serving as a benchmark for evaluating the effectiveness of various algorithms. It provides a standard set of 24 high-quality, diverse, and natural images, enabling researchers to assess the preservation of color and detail under different noise conditions. The dataset supports both visual and quantitative evaluations, facilitating comparisons between different denoising and restoration methods.
Test1200	https://doi.org/10.48550/arXiv.2406.18242 (2024), https://doi.org/10.1109/TCSVT.2024.3398810 (2023)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Test1200 dataset is primarily used for evaluating deraining algorithms, focusing on the removal of rain streaks from images. It provides a large set of images with synthetic rain, enabling comprehensive testing across various rain intensities. This dataset facilitates the validation of algorithm robustness and reliability, ensuring effective deraining performance in diverse conditions.
Rain14000	https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.48550/arXiv.2406.18242 (2024), https://doi.org/10.1109/TCSVT.2024.3398810 (2023)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The Rain14000 dataset is primarily used for training and evaluating rain removal algorithms, with a focus on diverse rain patterns and intensities. It contains 13,712 images with rain streaks, enabling robustness testing of deraining models. Researchers employ this dataset to develop and assess methods, such as conditional generative adversarial networks, aimed at effectively removing rain streaks from images.
Rain1200	https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.48550/arXiv.2504.09973 (2025)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The Rain1200 dataset is used for training and evaluating rain removal algorithms, specifically focusing on synthetic rain images with varying intensities. It is employed to synthesize images with rain degradation to assess the performance of image restoration techniques, particularly in de-raining applications. This dataset enables researchers to test and improve the effectiveness of algorithms in removing rain from images, enhancing their quality and usability.
Rain12	https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.48550/arXiv.2406.18242 (2024), https://doi.org/10.1109/TCSVT.2024.3398810 (2023)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The Rain12 dataset is used for training and evaluating rain removal algorithms, particularly focusing on real-world rain images. It serves as a benchmark for deraining models, enabling researchers to test and improve methods for removing rain streaks from images using techniques such as conditional generative adversarial networks. The dataset's challenging rainy images facilitate the development of robust deraining algorithms.
SICE	https://doi.org/10.48550/arXiv.2411.17687 (2024), https://doi.org/10.48550/arXiv.2505.18047 (2025)	https://doi.org/10.1109/CVPR46437.2021.00912 (2021)	The SICE dataset is used in research for single-image color and contrast enhancement. It provides multi-exposure images to train and evaluate models, focusing on color correction, detail preservation, and contrast improvement. This dataset enables researchers to assess the generalization of their models on real-world images, enhancing both visual quality and perceptual accuracy.
Rain13k	https://doi.org/10.48550/arXiv.2409.19403 (2024), https://doi.org/10.48550/arXiv.2411.17687 (2024), https://doi.org/10.48550/arXiv.2505.18047 (2025)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The Rain13k dataset is used for training and testing deraining models, specifically to remove rain streaks and improve image clarity. It consists of 13,711 training images and 4,298 test images, providing a large set of paired rainy and clean images. This dataset enables researchers to develop and evaluate deraining algorithms effectively.
RSID	https://doi.org/10.3390/electronics13142817 (2024)	https://doi.org/10.1016/J.INS.2019.02.058 (2019)	The RSID dataset is used for comparing and evaluating image restoration methods, particularly in dehazing and restoration performance in remote sensing images. It provides 7000 pairs of degraded and clean images for training and 1000 pairs for testing, enabling researchers to assess the effectiveness of different restoration algorithms.
RealBlur-J	https://doi.org/10.1109/CVPR52733.2024.00277 (2023), https://doi.org/10.48550/arXiv.2506.16960 (2025), https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1109/ICCV.2019.00567 (2019)	The RealBlur-J dataset is primarily used for evaluating motion deblurring algorithms, containing real-world blurred images with ground truth. It is employed to test the robustness and effectiveness of proposed methods in practical scenarios, focusing on improving image clarity and quality in real-world conditions. This dataset enables researchers to assess the performance of their algorithms on authentic, challenging data, ensuring that the solutions are viable for real-world applications.
AVIRIS	https://www.semanticscholar.org/paper/1fb8e5cc1d55d637a55be02138224cb4b9e87465 (2024)	https://doi.org/10.1016/j.isprsjprs.2022.04.007 (2022)	The AVIRIS dataset is used for evaluating and experimenting with hyperspectral image restoration methods, particularly focusing on composite degradations. It leverages extensive HSI data with numerous spectral bands across diverse geographical areas, enabling researchers to assess the performance of restoration techniques like PromptHSI against others. This dataset's comprehensive coverage and high spectral resolution facilitate robust testing and validation in hyperspectral image restoration research.
DID-Data	https://doi.org/10.1109/TCSVT.2023.3299324 (2024), https://doi.org/10.1109/CVPR52733.2024.00277 (2023)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The DID-Data dataset is used in research for training and evaluating image restoration methods, particularly in synthetic rainstreak degradation and image denoising. It integrates physics models and conditional adversarial learning to test robustness under diverse image conditions and degradation scenarios. This dataset enables researchers to assess the performance of their methods in challenging and varied environments.
All-Weather	https://doi.org/10.48550/arXiv.2410.15385 (2024), https://doi.org/10.48550/arXiv.2504.05135 (2025), https://doi.org/10.1109/CVPR52688.2022.00239 (2021) (+1)	https://doi.org/10.1109/CVPR52688.2022.00239 (2021)	The All-Weather dataset is used for training and evaluating models designed to restore images degraded by various adverse weather conditions, such as rain, haze, and snow. It employs methodologies like generative adversarial networks and benchmarks like DA 2 Diff to assess the effectiveness of restoration algorithms under different weather scenarios, ensuring robust performance and fair comparisons with previous methods.
FiveK	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The FiveK dataset is primarily used for low-light enhancement research, where it tests and evaluates the ability of algorithms to improve image quality in low-light conditions. It contains a diverse set of images with professional retouching, enabling researchers to assess the effectiveness of various image enhancement methods. This dataset facilitates the development and comparison of low-light enhancement techniques by providing a standardized benchmark.
Test2800	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Test2800 dataset is primarily used for deraining research, specifically to assess and validate the performance of deraining algorithms. It provides a large set of images with synthetic rain, enabling researchers to evaluate these methods across diverse weather conditions and a broader range of images. This dataset enhances the robustness and reliability of deraining algorithm evaluations by offering a more extensive and varied test set.
GoPro test set	https://doi.org/10.48550/arXiv.2310.10123 (2023), https://doi.org/10.48550/arXiv.2405.15475 (2024), https://doi.org/10.1007/978-3-031-72764-1_1 (2024) (+1)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The GoPro test set is primarily used for evaluating and comparing the performance of image restoration methods, particularly in motion deblurring. It consists of 2103 training and 1111 testing images, enabling researchers to assess the effectiveness of algorithms in removing motion blur and handling noise (σ=25) in dynamic scenes. This dataset facilitates the development and benchmarking of deep learning models, such as multi-scale convolutional neural networks, for high-resolution image restoration tasks.
CDD-11	https://doi.org/10.1109/TIP.2025.3572788 (2025), https://www.semanticscholar.org/paper/4af9a92a556981375dab533ccc55860f01c8b5da (2025)	https://doi.org/10.48550/arXiv.2407.04621 (2024)	The CDD-11 dataset is used to evaluate and simulate image restoration under various compositional degradations, including 11 types such as haze, rain, snow, and low-light conditions. It focuses on assessing the performance of the OneRestore framework in handling these degradation scenarios, enabling researchers to test and improve image restoration techniques in realistic settings.
SPA+	https://doi.org/10.48550/arXiv.2410.15067 (2024), https://doi.org/10.1109/WACV61041.2025.00069 (2025), https://doi.org/10.1145/3664647.3680762 (2024)	https://doi.org/10.1109/CVPR46437.2021.00912 (2021)	The SPA+ dataset is primarily used for evaluating and comparing methods in all-weather image restoration, specifically focusing on rain, haze, and snow removal. It is employed to test the effectiveness of models in handling synthetic and real-world weather conditions, particularly in removing rain streaks, water droplets, and other artifacts. This dataset enables researchers to conduct qualitative assessments and benchmark the performance of image deraining techniques.
NHR	https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.1109/TIP.2025.3572788 (2025)	https://doi.org/10.1145/3394171.3413763 (2020)	The NHR dataset is primarily used for training and evaluating models in nighttime dehazing tasks. It provides real-world nighttime hazy images to assess the performance of proposed methods, focusing on enhancing visibility and color fidelity. This dataset enables researchers to test and refine dehazing algorithms specifically tailored for low-light conditions.
GTA5	https://doi.org/10.1109/TCSVT.2024.3429557 (2024), https://doi.org/10.1109/TIP.2025.3572788 (2025)	https://doi.org/10.1145/3394171.3413763 (2020)	The GTA5 dataset is primarily used for dehazing research, particularly in synthetic nighttime dehazing tasks. It provides synthetic nighttime hazy images that are utilized for both training and evaluating methods. The dataset's focus on complex lighting conditions and urban scenes enables researchers to test the robustness of dehazing algorithms in challenging environments.
LoL v1	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The LoL v1 dataset is primarily used for low-light image enhancement research, focusing on improving image brightness and clarity in various low-light conditions. Researchers employ this dataset to evaluate the effectiveness of different enhancement techniques, assessing their performance across a range of challenging lighting scenarios. This dataset enables the development and testing of algorithms designed to enhance images captured in very low light, providing a standardized benchmark for comparing methods.
LoL v2	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The LoL v2 dataset is primarily used for low-light image enhancement research. It provides a newer, more challenging set of images, including additional images, to evaluate and improve low-light enhancement techniques. Researchers use this dataset to test the effectiveness of advanced enhancement methods, focusing on the quality and realism of the enhanced images.
SateHaze1k	https://doi.org/10.1109/TCSVT.2024.3429557 (2024)	https://doi.org/10.1109/WACV45572.2020.9093471 (2020)	The SateHaze1k dataset is primarily used for dehazing experiments in remote sensing, specifically for satellite image restoration. Researchers employ this dataset to improve image clarity using methods such as SAR image priors and conditional GANs. It is utilized to evaluate the performance of dehazing algorithms, particularly the Asimage dehazing model, in enhancing the quality of satellite imagery.
Raindrop datasets	https://doi.org/10.48550/arXiv.2310.10123 (2023), https://doi.org/10.48550/arXiv.2504.05135 (2025)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The Raindrop datasets are used for evaluating raindrop removal algorithms, specifically to restore images degraded by raindrops. Containing 58 images, the dataset is designed to assess the effectiveness of these algorithms in removing raindrops, thereby enhancing image quality. This enables researchers to compare and improve the performance of different raindrop removal techniques.
BSD100	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The BSD100 dataset is primarily used for super-resolution tasks, specifically single image super-resolution. It provides high-quality images for both training and evaluation, enabling researchers to enhance the resolution of low-quality images. The dataset's high-quality images facilitate the development and testing of algorithms aimed at improving image clarity and detail.
Manga109	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The Manga109 dataset is primarily used for super-resolution tasks, specifically focusing on enhancing the resolution and detail of manga images. Researchers employ this dataset to improve image clarity and detail through single image super-resolution techniques. The dataset's focus on manga images makes it particularly useful for evaluating and developing algorithms tailored to this specific type of content.
SPA	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The SPA dataset is primarily used for rain removal tasks in image restoration research. It features both synthetic and real rain images, which are utilized to assess and improve the performance of de-raining techniques. Researchers employ this dataset to evaluate the effectiveness of various rain removal methods, focusing on enhancing image quality and de-raining performance.
RealBlur-R	https://doi.org/10.1109/CVPR52733.2024.00277 (2023), https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1109/ICCV.2019.00567 (2019)	The RealBlur-R dataset is used for evaluating motion deblurring algorithms on real-world images, assessing the robustness and effectiveness of these methods in practical scenarios. It contains real-world blurred images with ground truth, enabling researchers to test and validate their algorithms against realistic conditions.
Flickr2K	https://doi.org/10.48550/arXiv.2310.10123 (2023), https://doi.org/10.48550/arXiv.2412.20157 (2024), https://doi.org/10.48550/arXiv.2404.02154 (2024)	https://doi.org/10.1109/CVPRW.2017.151 (2017)	The Flickr2K dataset is primarily used for image restoration tasks, including Gaussian color image denoising, compression, and super-resolution. It provides high-quality, high-resolution natural images, which are essential for training and evaluating models like AutoDIR. The dataset complements other datasets like DIV2K, offering diverse images for comprehensive model training, particularly in single-degradation scenarios and at various downsampled scales (x8 and x4).
OTS	https://doi.org/10.1109/TCSVT.2023.3299324 (2024)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The OTS dataset is primarily used for training and evaluating haze removal algorithms, specifically focusing on outdoor synthetic hazy images. Researchers employ this dataset to develop and test algorithms that enhance image clarity by removing haze, contributing to advancements in image restoration techniques. The synthetic nature of the dataset allows for controlled experimentation and robust algorithm validation.
ITS	https://doi.org/10.1109/TCSVT.2023.3299324 (2024)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The ITS dataset is primarily used for training and evaluating haze removal algorithms, specifically focusing on indoor synthetic hazy images. Researchers employ this dataset to develop and test algorithms that enhance image clarity by removing haze, addressing the challenge of improving visual quality in hazy conditions. The synthetic nature of the dataset allows for controlled experimentation and robust algorithm validation.
RealSR-Val	https://doi.org/10.48550/arXiv.2503.09403 (2025)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The RealSR-Val dataset is used for validating image super-resolution models, specifically focusing on real-world low-resolution (LQ) and high-resolution (HR) image pairs. It enables researchers to assess the performance of super-resolution techniques in realistic scenarios, ensuring that models generalize well to real-world conditions. This dataset is crucial for evaluating the effectiveness of super-resolution algorithms in handling authentic LQ-HR pairs.
DRealSR-Val	https://doi.org/10.48550/arXiv.2503.09403 (2025)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The DRealSR-Val dataset is used for validating image super-resolution models, specifically focusing on real-world low-resolution and high-resolution image pairs. It serves as a benchmark to evaluate the performance of these models in practical scenarios, ensuring they can effectively enhance image quality in real-world conditions. The dataset's emphasis on real-world images makes it particularly relevant for assessing the robustness and generalizability of super-resolution techniques.
T-OLED-Val	https://doi.org/10.48550/arXiv.2503.09403 (2025)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The T-OLED-Val dataset is used for validating image restoration models, particularly focusing on low-resolution (LQ) and high-resolution (HQ) image pairs from OLED displays and under-display cameras. It enables researchers to assess the performance of restoration models in enhancing image quality, ensuring that the models effectively handle the specific characteristics of T-OLED technology.
HSTS	https://doi.org/10.1109/TCSVT.2023.3299324 (2024)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The HSTS dataset is used for training and evaluating haze removal algorithms, specifically focusing on synthetic hazy images with varying conditions. This dataset enables researchers to test the robustness and effectiveness of their algorithms across different haze scenarios, contributing to advancements in image dehazing techniques.
DRealSR	https://doi.org/10.48550/arXiv.2503.09403 (2025)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The DRealSR dataset is mentioned in the citation context but lacks detailed descriptions of its usage in specific research studies. Therefore, there is no concrete evidence to describe its application, methodology, research questions, or enabling capabilities in any particular research area.
RealSR	https://doi.org/10.48550/arXiv.2503.09403 (2025)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The RealSR dataset is used for real-world super-resolution tasks, specifically to test the effectiveness of restoration algorithms. It consists of 15 paired images, enabling researchers to evaluate how well these algorithms perform in enhancing image resolution in practical scenarios. This dataset facilitates the development and assessment of super-resolution techniques by providing realistic test cases.
LHP-Rain	https://doi.org/10.48550/arXiv.2503.09403 (2025)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The LHP-Rain dataset is used for evaluating rain removal algorithms in image restoration. It consists of 20 paired images, which researchers use to assess the performance of these algorithms. The dataset enables the comparison of different methods by providing ground truth images, facilitating the analysis of effectiveness in rain removal tasks.
Snow100K-L test set	https://doi.org/10.1109/CVPR52688.2022.00239 (2021), https://doi.org/10.48550/arXiv.2504.05135 (2025)	https://doi.org/10.1109/CVPR.2018.00263 (2017)	The Snow100K-L test set is used to evaluate the effectiveness of snow removal algorithms, specifically focusing on clarity and detail preservation in snowy conditions. It consists of 16,081 images and is employed to assess methods' performance in removing snow, ensuring that restored images maintain high quality and detail. This dataset enables researchers to rigorously test and compare different snow removal techniques.
RESIDE-6K	https://doi.org/10.1109/TMM.2025.3535316 (2024)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The RESIDE-6K dataset is primarily used to assess and evaluate haze removal methods in image restoration. It contains 6,000 pairs of hazy and clear images, enabling researchers to test the effectiveness and robustness of dehazing techniques. This large-scale dataset supports the development and evaluation of algorithms designed to restore images degraded by haze, ensuring they perform well under various conditions.
Raindrop-A	https://doi.org/10.1109/TMM.2025.3535316 (2024)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The Raindrop-A dataset is used to test and evaluate raindrop removal algorithms, focusing on the impact of raindrops on image quality and the effectiveness of restoration methods. It features images with realistic raindrop effects, enabling researchers to assess the performance of techniques designed to remove raindrops from degraded images.
LOL-v2-synthetic	https://doi.org/10.1109/TIP.2025.3572788 (2025)	https://doi.org/10.1109/TIP.2021.3050850 (2021)	The dataset 'LOL-v2-synthetic' is mentioned in the citation context but lacks detailed descriptions of its usage in research. There is no explicit information regarding its application, methodology, research questions, or specific characteristics. Therefore, it cannot be accurately described as being used for All-in-One Image Restoration or any other specific research area based on the provided evidence.
RS100K-L	https://doi.org/10.1109/TMM.2025.3535316 (2024)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The RS100K-L dataset is used to evaluate image restoration techniques, specifically focusing on the removal of combined rain and snow degradations. It tests algorithms' ability to handle multiple degradations simultaneously, featuring images degraded by both rain and snow. This dataset enables researchers to assess the effectiveness of restoration methods in complex, real-world scenarios.
DCIE	https://doi.org/10.48550/arXiv.2410.15385 (2024)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The DCIE dataset is used for low-light image enhancement, focusing on improving color and contrast in low-light conditions. Researchers employ this dataset to develop and evaluate algorithms that address specific challenges in low-light imaging, enhancing the visual quality of images captured in dim environments. This dataset enables the testing and validation of enhancement techniques, contributing to advancements in low-light image processing.
MEF	https://doi.org/10.48550/arXiv.2410.15385 (2024)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The MEF dataset is used for low-light image enhancement, specifically focusing on multi-exposure fusion techniques. This methodology improves the dynamic range and detail in low-light scenes. The dataset enables researchers to address challenges in enhancing image quality under low-light conditions, providing a robust set of images for testing and validating multi-exposure fusion algorithms.
NPE	https://doi.org/10.48550/arXiv.2410.15385 (2024)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The NPE dataset is used for low-light image enhancement, focusing on noise reduction and detail preservation in low-light conditions. Researchers employ this dataset to develop and evaluate algorithms that improve image quality in dimly lit environments, addressing specific challenges such as noise and loss of detail. The dataset's emphasis on these aspects enables robust testing and validation of enhancement techniques.
JRSRD	https://doi.org/10.1109/TCSVT.2024.3519352 (2025), https://doi.org/10.1109/TCSVT.2024.3516074 (2024)	https://doi.org/10.48550/arXiv.2212.11548 (2022)	The JRSRD dataset is used for restoring images degraded by rain and other real-world factors, enhancing performance in challenging environments. It is specifically leveraged to evaluate deraining performance, providing images with rain streaks and raindrops to test the effectiveness of all-in-one image restoration models. This dataset enables researchers to assess and improve the robustness of image restoration techniques in realistic conditions.
Snow100K S	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Snow100K S dataset is primarily used for desnowing research, focusing on small-scale and small-sized images. It evaluates the effectiveness and performance of snow removal methods, enabling researchers to assess the quality of desnowing techniques on detailed, smaller image sets. This dataset facilitates the development and testing of algorithms designed to improve image clarity in snowy conditions.
Snow100K M	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Snow100K M dataset is primarily used for desnowing research, specifically to assess the performance of snow removal algorithms on medium-scale images. Studies employ this dataset to evaluate the effectiveness of desnowing techniques, focusing on the quality and efficiency of image restoration in snowy conditions. The dataset's medium-sized images are crucial for testing and validating these algorithms.
Snow100K L	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Snow100K L dataset is primarily used for desnowing research, specifically to test and validate the effectiveness of snow removal techniques on large-scale images. It focuses on assessing the robustness of these methods, leveraging the dataset's large-sized images to ensure that desnowing algorithms perform reliably under various conditions.
RESIDED-OTS	https://doi.org/10.48550/arXiv.2402.03738 (2024)	https://doi.org/10.1109/TITS.2016.2634580 (2016)	The RESIDED-OTS dataset is primarily used for enhancing and restoring images of land and underwater scenes. It incorporates depth information to improve image quality, detail, and contrast. Specifically, it supports techniques such as dual prior optimized contrast enhancement for underwater images and low-light image restoration for land scenes. This dataset enables researchers to focus on advanced image restoration methods, enhancing visibility and color accuracy in challenging environments.
Rain13k-Test	https://doi.org/10.48550/arXiv.2409.19403 (2024)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The Rain13k-Test dataset is used for evaluating deraining algorithms by combining multiple datasets to assess their effectiveness in diverse conditions. It is specifically employed to test the performance of algorithms in removing rain streaks from images, ensuring robustness across various scenarios. This dataset enables researchers to benchmark and compare deraining techniques comprehensively.
LSDIR-val	https://doi.org/10.48550/arXiv.2409.19403 (2024)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The LSDIR-val dataset is used for evaluating the performance of image restoration models, specifically in kernel deblurring and JPEG artifact removal. It assesses the accuracy of kernel estimation for various degradation types, enabling researchers to test and refine models that handle multiple image degradation issues effectively.
RSVD	https://doi.org/10.48550/arXiv.2411.17687 (2024)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The RSVD dataset is primarily used for video deblurring research, providing real-world blurred video data. It enables the training and evaluation of deblurring models, focusing on enhancing the clarity of motion-blurred videos. The dataset's real-world characteristics make it valuable for developing robust deblurring algorithms.
GenDS	https://doi.org/10.48550/arXiv.2411.17687 (2024)	https://www.semanticscholar.org/paper/20d4e85814f64977590bc9276eec84203f0fcf9b (2023)	The GenDS dataset is used to train and evaluate models for all-in-one image restoration, focusing on improving image quality across various degradation types. It is employed to train and compare models such as NAFNet, PromptIR, and Swin Transformer, assessing their performance and effectiveness in comprehensive restoration tasks. The dataset enables researchers to evaluate the impact of the data on model accuracy and to compare different models' capabilities in handling diverse image degradations.
LHP-/Real-Rain-Val	https://doi.org/10.48550/arXiv.2503.09403 (2025)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The LHP-/Real-Rain-Val dataset is used for validating image deraining models by providing rain-degraded and clean image pairs. This enables researchers to assess the effectiveness of deraining algorithms in restoring images to their original quality, focusing on the accuracy and performance of these models in removing rain artifacts.
SIDD-Val	https://doi.org/10.48550/arXiv.2503.09403 (2025)	https://doi.org/10.1109/CVPR.2018.00182 (2018)	The SIDD-Val dataset is primarily used for validating image denoising models by providing noisy and clean image pairs. Researchers employ this dataset to assess the performance and accuracy of their denoising algorithms, ensuring they effectively reduce noise while preserving image details. This validation process is crucial for advancing image restoration techniques.
RainDrop test dataset	https://doi.org/10.1109/CVPR52688.2022.00239 (2021)	https://doi.org/10.1109/CVPR.2018.00263 (2017)	The RainDrop test dataset is used for evaluating the performance of image restoration models, specifically focusing on the task of removing raindrops from images. It tests the effectiveness of restoration methods by providing a benchmark for assessing model accuracy and efficiency in this domain.
MC-blur	https://doi.org/10.1109/TCSVT.2024.3519352 (2025), https://doi.org/10.1109/TCSVT.2024.3516074 (2024)	https://doi.org/10.1109/TCSVT.2023.3319330 (2021)	The MC-blur dataset is used to advance and evaluate deblurring algorithms, addressing various types of blur such as motion, ultra-high-definition, and defocus blur. It serves as an unseen dataset to test the robustness of these algorithms in real-world scenarios, ensuring they can handle diverse and complex blurring conditions. This dataset enables researchers to refine and validate their methods, enhancing the performance and reliability of deblurring techniques.
RWBI	https://doi.org/10.1109/TCSVT.2024.3519352 (2025), https://doi.org/10.1109/TCSVT.2024.3516074 (2024)	https://doi.org/10.48550/arXiv.2212.11548 (2022)	The RWBI dataset is used to enhance and evaluate image restoration performance, particularly in real-world conditions involving complex degradations such as blur and varying illumination. It serves as an unseen benchmark for testing deblurring algorithms, providing realistic scenarios to assess and improve algorithm robustness.
RainKITTI2012	https://doi.org/10.1109/TCSVT.2024.3519352 (2025), https://doi.org/10.1109/TCSVT.2024.3516074 (2024)	https://doi.org/10.48550/arXiv.2212.11548 (2022)	The RainKITTI2012 dataset is utilized to test and improve image restoration algorithms, particularly in rainy conditions. It focuses on synthetic rain effects and is used as an unseen dataset to evaluate deraining algorithms, especially in the context of stereo image deraining with semantic understanding. This dataset enables researchers to assess the performance and robustness of deraining techniques under controlled synthetic rain scenarios.
Rain1800	https://doi.org/10.48550/arXiv.2406.18242 (2024), https://doi.org/10.1109/TCSVT.2024.3398810 (2023)	https://doi.org/10.1109/CVPR.2016.299 (2016)	The Rain1800 dataset is used to train and evaluate deraining models, providing a diverse set of rainy images for algorithm validation. It focuses on removing rain streaks from images, often employing conditional generative adversarial networks. This dataset enables researchers to test the effectiveness of deraining algorithms in various conditions, ensuring robust performance.
POLED	https://doi.org/10.48550/arXiv.2505.18047 (2025)	https://doi.org/10.1109/CVPR46437.2021.00912 (2021)	The POLED dataset is used to evaluate models' generalization capabilities on real-world under-display camera images from OLED displays. Researchers focus on assessing image clarity and noise reduction, employing the dataset to test and validate the performance of their models in enhancing image quality under specific display conditions.
LSDIR	https://doi.org/10.48550/arXiv.2404.02154 (2024), https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1109/CVPRW53098.2021.00074 (2021)	The LSDIR dataset is used for large-scale image restoration research, providing a vast number of high-quality, high-resolution natural images. It focuses on real-world image degradations, enabling the training and evaluation of robust restoration models. This dataset supports practical tasks in image restoration by offering a comprehensive resource for both training and evaluation.
AirNet	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The AirNet dataset is used to evaluate and assess image restoration techniques, particularly focusing on aerial images under various atmospheric conditions such as haze and rain. Researchers employ this dataset to test and compare the quality of image restoration methods, ensuring they effectively handle the unique challenges posed by aerial imagery. This enables the development and refinement of robust image restoration algorithms.
DDN-Data	https://doi.org/10.1109/CVPR52733.2024.00277 (2023)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The DDN-Data dataset is used to train and evaluate methods for synthetic rainstreak degradation and image denoising, focusing on realistic rain effects and real-world noise patterns. It enables researchers to develop and test algorithms that address specific image degradation issues, enhancing the robustness and effectiveness of image restoration techniques.
SIDD validation set	https://doi.org/10.48550/arXiv.2310.10123 (2023)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The SIDD validation set is used for validating deblurring algorithms, specifically focusing on real-world image degradation and noise. This dataset enables researchers to assess the performance of deblurring techniques by providing realistic and diverse examples of degraded images, ensuring that the algorithms can handle various types of noise and blur effectively.
DIV2K validation set	https://doi.org/10.48550/arXiv.2310.10123 (2023)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The DIV2K validation set is primarily used for super-resolution tasks, where it assesses the ability to enhance image resolution. Researchers employ this dataset to evaluate and compare different super-resolution algorithms, focusing on the quality and effectiveness of resolution enhancement. The dataset's high-resolution images provide a benchmark for validating these techniques, ensuring they meet performance standards in image restoration.
Rain100	https://doi.org/10.48550/arXiv.2310.10123 (2023)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The Rain100 dataset is primarily used for rain removal research, focusing on the elimination of rain streaks from images. It is employed to test and evaluate the effectiveness of various image restoration techniques in removing rain artifacts. This dataset enables researchers to assess the performance of their methods in enhancing image clarity and quality under rainy conditions.
Challenge-60	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/TCSVT.2019.2963772 (2019)	The Challenge-60 dataset is used for evaluating and comparing the performance of underwater image restoration methods, particularly focusing on enhancing images under natural light conditions. It is employed to assess color correction and visual quality, enabling researchers to visually compare restoration results and test algorithms like NU2Net. This dataset facilitates the development and refinement of techniques for improving underwater imagery in challenging natural light environments.
UCCS	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/TCSVT.2019.2963772 (2019)	The UCCS dataset is used for evaluating and comparing underwater image enhancement techniques, particularly focusing on natural light conditions. It is employed to assess the effectiveness of methods like NU2Net in addressing color casts and improving overall image quality. The dataset enables researchers to visually compare restoration results and evaluate the performance of different enhancement algorithms in realistic underwater environments.
EUVP-330	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/TCSVT.2019.2963772 (2019)	The EUVP-330 dataset is used for testing and comparing underwater image restoration algorithms, particularly focusing on enhancing images under natural light conditions. It evaluates the robustness of these algorithms in diverse lighting scenarios and assesses their ability to reduce color casts and improve visual clarity. This dataset enables researchers to visually compare restoration results and validate the performance of models like NU2Net.
LOL-Blur	https://doi.org/10.1109/TIP.2025.3572788 (2025)	https://doi.org/10.1007/978-3-031-20068-7_33 (2022)	The 'LOL-Blur' dataset is mentioned in the citation context but lacks detailed descriptions of its usage in research. There is no explicit information regarding its application in All-in-One Image Restoration or any other specific research area, methodology, or research questions. The dataset's characteristics and how it enables research are not provided in the available descriptions.
SnowCityScapes	https://doi.org/10.1109/TCSVT.2024.3519352 (2025)	https://doi.org/10.1109/CVPRW.2018.00119 (2018)	The SnowCityScapes dataset is used for evaluating the desnowing performance of all-in-one image restoration models. It provides images with snow, enabling researchers to test the effectiveness of these models in removing snow from images. This dataset facilitates the assessment of desnowing algorithms by offering realistic, snowy urban scenes, which are crucial for validating the robustness and accuracy of image restoration techniques.
All-Weather dataset	https://doi.org/10.1109/ACCESS.2025.3526168 (2023)	https://doi.org/10.1109/cvpr42600.2020.00324 (2020)	The All-Weather dataset is used to evaluate the performance of image restoration methods under various weather conditions. Researchers employ this dataset to demonstrate both subjective and objective improvements of their proposed methods over existing state-of-the-art techniques. The dataset's diverse weather conditions enable comprehensive testing and validation of image restoration algorithms.
WeatherStream	https://doi.org/10.48550/arXiv.2410.08177 (2024), https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1109/CVPR52729.2023.01297 (2023)	The WeatherStream dataset is used to evaluate and test weather condition restoration models, specifically focusing on dehazing, deraining, and desnowing algorithms. It provides a large set of paired images: 4,500 for dehazing, 4,800 for deraining, and 3,960 for desnowing. This extensive dataset enables researchers to train and validate models, ensuring robust performance across various weather conditions.
LOL-v2-syn	https://doi.org/10.1109/TIP.2025.3572788 (2025)	https://doi.org/10.1109/TIP.2021.3050850 (2021)	The dataset 'LOL-v2-syn' is mentioned in the citation context but lacks detailed descriptions of its usage in research. There is no explicit information regarding its application, methodology, research questions, or specific characteristics. Therefore, it cannot be accurately described as being used for All-in-One Image Restoration or any other specific research area based on the provided evidence.
Rain-Haze-Snow	https://doi.org/10.48550/arXiv.2505.12630 (2025), https://doi.org/10.1109/CVPR52729.2023.00563 (2023)	https://doi.org/10.1109/cvpr42600.2020.00324 (2020)	The 'Rain-Haze-Snow' dataset is used to train and evaluate machine learning models for removing weather-based degradations such as rain, haze, and snow from images. It supports a single-encoder, multi-decoder framework and is utilized in neural architecture search for all-in-one image restoration, focusing on these specific weather conditions. This dataset enables researchers to develop and test models that can handle multiple types of image degradations simultaneously.
ImageNet-C	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://www.semanticscholar.org/paper/49b64383fe36268410c430352637ed23b16820c5 (2019)	ImageNet-C is used to benchmark the robustness of neural networks against common corruptions and perturbations, particularly during the pre-training stage. Researchers adjust the intensity of degradation in images to systematically evaluate how well models withstand various types of image corruption. This dataset enables the assessment and improvement of model resilience in real-world conditions.
Lai [18]	https://doi.org/10.48550/arXiv.2505.21637 (2025)	https://doi.org/10.1109/NCC.2015.7084843 (2015)	The Lai [18] dataset is used to evaluate image restoration performance, specifically addressing issues of blur and noise. Researchers employ metrics such as PSNR, SSIM, LPIPS, and FID to assess the effectiveness of restoration techniques. This dataset enables rigorous quantitative analysis, facilitating comparisons between different image restoration methods.
SPANet [48]	https://doi.org/10.48550/arXiv.2505.21637 (2025)	https://doi.org/10.1109/NCC.2015.7084843 (2015)	The SPANet dataset is used to evaluate image restoration performance, specifically addressing issues like rain and haze. Researchers employ metrics such as PSNR, SSIM, LPIPS, and FID to assess the effectiveness of restoration techniques. This dataset enables rigorous quantitative analysis, facilitating comparisons between different image restoration methods and enhancing the reliability of performance evaluations.
PromptIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The PromptIR dataset is used to assess and evaluate prompt-based image restoration techniques, focusing on diverse image degradations. It enables researchers to test and compare image restoration methods, particularly those that incorporate prompts, to address various degradation issues. This dataset supports the development and refinement of prompt-based approaches in image restoration.
PIP	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The PIP dataset is used to evaluate and test image restoration methods, focusing on their ability to handle multiple and complex degradations simultaneously. This dataset enables researchers to assess the effectiveness of restoration techniques in diverse and challenging scenarios, ensuring robust performance across various image degradations.
TextpromptIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The TextpromptIR dataset is used to test and evaluate text-prompt guided image restoration methods, focusing on the integration of textual information into the image restoration process. This dataset enables researchers to assess how effectively textual prompts can enhance or guide the restoration of images, addressing specific research questions related to the performance and accuracy of these methods.
NDR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The NDR dataset is used to evaluate and assess noise reduction techniques in image restoration, specifically focusing on natural image datasets. It enables researchers to test and compare the effectiveness of various noise reduction methods, contributing to advancements in image restoration methodologies.
InstructIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The InstructIR dataset is used to assess and evaluate instruction-based image restoration methods, focusing on the ability to follow complex restoration commands. It enables researchers to test and compare different approaches in executing detailed restoration tasks, ensuring that the methodologies can accurately interpret and apply complex instructions to restore images.
AdaIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The AdaIR dataset is used to evaluate and test adaptive image restoration methods, specifically focusing on dynamic adjustment to image degradations and frequency mining and modulation. It enables researchers to assess the effectiveness of these techniques in handling various image degradations, thereby advancing the field of adaptive image restoration.
U-WADN	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The U-WADN dataset is used to test and evaluate image restoration methods, particularly focusing on unified-width adaptive dynamic networks for all-in-one image restoration. It is employed to assess the performance of these methods in handling diverse image degradations, enabling researchers to compare and refine techniques for robust image restoration.
DyNet	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The DyNet dataset is used to evaluate and assess dynamic network architectures and techniques for image restoration, specifically focusing on their adaptability to various image degradations. This dataset enables researchers to test and compare the performance of dynamic networks in handling different types of image restoration challenges, ensuring robustness and versatility in restoration methods.
AnyIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The AnyIR dataset is used to evaluate all-in-one image restoration methods, specifically focusing on their ability to handle multiple degradations and their versatility. This dataset enables researchers to assess the performance of these techniques under diverse conditions, ensuring they can effectively restore images with various types of degradation.
DaAIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The DaAIR dataset is used to evaluate and enhance data-augmented image restoration techniques, specifically focusing on improving the generalization capabilities of these methods. It is employed in testing and assessing various data-augmentation strategies to ensure that image restoration models perform well across diverse and unseen data. This dataset enables researchers to address the challenge of robustness in image restoration by providing a platform to rigorously test and refine their methodologies.
MEASNet	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The MEASNet dataset is used to evaluate multi-exposure adaptive synthesis networks and other multi-exposure image restoration techniques, specifically focusing on exposure correction. It enables researchers to test and assess the performance of these methods in enhancing image quality under varying exposure conditions.
HAIR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The HAIR dataset is used to evaluate hybrid adaptive and hybrid image restoration techniques, focusing on the combination of multiple restoration approaches. It enables researchers to assess the effectiveness of integrating various methods in image restoration, enhancing the robustness and adaptability of restoration algorithms.
Perceive-IR	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2401.13221 (2024)	The Perceive-IR dataset is used to assess and test perception-driven image restoration methods, focusing on enhancing visual quality. It enables researchers to evaluate the effectiveness of these methods by providing a benchmark for visual improvement, ensuring that restored images meet high perceptual standards.
rain-haze-noise-blur-dark	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.48550/arXiv.2403.14614 (2024)	The 'rain-haze-noise-blur-dark' dataset is used to evaluate image restoration techniques and all-in-one image restoration models. It focuses on images degraded by rain, haze, noise, blur, and low-light conditions. This dataset enables researchers to assess the effectiveness of restoration methods in handling multiple degradations simultaneously, providing a comprehensive evaluation framework for advanced image restoration algorithms.
TE42	https://doi.org/10.48550/arXiv.2506.16960 (2025)	https://doi.org/10.1007/978-981-15-5873-3_2 (2021)	The TE42 dataset is used to construct a pool of visual grounds for image restoration, specifically for camera testing and visual analysis. It provides a standardized set of images that enable researchers to evaluate and compare the performance of different image restoration techniques under various conditions. This dataset facilitates the development and refinement of algorithms by offering a consistent benchmark for visual quality assessment.
Singapore maritime dataset (SMD)	https://doi.org/10.48550/arXiv.2402.03738 (2024)	https://doi.org/10.1109/TITS.2016.2634580 (2016)	The Singapore maritime dataset (SMD) is used for water scene restoration and evaluating image restoration methods in maritime environments. It provides maritime images to test and improve restoration algorithms, particularly focusing on addressing visibility issues in hazy conditions. This dataset enables researchers to assess and enhance the performance of restoration techniques in challenging maritime settings.
LOL dataset	https://doi.org/10.1109/TMM.2025.3535316 (2024), https://doi.org/10.1109/TCSVT.2024.3519352 (2025)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The LOL dataset is used to evaluate the performance of low-light image enhancement methods, focusing on both quantitative metrics and visual quality improvements in low-light conditions. It enables researchers to assess and compare the effectiveness of different enhancement techniques, ensuring they meet the necessary standards for improving image clarity and detail in challenging lighting environments.
RainDS-syn	https://doi.org/10.1109/TMM.2025.3535316 (2024)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The RainDS-syn dataset is used to evaluate rain and raindrop removal techniques, featuring synthetic images with both rain and raindrop effects. Researchers employ this dataset to test and validate algorithms designed to restore images degraded by rain, focusing on the effectiveness of removing both rain streaks and raindrops. This dataset enables the assessment of image restoration methods under controlled conditions, providing a benchmark for comparing different approaches.
U45	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/TCSVT.2019.2963772 (2019)	The U45 dataset is used for evaluating and visually comparing underwater image enhancement algorithms, particularly focusing on real-world conditions under natural light. It enables researchers to assess the effectiveness of restoration techniques in enhancing underwater images, ensuring they perform well in natural lighting scenarios.
SQUID-16	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/TCSVT.2019.2963772 (2019)	The SQUID-16 dataset is used for testing and visual comparison of underwater image enhancement techniques, particularly focusing on natural lighting conditions and real-world scenarios. It enables researchers to evaluate the effectiveness of restoration methods in improving image quality under natural light, facilitating advancements in underwater imaging.
RESIDE-β	https://doi.org/10.48550/arXiv.2408.15994 (2024), https://doi.org/10.1109/TCSVT.2024.3429557 (2024)	https://doi.org/10.1109/CVPR.2017.183 (2016)	The RESIDE-β dataset is used for training models in image deraining and dehazing. It contains 72,135 image pairs, which are utilized to enhance model performance in removing rain and improving visibility in hazy images. This dataset enables researchers to develop and refine algorithms that address specific image degradation issues, focusing on practical applications in image restoration.
RTTS	https://doi.org/10.48550/arXiv.2408.15994 (2024)	https://doi.org/10.1109/ACSSC.2011.6190099 (2011)	The RTTS dataset is used for evaluating image restoration methods, particularly in scenarios where reference images are unavailable. It employs non-reference metrics for quantitative comparison, enabling researchers to assess the performance of restoration algorithms. Specifically, it is used to measure the effectiveness of haze removal techniques in real-world hazy conditions, providing a practical testbed for algorithmic improvements.
Snow100K-S	https://doi.org/10.3390/electronics13142817 (2024), https://doi.org/10.48550/arXiv.2504.09973 (2025)	https://doi.org/10.1109/ICCV48922.2021.00416 (2021)	The Snow100K-S dataset is used for evaluating and testing single image desnowing algorithms. It focuses on smaller-scale synthetic snowy images with varying intensities and complexities to assess algorithm performance. This dataset enables researchers to systematically analyze the effectiveness of snow removal techniques, providing a standardized benchmark for comparing different methods.
Google Landmarks dataset	https://doi.org/10.48550/arXiv.2411.18412 (2024)	https://doi.org/10.1109/CVPRW.2019.00251 (2019)	The Google Landmarks dataset is used to train and evaluate image restoration models, particularly focusing on high-quality images with NIMA scores exceeding 4.90 and resolutions greater than 400 pixels. This dataset provides a diverse set of real-world scenes, enabling researchers to test and improve the performance of their models in realistic conditions.
Test100	https://doi.org/10.1109/TCSVT.2024.3398810 (2023)	https://doi.org/10.1109/CVPR.2018.00079 (2018)	The Test100 dataset is used for evaluating the generalization capabilities of image restoration models, particularly focusing on their performance with diverse rain patterns. It serves as a smaller test set to provide insights into how well these models can handle varied conditions, enhancing the understanding of model robustness and adaptability.
SNOW 100K	https://doi.org/10.1109/TCSVT.2024.3429557 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The SNOW 100K dataset is used to evaluate model performance in complex snow scenarios, focusing on the effectiveness of models in addressing intricate snow degradations. This dataset enables researchers to test and validate their models against challenging snow conditions, ensuring robustness and reliability in real-world applications.
Houston University	https://doi.org/10.48550/arXiv.2503.09131 (2025)		The Houston University dataset is used to evaluate all-in-one image restoration methods, particularly focusing on the effectiveness of partitioning strategies in urban areas. This dataset enables researchers to assess how well these methods perform in complex urban environments, providing insights into the practical applicability of image restoration techniques.
WDC	https://doi.org/10.48550/arXiv.2503.09131 (2025)		The WDC dataset is used to evaluate all-in-one image restoration methods, particularly focusing on the effectiveness of partitioning strategies in urban areas. This involves assessing how well these methods can restore images by dividing them into manageable sections, enhancing the accuracy and efficiency of restoration in complex urban environments.
DID	https://doi.org/10.48550/arXiv.2412.20157 (2024)	https://doi.org/10.1109/CVPR.2017.186 (2017)	The DID dataset is primarily used for training deraining models, providing a diverse set of synthetic rain images. This enhances the robustness of the models by exposing them to varied rain conditions. The dataset's synthetic nature allows researchers to control and manipulate rain characteristics, improving the model's generalization and performance in real-world scenarios.
DDN	https://doi.org/10.48550/arXiv.2412.20157 (2024)	https://doi.org/10.1109/CVPR.2017.186 (2017)	The DDN dataset is used for training deraining models by providing additional synthetic rain images. This expands the training dataset, enhancing model performance in removing rain from images. The dataset's synthetic nature allows researchers to augment their training data, addressing the challenge of limited real-world rain imagery.
Laion-High-Resolution	https://www.semanticscholar.org/paper/7d7712fbd2f7cdda845c176b03b84f2df93a8b2f (2025)	https://doi.org/10.48550/arXiv.2210.08402 (2022)	The Laion-High-Resolution dataset is used to select high-quality, diverse images for image restoration experiments, specifically focusing on enhancing image resolution and quality. Researchers employ this dataset to evaluate and improve image restoration techniques, leveraging its rich and varied content to ensure robust and effective enhancement methods.
MiO100	https://doi.org/10.48550/arXiv.2503.09403 (2025)	https://doi.org/10.48550/arXiv.2401.03379 (2024)	The MiO100 dataset is used to generate low-quality images with mixed degradations, specifically for testing multiple-in-one image restoration methods. Researchers employ sequential and prompt learning strategies to evaluate these methods, focusing on their effectiveness in handling various image degradations. This dataset enables the development and assessment of advanced image restoration techniques by providing a diverse set of degraded images.
new dataset	https://doi.org/10.1109/CVPR52688.2022.00239 (2021)	https://doi.org/10.1109/CVPR.2018.00263 (2017)	The 'new dataset' is specifically used for raindrop removal in image restoration research. It supports the training and evaluation of models aimed at restoring images degraded by raindrops. This dataset enables researchers to develop and test algorithms that enhance image quality by effectively removing raindrop artifacts, focusing on improving visual clarity and detail in rainy conditions.
FoggyCityscape	https://doi.org/10.1109/TMM.2024.3377136 (2024)	https://doi.org/10.1007/s11263-018-1072-8 (2017)	The FoggyCityscape dataset is used to evaluate image restoration techniques, particularly focusing on images with synthetic fog and noise. Researchers employ this dataset to assess the effectiveness of restoration methods in challenging atmospheric conditions, ensuring that algorithms can enhance image clarity and reduce noise. This dataset enables rigorous testing and comparison of different restoration approaches, contributing to advancements in image processing under foggy conditions.
Cityscape	https://doi.org/10.1109/TMM.2024.3377136 (2024)	https://doi.org/10.1109/TPAMI.2016.2577031 (2015)	The Cityscape dataset is primarily used for pre-training the Faster-RCNN object detector, enhancing object detection accuracy in the context of all-in-one image restoration. This dataset's rich annotations and diverse urban scenes enable researchers to improve the robustness and precision of object detection models, which is crucial for effective image restoration tasks.
UAVDT	https://doi.org/10.1109/TIP.2025.3572788 (2025)	https://doi.org/10.1007/978-3-030-01249-6_23 (2018)	The UAVDT dataset is used to evaluate the generalization capability of models in image restoration, particularly focusing on the unique degradation aspects of UAV-captured images, such as varying levels of haze. This dataset enables researchers to test and improve restoration techniques tailored to aerial imagery, enhancing the clarity and usability of UAV-captured images.
SPAD	https://doi.org/10.1109/TIP.2025.3572788 (2025)	https://doi.org/10.1109/CVPR.2019.01255 (2019)	The SPAD dataset is used for conducting image restoration experiments, particularly focusing on image deraining. Researchers employ this dataset to evaluate the effectiveness of various image restoration techniques. The dataset's specific characteristics and images enable rigorous testing and validation of deraining algorithms, contributing to advancements in image restoration methodologies.
UHD-LOL	https://doi.org/10.1109/TCSVT.2024.3516074 (2024)	https://doi.org/10.48550/arXiv.2212.11548 (2022)	The UHD-LOL dataset is used to enhance low-light images in ultra-high-definition settings, specifically addressing complex lighting conditions. Researchers apply this dataset to improve image quality under challenging lighting scenarios, focusing on methodologies that enhance visibility and detail in low-light environments. This dataset enables the development and evaluation of advanced image enhancement techniques, ensuring better performance in real-world applications.
Real-ESRGAN	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://www.semanticscholar.org/paper/49b64383fe36268410c430352637ed23b16820c5 (2019)	The Real-ESRGAN dataset is used to generate degraded images for training and evaluation, focusing on various degradation configurations. This enhances the robustness of image restoration models. The dataset's ability to simulate diverse degradations is crucial for improving model performance across different scenarios. It enables researchers to test and refine algorithms specifically designed to handle complex image restoration challenges.
SOTS outdoors	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1007/978-3-030-58607-2_7 (2020)	The SOTS outdoors dataset is primarily used for evaluating dehazing algorithms. It provides a collection of outdoor scenes with both synthetic and real haze, enabling researchers to test and compare the effectiveness of different dehazing techniques. This dataset facilitates the assessment of algorithm performance in realistic conditions, enhancing the robustness and reliability of dehazing methods.
LOL ProRes	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	The LOL ProRes dataset is used for low-light image restoration, specifically to enhance images captured in low-light environments. Researchers employ this dataset to develop and evaluate algorithms that improve image quality under low-light conditions. The dataset's focus on low-light scenarios makes it particularly relevant for advancing techniques in this specialized area of image processing.
Transweather	https://doi.org/10.48550/arXiv.2410.15067 (2024)	https://doi.org/10.1109/CVPR52729.2023.02083 (2023)	The Transweather dataset is used for all-weather image restoration, specifically addressing rain, fog, and snow conditions. Researchers employ this dataset to develop and evaluate algorithms that enhance image quality under adverse weather conditions. The dataset's focus on diverse weather scenarios enables robust testing and validation of image restoration techniques, ensuring they perform effectively in real-world applications.
Motion Deblur	https://doi.org/10.48550/arXiv.2506.16960 (2025)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The Motion Deblur dataset is used to train and evaluate image deblurring models, specifically focusing on dynamic scenes captured by GoPro cameras. This dataset enables researchers to address the challenge of restoring clear images from motion-blurred ones, enhancing the quality of visual data in dynamic environments.
TURBID	https://doi.org/10.48550/arXiv.2506.16960 (2025)	https://doi.org/10.1109/LRA.2020.2974710 (2019)	The TURBID dataset is used to evaluate underwater image enhancement techniques, specifically focusing on improving visual perception. It is employed in methodologies that assess the effectiveness of these techniques, as evidenced by the use of Table 1 for performance evaluation. This dataset enables researchers to address the challenge of enhancing image clarity in underwater environments, which is crucial for various underwater imaging applications.
SOTS-Indoor	https://doi.org/10.1109/TCSVT.2024.3429557 (2024)	https://doi.org/10.1109/TIP.2023.3256763 (2022)	The SOTS-Indoor dataset is used to evaluate the performance of single image dehazing methods, specifically comparing the proposed method against DehazeFormer-L. Research focuses on metrics such as PSNR and computational efficiency (FLOPs). This dataset enables researchers to benchmark and validate the effectiveness and efficiency of their dehazing algorithms in indoor environments.
SMD	https://doi.org/10.48550/arXiv.2402.03738 (2024)	https://doi.org/10.1109/TITS.2016.2634580 (2016)	The SMD dataset is used to evaluate dehazing methods in image restoration research. It focuses on assessing image quality improvement through metrics such as PSNR, SSIM, and NIQE. This dataset enables researchers to quantitatively compare the effectiveness of different dehazing techniques, providing a standardized benchmark for performance evaluation.
Set12	https://doi.org/10.1109/CVPR52733.2024.00277 (2023)	https://doi.org/10.1109/TIP.2017.2662206 (2016)	Set12 is used to evaluate methods for grayscale image denoising, focusing on performance and quality improvements. The dataset's small, well-curated nature makes it suitable for detailed assessments of denoising techniques, enabling researchers to measure specific enhancements in image restoration accuracy and efficiency.
Enhancing Under-water Visual Perception (EUVP)	https://doi.org/10.48550/arXiv.2310.10123 (2023)	https://doi.org/10.1109/CVPR46437.2021.00906 (2020)	The EUVP dataset is used to evaluate techniques for reducing underexposure and blur artifacts in underwater images, enhancing visual perception. Researchers employ this dataset to test and validate methods that improve image clarity and quality, focusing on specific challenges like low light and distortion. This enables more accurate and reliable underwater imaging for various applications.
Enhancing Underwater Visual Perception (EUVP) dataset	https://doi.org/10.48550/arXiv.2310.10123 (2023)	https://doi.org/10.48550/arXiv.2309.06380 (2023)	The EUVP dataset is used to evaluate image restoration methods on underwater images, focusing on issues such as color correction and clarity improvement. Researchers employ this dataset to test and validate their algorithms, ensuring they effectively enhance visual perception in underwater environments. The dataset's relevance lies in its ability to provide realistic challenges for image restoration techniques, making it a valuable resource for advancing underwater visual perception technologies.
unseen under-display-camera dataset	https://doi.org/10.48550/arXiv.2310.10123 (2023)	https://doi.org/10.48550/arXiv.2309.06380 (2023)	The unseen under-display-camera dataset is used to test image restoration techniques, specifically focusing on reducing artifacts and enhancing image quality in under-display-camera images. Researchers employ this dataset to evaluate and improve the performance of image restoration algorithms, addressing challenges unique to under-display-camera technology.
WEB	https://doi.org/10.1109/TIP.2024.3456583 (2023)	https://doi.org/10.1109/TIP.2016.2631888 (2017)	The WEB dataset is used for training denoising models, providing web-based images that enhance the real-world applicability of these models. This dataset enables researchers to develop and refine algorithms that can effectively reduce noise in images sourced from the internet, improving their quality and usability in various applications.
NTIRE	https://doi.org/10.48550/arXiv.2404.02154 (2024)	https://doi.org/10.1109/CVPRW53098.2021.00074 (2021)	The NTIRE dataset is used to provide high-quality, high-resolution natural images for training and evaluation in image restoration tasks. It supports the development and assessment of algorithms designed to enhance image quality, focusing on restoring degraded images to their original state. This dataset enables researchers to benchmark and compare the performance of different restoration techniques effectively.
Flikr2K	https://doi.org/10.48550/arXiv.2404.02154 (2024)	https://doi.org/10.1109/CVPRW53098.2021.00074 (2021)	The Flikr2K dataset is used for training and evaluating image restoration models, focusing on diverse content and real-world image challenges. It enables researchers to test the robustness and versatility of their models by providing a wide range of image types and conditions, enhancing the reliability of image restoration techniques.
Laion-HR	https://doi.org/10.48550/arXiv.2404.02154 (2024)	https://doi.org/10.1109/CVPRW53098.2021.00074 (2021)	The Laion-HR dataset is used for large-scale image restoration, providing millions of high-resolution images to enhance the generalization and performance of restoration models. This dataset enables researchers to train and evaluate models on a diverse set of high-quality images, improving the robustness and effectiveness of image restoration techniques.
Snow100k-R	https://doi.org/10.48550/arXiv.2411.10708 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The Snow100k-R dataset is used to evaluate the effectiveness of AllRestorer in snow removal, focusing on enhancing clarity and detail in snowy scenes. This dataset enables researchers to assess the performance of image restoration techniques specifically designed to handle snow-related distortions, ensuring that restored images are clearer and more detailed.
SPA-Data	https://doi.org/10.48550/arXiv.2411.10708 (2024)	https://doi.org/10.1109/TIP.2018.2806202 (2017)	The SPA-Data dataset is used to evaluate the performance of AllRestorer in various real-world scenarios, focusing on multiple types of image degradation and restoration challenges. This dataset enables researchers to assess the effectiveness of image restoration techniques under diverse conditions, ensuring robustness and versatility in practical applications.
OTS dataset of RESIDE-β	https://doi.org/10.48550/arXiv.2408.15994 (2024)	https://doi.org/10.1109/ICCV.2001.937655 (2001)	The OTS dataset of RESIDE-β is primarily used for training image dehazing models, providing a large set of paired images that facilitate the development and improvement of these models. This dataset enables researchers to enhance the clarity of hazy images by training algorithms to effectively remove atmospheric haze, thereby improving image quality and visual clarity.
UIEB	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1016/j.image.2020.115978 (2019)	The UIEB dataset is used in research to evaluate and compare the visual quality and restoration effectiveness of enhanced underwater images against reference images. This involves assessing the performance of image enhancement techniques, focusing on how well they improve the clarity and detail of underwater scenes. The dataset enables researchers to quantitatively and qualitatively analyze the outcomes of different restoration methods, ensuring that enhancements are both visually appealing and scientifically valid.
LOL-v2-real	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1016/j.cviu.2022.103403 (2022)	The LOL-v2-real dataset is used to validate the performance of UniUIR on real-world low-light image enhancement, specifically by comparing it against other methods. This dataset enables researchers to assess the effectiveness of image enhancement techniques in practical, low-light conditions, ensuring that the methods can be reliably applied in real-world scenarios.
SID	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1016/j.cviu.2022.103403 (2022)	The SID dataset is used to validate the performance of UniUIR on low-light image enhancement, specifically focusing on Sony camera images. It enables researchers to assess and improve the effectiveness of image restoration techniques under low-light conditions, leveraging the dataset's characteristic focus on Sony camera data.
BAID	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1016/j.cviu.2022.103403 (2022)	The BAID dataset is used to validate the performance of UniUIR on backlit image enhancement, specifically by comparing it against other methods. This dataset enables researchers to assess and benchmark the effectiveness of image restoration techniques in enhancing backlit images, focusing on the improvement of visual quality and detail recovery.
T90	https://doi.org/10.48550/arXiv.2501.12981 (2025)	https://doi.org/10.1109/ICCV51070.2023.00371 (2023)	The T90 dataset is used to assess the effectiveness of underwater image restoration techniques on segmentation performance. Researchers apply the Segment Anything Model (SAM) to restored images from various underwater image restoration (UIR) methods, evaluating how these enhancements improve segmentation accuracy. This dataset enables the comparison of different UIR approaches and their impact on downstream computer vision tasks.
SIDD val	https://doi.org/10.48550/arXiv.2408.15994 (2024)	https://doi.org/10.48550/arXiv.2206.05514 (2022)	The SIDD val dataset is used to evaluate noise reduction in images, specifically focusing on real-world noise patterns and restoration quality. Researchers employ this dataset to assess the performance of image restoration techniques, ensuring they effectively handle authentic noise scenarios. This enables the development and refinement of algorithms that improve image clarity and fidelity in practical applications.
RealRain-1k-L	https://doi.org/10.48550/arXiv.2408.15994 (2024)	https://doi.org/10.48550/arXiv.2206.05514 (2022)	The RealRain-1k-L dataset is used to test rain removal algorithms, specifically focusing on their performance in real-world rainy scenes. Researchers employ this dataset to evaluate the effectiveness of deraining methodologies, ensuring they can handle authentic rain conditions. This dataset enables the assessment of algorithmic robustness and reliability in practical deraining applications.
SOTS (outdoor)	https://doi.org/10.1007/978-3-031-72764-1_1 (2024)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The SOTS (outdoor) dataset is used to evaluate dehazing methods, specifically focusing on outdoor scenes. It enables researchers to assess the performance of these methods in realistic conditions, ensuring that the dehazing techniques are effective in practical scenarios. The dataset's emphasis on outdoor environments provides a robust testbed for dehazing algorithms.
SOTS outdoor dataset	https://doi.org/10.1007/978-3-031-72764-1_1 (2024)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The SOTS outdoor dataset is used for dehazing comparisons in all-in-one image restoration methods, specifically to enhance outdoor image quality and improve clarity. Researchers employ this dataset to evaluate and compare the effectiveness of different dehazing techniques, focusing on the visual quality and clarity of restored images.
REDS dataset	https://doi.org/10.48550/arXiv.2411.18412 (2024)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The REDS dataset is used to evaluate methods for handling blur and JPEG artifacts in image restoration. Research focuses on assessing the effectiveness of approaches in managing compression artifacts, utilizing the dataset's characteristics to test and validate restoration techniques. This enables researchers to improve image quality in scenarios involving both blurring and compression.
SRRS dataset	https://doi.org/10.48550/arXiv.2411.18412 (2024)	https://doi.org/10.1109/CVPR.2017.35 (2016)	The SRRS dataset is used to evaluate image restoration approaches, particularly focusing on the robustness of methods in complex weather conditions such as haze and snow. Researchers employ this dataset to test and validate their algorithms, ensuring they can effectively handle multiple degradations simultaneously. This enables the assessment of performance in realistic, challenging environments.
BSD300	https://doi.org/10.1109/TCSVT.2024.3398810 (2023)	https://doi.org/10.1109/TCSVT.2019.2920407 (2017)	The BSD300 dataset is primarily used for image denoising research, where it serves as a benchmark for evaluating the performance of noise reduction techniques. Specifically, it is utilized in studies employing conditional generative adversarial networks (cGANs) to enhance image quality by effectively reducing noise. This dataset's diverse and high-quality images enable researchers to test and refine their models, ensuring robustness and generalizability in various denoising applications.
MIR	https://doi.org/10.48550/arXiv.2503.09131 (2025)	https://doi.org/10.4231/R7RX991C (2015)	The MIR dataset is used for fine-tuning models in real-world denoising scenarios, specifically to enhance denoising performance across diverse conditions. This dataset enables researchers to improve the robustness and effectiveness of image restoration models by providing a variety of real-world noise patterns, thus addressing the challenge of achieving high-quality denoising in practical applications.
Mix Degradations datasets	https://doi.org/10.48550/arXiv.2406.18242 (2024)	https://doi.org/10.1109/CVPR52688.2022.00564 (2021)	The Mix Degradations dataset is used to evaluate the performance of ConStyle models converted from U-Net models, specifically focusing on image restoration tasks under various degradations. This dataset enables researchers to assess how well these models handle different types of image degradations, providing insights into their effectiveness and robustness in real-world scenarios.
ImageNet	https://doi.org/10.48550/arXiv.2411.17687 (2024)	https://doi.org/10.1109/CVPR.2009.5206848 (2009)	The ImageNet dataset is primarily used to pre-train transformer encoders, which enhances their feature extraction capabilities. This pre-training focuses on improving generalization for image restoration tasks. The dataset's large scale and diverse image content enable researchers to develop models that perform well across various restoration challenges, leveraging the rich feature representations learned from ImageNet.
DF2K	https://doi.org/10.48550/arXiv.2504.09973 (2025)	https://doi.org/10.48550/arXiv.2401.03379 (2024)	The DF2K dataset is used to evaluate the versatility of image restoration methods across a comprehensive seven-task benchmark. This benchmark assesses the method's performance on diverse image restoration tasks, leveraging the dataset's extensive and varied content. The dataset enables researchers to test and validate their approaches in a robust, multi-faceted manner, ensuring broad applicability and effectiveness in real-world scenarios.
Indoor Training Set (ITS)	https://doi.org/10.1109/TCSVT.2024.3519352 (2025)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The Indoor Training Set (ITS) is used for training dehazing models on indoor scenes. It provides a diverse set of synthetic images with known ground truth, enabling researchers to develop and evaluate dehazing algorithms effectively. The dataset's synthetic nature and ground truth data facilitate the assessment of model performance in various indoor conditions.
Outdoor Training Set (OTS)	https://doi.org/10.1109/TCSVT.2024.3519352 (2025)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The Outdoor Training Set (OTS) is primarily used for training dehazing models on outdoor scenes. It offers a wide range of environmental conditions and lighting, enabling researchers to develop and test algorithms that effectively remove haze from images. This dataset supports the creation of robust dehazing models by providing diverse and realistic scenarios.
Real-world Task-driven Testing Set (RTTS)	https://doi.org/10.1109/TCSVT.2024.3519352 (2025)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The Real-world Task-driven Testing Set (RTTS) is used for evaluating dehazing models on real-world images, with a focus on task-specific performance in practical applications. This dataset enables researchers to assess how well dehazing algorithms function in real-world scenarios, ensuring that the models are effective beyond controlled environments. The dataset's emphasis on real-world conditions enhances the validity and applicability of the research findings.
Synthetic Objective Testing Set (SOTS)	https://doi.org/10.1109/TCSVT.2024.3519352 (2025)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The Synthetic Objective Testing Set (SOTS) is used for the objective evaluation of dehazing algorithms. It contains synthetic images with controlled parameters, enabling researchers to assess the performance of dehazing techniques systematically. The dataset's controlled environment facilitates precise performance measurement, making it a valuable resource for evaluating and comparing dehazing methods.
Hybrid Subjective Testing Set (HSTS)	https://doi.org/10.1109/TCSVT.2024.3519352 (2025)	https://doi.org/10.1109/TIP.2018.2867951 (2017)	The Hybrid Subjective Testing Set (HSTS) is used for subjective evaluation of dehazing results, integrating both synthetic and real-world images to assess visual quality. This dataset enables researchers to evaluate and compare the effectiveness of dehazing algorithms by providing a diverse set of images that reflect various real-world conditions and synthetic scenarios.
LSRW	https://doi.org/10.1109/TCSVT.2024.3519352 (2025)	https://www.semanticscholar.org/paper/c7798bbbcd2e85593a2b2d37b92dabac63420cd8 (2018)	The LSRW dataset is used for low-light image enhancement, focusing on training and testing models. It employs a partition ratio of 5600:50 for training and testing sets, respectively. This dataset enables researchers to develop and evaluate algorithms that improve image quality in low-light conditions, addressing specific challenges in image restoration and enhancement.
